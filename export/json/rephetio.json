{
  "comments": [
    {
      "body_html": "<p>We are looking to construct a catalog of <a href=\"https://en.wikipedia.org/wiki/Indication_%28medicine%29\">indications</a> (efficacious drug-disease pairs) with the following attributes (ordered by importance):</p>\r\n\r\n<ol><li>automated and high-throughput construction</li><li>high-quality, or varying levels of quality as long as quality level is annotated</li><li>comprehensive</li><li>disease modifying rather than symptomatic</li><li>compounds which map to pubchem</li><li><a href=\"https://en.wikipedia.org/wiki/Contraindication\">contraindications</a> and adverse effects are excluded and cataloged separately</li><li>diseases which map to the disease ontology</li><li>source is retrievable</li></ol>\r\n\r\n<p>A few options we can consider:</p>\r\n\r\n<ul><li><a href=\"http://ftp.ncbi.nlm.nih.gov/pub/lu/LabeledIn/\"><strong>LabeledIn</strong></a> — Curators manually identified indications from drug labels for 250 human prescription ingredients (drugs) <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.jbi.2014.08.004\" class=\"citation\" data-key=\"10.1016/j.jbi.2014.08.004\">1</a>]</span>.</li><li><a href=\"http://knowledgemap.mc.vanderbilt.edu/research/content/MEDI\"><strong>MEDI</strong></a> — Indications extracted from RxNorm, SIDER 2, MedlinePlus, and Wikipedia were integrated into a single resource. The high-precision subset (indications in RxNorm or two other resources) includes 13,304 unique indications for 2,136 medications <span class=\"citation\">[<a href=\"https://doi.org/10.1136/amiajnl-2012-001431\" class=\"citation\" data-key=\"10.1136/amiajnl-2012-001431\">2</a>]</span>. Further work added indication prevalence information <span class=\"citation\">[<a href=\"http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3900157/\" class=\"citation\" data-key=\"MediPrev\">3</a>]</span>. MEDI compares favorably to SemRep for extracting indications from clinical text <span class=\"citation\">[<a href=\"https://doi.org/10.1136/amiajnl-2014-002954\" class=\"citation\" data-key=\"10.1136/amiajnl-2014-002954\">4</a>]</span>.</li><li><strong>SemRep</strong> — \"<a href=\"http://semrep.nlm.nih.gov/\">SemRep</a> is a program that extracts semantic predications (subject-relation-object triples) from biomedical free text\" <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.jbi.2003.11.003\" class=\"citation\" data-key=\"10.1016/j.jbi.2003.11.003\">5</a>]</span>. SemRep has been used to extract <em>TREAT</em> relations from MeSH scope notes, Daily Med, DrugBank, and <a href=\"http://www.ahfsdruginformation.com/product-consumer-info.aspx\">AHFS Consumer Medication Information</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1145/1882992.1883096\" class=\"citation\" data-key=\"10.1145/1882992.1883096\">6</a>]</span>. SemRep has also been used to identify <em>TREAT</em> relations from Medline abstracts <span class=\"citation\">[<a href=\"http://www.d.umn.edu/~tpederse/Pubs/amia2012-liu.pdf\" class=\"citation\" data-key=\"LiuSemRep\">7</a>]</span>. A project called <a href=\"//skr3.nlm.nih.gov/SemMedDB/\">SemMedDB</a> provides the SemRep results from mining PubMed <span class=\"citation\">[<a href=\"https://doi.org/10.1093/bioinformatics/bts591\" class=\"citation\" data-key=\"10.1093/bioinformatics/bts591\">8</a>]</span>. </li><li><strong>SPL-X</strong> — <strong>S</strong>tructured <strong>P</strong>roduct <strong>L</strong>abels e<strong>X</strong>tractor — Using MetaMap, this project extracted indications from DailyMed drug labels that were available as XML <span class=\"citation\">[<a href=\"https://doi.org/10.1136/amiajnl-2012-001291\" class=\"citation\" data-key=\"10.1136/amiajnl-2012-001291\">9</a>]</span>. Data does not appear to be available.</li><li><strong><a href=\"http://ctdbase.org/\">Comparative Toxicogenomics Database</a></strong> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gku935\" class=\"citation\" data-key=\"10.1093/nar/gku935\">10</a>]</span> — Manual literature curators annotated drug-disease pairs as 'therapeutic'. The resource is extensive (the 'therapeutic' threshold was low) but incomplete.</li><li><strong><a href=\"http://sideeffects.embl.de/\">SIDER 2</a></strong> — In addition to extracting side effects from drug labels, SIDER also extracts indications <span class=\"citation\">[<a href=\"https://doi.org/10.1038/msb.2009.98\" class=\"citation\" data-key=\"10.1038/msb.2009.98\">11</a>]</span>. Since the approach is automated, some side effects may be extracted as indications and <em>vice versa</em>. This approach would only provide information for drugs with labels from the US FDA or Canada.</li></ul>\r\n\r\n<p>Any additional resources or suggestions?</p>\r\n\r\n<p></p>\r\n\r\n<p></p>",
      "body_md": "We are looking to construct a catalog of [indications](https://en.wikipedia.org/wiki/Indication_%28medicine%29) (efficacious drug-disease pairs) with the following attributes (ordered by importance):\r\n\r\n1. automated and high-throughput construction\r\n+ high-quality, or varying levels of quality as long as quality level is annotated\r\n+ comprehensive\r\n+ disease modifying rather than symptomatic\r\n+ compounds which map to pubchem\r\n+ [contraindications](https://en.wikipedia.org/wiki/Contraindication) and adverse effects are excluded and cataloged separately\r\n+ diseases which map to the disease ontology\r\n+ source is retrievable\r\n\r\nA few options we can consider:\r\n\r\n+ [**LabeledIn**](http://ftp.ncbi.nlm.nih.gov/pub/lu/LabeledIn/) -- Curators manually identified indications from drug labels for 250 human prescription ingredients (drugs) [@10.1016/j.jbi.2014.08.004].\r\n+ [**MEDI**](http://knowledgemap.mc.vanderbilt.edu/research/content/MEDI) -- Indications extracted from RxNorm, SIDER 2, MedlinePlus, and Wikipedia were integrated into a single resource. The high-precision subset (indications in RxNorm or two other resources) includes 13,304 unique indications for 2,136 medications [@10.1136/amiajnl-2012-001431]. Further work added indication prevalence information [@MediPrev]. MEDI compares favorably to SemRep for extracting indications from clinical text [@10.1136/amiajnl-2014-002954].\r\n+ **SemRep** -- \"[SemRep](http://semrep.nlm.nih.gov/) is a program that extracts semantic predications (subject-relation-object triples) from biomedical free text\" [@10.1016/j.jbi.2003.11.003]. SemRep has been used to extract *TREAT* relations from MeSH scope notes, Daily Med, DrugBank, and [AHFS Consumer Medication Information](http://www.ahfsdruginformation.com/product-consumer-info.aspx) [@10.1145/1882992.1883096]. SemRep has also been used to identify *TREAT* relations from Medline abstracts [@LiuSemRep]. A project called [SemMedDB](//skr3.nlm.nih.gov/SemMedDB/) provides the SemRep results from mining PubMed [@10.1093/bioinformatics/bts591]. \r\n+ **SPL-X** -- **S**tructured **P**roduct **L**abels e**X**tractor -- Using MetaMap, this project extracted indications from DailyMed drug labels that were available as XML [@10.1136/amiajnl-2012-001291]. Data does not appear to be available.\r\n+ **[Comparative Toxicogenomics Database](http://ctdbase.org/)** [@10.1093/nar/gku935] -- Manual literature curators annotated drug-disease pairs as 'therapeutic'. The resource is extensive (the 'therapeutic' threshold was low) but incomplete.\r\n+ **[SIDER 2](http://sideeffects.embl.de/)** -- In addition to extracting side effects from drug labels, SIDER also extracts indications [@10.1038/msb.2009.98]. Since the approach is automated, some side effects may be extracted as indications and *vice versa*. This approach would only provide information for drugs with labels from the US FDA or Canada.\r\n\r\nAny additional resources or suggestions?\r\n\r\n[@LiuSemRep]: http://www.d.umn.edu/~tpederse/Pubs/amia2012-liu.pdf \"Liu, Ying, et al. 'Using SemRep to label semantic relations extracted from clinical text.' AMIA annual symposium proceedings. Vol. 2012. American Medical Informatics Association, 2012.\"\r\n\r\n[@MediPrev]: http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3900157/ \"Wei W-Q, Mosley JD, Bastarache L, Denny JC (2013) Validation and enhancement of a Computable Medication Indication Resource (MEDI) using a large practice-based dataset. AMIA Annual Symposium Proceedings.\"",
      "comment_id": 29,
      "profile_id": 17,
      "published": "2015-01-14T05:55:24.832895Z",
      "thread_id": 21,
      "url": "/discussion/how-should-we-construct-a-catalog-of-drug-indications/21"
    },
    {
      "body_html": "<p>Are there any types of nodes or edges that you think we should include? Or do you think there is a superior resource for an information type than the one proposed?</p>\r\n\r\n<p>When constructing edges, we prefer data that is:</p>\r\n\r\n<ul><li>systematic, without knowledge bias</li><li>extensive in coverage</li><li>easy to process</li><li>without prohibitive reuse restrictions</li></ul><p>For node suggestions, we prefer controlled vocabularies so annotating the nodes with new edge types in the future is possible.</p>",
      "body_md": "Are there any types of nodes or edges that you think we should include? Or do you think there is a superior resource for an information type than the one proposed?\r\n\r\nWhen constructing edges, we prefer data that is:\r\n\r\n+ systematic, without knowledge bias\r\n+ extensive in coverage\r\n+ easy to process\r\n+ without prohibitive reuse restrictions\r\n\r\nFor node suggestions, we prefer controlled vocabularies so annotating the nodes with new edge types in the future is possible.",
      "comment_id": 30,
      "profile_id": 17,
      "published": "2015-01-16T00:46:28.796323Z",
      "thread_id": 22,
      "url": "/discussion/suggestions-for-additional-information-types/22"
    },
    {
      "body_html": "<p>Daniel — we talked a bit about how you'll be constructing this resource in a manner that is automated and reproducible. I think it would be good to put these details in the research plan — it will give people more opportunities to make suggestions. And if you'll be using techniques that you've used before it's probably a good idea to link people to that work.</p>\r\n\r\n<p>I want people to be able to share their opinion on how you can create the most value from this project. I'm sure you'll agree that enabling reproducibility and reuse is a big part of that.</p>\r\n\r\n<p>What do you think?</p>",
      "body_md": "Daniel -- we talked a bit about how you'll be constructing this resource in a manner that is automated and reproducible. I think it would be good to put these details in the research plan -- it will give people more opportunities to make suggestions. And if you'll be using techniques that you've used before it's probably a good idea to link people to that work.\r\n\r\nI want people to be able to share their opinion on how you can create the most value from this project. I'm sure you'll agree that enabling reproducibility and reuse is a big part of that.\r\n\r\nWhat do you think?",
      "comment_id": 31,
      "profile_id": 2,
      "published": "2015-01-16T10:18:57.266583Z",
      "thread_id": 23,
      "url": "/discussion/enabling-reproducibility-and-reuse/23"
    },
    {
      "body_html": "<blockquote><p>I think it would be good to put these details in the research plan — it will give people more opportunities to make suggestions.</p></blockquote>\r\n\r\n<p>Perhaps, we should discuss here what formats of data and types of services would be most valuable to the community. Then once we reach some consensus, I will update the proposal.</p>\r\n\r\n<p>Currently, I was planning on releasing the network in a few file formats:</p>\r\n\r\n<ul><li>as a single JSON text file based on a <a href=\"https://github.com/dhimmel/hetio/blob/master/hetio/readwrite.py\">specification we've developed</a>.</li><li>as a <a href=\"http://wiki.cytoscape.org/Cytoscape_User_Manual/Network_Formats\">SIF file</a> which is a text file of all edges. We will also provide an accompanying node table, with node attributes. This format is ideal for <a href=\"http://www.cytoscape.org/\">Cytoscape</a> users.</li><li>as a <a href=\"https://en.wikipedia.org/wiki/Graph_Modelling_Language\">GML file</a> — a poorly documented and varyingly implemented format for storing graphs. Despite it's problems, this format is widely supported.</li><li>as separate files for each metanode and metaedge. This will help users who are only interested in a single part of the network, bypass having to process the rest of the network.</li><li>as matrices for edge types that were constructed from continuous pairwise scores.</li></ul><p>An online tool for browsing the network would also be nice. I will look into options here.</p>",
      "body_md": "> I think it would be good to put these details in the research plan -- it will give people more opportunities to make suggestions.\r\n\r\nPerhaps, we should discuss here what formats of data and types of services would be most valuable to the community. Then once we reach some consensus, I will update the proposal.\r\n\r\nCurrently, I was planning on releasing the network in a few file formats:\r\n\r\n+ as a single JSON text file based on a [specification we've developed](https://github.com/dhimmel/hetio/blob/master/hetio/readwrite.py).\r\n+ as a [SIF file](http://wiki.cytoscape.org/Cytoscape_User_Manual/Network_Formats) which is a text file of all edges. We will also provide an accompanying node table, with node attributes. This format is ideal for [Cytoscape](http://www.cytoscape.org/) users.\r\n+ as a [GML file](https://en.wikipedia.org/wiki/Graph_Modelling_Language) -- a poorly documented and varyingly implemented format for storing graphs. Despite it's problems, this format is widely supported.\r\n+ as separate files for each metanode and metaedge. This will help users who are only interested in a single part of the network, bypass having to process the rest of the network.\r\n+ as matrices for edge types that were constructed from continuous pairwise scores.\r\n\r\nAn online tool for browsing the network would also be nice. I will look into options here.",
      "comment_id": 32,
      "profile_id": 17,
      "published": "2015-01-16T19:49:29.082635Z",
      "thread_id": 23,
      "url": "/discussion/enabling-reproducibility-and-reuse/23#2"
    },
    {
      "body_html": "<p>I am looking for a method to weight features based on their uniqueness: I want to downweight redundant features and upweight distinct features.</p>\r\n\r\n<p>The specific problem is weighting side effects when calculating side effect similarity between two drugs. The initial implementation of this analysis <span class=\"citation\">[<a href=\"https://doi.org/10.1126/science.1158140\" class=\"citation\" data-key=\"10.1126/science.1158140\">1</a>]</span> used the Gerstein-Sonnhammer-Chothia Algorithm <span class=\"citation\">[<a href=\"https://doi.org/10.1016/0022-2836%2894%2990012-4\" class=\"citation\" data-key=\"10.1016/0022-2836(94)90012-4\">2</a>]</span>. The initial implementation <a href=\"http://www.sciencemag.org/content/suppl/2008/07/10/321.5886.263.DC1/Campillos.SOM.pdf\">describes their method</a>:</p>\r\n\r\n<blockquote><p>Not all side effects are independent of each other; for example, 90% of drugs that cause nausea also cause vomiting. We correct for this redundancy by weighting side effects in a manner analogous to the down-weighting of similar protein sequences within multiple alignments <span class=\"citation\">[<a href=\"https://doi.org/10.1016/0022-2836%2894%2990012-4\" class=\"citation\" data-key=\"10.1016/0022-2836(94)90012-4\">2</a>]</span> (Fig. S1C). In order to determine the correlation weight, the correlation of side effects was determined by clustering all side effects according to their assigned drugs using a Tanimoto/Jacquard score to compute a distance matrix: The distance between two drugs was calculated by dividing the number of drugs that feature both side effects by the number of drugs that have either side effect associated. <strong>The Gerstein–Sonnhammer–Chothia algorithm <span class=\"citation\">[<a href=\"https://doi.org/10.1016/0022-2836%2894%2990012-4\" class=\"citation\" data-key=\"10.1016/0022-2836(94)90012-4\">2</a>]</span> was used to compute weights based on a hierarchal clustering with the aforementioned distance matrix <span class=\"citation\">[<a href=\"https://doi.org/10.1073/pnas.95.25.14863\" class=\"citation\" data-key=\"10.1073/pnas.95.25.14863\">3</a>]</span>.</strong></p></blockquote>\r\n\r\n<p>I would like to perform an identical analysis, while making the code and results public. The analysis follows the following steps:</p>\r\n\r\n<ol><li>Calculating pairwise side effect correlations.</li><li>Performing hierarchical clustering of side effects to produce a dendrogram</li><li>Inputting the denrogram into the GSC algorithm to calculate side effect weights.</li></ol>\r\n\r\n<p>I am looking for an implementation of step 3, that it easy to integrate with implementations of steps 1 and 2. My preferred languages are <em>R</em>, <em>python</em>, and <em>julia</em> (in that order). The author should be willing to post the code publicly under an open source license.</p>\r\n\r\n<p>An in detail description of the GSC algorithm can be found in the paper appendix titled, <em><a href=\"https://pdf.yt/d/Sx3jMbr8vANgxAej/download\">A Method to Weight Protein Sequences to Correct for Unequal Representation</a></em>.</p>\r\n\r\n<p>Also, if you know of a simpler or superior method for accomplishing this weighting task, please suggest.</p>",
      "body_md": "I am looking for a method to weight features based on their uniqueness: I want to downweight redundant features and upweight distinct features.\r\n\r\nThe specific problem is weighting side effects when calculating side effect similarity between two drugs. The initial implementation of this analysis [@10.1126/science.1158140] used the Gerstein-Sonnhammer-Chothia Algorithm [@10.1016/0022-2836(94)90012-4]. The initial implementation [describes their method](http://www.sciencemag.org/content/suppl/2008/07/10/321.5886.263.DC1/Campillos.SOM.pdf):\r\n\r\n> Not all side effects are independent of each other; for example, 90% of drugs that cause nausea also cause vomiting. We correct for this redundancy by weighting side effects in a manner analogous to the down-weighting of similar protein sequences within multiple alignments [@10.1016/0022-2836(94)90012-4] (Fig. S1C). In order to determine the correlation weight, the correlation of side effects was determined by clustering all side effects according to their assigned drugs using a Tanimoto/Jacquard score to compute a distance matrix: The distance between two drugs was calculated by dividing the number of drugs that feature both side effects by the number of drugs that have either side effect associated. **The Gerstein–Sonnhammer–Chothia algorithm [@10.1016/0022-2836(94)90012-4] was used to compute weights based on a hierarchal clustering with the aforementioned distance matrix [@10.1073/pnas.95.25.14863].**\r\n\r\nI would like to perform an identical analysis, while making the code and results public. The analysis follows the following steps:\r\n\r\n1. Calculating pairwise side effect correlations.\r\n2. Performing hierarchical clustering of side effects to produce a dendrogram\r\n3. Inputting the denrogram into the GSC algorithm to calculate side effect weights.\r\n\r\nI am looking for an implementation of step 3, that it easy to integrate with implementations of steps 1 and 2. My preferred languages are *R*, *python*, and *julia* (in that order). The author should be willing to post the code publicly under an open source license.\r\n\r\nAn in detail description of the GSC algorithm can be found in the paper appendix titled, *[A Method to Weight Protein Sequences to Correct for Unequal Representation](https://pdf.yt/d/Sx3jMbr8vANgxAej/download)*.\r\n\r\nAlso, if you know of a simpler or superior method for accomplishing this weighting task, please suggest.",
      "comment_id": 34,
      "profile_id": 17,
      "published": "2015-01-22T18:14:09.286193Z",
      "thread_id": 25,
      "url": "/discussion/seeking-an-open-source-implementation-of-the-gerstein-sonnhammer-chothia-algorithm/25"
    },
    {
      "body_html": "<p>As a follow-up to this, are you planning to make only the network available, or are you planning to release all of the code necessary to construct the network? If you release that code, will you use some testing and continuous integration process to evaluate regressions? Releasing the code would allow others in the future to assess the role that new experiments or new sources of information play in prediction quality. I agree with Jesse that more details on the overall development process would be great.</p>",
      "body_md": "As a follow-up to this, are you planning to make only the network available, or are you planning to release all of the code necessary to construct the network? If you release that code, will you use some testing and continuous integration process to evaluate regressions? Releasing the code would allow others in the future to assess the role that new experiments or new sources of information play in prediction quality. I agree with Jesse that more details on the overall development process would be great.",
      "comment_id": 35,
      "profile_id": 22,
      "published": "2015-01-22T20:43:07.278879Z",
      "thread_id": 23,
      "url": "/discussion/enabling-reproducibility-and-reuse/23#3"
    },
    {
      "body_html": "<p>Hey Daniel,</p>\r\n\r\n<p>This should do it:<br><a href=\"https://github.com/antoine-lizee/R-GSC/blob/master/GSC.R\" target=\"_blank\">https://github.com/antoine-lizee/R-GSC/blob/master/GSC.R</a></p>\r\n\r\n<p>It uses dendrogram objects in R.</p>\r\n\r\n<p>Once you get it, the implementation is quite straightforward and short, so it doesn't really justify creating a package. Everything in one file, you can just source it.<br>Have a go at it and tell me what you think.</p>\r\n\r\n<p>Best,<br>Antoine</p>\r\n\r\n<p>PS: the attached reference that explains the algorithm has its main example wrong because of the low (and surprisingly inconsistent) precision they use to do the maths.</p>",
      "body_md": "Hey Daniel,\r\n\r\nThis should do it:\r\nhttps://github.com/antoine-lizee/R-GSC/blob/master/GSC.R\r\n\r\nIt uses dendrogram objects in R.\r\n\r\nOnce you get it, the implementation is quite straightforward and short, so it doesn't really justify creating a package. Everything in one file, you can just source it.\r\nHave a go at it and tell me what you think.\r\n\r\nBest,\r\nAntoine\r\n\r\nPS: the attached reference that explains the algorithm has its main example wrong because of the low (and surprisingly inconsistent) precision they use to do the maths.",
      "comment_id": 38,
      "profile_id": 23,
      "published": "2015-01-23T04:11:25.882145Z",
      "thread_id": 25,
      "url": "/discussion/seeking-an-open-source-implementation-of-the-gerstein-sonnhammer-chothia-algorithm/25#2"
    },
    {
      "body_html": "<p><a href=\"/u/alizee\" class=\"username\">@alizee</a>, thanks for the <a href=\"https://github.com/antoine-lizee/R-GSC/\">open source implementation</a> — you just spared scientists all over the pain of unnecessary reimplementation.</p>\r\n\r\n<p>Here is the code I wrote, which calls your <code>GSC</code> function</p>\r\n\r\n<p></p><pre><code class=\"r\">GitHubScript &lt;- function(...) {\r\n  # Source a script from GitHub\r\n  library(RCurl)\r\n  github.url &lt;- file.path('https://raw.githubusercontent.com', ...)\r\n  script &lt;- RCurl::getURL(github.url)\r\n  eval(parse(text = script), envir = .GlobalEnv)\r\n}\r\n\r\nUnderrepresentationWeight &lt;- function(mat) {\r\n  # Returns underrepresentation weight for each column\r\n  col.dist &lt;- stats::dist(t(mat), method = 'binary')\r\n  col.clust &lt;- hclust(col.dist, method = 'ward.D2')\r\n  col.dendro &lt;- as.dendrogram(col.clust)\r\n  GitHubScript('antoine-lizee', 'R-GSC', 'master', 'GSC.R')\r\n  GSC(col.dendro)\r\n}</code></pre>\r\n\r\n<p>I have come accross two errors for my use cases</p>\r\n\r\n<p>The following code (which computes only the first 100 side effects for time) returns a vector of only <code>NaN</code>:<br></p>\r\n\r\n<p></p><pre><code class=\"r\">underrep.ind.vec &lt;- UnderrepresentationWeight(se.mat[, 1:100])</code></pre>\r\n\r\n<p>On a slightly larger matrix, I also got a maximum recursion depth error.</p>\r\n\r\n<p><code>se.mat</code> is a matrix where rows are compounds and columns are side effects. An element is <code>0</code> for no relationship and <code>1</code> for side effect. You can <a href=\"http://stat.ethz.ch/R-manual/R-devel/library/base/html/load.html\">load</a> <code>se.mat</code> from <a href=\"https://www.dropbox.com/s/8e12q0gkmxs54b6/se.mat.RData?raw=1\">this file</a>.</p>",
      "body_md": "@alizee, thanks for the [open source implementation](https://github.com/antoine-lizee/R-GSC/) -- you just spared scientists all over the pain of unnecessary reimplementation.\r\n\r\nHere is the code I wrote, which calls your `GSC` function\r\n\r\n```r\r\nGitHubScript <- function(...) {\r\n  # Source a script from GitHub\r\n  library(RCurl)\r\n  github.url <- file.path('https://raw.githubusercontent.com', ...)\r\n  script <- RCurl::getURL(github.url)\r\n  eval(parse(text = script), envir = .GlobalEnv)\r\n}\r\n\r\nUnderrepresentationWeight <- function(mat) {\r\n  # Returns underrepresentation weight for each column\r\n  col.dist <- stats::dist(t(mat), method = 'binary')\r\n  col.clust <- hclust(col.dist, method = 'ward.D2')\r\n  col.dendro <- as.dendrogram(col.clust)\r\n  GitHubScript('antoine-lizee', 'R-GSC', 'master', 'GSC.R')\r\n  GSC(col.dendro)\r\n}\r\n```\r\nI have come accross two errors for my use cases\r\n\r\nThe following code (which computes only the first 100 side effects for time) returns a vector of only `NaN`:\r\n```r\r\nunderrep.ind.vec <- UnderrepresentationWeight(se.mat[, 1:100])\r\n```\r\nOn a slightly larger matrix, I also got a maximum recursion depth error.\r\n\r\n`se.mat` is a matrix where rows are compounds and columns are side effects. An element is `0` for no relationship and `1` for side effect. You can [load](http://stat.ethz.ch/R-manual/R-devel/library/base/html/load.html) `se.mat` from [this file](https://www.dropbox.com/s/8e12q0gkmxs54b6/se.mat.RData?raw=1).",
      "comment_id": 40,
      "profile_id": 17,
      "published": "2015-01-23T19:58:27.683271Z",
      "thread_id": 25,
      "url": "/discussion/seeking-an-open-source-implementation-of-the-gerstein-sonnhammer-chothia-algorithm/25#3"
    },
    {
      "body_html": "<p>Hi Daniel,</p>\r\n\r\n<p>Thank you for your feedback. <br>I solved your first \"Nan\" problem. Below is a short explanation, and on the repository I added a <a href=\"https://github.com/antoine-lizee/R-GSC/blob/master/dhimmel_bugs_test.R\">file</a> in which I investigate the problem.</p>\r\n\r\n<p>The problem came from the fact that some of your vectors of features in your original matrix were <strong>exactly the same</strong>, i.e. some of your compounds have the exact same side effects. This resulted in a computed distance of zero between these two objects, and the clustering is putting them at the bottom of the dendrogram, at height 0. The algorithm wasn't designed for such an edge case and a division by 0 was giving you the NaN. I slightly changed the algorithm to work even with this edge case.<br>I quickly tested that the coefficients at this edge case were roughly the limit of the coefficients when the two vectors are getting similar, which shows that the handling of this edge case is appropriate. </p>\r\n\r\n<p>I am looking into some profiling and making it work for bigger matrices, so I'll update you regarding your other problem soon.</p>\r\n\r\n<p>Best,<br>Antoine</p>",
      "body_md": "Hi Daniel,\r\n\r\nThank you for your feedback. \r\nI solved your first \"Nan\" problem. Below is a short explanation, and on the repository I added a [file](https://github.com/antoine-lizee/R-GSC/blob/master/dhimmel_bugs_test.R) in which I investigate the problem.\r\n\r\nThe problem came from the fact that some of your vectors of features in your original matrix were **exactly the same**, i.e. some of your compounds have the exact same side effects. This resulted in a computed distance of zero between these two objects, and the clustering is putting them at the bottom of the dendrogram, at height 0. The algorithm wasn't designed for such an edge case and a division by 0 was giving you the NaN. I slightly changed the algorithm to work even with this edge case.\r\nI quickly tested that the coefficients at this edge case were roughly the limit of the coefficients when the two vectors are getting similar, which shows that the handling of this edge case is appropriate. \r\n\r\nI am looking into some profiling and making it work for bigger matrices, so I'll update you regarding your other problem soon.\r\n\r\nBest,\r\nAntoine",
      "comment_id": 45,
      "profile_id": 23,
      "published": "2015-01-25T03:22:18.788239Z",
      "thread_id": 25,
      "url": "/discussion/seeking-an-open-source-implementation-of-the-gerstein-sonnhammer-chothia-algorithm/25#4"
    },
    {
      "body_html": "<p>I plan to follow the 10 rules of reproducible computational research <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1003285\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1003285\">1</a>]</span>.</p>\r\n\r\n<p><a href=\"/u/caseygreene\" class=\"username\">@caseygreene</a>, I would like to release all of the code. I plan on doing a lot of the work in notebooks (of the <a href=\"http://rmarkdown.rstudio.com/\">R</a> and <a href=\"http://ipython.org/notebook.html\">python</a> varieties). However, my current plan lacks the level of automation that you are suggesting.</p>\r\n\r\n<p>Testing whether a new source of information has improved prediction should be straightforward. I am not sure exactly what you mean by \"continuous integration process\".</p>\r\n\r\n<p>I would like to provide a single script that performs the entire analysis, but this may be difficult because the computation will be performed in different venues and locations.</p>",
      "body_md": "I plan to follow the 10 rules of reproducible computational research [@10.1371/journal.pcbi.1003285].\r\n\r\n@caseygreene, I would like to release all of the code. I plan on doing a lot of the work in notebooks (of the [R](http://rmarkdown.rstudio.com/) and [python](http://ipython.org/notebook.html) varieties). However, my current plan lacks the level of automation that you are suggesting.\r\n\r\nTesting whether a new source of information has improved prediction should be straightforward. I am not sure exactly what you mean by \"continuous integration process\".\r\n\r\nI would like to provide a single script that performs the entire analysis, but this may be difficult because the computation will be performed in different venues and locations.",
      "comment_id": 49,
      "profile_id": 17,
      "published": "2015-01-26T15:00:59.175127Z",
      "thread_id": 23,
      "url": "/discussion/enabling-reproducibility-and-reuse/23#4"
    },
    {
      "body_html": "<p>If you get the entire analysis boiled down a one-step build process, there are services that can monitor your github repository, look for commits, and then kick off a build. You'd need to define test cases that determine that something looks different than you expect. Maybe you have a set of positive controls (known multi-use drugs?) and you evaluate the extent to which they are accurately predicted. Depending on how long the entire process takes, these services might be enough to monitor and identify any commits that produce large changes in your overall results. You could also use some sort of correlation measure to previous runs to look for any commits that produce abnormally large changes in the output.</p>",
      "body_md": "If you get the entire analysis boiled down a one-step build process, there are services that can monitor your github repository, look for commits, and then kick off a build. You'd need to define test cases that determine that something looks different than you expect. Maybe you have a set of positive controls (known multi-use drugs?) and you evaluate the extent to which they are accurately predicted. Depending on how long the entire process takes, these services might be enough to monitor and identify any commits that produce large changes in your overall results. You could also use some sort of correlation measure to previous runs to look for any commits that produce abnormally large changes in the output.",
      "comment_id": 51,
      "profile_id": 22,
      "published": "2015-01-26T15:14:48.758534Z",
      "thread_id": 23,
      "url": "/discussion/enabling-reproducibility-and-reuse/23#5"
    },
    {
      "body_html": "<p>Hey,</p>\r\n\r\n<p>I think the code is ready now. </p>\r\n\r\n<p>In addition to the fix above that let the algorithm run on datasets with objects that have the same representation, I added some routine check to increase the maximum recursive depth of R when calling the function. I used a robust adaptive approach to increase this recursion limit based on the estimated number of elements in the dendrogram, see the <a href=\"https://github.com/antoine-lizee/R-GSC/blob/master/GSC.R#L47\">code</a>.</p>\r\n\r\n<p>I also did some extensive testing and profiling in the <a href=\"https://github.com/antoine-lizee/R-GSC/blob/master/dhimmel_bugs_test.R\">dhimmel file</a> mentioned earlier. As expected, the algorithm is very cheap: execution time is linear in the number of elements of the dendrogram, with roughly <a href=\"https://github.com/antoine-lizee/R-GSC/blob/master/test/profiling.pdf\">10ms / kElements</a>. I tried to half the stack depth by writing a <a href=\"https://github.com/antoine-lizee/R-GSC/blob/master/test/GSC2.R\">more verbose</a> version of the GSC algorithm, but it didn't change performance, so I kept the first more elegant version.</p>\r\n\r\n<p>Enjoy!</p>",
      "body_md": "Hey,\r\n\r\nI think the code is ready now. \r\n\r\nIn addition to the fix above that let the algorithm run on datasets with objects that have the same representation, I added some routine check to increase the maximum recursive depth of R when calling the function. I used a robust adaptive approach to increase this recursion limit based on the estimated number of elements in the dendrogram, see the [code](https://github.com/antoine-lizee/R-GSC/blob/master/GSC.R#L47).\r\n\r\nI also did some extensive testing and profiling in the [dhimmel file] (https://github.com/antoine-lizee/R-GSC/blob/master/dhimmel_bugs_test.R) mentioned earlier. As expected, the algorithm is very cheap: execution time is linear in the number of elements of the dendrogram, with roughly [10ms / kElements] (https://github.com/antoine-lizee/R-GSC/blob/master/test/profiling.pdf). I tried to half the stack depth by writing a [more verbose](https://github.com/antoine-lizee/R-GSC/blob/master/test/GSC2.R) version of the GSC algorithm, but it didn't change performance, so I kept the first more elegant version.\r\n\r\nEnjoy!",
      "comment_id": 53,
      "profile_id": 23,
      "published": "2015-01-26T23:25:48.859352Z",
      "thread_id": 25,
      "url": "/discussion/seeking-an-open-source-implementation-of-the-gerstein-sonnhammer-chothia-algorithm/25#5"
    },
    {
      "body_html": "<p>SIDER is a <a href=\"http://sideeffects.embl.de/\">resource</a> which automatically parsed labels for approved drugs and annotated side effects and indications <span class=\"citation\">[<a href=\"https://doi.org/10.1038/msb.2009.98\" class=\"citation\" data-key=\"10.1038/msb.2009.98\">1</a>]</span>.</p>\r\n\r\n<p>We <a href=\"http://git.dhimmel.com/SIDER2/\">performed an analysis</a> using the <a href=\"http://sideeffects.embl.de/download/\">raw SIDER data</a>, to evaluate the accuracy, quality, and usefulness of this resource. In addition to using the indications, we are interested in adding side effects as a separate node and edge type in our network.</p>\r\n\r\n<p>After quality control to resolve conflicts (cases where a concept was annotated to a compound as both a side effect and indication), we found indications for 1005 drugs. <a href=\"/u/leobrueggeman\" class=\"username\">@leobrueggeman</a>, manually classified 101 random indications and found a precision of 63.4% [95% CI: 53.1–72.6%]. We browsed the indications for multiple sclerosis and found that many symptomatic treatments were included while many of the disease-modifying small molecules were absent. Overall the SIDER indications alone will be a rather <em>poor</em> resource. One possibility is combining <a href=\"http://git.dhimmel.com/SIDER2/data/sider2-processed.txt\">SIDER indications</a> with orthogonal methods.</p>\r\n\r\n<p>The precision of side effects was considerably better at 92.0% [95% CI: 84.4–96.2%]. However, despite being largely accurate, not all side effects are of the same relevance (frequencies vary and placebo levels of occurrence are frequently lacking). <a href=\"/u/leobrueggeman\" class=\"username\">@leobrueggeman</a>, could you provide some additional information on the deficiencies or strengths of the SIDER approach?</p>",
      "body_md": "SIDER is a [resource](http://sideeffects.embl.de/) which automatically parsed labels for approved drugs and annotated side effects and indications [@10.1038/msb.2009.98].\r\n\r\nWe [performed an analysis](http://git.dhimmel.com/SIDER2/) using the [raw SIDER data](http://sideeffects.embl.de/download/), to evaluate the accuracy, quality, and usefulness of this resource. In addition to using the indications, we are interested in adding side effects as a separate node and edge type in our network.\r\n\r\nAfter quality control to resolve conflicts (cases where a concept was annotated to a compound as both a side effect and indication), we found indications for 1005 drugs. @leobrueggeman, manually classified 101 random indications and found a precision of 63.4% [95% CI: 53.1--72.6%]. We browsed the indications for multiple sclerosis and found that many symptomatic treatments were included while many of the disease-modifying small molecules were absent. Overall the SIDER indications alone will be a rather *poor* resource. One possibility is combining [SIDER indications](http://git.dhimmel.com/SIDER2/data/sider2-processed.txt) with orthogonal methods.\r\n\r\nThe precision of side effects was considerably better at 92.0% [95% CI: 84.4--96.2%]. However, despite being largely accurate, not all side effects are of the same relevance (frequencies vary and placebo levels of occurrence are frequently lacking). @leobrueggeman, could you provide some additional information on the deficiencies or strengths of the SIDER approach?",
      "comment_id": 56,
      "profile_id": 17,
      "published": "2015-02-13T02:25:05.540731Z",
      "thread_id": 30,
      "url": "/discussion/assessing-the-quality-and-applicability-of-the-sider-2-resource/30"
    },
    {
      "body_html": "<p><a href=\"/u/caseygreene\" class=\"username\">@caseygreene</a> and <a href=\"/u/jspauld\" class=\"username\">@jspauld</a>, thanks for the suggestions. I've <a href=\"http://thinklab.com/p/rephetio/plan/compare/0ed4f4242ca776e6460be3f24e9e7e4d3a5c6ad3/2f775f436f7c99413a195f729ae9a20bfc25e6c5\">added</a> an <a href=\"http://thinklab.com/p/rephetio/plan#open-science\">open science section</a> to the proposal where I make commitments to:</p>\r\n\r\n<ul><li>the 10 simple rules for reproducible research in computational biology <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1003285\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1003285\">1</a>]</span></li><li>releasing all code on <a href=\"https://github.com/dhimmel\">GitHub</a></li><li>releasing all data</li><li>CC-BY or CC-0 licensing</li></ul><p>I also mention R Markdown and IPython notebooks, which I've been using extensively thus far — for example, when <a href=\"http://git.dhimmel.com/SIDER2/\">analyzing SIDER 2 data</a>.</p>\r\n\r\n<hr><p><a href=\"/u/caseygreene\" class=\"username\">@caseygreene</a>, I think your suggestion of implementing a continuous integration process is fantastic. I am hesitant to commit on this issue for a few reasons:</p>\r\n\r\n<ul><li>In the past, the computations have been extreme (requiring cluster usage) and this may be unwieldy to execute after every commit. I hope to optimize the algorithm, which may help in this regard.</li><li>I need to investigate these services more.</li><li>Our heterogeneous network framework and analyses are still rapidly evolving, so I don't want to invest lot's of time in code or methods that will soon be replaced.</li><li>I need to start writing unit tests for my programs. This seems like a more immediate issue that I will prioritize. Once I create proper unit tests, I will enable them as <a href=\"http://git-scm.com/book/en/v2/Customizing-Git-Git-Hooks#Client-Side-Hooks\">pre-commit hooks</a>.</li></ul><p>That being said, your suggestion is in line with the philosophy of ThinkLab and I will keep it in mind.</p>",
      "body_md": "@caseygreene and @jspauld, thanks for the suggestions. I've [added](http://thinklab.com/p/rephetio/plan/compare/0ed4f4242ca776e6460be3f24e9e7e4d3a5c6ad3/2f775f436f7c99413a195f729ae9a20bfc25e6c5) an [open science section](http://thinklab.com/p/rephetio/plan#open-science) to the proposal where I make commitments to:\r\n\r\n+ the 10 simple rules for reproducible research in computational biology [@10.1371/journal.pcbi.1003285]\r\n+ releasing all code on [GitHub](https://github.com/dhimmel)\r\n+ releasing all data\r\n+ CC-BY or CC-0 licensing\r\n\r\nI also mention R Markdown and IPython notebooks, which I've been using extensively thus far -- for example, when [analyzing SIDER 2 data](http://git.dhimmel.com/SIDER2/).\r\n\r\n***\r\n\r\n@caseygreene, I think your suggestion of implementing a continuous integration process is fantastic. I am hesitant to commit on this issue for a few reasons:\r\n\r\n+ In the past, the computations have been extreme (requiring cluster usage) and this may be unwieldy to execute after every commit. I hope to optimize the algorithm, which may help in this regard.\r\n+ I need to investigate these services more.\r\n+ Our heterogeneous network framework and analyses are still rapidly evolving, so I don't want to invest lot's of time in code or methods that will soon be replaced.\r\n+ I need to start writing unit tests for my programs. This seems like a more immediate issue that I will prioritize. Once I create proper unit tests, I will enable them as [pre-commit hooks](http://git-scm.com/book/en/v2/Customizing-Git-Git-Hooks#Client-Side-Hooks).\r\n\r\nThat being said, your suggestion is in line with the philosophy of ThinkLab and I will keep it in mind.",
      "comment_id": 57,
      "profile_id": 17,
      "published": "2015-02-16T22:41:28.927019Z",
      "thread_id": 23,
      "url": "/discussion/enabling-reproducibility-and-reuse/23#6"
    },
    {
      "body_html": "<p><strong>Update: See reply — this issue has been resolved. Links to our analyses and code have been changed to archived versions in this post.</strong></p>\r\n\r\n<hr>\r\n\r\n<p>MEDI is a <a href=\"http://knowledgemap.mc.vanderbilt.edu/research/content/MEDI\">publicly-available indication resource</a> standardized to ICD9/UMLS concepts for diseases and RxNorm ingredients for drugs. The accompanying publication clearly and concisely presents the analysis, which follows a rational, resourceful, and thorough methodology <span class=\"citation\">[<a href=\"https://doi.org/10.1136/amiajnl-2012-001431\" class=\"citation\" data-key=\"10.1136/amiajnl-2012-001431\">1</a>]</span>.</p>\r\n\r\n<p>The data is also already online, which <a href=\"http://thinklab.com/p/rephetio/how-should-we-construct-a-catalog-of-drug-indications/21\">is not the case</a> with some other indication resources we've evaluated. However, when <a href=\"http://cdn.rawgit.com/dhimmel/indications/65dbe8ec52c1c882cecb4451f5bcf433d5b189c7/medi/index.html\">processing the data</a> (<a href=\"https://github.com/dhimmel/indications/tree/65dbe8ec52c1c882cecb4451f5bcf433d5b189c7/medi\">source on github</a>), we came across a potential discrepancy between <a href=\"http://dx.doi.org/10.1136/amiajnl-2012-001431#T1\">Table 2 of the manuscript</a> and the <a href=\"http://cdn.rawgit.com/dhimmel/indications/65dbe8ec52c1c882cecb4451f5bcf433d5b189c7/medi/index.html#resource-counts\">statistics we generated</a>. The problem could have arisen from a mistake in our data processing or in MEDI's data export.</p>\r\n\r\n<p>Specifically, from the <a href=\"http://dx.doi.org/10.1136/amiajnl-2012-001431#T1\">manuscript</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1136/amiajnl-2012-001431\" class=\"citation\" data-key=\"10.1136/amiajnl-2012-001431\">1</a>]</span>:</p>\r\n\r\n<blockquote><p><strong>Table 2</strong>: Number of unique medications, ICD9 codes, and indication pairs extracted from each resource</p><table class=\"table markdown-table\"><thead><tr><th>Resource</th><th>Medications (% of total)</th><th>ICD9 codes (% of total)</th><th>Indication pairs (% of total)</th></tr></thead><tbody><tr><td>RxNorm</td><td>1,726 (56)</td><td>999 (33)</td><td>8,040 (13)</td></tr><tr><td>SIDER 2</td><td>1,554 (50)</td><td>1,703 (57)</td><td>17,702 (28)</td></tr><tr><td>MedlinePlus</td><td>1,629 (52)</td><td>869 (29)</td><td>16,581(26)</td></tr><tr><td>Wikipedia</td><td>2,608 (84)</td><td>2,624 (87)</td><td>34,911 (55)</td></tr><tr><td>Union of all resources</td><td>3,112</td><td>3,009</td><td>63,343</td></tr></tbody></table></blockquote>\r\n\r\n<p><a href=\"http://cdn.rawgit.com/dhimmel/indications/65dbe8ec52c1c882cecb4451f5bcf433d5b189c7/medi/index.html#resource-counts\">Our analysis</a> found different resource-specific counts. The comparison is complicated since the resource to numeric identifier mapping is unknown:</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>resource</th><th>medications</th><th>diseases</th><th>indications</th></tr></thead><tbody><tr><td>1</td><td>3,091</td><td>2,985</td><td>53,615</td></tr><tr><td>2</td><td>1,648</td><td>1,075</td><td>6,279</td></tr><tr><td>3</td><td>984</td><td>551</td><td>2,497</td></tr><tr><td>4</td><td>447</td><td>222</td><td>952</td></tr><tr><td>all</td><td>3,112</td><td>3,009</td><td>63,343</td></tr><tr><td>hps</td><td>2,139</td><td>1,345</td><td>13,379</td></tr></tbody></table>\r\n\r\n<p>We will reach out to the MEDI authors for assistance. Currently the discrepancy seems to have a negligible effect on the high-precision subset.</p>",
      "body_md": "**Update: See reply -- this issue has been resolved. Links to our analyses and code have been changed to archived versions in this post.**\r\n\r\n***\r\n\r\nMEDI is a [publicly-available indication resource](http://knowledgemap.mc.vanderbilt.edu/research/content/MEDI) standardized to ICD9/UMLS concepts for diseases and RxNorm ingredients for drugs. The accompanying publication clearly and concisely presents the analysis, which follows a rational, resourceful, and thorough methodology [@10.1136/amiajnl-2012-001431].\r\n\r\nThe data is also already online, which [is not the case](http://thinklab.com/p/rephetio/how-should-we-construct-a-catalog-of-drug-indications/21) with some other indication resources we've evaluated. However, when [processing the data](http://cdn.rawgit.com/dhimmel/indications/65dbe8ec52c1c882cecb4451f5bcf433d5b189c7/medi/index.html) ([source on github](https://github.com/dhimmel/indications/tree/65dbe8ec52c1c882cecb4451f5bcf433d5b189c7/medi)), we came across a potential discrepancy between [Table 2 of the manuscript](http://dx.doi.org/10.1136/amiajnl-2012-001431#T1) and the [statistics we generated](http://cdn.rawgit.com/dhimmel/indications/65dbe8ec52c1c882cecb4451f5bcf433d5b189c7/medi/index.html#resource-counts). The problem could have arisen from a mistake in our data processing or in MEDI's data export.\r\n\r\nSpecifically, from the [manuscript](http://dx.doi.org/10.1136/amiajnl-2012-001431#T1) [@10.1136/amiajnl-2012-001431]:\r\n> **Table 2**: Number of unique medications, ICD9 codes, and indication pairs extracted from each resource\r\n>\r\n| Resource               | Medications (% of total) | ICD9 codes (% of total) | Indication pairs (% of total) |\r\n|------------------------|--------------------------|-------------------------|-------------------------------|\r\n| RxNorm                 | 1,726 (56)                | 999 (33)                | 8,040 (13)                     |\r\n| SIDER 2                | 1,554 (50)                | 1,703 (57)               | 17,702 (28)                    |\r\n| MedlinePlus            | 1,629 (52)                | 869 (29)                | 16,581(26)                     |\r\n| Wikipedia              | 2,608 (84)                | 2,624 (87)               | 34,911 (55)                    |\r\n| Union of all resources | 3,112                     | 3,009                    | 63,343                         |\r\n\r\n[Our analysis](http://cdn.rawgit.com/dhimmel/indications/65dbe8ec52c1c882cecb4451f5bcf433d5b189c7/medi/index.html#resource-counts) found different resource-specific counts. The comparison is complicated since the resource to numeric identifier mapping is unknown:\r\n\r\n| resource | medications | diseases | indications |\r\n|----------|-------------|----------|-------------|\r\n| 1        | 3,091        | 2,985     | 53,615       |\r\n| 2        | 1,648        | 1,075     | 6,279        |\r\n| 3        | 984         | 551      | 2,497        |\r\n| 4        | 447         | 222      | 952         |\r\n| all      | 3,112        | 3,009     | 63,343       |\r\n| hps      | 2,139        | 1,345     | 13,379       |\r\n\r\nWe will reach out to the MEDI authors for assistance. Currently the discrepancy seems to have a negligible effect on the high-precision subset.",
      "comment_id": 58,
      "profile_id": 17,
      "published": "2015-02-17T02:21:47.753909Z",
      "thread_id": 31,
      "url": "/discussion/medi-indications-data-discrepancy-in-resource-specific-counts/31"
    },
    {
      "body_html": "<p>After contacting <a href=\"http://knowledgemap.mc.vanderbilt.edu/research/content/wei-qi-wei-mmed-phd\">Dr. Wei-Qi Wei</a>, we located the cause of the discrepancy. The integer values in the <code>MENTIONEDBYRESOURCES</code> column of <code>MEDI_01212013_0.csv</code> and <code>MEDI_01212013_UMLS.csv</code> refer to <em>how many</em> resources reported the indication. We had incorrectly assumed that this column referred to <em>which</em> resources reported the indication. Therefore, it appeared that each indication was only reported by a single resource.</p>\r\n\r\n<p>Resource-specific indications data is not available from the <a href=\"http://knowledgemap.mc.vanderbilt.edu/research/content/MEDI\">MEDI website</a>. However, the true counts for each resource combination are provided in <a href=\"http://dx.doi.org/10.1136/amiajnl-2012-001431#sec-8\">manuscript Figure 2</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1136/amiajnl-2012-001431\" class=\"citation\" data-key=\"10.1136/amiajnl-2012-001431\">1</a>]</span>:</p>\r\n\r\n<p><img src=\"http://jamia.oxfordjournals.org/content/jaminfo/20/5/954/F2.large.jpg\" alt=\"Weighted Venn diagram of the distribution of medications and indication pairs within the four resources\"></p>\r\n\r\n<p>We would like to thank the authors for their prompt response and clarification.</p>",
      "body_md": "After contacting [Dr. Wei-Qi Wei](http://knowledgemap.mc.vanderbilt.edu/research/content/wei-qi-wei-mmed-phd), we located the cause of the discrepancy. The integer values in the `MENTIONEDBYRESOURCES` column of `MEDI_01212013_0.csv` and `MEDI_01212013_UMLS.csv` refer to *how many* resources reported the indication. We had incorrectly assumed that this column referred to *which* resources reported the indication. Therefore, it appeared that each indication was only reported by a single resource.\r\n\r\nResource-specific indications data is not available from the [MEDI website](http://knowledgemap.mc.vanderbilt.edu/research/content/MEDI). However, the true counts for each resource combination are provided in [manuscript Figure 2](http://dx.doi.org/10.1136/amiajnl-2012-001431#sec-8) [@10.1136/amiajnl-2012-001431]:\r\n\r\n![Weighted Venn diagram of the distribution of medications and indication pairs within the four resources](http://jamia.oxfordjournals.org/content/jaminfo/20/5/954/F2.large.jpg)\r\n\r\nWe would like to thank the authors for their prompt response and clarification.",
      "comment_id": 63,
      "profile_id": 17,
      "published": "2015-02-17T17:26:17.673816Z",
      "thread_id": 31,
      "url": "/discussion/medi-indications-data-discrepancy-in-resource-specific-counts/31#2"
    },
    {
      "body_html": "<p><a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a> <br>From what I observed it seems that there are a few types of mistakes which, when combined, lead to a significant drop in the precision of indications. The biggest problem I saw in the SIDER data, and perhaps the easiest to fix, was that there were several \"indications\" which were not actually diseases (e.g. \"progression\", \"adverse reactions\", \"interactions\"). It should be possible to filter out these artifacts of text mining via reference to a disease ontology.</p>\r\n\r\n<p>The second repeated mistake I saw was that SIDER would on occasion mark a symptom of a real indication as an indication (e.g. agoraphobia, which sometimes accompanies panic disorder, was marked as an indication).</p>\r\n\r\n<p>Probably the hardest problem to sort out would be the cases where a disease is mentioned in the \"Indications and Usage\" section of a label, but is not actually treated by the drug (e.g. drug x treats disease y, in the case that patient has disease z, administer drug x at a slower rate). This is less common, but happened a few times in the random sample of 100 indications I analyzed.</p>\r\n\r\n<p>Lastly, an update to the drug list would be appropriate. There are only 888 drugs listed for SIDER, while the total number of FDA approved drugs is significantly higher. This difference could explain some of the gaps for indications.</p>\r\n\r\n<p>Hope this helps give context to some of the issues within the indications.<br>Leo</p>",
      "body_md": "@dhimmel \r\nFrom what I observed it seems that there are a few types of mistakes which, when combined, lead to a significant drop in the precision of indications. The biggest problem I saw in the SIDER data, and perhaps the easiest to fix, was that there were several \"indications\" which were not actually diseases (e.g. \"progression\", \"adverse reactions\", \"interactions\"). It should be possible to filter out these artifacts of text mining via reference to a disease ontology.\r\n\r\nThe second repeated mistake I saw was that SIDER would on occasion mark a symptom of a real indication as an indication (e.g. agoraphobia, which sometimes accompanies panic disorder, was marked as an indication).\r\n\r\nProbably the hardest problem to sort out would be the cases where a disease is mentioned in the \"Indications and Usage\" section of a label, but is not actually treated by the drug (e.g. drug x treats disease y, in the case that patient has disease z, administer drug x at a slower rate). This is less common, but happened a few times in the random sample of 100 indications I analyzed.\r\n\r\nLastly, an update to the drug list would be appropriate. There are only 888 drugs listed for SIDER, while the total number of FDA approved drugs is significantly higher. This difference could explain some of the gaps for indications.\r\n\r\nHope this helps give context to some of the issues within the indications.\r\nLeo",
      "comment_id": 65,
      "profile_id": 21,
      "published": "2015-02-17T19:20:28.273189Z",
      "thread_id": 30,
      "url": "/discussion/assessing-the-quality-and-applicability-of-the-sider-2-resource/30#2"
    },
    {
      "body_html": "<p>In our previous project to <a href=\"http://het.io/diease-genes\">predict disease-associated</a> genes from a heterogeneous network <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1004259\">1</a>]</span>, we used the <a href=\"http://www.genenames.org\">HGNC (HUGO Gene Nomenclature Committee) database</a> to encode genes <span class=\"citation\">[<a href=\"https://doi.org/10.1007/s00439-001-0615-0\" class=\"citation\" data-key=\"10.1007/s00439-001-0615-0\">2</a>, <a href=\"https://doi.org/10.1093/nar/gku1071\" class=\"citation\" data-key=\"10.1093/nar/gku1071\">3</a>]</span>. This resource, \"based at the European Bioinformatics Institute (EMBL-EBI), assigns unique symbols and names to human genes <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gku1071\" class=\"citation\" data-key=\"10.1093/nar/gku1071\">3</a>]</span>.\"</p>\r\n\r\n<p>For this project, we are considering switching to NCBI's <a href=\"http://www.ncbi.nlm.nih.gov/gene\">Entrez Gene</a> and would like feedback. \"The primary goals of Entrez Gene are to provide tracked, unique identifiers for genes and to report information associated with those identifiers for unrestricted public use. The identifier that is assigned (GeneID) is an integer, and is species specific <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gki031\" class=\"citation\" data-key=\"10.1093/nar/gki031\">4</a>]</span>.\"</p>\r\n\r\n<p>The main advantages of Entrez versus HGNC for gene identification include:</p>\r\n\r\n<ul><li>more species than human</li><li>GeneIDs which are less error prone than ambiguous gene symbols</li><li>integration with many other NCBI services such as <a href=\"http://www.ncbi.nlm.nih.gov/homologene\">HomoloGene</a>, which can relate orthologous genes across species</li></ul>\r\n\r\n<p>The main disadvantage is familiarity, as most biologists conceive human genes in terms of their HGNC symbols. Although symbol information is available in Entrez Gene, there is no guarantee that each Entrez Gene record has a single corresponding, current HGNC symbol.</p>\r\n\r\n<p>I am interested in:</p>\r\n\r\n<ul><li>the best way to retrieve, store, parse, and map to Entrez Gene records</li><li>how stable Entrez Gene identifiers are for protein-coding genes in humans</li><li>the difficulty of updating to new versions of the Entrez Gene database</li></ul>\r\n\r\n<p>Any advice or information would be appreciated!</p>",
      "body_md": "In our previous project to [predict disease-associated](http://het.io/diease-genes) genes from a heterogeneous network [@10.1371/journal.pcbi.1004259], we used the [HGNC (HUGO Gene Nomenclature Committee) database](http://www.genenames.org) to encode genes [@10.1007/s00439-001-0615-0 @10.1093/nar/gku1071]. This resource, \"based at the European Bioinformatics Institute (EMBL-EBI), assigns unique symbols and names to human genes [@10.1093/nar/gku1071].\"\r\n\r\nFor this project, we are considering switching to NCBI's [Entrez Gene](http://www.ncbi.nlm.nih.gov/gene) and would like feedback. \"The primary goals of Entrez Gene are to provide tracked, unique identifiers for genes and to report information associated with those identifiers for unrestricted public use. The identifier that is assigned (GeneID) is an integer, and is species specific [@10.1093/nar/gki031].\"\r\n\r\nThe main advantages of Entrez versus HGNC for gene identification include:\r\n\r\n+ more species than human\r\n+ GeneIDs which are less error prone than ambiguous gene symbols\r\n+ integration with many other NCBI services such as [HomoloGene](http://www.ncbi.nlm.nih.gov/homologene), which can relate orthologous genes across species\r\n\r\nThe main disadvantage is familiarity, as most biologists conceive human genes in terms of their HGNC symbols. Although symbol information is available in Entrez Gene, there is no guarantee that each Entrez Gene record has a single corresponding, current HGNC symbol.\r\n\r\nI am interested in:\r\n\r\n+ the best way to retrieve, store, parse, and map to Entrez Gene records\r\n+ how stable Entrez Gene identifiers are for protein-coding genes in humans\r\n+ the difficulty of updating to new versions of the Entrez Gene database\r\n\r\nAny advice or information would be appreciated!",
      "comment_id": 70,
      "profile_id": 17,
      "published": "2015-02-27T19:35:36.741691Z",
      "thread_id": 34,
      "url": "/discussion/using-entrez-gene-as-our-gene-vocabulary/34"
    },
    {
      "body_html": "<p>We use Entrez internally in our lab at the moment. We store them in a SQL database with their associated features. We've started using ElasticSearch to perform mapping from sources that use multiple alternative identifiers or that also include aliases, but in general we try to convert to Entrez.</p>\r\n\r\n<p>There are some problems with Entrez &lt;-&gt; HGNC, but they are relatively minor — especially for protein coding genes. IMP, GIANT, Tribe, and our other servers use entrez internally and map to symbol for display purposes.</p>\r\n\r\n<p>I have talked to people who are discussing more sophisticated systems to generate identifiers that unify the databases through an automated process capable of resolving ambiguities, and I am hopeful that some of those projects will come to fruition.</p>",
      "body_md": "We use Entrez internally in our lab at the moment. We store them in a SQL database with their associated features. We've started using ElasticSearch to perform mapping from sources that use multiple alternative identifiers or that also include aliases, but in general we try to convert to Entrez.\r\n\r\nThere are some problems with Entrez <-> HGNC, but they are relatively minor -- especially for protein coding genes. IMP, GIANT, Tribe, and our other servers use entrez internally and map to symbol for display purposes.\r\n\r\nI have talked to people who are discussing more sophisticated systems to generate identifiers that unify the databases through an automated process capable of resolving ambiguities, and I am hopeful that some of those projects will come to fruition.",
      "comment_id": 71,
      "profile_id": 22,
      "published": "2015-02-28T12:50:57.554844Z",
      "thread_id": 34,
      "url": "/discussion/using-entrez-gene-as-our-gene-vocabulary/34#2"
    },
    {
      "body_html": "<p>We have previously retrieved our human <a href=\"//geneontology.org/\">Gene Ontology</a> (GO) <span class=\"citation\">[<a href=\"https://doi.org/10.1038/75556\" class=\"citation\" data-key=\"10.1038/75556\">1</a>]</span> annotations from <a href=\"//www.broadinstitute.org/gsea/msigdb/collections.jsp#C5\">MSigDB</a>. MSigDB was designed for gene set enrichment analyses and therefore GO terms with fewer than 10 annotations are excluded. Additionally, MSigDB is infrequently updated and only contains human gene sets.</p>\r\n\r\n<p>Therefore, we created a <a href=\"//git.dhimmel.com/gene-ontology/\">utility to provide GO annotations</a> for a variety of species using the most recent annotation data. The resource relies on Entrez Gene as the <a href=\"//thinklab.com/discussion/using-entrez-gene-as-our-gene-vocabulary/34\">main gene vocabulary</a>. The utility's <a href=\"https://github.com/dhimmel/gene-ontology\">source code is online</a>, but briefly, annotations are retrieved from the Entrez <code>gene2go.gz</code> file and the python <a href=\"https://github.com/tanghaibao/goatools\">goatools package</a> is used to parse <code>go-basic.obo</code> and propagate annotations.</p>\r\n\r\n<p>Propagating annotations refers to transferring annotations from a more specific GO term to its broader parent terms. The theoretical justification is described <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nrg2363\" class=\"citation\" data-key=\"10.1038/nrg2363\">2</a>]</span>:</p>\r\n\r\n<blockquote><p>When a gene is annotated to a term, associations between the gene and the terms' parents are implicitly inferred. Because GO annotations to a term inherit all the properties of the ancestors of those terms, every path from any term back to its root(s) must be biologically accurate or the ontology must be revised.</p></blockquote>\r\n\r\n<p>We allow the user to choose propagated or unpropagated annotations, gene identifiers as Entrez IDs or symbols, and protein-coding or all genes. Since this resource is meant to be maximally useful, any suggestions or feature requests are welcome.</p>",
      "body_md": "We have previously retrieved our human [Gene Ontology](//geneontology.org/) (GO) [@10.1038/75556] annotations from [MSigDB](//www.broadinstitute.org/gsea/msigdb/collections.jsp#C5). MSigDB was designed for gene set enrichment analyses and therefore GO terms with fewer than 10 annotations are excluded. Additionally, MSigDB is infrequently updated and only contains human gene sets.\r\n\r\nTherefore, we created a [utility to provide GO annotations](//git.dhimmel.com/gene-ontology/) for a variety of species using the most recent annotation data. The resource relies on Entrez Gene as the [main gene vocabulary](//thinklab.com/discussion/using-entrez-gene-as-our-gene-vocabulary/34). The utility's [source code is online](https://github.com/dhimmel/gene-ontology), but briefly, annotations are retrieved from the Entrez `gene2go.gz` file and the python [goatools package](https://github.com/tanghaibao/goatools) is used to parse `go-basic.obo` and propagate annotations.\r\n\r\nPropagating annotations refers to transferring annotations from a more specific GO term to its broader parent terms. The theoretical justification is described [@10.1038/nrg2363]:\r\n\r\n> When a gene is annotated to a term, associations between the gene and the terms' parents are implicitly inferred. Because GO annotations to a term inherit all the properties of the ancestors of those terms, every path from any term back to its root(s) must be biologically accurate or the ontology must be revised.\r\n\r\nWe allow the user to choose propagated or unpropagated annotations, gene identifiers as Entrez IDs or symbols, and protein-coding or all genes. Since this resource is meant to be maximally useful, any suggestions or feature requests are welcome.",
      "comment_id": 77,
      "profile_id": 17,
      "published": "2015-03-12T16:26:39.610571Z",
      "thread_id": 39,
      "url": "/discussion/compiling-gene-ontology-annotations-into-an-easy-to-use-format/39"
    },
    {
      "body_html": "<p>Currently, we would like to integrate several drug resources that rely on different compound vocabularies. These resources include</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>type</th><th>resource</th><th>vocabulary</th></tr></thead><tbody><tr><td>indication</td><td><a href=\"http://knowledgemap.mc.vanderbilt.edu/research/content/MEDI\">MEDI</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1136/amiajnl-2012-001431\" class=\"citation\" data-key=\"10.1136/amiajnl-2012-001431\">1</a>]</span></td><td><a href=\"http://www.nlm.nih.gov/research/umls/rxnorm/\">RxNorm</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1136/amiajnl-2011-000116\" class=\"citation\" data-key=\"10.1136/amiajnl-2011-000116\">2</a>]</span></td></tr><tr><td>indication</td><td><a href=\"http://ftp.ncbi.nlm.nih.gov/pub/lu/LabeledIn/\">LabeledIn</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.jbi.2014.08.004\" class=\"citation\" data-key=\"10.1016/j.jbi.2014.08.004\">3</a>, <a href=\"https://doi.org/10.1093/database/bav016\" class=\"citation\" data-key=\"10.1093/database/bav016\">4</a>]</span></td><td><a href=\"http://www.nlm.nih.gov/research/umls/rxnorm/\">RxNorm</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1136/amiajnl-2011-000116\" class=\"citation\" data-key=\"10.1136/amiajnl-2011-000116\">2</a>]</span></td></tr><tr><td>transcriptional signatures</td><td><a href=\"http://www.lincscloud.org/\">LINCS</a></td><td>LINCS &amp; PubChem</td></tr><tr><td>target binding</td><td><a href=\"https://www.ebi.ac.uk/chembl/\">ChEMBL</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkt1031\" class=\"citation\" data-key=\"10.1093/nar/gkt1031\">5</a>]</span></td><td>ChEMBL</td></tr><tr><td>side effects</td><td><a href=\"http://sideeffects.embl.de/download/\">SIDER 2</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1038/msb.2009.98\" class=\"citation\" data-key=\"10.1038/msb.2009.98\">6</a>]</span></td><td><a href=\"http://stitch.embl.de/\">STITCH</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkt1207\" class=\"citation\" data-key=\"10.1093/nar/gkt1207\">7</a>]</span></td></tr><tr><td>side effects</td><td><a href=\"https://www.pharmgkb.org/downloads/\">OFFSIDES</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1126/scitranslmed.3003377\" class=\"citation\" data-key=\"10.1126/scitranslmed.3003377\">8</a>]</span></td><td><a href=\"http://stitch.embl.de/\">STITCH</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkt1207\" class=\"citation\" data-key=\"10.1093/nar/gkt1207\">7</a>]</span></td></tr></tbody></table>\r\n\r\n<p>We are planning on using <a href=\"http://www.drugbank.ca/\">DrugBank</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkt1068\" class=\"citation\" data-key=\"10.1093/nar/gkt1068\">9</a>]</span> as the primary vocabulary for compounds. While the <a href=\"http://www.drugbank.ca/stats\">coverage of DrugBank</a> is limited, DrugBank includes FDA-approved compounds and likely covers the majority of compounds that would be well-connected in the network. The main benefits of DrugBank are extensive information per compound and a level of granularity that matches our needs.</p>\r\n\r\n<p>We plan to use <a href=\"https://www.ebi.ac.uk/unichem/ucquery/listSources\">UniChem</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1186/1758-2946-5-3\" class=\"citation\" data-key=\"10.1186/1758-2946-5-3\">10</a>]</span> to map resources with available structures. Importantly, we will likely benefit from a permissive matching algorithm that ignores small structural variations <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.ddtec.2015.01.005\" class=\"citation\" data-key=\"10.1016/j.ddtec.2015.01.005\">11</a>]</span>. UniChem has a connectivity mapping feature to perform fuzzy matching <span class=\"citation\">[<a href=\"https://doi.org/10.1186/s13321-014-0043-5\" class=\"citation\" data-key=\"10.1186/s13321-014-0043-5\">12</a>]</span>.</p>",
      "body_md": "Currently, we would like to integrate several drug resources that rely on different compound vocabularies. These resources include\r\n\r\n| type | resource | vocabulary |\r\n| - | - | - |\r\n| indication | [MEDI](http://knowledgemap.mc.vanderbilt.edu/research/content/MEDI) [@10.1136/amiajnl-2012-001431] | [RxNorm](http://www.nlm.nih.gov/research/umls/rxnorm/) [@10.1136/amiajnl-2011-000116] |\r\n| indication | [LabeledIn](http://ftp.ncbi.nlm.nih.gov/pub/lu/LabeledIn/) [@10.1016/j.jbi.2014.08.004 @10.1093/database/bav016] | [RxNorm](http://www.nlm.nih.gov/research/umls/rxnorm/) [@10.1136/amiajnl-2011-000116] |\r\n| transcriptional signatures | [LINCS](http://www.lincscloud.org/) | LINCS & PubChem |\r\n| target binding | [ChEMBL](https://www.ebi.ac.uk/chembl/) [@10.1093/nar/gkt1031] | ChEMBL |\r\n| side effects | [SIDER 2](http://sideeffects.embl.de/download/) [@10.1038/msb.2009.98] | [STITCH](http://stitch.embl.de/) [@10.1093/nar/gkt1207] |\r\n| side effects | [OFFSIDES](https://www.pharmgkb.org/downloads/) [@10.1126/scitranslmed.3003377] | [STITCH](http://stitch.embl.de/) [@10.1093/nar/gkt1207] |\r\n\r\nWe are planning on using [DrugBank](http://www.drugbank.ca/) [@10.1093/nar/gkt1068] as the primary vocabulary for compounds. While the [coverage of DrugBank](http://www.drugbank.ca/stats) is limited, DrugBank includes FDA-approved compounds and likely covers the majority of compounds that would be well-connected in the network. The main benefits of DrugBank are extensive information per compound and a level of granularity that matches our needs.\r\n\r\nWe plan to use [UniChem](https://www.ebi.ac.uk/unichem/ucquery/listSources) [@10.1186/1758-2946-5-3] to map resources with available structures. Importantly, we will likely benefit from a permissive matching algorithm that ignores small structural variations [@10.1016/j.ddtec.2015.01.005]. UniChem has a connectivity mapping feature to perform fuzzy matching [@10.1186/s13321-014-0043-5].",
      "comment_id": 78,
      "profile_id": 17,
      "published": "2015-03-16T23:22:11.518392Z",
      "thread_id": 40,
      "url": "/discussion/unifying-drug-vocabularies/40"
    },
    {
      "body_html": "<p>This paper <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.jbi.2012.06.005\" class=\"citation\" data-key=\"10.1016/j.jbi.2012.06.005\">1</a>]</span> discusses the problem of mapping between medication vocabularies. They identify several major difficulties:</p>\r\n\r\n<blockquote><ol><li>the availability of up-to-date information to assess the suitability of a given terminological system for a particular use case, and to assess the quality and completeness of cross-terminology links</li><li>the difficulty of correctly using complex, rapidly evolving, modern terminologies</li><li>the time and effort required to complete and evaluate the mapping</li><li>the need to address differences in granularity between the source and target terminologies</li><li>the need to continuously update the mapping as terminological systems evolve</li></ol></blockquote>\r\n\r\n<p>They provide a helpful diagram (manuscript Fig. 2) that illustrates the connections between terminologies:</p>\r\n\r\n<blockquote><p><img src=\"http://www.j-biomed-inform.com/cms/attachment/2022323725/2041973432/gr2_lrg.jpg\" alt=\"\"></p></blockquote>\r\n\r\n<p>Since most of our resources include structural information, we will likely face a slightly different and more computationally-amenable set of mapping challenges. Nonetheless, the \"differences in granularity between the source and target terminologies\" will be an important consideration.</p>",
      "body_md": "This paper [@10.1016/j.jbi.2012.06.005] discusses the problem of mapping between medication vocabularies. They identify several major difficulties:\r\n\r\n>\r\n1. the availability of up-to-date information to assess the suitability of a given terminological system for a particular use case, and to assess the quality and completeness of cross-terminology links\r\n2. the difficulty of correctly using complex, rapidly evolving, modern terminologies\r\n3. the time and effort required to complete and evaluate the mapping\r\n4. the need to address differences in granularity between the source and target terminologies\r\n5. the need to continuously update the mapping as terminological systems evolve\r\n\r\nThey provide a helpful diagram (manuscript Fig. 2) that illustrates the connections between terminologies:\r\n> ![](http://www.j-biomed-inform.com/cms/attachment/2022323725/2041973432/gr2_lrg.jpg)\r\n\r\nSince most of our resources include structural information, we will likely face a slightly different and more computationally-amenable set of mapping challenges. Nonetheless, the \"differences in granularity between the source and target terminologies\" will be an important consideration.",
      "comment_id": 79,
      "profile_id": 17,
      "published": "2015-03-17T17:52:01.860572Z",
      "thread_id": 40,
      "url": "/discussion/unifying-drug-vocabularies/40#2"
    },
    {
      "body_html": "<h1>Integrating RxNorm ingredients</h1>\r\n\r\n<p>The <a href=\"http://www.nlm.nih.gov/research/umls/rxnorm/\">RxNorm terminology</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1136/amiajnl-2011-000116\" class=\"citation\" data-key=\"10.1136/amiajnl-2011-000116\">1</a>]</span> does not contain chemical structures for ingredients. However, the terminology does cross-reference the NDF-RT and FDA-SRS. The FDA-SRS identifiers, called UNIIs (Unique Ingredient Identifiers), are <a href=\"https://www.ebi.ac.uk/unichem/ucquery/listSources\">included in UniChem</a>. Therefore to map RxNorm ingredients to other vocabularies, we will first convert RXCUIs to UNIIs.</p>\r\n\r\n<p>We downloaded the RxNorm data release and <a href=\"http://www.nlm.nih.gov/research/umls/rxnorm/docs/2015/rxnorm_doco_full_2015-1.html\">loaded it into a MySQL database</a>. We used the following query to produce a RXCUI–UNII mapping:</p>\r\n\r\n<p></p><pre><code class=\"sql\">SELECT DISTINCT RXCUI, CODE\r\nFROM rxnorm.RXNCONSO\r\nWHERE SAB = 'MTHSPL' AND TTY = 'SU' AND CODE != 'NOCODE';</code></pre>",
      "body_md": "# Integrating RxNorm ingredients\r\n\r\nThe [RxNorm terminology](http://www.nlm.nih.gov/research/umls/rxnorm/) [@10.1136/amiajnl-2011-000116] does not contain chemical structures for ingredients. However, the terminology does cross-reference the NDF-RT and FDA-SRS. The FDA-SRS identifiers, called UNIIs (Unique Ingredient Identifiers), are [included in UniChem](https://www.ebi.ac.uk/unichem/ucquery/listSources). Therefore to map RxNorm ingredients to other vocabularies, we will first convert RXCUIs to UNIIs.\r\n\r\nWe downloaded the RxNorm data release and [loaded it into a MySQL database](http://www.nlm.nih.gov/research/umls/rxnorm/docs/2015/rxnorm_doco_full_2015-1.html). We used the following query to produce a RXCUI--UNII mapping:\r\n\r\n```sql\r\nSELECT DISTINCT RXCUI, CODE\r\nFROM rxnorm.RXNCONSO\r\nWHERE SAB = 'MTHSPL' AND TTY = 'SU' AND CODE != 'NOCODE';\r\n```",
      "comment_id": 81,
      "profile_id": 17,
      "published": "2015-03-17T19:40:52.373207Z",
      "thread_id": 40,
      "url": "/discussion/unifying-drug-vocabularies/40#3"
    },
    {
      "body_html": "<p>Would you consider hosting your knowledge network on WikiData ? <a href=\"https://www.wikidata.org/\" target=\"_blank\">https://www.wikidata.org/</a>.  WikiData is a new freebase-like open knowledge base being constructed by the Wikimedia Foundation.</p>\r\n\r\n<p>A couple reasons to think about this:<br>1) Our group has NIH funding to build many of the nodes and edges you need there and we have already started.<br>2) By working in WikiData, your project can benefit from an existing, large user/contributor community and from the WMF computational resources.<br>3) WikiData is fundamentally about open knowledge exchange.  Working in its context will ensure the greatest visibility and re-use for your network.  </p>\r\n\r\n<p>You probably wouldn't want to store computed probabilities there, but qualitative relationships would work well I think.  This would be a great use case for our own efforts..</p>",
      "body_md": "Would you consider hosting your knowledge network on WikiData ? https://www.wikidata.org/.  WikiData is a new freebase-like open knowledge base being constructed by the Wikimedia Foundation.\r\n\r\nA couple reasons to think about this:\r\n1) Our group has NIH funding to build many of the nodes and edges you need there and we have already started.\r\n2) By working in WikiData, your project can benefit from an existing, large user/contributor community and from the WMF computational resources.\r\n3) WikiData is fundamentally about open knowledge exchange.  Working in its context will ensure the greatest visibility and re-use for your network.  \r\n\r\nYou probably wouldn't want to store computed probabilities there, but qualitative relationships would work well I think.  This would be a great use case for our own efforts..\r\n",
      "comment_id": 82,
      "profile_id": 48,
      "published": "2015-03-18T22:23:07.532207Z",
      "thread_id": 23,
      "url": "/discussion/enabling-reproducibility-and-reuse/23#7"
    },
    {
      "body_html": "<p>Daniel,<br>Regarding what to upload.  The figure you presented in your research plan sums this up nicely <a href=\"https://dl.dropboxusercontent.com/s/yp0gjh1v3329xji/metagraph.png\" target=\"_blank\">https://dl.dropboxusercontent.com/s/yp0gjh1v3329xji/metagraph.png</a>Aside from perhaps the MSigDB collection (which could be added), those are exactly the nodes and edges that we hope to see in WikiData.  </p>\r\n\r\n<p>To use WikiData to its full power, you would actually use it within your own application in the same way that you would use your own internal relational database.  Rather than thinking of it only as a repository to export to, you could think of it as the central staging area for the data that you (and the rest of the community) want to compute with.  </p>\r\n\r\n<p>For more about how we are working with wikidata, you can check out the series of blog posts that describes the funded grant here starting here:  <a href=\"http://sulab.org/2013/07/the-future-of-the-gene-wiki/\" target=\"_blank\">http://sulab.org/2013/07/the-future-of-the-gene-wiki/</a>  </p>",
      "body_md": "Daniel,  \r\nRegarding what to upload.  The figure you presented in your research plan sums this up nicely https://dl.dropboxusercontent.com/s/yp0gjh1v3329xji/metagraph.png\r\nAside from perhaps the MSigDB collection (which could be added), those are exactly the nodes and edges that we hope to see in WikiData.  \r\n\r\nTo use WikiData to its full power, you would actually use it within your own application in the same way that you would use your own internal relational database.  Rather than thinking of it only as a repository to export to, you could think of it as the central staging area for the data that you (and the rest of the community) want to compute with.  \r\n\r\nFor more about how we are working with wikidata, you can check out the series of blog posts that describes the funded grant here starting here:  http://sulab.org/2013/07/the-future-of-the-gene-wiki/  ",
      "comment_id": 83,
      "profile_id": 48,
      "published": "2015-03-19T17:54:50.896960Z",
      "thread_id": 23,
      "url": "/discussion/enabling-reproducibility-and-reuse/23#8"
    },
    {
      "body_html": "<p>Instead of using <a href=\"http://www.brenda-enzymes.info/ontology.php?ontology_id=3\">Brenda Tissue Ontology</a>, I would suggest using <a href=\"http://uberon.org\">Uberon</a> for anatomy which incorporates <a href=\"http://cellontology.org/\">CL</a>.These ontologies provide greater breadth of anatomy and cell types for various species. In addition, I think that with integration with Disease Ontology into <a href=\"http://www.ebi.ac.uk/efo\">EFO</a> you can add more data sources to this network as well as links to further experiments. </p>\r\n\r\n<p>ENCODE makes use of Uberon, you can read more  <span class=\"citation\">[<a href=\"https://doi.org/10.1093/database/bav010\" class=\"citation\" data-key=\"10.1093/database/bav010\">1</a>]</span></p>",
      "body_md": "Instead of using [Brenda Tissue Ontology](http://www.brenda-enzymes.info/ontology.php?ontology_id=3), I would suggest using [Uberon](http://uberon.org) for anatomy which incorporates [CL](http://cellontology.org/).These ontologies provide greater breadth of anatomy and cell types for various species. In addition, I think that with integration with Disease Ontology into [EFO](http://www.ebi.ac.uk/efo) you can add more data sources to this network as well as links to further experiments. \r\n\r\nENCODE makes use of Uberon, you can read more  [@10.1093/database/bav010]",
      "comment_id": 84,
      "profile_id": 35,
      "published": "2015-03-19T19:15:53.264452Z",
      "thread_id": 41,
      "url": "/discussion/tissue-node/41"
    },
    {
      "body_html": "<p>Started discussion on changing ontology used for Tissue node. <a href=\"http://thinklab.com/discussion/tissue-node/41\">Discussion is here</a></p>",
      "body_md": "Started discussion on changing ontology used for Tissue node. [Discussion is here](http://thinklab.com/discussion/tissue-node/41)",
      "comment_id": 85,
      "profile_id": 35,
      "published": "2015-03-19T19:17:04.573384Z",
      "thread_id": 22,
      "url": "/discussion/suggestions-for-additional-information-types/22#2"
    },
    {
      "body_html": "<p>Hi <a href=\"/u/vsmalladi\" class=\"username\">@vsmalladi</a>, thanks for the <a href=\"https://uberon.github.io/\">Uberon</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1186/gb-2012-13-1-r5\" class=\"citation\" data-key=\"10.1186/gb-2012-13-1-r5\">1</a>]</span> suggestion.</p>\r\n\r\n<p>The project has good documentation, a nice user interface, and is <a href=\"https://github.com/obophenotype/uberon/commits/master\">actively maintained</a> — three important features when choosing an ontology (and areas where the <a href=\"http://www.brenda-enzymes.info/ontology.php?ontology_id=3\">BRENDA Tissue Ontology</a> (BTO) <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkq968\" class=\"citation\" data-key=\"10.1093/nar/gkq968\">2</a>]</span> sometimes lags behind.</p>\r\n\r\n<p>In our previous network <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1004259\">3</a>]</span>, we had under 100 tissues and only used BTO as a common vocabulary. Since the current project is in an early stage, it is difficult to know whether we will take full advantage of the rich structure and cross-referencing provided by next-generation ontologies. However, I agree it makes sense to build an extensible and forward-thinking network and Uberon will assist in these pursuits. We also prefer ontologies that will have the widest adoption and are free of restrictive licensing. Do you know Uberon's license?</p>\r\n\r\n<p>I noticed Uberon includes <a href=\"https://github.com/obophenotype/uberon/wiki/inter-anatomy-ontology-bridge-ontologies\">mappings to other ontologies</a>, called <em>bridges</em>. A BTO bridge doesn't currently exist, but perhaps we could contribute one for the 77 BTO terms (<a href=\"http://het.io/disease-genes/downloads/files/expression.txt.gz\">download link</a>) used in our disease network.</p>",
      "body_md": "Hi @vsmalladi, thanks for the [Uberon](https://uberon.github.io/) [@10.1186/gb-2012-13-1-r5] suggestion.\r\n\r\nThe project has good documentation, a nice user interface, and is [actively maintained](https://github.com/obophenotype/uberon/commits/master) -- three important features when choosing an ontology (and areas where the [BRENDA Tissue Ontology](http://www.brenda-enzymes.info/ontology.php?ontology_id=3) (BTO) [@10.1093/nar/gkq968] sometimes lags behind.\r\n\r\nIn our previous network [@10.1371/journal.pcbi.1004259], we had under 100 tissues and only used BTO as a common vocabulary. Since the current project is in an early stage, it is difficult to know whether we will take full advantage of the rich structure and cross-referencing provided by next-generation ontologies. However, I agree it makes sense to build an extensible and forward-thinking network and Uberon will assist in these pursuits. We also prefer ontologies that will have the widest adoption and are free of restrictive licensing. Do you know Uberon's license?\r\n\r\nI noticed Uberon includes [mappings to other ontologies](https://github.com/obophenotype/uberon/wiki/inter-anatomy-ontology-bridge-ontologies), called *bridges*. A BTO bridge doesn't currently exist, but perhaps we could contribute one for the 77 BTO terms ([download link](http://het.io/disease-genes/downloads/files/expression.txt.gz)) used in our disease network.",
      "comment_id": 86,
      "profile_id": 17,
      "published": "2015-03-20T02:35:04.095121Z",
      "thread_id": 41,
      "url": "/discussion/tissue-node/41#2"
    },
    {
      "body_html": "<p>Hi <a href=\"/u/b_good\" class=\"username\">@b_good</a>, fascinating work. I was amazed that the <a href=\"https://en.wikipedia.org/wiki/Gene_Wiki\">Gene Wiki</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pbio.0060175\" class=\"citation\" data-key=\"10.1371/journal.pbio.0060175\">1</a>]</span> <a href=\"http://sulab.org/2013/07/gene-wiki-progress-report/\">averages</a> \"two page views every single second\". This amazing traffic, and return on investement from the perspective of funders, illustrates the potential of open, crowdsourced, and collaborative undertakings.</p>\r\n\r\n<p>I think your wiki work capitalizes on a larger trend of computing moving to the web and browser. I recently made my <a href=\"http://slides.com/dhimmel/elevcan\">first html presentation</a>; my coding is now largely browser based thanks to <a href=\"http://jupyter.org/\">Jupyter</a> and <a href=\"http://www.rstudio.com/\">RStudio</a> and <a href=\"https://github.com/dhimmel\">hosted</a> online; API web-queries are now fundamental for information retrieval. It only makes sense that we adopt a information commons like Wikidata to integrate knowledge. The video below really sold me on the concept:</p>\r\n\r\n<p><iframe src=\"https://www.youtube.com/embed/Rww2dA-1Cqc\" width=\"640\" height=\"360\" frameborder=\"0\" allowfullscreen=\"true\"></iframe></p>\r\n\r\n<p>Since the initial stage of this project is highly prototypical, I am hesitant to immediately switch to Wikidata as our backend. However, I would love to work with you and your team to upload as much content as possible. Then for subsequent analyses, we could potentially pull from Wikidata.</p>",
      "body_md": "Hi @b_good, fascinating work. I was amazed that the [Gene Wiki](https://en.wikipedia.org/wiki/Gene_Wiki) [@10.1371/journal.pbio.0060175] [averages](http://sulab.org/2013/07/gene-wiki-progress-report/) \"two page views every single second\". This amazing traffic, and return on investement from the perspective of funders, illustrates the potential of open, crowdsourced, and collaborative undertakings.\r\n\r\nI think your wiki work capitalizes on a larger trend of computing moving to the web and browser. I recently made my [first html presentation](http://slides.com/dhimmel/elevcan); my coding is now largely browser based thanks to [Jupyter](http://jupyter.org/) and [RStudio](http://www.rstudio.com/) and [hosted](https://github.com/dhimmel) online; API web-queries are now fundamental for information retrieval. It only makes sense that we adopt a information commons like Wikidata to integrate knowledge. The video below really sold me on the concept:\r\n\r\n![:youtube](Rww2dA-1Cqc)\r\n\r\nSince the initial stage of this project is highly prototypical, I am hesitant to immediately switch to Wikidata as our backend. However, I would love to work with you and your team to upload as much content as possible. Then for subsequent analyses, we could potentially pull from Wikidata.",
      "comment_id": 87,
      "profile_id": 17,
      "published": "2015-03-20T04:06:29.499007Z",
      "thread_id": 23,
      "url": "/discussion/enabling-reproducibility-and-reuse/23#9"
    },
    {
      "body_html": "<p>Hi <a href=\"/u/dantericci\" class=\"username\">@dantericci</a>, I believe there is no restrictive licensing and is open to use. </p>\r\n\r\n<p>As for adpotion, they have many big projects and consotrium adopting use of Uberon. Such as EBI, <a href=\"http://uberon.github.io/about/adopters.html\">other adoptors</a>.</p>\r\n\r\n<p>Uberon does have cross-references to BTO, so I don't think we need to make a bridge. </p>",
      "body_md": "Hi @dantericci, I believe there is no restrictive licensing and is open to use. \r\n\r\nAs for adpotion, they have many big projects and consotrium adopting use of Uberon. Such as EBI, [other adoptors](http://uberon.github.io/about/adopters.html).\r\n\r\nUberon does have cross-references to BTO, so I don't think we need to make a bridge. ",
      "comment_id": 88,
      "profile_id": 35,
      "published": "2015-03-20T06:13:53.412703Z",
      "thread_id": 41,
      "url": "/discussion/tissue-node/41#3"
    },
    {
      "body_html": "<p>I <a href=\"http://thinklab.com/p/rephetio/plan/compare/cf0af88368d84640e6face839932af64a0963f5f/438864fde53c372dfa654dd59674f4bfc6cf249c\">updated the proposal</a> to replace BTO with Uberon.</p>\r\n\r\n<p>As for the BTO mapping, I didn't see <a href=\"https://github.com/obophenotype/uberon/tree/master/bridge\">any bridges on the GitHub</a> and the <a href=\"http://purl.obolibrary.org/obo/uberon/bridge/uberon-bridge-to-bto.owl\">BTO bridge download</a> produces an error. Am I looking in the wrong place or are the BTO mappings not populated yet?</p>",
      "body_md": "I [updated the proposal](http://thinklab.com/p/rephetio/plan/compare/cf0af88368d84640e6face839932af64a0963f5f/438864fde53c372dfa654dd59674f4bfc6cf249c) to replace BTO with Uberon.\r\n\r\nAs for the BTO mapping, I didn't see [any bridges on the GitHub](https://github.com/obophenotype/uberon/tree/master/bridge) and the [BTO bridge download](http://purl.obolibrary.org/obo/uberon/bridge/uberon-bridge-to-bto.owl) produces an error. Am I looking in the wrong place or are the BTO mappings not populated yet?",
      "comment_id": 89,
      "profile_id": 17,
      "published": "2015-03-20T06:41:44.409926Z",
      "thread_id": 41,
      "url": "/discussion/tissue-node/41#4"
    },
    {
      "body_html": "<p><a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a> Within the <a href=\"http://berkeleybop.org/ontologies/uberon.owl\">Uberon file</a> there are DbXref's. An example is for </p>\r\n\r\n<pre><code>&lt;owl:Class rdf:about=\"http://purl.obolibrary.org/obo/UBERON_0000002\"&gt;\r\n    &lt;rdfs:label rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\"&gt;uterine cervix&lt;/rdfs:label&gt;\r\n    &lt;oboInOwl:hasDbXref rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\"&gt;BTO:0001421&lt;/oboInOwl:hasDbXref&gt;\r\n    &lt;oboInOwl:hasDbXref rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\"&gt;BTO:0002249&lt;/oboInOwl:hasDbXref&gt;</code></pre>",
      "body_md": "@dhimmel Within the [Uberon file](http://berkeleybop.org/ontologies/uberon.owl) there are DbXref's. An example is for \r\n\r\n    <owl:Class rdf:about=\"http://purl.obolibrary.org/obo/UBERON_0000002\">\r\n        <rdfs:label rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">uterine cervix</rdfs:label>\r\n        <oboInOwl:hasDbXref rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">BTO:0001421</oboInOwl:hasDbXref>\r\n        <oboInOwl:hasDbXref rdf:datatype=\"http://www.w3.org/2001/XMLSchema#string\">BTO:0002249</oboInOwl:hasDbXref>",
      "comment_id": 90,
      "profile_id": 35,
      "published": "2015-03-20T15:44:19.979836Z",
      "thread_id": 41,
      "url": "/discussion/tissue-node/41#5"
    },
    {
      "body_html": "<h1>The UniChem Connectivity Search</h1>\r\n\r\n<p>UniChem is a structure-centric search engine (based on InChI identifiers <span class=\"citation\">[<a href=\"https://doi.org/10.1186/1758-2946-5-7\" class=\"citation\" data-key=\"10.1186/1758-2946-5-7\">1</a>]</span>) for compound unification <span class=\"citation\">[<a href=\"https://doi.org/10.1186/1758-2946-5-3\" class=\"citation\" data-key=\"10.1186/1758-2946-5-3\">2</a>]</span>. UniChem includes a widesearch mode that matches compounds based on common connectivity <span class=\"citation\">[<a href=\"https://doi.org/10.1186/s13321-014-0043-5\" class=\"citation\" data-key=\"10.1186/s13321-014-0043-5\">3</a>]</span>. We speculate that fuzzy matching will outperform a strict structural identity matching <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.ddtec.2015.01.005\" class=\"citation\" data-key=\"10.1016/j.ddtec.2015.01.005\">4</a>]</span> because:</p>\r\n\r\n<ul><li>we will retain more information by integrating greater percentages of external databases</li><li>small chemical variations may have a minimal pharmacodynamic impact</li><li>many resources and pharmacologists conceptualize compounds with less granularity than exact chemical structure</li></ul>\r\n\r\n<h1>Mapping external resrouces to DrugBank</h1>\r\n\r\n<p>We would like to standardize all compound resources using DrugBank <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkt1068\" class=\"citation\" data-key=\"10.1093/nar/gkt1068\">5</a>]</span>. To accomplish this task, we first <a href=\"//nbviewer.ipython.org/url/git.dhimmel.com/drugbank/parse.ipynb\">parsed the DrugBank xml download</a> to extract basic compound information. Second, we <a href=\"//nbviewer.ipython.org/url/git.dhimmel.com/drugbank/unichem-map.ipynb\">mapped DrugBank compounds to each resource in UniChem</a> using the connectivity search [<a href=\"https://www.ebi.ac.uk/unichem/info/widesearchInfo\">docs</a>]. Third, we <a href=\"//git.dhimmel.com/drugbank/unichem-map.html\">assessed the mappings using a variety of metrics</a>. For this third step, we concentrated only on approved small molecules as these will be the most essential and connected in our network.</p>\r\n\r\n<p>The following findings were aparent:</p>\r\n\r\n<ul><li>DrugBank contained 1,600 approved small molecules, 51 of which were lacking structural information and could not be mapped.</li><li>108 DrugBank compounds mapped to multiple DrugBank compounds indicating the granularity of our connectivity search is not equivalent to the granularity of the DrugBank inclusion criteria.</li><li>93% of DrugBank compounds had atleast one match in ChEMBL, 77% matched FDA SRS (UNII), 95% matched PubChem, 57% matched LINCS</li><li>Zolmitriptan (DB00315) matched 768 PubChem compounds</li></ul>\r\n\r\n<p>Given these findings, we have the following <strong>questions for a chemist or cheminformaticist</strong>:</p>\r\n\r\n<ol><li>Given our focus on pharmacodynamics rather than pharmacokinetics and our desire to avoid duplicate entities in the network, did we <a href=\"//nbviewer.ipython.org/url/git.dhimmel.com/drugbank/unichem-map.ipynb\">properly construct our UniChem query</a>? </li><li>Given that some DrugBank compounds matched multiple DrugBank compounds (<a href=\"//git.dhimmel.com/drugbank/unichem-map.html\">see histograms</a>), should we instead use the First InChIKey Hash Block (FIKHB) as the primary compound identifier?</li><li>~20% of approved small molecules in DrugBank did not match a FDA-SRS (UNII) compound, which is troubling. Many of these unmatched compounds would have matched by name matching. We would like an explanation for this discrepency and will look into the issue further ourselves.</li><li>Should we use a tiered matching system, where we take only exact matches when available and then expand to connecitivity matches if necessary?</li><li>Should we adopt an even more permissive (or alternative) mapping strategy for LINCS to annotate more compounds with transcriptomic profiles?</li><li>Is the excessive number of PubChem matches for some DrugBank compounds indicative of a larger problem? The full mapping can be <a href=\"//git.dhimmel.com/drugbank/data/mapping.tsv.gz\">downloaded here</a>.</li></ol>",
      "body_md": "# The UniChem Connectivity Search\r\n\r\nUniChem is a structure-centric search engine (based on InChI identifiers [@10.1186/1758-2946-5-7]) for compound unification [@10.1186/1758-2946-5-3]. UniChem includes a widesearch mode that matches compounds based on common connectivity [@10.1186/s13321-014-0043-5]. We speculate that fuzzy matching will outperform a strict structural identity matching [@10.1016/j.ddtec.2015.01.005] because:\r\n\r\n+ we will retain more information by integrating greater percentages of external databases\r\n+ small chemical variations may have a minimal pharmacodynamic impact\r\n+ many resources and pharmacologists conceptualize compounds with less granularity than exact chemical structure\r\n\r\n# Mapping external resrouces to DrugBank\r\n\r\nWe would like to standardize all compound resources using DrugBank [@10.1093/nar/gkt1068]. To accomplish this task, we first [parsed the DrugBank xml download](//nbviewer.ipython.org/url/git.dhimmel.com/drugbank/parse.ipynb) to extract basic compound information. Second, we [mapped DrugBank compounds to each resource in UniChem](//nbviewer.ipython.org/url/git.dhimmel.com/drugbank/unichem-map.ipynb) using the connectivity search [[docs](https://www.ebi.ac.uk/unichem/info/widesearchInfo)]. Third, we [assessed the mappings using a variety of metrics](//git.dhimmel.com/drugbank/unichem-map.html). For this third step, we concentrated only on approved small molecules as these will be the most essential and connected in our network.\r\n\r\nThe following findings were aparent:\r\n\r\n+ DrugBank contained 1,600 approved small molecules, 51 of which were lacking structural information and could not be mapped.\r\n+ 108 DrugBank compounds mapped to multiple DrugBank compounds indicating the granularity of our connectivity search is not equivalent to the granularity of the DrugBank inclusion criteria.\r\n+ 93% of DrugBank compounds had atleast one match in ChEMBL, 77% matched FDA SRS (UNII), 95% matched PubChem, 57% matched LINCS\r\n+ Zolmitriptan (DB00315) matched 768 PubChem compounds\r\n\r\nGiven these findings, we have the following **questions for a chemist or cheminformaticist**:\r\n\r\n1. Given our focus on pharmacodynamics rather than pharmacokinetics and our desire to avoid duplicate entities in the network, did we [properly construct our UniChem query](//nbviewer.ipython.org/url/git.dhimmel.com/drugbank/unichem-map.ipynb)? \r\n2. Given that some DrugBank compounds matched multiple DrugBank compounds ([see histograms](//git.dhimmel.com/drugbank/unichem-map.html)), should we instead use the First InChIKey Hash Block (FIKHB) as the primary compound identifier?\r\n3. ~20% of approved small molecules in DrugBank did not match a FDA-SRS (UNII) compound, which is troubling. Many of these unmatched compounds would have matched by name matching. We would like an explanation for this discrepency and will look into the issue further ourselves.\r\n4. Should we use a tiered matching system, where we take only exact matches when available and then expand to connecitivity matches if necessary?\r\n5. Should we adopt an even more permissive (or alternative) mapping strategy for LINCS to annotate more compounds with transcriptomic profiles?\r\n6. Is the excessive number of PubChem matches for some DrugBank compounds indicative of a larger problem? The full mapping can be [downloaded here](//git.dhimmel.com/drugbank/data/mapping.tsv.gz).",
      "comment_id": 91,
      "profile_id": 17,
      "published": "2015-03-20T21:37:04.117495Z",
      "thread_id": 40,
      "url": "/discussion/unifying-drug-vocabularies/40#4"
    },
    {
      "body_html": "<p>In order to make the disease data within the <em>Incomplete Interactome</em> easier to manipulate we have mapped the MeSH disease names used within the paper to their corresponding MeSH IDs. The outcome (<a href=\"https://raw.githubusercontent.com/LABrueggs/incomplete-interactome/master/disease_output.tsv\">here</a>) should make integrating data from this study simpler. The <a href=\"http://nbviewer.ipython.org/github/LABrueggs/incomplete-interactome/blob/master/SciencetoMESHterm.ipynb\">python program</a> and its associated input and output files can be found <a href=\"https://github.com/LABrueggs/incomplete-interactome\">here</a>.</p>",
      "body_md": "In order to make the disease data within the *Incomplete Interactome* easier to manipulate we have mapped the MeSH disease names used within the paper to their corresponding MeSH IDs. The outcome ([here](https://raw.githubusercontent.com/LABrueggs/incomplete-interactome/master/disease_output.tsv)) should make integrating data from this study simpler. The [python program](http://nbviewer.ipython.org/github/LABrueggs/incomplete-interactome/blob/master/SciencetoMESHterm.ipynb) and its associated input and output files can be found [here](https://github.com/LABrueggs/incomplete-interactome).",
      "comment_id": 92,
      "profile_id": 21,
      "published": "2015-03-25T21:20:49.529810Z",
      "thread_id": 42,
      "url": "/discussion/mapping-incomplete-interactome-disease-names-to-mesh/42"
    },
    {
      "body_html": "<p><a href=\"//www.lincscloud.org/\">LINCS</a> (Library of Integrated Cellular Signatures) provided \"perturbational profiles across multiple cell and perturbation types, as well as read-outs, at a massive scale.\" We plan to compute transcriptional profiles, i.e. expression signatures — sets of up and down-regulated genes — for the compounds in our network. We will be following a workflow suggested to us by Ted Natoli during the <a href=\"//www.lincscloud.org/training/\">online office hours</a>.</p>\r\n\r\n<p>For a given compound in our network, there may be multiple matched LINCS compounds. Additionally, each LINCS compound may have been assayed across multiple cell lines, dosages, and replicates. To calculate a single consensus transcriptional profile across multiple signatures we will</p>\r\n\r\n<ol><li>calculate pairwise correlations between signatures</li><li>calculate mean correlation with other signatures for each signature</li><li>scale similarities to sum to 1</li><li>multiply z-score signature vectors by their similarity weights</li><li>sum weighted z-score signature vectors</li></ol>\r\n\r\n<p>The z-score signature vectors are retrieved from the <code>/xchip/cogs/data/build/a2y13q1/modzs.gctx</code> file on the <a href=\"http://c3.lincscloud.org/\">C3 cloud</a>.</p>",
      "body_md": "[LINCS](//www.lincscloud.org/) (Library of Integrated Cellular Signatures) provided \"perturbational profiles across multiple cell and perturbation types, as well as read-outs, at a massive scale.\" We plan to compute transcriptional profiles, i.e. expression signatures -- sets of up and down-regulated genes -- for the compounds in our network. We will be following a workflow suggested to us by Ted Natoli during the [online office hours](//www.lincscloud.org/training/).\r\n\r\nFor a given compound in our network, there may be multiple matched LINCS compounds. Additionally, each LINCS compound may have been assayed across multiple cell lines, dosages, and replicates. To calculate a single consensus transcriptional profile across multiple signatures we will\r\n\r\n1. calculate pairwise correlations between signatures\r\n+ calculate mean correlation with other signatures for each signature\r\n+ scale similarities to sum to 1\r\n+ multiply z-score signature vectors by their similarity weights\r\n+ sum weighted z-score signature vectors\r\n\r\nThe z-score signature vectors are retrieved from the `/xchip/cogs/data/build/a2y13q1/modzs.gctx` file on the [C3 cloud](http://c3.lincscloud.org/).",
      "comment_id": 93,
      "profile_id": 17,
      "published": "2015-03-27T02:43:44.027312Z",
      "thread_id": 43,
      "url": "/discussion/computing-consensus-transcriptional-profiles-for-lincs-l1000-perturbations/43"
    },
    {
      "body_html": "<p>This discussion will explore how to unify the variety of disease vocabularies used by our resources. These resources are listed below:</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>type</th><th>resource</th><th>vocabulary</th></tr></thead><tbody><tr><td>indications</td><td>MEDI <span class=\"citation\">[<a href=\"https://doi.org/10.1136/amiajnl-2012-001431\" class=\"citation\" data-key=\"10.1136/amiajnl-2012-001431\">1</a>]</span></td><td>ICD-9</td></tr><tr><td>indications</td><td>LabeledIn <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.jbi.2014.08.004\" class=\"citation\" data-key=\"10.1016/j.jbi.2014.08.004\">2</a>, <a href=\"https://doi.org/10.1093/database/bav016\" class=\"citation\" data-key=\"10.1093/database/bav016\">3</a>]</span></td><td>UMLS <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkh061\" class=\"citation\" data-key=\"10.1093/nar/gkh061\">4</a>]</span></td></tr><tr><td>transcriptional signatures</td><td><a href=\"http://dev.stargeo.io/\">STAR-GEO</a></td><td>custom</td></tr><tr><td>symptoms</td><td>HSDN <span class=\"citation\">[<a href=\"https://doi.org/10.1038/ncomms5212\" class=\"citation\" data-key=\"10.1038/ncomms5212\">5</a>]</span></td><td><a href=\"//www.nlm.nih.gov/mesh/filelist.html\">MeSH</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1001/jama.271.14.1103\" class=\"citation\" data-key=\"10.1001/jama.271.14.1103\">6</a>]</span> (2011 release)</td></tr><tr><td>gene associations</td><td><a href=\"//het.io/disease-genes/downloads/\">het.io</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1101/011569\" class=\"citation\" data-key=\"10.1101/011569\">7</a>]</span></td><td><a href=\"//disease-ontology.org/\">Disease Ontology</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkr972\" class=\"citation\" data-key=\"10.1093/nar/gkr972\">8</a>, <a href=\"https://doi.org/10.1093/nar/gku1011\" class=\"citation\" data-key=\"10.1093/nar/gku1011\">9</a>]</span></td></tr><tr><td>pathophysiology</td><td><a href=\"//het.io/disease-genes/downloads/\">het.io</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1101/011569\" class=\"citation\" data-key=\"10.1101/011569\">7</a>]</span></td><td><a href=\"//disease-ontology.org/\">Disease Ontology</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkr972\" class=\"citation\" data-key=\"10.1093/nar/gkr972\">8</a>, <a href=\"https://doi.org/10.1093/nar/gku1011\" class=\"citation\" data-key=\"10.1093/nar/gku1011\">9</a>]</span></td></tr><tr><td>tissue localization</td><td><a href=\"//het.io/disease-genes/downloads/\">het.io</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1101/011569\" class=\"citation\" data-key=\"10.1101/011569\">7</a>]</span></td><td><a href=\"//disease-ontology.org/\">Disease Ontology</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkr972\" class=\"citation\" data-key=\"10.1093/nar/gkr972\">8</a>, <a href=\"https://doi.org/10.1093/nar/gku1011\" class=\"citation\" data-key=\"10.1093/nar/gku1011\">9</a>]</span></td></tr></tbody></table>\r\n\r\n<p>Our current plan is to use the Disease Ontology (DO) as our primary vocabulary. Therefore, we will have to map resources to DO terms.</p>",
      "body_md": "This discussion will explore how to unify the variety of disease vocabularies used by our resources. These resources are listed below:\r\n\r\n| type | resource | vocabulary |\r\n| - | - | - |\r\n| indications | MEDI [@10.1136/amiajnl-2012-001431] | ICD-9 |\r\n| indications | LabeledIn [@10.1016/j.jbi.2014.08.004 @10.1093/database/bav016] | UMLS [@10.1093/nar/gkh061] |\r\n| transcriptional signatures | [STAR-GEO](http://dev.stargeo.io/) | custom |\r\n| symptoms | HSDN [@10.1038/ncomms5212] | [MeSH](//www.nlm.nih.gov/mesh/filelist.html) [@10.1001/jama.271.14.1103] (2011 release) |\r\n| gene associations | [het.io](//het.io/disease-genes/downloads/) [@10.1101/011569] | [Disease Ontology](//disease-ontology.org/) [@10.1093/nar/gkr972 @10.1093/nar/gku1011] |\r\n| pathophysiology | [het.io](//het.io/disease-genes/downloads/) [@10.1101/011569] | [Disease Ontology](//disease-ontology.org/) [@10.1093/nar/gkr972 @10.1093/nar/gku1011] |\r\n| tissue localization | [het.io](//het.io/disease-genes/downloads/) [@10.1101/011569] | [Disease Ontology](//disease-ontology.org/) [@10.1093/nar/gkr972 @10.1093/nar/gku1011] |\r\n\r\nOur current plan is to use the Disease Ontology (DO) as our primary vocabulary. Therefore, we will have to map resources to DO terms.",
      "comment_id": 94,
      "profile_id": 17,
      "published": "2015-03-31T00:16:47.526338Z",
      "thread_id": 44,
      "url": "/discussion/unifying-disease-vocabularies/44"
    },
    {
      "body_html": "<p>The initial LabeledIn <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.jbi.2014.08.004\" class=\"citation\" data-key=\"10.1016/j.jbi.2014.08.004\">1</a>]</span> resource used expert curators. The team behind this project tested crowdsourced curation using Amazon Mechanical Turk workers <span class=\"citation\">[<a href=\"https://doi.org/10.1093/database/bav016\" class=\"citation\" data-key=\"10.1093/database/bav016\">2</a>]</span>. They found the majority vote of workers on whether a disease within a label was an indication had a high accuracy (96%).</p>\r\n\r\n<p>They <a href=\"ftp://ftp.ncbi.nlm.nih.gov/pub/lu/LabeledIn/Crowdsourcing/\">assessed</a> 3004 indications not already in LabeledIn corresponding to 706 new drug labels. We are looking to increase the coverage of the initial LabeledIn dataset by adding these crowdsourced indications.</p>",
      "body_md": "The initial LabeledIn [@10.1016/j.jbi.2014.08.004] resource used expert curators. The team behind this project tested crowdsourced curation using Amazon Mechanical Turk workers [@10.1093/database/bav016]. They found the majority vote of workers on whether a disease within a label was an indication had a high accuracy (96%).\r\n\r\nThey [assessed](ftp://ftp.ncbi.nlm.nih.gov/pub/lu/LabeledIn/Crowdsourcing/) 3004 indications not already in LabeledIn corresponding to 706 new drug labels. We are looking to increase the coverage of the initial LabeledIn dataset by adding these crowdsourced indications.",
      "comment_id": 96,
      "profile_id": 17,
      "published": "2015-04-01T21:45:15.517786Z",
      "thread_id": 21,
      "url": "/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#2"
    },
    {
      "body_html": "<p>The <a href=\"http://ftp.ncbi.nlm.nih.gov/pub/lu/LabeledIn/\">LabeledIn</a> resource consists of an expert curated <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.jbi.2014.08.004\" class=\"citation\" data-key=\"10.1016/j.jbi.2014.08.004\">1</a>]</span> and crowdsourced <span class=\"citation\">[<a href=\"https://doi.org/10.1093/database/bav016\" class=\"citation\" data-key=\"10.1093/database/bav016\">2</a>]</span> components. Here we will discuss parsing these resources to extract indications.</p>",
      "body_md": "The [LabeledIn](http://ftp.ncbi.nlm.nih.gov/pub/lu/LabeledIn/) resource consists of an expert curated [@10.1016/j.jbi.2014.08.004] and crowdsourced [@10.1093/database/bav016] components. Here we will discuss parsing these resources to extract indications.",
      "comment_id": 97,
      "profile_id": 17,
      "published": "2015-04-02T17:16:17.491299Z",
      "thread_id": 46,
      "url": "/discussion/processing-labeledin-to-extract-indications/46"
    },
    {
      "body_html": "<h1>Disease Ontology Resources</h1>\r\n\r\n<p>Since we plan to use the DO as our primary disease vocabulary, I thought I would keep track of related papers and projects here. These may be slightly off-topic but valuable to keep track of.</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>name</th><th>description</th><th>cite</th></tr></thead><tbody><tr><td><a href=\"//disease-ontology.org\">Disease Ontology</a></td><td>Main resource</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkr972\" class=\"citation\" data-key=\"10.1093/nar/gkr972\">1</a>, <a href=\"https://doi.org/10.1093/nar/gku1011\" class=\"citation\" data-key=\"10.1093/nar/gku1011\">2</a>]</span></td></tr><tr><td><a href=\"http://django.nubic.northwestern.edu/fundo/\">DOLite</a></td><td>DO terms are grouped using associated-gene similarity to produce a simplified vocabulary with little redundancy.</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1093/bioinformatics/btp193\" class=\"citation\" data-key=\"10.1093/bioinformatics/btp193\">3</a>]</span></td></tr><tr><td>DO_cancer_slim</td><td>Created a DO subset named <code>TOPNodes_DOcancerslim</code> composed of 63 non-redundant upper-level cancer terms</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1093/database/bav032\" class=\"citation\" data-key=\"10.1093/database/bav032\">4</a>]</span></td></tr><tr><td><a href=\"http://doa.nubic.northwestern.edu/pages/search.php\">DOAF</a></td><td>Provides gene annotations (extracted from GeneRIF) to the Disease Ontology.</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pone.0049686\" class=\"citation\" data-key=\"10.1371/journal.pone.0049686\">5</a>]</span></td></tr><tr><td><a href=\"http://django.nubic.northwestern.edu/fundo/\">FunDO</a></td><td>Provides gene annotations (extracted from GeneRIF) to the Disease Ontology. Uses diseases from DOLite. Potentially outdated.</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1186/1471-2164-10-S1-S6\" class=\"citation\" data-key=\"10.1186/1471-2164-10-S1-S6\">6</a>]</span></td></tr><tr><td><a href=\"https://github.com/GuangchuangYu/DOSE\">DOSE</a></td><td>DOSE is an R package to compute semantic similarity between DO terms. The result is pairwise similarities between DO terms based only on the ontology structure.</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1093/bioinformatics/btu684\" class=\"citation\" data-key=\"10.1093/bioinformatics/btu684\">7</a>]</span></td></tr><tr><td><a href=\"http://cran.r-project.org/web/packages/DOSim/index.html\">DOsim</a></td><td>Similar to DOSE but allegedly unmaintained or outdated</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1186/1471-2105-12-266\" class=\"citation\" data-key=\"10.1186/1471-2105-12-266\">8</a>]</span></td></tr></tbody></table>",
      "body_md": "# Disease Ontology Resources\r\n\r\nSince we plan to use the DO as our primary disease vocabulary, I thought I would keep track of related papers and projects here. These may be slightly off-topic but valuable to keep track of.\r\n\r\n| name | description | cite |\r\n| - | - | - |\r\n| [Disease Ontology](//disease-ontology.org) | Main resource | [@10.1093/nar/gkr972 @10.1093/nar/gku1011] |\r\n| [DOLite](http://django.nubic.northwestern.edu/fundo/) | DO terms are grouped using associated-gene similarity to produce a simplified vocabulary with little redundancy. | [@10.1093/bioinformatics/btp193] |\r\n| DO_cancer_slim | Created a DO subset named `TOPNodes_DOcancerslim` composed of 63 non-redundant upper-level cancer terms | [@10.1093/database/bav032] |\r\n| [DOAF](http://doa.nubic.northwestern.edu/pages/search.php) | Provides gene annotations (extracted from GeneRIF) to the Disease Ontology. | [@10.1371/journal.pone.0049686] |\r\n| [FunDO](http://django.nubic.northwestern.edu/fundo/) | Provides gene annotations (extracted from GeneRIF) to the Disease Ontology. Uses diseases from DOLite. Potentially outdated. | [@10.1186/1471-2164-10-S1-S6] |\r\n| [DOSE](https://github.com/GuangchuangYu/DOSE) | DOSE is an R package to compute semantic similarity between DO terms. The result is pairwise similarities between DO terms based only on the ontology structure.| [@10.1093/bioinformatics/btu684] |\r\n| [DOsim](http://cran.r-project.org/web/packages/DOSim/index.html) | Similar to DOSE but allegedly unmaintained or outdated | [@10.1186/1471-2105-12-266] |\r\n",
      "comment_id": 98,
      "profile_id": 17,
      "published": "2015-04-02T22:13:31.868516Z",
      "thread_id": 44,
      "url": "/discussion/unifying-disease-vocabularies/44#2"
    },
    {
      "body_html": "<p>What data are you planning to use to validate your framework?  E.g. what are the positive controls?  Presumably you would have some collection of drug-disease pairs that would be divided into development, training, and testing sets? </p>",
      "body_md": "What data are you planning to use to validate your framework?  E.g. what are the positive controls?  Presumably you would have some collection of drug-disease pairs that would be divided into development, training, and testing sets? ",
      "comment_id": 99,
      "profile_id": 48,
      "published": "2015-04-03T04:43:56.743898Z",
      "thread_id": 47,
      "url": "/discussion/evaluation-framework/47"
    },
    {
      "body_html": "<p>You say elsewhere that you want to avoid bias - that you want to work basically form experimental measurements as much as possible.  This has some merit, but it also seems like there must be quite a lot of value out there in the space of biased knowledge.. Some of that bias will be real signal.  Would be great to execute an experiment to empirically test the impact of bringing in prior knowledge (e.g. via text mining techniques for relation extraction).  Does it make it better or worse at the task at hand?</p>",
      "body_md": "You say elsewhere that you want to avoid bias - that you want to work basically form experimental measurements as much as possible.  This has some merit, but it also seems like there must be quite a lot of value out there in the space of biased knowledge.. Some of that bias will be real signal.  Would be great to execute an experiment to empirically test the impact of bringing in prior knowledge (e.g. via text mining techniques for relation extraction).  Does it make it better or worse at the task at hand?",
      "comment_id": 100,
      "profile_id": 48,
      "published": "2015-04-03T04:53:35.489041Z",
      "thread_id": 48,
      "url": "/discussion/text-as-a-resource-for-network-population/48"
    },
    {
      "body_html": "<p>This dataset might be worth looking into.  Drug-indication links captured from physicians in an EHR system <span class=\"citation\">[<a href=\"https://doi.org/10.1136/amiajnl-2012-000852\" class=\"citation\" data-key=\"10.1136/amiajnl-2012-000852\">1</a>]</span> .  Data appears to be available - though its in a 200+ page PDF!  <a href=\"http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3422843/bin/amiajnl-2012-000852-s1.pdf\" target=\"_blank\">http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3422843/bin/amiajnl-2012-000852-s1.pdf</a>(I'm sure that was a journal requirement).</p>",
      "body_md": "This dataset might be worth looking into.  Drug-indication links captured from physicians in an EHR system [@10.1136/amiajnl-2012-000852] .  Data appears to be available - though its in a 200+ page PDF!  http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3422843/bin/amiajnl-2012-000852-s1.pdf\r\n(I'm sure that was a journal requirement).\r\n",
      "comment_id": 101,
      "profile_id": 48,
      "published": "2015-04-03T05:35:58.188298Z",
      "thread_id": 21,
      "url": "/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#3"
    },
    {
      "body_html": "<p>Question: I was under the impression that the workers assessed individual indications rather than all indications within a specific label. Therefore each drug–disease (RxNORM–UMLS) pair should have it's own majority vote. However, the data release appears to be listed in terms of labels rather than indications. Some labels have multiple UMLS diseases but only report the outcome of a single vote. Majority votes should be in terms of indications rather than labels, right?</p>\r\n\r\n<p>Answer: You are right: each drug–disease (RxNORM–UMLS) pair should have it's own majority vote and majority votes should be in terms of indications rather than labels. The data is organized in this manner only (one entry = one drug-label/UMLSCUI pair). Each entry in the text file corresponds to one indication candidate (i.e. one disease UMLS-CUI) in a given drug label. The disease CUI is specified in the third field of the file. Also, as you have already noted that there for some entries with two CUIs in the third field. These correspond to composite mentions (e.g.\"Moderate to severe pain\"). Our <a href=\"http://metamap.nlm.nih.gov/\">disease NER module</a> detects two concepts for this phrase (\"moderate +pain\" and \"severe pain\") but we present this phrase as a single disease mention to the turkers and hence a single majority vote was computed for both UMLS-CUIs.</p>\r\n\r\n<p>We are happy to answer more questions! - LabeledIn Team</p>",
      "body_md": "Question: I was under the impression that the workers assessed individual indications rather than all indications within a specific label. Therefore each drug--disease (RxNORM--UMLS) pair should have it's own majority vote. However, the data release appears to be listed in terms of labels rather than indications. Some labels have multiple UMLS diseases but only report the outcome of a single vote. Majority votes should be in terms of indications rather than labels, right?\r\n \r\nAnswer: You are right: each drug--disease (RxNORM--UMLS) pair should have it's own majority vote and majority votes should be in terms of indications rather than labels. The data is organized in this manner only (one entry = one drug-label/UMLSCUI pair). Each entry in the text file corresponds to one indication candidate (i.e. one disease UMLS-CUI) in a given drug label. The disease CUI is specified in the third field of the file. Also, as you have already noted that there for some entries with two CUIs in the third field. These correspond to composite mentions (e.g.\"Moderate to severe pain\"). Our [disease NER module](http://metamap.nlm.nih.gov/) detects two concepts for this phrase (\"moderate +pain\" and \"severe pain\") but we present this phrase as a single disease mention to the turkers and hence a single majority vote was computed for both UMLS-CUIs.\r\n\r\nWe are happy to answer more questions! - LabeledIn Team",
      "comment_id": 102,
      "profile_id": 72,
      "published": "2015-04-03T17:19:55.617887Z",
      "thread_id": 46,
      "url": "/discussion/processing-labeledin-to-extract-indications/46#2"
    },
    {
      "body_html": "<p>Thanks <a href=\"/u/ritukhare\" class=\"username\">@ritukhare</a>, we've <a href=\"//git.dhimmel.com/indications/labeledin/\">processed your datasets</a> and combined the expert <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.jbi.2014.08.004\" class=\"citation\" data-key=\"10.1016/j.jbi.2014.08.004\">1</a>]</span> and crowdsourced <span class=\"citation\">[<a href=\"https://doi.org/10.1093/database/bav016\" class=\"citation\" data-key=\"10.1093/database/bav016\">2</a>]</span> indications. The <a href=\"//git.dhimmel.com/indications/labeledin/data/indications.tsv\">resulting .tsv file is available for download</a>. We provide ingredient and disease names here <em>only for convenience</em>, since our simplistic lookup methodology left many identifiers unnamed. </p>\r\n\r\n<p>Specifically, we extracted 1,335 indications from the <a href=\"//ftp.ncbi.nlm.nih.gov/pub/lu/LabeledIn/LabeledIn_Structured_Results.txt\">expert data release</a> and 1,516 indications from the <a href=\"//ftp.ncbi.nlm.nih.gov/pub/lu/LabeledIn/Crowdsourcing/Crowdsourced_Results.txt\">crowdsourced data release</a>. The two sets shared one indication, so merging the two resources resulted in <code>2850 = 1335 + 1516 - 1</code> indications.</p>\r\n\r\n<p>We calculated the total number of labels reporting each indication. For this task, we assumed <code>study_drug_label_ID</code> was consistent across the expert and crowdsourced datasets. If this assumption is wrong, the effect would be minimal, since the two releases report almost entirely disjoint sets of indications.</p>",
      "body_md": "Thanks @ritukhare, we've [processed your datasets](//git.dhimmel.com/indications/labeledin/) and combined the expert [@10.1016/j.jbi.2014.08.004] and crowdsourced [@10.1093/database/bav016] indications. The [resulting .tsv file is available for download](//git.dhimmel.com/indications/labeledin/data/indications.tsv). We provide ingredient and disease names here *only for convenience*, since our simplistic lookup methodology left many identifiers unnamed. \r\n\r\nSpecifically, we extracted 1,335 indications from the [expert data release](//ftp.ncbi.nlm.nih.gov/pub/lu/LabeledIn/LabeledIn_Structured_Results.txt) and 1,516 indications from the [crowdsourced data release](//ftp.ncbi.nlm.nih.gov/pub/lu/LabeledIn/Crowdsourcing/Crowdsourced_Results.txt). The two sets shared one indication, so merging the two resources resulted in `2850 = 1335 + 1516 - 1` indications.\r\n\r\nWe calculated the total number of labels reporting each indication. For this task, we assumed `study_drug_label_ID` was consistent across the expert and crowdsourced datasets. If this assumption is wrong, the effect would be minimal, since the two releases report almost entirely disjoint sets of indications.",
      "comment_id": 103,
      "profile_id": 17,
      "published": "2015-04-03T17:59:14.506499Z",
      "thread_id": 46,
      "url": "/discussion/processing-labeledin-to-extract-indications/46#3"
    },
    {
      "body_html": "<p>Hey <a href=\"/u/b_good\" class=\"username\">@b_good</a>, thanks for the suggestion <span class=\"citation\">[<a href=\"https://doi.org/10.1136/amiajnl-2012-000852\" class=\"citation\" data-key=\"10.1136/amiajnl-2012-000852\">1</a>]</span> and tracking down the data supplement, which I cannot find on the <a href=\"http://dx.doi.org/10.1136/amiajnl-2012-000852\">article's JAMIA page</a>. Hereon, I will refer to this resource as <code>ehrlink</code>, unless anyone can find a previously-used or author-preferred nickname.</p>\r\n\r\n<p>This resource is noteworthy because it will capture off-label usages better than LabeledIn (which is explicitly on-label) and MEDI (whose inclusion criteria likely favor on-label indications)</p>\r\n\r\n<p>I <a href=\"http://nbviewer.ipython.org/github/dhimmel/indications/blob/gh-pages/ehrlink/convert-to-text.ipynb\">converted the pdf file into a tsv file</a>, which can be downloaded <a href=\"//git.dhimmel.com/indications/ehrlink/download/amiajnl-2012-000852-s1.tsv\">here</a>.</p>",
      "body_md": "Hey @b_good, thanks for the suggestion [@10.1136/amiajnl-2012-000852] and tracking down the data supplement, which I cannot find on the [article's JAMIA page](http://dx.doi.org/10.1136/amiajnl-2012-000852). Hereon, I will refer to this resource as `ehrlink`, unless anyone can find a previously-used or author-preferred nickname.\r\n\r\nThis resource is noteworthy because it will capture off-label usages better than LabeledIn (which is explicitly on-label) and MEDI (whose inclusion criteria likely favor on-label indications)\r\n\r\nI [converted the pdf file into a tsv file](http://nbviewer.ipython.org/github/dhimmel/indications/blob/gh-pages/ehrlink/convert-to-text.ipynb), which can be downloaded [here](//git.dhimmel.com/indications/ehrlink/download/amiajnl-2012-000852-s1.tsv).",
      "comment_id": 104,
      "profile_id": 17,
      "published": "2015-04-03T20:10:47.043719Z",
      "thread_id": 21,
      "url": "/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#4"
    },
    {
      "body_html": "<h1>Evaluation with known indications</h1>\r\n\r\n<p><a href=\"/u/b_good\" class=\"username\">@b_good</a>, the primary means of evaluation will be assessing performance on a masked subset of indications. Previously <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1004259\">1</a>]</span>, we withheld 25% of observations for testing. During training (on the remaining 75% of observations), we can use cross-validation to identify optimal parameter values. We plan to measure performance using area under the ROC curve (AUROC). We will also consider using condensed-ROC curves <span class=\"citation\">[<a href=\"https://doi.org/10.1093/bioinformatics/btq140\" class=\"citation\" data-key=\"10.1093/bioinformatics/btq140\">2</a>]</span>, which emphasize top predictions.</p>\r\n\r\n<p>The <a href=\"http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d21\">discussion you noted</a> discusses how to construct a catalog of high-confidence indications, also known as a <em>gold standard</em>. What we haven't discussed thus far is how to create a negative set, which is a necessary input for our classification approaches. The simplest way to generate negatives is to treat all non-positives as negatives: if a compound is not indicated for a disease, the compound-disease pair is considered a negative. Since our positive set is incomplete, some true but unknown indications will be considered negatives. Given that the overwhelming majority of negatives will truly be negatives, I expect the impact of improper negatives to be minimal. However, our past experiences show many people find this response unsatisfactory and would prefer us to exclude potential positives from the negative set. We will probably do that for this project, for example by omitting compound-disease pairs that are in the low-precision subset of MEDI <span class=\"citation\">[<a href=\"https://doi.org/10.1136/amiajnl-2014-002954\" class=\"citation\" data-key=\"10.1136/amiajnl-2014-002954\">3</a>]</span>.</p>\r\n\r\n<p>In our previous project <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1004259\">1</a>]</span>, we found that our classification approach was resistant to overfitting. In other words, our training and testing AUROCs were comparable. We should still continue a formal testing paradigm as good practice, but there is a larger issue that I will discuss in my next post.</p>",
      "body_md": "# Evaluation with known indications\r\n\r\n@b_good, the primary means of evaluation will be assessing performance on a masked subset of indications. Previously [@10.1371/journal.pcbi.1004259], we withheld 25% of observations for testing. During training (on the remaining 75% of observations), we can use cross-validation to identify optimal parameter values. We plan to measure performance using area under the ROC curve (AUROC). We will also consider using condensed-ROC curves [@10.1093/bioinformatics/btq140], which emphasize top predictions.\r\n\r\nThe [discussion you noted](http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21) discusses how to construct a catalog of high-confidence indications, also known as a *gold standard*. What we haven't discussed thus far is how to create a negative set, which is a necessary input for our classification approaches. The simplest way to generate negatives is to treat all non-positives as negatives: if a compound is not indicated for a disease, the compound-disease pair is considered a negative. Since our positive set is incomplete, some true but unknown indications will be considered negatives. Given that the overwhelming majority of negatives will truly be negatives, I expect the impact of improper negatives to be minimal. However, our past experiences show many people find this response unsatisfactory and would prefer us to exclude potential positives from the negative set. We will probably do that for this project, for example by omitting compound-disease pairs that are in the low-precision subset of MEDI [@10.1136/amiajnl-2014-002954].\r\n\r\nIn our previous project [@10.1371/journal.pcbi.1004259], we found that our classification approach was resistant to overfitting. In other words, our training and testing AUROCs were comparable. We should still continue a formal testing paradigm as good practice, but there is a larger issue that I will discuss in my next post.",
      "comment_id": 109,
      "profile_id": 17,
      "published": "2015-04-07T17:58:47.060686Z",
      "thread_id": 47,
      "url": "/discussion/evaluation-framework/47#2"
    },
    {
      "body_html": "<p>You can access SemRep extracted semantic relations (e.g. treats, causes) based on all PubMed abstracts (updated bi-annually) via the semantic medline database.  With a UMLS login, you can get the complete MySQL dump via <a href=\"http://skr3.nlm.nih.gov/SemMedDB/\" target=\"_blank\">http://skr3.nlm.nih.gov/SemMedDB/</a> .  Main challenge here is in ensuring quality (as with any NLP output).</p>",
      "body_md": "You can access SemRep extracted semantic relations (e.g. treats, causes) based on all PubMed abstracts (updated bi-annually) via the semantic medline database.  With a UMLS login, you can get the complete MySQL dump via http://skr3.nlm.nih.gov/SemMedDB/ .  Main challenge here is in ensuring quality (as with any NLP output).",
      "comment_id": 110,
      "profile_id": 48,
      "published": "2015-04-07T19:33:29.194446Z",
      "thread_id": 21,
      "url": "/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#5"
    },
    {
      "body_html": "<h1>ehrlink problem and medication vocabularies</h1>\r\n\r\n<p>We have extracted the ehrlink <span class=\"citation\">[<a href=\"https://doi.org/10.1136/amiajnl-2012-000852\" class=\"citation\" data-key=\"10.1136/amiajnl-2012-000852\">1</a>]</span> indication data (<a href=\"#104\">see above</a>). Unfortunately, I am unfamiliar with the identifiers used for problems (diseases) and medications (drugs). I've posted a sampling below in case anyone can figure out.</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>problem_definition_id</th><th>problem</th></tr></thead><tbody><tr><td>63645</td><td>Complete D-transposition Of The Great Vessels</td></tr><tr><td>258894</td><td>Acromegaly</td></tr><tr><td>275590</td><td>Organic REM Sleep Behavior Disorder</td></tr><tr><td>62983</td><td>Arteriosclerotic Cardiovascular Disease (ASCVD)</td></tr><tr><td>75090</td><td>Cerebral Palsy</td></tr></tbody></table>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>medication_definition_id</th><th>medication</th></tr></thead><tbody><tr><td>17938</td><td>Sodium Polystyrene Sulfonate Oral Powder</td></tr><tr><td>21707</td><td>Clotrimazole Anti-Fungal 1 % External Cream</td></tr><tr><td>18805</td><td>Niacin CR 1000 MG Oral Tablet Extended Release</td></tr><tr><td>19598</td><td>ClonazePAM 0.5 MG Oral Tablet</td></tr><tr><td>136143</td><td>AmLODIPine Besylate 2.5 MG Oral Tablet</td></tr></tbody></table>\r\n\r\n<p>My worry is that these identifiers may not correspond to a standardized vocabulary that we can access and easily map to. I will contact the authors for clarification.</p>",
      "body_md": "# ehrlink problem and medication vocabularies\r\n\r\nWe have extracted the ehrlink [@10.1136/amiajnl-2012-000852] indication data ([see above](#104)). Unfortunately, I am unfamiliar with the identifiers used for problems (diseases) and medications (drugs). I've posted a sampling below in case anyone can figure out.\r\n\r\n| problem_definition_id | problem                                         |\r\n|-----------------------|-------------------------------------------------|\r\n| 63645                 | Complete D-transposition Of The Great Vessels   |\r\n| 258894                | Acromegaly                                      |\r\n| 275590                | Organic REM Sleep Behavior Disorder             |\r\n| 62983                 | Arteriosclerotic Cardiovascular Disease (ASCVD) |\r\n| 75090                 | Cerebral Palsy                                  |\r\n\r\n| medication_definition_id | medication                                     |\r\n|--------------------------|------------------------------------------------|\r\n| 17938                    | Sodium Polystyrene Sulfonate Oral Powder       |\r\n| 21707                    | Clotrimazole Anti-Fungal 1 % External Cream    |\r\n| 18805                    | Niacin CR 1000 MG Oral Tablet Extended Release |\r\n| 19598                    | ClonazePAM 0.5 MG Oral Tablet                  |\r\n| 136143                   | AmLODIPine Besylate 2.5 MG Oral Tablet         |\r\n\r\nMy worry is that these identifiers may not correspond to a standardized vocabulary that we can access and easily map to. I will contact the authors for clarification.",
      "comment_id": 111,
      "profile_id": 17,
      "published": "2015-04-08T01:53:46.278727Z",
      "thread_id": 21,
      "url": "/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#6"
    },
    {
      "body_html": "<p>This is great. Thanks <a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a>. There should be no confusion with the study_drug_label_ID between the two datasets: In expert-LabeledIn, the values are numbers and in crowd-LabeledIn, the values are concatenation of drug type and a number.</p>\r\n\r\n<p>I don't have a readily available mapping of ingredient and disease identifiers to names. Please note that the it would be more appropriate to use the title of drug label (SPL) instead of ingredient name as the title will also contain the dose form information of the drug (and we found that indications may be different between two drugs having same ingredient but different dose form). However, it's your decision.</p>",
      "body_md": "This is great. Thanks @dhimmel. There should be no confusion with the study_drug_label_ID between the two datasets: In expert-LabeledIn, the values are numbers and in crowd-LabeledIn, the values are concatenation of drug type and a number.\r\n\r\nI don't have a readily available mapping of ingredient and disease identifiers to names. Please note that the it would be more appropriate to use the title of drug label (SPL) instead of ingredient name as the title will also contain the dose form information of the drug (and we found that indications may be different between two drugs having same ingredient but different dose form). However, it's your decision.",
      "comment_id": 112,
      "profile_id": 72,
      "published": "2015-04-06T18:57:35.693780Z",
      "thread_id": 46,
      "url": "/discussion/processing-labeledin-to-extract-indications/46#4"
    },
    {
      "body_html": "<h1>Evaluation with novel indications</h1>\r\n\r\n<p>Experienced chemoinformaticians stress that impressive testing performance on known positives does not always translate to predicting <em>novel</em> positives. The causes are several fold:</p>\r\n\r\n<ul><li>the patterns behind established positives are not generative — those patterns do not translate to unknown positives.</li><li>predictions are made for instances that are not well-represented in the training set. Understanding the applicability domain of your model is crucial here.</li><li>the current set of positives is synchronous with the current state of knowledge. If the method does not incorporate untapped knowledge, novel predictions may not be possible.</li></ul>\r\n\r\n<p>These issues are one reason why the community places such emphasis on novel discovery when appraising new methods. Absent experimental verification of our top predicted indications, there are a few approaches we could consider that begin to assess our ability to predict the \"unkown\". Several potential approaches were explored by a past repurposing study <span class=\"citation\">[<a href=\"https://doi.org/10.1038/msb.2011.26\" class=\"citation\" data-key=\"10.1038/msb.2011.26\">1</a>]</span>:</p>\r\n\r\n<ul><li>Predicting indications currently undergoing clinical trials</li><li>Predicting potential indications that were not in our gold standard. For example, those indications in the MEDI low-precision subset or those identified using literature mining. </li></ul>\r\n\r\n<p>These approaches are both imperfect, but they are a start. Ideally, we could experimentally evaluate several predictions. This work could potentially be <a href=\"https://www.scienceexchange.com/\">outsourced</a> and thus parallelized. </p>",
      "body_md": "# Evaluation with novel indications\r\n\r\nExperienced chemoinformaticians stress that impressive testing performance on known positives does not always translate to predicting *novel* positives. The causes are several fold:\r\n\r\n+ the patterns behind established positives are not generative -- those patterns do not translate to unknown positives.\r\n+ predictions are made for instances that are not well-represented in the training set. Understanding the applicability domain of your model is crucial here.\r\n+ the current set of positives is synchronous with the current state of knowledge. If the method does not incorporate untapped knowledge, novel predictions may not be possible.\r\n\r\nThese issues are one reason why the community places such emphasis on novel discovery when appraising new methods. Absent experimental verification of our top predicted indications, there are a few approaches we could consider that begin to assess our ability to predict the \"unkown\". Several potential approaches were explored by a past repurposing study [@10.1038/msb.2011.26]:\r\n\r\n+ Predicting indications currently undergoing clinical trials\r\n+ Predicting potential indications that were not in our gold standard. For example, those indications in the MEDI low-precision subset or those identified using literature mining. \r\n\r\nThese approaches are both imperfect, but they are a start. Ideally, we could experimentally evaluate several predictions. This work could potentially be [outsourced](https://www.scienceexchange.com/) and thus parallelized. ",
      "comment_id": 113,
      "profile_id": 17,
      "published": "2015-04-08T05:15:41.083774Z",
      "thread_id": 47,
      "url": "/discussion/evaluation-framework/47#3"
    },
    {
      "body_html": "<blockquote><p>we found that indications may different between two drugs having same ingredient but different dose form</p></blockquote>\r\n\r\n<p><a href=\"/u/ritukhare\" class=\"username\">@ritukhare</a>, interesting to hear that examples of repurposing frequently relied on different dose forms (and perhaps dosage levels as well). I think we would like to ignore this complexity. In other words, our predicted indications will not include dosage or dose form recommendations. I am comfortable leaving these details for the end users to investigate.</p>",
      "body_md": "> we found that indications may different between two drugs having same ingredient but different dose form\r\n\r\n@ritukhare, interesting to hear that examples of repurposing frequently relied on different dose forms (and perhaps dosage levels as well). I think we would like to ignore this complexity. In other words, our predicted indications will not include dosage or dose form recommendations. I am comfortable leaving these details for the end users to investigate.",
      "comment_id": 114,
      "profile_id": 17,
      "published": "2015-04-08T05:23:57.025486Z",
      "thread_id": 46,
      "url": "/discussion/processing-labeledin-to-extract-indications/46#5"
    },
    {
      "body_html": "<p>Just to let you guys know that, at UNM, Oleg Ursu and I have been constructing such a catalog for nearly eight years. <br>Unfortunately, nobody funds this type of activity - or at least nobody has funded it so far - thus resources are somewhat limited.<br>Briefly, we manually curated all the active pharmaceutical ingredients APIs (over 4400; includes biologics), and mapped them to FDA approved drug labels (over 50000 ADLs). <br>From the ADLs one can extract/map indications, contra-indications, off-label indications... and to each API we mapped RxNorm [CUI], NPC, ATC, INN, plus targets, including numeric bioactivity &amp; type [MoA related; non-MoA assigned; as well as non-human targets]. We also mapped all our diseases to DOIDs - however, there are about 800 or so left that will take us a while to map.<br>A few pointers: <br>1) if you want to extract the data yourselves, you're in for a treat. There are diseases in \"indications\" that do NOT exist anywhere else [e.g., cancer XYZ with mutation A3999B, in other words it's not enough to have the disease, you need the right genotype!]; <br>2) you also have to deal with indications that are \"fringe\" (pregnancy is not a disease; neither is contraception)<br>3) indications etc. are not from PubMed - so please pay attention to approved labels<br>4) disease modifying is far from trivial - you need epi to show you that, X years after the Dx/Rx event, there was no recurrence [are steroids in anti-allergy disease modifying? probably not; are antibiotics in sinusitis disease-modifying? yes and no link_ref,[object Object],if it's chronic!</p>",
      "body_md": "Just to let you guys know that, at UNM, Oleg Ursu and I have been constructing such a catalog for nearly eight years. \r\nUnfortunately, nobody funds this type of activity - or at least nobody has funded it so far - thus resources are somewhat limited.\r\nBriefly, we manually curated all the active pharmaceutical ingredients APIs (over 4400; includes biologics), and mapped them to FDA approved drug labels (over 50000 ADLs). \r\nFrom the ADLs one can extract/map indications, contra-indications, off-label indications... and to each API we mapped RxNorm [CUI], NPC, ATC, INN, plus targets, including numeric bioactivity & type [MoA related; non-MoA assigned; as well as non-human targets]. We also mapped all our diseases to DOIDs - however, there are about 800 or so left that will take us a while to map.\r\nA few pointers: \r\n1) if you want to extract the data yourselves, you're in for a treat. There are diseases in \"indications\" that do NOT exist anywhere else [e.g., cancer XYZ with mutation A3999B, in other words it's not enough to have the disease, you need the right genotype!]; \r\n2) you also have to deal with indications that are \"fringe\" (pregnancy is not a disease; neither is contraception)\r\n3) indications etc. are not from PubMed - so please pay attention to approved labels\r\n4) disease modifying is far from trivial - you need epi to show you that, X years after the Dx/Rx event, there was no recurrence [are steroids in anti-allergy disease modifying? probably not; are antibiotics in sinusitis disease-modifying? yes and no [if it's chronic!]\r\n",
      "comment_id": 115,
      "profile_id": 75,
      "published": "2015-04-08T14:53:34.682008Z",
      "thread_id": 21,
      "url": "/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#7"
    },
    {
      "body_html": "<p>My colleagues and I have worked on multiple approaches to create this knowledge in the papers below:</p>\r\n\r\n<ol><li>Wright A, Chen ES, Maloney FL. An automated technique for identifying associations between medications, laboratory results and problems. J Biomed Inform. 2010 Dec;43(6):891–901. <a href=\"http://www.ncbi.nlm.nih.gov/pubmed/20884377\" target=\"_blank\">http://www.ncbi.nlm.nih.gov/pubmed/20884377</a></li><li>McCoy AB, Wright A, Laxmisan A, Singh H, Sittig DF. A prototype knowledge base and SMART app to facilitate organization of patient medications by clinical problems. AMIA Annu Symp Proc. 2011;2011:888–94. <a href=\"http://www.ncbi.nlm.nih.gov/pubmed/22195147\" target=\"_blank\">http://www.ncbi.nlm.nih.gov/pubmed/22195147</a></li><li>McCoy AB, Wright A, Laxmisan A, Ottosen MJ, McCoy JA, Butten D, et al. Development and evaluation of a crowdsourcing methodology for knowledge base construction: identifying relationships between clinical problems and medications. J Am Med Inform Assoc. 2012 Oct;19(5):713–8. <a href=\"http://www.ncbi.nlm.nih.gov/pubmed/22582202\" target=\"_blank\">http://www.ncbi.nlm.nih.gov/pubmed/22582202</a></li><li>McCoy AB, Wright A, Rogith D, Fathiamini S, Ottenbacher AJ, Sittig DF. Development of a clinician reputation metric to identify appropriate problem-medication pairs in a crowdsourced knowledge base. J Biomed Inform. 2014 Apr;48:66–72. <a href=\"http://www.ncbi.nlm.nih.gov/pubmed/24321170\" target=\"_blank\">http://www.ncbi.nlm.nih.gov/pubmed/24321170</a></li></ol>\r\n\r\n<p>In the JAMIA paper mentioned above, we used what we called a crowdsourcing approach to get this data. We have recently validated that approach at another site, and that publication is coming out in ACI soon. Unfortunately, in the original version, as you suspected, our medications and problems not mapped to any standardized terminology. The identifiers are local to the EHR, and while we have made some attempts to map them to RxNorm and SNOMED-CT, we were never able to get a really accurate set. However, the validation uses data from a different EHR, which I believe can be more easily mapped. Once the paper is out, I'll see if I can share that data.</p>",
      "body_md": "My colleagues and I have worked on multiple approaches to create this knowledge in the papers below:\r\n\r\n1. Wright A, Chen ES, Maloney FL. An automated technique for identifying associations between medications, laboratory results and problems. J Biomed Inform. 2010 Dec;43(6):891–901. http://www.ncbi.nlm.nih.gov/pubmed/20884377\r\n2. McCoy AB, Wright A, Laxmisan A, Singh H, Sittig DF. A prototype knowledge base and SMART app to facilitate organization of patient medications by clinical problems. AMIA Annu Symp Proc. 2011;2011:888–94. http://www.ncbi.nlm.nih.gov/pubmed/22195147\r\n3. McCoy AB, Wright A, Laxmisan A, Ottosen MJ, McCoy JA, Butten D, et al. Development and evaluation of a crowdsourcing methodology for knowledge base construction: identifying relationships between clinical problems and medications. J Am Med Inform Assoc. 2012 Oct;19(5):713–8. http://www.ncbi.nlm.nih.gov/pubmed/22582202\r\n4. McCoy AB, Wright A, Rogith D, Fathiamini S, Ottenbacher AJ, Sittig DF. Development of a clinician reputation metric to identify appropriate problem-medication pairs in a crowdsourced knowledge base. J Biomed Inform. 2014 Apr;48:66–72. http://www.ncbi.nlm.nih.gov/pubmed/24321170\r\n\r\nIn the JAMIA paper mentioned above, we used what we called a crowdsourcing approach to get this data. We have recently validated that approach at another site, and that publication is coming out in ACI soon. Unfortunately, in the original version, as you suspected, our medications and problems not mapped to any standardized terminology. The identifiers are local to the EHR, and while we have made some attempts to map them to RxNorm and SNOMED-CT, we were never able to get a really accurate set. However, the validation uses data from a different EHR, which I believe can be more easily mapped. Once the paper is out, I'll see if I can share that data.",
      "comment_id": 116,
      "profile_id": 77,
      "published": "2015-04-08T17:40:12.289974Z",
      "thread_id": 21,
      "url": "/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#8"
    },
    {
      "body_html": "<p>I find crowdsourcing useful when you use a team of experts. So, for example, a carefully selected team of experts, when working on the same problem, can give surprisingly interesting feedback on an otherwise difficult problem.<br><a href=\"http://www.nature.com/nchembio/journal/v5/n7/abs/nchembio0709-441.html\" target=\"_blank\">http://www.nature.com/nchembio/journal/v5/n7/abs/nchembio0709-441.html</a>Please note that this paper is not about data entry, but about polling experts for their opinion.</p>\r\n\r\n<p>I professionally supervised data entry for chemical structures, chemical bioactivities, as well as controlled vocabulary descriptions for assays, indexing medicinal chemistry literature. The average <em>trained</em> person loading data had an error rate of 5-10% - errors varied with period (e.g., the closer to the deadline, usually Christmas, the worse the quality). We used a 3-layer quality control system. And even so, we had a 1-2% error in our database, as revealed by comparison with two other systems. <br>See this paper <a href=\"http://pubs.acs.org/doi/abs/10.1021/ci400099q\" target=\"_blank\">http://pubs.acs.org/doi/abs/10.1021/ci400099q</a> for details (mine is the WOMBAT database).</p>\r\n\r\n<p>With this in mid, I want to point out that crowdsourcing problem medication pairs by clinicians is an intriguing effort, and if the data is publicly available I would like to learn more. There are risks because a) verification of data entry was probably not done at the entry level (was the clinician familiar with both the drug and the disease?); b) the person determining the problem would require training in pharmacovigilance, understanding of known side-effects, etc. I assume you have done that, and that you compared the sets? I apologize that I do not have time to access your papers right now. </p>",
      "body_md": "I find crowdsourcing useful when you use a team of experts. So, for example, a carefully selected team of experts, when working on the same problem, can give surprisingly interesting feedback on an otherwise difficult problem.\r\nhttp://www.nature.com/nchembio/journal/v5/n7/abs/nchembio0709-441.html\r\nPlease note that this paper is not about data entry, but about polling experts for their opinion.\r\n\r\nI professionally supervised data entry for chemical structures, chemical bioactivities, as well as controlled vocabulary descriptions for assays, indexing medicinal chemistry literature. The average *trained* person loading data had an error rate of 5-10% - errors varied with period (e.g., the closer to the deadline, usually Christmas, the worse the quality). We used a 3-layer quality control system. And even so, we had a 1-2% error in our database, as revealed by comparison with two other systems. \r\nSee this paper http://pubs.acs.org/doi/abs/10.1021/ci400099q for details (mine is the WOMBAT database).\r\n\r\nWith this in mid, I want to point out that crowdsourcing problem medication pairs by clinicians is an intriguing effort, and if the data is publicly available I would like to learn more. There are risks because a) verification of data entry was probably not done at the entry level (was the clinician familiar with both the drug and the disease?); b) the person determining the problem would require training in pharmacovigilance, understanding of known side-effects, etc. I assume you have done that, and that you compared the sets? I apologize that I do not have time to access your papers right now. ",
      "comment_id": 117,
      "profile_id": 75,
      "published": "2015-04-08T18:05:35.112012Z",
      "thread_id": 21,
      "url": "/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#9"
    },
    {
      "body_html": "<p>To clarify the crowdsourcing approach, in our study the clinicians are completing the task because it is required during routine care, not solely for the purpose of creating a knowledge base. They are entering the data into the EHR because they are prescribing a medication to a patient and are often required to link it to one or more of the patient's problems for billing purposes. We did not ask them to do any additional work outside of their own routine clinical practice.</p>",
      "body_md": "To clarify the crowdsourcing approach, in our study the clinicians are completing the task because it is required during routine care, not solely for the purpose of creating a knowledge base. They are entering the data into the EHR because they are prescribing a medication to a patient and are often required to link it to one or more of the patient's problems for billing purposes. We did not ask them to do any additional work outside of their own routine clinical practice.",
      "comment_id": 118,
      "profile_id": 77,
      "published": "2015-04-08T18:16:23.522075Z",
      "thread_id": 21,
      "url": "/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#10"
    },
    {
      "body_html": "<p>thank you - was wondering about that. this does make their work more reliable.</p>",
      "body_md": "thank you - was wondering about that. this does make their work more reliable.",
      "comment_id": 119,
      "profile_id": 75,
      "published": "2015-04-08T19:29:35.198699Z",
      "thread_id": 21,
      "url": "/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#11"
    },
    {
      "body_html": "<blockquote><p>there must be quite a lot of value out there in the space of biased knowledge</p></blockquote>\r\n\r\n<p>You are correct. In our current proposal, we do use text mining for the symptom-disease edges and tissue-disease edges. We also rely on literature curation for compound-target binding and protein interactions.</p>\r\n\r\n<blockquote><p>Would be great to execute an experiment to empirically test the impact of bringing in prior knowledge</p></blockquote>\r\n\r\n<p>I agree, we should fit a model that excludes all knowledge-biased domains. I reckon this model's performance on known indications will be drastically inferior. The worry with predicting known indications with known biology is that your testing performance becomes nearly perfect. However, your novel predictions are not interesting — they would be readily apparent to a pharmacologist.</p>\r\n\r\n<p>The more text mining data you include the larger your gap between testing performance and generative performance (see our <a href=\"http://thinklab.com/discussion/evaluation-framework/47#113\">discussion on evaluation</a>). Therefore, I like the following workflow:</p>\r\n\r\n<ol><li>Start with high-throughput resources that are not affected by knowledge bias (a.k.a. study bias)</li><li>If the algorithm performs significantly better than random, explore the top predictions.</li><li>If performance is mediocre, add a biased resource that provides orthogonal information (information not already included from a systematic resource)</li><li>Repeat.</li></ol>\r\n\r\n<p>One final note to help explain the insidiousness of the knowledge bias. In <a href=\"http://ctdbase.org/\">CTD</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gku935\" class=\"citation\" data-key=\"10.1093/nar/gku935\">1</a>]</span>, curators may read that <code>compound_X</code> treats <code>disease_X</code> and also targets <code>gene_X</code> and therefore add interactions between all three entities to their knowledgebase. In reality the study hasn't proven that <code>gene_X</code> is associated with <code>disease_X</code> but this relationship was still extracted. This happens on a macro-scale across the entire compendium of published literature: specific network vicinities become well studied and the resulting disease-gene-compound triangles are more a result of attention rather than noteworthy biology.</p>",
      "body_md": "> there must be quite a lot of value out there in the space of biased knowledge\r\n\r\nYou are correct. In our current proposal, we do use text mining for the symptom-disease edges and tissue-disease edges. We also rely on literature curation for compound-target binding and protein interactions.\r\n\r\n> Would be great to execute an experiment to empirically test the impact of bringing in prior knowledge\r\n\r\nI agree, we should fit a model that excludes all knowledge-biased domains. I reckon this model's performance on known indications will be drastically inferior. The worry with predicting known indications with known biology is that your testing performance becomes nearly perfect. However, your novel predictions are not interesting -- they would be readily apparent to a pharmacologist.\r\n\r\nThe more text mining data you include the larger your gap between testing performance and generative performance (see our [discussion on evaluation](http://thinklab.com/discussion/evaluation-framework/47#113)). Therefore, I like the following workflow:\r\n\r\n1. Start with high-throughput resources that are not affected by knowledge bias (a.k.a. study bias)\r\n2. If the algorithm performs significantly better than random, explore the top predictions.\r\n3. If performance is mediocre, add a biased resource that provides orthogonal information (information not already included from a systematic resource)\r\n4. Repeat.\r\n\r\nOne final note to help explain the insidiousness of the knowledge bias. In [CTD](http://ctdbase.org/) [@10.1093/nar/gku935], curators may read that `compound_X` treats `disease_X` and also targets `gene_X` and therefore add interactions between all three entities to their knowledgebase. In reality the study hasn't proven that `gene_X` is associated with `disease_X` but this relationship was still extracted. This happens on a macro-scale across the entire compendium of published literature: specific network vicinities become well studied and the resulting disease-gene-compound triangles are more a result of attention rather than noteworthy biology.",
      "comment_id": 120,
      "profile_id": 17,
      "published": "2015-04-08T22:22:49.866720Z",
      "thread_id": 48,
      "url": "/discussion/text-as-a-resource-for-network-population/48#2"
    },
    {
      "body_html": "<h1>Seeking a Slim DO with distinct terms.</h1>\r\n\r\n<p>The Disease Ontology is a hierarchy of human diseases. However, our current method has been designed for <em>distinct</em> nodes (especially with respect to diseases and compounds, since we will be predicting indications). By distinct we mean non-redundant — in a non-redundant set of terms, no terms should be an ancestor or descendant of any other term. </p>\r\n\r\n<p>Additionally, we would like to pick terms at an appropriate level of specificity. Below, I show lineages of DO terms and bold the term whose specificity I prefer:</p>\r\n\r\n<ul><li>cancer &gt; organ system cancer &gt; respiratory system cancer &gt; <strong>lung cancer</strong> &gt; Pancoast tumor &gt; lung superior sulcus carcinoma</li><li>neurodegenerative disease &gt; demyelinating disease &gt; <strong>multiple sclerosis</strong> &gt; relapsing-remitting multiple sclerosis</li><li>glucose metabolism disease &gt; diabetes mellitus &gt; <strong>type 2 diabetes mellitus</strong> &gt; diabetic peripheral angiopathy</li></ul>\r\n\r\n<p>Ideally, we chose a level of specificity such that:</p>\r\n\r\n<ul><li>a term and its descendants form a cohesive and differentiated disease concept</li><li>disease data is collected at a similar level of specificity</li><li>sufficient data exists for the term, after propagating data annotated to more specific terms</li></ul>\r\n\r\n<p>These are competing aims and we will most likely have to make difficult subjective decisions. In the past <span class=\"citation\">[<a href=\"https://doi.org/10.1101/011569\" class=\"citation\" data-key=\"10.1101/011569\">1</a>]</span>, we identified <a href=\"http://het.io/disease-genes/downloads/files/diseases.txt\">108 distinct, complex diseases</a> by investigating only diseases with GWAS. However, GWAS may be too restrictive of a filter for the present study. We are more concerned with omitting diseases that would be poorly connected in the network. Some diseases may be well connected but lacking GWAS. We also would prefer to focus on diseases with indications as indications are needed to train our model.</p>\r\n\r\n<p>Two previous DO studies may be helpful here:</p>\r\n\r\n<ol><li><strong>DOLite</strong> took a data-driven approach to selecting a consolidated set of DO terms <span class=\"citation\">[<a href=\"https://doi.org/10.1093/bioinformatics/btp193\" class=\"citation\" data-key=\"10.1093/bioinformatics/btp193\">2</a>]</span>. I have not been able to locate the list of DO identifiers composing DOLite. These terms may also be obsolete as the project is dated. <em><strong>Any information regarding DOLite would be appreciated.</strong></em></li><li><strong>DO_cancer_slim</strong> created a DO subset named <code>TOPNodes_DOcancerslim</code> composed of 63 non-redundant upper-level cancer terms <span class=\"citation\">[<a href=\"https://doi.org/10.1093/database/bav032\" class=\"citation\" data-key=\"10.1093/database/bav032\">3</a>]</span>. <em><strong>We would like a similar term list but encompassing all diseases, not just cancers.</strong></em></li></ol>",
      "body_md": "# Seeking a Slim DO with distinct terms.\r\n\r\nThe Disease Ontology is a hierarchy of human diseases. However, our current method has been designed for *distinct* nodes (especially with respect to diseases and compounds, since we will be predicting indications). By distinct we mean non-redundant -- in a non-redundant set of terms, no terms should be an ancestor or descendant of any other term. \r\n\r\nAdditionally, we would like to pick terms at an appropriate level of specificity. Below, I show lineages of DO terms and bold the term whose specificity I prefer:\r\n\r\n+ cancer > organ system cancer > respiratory system cancer > **lung cancer** > Pancoast tumor > lung superior sulcus carcinoma\r\n+ neurodegenerative disease > demyelinating disease > **multiple sclerosis** > relapsing-remitting multiple sclerosis\r\n+ glucose metabolism disease > diabetes mellitus > **type 2 diabetes mellitus** > diabetic peripheral angiopathy\r\n\r\nIdeally, we chose a level of specificity such that:\r\n\r\n+ a term and its descendants form a cohesive and differentiated disease concept\r\n+ disease data is collected at a similar level of specificity\r\n+ sufficient data exists for the term, after propagating data annotated to more specific terms\r\n\r\nThese are competing aims and we will most likely have to make difficult subjective decisions. In the past [@10.1101/011569], we identified [108 distinct, complex diseases](http://het.io/disease-genes/downloads/files/diseases.txt) by investigating only diseases with GWAS. However, GWAS may be too restrictive of a filter for the present study. We are more concerned with omitting diseases that would be poorly connected in the network. Some diseases may be well connected but lacking GWAS. We also would prefer to focus on diseases with indications as indications are needed to train our model.\r\n\r\nTwo previous DO studies may be helpful here:\r\n\r\n1. **DOLite** took a data-driven approach to selecting a consolidated set of DO terms [@10.1093/bioinformatics/btp193]. I have not been able to locate the list of DO identifiers composing DOLite. These terms may also be obsolete as the project is dated. _**Any information regarding DOLite would be appreciated.**_\r\n+ **DO_cancer_slim** created a DO subset named `TOPNodes_DOcancerslim` composed of 63 non-redundant upper-level cancer terms [@10.1093/database/bav032]. _**We would like a similar term list but encompassing all diseases, not just cancers.**_",
      "comment_id": 121,
      "profile_id": 17,
      "published": "2015-04-09T00:05:43.325198Z",
      "thread_id": 44,
      "url": "/discussion/unifying-disease-vocabularies/44#3"
    },
    {
      "body_html": "<p>While <a href=\"http://nbviewer.ipython.org/url/git.dhimmel.com/drugbank/unichem-map.ipynb\">mapping</a> DrugBank compounds to LINCS, we have noticed that UniChem's mapping is potentially outdated. UniChem maps to LINCS compound identifiers that begin with <code>LSM-</code> while the current LINCS small molecule identifiers (called <code>pert_id</code>) begin with <code>BRD-</code>.</p>\r\n\r\n<p>UniChem searches that match to LINCS, hyperlink to the <a href=\"http://life.ccs.miami.edu/life/\">LIFE resource</a>, which is not up to date with the released LINCS data (<a href=\"https://www.ebi.ac.uk/unichem/frontpage/results?queryText=ULSMZGGENQYXHL-UHFFFAOYSA-N&amp;kind=InChIKey&amp;sources=&amp;incl=exclude\">example search</a> and <a href=\"http://life.ccs.miami.edu/life/summary?mode=SmallMolecule&amp;source=LINCS&amp;input=LSM-3295\">example link</a>).</p>\r\n\r\n<p>LIFE contains ~9000 small molecules versus &gt;20000 at LINCS and also does not consistently supply the main pert_id used by LINCS. The <code>LINCS ID</code> used by LIFE doesn't appear in the compound information that is currently obtainable from the LINCS API, so it may be an obsolete ID system replaced by pert_id.</p>\r\n\r\n<p>We will contact UniChem to alert them and will solicit feedback from the LINCS team regarding the ID confusion.</p>",
      "body_md": "While [mapping](http://nbviewer.ipython.org/url/git.dhimmel.com/drugbank/unichem-map.ipynb) DrugBank compounds to LINCS, we have noticed that UniChem's mapping is potentially outdated. UniChem maps to LINCS compound identifiers that begin with `LSM-` while the current LINCS small molecule identifiers (called `pert_id`) begin with `BRD-`.\r\n\r\nUniChem searches that match to LINCS, hyperlink to the [LIFE resource](http://life.ccs.miami.edu/life/), which is not up to date with the released LINCS data ([example search](https://www.ebi.ac.uk/unichem/frontpage/results?queryText=ULSMZGGENQYXHL-UHFFFAOYSA-N&kind=InChIKey&sources=&incl=exclude) and [example link](http://life.ccs.miami.edu/life/summary?mode=SmallMolecule&source=LINCS&input=LSM-3295)).\r\n\r\nLIFE contains ~9000 small molecules versus >20000 at LINCS and also does not consistently supply the main pert_id used by LINCS. The `LINCS ID` used by LIFE doesn't appear in the compound information that is currently obtainable from the LINCS API, so it may be an obsolete ID system replaced by pert_id.\r\n\r\nWe will contact UniChem to alert them and will solicit feedback from the LINCS team regarding the ID confusion.",
      "comment_id": 122,
      "profile_id": 21,
      "published": "2015-04-09T00:53:23.882384Z",
      "thread_id": 51,
      "url": "/discussion/unichem-mapping-to-lincs-small-molecules/51"
    },
    {
      "body_html": "<p>Perhaps this explains why 39% of DrugBank approved small molecules <a href=\"http://git.dhimmel.com/drugbank/unichem-map.html\">did not map</a> to a single LINCS compound: the LINCS resource was half it's current size.</p>\r\n\r\n<p>Until this issue is resolved, we have two workarounds:</p>\r\n\r\n<ol><li>Identify LINCS small molecules with their PubChem identifiers, which are provided for most compounds.</li><li>Match LINCS compounds to DrugBank using the provided InChIKeys and UniChem.</li></ol>",
      "body_md": "Perhaps this explains why 39% of DrugBank approved small molecules [did not map](http://git.dhimmel.com/drugbank/unichem-map.html) to a single LINCS compound: the LINCS resource was half it's current size.\r\n\r\nUntil this issue is resolved, we have two workarounds:\r\n\r\n1. Identify LINCS small molecules with their PubChem identifiers, which are provided for most compounds.\r\n2. Match LINCS compounds to DrugBank using the provided InChIKeys and UniChem.",
      "comment_id": 123,
      "profile_id": 17,
      "published": "2015-04-09T01:14:34.957461Z",
      "thread_id": 51,
      "url": "/discussion/unichem-mapping-to-lincs-small-molecules/51#2"
    },
    {
      "body_html": "<blockquote><p>My colleagues and I have worked on multiple approaches to create this knowledge in the papers <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.jbi.2010.09.009\" class=\"citation\" data-key=\"10.1016/j.jbi.2010.09.009\">1</a>, <a href=\"https://doi.org/10.1136/amiajnl-2012-000852\" class=\"citation\" data-key=\"10.1136/amiajnl-2012-000852\">2</a>, <a href=\"https://doi.org/10.1016/j.jbi.2013.11.010\" class=\"citation\" data-key=\"10.1016/j.jbi.2013.11.010\">3</a>]</span></p></blockquote>\r\n\r\n<p><a href=\"/u/allisonmccoy\" class=\"username\">@allisonmccoy</a>, thanks for the references. I like your approach because it captures what clinicians are actually using to treat diseases (and can provide indication prevalence — what percent of patients with problem X receive medication X). Too bad that the identifiers are local. We would definitely appreciate the validation data when available, especially if it can be mapped to standard terminologies.</p>\r\n\r\n<p>In terms of the mappings from the <a href=\"#104\">aforementioned</a> study <span class=\"citation\">[<a href=\"https://doi.org/10.1136/amiajnl-2012-000852\" class=\"citation\" data-key=\"10.1136/amiajnl-2012-000852\">2</a>]</span>, we still may be able to extract some utility: for example, we could manually map indications for diseases where our indications were lacking. <a href=\"/u/allisonmccoy\" class=\"username\">@allisonmccoy</a>, did any of the other papers you highlighted release data that could add value here?</p>\r\n\r\n<p><a href=\"/u/TIOprea\" class=\"username\">@TIOprea</a> mentioned the difficulty of identifying disease-modifying indications, even in a carefully hand-curated database. <a href=\"/u/allisonmccoy\" class=\"username\">@allisonmccoy</a>, does your method favor disease-modifying links? For example, if modafinil were prescribed to treat MS-induced fatigue, would the clinicians link modafinil to multiple sclerosis or fatigue?</p>",
      "body_md": "> My colleagues and I have worked on multiple approaches to create this knowledge in the papers [@10.1016/j.jbi.2010.09.009 @10.1136/amiajnl-2012-000852 @10.1016/j.jbi.2013.11.010]\r\n\r\n@allisonmccoy, thanks for the references. I like your approach because it captures what clinicians are actually using to treat diseases (and can provide indication prevalence -- what percent of patients with problem X receive medication X). Too bad that the identifiers are local. We would definitely appreciate the validation data when available, especially if it can be mapped to standard terminologies.\r\n\r\nIn terms of the mappings from the [aforementioned](#104) study [@10.1136/amiajnl-2012-000852], we still may be able to extract some utility: for example, we could manually map indications for diseases where our indications were lacking. @allisonmccoy, did any of the other papers you highlighted release data that could add value here?\r\n\r\n@TIOprea mentioned the difficulty of identifying disease-modifying indications, even in a carefully hand-curated database. @allisonmccoy, does your method favor disease-modifying links? For example, if modafinil were prescribed to treat MS-induced fatigue, would the clinicians link modafinil to multiple sclerosis or fatigue?",
      "comment_id": 124,
      "profile_id": 17,
      "published": "2015-04-09T01:28:15.012962Z",
      "thread_id": 21,
      "url": "/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#12"
    },
    {
      "body_html": "<blockquote><p>Did any of the other papers you highlighted release data that could add value here?</p></blockquote>\r\n\r\n<p>I don't believe so. I also omitted one more paper that validated the approach in Wright, et al.:</p>\r\n\r\n<ol><li>Wright A, McCoy A, Henkin S, Flaherty M, Sittig D. Validation of an association rule mining-based method to infer associations between medications and problems. Appl Clin Inform. 2013;4(1):100–9. </li></ol>\r\n\r\n<p>The 2nd reference uses RxNorm, SNOMED-CT, and NDF-RT, all of which is freely available, so that knowledge base could easily be regenerated by another party.</p>\r\n\r\n<blockquote><p>Does your method favor disease-modifying links? For example, if modafinil were prescribed to treat MS-induced fatigue, would the clinicians link modafinil to multiple sclerosis or fatigue?</p></blockquote>\r\n\r\n<p>It could be either, but more than likely it would be linked to MS, because that's what would be on the problem list already and easily linked during e-prescribing, but in our evaluation, we would have counted either as correct. We actually had a lot of discussion about this while doing the evaluations, because it did occur frequently.</p>",
      "body_md": "> Did any of the other papers you highlighted release data that could add value here?\r\n\r\nI don't believe so. I also omitted one more paper that validated the approach in Wright, et al.:\r\n\r\n5. Wright A, McCoy A, Henkin S, Flaherty M, Sittig D. Validation of an association rule mining-based method to infer associations between medications and problems. Appl Clin Inform. 2013;4(1):100–9. \r\n\r\nThe 2nd reference uses RxNorm, SNOMED-CT, and NDF-RT, all of which is freely available, so that knowledge base could easily be regenerated by another party.\r\n\r\n> Does your method favor disease-modifying links? For example, if modafinil were prescribed to treat MS-induced fatigue, would the clinicians link modafinil to multiple sclerosis or fatigue?\r\n\r\nIt could be either, but more than likely it would be linked to MS, because that's what would be on the problem list already and easily linked during e-prescribing, but in our evaluation, we would have counted either as correct. We actually had a lot of discussion about this while doing the evaluations, because it did occur frequently.",
      "comment_id": 125,
      "profile_id": 77,
      "published": "2015-04-09T01:43:12.201326Z",
      "thread_id": 21,
      "url": "/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#13"
    },
    {
      "body_html": "<p><a href=\"/u/TIOprea\" class=\"username\">@TIOprea</a>, thanks for your insights. You touch on important points. In general our method may not require a perfect indication catalog to succeed, so I am hopeful despite the difficulties you mention. Specifically,</p>\r\n\r\n<blockquote><p>There are diseases in \"indications\" that do NOT exist anywhere else [e.g., cancer XYZ with mutation A3999B, in other words it's not enough to have the disease, you need the right genotype!]</p></blockquote>\r\n\r\n<p>In this case, \"cancer XYZ with mutation A3999B\" would likely not be in the Disease Ontology and if it were would probably lack cross-references. However, if the disease did map to the DO, we would <a href=\"http://thinklab.com/discussion/unifying-disease-vocabularies/44#121\">propagate the indication</a> to \"cancer XYZ\".</p>\r\n\r\n<blockquote><p>you also have to deal with indications that are \"fringe\" (pregnancy is not a disease; neither is contraception)</p></blockquote>\r\n\r\n<p>These indications would not make it into the network because they do not relate to an included disease term. Information loss is ); but we'll get over it (;</p>\r\n\r\n<blockquote><p>indications etc. are not from PubMed - so please pay attention to approved labels</p></blockquote>\r\n\r\n<p>Thanks for the perspective. We won't include these as part of our gold standard.</p>\r\n\r\n<blockquote><p>disease modifying is far from trivial - you need epi to show you that</p></blockquote>\r\n\r\n<p>This I think will be the biggest difficulty. One option could be to exclude drugs that mostly treat symptoms. We noticed that drugs with many indications tended to be of this category. For multiple sclerosis, disease modifying is an <a href=\"http://www.nationalmssociety.org/Treating-MS/Medications\">established concept with currently 12 drugs</a>. Unfortunately, the MS indications we've <a href=\"http://git.dhimmel.com/indications/medi/\">extracted from MEDI</a> and <a href=\"http://git.dhimmel.com/indications/labeledin/\">LabeledIn</a> are predominantly symptomatic. And to make matters worse, for most other diseases the DM status seems much more poorly defined.</p>",
      "body_md": "@TIOprea, thanks for your insights. You touch on important points. In general our method may not require a perfect indication catalog to succeed, so I am hopeful despite the difficulties you mention. Specifically,\r\n\r\n> There are diseases in \"indications\" that do NOT exist anywhere else [e.g., cancer XYZ with mutation A3999B, in other words it's not enough to have the disease, you need the right genotype!]\r\n\r\nIn this case, \"cancer XYZ with mutation A3999B\" would likely not be in the Disease Ontology and if it were would probably lack cross-references. However, if the disease did map to the DO, we would [propagate the indication](http://thinklab.com/discussion/unifying-disease-vocabularies/44#121) to \"cancer XYZ\".\r\n\r\n> you also have to deal with indications that are \"fringe\" (pregnancy is not a disease; neither is contraception)\r\n\r\nThese indications would not make it into the network because they do not relate to an included disease term. Information loss is ); but we'll get over it (;\r\n\r\n> indications etc. are not from PubMed - so please pay attention to approved labels\r\n\r\nThanks for the perspective. We won't include these as part of our gold standard.\r\n\r\n> disease modifying is far from trivial - you need epi to show you that\r\n\r\nThis I think will be the biggest difficulty. One option could be to exclude drugs that mostly treat symptoms. We noticed that drugs with many indications tended to be of this category. For multiple sclerosis, disease modifying is an [established concept with currently 12 drugs](http://www.nationalmssociety.org/Treating-MS/Medications). Unfortunately, the MS indications we've [extracted from MEDI](http://git.dhimmel.com/indications/medi/) and [LabeledIn](http://git.dhimmel.com/indications/labeledin/) are predominantly symptomatic. And to make matters worse, for most other diseases the DM status seems much more poorly defined.",
      "comment_id": 126,
      "profile_id": 17,
      "published": "2015-04-09T01:53:53.624696Z",
      "thread_id": 21,
      "url": "/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#14"
    },
    {
      "body_html": "<blockquote><p>The 2nd reference <span class=\"citation\">[<a href=\"http://www.ncbi.nlm.nih.gov/pubmed/22195147\" class=\"citation\" data-key=\"McCoy_2011\">1</a>]</span> uses RxNorm, SNOMED-CT, and NDF-RT, all of which is freely available, so that knowledge base could easily be regenerated by another party.</p></blockquote>\r\n\r\n<p><a href=\"/u/allisonmccoy\" class=\"username\">@allisonmccoy</a>, I believe when MEDI <span class=\"citation\">[<a href=\"https://doi.org/10.1136/amiajnl-2012-001431\" class=\"citation\" data-key=\"10.1136/amiajnl-2012-001431\">2</a>]</span> extracts RxNorm indications, they are taking information from the NDF-RT. My belief is based on that in the introduction they state:</p>\r\n\r\n<blockquote><p>The integration of RxNorm with the National Drug File–Reference Terminology (NDF-RT) from the Veterans Health Administration has added significant indication information between single-ingredient medications and diseases through ‘may_treat’ and ‘may_prevent’ therapeutic relationships. NDF-RT includes both on-label and off-label indications, but its performance on indications has not been previously reported. Preliminary work with earlier versions of RxNorm and NDF-RT demonstrated that a number of medications were lacking indications.</p></blockquote>\r\n\r\n<p>Then in the methods they state:</p>\r\n\r\n<blockquote><p>To obtain indications of a medication from RxNorm, we retrieved all diseases that connect with the medication through either ‘may_be_treated_by’ or ‘may_be_prevented_by’ relationships.</p></blockquote>\r\n\r\n<p>Do you know whether the RxNorm portion of MEDI relied on the same underlying NDF-RT data that you collected for the 2011 AMIA Proceedings Paper <span class=\"citation\">[<a href=\"http://www.ncbi.nlm.nih.gov/pubmed/22195147\" class=\"citation\" data-key=\"McCoy_2011\">1</a>]</span>? </p>\r\n\r\n<p></p>",
      "body_md": "> The 2nd reference [@McCoy_2011] uses RxNorm, SNOMED-CT, and NDF-RT, all of which is freely available, so that knowledge base could easily be regenerated by another party.\r\n\r\n@allisonmccoy, I believe when MEDI [@10.1136/amiajnl-2012-001431] extracts RxNorm indications, they are taking information from the NDF-RT. My belief is based on that in the introduction they state:\r\n\r\n> The integration of RxNorm with the National Drug File–Reference Terminology (NDF-RT) from the Veterans Health Administration has added significant indication information between single-ingredient medications and diseases through ‘may_treat’ and ‘may_prevent’ therapeutic relationships. NDF-RT includes both on-label and off-label indications, but its performance on indications has not been previously reported. Preliminary work with earlier versions of RxNorm and NDF-RT demonstrated that a number of medications were lacking indications.\r\n\r\nThen in the methods they state:\r\n\r\n> To obtain indications of a medication from RxNorm, we retrieved all diseases that connect with the medication through either ‘may_be_treated_by’ or ‘may_be_prevented_by’ relationships.\r\n\r\nDo you know whether the RxNorm portion of MEDI relied on the same underlying NDF-RT data that you collected for the 2011 AMIA Proceedings Paper [@McCoy_2011]? \r\n\r\n[@McCoy_2011]: http://www.ncbi.nlm.nih.gov/pubmed/22195147 \"McCoy AB, Wright A, Laxmisan A, Singh H, Sittig DF. A prototype knowledge base and SMART app to facilitate organization of patient medications by clinical problems. AMIA Annu Symp Proc. 2011;2011:888–94.\"",
      "comment_id": 127,
      "profile_id": 17,
      "published": "2015-04-09T02:14:45.918691Z",
      "thread_id": 21,
      "url": "/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#15"
    },
    {
      "body_html": "<blockquote><p>Do you know whether the RxNorm portion of MEDI relied on the same underlying NDF-RT data that you collected for the 2011 AMIA Proceedings Paper [1]?</p></blockquote>\r\n\r\n<p><a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a> We only used the may_treat relationship, but we also took advantage of the is_a hierarchy for problems and ingredient_of relationships between medications and expanded the original set of pairs. So there is some overlap between the two, but likely some pairs that exist in only one or the other.</p>",
      "body_md": "> Do you know whether the RxNorm portion of MEDI relied on the same underlying NDF-RT data that you collected for the 2011 AMIA Proceedings Paper [1]?\r\n\r\n@dhimmel We only used the may_treat relationship, but we also took advantage of the is_a hierarchy for problems and ingredient_of relationships between medications and expanded the original set of pairs. So there is some overlap between the two, but likely some pairs that exist in only one or the other.",
      "comment_id": 128,
      "profile_id": 77,
      "published": "2015-04-09T02:18:37.037126Z",
      "thread_id": 21,
      "url": "/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#16"
    },
    {
      "body_html": "<p>One of the edge types we plan to incorporate in our network is that between diseases and symptoms. This data will come from the work of <em>Zhou et al.</em> in their <a href=\"https://dx.doi.org/10.1038/ncomms5212\">\"Human symptoms–disease network\"</a> paper. The supplementary data released by <em>Zhou et al.</em> identifies diseases and symptoms by their MeSH names, but does not include the associated MeSH IDs. To ease interoperability we have performed the minor task of appending the relevant MeSH IDs to these files. The result can be found <a href=\"https://github.com/LABrueggs/HSDN\">here</a>.</p>",
      "body_md": "One of the edge types we plan to incorporate in our network is that between diseases and symptoms. This data will come from the work of *Zhou et al.* in their [\"Human symptoms–disease network\"](https://dx.doi.org/10.1038/ncomms5212) paper. The supplementary data released by *Zhou et al.* identifies diseases and symptoms by their MeSH names, but does not include the associated MeSH IDs. To ease interoperability we have performed the minor task of appending the relevant MeSH IDs to these files. The result can be found [here](https://github.com/LABrueggs/HSDN).",
      "comment_id": 129,
      "profile_id": 21,
      "published": "2015-04-09T17:39:42.896099Z",
      "thread_id": 52,
      "url": "/discussion/human-symptom-disease-network-mesh-id-matching/52"
    },
    {
      "body_html": "<h1>Selecting the top nodes from DO Cancer Slim</h1>\r\n\r\n<p>I emailed <a href=\"http://medschool.umaryland.edu/FACULTYRESEARCHPROFILE/viewprofile.aspx?id=20337\">Lynn Schriml</a>, a lead investigator for the DO, asking about the creation of a consolidated and distinct set of high-level cancer terms. This work was <a href=\"https://dx.doi.org/10.1093/database/bav032\">recently published</a> in <em>Database</em> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/database/bav032\" class=\"citation\" data-key=\"10.1093/database/bav032\">1</a>]</span>. I wrote:</p>\r\n\r\n<blockquote><p>My main question is how did you decide which terms should be included in TopNodes_DOcancerslim? I want to generate a similar top-level term set but for all diseases. Was this a very difficult task that required medical expertise? Do you have any plans to create a DO-wide slim set? (Ideally, I would prefer to rely on an existing effort than to recreate the wheel).</p></blockquote>\r\n\r\n<p><strong>Response by Lynn Schriml</strong> (posted with permission):</p>\r\n\r\n<p>We are not planning on creating a DO wide slim at this time.</p>\r\n\r\n<p>Creating the DO cancer slim and the TOP nodes slim was a couple of months work by a team, including MDs, cancer and disease experts.</p>\r\n\r\n<p>We started with a set of terms from multiple cancer sources that we wanted align. We worked to identify how each term mapped to the current nomenclature of disease (disease names change over time), we then worked to define each term, figure out if the term was represented in DO, and where to place the term in DO, then we added the terms, creating DO definitions. We also reviewed and edited related terms. Once we had the larger set of terms defined, we looked at their parent nodes up to the top node for cancer. </p>\r\n\r\n<p>We wanted to identify body system level parents that reflected both the most specific we could be (not mapping the new TOP node parent all the way up to cancer), and for the TOP node to be biologically informative. There was also much discussion in our work group to finalize these choices. When that was done, we then edited the DO file, adding the new subtypes (slims) and adding each term in (one at a time).</p>",
      "body_md": "# Selecting the top nodes from DO Cancer Slim\r\n\r\nI emailed [Lynn Schriml](http://medschool.umaryland.edu/FACULTYRESEARCHPROFILE/viewprofile.aspx?id=20337), a lead investigator for the DO, asking about the creation of a consolidated and distinct set of high-level cancer terms. This work was [recently published](https://dx.doi.org/10.1093/database/bav032) in *Database* [@10.1093/database/bav032]. I wrote:\r\n\r\n> My main question is how did you decide which terms should be included in TopNodes_DOcancerslim? I want to generate a similar top-level term set but for all diseases. Was this a very difficult task that required medical expertise? Do you have any plans to create a DO-wide slim set? (Ideally, I would prefer to rely on an existing effort than to recreate the wheel).\r\n\r\n**Response by Lynn Schriml** (posted with permission):\r\n\r\nWe are not planning on creating a DO wide slim at this time.\r\n\r\nCreating the DO cancer slim and the TOP nodes slim was a couple of months work by a team, including MDs, cancer and disease experts.\r\n\r\nWe started with a set of terms from multiple cancer sources that we wanted align. We worked to identify how each term mapped to the current nomenclature of disease (disease names change over time), we then worked to define each term, figure out if the term was represented in DO, and where to place the term in DO, then we added the terms, creating DO definitions. We also reviewed and edited related terms. Once we had the larger set of terms defined, we looked at their parent nodes up to the top node for cancer. \r\n\r\nWe wanted to identify body system level parents that reflected both the most specific we could be (not mapping the new TOP node parent all the way up to cancer), and for the TOP node to be biologically informative. There was also much discussion in our work group to finalize these choices. When that was done, we then edited the DO file, adding the new subtypes (slims) and adding each term in (one at a time).",
      "comment_id": 130,
      "profile_id": 17,
      "published": "2015-04-10T00:30:43.175427Z",
      "thread_id": 44,
      "url": "/discussion/unifying-disease-vocabularies/44#4"
    },
    {
      "body_html": "<h1>Reconstructing DO Lite</h1>\r\n\r\n<p>DO Lite is an outdated project which provided a consolidated disease terminology <span class=\"citation\">[<a href=\"https://doi.org/10.1093/bioinformatics/btp193\" class=\"citation\" data-key=\"10.1093/bioinformatics/btp193\">1</a>]</span>. The only data release we could find is a mapping of disease names to implicated genes. Unfortunately, <a href=\"http://django.nubic.northwestern.edu/fundo/media/data/do_lite.txt\">this dataset</a> omits the actual DO identifiers.</p>\r\n\r\n<p>We extracted these disease names found 561 different terms. We <a href=\"http://nbviewer.ipython.org/github/dhimmel/disease-ontology/blob/gh-pages/dolite/dolite.ipynb\">used a text matching paradigm to match</a> these disease names to current DO terms. The paradigm consisted of the following steps:</p>\r\n\r\n<ol><li>creating a mapping of names (including synonyms) to DO identifiers [<a href=\"http://git.dhimmel.com/disease-ontology/data/term-names.tsv\">tsv</a>]</li><li>mapping DOLite names to current DO names (via exact lowercase match) [<a href=\"http://git.dhimmel.com/disease-ontology/dolite/dolite_to_doid.tsv\">tsv</a>]</li></ol>\r\n\r\n<p>A majority (<code>66.3% =  372 / 561</code>) of DOLite terms were matched to a current DO identifier. We may consider using these terms as a reference when manually constructing a DO Slim.</p>",
      "body_md": "# Reconstructing DO Lite\r\n\r\nDO Lite is an outdated project which provided a consolidated disease terminology [@10.1093/bioinformatics/btp193]. The only data release we could find is a mapping of disease names to implicated genes. Unfortunately, [this dataset](http://django.nubic.northwestern.edu/fundo/media/data/do_lite.txt) omits the actual DO identifiers.\r\n\r\nWe extracted these disease names found 561 different terms. We [used a text matching paradigm to match](http://nbviewer.ipython.org/github/dhimmel/disease-ontology/blob/gh-pages/dolite/dolite.ipynb) these disease names to current DO terms. The paradigm consisted of the following steps:\r\n\r\n1. creating a mapping of names (including synonyms) to DO identifiers [[tsv](http://git.dhimmel.com/disease-ontology/data/term-names.tsv)]\r\n2. mapping DOLite names to current DO names (via exact lowercase match) [[tsv](http://git.dhimmel.com/disease-ontology/dolite/dolite_to_doid.tsv)]\r\n\r\nA majority (`66.3% =  372 / 561`) of DOLite terms were matched to a current DO identifier. We may consider using these terms as a reference when manually constructing a DO Slim.",
      "comment_id": 131,
      "profile_id": 17,
      "published": "2015-04-10T03:45:06.006320Z",
      "thread_id": 44,
      "url": "/discussion/unifying-disease-vocabularies/44#5"
    },
    {
      "body_html": "<p>The <a href=\"http://lincs-dcic.org/\">BD2K-LINCS Data Coordination and Integration Center</a>  is part of the Big Data to Knowledge (BD2K) NIH initiative, and it is the data coordination center for the NIH Common Fund's Library of Integrated Network-based Cellular Signatures (LINCS) program, which aims to characterize how a variety of human cells, tissues and the entire organism respond to perturbations by drugs and other molecular factors. </p>\r\n\r\n<p>The <a href=\"http://www.lincsproject.org/centers/bd2k-lincs-dcic/\">BD2K- LINCS DCIC</a> works closely with each <a href=\"http://www.lincsproject.org/centers/data-and-signature-generating-centers/\">LINCS Data and Signature Generation Centers (DSGC)</a>. The DCIC also collaborates with other other organizations and projects like EBI (UniChem, ChEMBL, ChEBI), PubChem.<br>The LINCS Production Phase (LP2) DSGC's are:<br>-  Drug Toxicity Signature Generation Center (Icahn School of Medicine at Mount Sinai)<br>-  HMS LINCS Center (Harvard Medical School)<br>-  LINCS Center for Transcriptomics (Broad Institute)<br>-  LINCS Proteomic Characterization Center for Signaling and Epigenetics (Broad Institute)<br>-  Microenvironment Perturbagen (MEP) LINCS Center (Oregon Health and Science University)<br>-  NeuroLINCS Center (University of California, Irvine)</p>\r\n\r\n<p>The UniChem chemical structure cross-reference is mapped against the standardized LINCS small molecule (LSM).  The DCIC uses a simple schema to combine LINCS and other data into a coherent and computable knowledge framework. The Center develops meta-data standards that enable data integration and representation across the data and signature generation centers (DGSCs). Members of the DCIC are actively developing a next generation integrated web-based platform for the LINCS project that will serve as the foundation for LINCS activities and federate LINCS data, signatures, analysis algorithms, pipelines, APIs and web tools.  </p>\r\n\r\n<p>UniChem cross-references the standardized LINCS Small Molecule ID (LSM ID).  The LSM IDs are mapped to each center's compound and / or sample identifiers.  One example of such Center-specific IDs are identifier with the prefix \"BRD\", which correspond to small molecule compound IDs from the LINCS Center for Transcriptomics (Broad Institute).</p>",
      "body_md": "The [BD2K-LINCS Data Coordination and Integration Center](http://lincs-dcic.org/)  is part of the Big Data to Knowledge (BD2K) NIH initiative, and it is the data coordination center for the NIH Common Fund's Library of Integrated Network-based Cellular Signatures (LINCS) program, which aims to characterize how a variety of human cells, tissues and the entire organism respond to perturbations by drugs and other molecular factors. \r\n  \r\n\r\nThe [BD2K- LINCS DCIC](http://www.lincsproject.org/centers/bd2k-lincs-dcic/) works closely with each [LINCS Data and Signature Generation Centers (DSGC)](http://www.lincsproject.org/centers/data-and-signature-generating-centers/). The DCIC also collaborates with other other organizations and projects like EBI (UniChem, ChEMBL, ChEBI), PubChem.\r\nThe LINCS Production Phase (LP2) DSGC's are:\r\n-  Drug Toxicity Signature Generation Center (Icahn School of Medicine at Mount Sinai)\r\n-  HMS LINCS Center (Harvard Medical School)\r\n-  LINCS Center for Transcriptomics (Broad Institute)\r\n-  LINCS Proteomic Characterization Center for Signaling and Epigenetics (Broad Institute)\r\n-  Microenvironment Perturbagen (MEP) LINCS Center (Oregon Health and Science University)\r\n-  NeuroLINCS Center (University of California, Irvine)\r\n\r\nThe UniChem chemical structure cross-reference is mapped against the standardized LINCS small molecule (LSM).  The DCIC uses a simple schema to combine LINCS and other data into a coherent and computable knowledge framework. The Center develops meta-data standards that enable data integration and representation across the data and signature generation centers (DGSCs). Members of the DCIC are actively developing a next generation integrated web-based platform for the LINCS project that will serve as the foundation for LINCS activities and federate LINCS data, signatures, analysis algorithms, pipelines, APIs and web tools.  \r\n\r\nUniChem cross-references the standardized LINCS Small Molecule ID (LSM ID).  The LSM IDs are mapped to each center's compound and / or sample identifiers.  One example of such Center-specific IDs are identifier with the prefix \"BRD\", which correspond to small molecule compound IDs from the LINCS Center for Transcriptomics (Broad Institute).",
      "comment_id": 132,
      "profile_id": 79,
      "published": "2015-04-13T18:44:55.931707Z",
      "thread_id": 51,
      "url": "/discussion/unichem-mapping-to-lincs-small-molecules/51#3"
    },
    {
      "body_html": "<p>We have chosen to rely on <a href=\"http://www.bindingdb.org/bind/index.jsp\">BindingDB</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkl999\" class=\"citation\" data-key=\"10.1093/nar/gkl999\">1</a>, <a href=\"https://doi.org/10.2174/1386207013330670\" class=\"citation\" data-key=\"10.2174/1386207013330670\">2</a>]</span> for compound–protein binding (ligand–target affinity) information. Their website provides a <a href=\"http://www.bindingdb.org/bind/BindingDB-Intro2a.pdf\">nice background on this topic</a>. BindingDB includes several other databases including ChEMBL <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkr777\" class=\"citation\" data-key=\"10.1093/nar/gkr777\">3</a>, <a href=\"https://doi.org/10.1093/nar/gkt1031\" class=\"citation\" data-key=\"10.1093/nar/gkt1031\">4</a>]</span> and PubChem BioAssay <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkp965\" class=\"citation\" data-key=\"10.1093/nar/gkp965\">5</a>, <a href=\"https://doi.org/10.1093/nar/gkr1132\" class=\"citation\" data-key=\"10.1093/nar/gkr1132\">6</a>, <a href=\"https://doi.org/10.1093/nar/gkt978\" class=\"citation\" data-key=\"10.1093/nar/gkt978\">7</a>]</span> and <a href=\"https://www.bindingdb.org/bind/chemsearch/marvin/SDFdownload.jsp?all_download=yes\">provides</a> well-annotated data in convenient formats.</p>\r\n\r\n<p>We have <a href=\"http://nbviewer.ipython.org/github/dhimmel/bindingdb/blob/gh-pages/process.ipynb\">begun our parsing of BindingDB</a> from the <code>BindingDB_All_2015m3</code> release. We have taken the following steps:</p>\r\n\r\n<ol><li>Some binding experiments refer to multichain protein complexes. However, <code>96% = 1073428 / 1115639</code> of experiments assayed a single chain protein. For simplicity, we decided to omit binding to complexes.</li><li>Of the remaining interactions, the protein targets for <code>20% = 215107 / 1073428 </code> did not map to a SwissProt identifier and were excluded.</li><li>Of the remaining interactions <code>78% = 673750 / 858321</code> were curated with <code>Homo sapiens</code> as the organism. While we will most likely only end up using the human targets, this filtering should naturally occur at a later stage.</li></ol>\r\n\r\n<p>The next step is translating BindingDB compounds to DrugBank compounds. Many BindingDB compounds may match a single DrugBank compound. Additionally multiple experiments may report affinities for the same compound–target pair. There are several affinity metrics (<code>Ki (nM)</code>, <code>IC50 (nM)</code>, <code>Kd (nM)</code>, <code>EC50 (nM)</code>) that are in nanomolar units. We would like to combine all affinities for a DrugBank–EntrezGene pair into a single molarity value (which can then be used as a network inclusion threshold).</p>\r\n\r\n<p>We would like input on how to combine affinities across experiments. Are some molarity measurements more precise? Are certain source databases less error prone? We are looking for simple and rational rules and are willing to accept a healthy dose of reductionism.</p>",
      "body_md": "We have chosen to rely on [BindingDB](http://www.bindingdb.org/bind/index.jsp) [@10.1093/nar/gkl999 @10.2174/1386207013330670] for compound--protein binding (ligand--target affinity) information. Their website provides a [nice background on this topic](http://www.bindingdb.org/bind/BindingDB-Intro2a.pdf). BindingDB includes several other databases including ChEMBL [@10.1093/nar/gkr777 @10.1093/nar/gkt1031] and PubChem BioAssay [@10.1093/nar/gkp965 @10.1093/nar/gkr1132 @10.1093/nar/gkt978] and [provides](https://www.bindingdb.org/bind/chemsearch/marvin/SDFdownload.jsp?all_download=yes) well-annotated data in convenient formats.\r\n\r\nWe have [begun our parsing of BindingDB](http://nbviewer.ipython.org/github/dhimmel/bindingdb/blob/gh-pages/process.ipynb) from the `BindingDB_All_2015m3` release. We have taken the following steps:\r\n\r\n1. Some binding experiments refer to multichain protein complexes. However, `96% = 1073428 / 1115639` of experiments assayed a single chain protein. For simplicity, we decided to omit binding to complexes.\r\n+ Of the remaining interactions, the protein targets for `20% = 215107 / 1073428 ` did not map to a SwissProt identifier and were excluded.\r\n+ Of the remaining interactions `78% = 673750 / 858321` were curated with `Homo sapiens` as the organism. While we will most likely only end up using the human targets, this filtering should naturally occur at a later stage.\r\n\r\nThe next step is translating BindingDB compounds to DrugBank compounds. Many BindingDB compounds may match a single DrugBank compound. Additionally multiple experiments may report affinities for the same compound--target pair. There are several affinity metrics (`Ki (nM)`, `IC50 (nM)`, `Kd (nM)`, `EC50 (nM)`) that are in nanomolar units. We would like to combine all affinities for a DrugBank--EntrezGene pair into a single molarity value (which can then be used as a network inclusion threshold).\r\n \r\nWe would like input on how to combine affinities across experiments. Are some molarity measurements more precise? Are certain source databases less error prone? We are looking for simple and rational rules and are willing to accept a healthy dose of reductionism.",
      "comment_id": 133,
      "profile_id": 17,
      "published": "2015-04-13T20:32:22.786364Z",
      "thread_id": 53,
      "url": "/discussion/integrating-drug-target-information-from-bindingdb/53"
    },
    {
      "body_html": "<p>Hi Daniel,</p>\r\n\r\n<p>Most of the data in bindingDB are 50% inhibitor concentrations (IC50s), inhibition constants (Kis), with occasional dissocation constants (Kds), all in default units of nanomolar (nM).  The IC50 values are regarded as less rigorous measures of binding affinity as they depend to some degree on the association constant of the enzyme substrate used in measuring the IC50 value. The Ki and Kd values should be somewhat more rigorous. If a given compound and protein target have multiple measurements of different types, I'd probably use them in the following order of preference: Kd over Ki over IC50.  That said, most of the data are IC50s, so this case won't arise all that often.  </p>\r\n\r\n<p>Hope this helps!<br>Regards,<br>Mike</p>",
      "body_md": "Hi Daniel,\r\n\r\nMost of the data in bindingDB are 50% inhibitor concentrations (IC50s), inhibition constants (Kis), with occasional dissocation constants (Kds), all in default units of nanomolar (nM).  The IC50 values are regarded as less rigorous measures of binding affinity as they depend to some degree on the association constant of the enzyme substrate used in measuring the IC50 value. The Ki and Kd values should be somewhat more rigorous. If a given compound and protein target have multiple measurements of different types, I'd probably use them in the following order of preference: Kd over Ki over IC50.  That said, most of the data are IC50s, so this case won't arise all that often.  \r\n\r\nHope this helps!\r\nRegards,\r\nMike",
      "comment_id": 135,
      "profile_id": 80,
      "published": "2015-04-14T00:34:03.123002Z",
      "thread_id": 53,
      "url": "/discussion/integrating-drug-target-information-from-bindingdb/53#2"
    },
    {
      "body_html": "<p>The table below categorizes each binding by the affinity measures reported in bindingDB. Some reports include multiple measures. After filtering multichain and unmapped proteins, the number of bindings per category is reported:</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>IC50 (nM)</th><th>Ki (nM)</th><th>Kd (nM)</th><th>EC50 (nM)</th><th>count</th></tr></thead><tbody><tr><td>-</td><td>-</td><td>-</td><td>-</td><td>881</td></tr><tr><td>IC50</td><td>-</td><td>-</td><td>-</td><td>480,070</td></tr><tr><td>-</td><td>Ki</td><td>-</td><td>-</td><td>245,475</td></tr><tr><td>-</td><td>-</td><td>Kd</td><td>-</td><td>55,044</td></tr><tr><td>-</td><td>-</td><td>-</td><td>EC50</td><td>74,549</td></tr><tr><td>IC50</td><td>Ki</td><td>-</td><td>-</td><td>985</td></tr><tr><td>IC50</td><td>-</td><td>Kd</td><td>-</td><td>76</td></tr><tr><td>IC50</td><td>-</td><td>-</td><td>EC50</td><td>631</td></tr><tr><td>-</td><td>Ki</td><td>Kd</td><td>-</td><td>4</td></tr><tr><td>-</td><td>Ki</td><td>-</td><td>EC50</td><td>574</td></tr><tr><td>-</td><td>-</td><td>Kd</td><td>EC50</td><td>8</td></tr><tr><td>IC50</td><td>Ki</td><td>Kd</td><td>-</td><td>1</td></tr><tr><td>IC50</td><td>Ki</td><td>-</td><td>EC50</td><td>23</td></tr></tbody></table>\r\n\r\n<p>Definitions for reference:</p>\r\n\r\n<ul><li>IC50 - half maximal inhibitory concentration</li><li>Kd - dissociation constant</li><li>Ki - inhibitor constant</li><li>EC50 - half maximal effective concentration</li></ul>\r\n\r\n<p><a href=\"/u/mkgilson\" class=\"username\">@mkgilson</a>, thanks! What about EC50s, of which there are 74,549 reports? Can we include this information, and if so where should EC50s fall in the preference order? </p>\r\n\r\n<p>Also is it possible to infer whether a ligand is an agonist or antagonist based on which measures are reported?</p>",
      "body_md": "The table below categorizes each binding by the affinity measures reported in bindingDB. Some reports include multiple measures. After filtering multichain and unmapped proteins, the number of bindings per category is reported:\r\n\r\n| IC50 (nM) | Ki (nM) | Kd (nM) | EC50 (nM) | count |\r\n| - | - | - | - | - |\r\n| - | - | - | - | 881 |\r\n| IC50 | - | - | - | 480,070 |\r\n| - | Ki | - | - | 245,475 |\r\n|- | - | Kd | - | 55,044 |\r\n| - | - | - | EC50 | 74,549 |\r\n| IC50 | Ki | - | - | 985 |\r\n| IC50 | - | Kd | - | 76 |\r\n| IC50 | - | - | EC50 | 631 |\r\n| - | Ki | Kd | - | 4 |\r\n| - | Ki | - | EC50 | 574 |\r\n| - | - | Kd | EC50 | 8 |\r\n| IC50 | Ki | Kd | - | 1 |\r\n| IC50 | Ki | - | EC50 | 23 |\r\n\r\nDefinitions for reference:\r\n\r\n+ IC50 - half maximal inhibitory concentration\r\n+ Kd - dissociation constant\r\n+ Ki - inhibitor constant\r\n+ EC50 - half maximal effective concentration\r\n\r\n@mkgilson, thanks! What about EC50s, of which there are 74,549 reports? Can we include this information, and if so where should EC50s fall in the preference order? \r\n\r\nAlso is it possible to infer whether a ligand is an agonist or antagonist based on which measures are reported?",
      "comment_id": 136,
      "profile_id": 17,
      "published": "2015-04-14T16:18:39.208944Z",
      "thread_id": 53,
      "url": "/discussion/integrating-drug-target-information-from-bindingdb/53#3"
    },
    {
      "body_html": "<p>Hi Dan,</p>\r\n\r\n<p>I'd significantly downweight or ignore the EC50s, as these are at greatest risk of not corresponding to a confirmed binding reaction.  For example, there might be a compound which binds, or is expected to bind,  a particular protein target; but the measurement done is to expose cells to the compound and report the concentration at which it is \"50% effective\" (hence EC50) in producing a biological effect supposedly due to binding of the protein target.</p>\r\n\r\n<p>Unfortunately, agonism/antagonism is not readily available.</p>\r\n\r\n<p>Regards,<br>Mike</p>",
      "body_md": "Hi Dan,\r\n\r\nI'd significantly downweight or ignore the EC50s, as these are at greatest risk of not corresponding to a confirmed binding reaction.  For example, there might be a compound which binds, or is expected to bind,  a particular protein target; but the measurement done is to expose cells to the compound and report the concentration at which it is \"50% effective\" (hence EC50) in producing a biological effect supposedly due to binding of the protein target.\r\n\r\nUnfortunately, agonism/antagonism is not readily available.\r\n\r\nRegards,\r\nMike",
      "comment_id": 137,
      "profile_id": 80,
      "published": "2015-04-14T17:29:15.868281Z",
      "thread_id": 53,
      "url": "/discussion/integrating-drug-target-information-from-bindingdb/53#4"
    },
    {
      "body_html": "<p>The following tables will help you map between LINCS Centers to LINCS Small Molecule ID (LSM):<br><a href=\"http://lincs-dcic.org/metadata/SmallMolecules/LincsID2FacilityID_LINCS_StandardizedCmpds_LSMIDs.txt\">mapping of LINCS Small Molecules to LINCS Facility ID</a><br><a href=\"http://lincs-dcic.org/metadata/SmallMolecules/CompoundTable_LINCS_StandardizedCmpds_LSMIDs.txt\">LINCS compound table</a><br><a href=\"http://lincs-dcic.org/metadata/SmallMolecules/SampleTable_LincsID2FacilityID2CenterBatchID_LINCS_StandardizedCmpds_LSMIDs.txt\">LINCS by SM_Center_Sample_ID</a></p>",
      "body_md": "The following tables will help you map between LINCS Centers to LINCS Small Molecule ID (LSM):\r\n[mapping of LINCS Small Molecules to LINCS Facility ID](http://lincs-dcic.org/metadata/SmallMolecules/LincsID2FacilityID_LINCS_StandardizedCmpds_LSMIDs.txt)\r\n[LINCS compound table](http://lincs-dcic.org/metadata/SmallMolecules/CompoundTable_LINCS_StandardizedCmpds_LSMIDs.txt)\r\n[LINCS by SM_Center_Sample_ID](http://lincs-dcic.org/metadata/SmallMolecules/SampleTable_LincsID2FacilityID2CenterBatchID_LINCS_StandardizedCmpds_LSMIDs.txt)",
      "comment_id": 138,
      "profile_id": 79,
      "published": "2015-04-15T19:25:54.569964Z",
      "thread_id": 51,
      "url": "/discussion/unichem-mapping-to-lincs-small-molecules/51#4"
    },
    {
      "body_html": "<p>The <a href=\"https://sites.google.com/site/bd2klincsdatascience/\">BD2K LINCS Data Science Research webinars</a> serve as a general forum to engage data scientists within and outside of LINCS project to work on problems related to LINCS data analysis and integration. </p>\r\n\r\n<p>The <a href=\"http://lincs-dcic.org/\">BD2K-LINCS DCIC</a> engages the research community by delivering high quality educational materials through the web as well as through mentoring, seminars and symposia. Also, Center investigators actively engage in the education of a new generation of Big Data Scientists by developing a graduate-level Big Data Science MOOC that will be delivered to graduate students in Big Data Biostatistics and other Biomedical Informatics graduate programs.</p>\r\n\r\n<p>See <a href=\"http://lincs-dcic.org/#/training\">BD2K-LINCS DCIC Training and Outreach</a>.</p>",
      "body_md": "The [BD2K LINCS Data Science Research webinars](https://sites.google.com/site/bd2klincsdatascience/) serve as a general forum to engage data scientists within and outside of LINCS project to work on problems related to LINCS data analysis and integration. \r\n\r\nThe [BD2K-LINCS DCIC](http://lincs-dcic.org/) engages the research community by delivering high quality educational materials through the web as well as through mentoring, seminars and symposia. Also, Center investigators actively engage in the education of a new generation of Big Data Scientists by developing a graduate-level Big Data Science MOOC that will be delivered to graduate students in Big Data Biostatistics and other Biomedical Informatics graduate programs.\r\n\r\nSee [BD2K-LINCS DCIC Training and Outreach](http://lincs-dcic.org/#/training).\r\n",
      "comment_id": 139,
      "profile_id": 79,
      "published": "2015-04-15T19:32:12.014858Z",
      "thread_id": 43,
      "url": "/discussion/computing-consensus-transcriptional-profiles-for-lincs-l1000-perturbations/43#2"
    },
    {
      "body_html": "<p><a href=\"/u/cchung\" class=\"username\">@cchung</a>, Thank you for the useful links. Looking into the file you linked to named <a href=\"http://lincs-dcic.org/metadata/SmallMolecules/LincsID2FacilityID_LINCS_StandardizedCmpds_LSMIDs.txt\">mapping of LINCS Small Molecules to LINCS Facility ID</a> (<code>LincsID2FacilityID_LINCS_StandardizedCmpds_LSMIDs.txt</code>), we found that it contained 35,305 <code>BRD-</code> small molecule perturbagen IDs. Separate from this, we have a smaller set of <code>BRD-</code> small molecule perturbagen IDs (20,413) extracted from the <a href=\"http://api.lincscloud.org/\">LINCS L1000 API</a>. In comparing these two sets, we found only 13,796 common <code>BRD-</code> IDs.</p>\r\n\r\n<p>This means that many of the <code>BRD-</code> small molecule perturbagen IDs mapped to <code>LSM</code> IDs do not have transcriptional profiles from Broad. Additionally many compounds that were transcriptionally profiled are not mapped to the <code>LSM</code> ID set.</p>\r\n\r\n<p>Therefore, to integrate <code>BRD</code> compounds, we will rely on the supplied pubchem CIDs, which almost all compounds had.</p>",
      "body_md": "@cchung, Thank you for the useful links. Looking into the file you linked to named [mapping of LINCS Small Molecules to LINCS Facility ID](http://lincs-dcic.org/metadata/SmallMolecules/LincsID2FacilityID_LINCS_StandardizedCmpds_LSMIDs.txt) (`LincsID2FacilityID_LINCS_StandardizedCmpds_LSMIDs.txt`), we found that it contained 35,305 `BRD-` small molecule perturbagen IDs. Separate from this, we have a smaller set of `BRD-` small molecule perturbagen IDs (20,413) extracted from the [LINCS L1000 API](http://api.lincscloud.org/). In comparing these two sets, we found only 13,796 common `BRD-` IDs.\r\n\r\nThis means that many of the `BRD-` small molecule perturbagen IDs mapped to `LSM` IDs do not have transcriptional profiles from Broad. Additionally many compounds that were transcriptionally profiled are not mapped to the `LSM` ID set.\r\n\r\nTherefore, to integrate `BRD` compounds, we will rely on the supplied pubchem CIDs, which almost all compounds had.",
      "comment_id": 140,
      "profile_id": 21,
      "published": "2015-04-15T21:48:29.611008Z",
      "thread_id": 51,
      "url": "/discussion/unichem-mapping-to-lincs-small-molecules/51#5"
    },
    {
      "body_html": "<p>The count difference is because the <a href=\"http://www.lincscloud.org/perturbagens/\">L1000 dataset contains  20,413 small-molecules</a> profiled as part of the LINCS program, the Broad Connectivity Map, NIH efforts such as CDRP, and other projects.  We are standardizing the remaining - will keep you posted on the release!</p>",
      "body_md": "The count difference is because the [L1000 dataset contains  20,413 small-molecules](http://www.lincscloud.org/perturbagens/) profiled as part of the LINCS program, the Broad Connectivity Map, NIH efforts such as CDRP, and other projects.  We are standardizing the remaining - will keep you posted on the release!\r\n",
      "comment_id": 141,
      "profile_id": 79,
      "published": "2015-04-16T13:55:58.879377Z",
      "thread_id": 51,
      "url": "/discussion/unichem-mapping-to-lincs-small-molecules/51#6"
    },
    {
      "body_html": "<p><a href=\"/u/leobrueggeman\" class=\"username\">@leobrueggeman</a> and I attended the online LINCS office hours today. We spoke primarily with Ted who provided some helpful insights and suggestions.</p>\r\n\r\n<ol><li><p><strong>Spearman's correlation</strong> is preferred to the Pearson's correlation when calculating correlations between transcriptional profiles. Spearman's correlation is rank based and therefore less prone to excessive influence of extremes. We will switch from Pearson's to Spearman's correlation in step 2 <a href=\"#\">above</a>.</p></li><li><p><strong>Gold signatures</strong> — Multiple replicates (often 3) are performed for each signature. Higher quality signatures are considered gold (<code>is_gold</code>) based on a heuristic that values reproducibility across replicates and distinctness of that signature. They require the aggregate correlation within replicates to exceed a threshold among other criteria. Around half of the dataset is gold. The informativeness of nongold signatures is dubious, thus Ted suggests restricting to gold signatures.</p></li><li><p><strong>Z-score threshold</strong> — when setting a DEG (deferentially expressed gene) threshold, the LINCS team uses <code>&gt; 2.0</code> or <code>&lt; -2.0</code> and is pleased with the results.</p></li><li><p><strong>Signature number bias in DEG counts</strong> — We found that some perturbagens had an extremely high number of DEGs. We speculate that this occurs for perturbagens with few signatures, since with many signatures across varying contexts, a large set of consistently dysregulated genes seems unlikely. Two possible corrections for this bias are: a) choose a constant number of signatures to include per perturbagen. However, this would lead to information loss, which is undesirable. b) develop an empirical method for adjusting for expected DEG numbers. We will explore option (b) in a future post.</p></li><li><p><strong>Best inferred gene set</strong> — (<code>is_bing</code>) refers to genes that are reliably imputed from the 1000 assayed genes (L1000). We plan to switch to only included the ~7,500 bing genes in our DEG analysis because we would like to avoid unreliable data. This may also help reduce the excess of DEG for certain perturbagens. Whether a gene is part of the bing subset can be retrieved through the <code>geneinfo</code> <a href=\"http://api.lincscloud.org/a2/docs/geneinfo\">API query</a>. </p></li></ol>",
      "body_md": "@leobrueggeman and I attended the online LINCS office hours today. We spoke primarily with Ted who provided some helpful insights and suggestions.\r\n\r\n1. **Spearman's correlation** is preferred to the Pearson's correlation when calculating correlations between transcriptional profiles. Spearman's correlation is rank based and therefore less prone to excessive influence of extremes. We will switch from Pearson's to Spearman's correlation in step 2 [above](#).\r\n\r\n2. **Gold signatures** -- Multiple replicates (often 3) are performed for each signature. Higher quality signatures are considered gold (`is_gold`) based on a heuristic that values reproducibility across replicates and distinctness of that signature. They require the aggregate correlation within replicates to exceed a threshold among other criteria. Around half of the dataset is gold. The informativeness of nongold signatures is dubious, thus Ted suggests restricting to gold signatures.\r\n\r\n3. **Z-score threshold** -- when setting a DEG (deferentially expressed gene) threshold, the LINCS team uses `> 2.0` or `< -2.0` and is pleased with the results.\r\n\r\n4. **Signature number bias in DEG counts** -- We found that some perturbagens had an extremely high number of DEGs. We speculate that this occurs for perturbagens with few signatures, since with many signatures across varying contexts, a large set of consistently dysregulated genes seems unlikely. Two possible corrections for this bias are: a) choose a constant number of signatures to include per perturbagen. However, this would lead to information loss, which is undesirable. b) develop an empirical method for adjusting for expected DEG numbers. We will explore option (b) in a future post.\r\n\r\n5. **Best inferred gene set** -- (`is_bing`) refers to genes that are reliably imputed from the 1000 assayed genes (L1000). We plan to switch to only included the ~7,500 bing genes in our DEG analysis because we would like to avoid unreliable data. This may also help reduce the excess of DEG for certain perturbagens. Whether a gene is part of the bing subset can be retrieved through the `geneinfo` [API query](http://api.lincscloud.org/a2/docs/geneinfo). \r\n",
      "comment_id": 142,
      "profile_id": 17,
      "published": "2015-04-16T18:56:14.776626Z",
      "thread_id": 43,
      "url": "/discussion/computing-consensus-transcriptional-profiles-for-lincs-l1000-perturbations/43#3"
    },
    {
      "body_html": "<h1>BindingDB Processing</h1>\r\n\r\n<p>For our network, we desire binding edges between entrez genes and drugbank compounds. We coerced the bindingDB to conform to our desires using the following steps:</p>\r\n\r\n<h3><a href=\"https://github.com/dhimmel/bindingdb/blob/95aa588c6e553d85f7bd9030956297076f0df5e3/process.ipynb\">Dataset cleanup and tidying</a>:</h3>\r\n\r\n<ol><li>downloading and reading bindingDB</li><li>removing interactions with multichain complexes or without uniprot protein IDs</li><li>converting binding affinities to floats</li><li>retrieving entrez genes corresponding to uniprot proteins (<a href=\"http://git.dhimmel.com/uniprot/data/map/GeneID.tsv.gz\">download mapping</a>)</li><li>gathering data so rows contain only a single affinity measurement, uniprot protein, and entrez gene (<a href=\"https://github.com/dhimmel/bindingdb/blob/95aa588c6e553d85f7bd9030956297076f0df5e3/data/binding.tsv.gz\">download tidied data</a>)</li></ol>\r\n\r\n<h3><a href=\"https://htmlpreview.github.io/?https://github.com/dhimmel/bindingdb/blob/95aa588c6e553d85f7bd9030956297076f0df5e3/collapse.html\">Collapsing bindingDB into compound-gene relationships</a>:</h3>\r\n\r\n<ol><li>restricting to human interactions</li><li>mapping bindingDB compounds to drugbank (<a href=\"http://git.dhimmel.com/drugbank/data/mapping/bindingdb.tsv\">download fuzzy mapping</a>)</li><li>multiple affinities for the same bindingdb–uniprot pairs were resolved by preferentially selecting Kd over Ki over IC50 and taking a geometric mean when there were multiple measurements of the same measure (<a href=\"https://github.com/dhimmel/bindingdb/blob/95aa588c6e553d85f7bd9030956297076f0df5e3/data/bindings-drugbank-collapsed.tsv\">download</a>)</li><li>collapsing into drugbank–gene pairs, taking the minimum affinity reported across grouped bindingdb–uniprot pairs (<a href=\"https://github.com/dhimmel/bindingdb/blob/95aa588c6e553d85f7bd9030956297076f0df5e3/data/bindings-drugbank-gene.tsv\">download</a>)</li></ol>\r\n\r\n<p>The resulting drugbank–gene dataset contained 21,617 interactions. Setting an affinity threshold at 1 micromolar (1000 nanomolar) — a threshold suggested by both <a href=\"/u/mkgilson\" class=\"username\">@mkgilson</a> and <a href=\"/u/alessandrodidonna\" class=\"username\">@alessandrodidonna</a> in conversation — retained ~20% of interactions. After thresholding at 1 micromolar, 890 genes and 1,634 drugbank compounds participated in 5,701 binding interactions.</p>",
      "body_md": "# BindingDB Processing\r\n\r\nFor our network, we desire binding edges between entrez genes and drugbank compounds. We coerced the bindingDB to conform to our desires using the following steps:\r\n\r\n### [Dataset cleanup and tidying](https://github.com/dhimmel/bindingdb/blob/95aa588c6e553d85f7bd9030956297076f0df5e3/process.ipynb):\r\n\r\n1. downloading and reading bindingDB\r\n2. removing interactions with multichain complexes or without uniprot protein IDs\r\n3. converting binding affinities to floats\r\n4. retrieving entrez genes corresponding to uniprot proteins ([download mapping](http://git.dhimmel.com/uniprot/data/map/GeneID.tsv.gz))\r\n5. gathering data so rows contain only a single affinity measurement, uniprot protein, and entrez gene ([download tidied data](https://github.com/dhimmel/bindingdb/blob/95aa588c6e553d85f7bd9030956297076f0df5e3/data/binding.tsv.gz))\r\n\r\n### [Collapsing bindingDB into compound-gene relationships](https://htmlpreview.github.io/?https://github.com/dhimmel/bindingdb/blob/95aa588c6e553d85f7bd9030956297076f0df5e3/collapse.html):\r\n\r\n1. restricting to human interactions\r\n2. mapping bindingDB compounds to drugbank ([download fuzzy mapping](http://git.dhimmel.com/drugbank/data/mapping/bindingdb.tsv))\r\n3. multiple affinities for the same bindingdb--uniprot pairs were resolved by preferentially selecting Kd over Ki over IC50 and taking a geometric mean when there were multiple measurements of the same measure ([download](https://github.com/dhimmel/bindingdb/blob/95aa588c6e553d85f7bd9030956297076f0df5e3/data/bindings-drugbank-collapsed.tsv))\r\n4. collapsing into drugbank--gene pairs, taking the minimum affinity reported across grouped bindingdb--uniprot pairs ([download](https://github.com/dhimmel/bindingdb/blob/95aa588c6e553d85f7bd9030956297076f0df5e3/data/bindings-drugbank-gene.tsv))\r\n\r\nThe resulting drugbank--gene dataset contained 21,617 interactions. Setting an affinity threshold at 1 micromolar (1000 nanomolar) -- a threshold suggested by both @mkgilson and @alessandrodidonna in conversation -- retained ~20% of interactions. After thresholding at 1 micromolar, 890 genes and 1,634 drugbank compounds participated in 5,701 binding interactions.",
      "comment_id": 143,
      "profile_id": 17,
      "published": "2015-04-16T21:16:29.833048Z",
      "thread_id": 53,
      "url": "/discussion/integrating-drug-target-information-from-bindingdb/53#5"
    },
    {
      "body_html": "<h1>Creating a slim DO</h1>\r\n\r\n<p>We created a slim DO with <a href=\"https://github.com/dhimmel/disease-ontology/blob/75050ea2d4f60e745d3f3578ae03560a2cc0e444/data/slim-terms.tsv\" title=\"TSV of DO Slim diseases\">137 terms</a> where:</p>\r\n\r\n<ol><li>no terms were descendants/ancestors of other terms</li><li>terms were specific enough to be clinically relevant</li><li>terms were general enough to be well annotated</li></ol>\r\n\r\n<p>To create this slim term set, we combined the diseases from:</p>\r\n\r\n<ol><li>hetio <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1004259\">1</a>]</span> — 108 complex diseases contained in the GWAS Catalog.</li><li>TOPNodes_DOcancerslim <span class=\"citation\">[<a href=\"https://doi.org/10.1093/database/bav032\" class=\"citation\" data-key=\"10.1093/database/bav032\">2</a>]</span> — a body system focused set of 63 cancer terms.</li></ol>\r\n\r\n<p>We found that both sources contained overlapping nodes, and we removed 34 nodes to create a non-overlapping term set. We chose the following rules to resolve overlapping nodes:</p>\r\n\r\n<ol><li>For cancers in TOPNodes_DOcancerslim, retain only the most specific cancer</li><li>Remove hetio terms that descend from TOPNodes_DOcancerslim terms</li><li>For the remaining overlapping hetio terms, choose the term with greater clinical interest or GWAS annotations. For 4 out of the 5 conflicts under this rule, we chose to retain the more general term.</li></ol>\r\n\r\n<h3>Other notes:</h3>\r\n\r\n<p>The repository with our DO analysis is <a href=\"https://github.com/dhimmel/disease-ontology\">here</a> and contains notebooks for <a href=\"https://github.com/dhimmel/disease-ontology/blob/75050ea2d4f60e745d3f3578ae03560a2cc0e444/DO-xrefs.ipynb\">extracting xrefs</a> and <a href=\"https://github.com/dhimmel/disease-ontology/blob/75050ea2d4f60e745d3f3578ae03560a2cc0e444/slim.ipynb\">evaluating our slim DO</a> <span class=\"citation\">[<a href=\"https://doi.org/10.5281/zenodo.45584\" class=\"citation\" data-key=\"10.5281/zenodo.45584\">3</a>]</span>.</p>\r\n\r\n<p>We plan to propagate annotations from more specific terms to our slim terms. To facilitate this process, we created a <a href=\"https://github.com/dhimmel/disease-ontology/blob/75050ea2d4f60e745d3f3578ae03560a2cc0e444/data/xrefs-prop-slim.tsv\">propagated DO slim xref mapping file</a>.</p>\r\n\r\n<p>Pleural cancer (<code>DOID:9917</code>) was a TOPNodes_DOcancerslim term but was not found in the ontology version we downloaded (subversion revision 2810).</p>",
      "body_md": "# Creating a slim DO\r\n\r\nWe created a slim DO with [137 terms](https://github.com/dhimmel/disease-ontology/blob/75050ea2d4f60e745d3f3578ae03560a2cc0e444/data/slim-terms.tsv \"TSV of DO Slim diseases\") where:\r\n\r\n1. no terms were descendants/ancestors of other terms\r\n2. terms were specific enough to be clinically relevant\r\n3. terms were general enough to be well annotated\r\n\r\nTo create this slim term set, we combined the diseases from:\r\n\r\n1. hetio [@10.1371/journal.pcbi.1004259] -- 108 complex diseases contained in the GWAS Catalog.\r\n2. TOPNodes_DOcancerslim [@10.1093/database/bav032] -- a body system focused set of 63 cancer terms.\r\n\r\nWe found that both sources contained overlapping nodes, and we removed 34 nodes to create a non-overlapping term set. We chose the following rules to resolve overlapping nodes:\r\n\r\n1. For cancers in TOPNodes_DOcancerslim, retain only the most specific cancer\r\n2. Remove hetio terms that descend from TOPNodes_DOcancerslim terms\r\n3. For the remaining overlapping hetio terms, choose the term with greater clinical interest or GWAS annotations. For 4 out of the 5 conflicts under this rule, we chose to retain the more general term.\r\n\r\n### Other notes:\r\n\r\nThe repository with our DO analysis is [here](https://github.com/dhimmel/disease-ontology) and contains notebooks for [extracting xrefs](https://github.com/dhimmel/disease-ontology/blob/75050ea2d4f60e745d3f3578ae03560a2cc0e444/DO-xrefs.ipynb) and [evaluating our slim DO](https://github.com/dhimmel/disease-ontology/blob/75050ea2d4f60e745d3f3578ae03560a2cc0e444/slim.ipynb) [@10.5281/zenodo.45584].\r\n\r\nWe plan to propagate annotations from more specific terms to our slim terms. To facilitate this process, we created a [propagated DO slim xref mapping file](https://github.com/dhimmel/disease-ontology/blob/75050ea2d4f60e745d3f3578ae03560a2cc0e444/data/xrefs-prop-slim.tsv).\r\n\r\nPleural cancer (`DOID:9917`) was a TOPNodes_DOcancerslim term but was not found in the ontology version we downloaded (subversion revision 2810).",
      "comment_id": 144,
      "profile_id": 17,
      "published": "2015-04-17T18:45:07.422925Z",
      "thread_id": 44,
      "url": "/discussion/unifying-disease-vocabularies/44#6"
    },
    {
      "body_html": "<p>We mapped the MeSH diseases from the HSDN <span class=\"citation\">[<a href=\"https://doi.org/10.1038/ncomms5212\" class=\"citation\" data-key=\"10.1038/ncomms5212\">1</a>]</span> to <a href=\"http://thinklab.com/discussion/unifying-disease-vocabularies/44#144\">our slim DO</a>. See the <a href=\"https://cdn.rawgit.com/dhimmel/hsdn/51d31d738fe3cad0a12c736b8def333729c3c7f4/index.html\">notebook</a> for more info or download the <a href=\"https://raw.githubusercontent.com/dhimmel/hsdn/51d31d738fe3cad0a12c736b8def333729c3c7f4/data/symptoms-DO.tsv\">mapped data</a>.</p>\r\n\r\n<p>Each disease-symptom relationship includes a <code>tfidf_score</code> (term frequency-inverse document frequency). This score, <span class=\"math\">$$w_{i,j}$$</span>, between symptom <em>i</em> and disease <em>j</em> was calculated with:</p>\r\n\r\n<p></p><div class=\"math\">$$$\r\nw_{i,j} = W_{i,j} \\times \\log{\\frac{N}{n_i}}\r\n$$$</div>\r\n\r\n<p>where <span class=\"math\">$$W_{i,j}$$</span> is the number of co-occurrences in PubMed, <em>N</em> is the total number of diseases, and <span class=\"math\">$$n_i$$</span> is the number of diseases where symptom <em>i</em> appears.</p>\r\n\r\n<p>At some point we will set an inclusion threshold for symptom edges based on their <code>tfidf_score</code>.</p>\r\n\r\n<p>We used a propagated slim DO mapping, so symptoms for MeSH term \"relapsing-remitting multiple sclerosis\" for example were included as symptoms for DO term \"multiple sclerosis\".</p>",
      "body_md": "We mapped the MeSH diseases from the HSDN [@10.1038/ncomms5212] to [our slim DO](http://thinklab.com/discussion/unifying-disease-vocabularies/44#144). See the [notebook](https://cdn.rawgit.com/dhimmel/hsdn/51d31d738fe3cad0a12c736b8def333729c3c7f4/index.html) for more info or download the [mapped data](https://raw.githubusercontent.com/dhimmel/hsdn/51d31d738fe3cad0a12c736b8def333729c3c7f4/data/symptoms-DO.tsv).\r\n\r\nEach disease-symptom relationship includes a `tfidf_score` (term frequency-inverse document frequency). This score, $$w_{i,j}$$, between symptom *i* and disease *j* was calculated with:\r\n\r\n$$$\r\nw_{i,j} = W_{i,j} \\times \\log{\\frac{N}{n_i}}\r\n$$$\r\n\r\nwhere $$W_{i,j}$$ is the number of co-occurrences in PubMed, *N* is the total number of diseases, and $$n_i$$ is the number of diseases where symptom *i* appears.\r\n\r\nAt some point we will set an inclusion threshold for symptom edges based on their `tfidf_score`.\r\n\r\nWe used a propagated slim DO mapping, so symptoms for MeSH term \"relapsing-remitting multiple sclerosis\" for example were included as symptoms for DO term \"multiple sclerosis\".",
      "comment_id": 145,
      "profile_id": 17,
      "published": "2015-04-20T16:53:13.382327Z",
      "thread_id": 52,
      "url": "/discussion/human-symptom-disease-network-mesh-id-matching/52#2"
    },
    {
      "body_html": "<h1>PREDICT Indications</h1>\r\n\r\n<p>An existing computational repurposing approach called PREDICT <span class=\"citation\">[<a href=\"https://doi.org/10.1038/msb.2011.26\" class=\"citation\" data-key=\"10.1038/msb.2011.26\">1</a>]</span>, compiled indications for their analysis. They describe their approach as:</p>\r\n\r\n<blockquote><p>The associations between drugs and UMLS disease concepts were integrated from four different sources using three different methods: (i) direct mapping to drugs, exploiting embedded UMLS links between concepts and drugs; (ii) drug–condition associations downloaded from <a href=\"http://drugs.com\" target=\"_blank\">http://drugs.com</a>, where conditions were mapped to UMLS concepts using MetaMap; and (iii) indication‐based mapping. For the latter, we extracted UMLS concepts using the MetaMap tool from textual drug indications downloaded from FDA package inserts (available in the DailyMed website, <a href=\"http://dailymed.nlm.nih.gov\" target=\"_blank\">http://dailymed.nlm.nih.gov</a>) and DrugBank. In addition, we manually added 44 associations occurring in phase IV (post‐marketing) clinical trials.</p><p>... Finally, performing a manual curation of the extracted UMLS concepts from textual description of drug indications, we observed that they are more prone to false positives. We thus required that associations extracted from drug indications appear also in at least one more source.</p></blockquote>\r\n\r\n<p>Compounds are from DrugBank and diseases are from OMIM and the UMLS, which are both cross-referenced by the DO. The study does not report the precision of their indications making it difficult to assess how the quality compares with MEDI-HPS and LabeledIn.</p>\r\n\r\n<p>We combined the supplementary datasets from the study to create a table of PREDICT indications (<a href=\"http://git.dhimmel.com/indications/msb-predict/\">notebook</a>, <a href=\"http://git.dhimmel.com/indications/msb-predict/data/indications-umls.tsv\">download</a>). We will further investigate including these indications.</p>",
      "body_md": "# PREDICT Indications\r\n\r\nAn existing computational repurposing approach called PREDICT [@10.1038/msb.2011.26], compiled indications for their analysis. They describe their approach as:\r\n\r\n> The associations between drugs and UMLS disease concepts were integrated from four different sources using three different methods: (i) direct mapping to drugs, exploiting embedded UMLS links between concepts and drugs; (ii) drug–condition associations downloaded from http://drugs.com, where conditions were mapped to UMLS concepts using MetaMap; and (iii) indication‐based mapping. For the latter, we extracted UMLS concepts using the MetaMap tool from textual drug indications downloaded from FDA package inserts (available in the DailyMed website, http://dailymed.nlm.nih.gov) and DrugBank. In addition, we manually added 44 associations occurring in phase IV (post‐marketing) clinical trials.\r\n\r\n>... Finally, performing a manual curation of the extracted UMLS concepts from textual description of drug indications, we observed that they are more prone to false positives. We thus required that associations extracted from drug indications appear also in at least one more source.\r\n\r\nCompounds are from DrugBank and diseases are from OMIM and the UMLS, which are both cross-referenced by the DO. The study does not report the precision of their indications making it difficult to assess how the quality compares with MEDI-HPS and LabeledIn.\r\n\r\nWe combined the supplementary datasets from the study to create a table of PREDICT indications ([notebook](http://git.dhimmel.com/indications/msb-predict/), [download](http://git.dhimmel.com/indications/msb-predict/data/indications-umls.tsv)). We will further investigate including these indications.",
      "comment_id": 148,
      "profile_id": 17,
      "published": "2015-04-21T18:56:59.333381Z",
      "thread_id": 21,
      "url": "/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#17"
    },
    {
      "body_html": "<h1>Indication Set</h1>\r\n\r\n<p>Now that we have decided which <a href=\"http://thinklab.com/discussion/unifying-disease-vocabularies/44#144\">diseases</a> and <a href=\"http://thinklab.com/discussion/unifying-drug-vocabularies/40\">compounds</a> to include in the network, we can map indications onto these nodes.</p>\r\n\r\n<p>Our indication set contains four indication resources:</p>\r\n\r\n<ol><li>MEDI-HPS — indications from the MEDI's high precision subset</li><li>MEDI-LPS — indications from the MEDI's low precision subset</li><li>LabeledIn — drug label indications extracted by experts or Mechanical Turks</li><li>PREDICT — indications compiled by the PREDICT study</li></ol>\r\n\r\n<p>We anticipate constructing our gold standard of indications from MEDI-HPS, LabeledIn, and PREDICT while omitting MEDI-LPS, which has a lower precision. We did not include ehrlink <span class=\"citation\">[<a href=\"https://doi.org/10.1136/amiajnl-2012-000852\" class=\"citation\" data-key=\"10.1136/amiajnl-2012-000852\">1</a>]</span> because the vocabularies were not mapped. However, we would happily reward anyone who contributes a mapping of <a href=\"https://raw.githubusercontent.com/dhimmel/indications/f7ea9f9d932cf083c68cdb0395b474b215013280/ehrlink/data/problems.tsv\">the problems</a> to the DO and <a href=\"https://raw.githubusercontent.com/dhimmel/indications/f7ea9f9d932cf083c68cdb0395b474b215013280/ehrlink/data/medications.tsv\">the medications</a> to DrugBank.</p>\r\n\r\n<h3>Indication Links</h3>\r\n\r\n<ul><li><a href=\"https://cdn.rawgit.com/dhimmel/indications/f7ea9f9d932cf083c68cdb0395b474b215013280/merge.html\">analysis notebook</a> — includes a searchable table</li><li><a href=\"https://raw.githubusercontent.com/dhimmel/indications/f7ea9f9d932cf083c68cdb0395b474b215013280/data/indications.tsv\">data download</a> — tsv file</li></ul>\r\n\r\n<p>We would still like a way to differentiate disease-modifying from symptomatic indications and will explore manually classifying a subset of indications and training a model.</p>",
      "body_md": "# Indication Set\r\n\r\nNow that we have decided which [diseases](http://thinklab.com/discussion/unifying-disease-vocabularies/44#144) and [compounds](http://thinklab.com/discussion/unifying-drug-vocabularies/40) to include in the network, we can map indications onto these nodes.\r\n\r\nOur indication set contains four indication resources:\r\n\r\n1. MEDI-HPS -- indications from the MEDI's high precision subset\r\n2. MEDI-LPS -- indications from the MEDI's low precision subset\r\n2. LabeledIn -- drug label indications extracted by experts or Mechanical Turks\r\n3. PREDICT -- indications compiled by the PREDICT study\r\n\r\nWe anticipate constructing our gold standard of indications from MEDI-HPS, LabeledIn, and PREDICT while omitting MEDI-LPS, which has a lower precision. We did not include ehrlink [@10.1136/amiajnl-2012-000852] because the vocabularies were not mapped. However, we would happily reward anyone who contributes a mapping of [the problems](https://raw.githubusercontent.com/dhimmel/indications/f7ea9f9d932cf083c68cdb0395b474b215013280/ehrlink/data/problems.tsv) to the DO and [the medications](https://raw.githubusercontent.com/dhimmel/indications/f7ea9f9d932cf083c68cdb0395b474b215013280/ehrlink/data/medications.tsv) to DrugBank.\r\n\r\n### Indication Links\r\n\r\n+ [analysis notebook](https://cdn.rawgit.com/dhimmel/indications/f7ea9f9d932cf083c68cdb0395b474b215013280/merge.html) -- includes a searchable table\r\n+ [data download](https://raw.githubusercontent.com/dhimmel/indications/f7ea9f9d932cf083c68cdb0395b474b215013280/data/indications.tsv) -- tsv file\r\n\r\nWe would still like a way to differentiate disease-modifying from symptomatic indications and will explore manually classifying a subset of indications and training a model.",
      "comment_id": 149,
      "profile_id": 17,
      "published": "2015-04-21T21:54:58.762400Z",
      "thread_id": 21,
      "url": "/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#18"
    },
    {
      "body_html": "<p>Evolutionary rate covariation (ERC) assesses whether two genes have a similar evolutionary history. A recent study computed ERC values in humans and found that genes associated with the same disease were often tied together by similar evolutionary histories <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pgen.1004967\" class=\"citation\" data-key=\"10.1371/journal.pgen.1004967\">1</a>]</span>. The study based their gene sets on <a href=\"http://www.omim.org/\">OMIM</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkn665\" class=\"citation\" data-key=\"10.1093/nar/gkn665\">2</a>]</span>, which focuses on Mendelian genetics, so whether ERC prioritizes disease-associated genes for complex diseases in unclear. However, this resource is attractive as an orthogonal, systematic, and unbiased indicator of common gene functionality.</p>\r\n\r\n<p>We began working with the human data from the <a href=\"http://csb.pitt.edu/erc_analysis/Methods.php\">website</a>. First, we parsed the data, converted from a matrix format to a tidy pairwise format, and mapped the UCSC gene ids to Entrez Gene (<a href=\"http://nbviewer.ipython.org/github/dhimmel/erc/blob/c1f19cc70758a4d880881221697f49ab0f41ee10/erc.ipynb\">notebook</a>). Next, we collapsed the values by Entrez Gene pairs (<a href=\"https://github.com/dhimmel/erc/blob/c1f19cc70758a4d880881221697f49ab0f41ee10/entrez-group.R\">code</a>). Almost all UCSC–Entrez mappings were one-to-one, but in the case of many-to-one, we took the average correlation value.</p>\r\n\r\n<p>Our goal is to extract gene pairs that share an evolutionary history. ERC values are provided for all gene pairs with sufficient data, but we are only interested in the small subset of biologically-meaningful correlations. Here we consider using the ERC value as a threshold:</p>\r\n\r\n<h3>Figure 1. Distribution of ERC values</h3>\r\n\r\n<p><img src=\"https://raw.githubusercontent.com/dhimmel/erc/c1f19cc70758a4d880881221697f49ab0f41ee10/figure/erc-value-dist.png\" alt=\"\"></p>\r\n\r\n<h3>Figure 2. Probability of positive or negative sign given absolute ERC value</h3>\r\n\r\n<p><img src=\"https://raw.githubusercontent.com/dhimmel/erc/c1f19cc70758a4d880881221697f49ab0f41ee10/figure/erc-signed-dist.png\" alt=\"\"></p>\r\n\r\n<p>Assuming that dissimilar evolutionary histories are not present, we can use Figure 2 to select an ERC threshold. Assuming a symmetric null distribution, selecting a threshold of <code>ERC &gt; 0.75</code> would lead to a false discovery rate of approximately 10%. We can also take an empirical approach and optimize the threshold based on performance.</p>\r\n\r\n<p>We would appreciate any community feedback on rational thresholding techniques. Additionally, we may want to consider a separate edge for dissimilar evolutionary history — is that a meaningful concept?</p>",
      "body_md": "Evolutionary rate covariation (ERC) assesses whether two genes have a similar evolutionary history. A recent study computed ERC values in humans and found that genes associated with the same disease were often tied together by similar evolutionary histories [@10.1371/journal.pgen.1004967]. The study based their gene sets on [OMIM](http://www.omim.org/) [@10.1093/nar/gkn665], which focuses on Mendelian genetics, so whether ERC prioritizes disease-associated genes for complex diseases in unclear. However, this resource is attractive as an orthogonal, systematic, and unbiased indicator of common gene functionality.\r\n\r\nWe began working with the human data from the [website](http://csb.pitt.edu/erc_analysis/Methods.php). First, we parsed the data, converted from a matrix format to a tidy pairwise format, and mapped the UCSC gene ids to Entrez Gene ([notebook](http://nbviewer.ipython.org/github/dhimmel/erc/blob/c1f19cc70758a4d880881221697f49ab0f41ee10/erc.ipynb)). Next, we collapsed the values by Entrez Gene pairs ([code](https://github.com/dhimmel/erc/blob/c1f19cc70758a4d880881221697f49ab0f41ee10/entrez-group.R)). Almost all UCSC--Entrez mappings were one-to-one, but in the case of many-to-one, we took the average correlation value.\r\n\r\nOur goal is to extract gene pairs that share an evolutionary history. ERC values are provided for all gene pairs with sufficient data, but we are only interested in the small subset of biologically-meaningful correlations. Here we consider using the ERC value as a threshold:\r\n\r\n### Figure 1. Distribution of ERC values\r\n![](https://raw.githubusercontent.com/dhimmel/erc/c1f19cc70758a4d880881221697f49ab0f41ee10/figure/erc-value-dist.png)\r\n\r\n### Figure 2. Probability of positive or negative sign given absolute ERC value\r\n![](https://raw.githubusercontent.com/dhimmel/erc/c1f19cc70758a4d880881221697f49ab0f41ee10/figure/erc-signed-dist.png)\r\n\r\nAssuming that dissimilar evolutionary histories are not present, we can use Figure 2 to select an ERC threshold. Assuming a symmetric null distribution, selecting a threshold of `ERC > 0.75` would lead to a false discovery rate of approximately 10%. We can also take an empirical approach and optimize the threshold based on performance.\r\n\r\nWe would appreciate any community feedback on rational thresholding techniques. Additionally, we may want to consider a separate edge for dissimilar evolutionary history -- is that a meaningful concept?",
      "comment_id": 151,
      "profile_id": 17,
      "published": "2015-04-23T03:38:31.939487Z",
      "thread_id": 57,
      "url": "/discussion/selecting-informative-erc-evolutionary-rate-covariation-values-between-genes/57"
    },
    {
      "body_html": "<p>The above formula used to calculate <code>tfidf_score</code> adjusts for the frequency of the symptom, but not the frequency of disease. Therefore we speculate that the scores are comparable within but not across diseases. Since we want to adopt a single inclusion threshold for all symptom-disease pairs, we would like to reformulate the metric to adjust for disease frequency.</p>\r\n\r\n<p>We added a <a href=\"https://cdn.rawgit.com/dhimmel/hsdn/af2237af712be4b5319fa3669527e3fa1dbdfe44/index.html\">new visualization and table</a> to investigate a disease-frequency bias. It appears that diseases that occur in more PubMed records have a higher number of symptoms exceeding a given <code>tfidf_score</code>.</p>",
      "body_md": "The above formula used to calculate `tfidf_score` adjusts for the frequency of the symptom, but not the frequency of disease. Therefore we speculate that the scores are comparable within but not across diseases. Since we want to adopt a single inclusion threshold for all symptom-disease pairs, we would like to reformulate the metric to adjust for disease frequency.\r\n\r\nWe added a [new visualization and table](https://cdn.rawgit.com/dhimmel/hsdn/af2237af712be4b5319fa3669527e3fa1dbdfe44/index.html) to investigate a disease-frequency bias. It appears that diseases that occur in more PubMed records have a higher number of symptoms exceeding a given `tfidf_score`.",
      "comment_id": 167,
      "profile_id": 17,
      "published": "2015-04-28T22:43:19.909493Z",
      "thread_id": 52,
      "url": "/discussion/human-symptom-disease-network-mesh-id-matching/52#3"
    },
    {
      "body_html": "<p>Another paper by the same group <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004120\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1004120\">1</a>]</span> includes what I presume to be a subset of these diseases, so this mapping could be helpful there as well.</p>",
      "body_md": "Another paper by the same group [@10.1371/journal.pcbi.1004120] includes what I presume to be a subset of these diseases, so this mapping could be helpful there as well.\r\n",
      "comment_id": 168,
      "profile_id": 17,
      "published": "2015-04-29T00:21:16.730403Z",
      "thread_id": 42,
      "url": "/discussion/mapping-incomplete-interactome-disease-names-to-mesh/42#2"
    },
    {
      "body_html": "<p>Hi Daniel,</p>\r\n\r\n<p>I spend some time solving your problem about mapping the drug names from one arbitrary system to a known ontology. As a matter of fact RxNorm proposes an <a href=\"http://rxnav.nlm.nih.gov/RxNormAPIs.html#\">API</a> which has an <a href=\"http://rxnav.nlm.nih.gov/RxNormAPIs.html#uLink=RxNorm_REST_getApproximateMatch\">endpoint</a> that can directly be queried for fuzzy matching - so that's useful. It will be helpful to look into the different endpoints of the API down the road, they provide many useful features (though poorly documented).</p>\r\n\r\n<p>I <a href=\"https://github.com/antoine-lizee/RRxNorm\">wrote a script (in R)</a> to match all the medication names in your file and get the related properties of the retrieved Rx concepts. It took an hour + to run because of stalling to avoid going over API quotas. The fuzzy-matching API returns several rxcui matches for <em>each medication</em>. A score, ranging from 0 to 100, is attached to every match.</p>\r\n\r\n<p>The main output file can have several concepts per medication names if (i) there is <strong>ambiguity</strong>, i.e. there is more than one best match for a medication or (ii) the best match is <strong>imperfect</strong>, i.e. the best score is not 100 (then the first three are reported).<br>The <a href=\"https://raw.githubusercontent.com/antoine-lizee/RRxNorm/master/Output/unambiguousMatches.csv\">final output</a> is a subset of this file with only the huge majority of unambiguous hits (and we thus have one concept per medication string).</p>\r\n\r\n<p>Here are some numbers:<br> 1. Only 2353 medications got matched with a valid concept, out of 2537 initially. Some names don't correspond to any medication and are filtered out.<br> 2. From these 2353 matched medications, 2281 (97%) have an unambiguous first match. These are in the final output.<br> 3. These 2281 unambiguous hits match to a total of 2148 different rxcuis.<br> 4. 1490 (63%) medications have at least one perfect match, with 1471 (63%) being unambiguous.<br> 5. These 1471 unambiguous perfect hits match to a total of 1442 different rxcuis.</p>\r\n\r\n<p><strong>QC</strong> is straightforward by <a href=\"https://github.com/antoine-lizee/RRxNorm/blob/master/Output/unambiguousMatchesForQC.csv\">comparing</a> the original medication names and the retrieved name of each matched rxcui. I quickly checked and even the non-perfect matches (with a score different than 100) seems on point, at the exception of the \"therapies\" that have very few equivalents in RxNorm and definitely match to the wrong concept.</p>\r\n\r\n<p>Potential future directions:<br>1. Assess the quality of the matches through a systematic check based on the <a href=\"https://github.com/antoine-lizee/RRxNorm/blob/master/Output/unambiguousMatchesForQC.csv\">QC file</a> mentioned above. <br>2. Enrich the final dataset by resolving ambiguity from the term types reported in the rxcui properties.</p>",
      "body_md": "Hi Daniel,\r\n\r\nI spend some time solving your problem about mapping the drug names from one arbitrary system to a known ontology. As a matter of fact RxNorm proposes an [API](http://rxnav.nlm.nih.gov/RxNormAPIs.html#) which has an [endpoint](http://rxnav.nlm.nih.gov/RxNormAPIs.html#uLink=RxNorm_REST_getApproximateMatch) that can directly be queried for fuzzy matching - so that's useful. It will be helpful to look into the different endpoints of the API down the road, they provide many useful features (though poorly documented).\r\n\r\nI [wrote a script (in R)](https://github.com/antoine-lizee/RRxNorm) to match all the medication names in your file and get the related properties of the retrieved Rx concepts. It took an hour + to run because of stalling to avoid going over API quotas. The fuzzy-matching API returns several rxcui matches for *each medication*. A score, ranging from 0 to 100, is attached to every match.\r\n\r\nThe main output file can have several concepts per medication names if (i) there is **ambiguity**, i.e. there is more than one best match for a medication or (ii) the best match is **imperfect**, i.e. the best score is not 100 (then the first three are reported).\r\nThe [final output](https://raw.githubusercontent.com/antoine-lizee/RRxNorm/master/Output/unambiguousMatches.csv) is a subset of this file with only the huge majority of unambiguous hits (and we thus have one concept per medication string).\r\n\r\nHere are some numbers:\r\n 1. Only 2353 medications got matched with a valid concept, out of 2537 initially. Some names don't correspond to any medication and are filtered out.\r\n 2. From these 2353 matched medications, 2281 (97%) have an unambiguous first match. These are in the final output.\r\n 3. These 2281 unambiguous hits match to a total of 2148 different rxcuis.\r\n 4. 1490 (63%) medications have at least one perfect match, with 1471 (63%) being unambiguous.\r\n 5. These 1471 unambiguous perfect hits match to a total of 1442 different rxcuis.\r\n\r\n**QC** is straightforward by [comparing](https://github.com/antoine-lizee/RRxNorm/blob/master/Output/unambiguousMatchesForQC.csv) the original medication names and the retrieved name of each matched rxcui. I quickly checked and even the non-perfect matches (with a score different than 100) seems on point, at the exception of the \"therapies\" that have very few equivalents in RxNorm and definitely match to the wrong concept.\r\n\r\nPotential future directions:\r\n1. Assess the quality of the matches through a systematic check based on the [QC file](https://github.com/antoine-lizee/RRxNorm/blob/master/Output/unambiguousMatchesForQC.csv) mentioned above. \r\n2. Enrich the final dataset by resolving ambiguity from the term types reported in the rxcui properties.",
      "comment_id": 169,
      "profile_id": 23,
      "published": "2015-04-29T08:52:41.447548Z",
      "thread_id": 21,
      "url": "/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#19"
    },
    {
      "body_html": "<p><em>Below, I've copied the <a href=\"http://www.nature.com/ncomms/2014/140626/ncomms5212/extref/ncomms5212-s1.pdf\">supplementary methods section</a> from the HSDN <span class=\"citation\">[<a href=\"https://doi.org/10.1038/ncomms5212\" class=\"citation\" data-key=\"10.1038/ncomms5212\">1</a>]</span> describing how the literature mining was accomplished. I think a similar method could help us if we choose to perform our own <a href=\"http://thinklab.com/discussion/text-as-a-resource-for-network-population/48\">text mining</a> for network population.</em></p>\r\n\r\n<p>We use the Medical Subject Headings (MeSH) <span class=\"citation\">[<a href=\"https://doi.org/10.1001/jama.1994.03510380059038\" class=\"citation\" data-key=\"10.1001/jama.1994.03510380059038\">2</a>]</span> terminology to generate symptom-disease relationships from the metadata extracted from PubMed <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkl1031\" class=\"citation\" data-key=\"10.1093/nar/gkl1031\">3</a>]</span> bibliographic records. PubMed is currently the most comprehensive literature database on biomedical sciences. It includes MEDLINE <span class=\"citation\">[<a href=\"https://doi.org/10.3163/1536-5050.95.4.416\" class=\"citation\" data-key=\"10.3163/1536-5050.95.4.416\">4</a>]</span> and uses MeSH for each citation to facilitate information retrieval. MeSH is a controlled thesaurus that is used for the annotation of published articles, resulting in a high quality representation of their main topics and contributions. The MeSH terms are assigned manually by trained indexers and have been used in numerous biomedical text mining and literature-based discovery studies <span class=\"citation\">[<a href=\"https://doi.org/10.1038/ng895\" class=\"citation\" data-key=\"10.1038/ng895\">5</a>, <a href=\"https://doi.org/10.1093/bioinformatics/btr223\" class=\"citation\" data-key=\"10.1093/bioinformatics/btr223\">6</a>, <a href=\"https://doi.org/10.1002/asi.20438\" class=\"citation\" data-key=\"10.1002/asi.20438\">7</a>, <a href=\"https://doi.org/10.1038/nrg1768\" class=\"citation\" data-key=\"10.1038/nrg1768\">8</a>]</span>.</p>\r\n\r\n<p>We downloaded the <a href=\"http://www.nlm.nih.gov/mesh/2011/download/termscon.html\">2011 ASCII version of MeSH</a> that contains 26,142 distinct terms and their unified identifiers. The MeSH vocabulary is structured as a hierarchical tree with 16 top nodes, representing general categories, such as ‘Anatomy’, ‘Diseases’ and ‘Phenomena and Processes.’ The broad category ‘Diseases’ contains the sub-category ‘Symptoms and Signs’ (MeSH tree code C23.888) that incorporates terms related to clinical manifestations observed by physicians or perceived by patients. We used all terms contained in the ‘Disease’ category (Table S1), excluding ‘Animal diseases’, as well as twenty terms, which only represent unspecific disease information, such as ‘Diseases’ itself, ‘Syndrome’, ‘Chronic diseases’ and ‘Infection’. In total, we obtained 4,442 distinct MeSH disease terms and 327 distinct MeSH symptom terms to be used for the PubMed query. To ensure that we only retrieve records with the corresponding indexed disease terms as a major topic, we search MEDLINE with the constraint “[Majr:NoExp]”, which filters for bibliographic records with the study of a specific disease as a main contribution. Using the E-Utility API web service interface of the National Center for Biotechnology Information, we developed a JAVA program to automatically search all MEDLINE bibliographic records published between 1966 and October 2011 (Figure S4). The total number of corresponding PubMed records was 7,109,429, of which 6,553,494 included a disease and 1,405,038 a symptom term. The number of records that contain both a disease, as well as a symptom term was 849,103. They included all 4,442 MeSH disease terms and almost all (322, i.e. 98%) symptom terms.</p>\r\n\r\n<p><img src=\"https://raw.githubusercontent.com/dhimmel/hsdn/ca31229cf7174d8ee22567a455f386412a592144/figure/figS4.png\" alt=\"Figure S4 from the Human symptoms–disease network\"></p>",
      "body_md": "*Below, I've copied the [supplementary methods section](http://www.nature.com/ncomms/2014/140626/ncomms5212/extref/ncomms5212-s1.pdf) from the HSDN [@10.1038/ncomms5212] describing how the literature mining was accomplished. I think a similar method could help us if we choose to perform our own [text mining](http://thinklab.com/discussion/text-as-a-resource-for-network-population/48) for network population.*\r\n\r\nWe use the Medical Subject Headings (MeSH) [@10.1001/jama.1994.03510380059038] terminology to generate symptom-disease relationships from the metadata extracted from PubMed [@10.1093/nar/gkl1031] bibliographic records. PubMed is currently the most comprehensive literature database on biomedical sciences. It includes MEDLINE [@10.3163/1536-5050.95.4.416] and uses MeSH for each citation to facilitate information retrieval. MeSH is a controlled thesaurus that is used for the annotation of published articles, resulting in a high quality representation of their main topics and contributions. The MeSH terms are assigned manually by trained indexers and have been used in numerous biomedical text mining and literature-based discovery studies [@10.1038/ng895 @10.1093/bioinformatics/btr223 @10.1002/asi.20438 @10.1038/nrg1768].\r\n\r\nWe downloaded the [2011 ASCII version of MeSH](http://www.nlm.nih.gov/mesh/2011/download/termscon.html) that contains 26,142 distinct terms and their unified identifiers. The MeSH vocabulary is structured as a hierarchical tree with 16 top nodes, representing general categories, such as ‘Anatomy’, ‘Diseases’ and ‘Phenomena and Processes.’ The broad category ‘Diseases’ contains the sub-category ‘Symptoms and Signs’ (MeSH tree code C23.888) that incorporates terms related to clinical manifestations observed by physicians or perceived by patients. We used all terms contained in the ‘Disease’ category (Table S1), excluding ‘Animal diseases’, as well as twenty terms, which only represent unspecific disease information, such as ‘Diseases’ itself, ‘Syndrome’, ‘Chronic diseases’ and ‘Infection’. In total, we obtained 4,442 distinct MeSH disease terms and 327 distinct MeSH symptom terms to be used for the PubMed query. To ensure that we only retrieve records with the corresponding indexed disease terms as a major topic, we search MEDLINE with the constraint “[Majr:NoExp]”, which filters for bibliographic records with the study of a specific disease as a main contribution. Using the E-Utility API web service interface of the National Center for Biotechnology Information, we developed a JAVA program to automatically search all MEDLINE bibliographic records published between 1966 and October 2011 (Figure S4). The total number of corresponding PubMed records was 7,109,429, of which 6,553,494 included a disease and 1,405,038 a symptom term. The number of records that contain both a disease, as well as a symptom term was 849,103. They included all 4,442 MeSH disease terms and almost all (322, i.e. 98%) symptom terms.\r\n\r\n![Figure S4 from the Human symptoms–disease network](https://raw.githubusercontent.com/dhimmel/hsdn/ca31229cf7174d8ee22567a455f386412a592144/figure/figS4.png)",
      "comment_id": 176,
      "profile_id": 17,
      "published": "2015-04-30T20:51:53.215222Z",
      "thread_id": 52,
      "url": "/discussion/human-symptom-disease-network-mesh-id-matching/52#4"
    },
    {
      "body_html": "<p>We would like to convert from RxNorm medications to their ingredients. RxNorm is an ontology, with terms connected by <a href=\"http://www.nlm.nih.gov/research/umls/rxnorm/docs/2015/appendix1.html\">relationship types</a>, which can be traversed to map ingredients. This is necessary to <a href=\"http://thinklab.com/discussion/unifying-drug-vocabularies/40\">map RxNorm medications to DrugBank</a>, enabling network inclusion. Additionally, we need to know when medications map to multiple ingredients as we are excluding combination therapies for the time being. Once the mapping is complete, we can proceed with <a href=\"http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#169\">integrating the ehrlink resource</a>. This discussion will follow our attempts to map concepts to ingredients.</p>",
      "body_md": "We would like to convert from RxNorm medications to their ingredients. RxNorm is an ontology, with terms connected by [relationship types](http://www.nlm.nih.gov/research/umls/rxnorm/docs/2015/appendix1.html), which can be traversed to map ingredients. This is necessary to [map RxNorm medications to DrugBank](http://thinklab.com/discussion/unifying-drug-vocabularies/40), enabling network inclusion. Additionally, we need to know when medications map to multiple ingredients as we are excluding combination therapies for the time being. Once the mapping is complete, we can proceed with [integrating the ehrlink resource](http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#169). This discussion will follow our attempts to map concepts to ingredients.",
      "comment_id": 177,
      "profile_id": 17,
      "published": "2015-04-30T22:03:36.193097Z",
      "thread_id": 61,
      "url": "/discussion/retrieving-the-ingredients-in-rxnorm-concepts/61"
    },
    {
      "body_html": "<h1>RxNorm term types</h1>\r\n\r\n<p>RxNorm concepts each have a specified term type (<code>TTY</code>). RxNorm documentation is oftentimes difficult to navigate, so we provide definitions for <a href=\"http://rxnav.nlm.nih.gov/RxNormAPIs.html#uLink=RxNorm_REST_getTermTypes\">all term types</a> below. The descriptions are from <span class=\"citation\">[<a href=\"https://doi.org/10.1136/amiajnl-2011-000116\" class=\"citation\" data-key=\"10.1136/amiajnl-2011-000116\">1</a>]</span>, while definitions were found <a href=\"http://rxnav.nlm.nih.gov/RxNavViews.html\">here</a>.</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th><code>TTY</code></th><th>Definition</th><th>Description</th></tr></thead><tbody><tr><td><code>BN</code></td><td>brand name</td><td></td></tr><tr><td><code>BPCK</code></td><td>branded pack</td><td></td></tr><tr><td><code>DF</code></td><td>dose form</td><td></td></tr><tr><td><code>DFG</code></td><td>dose form group</td><td></td></tr><tr><td><code>GPCK</code></td><td>generic pack</td><td></td></tr><tr><td><code>IN</code></td><td>ingredient</td><td>The term type (TTY) indicating that this name is that of the substance represented in an RxNorm name responsible for the medicinal activity. Also, the name and the substance.</td></tr><tr><td><code>MIN</code></td><td>multiple ingredients</td><td>The TTY indicating that this name is that of the ingredients of a combination product represented in an RxNorm name, where those ingredients are responsible for the medicinal activity. Also, the name and the substances.</td></tr><tr><td><code>PIN</code></td><td>precise ingredient</td><td>The TTY indicating that this name is that of the substance, expressed more precisely as a salt or ester of the ingredient, represented in an RxNorm name. Also, the name and the substance expressed precisely.</td></tr><tr><td><code>SBD</code></td><td>branded drug</td><td>The TTY indicating that this name is the normalized name created for a branded clinical drug. The name consists of ingredient, strength, and dose form, followed by a brand name in square brackets. Also, the name and the product.</td></tr><tr><td><code>SBDC</code></td><td>branded drug component</td><td></td></tr><tr><td><code>SBDF</code></td><td>branded dose form</td><td></td></tr><tr><td><code>SBDG</code></td><td>branded dose form group</td><td></td></tr><tr><td><code>SCD</code></td><td>clinical drug</td><td></td></tr><tr><td><code>SCDC</code></td><td>clinical drug component</td><td></td></tr><tr><td><code>SCDF</code></td><td>clinical dose form</td><td></td></tr><tr><td><code>SCDG</code></td><td>clinical dose form group</td><td></td></tr></tbody></table>",
      "body_md": "# RxNorm term types\r\n\r\nRxNorm concepts each have a specified term type (`TTY`). RxNorm documentation is oftentimes difficult to navigate, so we provide definitions for [all term types](http://rxnav.nlm.nih.gov/RxNormAPIs.html#uLink=RxNorm_REST_getTermTypes) below. The descriptions are from [@10.1136/amiajnl-2011-000116], while definitions were found [here](http://rxnav.nlm.nih.gov/RxNavViews.html).\r\n\r\n| `TTY` | Definition | Description |\r\n|--------|----------|----------------|\r\n| `BN` | brand name |  |\r\n| `BPCK` | branded pack |  |\r\n| `DF` | dose form |  |\r\n| `DFG` | dose form group |  |\r\n| `GPCK` | generic pack |  |\r\n| `IN` | ingredient | The term type (TTY) indicating that this name is that of the substance represented in an RxNorm name responsible for the medicinal activity. Also, the name and the substance. |\r\n| `MIN` | multiple ingredients | The TTY indicating that this name is that of the ingredients of a combination product represented in an RxNorm name, where those ingredients are responsible for the medicinal activity. Also, the name and the substances. |\r\n| `PIN` | precise ingredient | The TTY indicating that this name is that of the substance, expressed more precisely as a salt or ester of the ingredient, represented in an RxNorm name. Also, the name and the substance expressed precisely. |\r\n| `SBD` | branded drug | The TTY indicating that this name is the normalized name created for a branded clinical drug. The name consists of ingredient, strength, and dose form, followed by a brand name in square brackets. Also, the name and the product. |\r\n| `SBDC` | branded drug component |  |\r\n| `SBDF` | branded dose form |  |\r\n| `SBDG` | branded dose form group |  |\r\n| `SCD` | clinical drug |  |\r\n| `SCDC` | clinical drug component |  |\r\n| `SCDF` | clinical dose form |  |\r\n| `SCDG` | clinical dose form group |  |",
      "comment_id": 178,
      "profile_id": 17,
      "published": "2015-04-30T22:04:16.067751Z",
      "thread_id": 61,
      "url": "/discussion/retrieving-the-ingredients-in-rxnorm-concepts/61#2"
    },
    {
      "body_html": "<h1>RxNorm API method</h1>\r\n\r\n<p>We found a method to retrieve ingredients using the <code>allrelated</code> <a href=\"http://rxnav.nlm.nih.gov/RxNormAPIs.html#uLink=RxNorm_REST_getAllRelatedInfo\">RxNorm API command</a>. An example query for rxcui <code>198440</code> looks like:</p>\r\n\r\n<p><code>http://rxnav.nlm.nih.gov/REST/rxcui/198440/allrelated</code></p>\r\n\r\n<p>Ingredients can be extracted from the returned xml with the following XPath query:</p>\r\n\r\n<p><code>./allRelatedGroup/conceptGroup[tty='IN']/conceptProperties</code></p>\r\n\r\n<p>We wrote a <a href=\"http://nbviewer.ipython.org/github/dhimmel/indications/blob/aa2405b1015be580a5452d5e318f8d3e72468713/ehrlink/rxnorm-ingredient-map.ipynb\">python script</a> to perform this operation on the ehrlink <span class=\"citation\">[<a href=\"https://doi.org/10.1136/amiajnl-2012-000852\" class=\"citation\" data-key=\"10.1136/amiajnl-2012-000852\">1</a>]</span> RxNorm medications <a href=\"http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#169\">mapped</a> by <a href=\"/u/alizee\" class=\"username\">@alizee</a>. The resulting ingredient map is available for <a href=\"https://raw.githubusercontent.com/dhimmel/indications/aa2405b1015be580a5452d5e318f8d3e72468713/ehrlink/data/rxnorm-as-ingredient.tsv\">download</a>.</p>",
      "body_md": "# RxNorm API method\r\n\r\nWe found a method to retrieve ingredients using the `allrelated` [RxNorm API command](http://rxnav.nlm.nih.gov/RxNormAPIs.html#uLink=RxNorm_REST_getAllRelatedInfo). An example query for rxcui `198440` looks like:\r\n\r\n`http://rxnav.nlm.nih.gov/REST/rxcui/198440/allrelated`\r\n\r\nIngredients can be extracted from the returned xml with the following XPath query:\r\n\r\n`./allRelatedGroup/conceptGroup[tty='IN']/conceptProperties`\r\n\r\nWe wrote a [python script](http://nbviewer.ipython.org/github/dhimmel/indications/blob/aa2405b1015be580a5452d5e318f8d3e72468713/ehrlink/rxnorm-ingredient-map.ipynb) to perform this operation on the ehrlink [@10.1136/amiajnl-2012-000852] RxNorm medications [mapped](http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#169) by @alizee. The resulting ingredient map is available for [download](https://raw.githubusercontent.com/dhimmel/indications/aa2405b1015be580a5452d5e318f8d3e72468713/ehrlink/data/rxnorm-as-ingredient.tsv).",
      "comment_id": 179,
      "profile_id": 17,
      "published": "2015-05-01T04:06:57.676423Z",
      "thread_id": 61,
      "url": "/discussion/retrieving-the-ingredients-in-rxnorm-concepts/61#3"
    },
    {
      "body_html": "<p>ehrlink is our name for a study where an EHR system prompted clinicians to report the problem that a medication was prescribed for <span class=\"citation\">[<a href=\"https://doi.org/10.1136/amiajnl-2012-000852\" class=\"citation\" data-key=\"10.1136/amiajnl-2012-000852\">1</a>]</span>. The resulting high-confidence set contained 11,166 problem-medication pairs with precision exceeding 95%. Thus far, the comments pertaining to ehrlink have been scattered, so this discussion is meant to consolidate and provide a home for further analysis.</p>\r\n\r\n<p>Here is the history of this <em>collaborative integration effort</em>:</p>\r\n\r\n<ol><li><a href=\"/u/b_good\" class=\"username\">@b_good</a> initially <a href=\"//thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#101\">suggested</a> the resource and located the data supplement.</li><li><a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a> converted the pdf data supplement to a tsv file (<a href=\"//thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#101\">comment</a>, <a href=\"http://nbviewer.ipython.org/github/dhimmel/indications/blob/gh-pages/ehrlink/convert-to-text.ipynb\">notebook</a>, <a href=\"//git.dhimmel.com/indications/ehrlink/download/amiajnl-2012-000852-s1.tsv\">download</a>).</li><li><a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a> <a href=\"http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#111\">determined</a> the identifiers were not from a standard terminology</li><li><a href=\"/u/allisonmccoy\" class=\"username\">@allisonmccoy</a> <a href=\"http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#116\">joined</a> the discussion, confirming the proprietary identifiers and providing additional related studies.</li><li><a href=\"/u/allisonmccoy\" class=\"username\">@allisonmccoy</a> and <a href=\"/u/TIOprea\" class=\"username\">@TIOprea</a> <a href=\"http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#119\">discussed</a> the reliability of the resource.</li><li><a href=\"/u/alizee\" class=\"username\">@alizee</a> mapped the medication terms from ehrlink to RxNorm (<a href=\"http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#169\">comment</a>, <a href=\"https://github.com/antoine-lizee/RRxNorm\">repository</a>).</li><li><a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a> mapped the RxNorm concepts matched by <a href=\"/u/alizee\" class=\"username\">@alizee</a> to RxNorm ingredients (<a href=\"//thinklab.com/discussion/retrieving-the-ingredients-in-rxnorm-concepts/61#179\">comment</a>, <a href=\"http://nbviewer.ipython.org/github/dhimmel/indications/blob/aa2405b1015be580a5452d5e318f8d3e72468713/ehrlink/rxnorm-ingredient-map.ipynb\">notebook</a>, <a href=\"https://raw.githubusercontent.com/dhimmel/indications/aa2405b1015be580a5452d5e318f8d3e72468713/ehrlink/data/rxnorm-as-ingredient.tsv\">download</a>).</li></ol>",
      "body_md": "ehrlink is our name for a study where an EHR system prompted clinicians to report the problem that a medication was prescribed for [@10.1136/amiajnl-2012-000852]. The resulting high-confidence set contained 11,166 problem-medication pairs with precision exceeding 95%. Thus far, the comments pertaining to ehrlink have been scattered, so this discussion is meant to consolidate and provide a home for further analysis.\r\n\r\nHere is the history of this *collaborative integration effort*:\r\n\r\n1. @b_good initially [suggested](//thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#101) the resource and located the data supplement.\r\n+ @dhimmel converted the pdf data supplement to a tsv file ([comment](//thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#101), [notebook](http://nbviewer.ipython.org/github/dhimmel/indications/blob/gh-pages/ehrlink/convert-to-text.ipynb), [download](//git.dhimmel.com/indications/ehrlink/download/amiajnl-2012-000852-s1.tsv)).\r\n+ @dhimmel [determined](http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#111) the identifiers were not from a standard terminology\r\n+ @allisonmccoy [joined](http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#116) the discussion, confirming the proprietary identifiers and providing additional related studies.\r\n+ @allisonmccoy and @TIOprea [discussed](http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#119) the reliability of the resource.\r\n+ @alizee mapped the medication terms from ehrlink to RxNorm ([comment](http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#169), [repository](https://github.com/antoine-lizee/RRxNorm)).\r\n+ @dhimmel mapped the RxNorm concepts matched by @alizee to RxNorm ingredients ([comment](//thinklab.com/discussion/retrieving-the-ingredients-in-rxnorm-concepts/61#179), [notebook](http://nbviewer.ipython.org/github/dhimmel/indications/blob/aa2405b1015be580a5452d5e318f8d3e72468713/ehrlink/rxnorm-ingredient-map.ipynb), [download](https://raw.githubusercontent.com/dhimmel/indications/aa2405b1015be580a5452d5e318f8d3e72468713/ehrlink/data/rxnorm-as-ingredient.tsv)).",
      "comment_id": 181,
      "profile_id": 17,
      "published": "2015-05-01T14:51:24.555126Z",
      "thread_id": 62,
      "url": "/discussion/extracting-indications-from-the-ehrlink-resource/62"
    },
    {
      "body_html": "<p>To go further on resolving ambiguities when retrieving concepts, I had to look up abbreviations of the TTY too. I had seen <a href=\"http://rxnav.nlm.nih.gov/RxNavViews.html\">the very useful link you mention above</a> from the RxNav documentation, but I finally used the more general ressource that is the MetaThesaurus of UMLS. <a href=\"http://www.nlm.nih.gov/research/umls/knowledge_sources/metathesaurus/release/abbreviations.html#mrdoc_TTY\">This page</a> lists all the abbreviations used in the Rx system.</p>\r\n\r\n<p>I <a href=\"https://github.com/antoine-lizee/RRxNorm/blob/master/getTTYs.R\">extracted</a> from this page the table with all the TTY abbreviations into a reusable <a href=\"https://github.com/antoine-lizee/RRxNorm/blob/master/Output/TTYInSourceAbbreviations.csv\">csv file</a>. It could be useful down the road to other people.</p>",
      "body_md": "To go further on resolving ambiguities when retrieving concepts, I had to look up abbreviations of the TTY too. I had seen [the very useful link you mention above](http://rxnav.nlm.nih.gov/RxNavViews.html) from the RxNav documentation, but I finally used the more general ressource that is the MetaThesaurus of UMLS. [This page](http://www.nlm.nih.gov/research/umls/knowledge_sources/metathesaurus/release/abbreviations.html#mrdoc_TTY) lists all the abbreviations used in the Rx system.\r\n\r\nI [extracted](https://github.com/antoine-lizee/RRxNorm/blob/master/getTTYs.R) from this page the table with all the TTY abbreviations into a reusable [csv file](https://github.com/antoine-lizee/RRxNorm/blob/master/Output/TTYInSourceAbbreviations.csv). It could be useful down the road to other people.",
      "comment_id": 183,
      "profile_id": 23,
      "published": "2015-05-01T20:00:14.399789Z",
      "thread_id": 61,
      "url": "/discussion/retrieving-the-ingredients-in-rxnorm-concepts/61#4"
    },
    {
      "body_html": "<h1>Mapping ehrlink diseases to the DO</h1>\r\n\r\n<p>The ehrlink high-confidence set contains indications for 1,596 problems (<a href=\"https://raw.githubusercontent.com/dhimmel/indications/968bd8c947fe045a56caefb9f08182dea6e20662/ehrlink/data/problems.tsv\">download</a>). We used a simplistic string matching scheme to map these terms to the disease ontology. Lowercase ehrlink problem names were matched to lowercase DO names and synonyms (<a href=\"http://nbviewer.ipython.org/github/dhimmel/indications/blob/968bd8c947fe045a56caefb9f08182dea6e20662/ehrlink/problem-map.ipynb\">notebook</a>, <a href=\"https://raw.githubusercontent.com/dhimmel/indications/968bd8c947fe045a56caefb9f08182dea6e20662/ehrlink/data/problem-to-doid.tsv\">results</a>).</p>\r\n\r\n<p><code>22.9% = 365 / 1596</code> of the ehrlink problems mapped to the disease ontology. Of the 137 DO slim terms, 50 had a matching ehrlink problem. When we include propagated matching to DO slim terms, 5 additional diseases get matched. While these recall numbers appear low, we do recover a decent extent of the major complex diseases with few to no false positives.</p>",
      "body_md": "# Mapping ehrlink diseases to the DO\r\n\r\nThe ehrlink high-confidence set contains indications for 1,596 problems ([download](https://raw.githubusercontent.com/dhimmel/indications/968bd8c947fe045a56caefb9f08182dea6e20662/ehrlink/data/problems.tsv)). We used a simplistic string matching scheme to map these terms to the disease ontology. Lowercase ehrlink problem names were matched to lowercase DO names and synonyms ([notebook](http://nbviewer.ipython.org/github/dhimmel/indications/blob/968bd8c947fe045a56caefb9f08182dea6e20662/ehrlink/problem-map.ipynb), [results](https://raw.githubusercontent.com/dhimmel/indications/968bd8c947fe045a56caefb9f08182dea6e20662/ehrlink/data/problem-to-doid.tsv)).\r\n\r\n`22.9% = 365 / 1596` of the ehrlink problems mapped to the disease ontology. Of the 137 DO slim terms, 50 had a matching ehrlink problem. When we include propagated matching to DO slim terms, 5 additional diseases get matched. While these recall numbers appear low, we do recover a decent extent of the major complex diseases with few to no false positives.",
      "comment_id": 184,
      "profile_id": 17,
      "published": "2015-05-01T22:18:31.017689Z",
      "thread_id": 62,
      "url": "/discussion/extracting-indications-from-the-ehrlink-resource/62#2"
    },
    {
      "body_html": "<p>UPDATE:<br>I went forward on resolving the ambiguity, using the term source in type, and then the number of \"atoms\" that matches each medication name. </p>\r\n\r\n<p>This brings down the number of remaining ambiguity from 72 to 11 medications (0.5%).</p>\r\n\r\n<p>I understand you want to extract the ingredients from these concepts, so it doesn't necessarily matter that there are two \"top\" matches for one medication after trying to resolve ambiguity (both will likely lead to the same components). As a result I created both the file for the <a href=\"https://raw.githubusercontent.com/antoine-lizee/RRxNorm/master/Output/resolvedMatches.csv\">successfully resolved matches</a>, and the <a href=\"https://raw.githubusercontent.com/antoine-lizee/RRxNorm/master/Output/allResolvedMatches.csv\">file for all the best matches after trying to resolve them</a>. The latter has 100% of the medications, including the 11 ambiguous, for which I took arbitrarily one of the top concepts. This is the file you'll want to work off in the future.</p>\r\n\r\n<p>I also created the <a href=\"https://github.com/antoine-lizee/RRxNorm/blob/master/Output/resolvedMatchesForQC.csv\">QC file</a> for the ambiguity resolution step.</p>",
      "body_md": "UPDATE:\r\nI went forward on resolving the ambiguity, using the term source in type, and then the number of \"atoms\" that matches each medication name. \r\n\r\nThis brings down the number of remaining ambiguity from 72 to 11 medications (0.5%).\r\n\r\nI understand you want to extract the ingredients from these concepts, so it doesn't necessarily matter that there are two \"top\" matches for one medication after trying to resolve ambiguity (both will likely lead to the same components). As a result I created both the file for the [successfully resolved matches](https://raw.githubusercontent.com/antoine-lizee/RRxNorm/master/Output/resolvedMatches.csv), and the [file for all the best matches after trying to resolve them](https://raw.githubusercontent.com/antoine-lizee/RRxNorm/master/Output/allResolvedMatches.csv). The latter has 100% of the medications, including the 11 ambiguous, for which I took arbitrarily one of the top concepts. This is the file you'll want to work off in the future.\r\n\r\nI also created the [QC file](https://github.com/antoine-lizee/RRxNorm/blob/master/Output/resolvedMatchesForQC.csv) for the ambiguity resolution step.",
      "comment_id": 185,
      "profile_id": 23,
      "published": "2015-05-03T20:54:06.377956Z",
      "thread_id": 21,
      "url": "/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#20"
    },
    {
      "body_html": "<h1>Mapping ehrlink to DO and RxNorm ingredient terms</h1>\r\n\r\n<p>We created a version of ehrlink with the subset problem-medication pairs that mapped to standardized terminologies (<a href=\"https://cdn.rawgit.com/dhimmel/indications/169dd2bb5f1a77f7cd54f1b7d6181f914f666e89/ehrlink/index.html\">notebook</a>, <a href=\"https://raw.githubusercontent.com/dhimmel/indications/169dd2bb5f1a77f7cd54f1b7d6181f914f666e89/ehrlink/data/indications.tsv\">download</a>). We converted problems to DO terms (<a href=\"#184\">see above</a>). Then we converted medications to RxNorm concepts, using the <a href=\"http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#185\">mapping</a> produced by <a href=\"/u/alizee\" class=\"username\">@alizee</a>. We excluded any RxNorm matches with <code>score &lt; 55</code> as errors were observed below this threshold. Overall, the RxNorm <code>approximateTerm</code> <a href=\"http://rxnav.nlm.nih.gov/RxNormAPIs.html#uLink=RxNorm_REST_getApproximateMatch\">function of the API</a> performed impressively. Next we converted RxNorm concepts into their active ingredients and restricted to single-ingredient medications.</p>\r\n\r\n<p><code>33.3% = 3719 / 11166</code> of the original problem-medication pairs successfully mapped to an ingredient and DO term. Users should take note that our mapping procedure was motivated by precision and automation, rather than recall.</p>",
      "body_md": "# Mapping ehrlink to DO and RxNorm ingredient terms\r\n\r\nWe created a version of ehrlink with the subset problem-medication pairs that mapped to standardized terminologies ([notebook](https://cdn.rawgit.com/dhimmel/indications/169dd2bb5f1a77f7cd54f1b7d6181f914f666e89/ehrlink/index.html), [download](https://raw.githubusercontent.com/dhimmel/indications/169dd2bb5f1a77f7cd54f1b7d6181f914f666e89/ehrlink/data/indications.tsv)). We converted problems to DO terms ([see above](#184)). Then we converted medications to RxNorm concepts, using the [mapping](http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#185) produced by @alizee. We excluded any RxNorm matches with `score < 55` as errors were observed below this threshold. Overall, the RxNorm `approximateTerm` [function of the API](http://rxnav.nlm.nih.gov/RxNormAPIs.html#uLink=RxNorm_REST_getApproximateMatch) performed impressively. Next we converted RxNorm concepts into their active ingredients and restricted to single-ingredient medications.\r\n\r\n`33.3% = 3719 / 11166` of the original problem-medication pairs successfully mapped to an ingredient and DO term. Users should take note that our mapping procedure was motivated by precision and automation, rather than recall.",
      "comment_id": 190,
      "profile_id": 17,
      "published": "2015-05-05T01:11:23.690583Z",
      "thread_id": 62,
      "url": "/discussion/extracting-indications-from-the-ehrlink-resource/62#3"
    },
    {
      "body_html": "<h1>Revised indications which include ehrlink</h1>\r\n\r\n<p>We were able to <a href=\"//thinklab.com/discussion/extracting-indications-from-the-ehrlink-resource/62#190\">collaboratively map</a> ehrlink to RxNorm and the DO.</p>\r\n\r\n<p>Our indication catalog, which only includes DO slim diseases and approved small molecules in DrugBank, now contains:</p>\r\n\r\n<ul><li>1,386 high-confidence indications retrieved from MEDI-HPS <span class=\"citation\">[<a href=\"https://doi.org/10.1136/amiajnl-2012-001431\" class=\"citation\" data-key=\"10.1136/amiajnl-2012-001431\">1</a>]</span>, LabeledIn <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.jbi.2014.08.004\" class=\"citation\" data-key=\"10.1016/j.jbi.2014.08.004\">2</a>, <a href=\"https://doi.org/10.1093/database/bav016\" class=\"citation\" data-key=\"10.1093/database/bav016\">3</a>]</span>, PREDICT <span class=\"citation\">[<a href=\"https://doi.org/10.1038/msb.2011.26\" class=\"citation\" data-key=\"10.1038/msb.2011.26\">4</a>]</span>, and ehrlink <span class=\"citation\">[<a href=\"https://doi.org/10.1136/amiajnl-2012-000852\" class=\"citation\" data-key=\"10.1136/amiajnl-2012-000852\">5</a>]</span> covering 96 diseases and 602 compounds</li><li>1,113 low-confidence indications retrieved from MEDI-LPS <span class=\"citation\">[<a href=\"https://doi.org/10.1136/amiajnl-2012-001431\" class=\"citation\" data-key=\"10.1136/amiajnl-2012-001431\">1</a>]</span></li></ul>\r\n\r\n<p>The combined high and low-confidence indication set covers 107 diseases and 744 compounds. For more information see the <a href=\"https://cdn.rawgit.com/dhimmel/indications/36f0c5f143618abbbf8c9eb94b7318cb5936fd61/merge.html\">notebook</a>, table of <a href=\"https://github.com/dhimmel/indications/blob/36f0c5f143618abbbf8c9eb94b7318cb5936fd61/data/indications-with-source.tsv\">indications with resource info</a>, or table of <a href=\"https://github.com/dhimmel/indications/blob/36f0c5f143618abbbf8c9eb94b7318cb5936fd61/data/indications.tsv\">collapsed indications</a>.</p>",
      "body_md": "# Revised indications which include ehrlink\r\n\r\nWe were able to [collaboratively map](//thinklab.com/discussion/extracting-indications-from-the-ehrlink-resource/62#190) ehrlink to RxNorm and the DO.\r\n\r\nOur indication catalog, which only includes DO slim diseases and approved small molecules in DrugBank, now contains:\r\n\r\n+ 1,386 high-confidence indications retrieved from MEDI-HPS [@10.1136/amiajnl-2012-001431], LabeledIn [@10.1016/j.jbi.2014.08.004 @10.1093/database/bav016], PREDICT [@10.1038/msb.2011.26], and ehrlink [@10.1136/amiajnl-2012-000852] covering 96 diseases and 602 compounds\r\n+ 1,113 low-confidence indications retrieved from MEDI-LPS [@10.1136/amiajnl-2012-001431]\r\n\r\nThe combined high and low-confidence indication set covers 107 diseases and 744 compounds. For more information see the [notebook](https://cdn.rawgit.com/dhimmel/indications/36f0c5f143618abbbf8c9eb94b7318cb5936fd61/merge.html), table of [indications with resource info](https://github.com/dhimmel/indications/blob/36f0c5f143618abbbf8c9eb94b7318cb5936fd61/data/indications-with-source.tsv), or table of [collapsed indications](https://github.com/dhimmel/indications/blob/36f0c5f143618abbbf8c9eb94b7318cb5936fd61/data/indications.tsv).",
      "comment_id": 191,
      "profile_id": 17,
      "published": "2015-05-05T05:16:58.441919Z",
      "thread_id": 21,
      "url": "/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#21"
    },
    {
      "body_html": "<h1>Compound Vocabulary</h1>\r\n\r\n<p>We have proceeded with a subset of 1,552 terms from DrugBank <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkt1068\" class=\"citation\" data-key=\"10.1093/nar/gkt1068\">1</a>]</span> as our compound vocabulary. <a href=\"https://github.com/dhimmel/drugbank/blob/503968ed700257215f7c81137d29f86ab71e7ac4/data/drugbank-slim.tsv\">Included compounds</a> meet the following criteria:</p>\r\n\r\n<ul><li>DrugBank type is <code>small molecule</code></li><li>DrugBank groups includes <code>approved</code></li><li>Have an InChI chemical structure</li></ul>\r\n\r\n<p>Other compound vocabularies are mapped to DrugBank with UniChem <span class=\"citation\">[<a href=\"https://doi.org/10.1186/s13321-014-0043-5\" class=\"citation\" data-key=\"10.1186/s13321-014-0043-5\">2</a>]</span> using the most permissive matching scheme <a href=\"https://www.ebi.ac.uk/unichem/info/widesearchInfo\">available</a> (<code>B = 0</code> and <code>C = 4</code>). <code>B = 0</code> matches compounds using the FIKHB (First InChIKey Hash Block) which is based on atomic connectivity <span class=\"citation\">[<a href=\"https://doi.org/10.1186/1758-2946-5-7\" class=\"citation\" data-key=\"10.1186/1758-2946-5-7\">3</a>]</span>. <code>C = 4</code> matches compounds which share a component with a component of the DrugBank compound, in order to ignore differences based on salts and acids.</p>",
      "body_md": "# Compound Vocabulary\r\n\r\nWe have proceeded with a subset of 1,552 terms from DrugBank [@10.1093/nar/gkt1068] as our compound vocabulary. [Included compounds](https://github.com/dhimmel/drugbank/blob/503968ed700257215f7c81137d29f86ab71e7ac4/data/drugbank-slim.tsv) meet the following criteria:\r\n\r\n+ DrugBank type is `small molecule`\r\n+ DrugBank groups includes `approved`\r\n+ Have an InChI chemical structure\r\n\r\nOther compound vocabularies are mapped to DrugBank with UniChem [@10.1186/s13321-014-0043-5] using the most permissive matching scheme [available](https://www.ebi.ac.uk/unichem/info/widesearchInfo) (`B = 0` and `C = 4`). `B = 0` matches compounds using the FIKHB (First InChIKey Hash Block) which is based on atomic connectivity [@10.1186/1758-2946-5-7]. `C = 4` matches compounds which share a component with a component of the DrugBank compound, in order to ignore differences based on salts and acids.",
      "comment_id": 192,
      "profile_id": 17,
      "published": "2015-05-05T05:23:16.481212Z",
      "thread_id": 40,
      "url": "/discussion/unifying-drug-vocabularies/40#5"
    },
    {
      "body_html": "<p>We talked to Dave and Ted at the LINCS office hours today. Here are the meeting notes:</p>\r\n\r\n<h2>Probes and genes</h2>\r\n\r\n<p>There have been two versions of landmark genes (the genes that are measured by the L1000 platform). In the first version (<code>pr_pool_id = 'deltap'</code>), there were 979 landmark genes. In the current version (<code>pr_pool_id = 'epsilon'</code>), there are 978.</p>\r\n\r\n<p>The L1000 platform is designed to imitate the Affymetrix HG-U133A array <span class=\"citation\">[<a href=\"https://doi.org/10.1186/gb-2006-7-7-r61\" class=\"citation\" data-key=\"10.1186/gb-2006-7-7-r61\">1</a>]</span>, so L1000 output is in probe-space. The LINCS team performs their analyses in probe-space. For landmark genes, the probe-to-gene correspondence is one-to-one. However, other genes may consist of multiple probes. We plan to average z-scores across probes to convert our observations into gene-space.</p>\r\n\r\n<h2>Computing consensus signatures</h2>\r\n\r\n<p>When drugs have multiple signatures, we find the average correlation value for each signature. We have noticed that some signatures have negative correlations and were thus contributing their inverse signature to the consensus. We are uncomfortable with negative weights and therefore plan to set a minimum correlation threshold for each signature. A minimum of <code>0</code> would exclude all negatively correlated signatures. Another option is <code>0.1</code>, which is used by the LINCS team when processing shRNA data.</p>\r\n\r\n<h1>Miscellaneous</h1>\r\n\r\n<ul><li>The API returns <code>-666</code> for missing values.</li><li>Instances refer to the replicates that compose a signature.</li><li><a href=\"/u/leobrueggeman\" class=\"username\">@leobrueggeman</a>, will be presenting on LINCS at lab meeting today (<a href=\"http://slides.com/leoo/lincs\">presentation</a>).</li><li><code>is_summly</code> refers to whether a perturbagen has been profiled across a broad range of cell lines.</li></ul>",
      "body_md": "We talked to Dave and Ted at the LINCS office hours today. Here are the meeting notes:\r\n\r\n## Probes and genes\r\n\r\nThere have been two versions of landmark genes (the genes that are measured by the L1000 platform). In the first version (`pr_pool_id = 'deltap'`), there were 979 landmark genes. In the current version (`pr_pool_id = 'epsilon'`), there are 978.\r\n\r\nThe L1000 platform is designed to imitate the Affymetrix HG-U133A array [@10.1186/gb-2006-7-7-r61], so L1000 output is in probe-space. The LINCS team performs their analyses in probe-space. For landmark genes, the probe-to-gene correspondence is one-to-one. However, other genes may consist of multiple probes. We plan to average z-scores across probes to convert our observations into gene-space.\r\n\r\n## Computing consensus signatures\r\n\r\nWhen drugs have multiple signatures, we find the average correlation value for each signature. We have noticed that some signatures have negative correlations and were thus contributing their inverse signature to the consensus. We are uncomfortable with negative weights and therefore plan to set a minimum correlation threshold for each signature. A minimum of `0` would exclude all negatively correlated signatures. Another option is `0.1`, which is used by the LINCS team when processing shRNA data.\r\n\r\n# Miscellaneous\r\n\r\n+ The API returns `-666` for missing values.\r\n+ Instances refer to the replicates that compose a signature.\r\n+ @leobrueggeman, will be presenting on LINCS at lab meeting today ([presentation](http://slides.com/leoo/lincs)).\r\n+ `is_summly` refers to whether a perturbagen has been profiled across a broad range of cell lines.",
      "comment_id": 203,
      "profile_id": 17,
      "published": "2015-05-07T18:39:43.748862Z",
      "thread_id": 43,
      "url": "/discussion/computing-consensus-transcriptional-profiles-for-lincs-l1000-perturbations/43#4"
    },
    {
      "body_html": "<h2>Background reading on Gene Ontology annotations</h2>\r\n\r\n<ol><li>Gene Ontology Annotations and Resources <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gks1050\" class=\"citation\" data-key=\"10.1093/nar/gks1050\">1</a>]</span></li><li>Use and misuse of the gene ontology annotations <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nrg2363\" class=\"citation\" data-key=\"10.1038/nrg2363\">2</a>]</span></li><li>Understanding how and why the Gene Ontology and its annotations evolve: the GO within UniProt <span class=\"citation\">[<a href=\"https://doi.org/10.1186/2047-217X-3-4\" class=\"citation\" data-key=\"10.1186/2047-217X-3-4\">3</a>]</span></li><li>Quality of Computationally Inferred Gene Ontology Annotations <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1002533\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1002533\">4</a>]</span></li></ol>\r\n\r\n<h3>Updates</h3>\r\n\r\n<ul><li><a href=\"http://arxiv.org/abs/1602.01876\" title=\"arXiv\">Primer on the Gene Ontology</a></li><li><a href=\"http://arxiv.org/abs/1602.01875\" title=\"arXiv\">Gene Ontology: Pitfalls, Biases, Remedies</a></li></ul>",
      "body_md": "## Background reading on Gene Ontology annotations\r\n\r\n1. Gene Ontology Annotations and Resources [@10.1093/nar/gks1050]\r\n+ Use and misuse of the gene ontology annotations [@10.1038/nrg2363]\r\n+ Understanding how and why the Gene Ontology and its annotations evolve: the GO within UniProt [@10.1186/2047-217X-3-4]\r\n+ Quality of Computationally Inferred Gene Ontology Annotations [@10.1371/journal.pcbi.1002533]\r\n\r\n### Updates\r\n\r\n+ [Primer on the Gene Ontology](http://arxiv.org/abs/1602.01876 \"arXiv\")\r\n+ [Gene Ontology: Pitfalls, Biases, Remedies](http://arxiv.org/abs/1602.01875 \"arXiv\")",
      "comment_id": 206,
      "profile_id": 17,
      "published": "2015-05-08T18:06:54.819989Z",
      "thread_id": 39,
      "url": "/discussion/compiling-gene-ontology-annotations-into-an-easy-to-use-format/39#2"
    },
    {
      "body_html": "<p>We have proceeded with Entrez Gene for gene identification.</p>\r\n\r\n<p><a href=\"/u/caseygreene\" class=\"username\">@caseygreene</a>, do you have any advice or information on how to build the SQL database? I found <a href=\"http://jura.wi.mit.edu/entrez_gene/\">this site</a> which provides instructions and Perl scripts. Do you use the same <a href=\"http://jura.wi.mit.edu/entrez_gene/entrez_gene.pdf\">schema</a>?</p>",
      "body_md": "We have proceeded with Entrez Gene for gene identification.\r\n\r\n@caseygreene, do you have any advice or information on how to build the SQL database? I found [this site](http://jura.wi.mit.edu/entrez_gene/) which provides instructions and Perl scripts. Do you use the same [schema](http://jura.wi.mit.edu/entrez_gene/entrez_gene.pdf)?",
      "comment_id": 207,
      "profile_id": 17,
      "published": "2015-05-08T18:58:07.489475Z",
      "thread_id": 34,
      "url": "/discussion/using-entrez-gene-as-our-gene-vocabulary/34#3"
    },
    {
      "body_html": "<p>We have done it a couple of ways. Currently we like to We have an EntrezID field that's an index, a systematic name that's an index (if you're human, this is HGNC identifiers), standard name (you won't need this for human only), the gene description, a foreign key to the organism (again, if only human, won't need this), the aliases (space separated list of previous/alternative names — used only for full text search), whether or not the gene is now obsolete (used during updates), and a few other things that we use for search.</p>\r\n\r\n<p>For other identifiers, we have a table of cross reference databases, which has a name (index) and a url. URL has characters in it that signify that the ID for the database is supposed to go there.</p>\r\n\r\n<p>We then have a table of cross references, which has foreign keys to both the cross reference database and gene, as well as a cross reference id (also db index).</p>\r\n\r\n<p>If you want python code to generate this and/or load identifiers using the Django ORM, we can supply it. We might also be able to open source it as part of a pip installable django app on pypi. This is on our to-do list, so we could potentially reprioritize if this is particularly useful to you.</p>",
      "body_md": "We have done it a couple of ways. Currently we like to We have an EntrezID field that's an index, a systematic name that's an index (if you're human, this is HGNC identifiers), standard name (you won't need this for human only), the gene description, a foreign key to the organism (again, if only human, won't need this), the aliases (space separated list of previous/alternative names -- used only for full text search), whether or not the gene is now obsolete (used during updates), and a few other things that we use for search.\r\n\r\nFor other identifiers, we have a table of cross reference databases, which has a name (index) and a url. URL has characters in it that signify that the ID for the database is supposed to go there.\r\n\r\nWe then have a table of cross references, which has foreign keys to both the cross reference database and gene, as well as a cross reference id (also db index).\r\n\r\nIf you want python code to generate this and/or load identifiers using the Django ORM, we can supply it. We might also be able to open source it as part of a pip installable django app on pypi. This is on our to-do list, so we could potentially reprioritize if this is particularly useful to you.",
      "comment_id": 208,
      "profile_id": 22,
      "published": "2015-05-08T19:43:12.982725Z",
      "thread_id": 34,
      "url": "/discussion/using-entrez-gene-as-our-gene-vocabulary/34#4"
    },
    {
      "body_html": "<p><a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a> I'd add this as particularly important for GO as well: <a href=\"http://wiki.geneontology.org/index.php/Transitive_closure\" target=\"_blank\">http://wiki.geneontology.org/index.php/Transitive_closure</a></p>\r\n\r\n<p>People frequently overlook this.</p>",
      "body_md": "@dhimmel I'd add this as particularly important for GO as well: http://wiki.geneontology.org/index.php/Transitive_closure\r\n\r\nPeople frequently overlook this.",
      "comment_id": 209,
      "profile_id": 22,
      "published": "2015-05-08T19:46:56.057944Z",
      "thread_id": 39,
      "url": "/discussion/compiling-gene-ontology-annotations-into-an-easy-to-use-format/39#3"
    },
    {
      "body_html": "<p>DrugBank <a href=\"http://www.drugbank.ca/documentation\">contains</a> four types of drug-protein interactions:</p>\r\n\r\n<ul><li><strong>Target</strong>: A protein, macromolecule, nucleic acid, or small molecule to which a given drug binds, resulting in an alteration of the normal function of the bound molecule anda desirable therapeutic effect. Drug targets are most commonly proteins such as enzymes, ion channels, and receptors.</li><li><strong>Enzyme</strong>: A protein which catalyzes chemical reactions involving the a given drug (substrate). Most drugs are metabolized by the Cytochrome P450 enzymes.</li><li><strong>Transporter</strong>: A membrane bound protein which shuttles ions, small molecules or macromolecules across membranes, into cells or out of cells.</li><li><strong>Carrier</strong>: A secreted protein which binds to drugs, carrying them to cell transporters, where they are moved into the cell. Drug carriers may be used in drug design to increase the effectiveness of drug delivery to the target sites of pharmacological actions.</li></ul>\r\n\r\n<p>We extracted DrugBank-protein interactions (<a href=\"http://nbviewer.ipython.org/github/dhimmel/drugbank/blob/22d835b3cd0ed421c18f855a85a183a9c1349e8f/parse.ipynb\">notebook</a>, <a href=\"https://raw.githubusercontent.com/dhimmel/drugbank/22d835b3cd0ed421c18f855a85a183a9c1349e8f/data/proteins.tsv\">download</a>). Our resource includes all DrugBank interactions that met the following criteria:</p>\r\n\r\n<ol><li>The interaction is between a drug and <em>single</em> protein. A target which is \"protein group\" and contains multiple uniprot proteins would be excluded. Examples include the <a href=\"//www.drugbank.ca/biodb/bio_entities/BE0004797\">GABA-A receptor (anion channel)</a> and <a href=\"//www.drugbank.ca/biodb/bio_entities/BE0004956\">NMDA receptor</a>. Likewise, a target which is not a protein, such as <a href=\"//www.drugbank.ca/biodb/bio_entities/BE0004796\">DNA</a> or <a href=\"//www.drugbank.ca/biodb/bio_entities/BE0004815\">Phosphate</a>, would be excluded.</li><li>The protein maps to an entrez gene. Some uniprot proteins did not such as <a href=\"//www.uniprot.org/uniprot/Q7ZJM1\">Q7ZJM1</a>, <a href=\"//www.uniprot.org/uniprot/Q59GM9\">Q59GM9</a>, and <a href=\"//www.uniprot.org/uniprot/Q53ET4\">Q53ET4</a> — all TrEMBL (unreviewed) terms with low <a href=\"http://www.uniprot.org/help/annotation_score\">annotation scores</a>.</li></ol>\r\n\r\n<p>In total, we extracted 19,906 interactions for 5,878 drugs and 3,757 genes.</p>",
      "body_md": "DrugBank [contains](http://www.drugbank.ca/documentation) four types of drug-protein interactions:\r\n\r\n+ **Target**: A protein, macromolecule, nucleic acid, or small molecule to which a given drug binds, resulting in an alteration of the normal function of the bound molecule anda desirable therapeutic effect. Drug targets are most commonly proteins such as enzymes, ion channels, and receptors.\r\n+ **Enzyme**: A protein which catalyzes chemical reactions involving the a given drug (substrate). Most drugs are metabolized by the Cytochrome P450 enzymes.\r\n+ **Transporter**: A membrane bound protein which shuttles ions, small molecules or macromolecules across membranes, into cells or out of cells.\r\n+ **Carrier**: A secreted protein which binds to drugs, carrying them to cell transporters, where they are moved into the cell. Drug carriers may be used in drug design to increase the effectiveness of drug delivery to the target sites of pharmacological actions.\r\n\r\nWe extracted DrugBank-protein interactions ([notebook](http://nbviewer.ipython.org/github/dhimmel/drugbank/blob/22d835b3cd0ed421c18f855a85a183a9c1349e8f/parse.ipynb), [download](https://raw.githubusercontent.com/dhimmel/drugbank/22d835b3cd0ed421c18f855a85a183a9c1349e8f/data/proteins.tsv)). Our resource includes all DrugBank interactions that met the following criteria:\r\n\r\n1. The interaction is between a drug and *single* protein. A target which is \"protein group\" and contains multiple uniprot proteins would be excluded. Examples include the [GABA-A receptor (anion channel)](//www.drugbank.ca/biodb/bio_entities/BE0004797) and [NMDA receptor](//www.drugbank.ca/biodb/bio_entities/BE0004956). Likewise, a target which is not a protein, such as [DNA](//www.drugbank.ca/biodb/bio_entities/BE0004796) or [Phosphate](//www.drugbank.ca/biodb/bio_entities/BE0004815), would be excluded.\r\n2. The protein maps to an entrez gene. Some uniprot proteins did not such as [Q7ZJM1](//www.uniprot.org/uniprot/Q7ZJM1), [Q59GM9](//www.uniprot.org/uniprot/Q59GM9), and [Q53ET4](//www.uniprot.org/uniprot/Q53ET4) -- all TrEMBL (unreviewed) terms with low [annotation scores](http://www.uniprot.org/help/annotation_score).\r\n\r\nIn total, we extracted 19,906 interactions for 5,878 drugs and 3,757 genes.",
      "comment_id": 212,
      "profile_id": 17,
      "published": "2015-05-09T06:26:06.869629Z",
      "thread_id": 65,
      "url": "/discussion/protein-target-carrier-transporter-and-enzyme-interactions-in-drugbank/65"
    },
    {
      "body_html": "<p>Larry Hunter just gave a talk here where he highlighted his group's work developing KaBOB:<br><a href=\"http://www.biomedcentral.com/1471-2105/16/126/abstract\" target=\"_blank\">http://www.biomedcentral.com/1471-2105/16/126/abstract</a></p>\r\n\r\n<p>Some of the work that they've done may help with processing of external databases. They unify some of the drug/target concepts in DrugBank and PharmGCB, for example, by developing abstract representations of genes, gene products, variants, etc.</p>",
      "body_md": "Larry Hunter just gave a talk here where he highlighted his group's work developing KaBOB:\r\nhttp://www.biomedcentral.com/1471-2105/16/126/abstract\r\n\r\nSome of the work that they've done may help with processing of external databases. They unify some of the drug/target concepts in DrugBank and PharmGCB, for example, by developing abstract representations of genes, gene products, variants, etc.",
      "comment_id": 214,
      "profile_id": 22,
      "published": "2015-05-09T13:55:34.618123Z",
      "thread_id": 66,
      "url": "/discussion/kabob-knowledgebase/66"
    },
    {
      "body_html": "<p>Thanks for the recommendation <span class=\"citation\">[<a href=\"https://doi.org/10.1186/s12859-015-0559-3\" class=\"citation\" data-key=\"10.1186/s12859-015-0559-3\">1</a>]</span>. Unless there is a specific contribution that this resource could immediately provide, I am wary to invest significant time in understanding and integrating it.</p>\r\n\r\n<p>For example, do we want to introduce a dependency on a <a href=\"https://github.com/UCDenver-ccp/datasource/blob/master/datasource-fileparsers/src/main/java/edu/ucdenver/ccp/datasource/fileparsers/drugbank/DrugBankDrugRecord.java\">1,665 line java package</a> to parse a DrugBank record, when we can retrieve the small subset of information we require with <a href=\"https://github.com/dhimmel/drugbank/blob/93d4974e05e238fc45d87e9a79d3f2b23cab58e1/parse.ipynb\">much simpler scripts</a>.</p>\r\n\r\n<p>My initial sense is that while this study tackles some important problems in biodata integration, there isn't a readily available way to easily retrieve and incorporate the unified vocabularies. It would be great to get feedback from the authors, in case I am wrong.</p>",
      "body_md": "Thanks for the recommendation [@10.1186/s12859-015-0559-3]. Unless there is a specific contribution that this resource could immediately provide, I am wary to invest significant time in understanding and integrating it.\r\n\r\nFor example, do we want to introduce a dependency on a [1,665 line java package](https://github.com/UCDenver-ccp/datasource/blob/master/datasource-fileparsers/src/main/java/edu/ucdenver/ccp/datasource/fileparsers/drugbank/DrugBankDrugRecord.java) to parse a DrugBank record, when we can retrieve the small subset of information we require with [much simpler scripts](https://github.com/dhimmel/drugbank/blob/93d4974e05e238fc45d87e9a79d3f2b23cab58e1/parse.ipynb).\r\n\r\nMy initial sense is that while this study tackles some important problems in biodata integration, there isn't a readily available way to easily retrieve and incorporate the unified vocabularies. It would be great to get feedback from the authors, in case I am wrong.",
      "comment_id": 215,
      "profile_id": 17,
      "published": "2015-05-09T19:44:06.933442Z",
      "thread_id": 66,
      "url": "/discussion/kabob-knowledgebase/66#2"
    },
    {
      "body_html": "<h1>Transitive Closure</h1>\r\n\r\n<p><a href=\"/u/caseygreene\" class=\"username\">@caseygreene</a>, our resource has an option to propagate annotations to account for transitive closure. Briefly, transitive closure is defined through example as:</p>\r\n\r\n<blockquote><p>‘every kidney is located in some body’ follows from ‘every kidney is located in some abdomen’ and ‘every abdomen is located in some body’ <span class=\"citation\">[<a href=\"https://doi.org/10.1093/bioinformatics/btr164\" class=\"citation\" data-key=\"10.1093/bioinformatics/btr164\">1</a>]</span></p></blockquote>\r\n\r\n<p>Our current propagation method transfers annotations across <code>is_a</code> relationships between terms in the <code>go-basic.obo</code> ontology. We rely on the <a href=\"https://github.com/tanghaibao/goatools\">goatools python package</a> to process the gene ontology. This package <a href=\"https://github.com/tanghaibao/goatools/blob/b7aab4ee4d242d67aa7f4eba2bb5015238875a6b/goatools/obo_parser.py#L91\">appears to discard all non-<code>is_a</code> relationships</a>. It sounds like our method would classify as the \"the old way\" according to <a href=\"http://wiki.geneontology.org/index.php/Transitive_closure\">your link</a>.</p>\r\n\r\n<p>Is there an easy way to retrieve a table of closure relationships that we should use for annotation propagation? The site mentions a \"pre-computed closure tsv\" but does not indicate whether it is currently available. If we do switch to a method that incorporates additional relationship types beyond <code>is_a</code>, which additional types do you recommend propagating on?</p>",
      "body_md": "# Transitive Closure\r\n\r\n@caseygreene, our resource has an option to propagate annotations to account for transitive closure. Briefly, transitive closure is defined through example as:\r\n\r\n> ‘every kidney is located in some body’ follows from ‘every kidney is located in some abdomen’ and ‘every abdomen is located in some body’ [@10.1093/bioinformatics/btr164]\r\n\r\nOur current propagation method transfers annotations across `is_a` relationships between terms in the `go-basic.obo` ontology. We rely on the [goatools python package](https://github.com/tanghaibao/goatools) to process the gene ontology. This package [appears to discard all non-`is_a` relationships](https://github.com/tanghaibao/goatools/blob/b7aab4ee4d242d67aa7f4eba2bb5015238875a6b/goatools/obo_parser.py#L91). It sounds like our method would classify as the \"the old way\" according to [your link](http://wiki.geneontology.org/index.php/Transitive_closure).\r\n\r\nIs there an easy way to retrieve a table of closure relationships that we should use for annotation propagation? The site mentions a \"pre-computed closure tsv\" but does not indicate whether it is currently available. If we do switch to a method that incorporates additional relationship types beyond `is_a`, which additional types do you recommend propagating on?",
      "comment_id": 216,
      "profile_id": 17,
      "published": "2015-05-09T20:26:06.382072Z",
      "thread_id": 39,
      "url": "/discussion/compiling-gene-ontology-annotations-into-an-easy-to-use-format/39#4"
    },
    {
      "body_html": "<h2>Background</h2>\r\n\r\n<p>The National Library of Medicine (NLM) produces a catalog of 23 million journal articles called PubMed. PubMed contains <a href=\"//www.nlm.nih.gov/pubs/factsheets/dif_med_pub.html\">two subsets</a> that are relevant for literature mining:</p>\r\n\r\n<ol><li><strong>PubMed Central (PMC)</strong> — 3.4 million articles that include full texts, rather than just abstracts.</li><li><strong>MEDLINE</strong> — 21 million articles that are manually annotated with their topics. Topics are chosen from the MeSH vocabulary. 5,594 journals are <a href=\"http://www.ncbi.nlm.nih.gov/nlmcatalog/?term=currentlyindexed\">currently indexed</a>.</li></ol>\r\n\r\n<p>MeSH, which stands for Medical Subject Headings, is a broad terminology of ~27 thousand terms structured hierarchically to form an ontology. <em>Skilled subject analysts</em> at the NLM <a href=\"//www.ncbi.nlm.nih.gov/books/NBK3827/#pubmedhelp.MeSH_Terms_MH\">typically assign</a> 10–12 MeSH terms per article and denote a subset of these terms as <em>major topics</em>.</p>\r\n\r\n<h2>Application</h2>\r\n\r\n<p>Text mining, as <a href=\"//thinklab.com/discussion/text-as-a-resource-for-network-population/48\">suggested to us</a> by <a href=\"/u/b_good\" class=\"username\">@b_good</a>, is an intriguing technique because it is widely-applicable and draws from a knowledge base of epic proportions <span class=\"citation\">[<a href=\"https://doi.org/10.1186/1742-5581-3-2\" class=\"citation\" data-key=\"10.1186/1742-5581-3-2\">1</a>]</span>.</p>\r\n\r\n<p>We would like to infer relationships between nodes in our network based on MEDLINE cooccurrence. We will search for pairs of MeSH terms that are assigned to the same articles beyond what would be expected if the terms were unrelated. This approach has successfully identified disease symptoms <span class=\"citation\">[<a href=\"https://doi.org/10.1038/ncomms5212\" class=\"citation\" data-key=\"10.1038/ncomms5212\">2</a>]</span> (<a href=\"https://cdn.rawgit.com/dhimmel/hsdn/51d31d738fe3cad0a12c736b8def333729c3c7f4/index.html\">browse results</a>). The method is versatile and can be applied to any nodes which have been mapped to MeSH.</p>",
      "body_md": "## Background\r\n\r\nThe National Library of Medicine (NLM) produces a catalog of 23 million journal articles called PubMed. PubMed contains [two subsets](//www.nlm.nih.gov/pubs/factsheets/dif_med_pub.html) that are relevant for literature mining:\r\n\r\n1. **PubMed Central (PMC)** -- 3.4 million articles that include full texts, rather than just abstracts.\r\n2. **MEDLINE** -- 21 million articles that are manually annotated with their topics. Topics are chosen from the MeSH vocabulary. 5,594 journals are [currently indexed](http://www.ncbi.nlm.nih.gov/nlmcatalog/?term=currentlyindexed).\r\n\r\nMeSH, which stands for Medical Subject Headings, is a broad terminology of ~27 thousand terms structured hierarchically to form an ontology. *Skilled subject analysts* at the NLM [typically assign](//www.ncbi.nlm.nih.gov/books/NBK3827/#pubmedhelp.MeSH_Terms_MH) 10--12 MeSH terms per article and denote a subset of these terms as *major topics*.\r\n\r\n## Application\r\n\r\nText mining, as [suggested to us](//thinklab.com/discussion/text-as-a-resource-for-network-population/48) by @b_good, is an intriguing technique because it is widely-applicable and draws from a knowledge base of epic proportions [@10.1186/1742-5581-3-2].\r\n\r\nWe would like to infer relationships between nodes in our network based on MEDLINE cooccurrence. We will search for pairs of MeSH terms that are assigned to the same articles beyond what would be expected if the terms were unrelated. This approach has successfully identified disease symptoms [@10.1038/ncomms5212] ([browse results](https://cdn.rawgit.com/dhimmel/hsdn/51d31d738fe3cad0a12c736b8def333729c3c7f4/index.html)). The method is versatile and can be applied to any nodes which have been mapped to MeSH.",
      "comment_id": 217,
      "profile_id": 17,
      "published": "2015-05-10T21:10:43.806808Z",
      "thread_id": 67,
      "url": "/discussion/mining-knowledge-from-medline-articles-and-their-indexed-mesh-terms/67"
    },
    {
      "body_html": "<p>The <a href=\"//disease-ontology.org/\">Disease Ontology</a> (DO) <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkr972\" class=\"citation\" data-key=\"10.1093/nar/gkr972\">1</a>, <a href=\"https://doi.org/10.1093/nar/gku1011\" class=\"citation\" data-key=\"10.1093/nar/gku1011\">2</a>]</span> is an open source ontology of human diseases. We are using a <a href=\"//thinklab.com/discussion/unifying-disease-vocabularies/44#144\">subset of the DO</a>, which we refer to as DO slim, as our primary disease vocabulary.</p>\r\n\r\n<p>We plan on using this discussion to document <a href=\"//sourceforge.net/p/diseaseontology/feature-requests/\">DO feature requests</a> related to our project. Individuals who contribute to the DO to assist our project should post here so their efforts can be rewarded.</p>",
      "body_md": "The [Disease Ontology](//disease-ontology.org/) (DO) [@10.1093/nar/gkr972 @10.1093/nar/gku1011] is an open source ontology of human diseases. We are using a [subset of the DO](//thinklab.com/discussion/unifying-disease-vocabularies/44#144), which we refer to as DO slim, as our primary disease vocabulary.\r\n\r\nWe plan on using this discussion to document [DO feature requests](//sourceforge.net/p/diseaseontology/feature-requests/) related to our project. Individuals who contribute to the DO to assist our project should post here so their efforts can be rewarded.",
      "comment_id": 218,
      "profile_id": 17,
      "published": "2015-05-12T02:41:44.069056Z",
      "thread_id": 68,
      "url": "/discussion/disease-ontology-feature-requests/68"
    },
    {
      "body_html": "<h1>MeSH cross-reference additions</h1>\r\n\r\n<p>Of our 137 <a href=\"//thinklab.com/discussion/unifying-disease-vocabularies/44#144\">DO slim</a> terms, 19 did not contain a MeSH (<code>MSH</code>) xref. We manually mapped 16 of these terms (<a href=\"https://raw.githubusercontent.com/dhimmel/disease-ontology/89a4fa3e8eb4703d0d3f2c6001ff807876f8b045/requests/DO-slim-to-mesh.tsv\">tsv download</a>):</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>doid_code</th><th>doid_name</th><th>mesh_id</th><th>mesh_name</th></tr></thead><tbody><tr><td>DOID:0050741</td><td>alcohol dependence</td><td>D000437</td><td>Alcoholism</td></tr><tr><td>DOID:0050742</td><td>nicotine dependence</td><td>D014029</td><td>Tobacco Use Disorder</td></tr><tr><td>DOID:0060119</td><td>pharynx cancer</td><td>D010610</td><td>Pharyngeal Neoplasms</td></tr><tr><td>DOID:10021</td><td>duodenum cancer</td><td>D004379</td><td>Duodenal Neoplasms</td></tr><tr><td>DOID:10153</td><td>ileum cancer</td><td>D007078</td><td>Ileal Neoplasms</td></tr><tr><td>DOID:1115</td><td>sarcoma</td><td>D012509</td><td>Sarcoma</td></tr><tr><td>DOID:11615</td><td>penile cancer</td><td>D010412</td><td>Penile Neoplasms</td></tr><tr><td>DOID:11920</td><td>tracheal cancer</td><td>D014134</td><td>Tracheal Neoplasms</td></tr><tr><td>DOID:1324</td><td>lung cancer</td><td>D008175</td><td>Lung Neoplasms</td></tr><tr><td>DOID:1725</td><td>peritoneum cancer</td><td>D010534</td><td>Peritoneal Neoplasms</td></tr><tr><td>DOID:1781</td><td>thyroid cancer</td><td>D013964</td><td>Thyroid Neoplasms</td></tr><tr><td>DOID:4362</td><td>cervical cancer</td><td>D002583</td><td>Uterine Cervical Neoplasms</td></tr><tr><td>DOID:4481</td><td>allergic rhinitis</td><td>D065631</td><td>Rhinitis, Allergic</td></tr><tr><td>DOID:8398</td><td>osteoarthritis</td><td>D010003</td><td>Osteoarthritis</td></tr><tr><td>DOID:8893</td><td>psoriasis</td><td>D011565</td><td>Psoriasis</td></tr><tr><td>DOID:90</td><td>degenerative disc disease</td><td>D055959</td><td>Intervertebral Disc Degeneration</td></tr></tbody></table>\r\n\r\n<p>Comprehensive MeSH cross-references will enable <a href=\"http://thinklab.com/discussion/mining-knowledge-from-medline-articles-and-their-indexed-mesh-terms/67\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d67\">literature mining through MEDLINE</a>.</p>",
      "body_md": "# MeSH cross-reference additions\r\n\r\nOf our 137 [DO slim](//thinklab.com/discussion/unifying-disease-vocabularies/44#144) terms, 19 did not contain a MeSH (`MSH`) xref. We manually mapped 16 of these terms ([tsv download](https://raw.githubusercontent.com/dhimmel/disease-ontology/89a4fa3e8eb4703d0d3f2c6001ff807876f8b045/requests/DO-slim-to-mesh.tsv)):\r\n\r\n| doid_code | doid_name | mesh_id | mesh_name |\r\n|--------------|---------------------------|---------|----------------------------------|\r\n| DOID:0050741 | alcohol dependence | D000437 | Alcoholism |\r\n| DOID:0050742 | nicotine dependence | D014029 | Tobacco Use Disorder |\r\n| DOID:0060119 | pharynx cancer | D010610 | Pharyngeal Neoplasms |\r\n| DOID:10021 | duodenum cancer | D004379 | Duodenal Neoplasms |\r\n| DOID:10153 | ileum cancer | D007078 | Ileal Neoplasms |\r\n| DOID:1115 | sarcoma | D012509 | Sarcoma |\r\n| DOID:11615 | penile cancer | D010412 | Penile Neoplasms |\r\n| DOID:11920 | tracheal cancer | D014134 | Tracheal Neoplasms |\r\n| DOID:1324 | lung cancer | D008175 | Lung Neoplasms |\r\n| DOID:1725 | peritoneum cancer | D010534 | Peritoneal Neoplasms |\r\n| DOID:1781 | thyroid cancer | D013964 | Thyroid Neoplasms |\r\n| DOID:4362 | cervical cancer | D002583 | Uterine Cervical Neoplasms |\r\n| DOID:4481 | allergic rhinitis | D065631 | Rhinitis, Allergic |\r\n| DOID:8398 | osteoarthritis | D010003 | Osteoarthritis |\r\n| DOID:8893 | psoriasis | D011565 | Psoriasis |\r\n| DOID:90 | degenerative disc disease | D055959 | Intervertebral Disc Degeneration |\r\n\r\nComprehensive MeSH cross-references will enable [literature mining through MEDLINE](http://thinklab.com/discussion/mining-knowledge-from-medline-articles-and-their-indexed-mesh-terms/67).",
      "comment_id": 219,
      "profile_id": 17,
      "published": "2015-05-12T02:52:52.494516Z",
      "thread_id": 68,
      "url": "/discussion/disease-ontology-feature-requests/68#2"
    },
    {
      "body_html": "<h1>Mistakes in xref resource abbreviations</h1>\r\n\r\n<p>MedDRA cross-references are inconsistently denoted with <code>MedDRA</code> and <code>MEDDRA</code>.</p>\r\n\r\n<p>The following examples include snippets from the <code>HumanDO.obo</code> (revision 2810). Unless otherwise noted, the errors are on the last copied line.</p>\r\n\r\n<p><code>IDC</code> should be <code>ICD</code> for the International Classification of Diseases (last two lines):<br></p>\r\n\r\n<p></p><pre><code class=\"no-highlight hljs\">[Term]\r\nid: DOID:0060236\r\nname: xanthinuria\r\ndef: \"A purine-pyrimidine metabolic disorder characterized by deficiency of xanthine oxidase, resulting in excretion of large amounts of xanthine in the urine and the formation of xanthine stones.\" [url:http\\://en.wikipedia.org/wiki/Xanthinuria, url:http\\://www.ncbi.nlm.nih.gov/pubmed/4369449]\r\ncomment: NT MGI.\r\nsubset: DO_MGI_slim\r\nsynonym: \"xanthine dehydrogenase deficiency\" EXACT []\r\nsynonym: \"xanthine oxidase deficiency\" EXACT []\r\nxref: HP:0010934\r\nxref: IDC10CM:E79.8\r\nxref: IDC9CM:277.2</code></pre>\r\n\r\n<p><code>IDC</code> should be <code>ICD</code>:<br></p>\r\n\r\n<p></p><pre><code class=\"no-highlight hljs\">[Term]\r\nid: DOID:0060332\r\nname: mitochondrial complex V (ATP synthase) deficiency nuclear type 3\r\ndef: \"A mitochondrial metabolism disease that has material basis in mutation in the ATP5E gene on chromosome 20q13.\" [url:http\\://omim.org/entry/614053]\r\nsubset: DO_MGI_slim\r\nsynonym: \"MC5DN3\" EXACT []\r\nxref: IDC10CM:E88.8</code></pre>\r\n\r\n<p><code>IDC</code> should be <code>ICD</code>:<br></p>\r\n\r\n<p></p><pre><code class=\"no-highlight hljs\">[Term]\r\nid: DOID:5212\r\nname: congenital disorder of glycosylation\r\ndef: \"A carbohydrate metabolic disorder that involves deficient or defective glycosylation of a variety of tissue proteins and/or lipids.\" [url:http\\://en.wikipedia.org/wiki/Congenital_disorder_of_glycosylation]\r\ncomment: Xref MGI.\r\nsubset: DO_MGI_slim\r\nsynonym: \"carbohydrate-deficient glycoprotein syndrome\" EXACT []\r\nxref: ICD10CM:77.8\r\nxref: IDC9CM:271.8</code></pre>\r\n\r\n<p><code>UML_CUI</code> should be <code>UMLS_CUI</code> for the Unified Medical Language System:<br></p>\r\n\r\n<p></p><pre><code class=\"no-highlight hljs\">[Term]\r\nid: DOID:0060313\r\nname: tracheomalacia\r\ndef: \"A tracheal disease characterized by flaccidity of the tracheal support cartilage.\" [url:http\\://en.wikipedia.org/wiki/Tracheomalacia]\r\ncomment: PRISM.\r\nsynonym: \"congenital tracheomalacia\" EXACT []\r\nxref: HP:0002779\r\nxref: ICD10CM:Q32.0\r\nxref: MSH:C557675\r\nxref: NCI:C98634\r\nxref: ORDO:95430\r\nxref: UML_CUI:C0392109</code></pre>\r\n\r\n<p><code>UMLS</code> should be <code>UMLS_CUI</code> for consistency:<br></p>\r\n\r\n<p></p><pre><code class=\"no-highlight hljs\">[Term]\r\nid: DOID:0060217\r\nname: Cogan-Reese syndrome\r\ndef: \"A rare eye disease characterized by variable iris atrophy, pigmented and pedunculated nodules located_in iris and attachment of the iris to the cornea (peripheral anterior synechiae) and characterized_by glaucoma.\" [url:http\\://en.wikipedia.org/wiki/Iridocorneal_endothelial_syndrome, url:http\\://rarediseases.info.nih.gov/gard/6125/cogan-reese-syndrome/resources/1]\r\nxref: ICD10CM:H21.1\r\nxref: MEDDRA:10059200\r\nxref: ORDO:98980\r\nxref: UMLS:C1168173</code></pre>",
      "body_md": "# Mistakes in xref resource abbreviations\r\n\r\nMedDRA cross-references are inconsistently denoted with `MedDRA` and `MEDDRA`.\r\n\r\nThe following examples include snippets from the `HumanDO.obo` (revision 2810). Unless otherwise noted, the errors are on the last copied line.\r\n\r\n`IDC` should be `ICD` for the International Classification of Diseases (last two lines):\r\n```\r\n[Term]\r\nid: DOID:0060236\r\nname: xanthinuria\r\ndef: \"A purine-pyrimidine metabolic disorder characterized by deficiency of xanthine oxidase, resulting in excretion of large amounts of xanthine in the urine and the formation of xanthine stones.\" [url:http\\://en.wikipedia.org/wiki/Xanthinuria, url:http\\://www.ncbi.nlm.nih.gov/pubmed/4369449]\r\ncomment: NT MGI.\r\nsubset: DO_MGI_slim\r\nsynonym: \"xanthine dehydrogenase deficiency\" EXACT []\r\nsynonym: \"xanthine oxidase deficiency\" EXACT []\r\nxref: HP:0010934\r\nxref: IDC10CM:E79.8\r\nxref: IDC9CM:277.2\r\n```\r\n`IDC` should be `ICD`:\r\n```\r\n[Term]\r\nid: DOID:0060332\r\nname: mitochondrial complex V (ATP synthase) deficiency nuclear type 3\r\ndef: \"A mitochondrial metabolism disease that has material basis in mutation in the ATP5E gene on chromosome 20q13.\" [url:http\\://omim.org/entry/614053]\r\nsubset: DO_MGI_slim\r\nsynonym: \"MC5DN3\" EXACT []\r\nxref: IDC10CM:E88.8\r\n```\r\n`IDC` should be `ICD`:\r\n```\r\n[Term]\r\nid: DOID:5212\r\nname: congenital disorder of glycosylation\r\ndef: \"A carbohydrate metabolic disorder that involves deficient or defective glycosylation of a variety of tissue proteins and/or lipids.\" [url:http\\://en.wikipedia.org/wiki/Congenital_disorder_of_glycosylation]\r\ncomment: Xref MGI.\r\nsubset: DO_MGI_slim\r\nsynonym: \"carbohydrate-deficient glycoprotein syndrome\" EXACT []\r\nxref: ICD10CM:77.8\r\nxref: IDC9CM:271.8\r\n```\r\n`UML_CUI` should be `UMLS_CUI` for the Unified Medical Language System:\r\n```\r\n[Term]\r\nid: DOID:0060313\r\nname: tracheomalacia\r\ndef: \"A tracheal disease characterized by flaccidity of the tracheal support cartilage.\" [url:http\\://en.wikipedia.org/wiki/Tracheomalacia]\r\ncomment: PRISM.\r\nsynonym: \"congenital tracheomalacia\" EXACT []\r\nxref: HP:0002779\r\nxref: ICD10CM:Q32.0\r\nxref: MSH:C557675\r\nxref: NCI:C98634\r\nxref: ORDO:95430\r\nxref: UML_CUI:C0392109\r\n```\r\n`UMLS` should be `UMLS_CUI` for consistency:\r\n```\r\n[Term]\r\nid: DOID:0060217\r\nname: Cogan-Reese syndrome\r\ndef: \"A rare eye disease characterized by variable iris atrophy, pigmented and pedunculated nodules located_in iris and attachment of the iris to the cornea (peripheral anterior synechiae) and characterized_by glaucoma.\" [url:http\\://en.wikipedia.org/wiki/Iridocorneal_endothelial_syndrome, url:http\\://rarediseases.info.nih.gov/gard/6125/cogan-reese-syndrome/resources/1]\r\nxref: ICD10CM:H21.1\r\nxref: MEDDRA:10059200\r\nxref: ORDO:98980\r\nxref: UMLS:C1168173\r\n```",
      "comment_id": 220,
      "profile_id": 17,
      "published": "2015-05-12T03:11:16.676004Z",
      "thread_id": 68,
      "url": "/discussion/disease-ontology-feature-requests/68#3"
    },
    {
      "body_html": "<h1>UMLS cross-reference additions</h1>\r\n\r\n<p>Of our 137 DO slim terms, 6 did not contain a UMLS (<code>UMLS_CUI</code>) xref. We manually mapped 5 of these terms (<a href=\"https://raw.githubusercontent.com/dhimmel/disease-ontology/9fd75f14b17e01bebc97faf1bfa1b9025e9ce4de/requests/DO-slim-to-umls.tsv\">tsv download</a>):</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>doid_code</th><th>doid_name</th><th>umls_cui</th><th>umls_name</th></tr></thead><tbody><tr><td>DOID:0050156</td><td>idiopathic pulmonary fibrosis</td><td>C1800706</td><td>Idiopathic Pulmonary Fibrosis</td></tr><tr><td>DOID:0050425</td><td>restless legs syndrome</td><td>C0035258</td><td>Restless Legs Syndrome</td></tr><tr><td>DOID:0050741</td><td>alcohol dependence</td><td>C0001973</td><td>Alcoholic Intoxication, Chronic</td></tr><tr><td>DOID:0050742</td><td>nicotine dependence</td><td>C0028043</td><td>Nicotine Dependence</td></tr><tr><td>DOID:0060119</td><td>pharynx cancer</td><td>C0031347</td><td>Pharyngeal Neoplasms</td></tr></tbody></table>",
      "body_md": "# UMLS cross-reference additions\r\n\r\nOf our 137 DO slim terms, 6 did not contain a UMLS (`UMLS_CUI`) xref. We manually mapped 5 of these terms ([tsv download](https://raw.githubusercontent.com/dhimmel/disease-ontology/9fd75f14b17e01bebc97faf1bfa1b9025e9ce4de/requests/DO-slim-to-umls.tsv)):\r\n\r\n| doid_code | doid_name | umls_cui | umls_name |\r\n|--------------|-------------------------------|----------|---------------------------------|\r\n| DOID:0050156 | idiopathic pulmonary fibrosis | C1800706 | Idiopathic Pulmonary Fibrosis |\r\n| DOID:0050425 | restless legs syndrome | C0035258 | Restless Legs Syndrome |\r\n| DOID:0050741 | alcohol dependence | C0001973 | Alcoholic Intoxication, Chronic |\r\n| DOID:0050742 | nicotine dependence | C0028043 | Nicotine Dependence |\r\n| DOID:0060119 | pharynx cancer | C0031347 | Pharyngeal Neoplasms |",
      "comment_id": 221,
      "profile_id": 17,
      "published": "2015-05-12T03:37:08.730559Z",
      "thread_id": 68,
      "url": "/discussion/disease-ontology-feature-requests/68#4"
    },
    {
      "body_html": "<h1><em>Proof of concept</em> implementation</h1>\r\n\r\n<p>We implemented a topic cooccurrence calculator based on MEDLINE and used this method to identify <strong>disease-symptom relationships</strong> (<a href=\"//nbviewer.ipython.org/github/dhimmel/medline/blob/61590a7007d282429694e52a3a6743af99c1ab12/symptoms.ipynb\">notebook</a>, <a href=\"https://github.com/dhimmel/medline/blob/61590a7007d282429694e52a3a6743af99c1ab12/eutility.py\">API query script</a>, <a href=\"https://raw.githubusercontent.com/dhimmel/medline/gh-pages/data/disease-symptom-cooccurrence.tsv\">tsv of results</a>).</p>\r\n\r\n<p>First we created a <strong>disease set</strong> of 119 MeSH terms that mapped to DO slim diseases (<a href=\"https://github.com/dhimmel/medline/blob/61590a7007d282429694e52a3a6743af99c1ab12/data/DO-slim-to-mesh.tsv\">tsv of diseases</a>). Next, we created a <strong>symptom set</strong> of 438 MeSH terms by finding all descendants of <code>D012816</code> (Signs and Symptoms) (<a href=\"//nbviewer.ipython.org/github/dhimmel/mesh/blob/e561301360e6de2140dedeaa7c7e17ce4714eb7f/mesh.ipynb\">notebook</a>, <a href=\"https://github.com/dhimmel/mesh/blob/e561301360e6de2140dedeaa7c7e17ce4714eb7f/data/symptoms.tsv\">tsv of symptoms</a>).</p>\r\n\r\n<p>For each disease, we identified the articles where that disease was a major topic. For each symptom, we identified the articles where that symptom was a topic. We then identified the articles that contained both a disease major topic and symptom topic. We based further analysis only on these 392,397 articles that contain at least one disease–symptom cooccurrence.</p>\r\n\r\n<p>For each symptom–disease pair, we calculated:</p>\r\n\r\n<ul><li><code>cooccurrence</code> — the number of articles where the disease and symptom terms cooccurred.</li><li><code>expected</code> — the number of expected cooccurrences by chance based on each term's marginal frequency.</li><li><code>enrichment</code> — <code>cooccurrence</code> divided by <code>expected</code>.</li><li><code>odds_ratio</code> — the odds of <code>cooccurrence</code> divided by the odds of <code>expected</code>. This calculation appears to be slightly messed up due to non-integer expected counts.</li><li><code>p_fisher</code> — the p-value from Fisher's exact test evaluating whether the observed cooccurrence exceeded that expected by chance.</li></ul>\r\n\r\n<p><a href=\"/u/apankov\" class=\"username\">@apankov</a>, can you comment on the Fisher's exact test and whether there is a superior way to identify terms that significantly cooccur?</p>\r\n\r\n<p><a href=\"/u/b_good\" class=\"username\">@b_good</a> or others: do you know of better metrics for literature mining? One issue is that our approach may miss common symptoms that are not greatly enriched for any particular disease. The HSDN study <span class=\"citation\">[<a href=\"https://doi.org/10.1038/ncomms5212\" class=\"citation\" data-key=\"10.1038/ncomms5212\">1</a>]</span> used a TF-IDF measure, but <a href=\"//thinklab.com/discussion/human-symptom-disease-network-mesh-id-matching/52#167\">we require</a> metrics that are comparable across diseases.</p>",
      "body_md": "# *Proof of concept* implementation\r\n\r\nWe implemented a topic cooccurrence calculator based on MEDLINE and used this method to identify **disease-symptom relationships** ([notebook](//nbviewer.ipython.org/github/dhimmel/medline/blob/61590a7007d282429694e52a3a6743af99c1ab12/symptoms.ipynb), [API query script](https://github.com/dhimmel/medline/blob/61590a7007d282429694e52a3a6743af99c1ab12/eutility.py), [tsv of results](https://raw.githubusercontent.com/dhimmel/medline/gh-pages/data/disease-symptom-cooccurrence.tsv)).\r\n\r\nFirst we created a **disease set** of 119 MeSH terms that mapped to DO slim diseases ([tsv of diseases](https://github.com/dhimmel/medline/blob/61590a7007d282429694e52a3a6743af99c1ab12/data/DO-slim-to-mesh.tsv)). Next, we created a **symptom set** of 438 MeSH terms by finding all descendants of `D012816` (Signs and Symptoms) ([notebook](//nbviewer.ipython.org/github/dhimmel/mesh/blob/e561301360e6de2140dedeaa7c7e17ce4714eb7f/mesh.ipynb), [tsv of symptoms](https://github.com/dhimmel/mesh/blob/e561301360e6de2140dedeaa7c7e17ce4714eb7f/data/symptoms.tsv)).\r\n\r\nFor each disease, we identified the articles where that disease was a major topic. For each symptom, we identified the articles where that symptom was a topic. We then identified the articles that contained both a disease major topic and symptom topic. We based further analysis only on these 392,397 articles that contain at least one disease--symptom cooccurrence.\r\n\r\nFor each symptom--disease pair, we calculated:\r\n\r\n+ `cooccurrence` -- the number of articles where the disease and symptom terms cooccurred.\r\n+ `expected` -- the number of expected cooccurrences by chance based on each term's marginal frequency.\r\n+ `enrichment` -- `cooccurrence` divided by `expected`.\r\n+ `odds_ratio` -- the odds of `cooccurrence` divided by the odds of `expected`. This calculation appears to be slightly messed up due to non-integer expected counts.\r\n+ `p_fisher` -- the p-value from Fisher's exact test evaluating whether the observed cooccurrence exceeded that expected by chance.\r\n\r\n@apankov, can you comment on the Fisher's exact test and whether there is a superior way to identify terms that significantly cooccur?\r\n\r\n@b_good or others: do you know of better metrics for literature mining? One issue is that our approach may miss common symptoms that are not greatly enriched for any particular disease. The HSDN study [@10.1038/ncomms5212] used a TF-IDF measure, but [we require](//thinklab.com/discussion/human-symptom-disease-network-mesh-id-matching/52#167) metrics that are comparable across diseases.",
      "comment_id": 222,
      "profile_id": 17,
      "published": "2015-05-13T19:51:58.974363Z",
      "thread_id": 67,
      "url": "/discussion/mining-knowledge-from-medline-articles-and-their-indexed-mesh-terms/67#2"
    },
    {
      "body_html": "<p>I think the Fisher's exact test will be accepted well by reviewers, but Barnard's test could be a good alternative. Otherwise, if you can calculate a p-value based on permutation (or get a bootstrapped estimates for the variance of the number of expected cooccurrences) , that could be an easy, straightforward approach.</p>",
      "body_md": "I think the Fisher's exact test will be accepted well by reviewers, but Barnard's test could be a good alternative. Otherwise, if you can calculate a p-value based on permutation (or get a bootstrapped estimates for the variance of the number of expected cooccurrences) , that could be an easy, straightforward approach.\r\n\r\n",
      "comment_id": 223,
      "profile_id": 84,
      "published": "2015-05-13T23:39:44.558228Z",
      "thread_id": 67,
      "url": "/discussion/mining-knowledge-from-medline-articles-and-their-indexed-mesh-terms/67#3"
    },
    {
      "body_html": "<p>Thanks <a href=\"/u/apankov\" class=\"username\">@apankov</a>. I couldn't find a python implementation of <a href=\"https://en.wikipedia.org/wiki/Barnard%27s_test\">Barnard's test</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1038/156177a0\" class=\"citation\" data-key=\"10.1038/156177a0\">1</a>, <a href=\"https://doi.org/10.1093/biomet/34.1-2.123\" class=\"citation\" data-key=\"10.1093/biomet/34.1-2.123\">2</a>]</span>, so I think we'll stick with <a href=\"https://en.wikipedia.org/wiki/Fisher%27s_exact_test\">Fisher's exact test</a> <span class=\"citation\">[<a href=\"https://doi.org/10.2307/2340521\" class=\"citation\" data-key=\"10.2307/2340521\">3</a>]</span> for simplicity. The fidelity of <em>p</em>-values is not a major concern here.</p>\r\n\r\n<p>However, it has occurred to me that in our above post, we incorrectly created the contingency table for the exact test. We now <a href=\"https://github.com/dhimmel/medline/blob/a3e35d7dd58fb64f4043247e661259c743dce7d5/cooccurrence.py#L44\">construct it</a> similarly to <a href=\"https://dx.doi.org/10.1016/j.jbi.2006.11.003#tbl1\">Table 1 of this paper</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.jbi.2006.11.003\" class=\"citation\" data-key=\"10.1016/j.jbi.2006.11.003\">4</a>]</span> so that the contingency table is:</p>\r\n\r\n<p></p><div class=\"math\">$$$\r\n\\begin{bmatrix}\r\na &amp; b\\\\\r\nc &amp; d\r\n\\end{bmatrix}\r\n$$$</div>\r\n\r\n<p>where</p>\r\n\r\n<ul><li><em>a</em> is the number of studies with both the disease and the symptom (<code>cooccurrence</code>)</li><li><em>b</em> is the number of studies with the disease and without the symptom</li><li><em>c</em> is the number of studies without the disease and with the symptom</li><li><em>d</em> is the number of studies without either the disease or symptom</li></ul>\r\n\r\n<p>The revised symptom–disease pair tsv file is <a href=\"https://raw.githubusercontent.com/dhimmel/medline/a3e35d7dd58fb64f4043247e661259c743dce7d5/data/disease-symptom-cooccurrence.tsv\">available here</a>.</p>",
      "body_md": "Thanks @apankov. I couldn't find a python implementation of [Barnard's test](https://en.wikipedia.org/wiki/Barnard%27s_test) [@10.1038/156177a0 @10.1093/biomet/34.1-2.123], so I think we'll stick with [Fisher's exact test](https://en.wikipedia.org/wiki/Fisher%27s_exact_test) [@10.2307/2340521] for simplicity. The fidelity of *p*-values is not a major concern here.\r\n\r\nHowever, it has occurred to me that in our above post, we incorrectly created the contingency table for the exact test. We now [construct it](https://github.com/dhimmel/medline/blob/a3e35d7dd58fb64f4043247e661259c743dce7d5/cooccurrence.py#L44) similarly to [Table 1 of this paper](https://dx.doi.org/10.1016/j.jbi.2006.11.003#tbl1) [@10.1016/j.jbi.2006.11.003] so that the contingency table is:\r\n\r\n$$$\r\n\\begin{bmatrix}\r\na & b\\\\\r\nc & d\r\n\\end{bmatrix}\r\n$$$\r\n\r\nwhere\r\n\r\n+ *a* is the number of studies with both the disease and the symptom (`cooccurrence`)\r\n+ *b* is the number of studies with the disease and without the symptom\r\n+ *c* is the number of studies without the disease and with the symptom\r\n+ *d* is the number of studies without either the disease or symptom\r\n\r\nThe revised symptom--disease pair tsv file is [available here](https://raw.githubusercontent.com/dhimmel/medline/a3e35d7dd58fb64f4043247e661259c743dce7d5/data/disease-symptom-cooccurrence.tsv).",
      "comment_id": 224,
      "profile_id": 17,
      "published": "2015-05-15T22:54:27.488404Z",
      "thread_id": 67,
      "url": "/discussion/mining-knowledge-from-medline-articles-and-their-indexed-mesh-terms/67#4"
    },
    {
      "body_html": "<p>We have calculated molecular (aka chemical/structural) similarities between DrugBank compounds. First, we retrieved the compound structures as an SDF file from the <a href=\"http://www.drugbank.ca/downloads#structures\">download page</a>. Then we calculated extended connectivity fingerprints for each compound using the Morgan/circular method <span class=\"citation\">[<a href=\"https://doi.org/10.1021/ci100050t\" class=\"citation\" data-key=\"10.1021/ci100050t\">1</a>]</span>. We chose a radius of 2, since \"Typically, two iterations is sufficient for fingerprints that will be used for similarity or clustering. <span class=\"citation\">[<a href=\"https://doi.org/10.1021/ci100050t\" class=\"citation\" data-key=\"10.1021/ci100050t\">1</a>]</span>\" Finally, we computed all pairwise similarities <a href=\"http://www.rdkit.org/Python_Docs/rdkit.DataStructs.cDataStructs-module.html#DiceSimilarity\">using</a> the <a href=\"https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient\">Dice coefficient</a> <span class=\"citation\">[<a href=\"https://doi.org/10.2307/1932409\" class=\"citation\" data-key=\"10.2307/1932409\">2</a>]</span>.</p>\r\n\r\n<p>The similarities for the subset of DrugBank compounds included in our network is <a href=\"https://github.com/dhimmel/drugbank/blob/55587651ee9417e4621707dac559d84c984cf5fa/data/similarity-slim.tsv.gz\">available here</a>. We posted the full set of similarities (for all DrugBank compounds with structures) on <a href=\"https://dx.doi.org/10.6084/m9.figshare.1418386\">figshare</a> <span class=\"citation\">[<a href=\"https://doi.org/10.6084/m9.figshare.1418386\" class=\"citation\" data-key=\"10.6084/m9.figshare.1418386\">3</a>]</span>.</p>\r\n\r\n<p>See the <a href=\"http://nbviewer.ipython.org/github/dhimmel/drugbank/blob/9eb1e15ada5e6579e5aea1cae784c10602037b05/similarity.ipynb\">notebook of the analysis</a> for more details.</p>",
      "body_md": "We have calculated molecular (aka chemical/structural) similarities between DrugBank compounds. First, we retrieved the compound structures as an SDF file from the [download page](http://www.drugbank.ca/downloads#structures). Then we calculated extended connectivity fingerprints for each compound using the Morgan/circular method [@10.1021/ci100050t]. We chose a radius of 2, since \"Typically, two iterations is sufficient for fingerprints that will be used for similarity or clustering. [@10.1021/ci100050t]\" Finally, we computed all pairwise similarities [using] (http://www.rdkit.org/Python_Docs/rdkit.DataStructs.cDataStructs-module.html#DiceSimilarity) the [Dice coefficient](https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient) [@10.2307/1932409].\r\n\r\nThe similarities for the subset of DrugBank compounds included in our network is [available here](https://github.com/dhimmel/drugbank/blob/55587651ee9417e4621707dac559d84c984cf5fa/data/similarity-slim.tsv.gz). We posted the full set of similarities (for all DrugBank compounds with structures) on [figshare](https://dx.doi.org/10.6084/m9.figshare.1418386) [@10.6084/m9.figshare.1418386].\r\n\r\nSee the [notebook of the analysis](http://nbviewer.ipython.org/github/dhimmel/drugbank/blob/9eb1e15ada5e6579e5aea1cae784c10602037b05/similarity.ipynb) for more details.",
      "comment_id": 226,
      "profile_id": 17,
      "published": "2015-05-19T02:56:31.081597Z",
      "thread_id": 70,
      "url": "/discussion/calculating-molecular-similarities-between-drugbank-compounds/70"
    },
    {
      "body_html": "<p>I came across the following paper that has useful information regarding the LINCS data integration standards:</p>\r\n\r\n<blockquote><p>Metadata Standard and Data Exchange Specifications to Describe, Model, and Integrate Complex and Diverse High-Throughput Screening Data from the Library of Integrated Network-based Cellular Signatures (LINCS). <span class=\"citation\">[<a href=\"https://doi.org/10.1177/1087057114522514\" class=\"citation\" data-key=\"10.1177/1087057114522514\">1</a>]</span></p></blockquote>",
      "body_md": "I came across the following paper that has useful information regarding the LINCS data integration standards:\r\n\r\n> Metadata Standard and Data Exchange Specifications to Describe, Model, and Integrate Complex and Diverse High-Throughput Screening Data from the Library of Integrated Network-based Cellular Signatures (LINCS). [@10.1177/1087057114522514]",
      "comment_id": 228,
      "profile_id": 17,
      "published": "2015-05-20T11:23:17.925877Z",
      "thread_id": 51,
      "url": "/discussion/unichem-mapping-to-lincs-small-molecules/51#7"
    },
    {
      "body_html": "<h1>Anatomy–Disease Relationships</h1>\r\n\r\n<p>The Uberon ontology <span class=\"citation\">[<a href=\"https://doi.org/10.1186/gb-2012-13-1-r5\" class=\"citation\" data-key=\"10.1186/gb-2012-13-1-r5\">1</a>]</span> of anatomical structures includes MeSH <a href=\"https://github.com/dhimmel/uberon/blob/0c50839eb3e58a89e81018978f269210d2212d58/data/mesh-map.tsv\">cross-references</a>. Thus, we performed our MEDLINE cooccurrence analysis described above to find relationships between diseases and anatomical structures (<a href=\"http://nbviewer.ipython.org/github/dhimmel/medline/blob/ef0aef8b9c4bfcaa4cf46f03efe6d0ea0dc5d13b/tissues.ipynb\">notebook</a>, <a href=\"https://raw.githubusercontent.com/dhimmel/medline/ef0aef8b9c4bfcaa4cf46f03efe6d0ea0dc5d13b/data/disease-uberon-cooccurrence.tsv\">tsv download</a>).</p>\r\n\r\n<p>The ability of this method to capture disease localization was exceptional. For example, the top five terms by <em>p</em>-value for multiple sclerosis were:</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>mesh_name</th><th>cooccurrence</th><th>expected</th><th>enrichment</th><th>odds_ratio</th><th>p_fisher</th></tr></thead><tbody><tr><td>Central Nervous System</td><td>881</td><td>38.6</td><td>22.8</td><td>34.3</td><td>0.000</td></tr><tr><td>Spinal Cord</td><td>1492</td><td>80.8</td><td>18.5</td><td>27.5</td><td>0.000</td></tr><tr><td>Myelin Sheath</td><td>1006</td><td>19.9</td><td>50.5</td><td>146.8</td><td>0.000</td></tr><tr><td>Brain</td><td>4777</td><td>778.3</td><td>6.1</td><td>11.5</td><td>0.000</td></tr><tr><td>Optic Nerve</td><td>372</td><td>36.5</td><td>10.2</td><td>11.9</td><td>0.000</td></tr></tbody></table>\r\n\r\n<p>One improvement would be to exclude Uberon terms that don't exist in humans such as venom (<code>UBERON:0007113</code>). Additionally, there are some <a href=\"https://github.com/obophenotype/uberon/issues/698#issuecomment-104079963\">Uberon–MeSH mapping issues</a> that should get resolved soon allowing us to update the analysis.</p>",
      "body_md": "# Anatomy--Disease Relationships\r\n\r\nThe Uberon ontology [@10.1186/gb-2012-13-1-r5] of anatomical structures includes MeSH [cross-references](https://github.com/dhimmel/uberon/blob/0c50839eb3e58a89e81018978f269210d2212d58/data/mesh-map.tsv). Thus, we performed our MEDLINE cooccurrence analysis described above to find relationships between diseases and anatomical structures ([notebook](http://nbviewer.ipython.org/github/dhimmel/medline/blob/ef0aef8b9c4bfcaa4cf46f03efe6d0ea0dc5d13b/tissues.ipynb), [tsv download](https://raw.githubusercontent.com/dhimmel/medline/ef0aef8b9c4bfcaa4cf46f03efe6d0ea0dc5d13b/data/disease-uberon-cooccurrence.tsv)).\r\n\r\nThe ability of this method to capture disease localization was exceptional. For example, the top five terms by *p*-value for multiple sclerosis were:\r\n\r\n| mesh_name | cooccurrence | expected | enrichment | odds_ratio | p_fisher |\r\n|------------------------|--------------|----------|------------|------------|----------|\r\n| Central Nervous System | 881 | 38.6 | 22.8 | 34.3 | 0.000 |\r\n| Spinal Cord | 1492 | 80.8 | 18.5 | 27.5 | 0.000 |\r\n| Myelin Sheath | 1006 | 19.9 | 50.5 | 146.8 | 0.000 |\r\n| Brain | 4777 | 778.3 | 6.1 | 11.5 | 0.000 |\r\n| Optic Nerve | 372 | 36.5 | 10.2 | 11.9 | 0.000 |\r\n\r\nOne improvement would be to exclude Uberon terms that don't exist in humans such as venom (`UBERON:0007113`). Additionally, there are some [Uberon--MeSH mapping issues](https://github.com/obophenotype/uberon/issues/698#issuecomment-104079963) that should get resolved soon allowing us to update the analysis.",
      "comment_id": 229,
      "profile_id": 17,
      "published": "2015-05-21T03:35:08.975314Z",
      "thread_id": 67,
      "url": "/discussion/mining-knowledge-from-medline-articles-and-their-indexed-mesh-terms/67#5"
    },
    {
      "body_html": "<p>Hi <a href=\"/u/vsmalladi\" class=\"username\">@vsmalladi</a>, we have proceeded with Uberon and incorporated the MeSH cross-references. Specifically, we <a href=\"http://thinklab.com/d/67#229\">identified</a> disease–anatomy localization using literature mining.</p>\r\n\r\n<p>We would like a way to restrict terms to structures in humans. Does anyone know how to implement a species filter?</p>\r\n\r\n<p>We would also like to incorporate the Cell Ontology (CL) for cell information <span class=\"citation\">[<a href=\"https://doi.org/10.1186/gb-2005-6-2-r21\" class=\"citation\" data-key=\"10.1186/gb-2005-6-2-r21\">1</a>]</span>. However, there is a <a href=\"https://code.google.com/p/cell-ontology/issues/detail?id=146#c2\">MeSH xref issue</a> that will need to be remedied first.</p>",
      "body_md": "Hi @vsmalladi, we have proceeded with Uberon and incorporated the MeSH cross-references. Specifically, we [identified](http://thinklab.com/d/67#229) disease--anatomy localization using literature mining.\r\n\r\nWe would like a way to restrict terms to structures in humans. Does anyone know how to implement a species filter?\r\n\r\nWe would also like to incorporate the Cell Ontology (CL) for cell information [@10.1186/gb-2005-6-2-r21]. However, there is a [MeSH xref issue](https://code.google.com/p/cell-ontology/issues/detail?id=146#c2) that will need to be remedied first.",
      "comment_id": 230,
      "profile_id": 17,
      "published": "2015-05-21T03:46:33.583308Z",
      "thread_id": 41,
      "url": "/discussion/tissue-node/41#6"
    },
    {
      "body_html": "<h1>Combining z-scores across multiple signatures</h1>\r\n\r\n<p>To create consensus signatures for a compound, we have been taking a weighted average of z-scores (steps 4–5 <a href=\"#3\">above</a>). It has occurred to us that this is an underpowered method, just as averaging p-values is a weak method of meta-analysis. </p>\r\n\r\n<p>Instead we can use <a href=\"https://en.wikipedia.org/wiki/Fisher%27s_method#Relation_to_Stouffer.27s_Z-score_method\">Stouffer's method</a> to meta-analyze z-scores <span class=\"citation\">[<a href=\"http://press.princeton.edu/titles/2692.html\" class=\"citation\" data-key=\"stouffer\">1</a>]</span>. This method accepts weights (calculated in steps 2–3 <a href=\"#3\">above</a>). The formula is below for weight vector <em>w</em> and z-score vector <em>Z</em>:</p>\r\n\r\n<div class=\"math\">$$$\r\nZ \\sim \\frac{\\sum_{i=1}^k w_iZ_i}{\\sqrt{\\sum_{i=1}^k w_i^2}}\r\n$$$</div>\r\n\r\n",
      "body_md": "# Combining z-scores across multiple signatures\r\n\r\nTo create consensus signatures for a compound, we have been taking a weighted average of z-scores (steps 4--5 [above](#3)). It has occurred to us that this is an underpowered method, just as averaging p-values is a weak method of meta-analysis. \r\n\r\nInstead we can use [Stouffer's method](https://en.wikipedia.org/wiki/Fisher%27s_method#Relation_to_Stouffer.27s_Z-score_method) to meta-analyze z-scores [@stouffer]. This method accepts weights (calculated in steps 2--3 [above](#3)). The formula is below for weight vector *w* and z-score vector *Z*:\r\n\r\n$$$\r\nZ \\sim \\frac{\\sum_{i=1}^k w_iZ_i}{\\sqrt{\\sum_{i=1}^k w_i^2}}\r\n$$$\r\n\r\n[@stouffer]: http://press.princeton.edu/titles/2692.html \"Stouffer SA, Suchman EA, DeVinney LC, Star SA, Williams RM. (1949) *The American Soldier, Vol.1: Adjustment during Army Life*. Princeton University Press\"",
      "comment_id": 231,
      "profile_id": 17,
      "published": "2015-05-21T05:04:41.405554Z",
      "thread_id": 43,
      "url": "/discussion/computing-consensus-transcriptional-profiles-for-lincs-l1000-perturbations/43#5"
    },
    {
      "body_html": "<p><a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a> You can restrict structures by NCBI taxon ID Human would be Taxon:9606</p>\r\n\r\n<p>Can you elaborate on the MeSH issue? I might be able to help. </p>",
      "body_md": "@dhimmel You can restrict structures by NCBI taxon ID Human would be Taxon:9606\r\n\r\nCan you elaborate on the MeSH issue? I might be able to help. ",
      "comment_id": 232,
      "profile_id": 35,
      "published": "2015-05-22T05:05:57.647307Z",
      "thread_id": 41,
      "url": "/discussion/tissue-node/41#7"
    },
    {
      "body_html": "<p><a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a> To understand what relationships you should compute closure on I recommend reading <a href=\"http://geneontology.org/page/ontology-relations\" target=\"_blank\">http://geneontology.org/page/ontology-relations</a></p>\r\n\r\n<p>I would add <code>part_of</code><code> and maybe </code><code>has_part</code>` first before exploring the other relationships. </p>\r\n\r\n<p>Another option for reasoning that can take advantage of the relationships is <a href=\"https://github.com/owlcollab/owltools\" target=\"_blank\">https://github.com/owlcollab/owltools</a></p>",
      "body_md": "@dhimmel To understand what relationships you should compute closure on I recommend reading http://geneontology.org/page/ontology-relations\r\n\r\nI would add ```part_of```` and maybe ```has_part``` first before exploring the other relationships. \r\n\r\nAnother option for reasoning that can take advantage of the relationships is https://github.com/owlcollab/owltools",
      "comment_id": 233,
      "profile_id": 35,
      "published": "2015-05-22T21:39:45.073691Z",
      "thread_id": 39,
      "url": "/discussion/compiling-gene-ontology-annotations-into-an-easy-to-use-format/39#5"
    },
    {
      "body_html": "<h1>Restricting to human terms</h1>\r\n\r\n<p><a href=\"/u/vsmalladi\" class=\"username\">@vsmalladi</a>, thanks for the pointer. In the <a href=\"//berkeleybop.org/ontologies/uberon/ext.obo\">obo</a> header I see:<br></p>\r\n\r\n<p></p><pre><code class=\"no-highlight hljs\">treat-xrefs-as-reverse-genus-differentia: DHBA part_of NCBITaxon:9606\r\ntreat-xrefs-as-reverse-genus-differentia: EHDAA2 part_of NCBITaxon:9606\r\ntreat-xrefs-as-reverse-genus-differentia: FMA part_of NCBITaxon:9606\r\ntreat-xrefs-as-reverse-genus-differentia: HBA part_of NCBITaxon:9606\r\ntreat-xrefs-as-reverse-genus-differentia: HsapDv part_of NCBITaxon:9606</code></pre>\r\n\r\n<p>Therefore I speculate the best way to identify human applicable terms would be to identify all terms with a cross-reference to the above resources and all broader terms in the hierarchy. Is that what you suggest?</p>",
      "body_md": "# Restricting to human terms\r\n\r\n@vsmalladi, thanks for the pointer. In the [obo](//berkeleybop.org/ontologies/uberon/ext.obo) header I see:\r\n```\r\ntreat-xrefs-as-reverse-genus-differentia: DHBA part_of NCBITaxon:9606\r\ntreat-xrefs-as-reverse-genus-differentia: EHDAA2 part_of NCBITaxon:9606\r\ntreat-xrefs-as-reverse-genus-differentia: FMA part_of NCBITaxon:9606\r\ntreat-xrefs-as-reverse-genus-differentia: HBA part_of NCBITaxon:9606\r\ntreat-xrefs-as-reverse-genus-differentia: HsapDv part_of NCBITaxon:9606\r\n```\r\nTherefore I speculate the best way to identify human applicable terms would be to identify all terms with a cross-reference to the above resources and all broader terms in the hierarchy. Is that what you suggest?",
      "comment_id": 234,
      "profile_id": 17,
      "published": "2015-05-23T21:52:32.772955Z",
      "thread_id": 41,
      "url": "/discussion/tissue-node/41#8"
    },
    {
      "body_html": "<p><a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a> </p>\r\n\r\n<p>Actually what you want to do is for each term filter on <code>present_in_taxon</code>:</p>\r\n\r\n<p>   property_value: present_in_taxon NCBITaxon:7777</p>",
      "body_md": "@dhimmel \r\n\r\nActually what you want to do is for each term filter on ```present_in_taxon```:\r\n\r\n   property_value: present_in_taxon NCBITaxon:7777\r\n\r\n",
      "comment_id": 235,
      "profile_id": 35,
      "published": "2015-05-26T21:20:05.133071Z",
      "thread_id": 41,
      "url": "/discussion/tissue-node/41#9"
    },
    {
      "body_html": "<p>Our validation manuscript has been published, <a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a>: <a href=\"http://aci.schattauer.de/en/contents/current-issue/issue/special/manuscript/24377/show.html\" target=\"_blank\">http://aci.schattauer.de/en/contents/current-issue/issue/special/manuscript/24377/show.html</a></p>\r\n\r\n<p>I'll see what I can do about sharing the data, but unfortunately I've got travel coming up along with several deadlines, so it may be a little while longer before I'm able to do that.</p>",
      "body_md": "Our validation manuscript has been published, @dhimmel: http://aci.schattauer.de/en/contents/current-issue/issue/special/manuscript/24377/show.html\r\n\r\nI'll see what I can do about sharing the data, but unfortunately I've got travel coming up along with several deadlines, so it may be a little while longer before I'm able to do that.",
      "comment_id": 236,
      "profile_id": 77,
      "published": "2015-05-27T14:26:51.387135Z",
      "thread_id": 21,
      "url": "/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#22"
    },
    {
      "body_html": "<p><a href=\"/u/vsmalladi\" class=\"username\">@vsmalladi</a>, <a href=\"http://berkeleybop.org/ontologies/uberon/ext.obo\">the obo</a> only contains <code>relationship: present_in_taxon NCBITaxon:9606</code> for four terms. Is there a more extensive listing of <code>present_in_taxon</code> relationships that you are aware of?</p>\r\n\r\n<p>Meanwhile the <a href=\"https://github.com/dhimmel/uberon/blob/50c311f3d15744e8c559ea76178bdd7542f6d16b/data/mesh-map.tsv\">results</a> of the <code>treat-xrefs-as-reverse-genus-differentia</code> method look satisfactory. Terms were annotated as human (<code>in_human = 1</code>) if they or any terms they subsumed (along <code>is_a</code>, <code>part_of</code>, and <code>develops_from</code> relationships) contained a cross-reference to any of the following resources: <code>DHBA</code>, <code>EHDAA2</code>, <code>FMA</code>, <code>HBA</code>, and <code>HsapDv</code> (<a href=\"https://github.com/dhimmel/uberon/blob/50c311f3d15744e8c559ea76178bdd7542f6d16b/mesh-map.ipynb\">notebook</a>). Most terms where <code>in_human = 0</code> are not appropriate for humans.</p>",
      "body_md": "@vsmalladi, [the obo](http://berkeleybop.org/ontologies/uberon/ext.obo) only contains `relationship: present_in_taxon NCBITaxon:9606` for four terms. Is there a more extensive listing of `present_in_taxon` relationships that you are aware of?\r\n\r\nMeanwhile the [results](https://github.com/dhimmel/uberon/blob/50c311f3d15744e8c559ea76178bdd7542f6d16b/data/mesh-map.tsv) of the `treat-xrefs-as-reverse-genus-differentia` method look satisfactory. Terms were annotated as human (`in_human = 1`) if they or any terms they subsumed (along `is_a`, `part_of`, and `develops_from` relationships) contained a cross-reference to any of the following resources: `DHBA`, `EHDAA2`, `FMA`, `HBA`, and `HsapDv` ([notebook](https://github.com/dhimmel/uberon/blob/50c311f3d15744e8c559ea76178bdd7542f6d16b/mesh-map.ipynb)). Most terms where `in_human = 0` are not appropriate for humans.\r\n\r\n\r\n",
      "comment_id": 237,
      "profile_id": 17,
      "published": "2015-06-02T18:51:21.520906Z",
      "thread_id": 41,
      "url": "/discussion/tissue-node/41#10"
    },
    {
      "body_html": "<p><a href=\"/u/caseygreene\" class=\"username\">@caseygreene</a>, thanks for the description of your database setup. In the immediate term, I don't need any of the advanced features that your design accommodates such as elastic search and efficient lookup, so I just did a simple <a href=\"//nbviewer.ipython.org/github/dhimmel/entrez-gene/blob/2208158e9e9691d54d48faf3b6b9c2c8f69d7914/retrieve.ipynb\">parsing</a> of the human subset and exported three tsv files (<a href=\"https://github.com/dhimmel/entrez-gene/blob/2208158e9e9691d54d48faf3b6b9c2c8f69d7914/data/genes-human.tsv\">genes</a>, <a href=\"https://github.com/dhimmel/entrez-gene/blob/2208158e9e9691d54d48faf3b6b9c2c8f69d7914/data/symbols-human.tsv\">symbols</a>, <a href=\"https://github.com/dhimmel/entrez-gene/blob/2208158e9e9691d54d48faf3b6b9c2c8f69d7914/data/xrefs-human.tsv\">cross-references</a>).</p>\r\n\r\n<p>Therefore, don't reprioritize for me, but I think the pypi package is a great idea. It looks like your <a href=\"//tribe.greenelab.com/\">Tribe</a> API already supports Entrez gene lookup. However, I'm confused about the usage, since the <a href=\"//tribe.greenelab.com/#/demo/speak\">demo code</a> is equivalent to:</p>\r\n\r\n<p></p><pre><code class=\"python\">import requests\r\npayload = {'show_tip': 'true'}\r\nresponse = requests.get('http://tribe.greenelab.com/api/v1/geneset/', params=payload)</code></pre>\r\n\r\n<p>How do you specify the query string (the gene symbol/name for which you want the GeneID)? It may be the case that your API already provides most of the functionality a user may need. In that case, a local Entrez Gene database may not be needed at all.</p>\r\n\r\n<p>Summary: my vote is for a powerful, well-documented API as a primary resource, with an open source codebase.</p>",
      "body_md": "@caseygreene, thanks for the description of your database setup. In the immediate term, I don't need any of the advanced features that your design accommodates such as elastic search and efficient lookup, so I just did a simple [parsing](//nbviewer.ipython.org/github/dhimmel/entrez-gene/blob/2208158e9e9691d54d48faf3b6b9c2c8f69d7914/retrieve.ipynb) of the human subset and exported three tsv files ([genes](https://github.com/dhimmel/entrez-gene/blob/2208158e9e9691d54d48faf3b6b9c2c8f69d7914/data/genes-human.tsv), [symbols](https://github.com/dhimmel/entrez-gene/blob/2208158e9e9691d54d48faf3b6b9c2c8f69d7914/data/symbols-human.tsv), [cross-references](https://github.com/dhimmel/entrez-gene/blob/2208158e9e9691d54d48faf3b6b9c2c8f69d7914/data/xrefs-human.tsv)).\r\n\r\nTherefore, don't reprioritize for me, but I think the pypi package is a great idea. It looks like your [Tribe](//tribe.greenelab.com/) API already supports Entrez gene lookup. However, I'm confused about the usage, since the [demo code](//tribe.greenelab.com/#/demo/speak) is equivalent to:\r\n\r\n```python\r\nimport requests\r\npayload = {'show_tip': 'true'}\r\nresponse = requests.get('http://tribe.greenelab.com/api/v1/geneset/', params=payload)\r\n```\r\n\r\nHow do you specify the query string (the gene symbol/name for which you want the GeneID)? It may be the case that your API already provides most of the functionality a user may need. In that case, a local Entrez Gene database may not be needed at all.\r\n\r\nSummary: my vote is for a powerful, well-documented API as a primary resource, with an open source codebase.",
      "comment_id": 238,
      "profile_id": 17,
      "published": "2015-06-07T23:11:43.668288Z",
      "thread_id": 34,
      "url": "/discussion/using-entrez-gene-as-our-gene-vocabulary/34#5"
    },
    {
      "body_html": "<h2>Background</h2>\r\n\r\n<p>GWAS uncover disease-associated loci, but due to sparse genotyping arrays and linkage disequilibrium (LD), identifying the specific SNP driving the association is difficult. Therefore, GWAS usually report the most significant hit as the single lead SNP for a loci, leaving the identification of a causal SNP for later research. Often multiple GWAS of the same disease will identify different lead SNPs in the same region, presumable all tagging the same causal variant. Therefore, around any lead SNP is a <em>region of indetermination</em>—a genomic window in which the SNP driving the association is likely to reside.</p>\r\n\r\n<h2>Application</h2>\r\n\r\n<p>When extracting disease-gene associations from the <a href=\"//www.ebi.ac.uk/gwas/\">GWAS Catalog</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkt1229\" class=\"citation\" data-key=\"10.1093/nar/gkt1229\">1</a>]</span>, we collapse multiple associations for the same disease into loci (regions) <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1004259\">2</a>]</span>. Starting with lead SNPs for each association, we find the corresponding windows and overlap them into genomically disjoint sets.</p>\r\n\r\n<p>Previously, we retrieved windows for GWAS lead-SNPs from the <a href=\"https://www.broadinstitute.org/mpg/dapple/dappleTMP.php\">DAPPLE</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pgen.1001273\" class=\"citation\" data-key=\"10.1371/journal.pgen.1001273\">3</a>]</span> wingspan files. DAPPLE windows \"were calculated for each lead-SNP by finding the furthest upstream and downstream SNPs where <span class=\"math\">$$r^2 &gt; 0.5$$</span> and extending outwards to the next recombination hotspot <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1004259\">2</a>]</span>.\"</p>\r\n\r\n<p>However, DAPPLE relied on HapMap <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nature04226\" class=\"citation\" data-key=\"10.1038/nature04226\">4</a>]</span> for LD data, which is now outdated. Many SNPs in the GWAS catalog are not in HapMap. Since HapMap is missing many SNPs, extending to the next recombination hotspot was necessary.</p>\r\n\r\n<h1>Questions</h1>\r\n\r\n<ol><li><strong>Given a lead SNP, how should we identify the furthest upstream and downstream SNPs with <span class=\"math\">$$r^2$$</span> exceeding a given threshold?</strong> Which data and tools should we use?</li><li>In the context of GWAS loci, is <span class=\"math\">$$r^2 &gt; 0.5$$</span> too low of a threshold for windows?</li><li>Is the recombination hotspot extension necessary?</li></ol>\r\n\r\n<p>We would like to identify windows for ~5000 SNPs which are identified in dbSNP build 142 rsids.</p>",
      "body_md": "## Background\r\n\r\nGWAS uncover disease-associated loci, but due to sparse genotyping arrays and linkage disequilibrium (LD), identifying the specific SNP driving the association is difficult. Therefore, GWAS usually report the most significant hit as the single lead SNP for a loci, leaving the identification of a causal SNP for later research. Often multiple GWAS of the same disease will identify different lead SNPs in the same region, presumable all tagging the same causal variant. Therefore, around any lead SNP is a *region of indetermination*---a genomic window in which the SNP driving the association is likely to reside.\r\n\r\n## Application\r\n\r\nWhen extracting disease-gene associations from the [GWAS Catalog](//www.ebi.ac.uk/gwas/) [@10.1093/nar/gkt1229], we collapse multiple associations for the same disease into loci (regions) [@10.1371/journal.pcbi.1004259]. Starting with lead SNPs for each association, we find the corresponding windows and overlap them into genomically disjoint sets.\r\n\r\nPreviously, we retrieved windows for GWAS lead-SNPs from the [DAPPLE](https://www.broadinstitute.org/mpg/dapple/dappleTMP.php) [@10.1371/journal.pgen.1001273] wingspan files. DAPPLE windows \"were calculated for each lead-SNP by finding the furthest upstream and downstream SNPs where $$r^2 > 0.5$$ and extending outwards to the next recombination hotspot [@10.1371/journal.pcbi.1004259].\"\r\n\r\nHowever, DAPPLE relied on HapMap [@10.1038/nature04226] for LD data, which is now outdated. Many SNPs in the GWAS catalog are not in HapMap. Since HapMap is missing many SNPs, extending to the next recombination hotspot was necessary.\r\n\r\n# Questions\r\n\r\n1. **Given a lead SNP, how should we identify the furthest upstream and downstream SNPs with $$r^2$$ exceeding a given threshold?** Which data and tools should we use?\r\n2. In the context of GWAS loci, is $$r^2 > 0.5$$ too low of a threshold for windows?\r\n3. Is the recombination hotspot extension necessary?\r\n\r\nWe would like to identify windows for ~5000 SNPs which are identified in dbSNP build 142 rsids.",
      "comment_id": 239,
      "profile_id": 17,
      "published": "2015-06-08T18:54:53.853760Z",
      "thread_id": 71,
      "url": "/discussion/calculating-genomic-windows-for-gwas-lead-snps/71"
    },
    {
      "body_html": "<p>I would suggest using 1000 genomes for the LD calculation here with a more stringent r^2 cutoff (maybe 0.8?). Some LD information is available through their browser</p>\r\n\r\n<p><a href=\"http://browser.1000genomes.org/Homo_sapiens/Location/Genome?db=core;r=2:31451742-31452000\">http://browser.1000genomes.org/Homo_sapiens/Location/Genome?db=core;r=2:31451742-31452000</a></p>\r\n\r\n<p>Here is a thread discussing similar ideas:<br><a href=\"https://www.biostars.org/p/2909/\">https://www.biostars.org/p/2909/</a></p>\r\n\r\n<p>The other resource of interest is the ExAC dataset: <a href=\"http://exac.broadinstitute.org/\">http://exac.broadinstitute.org/</a> I don't think the LD data is available, but it's worthwhile reaching out to them!</p>",
      "body_md": "I would suggest using 1000 genomes for the LD calculation here with a more stringent r^2 cutoff (maybe 0.8?). Some LD information is available through their browser\r\n\r\nhttp://browser.1000genomes.org/Homo_sapiens/Location/Genome?db=core;r=2:31451742-31452000\r\n\r\nHere is a thread discussing similar ideas:\r\nhttps://www.biostars.org/p/2909/\r\n\r\nThe other resource of interest is the ExAC dataset: http://exac.broadinstitute.org/ I don't think the LD data is available, but it's worthwhile reaching out to them!",
      "comment_id": 240,
      "profile_id": 103,
      "published": "2015-06-08T20:58:12.464481Z",
      "thread_id": 71,
      "url": "/discussion/calculating-genomic-windows-for-gwas-lead-snps/71#2"
    },
    {
      "body_html": "<p>For identifier mapping, you might want to check out <a href=\"http://bridgedb.org/\">BridgeDb</a>, which provides both mapping databases and libraries to add identifier mapping functionality to any project. It's 100% free and <a href=\"https://github.com/bridgedb/BridgeDb\">open source</a>.</p>\r\n\r\n<p>There are many ways to integrate BridgeDb into your own tool or resource. The easiest is simply to make web service calls, like:</p>\r\n\r\n<p><a href=\"http://webservice.bridgedb.org/Human/xrefs/H/CCR5\">http://webservice.bridgedb.org/Human/xrefs/H/CCR5</a><br>(for all mappings connected to HGNC \"CCR5\"), or</p>\r\n\r\n<p><a href=\"http://webservice.bridgedb.org/Human/xrefs/H/CCR5?dataSource=Entrez%20Gene\">http://webservice.bridgedb.org/Human/xrefs/H/CCR5?dataSource=Entrez%20Gene</a><br>(to only retrieve the Entrez Gene for \"CCR5\")</p>\r\n\r\n<p>Here are some docs for additional web service syntax: <a href=\"http://bridgedb.org/wiki/BridgeWebservice\">http://bridgedb.org/wiki/BridgeWebservice</a></p>\r\n\r\n<p>If performance is an issue, e.g., you want to query 10,000 times a day, then you can install the databases locally and implement the libs provided by the project into your tool and have complete control over database versions, etc.</p>",
      "body_md": "For identifier mapping, you might want to check out [BridgeDb](http://bridgedb.org/), which provides both mapping databases and libraries to add identifier mapping functionality to any project. It's 100% free and [open source](https://github.com/bridgedb/BridgeDb).\r\n\r\nThere are many ways to integrate BridgeDb into your own tool or resource. The easiest is simply to make web service calls, like:\r\n\r\nhttp://webservice.bridgedb.org/Human/xrefs/H/CCR5\r\n(for all mappings connected to HGNC \"CCR5\"), or\r\n\r\nhttp://webservice.bridgedb.org/Human/xrefs/H/CCR5?dataSource=Entrez%20Gene\r\n(to only retrieve the Entrez Gene for \"CCR5\")\r\n\r\nHere are some docs for additional web service syntax: http://bridgedb.org/wiki/BridgeWebservice\r\n\r\nIf performance is an issue, e.g., you want to query 10,000 times a day, then you can install the databases locally and implement the libs provided by the project into your tool and have complete control over database versions, etc.",
      "comment_id": 241,
      "profile_id": 104,
      "published": "2015-06-09T00:52:06.974181Z",
      "thread_id": 34,
      "url": "/discussion/using-entrez-gene-as-our-gene-vocabulary/34#6"
    },
    {
      "body_html": "<p>For Table 1, you might consider adding another Gene Set resource based on curated pathways.  These are analogous to GO-Biological Process terms, but are much more focused and constrained. In fact, they also include small molecules and drugs, so they can serve as more than just <em>gene</em> sets.</p>\r\n\r\n<p>Likewise, for Table 2, you could add a number of interaction resources with pathway data.  As co-founder of <a href=\"http://wikipathways.org\">WikiPathways</a>, I have to recommend that one in particular! :)  It's 100% free, open source and open access.  I can also recommend <a href=\"http://www.reactome.org\">Reactome</a> and <a href=\"http://www.pathwaycommons.org/\">Pathway Commons</a>, the latter of which compiles pathway data from multiple sources into BioPAX data format.</p>\r\n\r\n<p>Again, these would not only provide high-quality gene-gene interactions for your network, but also direct drug-gene interactions. And in relation to your Figure 1, they would also provide Disease and Tissue associations.</p>\r\n\r\n<p>You can download all human pathways from WikiPathways <a href=\"http://wikipathways.org/index.php/Download_Pathways\">in multiple formats</a>, or parse just the Entrez Genes in Human pathways from <a href=\"http://www.pathvisio.org/data/bots/gmt/wikipathways.gmt\">this single dump file</a>. The advantage to the first option are that you are getting the original data, as curated by contributors; the disadvantage is that you have to perform the ID mapping to unify to Entrez and your preferred small molecule system. The advantage of the second option (the dump file) is that the Entrez ID unification has been done for you; the disadvantage is that anything that didn't map to Entrez is simply discarded (including drugs and small molecules!).</p>",
      "body_md": "For Table 1, you might consider adding another Gene Set resource based on curated pathways.  These are analogous to GO-Biological Process terms, but are much more focused and constrained. In fact, they also include small molecules and drugs, so they can serve as more than just *gene* sets.\r\n\r\nLikewise, for Table 2, you could add a number of interaction resources with pathway data.  As co-founder of [WikiPathways](http://wikipathways.org), I have to recommend that one in particular! :)  It's 100% free, open source and open access.  I can also recommend [Reactome](http://www.reactome.org) and [Pathway Commons](http://www.pathwaycommons.org/), the latter of which compiles pathway data from multiple sources into BioPAX data format.\r\n\r\nAgain, these would not only provide high-quality gene-gene interactions for your network, but also direct drug-gene interactions. And in relation to your Figure 1, they would also provide Disease and Tissue associations.\r\n\r\nYou can download all human pathways from WikiPathways [in multiple formats](http://wikipathways.org/index.php/Download_Pathways), or parse just the Entrez Genes in Human pathways from [this single dump file](http://www.pathvisio.org/data/bots/gmt/wikipathways.gmt). The advantage to the first option are that you are getting the original data, as curated by contributors; the disadvantage is that you have to perform the ID mapping to unify to Entrez and your preferred small molecule system. The advantage of the second option (the dump file) is that the Entrez ID unification has been done for you; the disadvantage is that anything that didn't map to Entrez is simply discarded (including drugs and small molecules!).\r\n",
      "comment_id": 242,
      "profile_id": 104,
      "published": "2015-06-09T01:15:52.903978Z",
      "thread_id": 72,
      "url": "/discussion/adding-pathway-resources-to-your-network/72"
    },
    {
      "body_html": "<p><a href=\"/u/alexanderpico\" class=\"username\">@alexanderpico</a>, thanks for letting us know about the best current pathway resources.</p>\r\n\r\n<h2>MSigDB Canonical Pathways</h2>\r\n\r\n<p>In the past, we used the versions of <a href=\"http://www.reactome.org/\">Reactome</a>, <a href=\"http://www.genome.jp/kegg/pathway.html\">KEGG</a>, and <a href=\"http://www.biocarta.com/\">BioCarta</a> provided by MSigDB <span class=\"citation\">[<a href=\"https://doi.org/10.1073/pnas.0506580102\" class=\"citation\" data-key=\"10.1073/pnas.0506580102\">1</a>, <a href=\"https://doi.org/10.1093/bioinformatics/btr260\" class=\"citation\" data-key=\"10.1093/bioinformatics/btr260\">2</a>]</span>. MSigDB version 5.0 was <a href=\"https://www.broadinstitute.org/cancer/software/gsea/wiki/index.php/MSigDB_v5.0_Release_Notes\">released in April</a>, but it's unclear whether the pathway resources were updated. However, the \"C2: Canonical Pathways\" (CP) collection <a href=\"https://www.broadinstitute.org/gsea/msigdb/collection_details.jsp#CP\">integrates 9</a> pathway resources, so I think we should create a <em>C2: CP</em> metanode with a node for each MSigDB CP gene set.</p>\r\n\r\n<h2>WikiPathways</h2>\r\n\r\n<p>We can have a separate metanode for <a href=\"//www.wikipathways.org/\">WikiPathways</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pbio.0060184\" class=\"citation\" data-key=\"10.1371/journal.pbio.0060184\">3</a>, <a href=\"https://doi.org/10.1093/nar/gkr1074\" class=\"citation\" data-key=\"10.1093/nar/gkr1074\">4</a>]</span>. The open and crowdsourced nature of WikiPathways is ideal. The inclusion of compounds, tissues, diseases in addition to genes in these pathways could provide a major performance boost for our method. The benefit will depends on how frequently non-gene entities are included in these pathways. What percent of pathways include diseases, tissues, or drugs? Additionally, are non-gene entities identified as free text, or are they structured by a standardized vocabulary?</p>\r\n\r\n<h2>Pathway Commons</h2>\r\n\r\n<p>I like how Pathway Commons <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkq1039\" class=\"citation\" data-key=\"10.1093/nar/gkq1039\">5</a>]</span> brings a common format to <a href=\"http://www.pathwaycommons.org/pc2/datasources\">many resources</a>. One worry is that Pathway Commons contains edges, such as those from DrugBank, which will be included elsewhere in the network. One solution would be to <a href=\"http://www.pathwaycommons.org/pc2/downloads\">pick and chose</a> which source databases to integrate from Pathway Commons. After including <em>MSigDB C2: CP</em> and <em>WikiPathways</em>, will Pathway Commons contain much information not already captured? If not, we may just stick with the above resources.</p>\r\n\r\n<h2>General Questions</h2>\r\n\r\n<ol><li>How much do these pathway resources overlap? Does WikiPathways include pathways directly taken from other databases?</li><li>Do databases differ greatly in quality or type of pathways encoded? If the databases do differ, it may make sense to give each a separate metanode. Otherwise, we will organize all pathways by 1 or 2 metanodes.</li></ol>",
      "body_md": "@alexanderpico, thanks for letting us know about the best current pathway resources.\r\n\r\n## MSigDB Canonical Pathways\r\n\r\nIn the past, we used the versions of [Reactome](http://www.reactome.org/), [KEGG](http://www.genome.jp/kegg/pathway.html), and [BioCarta](http://www.biocarta.com/) provided by MSigDB [@10.1073/pnas.0506580102 @10.1093/bioinformatics/btr260]. MSigDB version 5.0 was [released in April](https://www.broadinstitute.org/cancer/software/gsea/wiki/index.php/MSigDB_v5.0_Release_Notes), but it's unclear whether the pathway resources were updated. However, the \"C2: Canonical Pathways\" (CP) collection [integrates 9](https://www.broadinstitute.org/gsea/msigdb/collection_details.jsp#CP) pathway resources, so I think we should create a *C2: CP* metanode with a node for each MSigDB CP gene set.\r\n\r\n## WikiPathways\r\n\r\nWe can have a separate metanode for [WikiPathways](//www.wikipathways.org/) [@10.1371/journal.pbio.0060184 @10.1093/nar/gkr1074]. The open and crowdsourced nature of WikiPathways is ideal. The inclusion of compounds, tissues, diseases in addition to genes in these pathways could provide a major performance boost for our method. The benefit will depends on how frequently non-gene entities are included in these pathways. What percent of pathways include diseases, tissues, or drugs? Additionally, are non-gene entities identified as free text, or are they structured by a standardized vocabulary?\r\n\r\n## Pathway Commons\r\n\r\nI like how Pathway Commons [@10.1093/nar/gkq1039] brings a common format to [many resources](http://www.pathwaycommons.org/pc2/datasources). One worry is that Pathway Commons contains edges, such as those from DrugBank, which will be included elsewhere in the network. One solution would be to [pick and chose](http://www.pathwaycommons.org/pc2/downloads) which source databases to integrate from Pathway Commons. After including *MSigDB C2: CP* and *WikiPathways*, will Pathway Commons contain much information not already captured? If not, we may just stick with the above resources.\r\n\r\n## General Questions\r\n\r\n1. How much do these pathway resources overlap? Does WikiPathways include pathways directly taken from other databases?\r\n+ Do databases differ greatly in quality or type of pathways encoded? If the databases do differ, it may make sense to give each a separate metanode. Otherwise, we will organize all pathways by 1 or 2 metanodes.",
      "comment_id": 244,
      "profile_id": 17,
      "published": "2015-06-10T18:22:49.540745Z",
      "thread_id": 72,
      "url": "/discussion/adding-pathway-resources-to-your-network/72#2"
    },
    {
      "body_html": "<p><a href=\"/u/alexanderpico\" class=\"username\">@alexanderpico</a>, thanks for the BridgeDB suggestion. It looks like <a href=\"http://webservice.bridgedb.org/Human/targetDataSources\">several transcript/gene/protein resources</a> are integrated including HGNC, Entrez Gene, Affy, Illumina, WikiGenes, UniGene, UCSC Genome Browser, Uniprot, RefSeq, miRBase, and Ensembl. That's great — we may or may not need these mappings at this point.</p>\r\n\r\n<p>One worry I have is that the resource is outdated. The build date for human gene products is 2013-07-01. However, on 2014-11-21 version 2.0.0 was released. Does this mean the database was also rebuilt? In either case, I would like more frequent updates. Do you know the status of the project and whether it is actively maintained?</p>\r\n\r\n<p>One final note is that <a href=\"/u/caseygreene\" class=\"username\">@caseygreene</a>'s Tribe service allows free-text gene lookup, through elasticsearch. Currently, we do not need this feature. However, perhaps <a href=\"/u/alexanderpico\" class=\"username\">@alexanderpico</a> Pathways4Life project <span class=\"citation\">[<a href=\"/p/pathways4life\" class=\"citation\" data-key=\"10.15363/thinklab.8\">1</a>]</span> does. Also, perhaps <a href=\"http://tribe.greenelab.com/#/home\">Tribe</a>—a gene set wiki with a private option—would like to autopopulate <a href=\"//www.wikipathways.org/index.php/WikiPathways\">WikiPathways</a>.</p>",
      "body_md": "@alexanderpico, thanks for the BridgeDB suggestion. It looks like [several transcript/gene/protein resources](http://webservice.bridgedb.org/Human/targetDataSources) are integrated including HGNC, Entrez Gene, Affy, Illumina, WikiGenes, UniGene, UCSC Genome Browser, Uniprot, RefSeq, miRBase, and Ensembl. That's great -- we may or may not need these mappings at this point.\r\n\r\nOne worry I have is that the resource is outdated. The build date for human gene products is 2013-07-01. However, on 2014-11-21 version 2.0.0 was released. Does this mean the database was also rebuilt? In either case, I would like more frequent updates. Do you know the status of the project and whether it is actively maintained?\r\n\r\nOne final note is that @caseygreene's Tribe service allows free-text gene lookup, through elasticsearch. Currently, we do not need this feature. However, perhaps @alexanderpico Pathways4Life project [@10.15363/thinklab.8] does. Also, perhaps [Tribe](http://tribe.greenelab.com/#/home)---a gene set wiki with a private option---would like to autopopulate [WikiPathways](//www.wikipathways.org/index.php/WikiPathways).",
      "comment_id": 245,
      "profile_id": 17,
      "published": "2015-06-10T18:47:13.538545Z",
      "thread_id": 34,
      "url": "/discussion/using-entrez-gene-as-our-gene-vocabulary/34#7"
    },
    {
      "body_html": "<p>Right. The database build system was recently updated from using Ensembl's Perl API to using BioMart. This will allow frequent updates; probably quarterly.</p>",
      "body_md": "Right. The database build system was recently updated from using Ensembl's Perl API to using BioMart. This will allow frequent updates; probably quarterly.",
      "comment_id": 246,
      "profile_id": 104,
      "published": "2015-06-10T19:08:23.025368Z",
      "thread_id": 34,
      "url": "/discussion/using-entrez-gene-as-our-gene-vocabulary/34#8"
    },
    {
      "body_html": "<p>Figures 1 and 2 in <a href=\"http://thinklab.com/p/pathways4life\">the Pathways4Life proposal</a> will answer questions about overlap and frequency of updates.  Pathway Commons is not a primary source; their focus is on compiling from as many sources as possible. So, given their restriction to BioPAX, they definitely include more than any single resource.</p>",
      "body_md": "Figures 1 and 2 in [the Pathways4Life proposal](http://thinklab.com/p/pathways4life) will answer questions about overlap and frequency of updates.  Pathway Commons is not a primary source; their focus is on compiling from as many sources as possible. So, given their restriction to BioPAX, they definitely include more than any single resource.",
      "comment_id": 247,
      "profile_id": 104,
      "published": "2015-06-10T19:12:41.943422Z",
      "thread_id": 72,
      "url": "/discussion/adding-pathway-resources-to-your-network/72#3"
    },
    {
      "body_html": "<p><a href=\"/u/alexanderpico\" class=\"username\">@alexanderpico</a>, thanks figures 1 and 2 do help, however I am more interested in <a href=\"http://thinklab.com/discussion/pathway-novelty-based-on-unique-relationships-rather-than-genes/75\">edge-based measures of overlap</a>. Do you have a general sense of whether the same pathways are represented in multiple databases?</p>\r\n\r\n<p>My interpretation of Figure 1 is that it provides a lower bound of uniqueness. The fact that there are many genes unique in KEGG, Reactome, and WikiPathways warrants the inclusion of all three resources. However, it doesn't answer whether the common genes are from duplicated pathways or not.</p>",
      "body_md": "@alexanderpico, thanks figures 1 and 2 do help, however I am more interested in [edge-based measures of overlap](http://thinklab.com/discussion/pathway-novelty-based-on-unique-relationships-rather-than-genes/75). Do you have a general sense of whether the same pathways are represented in multiple databases?\r\n\r\nMy interpretation of Figure 1 is that it provides a lower bound of uniqueness. The fact that there are many genes unique in KEGG, Reactome, and WikiPathways warrants the inclusion of all three resources. However, it doesn't answer whether the common genes are from duplicated pathways or not.",
      "comment_id": 252,
      "profile_id": 17,
      "published": "2015-06-11T00:29:13.219315Z",
      "thread_id": 72,
      "url": "/discussion/adding-pathway-resources-to-your-network/72#4"
    },
    {
      "body_html": "<p><a href=\"/u/marinasirota\" class=\"username\">@marinasirota</a>, thanks for the advice.</p>\r\n\r\n<p>The <a href=\"https://www.broadinstitute.org/mpg/snap/ldsearch.php\">SNAP Proxy Search</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/bioinformatics/btn564\" class=\"citation\" data-key=\"10.1093/bioinformatics/btn564\">1</a>]</span> allows us to find all SNPs within 500kb and with LD above a provided threshold for the query SNP, using 1000 Genomes (KG) pilot data.</p>\r\n\r\n<p>One issue with KG is that the whole-genome sequencing was done at low depth (4x coverage) and that only 179 samples were sequenced: 60 CEU, 59 YRI, 30 CHB, and 30 JPT <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nature09534\" class=\"citation\" data-key=\"10.1038/nature09534\">2</a>]</span>. Therefore many low frequency or technically difficult variants were likely missed. Since GWAS have mostly focused on common variants, the puniness of 1000 Genomes pilot data may be acceptable.</p>\r\n\r\n<p>We went ahead and evaluated the SNAP LD information from KG for our GWAS lead SNPs. For each lead SNP, we found all SNPs in <span class=\"math\">$$r^2 \\geq 0.8$$</span> in the European subset of 60 individuals. The <a href=\"https://github.com/dhimmel/gwas-catalog/blob/568e063010d725c335a019ac20c2d023d000f5d4/windows.ipynb\">findings are as follows</a>:</p>\r\n\r\n<ul><li>Of 5,255 GWAS lead SNPs, 517 were not found by SNAP</li><li>SNPs with lower minor allele frequencies were more likely to have large windows (kilobase spans). We speculate this results from greater noise in <span class=\"math\">$$r^2$$</span> values when the number of minor alleles is low, enabling far away SNPs to appear in high LD by chance. </li><li>614 lead SNPs have a zero-length span — no SNPs were found with LD exceeding the threshold. Most likely this is due to the incompleteness of KG.</li><li>Window spans measured in kilobases are highly, positively correlated with spans measured in centimorgans. Therefore, we cannot chose a single centimorgan threshold to approximate windows calculated using the <span class=\"math\">$$r^2$$</span> method.</li></ul>\r\n\r\n<p>In conclusion, the KG data retrieved from SNAP is feasible but not ideal. We will look into larger datasets and have <a href=\"https://github.com/konradjk/exac_browser/issues/189\">reached out to the ExAC team</a>.</p>",
      "body_md": "@marinasirota, thanks for the advice.\r\n\r\nThe [SNAP Proxy Search](https://www.broadinstitute.org/mpg/snap/ldsearch.php) [@10.1093/bioinformatics/btn564] allows us to find all SNPs within 500kb and with LD above a provided threshold for the query SNP, using 1000 Genomes (KG) pilot data.\r\n\r\nOne issue with KG is that the whole-genome sequencing was done at low depth (4x coverage) and that only 179 samples were sequenced: 60 CEU, 59 YRI, 30 CHB, and 30 JPT [@10.1038/nature09534]. Therefore many low frequency or technically difficult variants were likely missed. Since GWAS have mostly focused on common variants, the puniness of 1000 Genomes pilot data may be acceptable.\r\n\r\nWe went ahead and evaluated the SNAP LD information from KG for our GWAS lead SNPs. For each lead SNP, we found all SNPs in $$r^2 \\geq 0.8$$ in the European subset of 60 individuals. The [findings are as follows](https://github.com/dhimmel/gwas-catalog/blob/568e063010d725c335a019ac20c2d023d000f5d4/windows.ipynb):\r\n\r\n+ Of 5,255 GWAS lead SNPs, 517 were not found by SNAP\r\n+ SNPs with lower minor allele frequencies were more likely to have large windows (kilobase spans). We speculate this results from greater noise in $$r^2$$ values when the number of minor alleles is low, enabling far away SNPs to appear in high LD by chance. \r\n+ 614 lead SNPs have a zero-length span -- no SNPs were found with LD exceeding the threshold. Most likely this is due to the incompleteness of KG.\r\n+ Window spans measured in kilobases are highly, positively correlated with spans measured in centimorgans. Therefore, we cannot chose a single centimorgan threshold to approximate windows calculated using the $$r^2$$ method.\r\n\r\nIn conclusion, the KG data retrieved from SNAP is feasible but not ideal. We will look into larger datasets and have [reached out to the ExAC team](https://github.com/konradjk/exac_browser/issues/189).",
      "comment_id": 254,
      "profile_id": 17,
      "published": "2015-06-11T22:14:15.659411Z",
      "thread_id": 71,
      "url": "/discussion/calculating-genomic-windows-for-gwas-lead-snps/71#3"
    },
    {
      "body_html": "<p>That measure of overlap is fraught with caveats relating to exactly how edges are modeled. When each of the three resource mentioned here converts to a single exchange format, like BioPAX, for example, we each make a unique set of mapping decisions and compromises. Nevertheless, you're absolutely right that node overlap is a lower bound, but I don't have a good estimate for edge overlap. Just browsing the pathway titles is the most convincing way to see that we cover much of the same ground: metabolism, signaling and gene regulation.</p>",
      "body_md": "That measure of overlap is fraught with caveats relating to exactly how edges are modeled. When each of the three resource mentioned here converts to a single exchange format, like BioPAX, for example, we each make a unique set of mapping decisions and compromises. Nevertheless, you're absolutely right that node overlap is a lower bound, but I don't have a good estimate for edge overlap. Just browsing the pathway titles is the most convincing way to see that we cover much of the same ground: metabolism, signaling and gene regulation.",
      "comment_id": 257,
      "profile_id": 104,
      "published": "2015-06-12T02:05:40.666985Z",
      "thread_id": 72,
      "url": "/discussion/adding-pathway-resources-to-your-network/72#5"
    },
    {
      "body_html": "<h1>Permissive <span class=\"math\">$$r^2$$</span> threshold when relying on low-powered LD data</h1>\r\n\r\n<p><a href=\"/u/marinasirota\" class=\"username\">@marinasirota</a>, I intuitively agree that for the modern GWAS assaying and imputing millions of SNPs, lead SNPs are likely be in <span class=\"math\">$$r^2 \\geq 0.8$$</span> with the SNPs driving the association. However, when using the 1000 Genomes Pilot data for LD, I think we should use a more permissive threshold of <span class=\"math\">$$r^2 \\geq 0.5$$</span>. The 0.8 threshold produces <a href=\"https://github.com/dhimmel/gwas-catalog/blob/568e063010d725c335a019ac20c2d023d000f5d4/windows.ipynb\">614</a> windows with zero-length spans compared to <a href=\"https://github.com/dhimmel/gwas-catalog/blob/cbc30cbe88bda38c7ebe9c32802b051436431065/windows.ipynb\">149</a> for the 0.5 threshold. Zero-length spans are equivalent to declaring that the lead SNP is the only SNP capable of creating the association. I would prefer to minimize these instances when we have such incomplete LD information.</p>",
      "body_md": "# Permissive $$r^2$$ threshold when relying on low-powered LD data\r\n\r\n@marinasirota, I intuitively agree that for the modern GWAS assaying and imputing millions of SNPs, lead SNPs are likely be in $$r^2 \\geq 0.8$$ with the SNPs driving the association. However, when using the 1000 Genomes Pilot data for LD, I think we should use a more permissive threshold of $$r^2 \\geq 0.5$$. The 0.8 threshold produces [614](https://github.com/dhimmel/gwas-catalog/blob/568e063010d725c335a019ac20c2d023d000f5d4/windows.ipynb) windows with zero-length spans compared to [149](https://github.com/dhimmel/gwas-catalog/blob/cbc30cbe88bda38c7ebe9c32802b051436431065/windows.ipynb) for the 0.5 threshold. Zero-length spans are equivalent to declaring that the lead SNP is the only SNP capable of creating the association. I would prefer to minimize these instances when we have such incomplete LD information.",
      "comment_id": 259,
      "profile_id": 17,
      "published": "2015-06-12T18:15:23.590185Z",
      "thread_id": 71,
      "url": "/discussion/calculating-genomic-windows-for-gwas-lead-snps/71#4"
    },
    {
      "body_html": "<p><a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a> - that makes sense.  </p>",
      "body_md": "@dhimmel - that makes sense.  ",
      "comment_id": 260,
      "profile_id": 103,
      "published": "2015-06-12T20:00:07.588699Z",
      "thread_id": 71,
      "url": "/discussion/calculating-genomic-windows-for-gwas-lead-snps/71#5"
    },
    {
      "body_html": "<p>We recently worked on a (mini-)study to investigate the relationship between the ERC values of gene-pairs and the extent to which they share their interacting partners. The Jaccard coefficient was used to quantify the extent to which genes share interacting partners (higher the Jaccard, more the fraction of interacting partners shared). We used the yeast ERC dataset, and interestingly found that there is a weak, but significant positive correlation between ERC values of gene pairs and Jaccard coefficient (JC) of the interacting partners of the two genes. We additionally saw that using JC in conjunction with ERC has potential to reduce the number of false discoveries in interaction prediction. I could attach the full report of our investigation if it interests you.</p>\r\n\r\n<p>I think it would be interesting to refine the approach further, and apply the same in the human context as well - it may very well turn out to be more powerful than thresholding based on ERC values.</p>",
      "body_md": "We recently worked on a (mini-)study to investigate the relationship between the ERC values of gene-pairs and the extent to which they share their interacting partners. The Jaccard coefficient was used to quantify the extent to which genes share interacting partners (higher the Jaccard, more the fraction of interacting partners shared). We used the yeast ERC dataset, and interestingly found that there is a weak, but significant positive correlation between ERC values of gene pairs and Jaccard coefficient (JC) of the interacting partners of the two genes. We additionally saw that using JC in conjunction with ERC has potential to reduce the number of false discoveries in interaction prediction. I could attach the full report of our investigation if it interests you.\r\n\r\nI think it would be interesting to refine the approach further, and apply the same in the human context as well - it may very well turn out to be more powerful than thresholding based on ERC values.",
      "comment_id": 268,
      "profile_id": 107,
      "published": "2015-06-16T18:28:41.237981Z",
      "thread_id": 57,
      "url": "/discussion/selecting-informative-erc-evolutionary-rate-covariation-values-between-genes/57#2"
    },
    {
      "body_html": "<p>The protein interaction project sounds interesting. Have you considered using a random walk with restart on the protein interaction network for PPI-similarity? I think you will find it preferable to the Jaccard coefficient, since it considers more than just first degree neighbors. I have some python code for the random walk that I can open source, if you can't find an implementation. What protein interaction network are you using? I think a systematic PPI network (that isn't ridden with knowledge bias) would be especially interesting. I suggest the HI-II-14 network from <a href=\"http://interactome.dfci.harvard.edu/H_sapiens/index.php?page=download\">here</a>.</p>\r\n\r\n<p>In terms of this project, we would like to keep the ERC edges independent of the PPI edges. The ERC values are attractive to us as a completely orthogonal resource to the protein interactions.</p>",
      "body_md": "The protein interaction project sounds interesting. Have you considered using a random walk with restart on the protein interaction network for PPI-similarity? I think you will find it preferable to the Jaccard coefficient, since it considers more than just first degree neighbors. I have some python code for the random walk that I can open source, if you can't find an implementation. What protein interaction network are you using? I think a systematic PPI network (that isn't ridden with knowledge bias) would be especially interesting. I suggest the HI-II-14 network from [here](http://interactome.dfci.harvard.edu/H_sapiens/index.php?page=download).\r\n\r\nIn terms of this project, we would like to keep the ERC edges independent of the PPI edges. The ERC values are attractive to us as a completely orthogonal resource to the protein interactions.",
      "comment_id": 270,
      "profile_id": 17,
      "published": "2015-06-16T18:47:14.342149Z",
      "thread_id": 57,
      "url": "/discussion/selecting-informative-erc-evolutionary-rate-covariation-values-between-genes/57#3"
    },
    {
      "body_html": "<p>The <a href=\"https://www.ebi.ac.uk/gwas/\">GWAS Catalog</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkt1229\" class=\"citation\" data-key=\"10.1093/nar/gkt1229\">1</a>]</span> compiles SNP associations from published genome-wide studies. We converted the catalog from SNP associations to gene associations. We classify each gene association as high or low confidence and as primary or secondary (based on whether the gene is assumed to drive the signal at a loci).</p>\r\n\r\n<p>We only extracted associations for diseases in <a href=\"http://thinklab.com/discussion/unifying-disease-vocabularies/44#144\">DO Slim</a>, which should cover most diseases in the catalog while excluding traits. Genes are restricted to protein-coding.</p>\r\n\r\n<h2>External resources</h2>\r\n\r\n<ul><li><a href=\"https://github.com/dhimmel/gwas-catalog/blob/0617ea7ea8268f21f5ca1b8dbe487dd12671fc7b/data/gene-associations.tsv\"><strong>compiled gene associations</strong></a></li><li>summary files with <a href=\"https://github.com/dhimmel/gwas-catalog/blob/0617ea7ea8268f21f5ca1b8dbe487dd12671fc7b/data/diseases.tsv\">associations per disease</a> and <a href=\"https://github.com/dhimmel/gwas-catalog/blob/0617ea7ea8268f21f5ca1b8dbe487dd12671fc7b/data/genes.tsv\">associations per gene</a></li><li><a href=\"https://github.com/dhimmel/gwas-catalog/blob/0617ea7ea8268f21f5ca1b8dbe487dd12671fc7b/data/snp-associations.tsv\">compiled SNP associations</a> — a processed subset of the GWAS Catalog</li><li><a href=\"https://github.com/dhimmel/gwas-catalog/blob/0617ea7ea8268f21f5ca1b8dbe487dd12671fc7b/loci.ipynb\">notebook</a> for processing loci</li><li><a href=\"http://thinklab.com/discussion/calculating-genomic-windows-for-gwas-lead-snps/71\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d71\">discussion</a> and <a href=\"https://github.com/dhimmel/gwas-catalog/blob/0617ea7ea8268f21f5ca1b8dbe487dd12671fc7b/windows.ipynb\">notebook</a> for calculating lead-SNP windows</li></ul>\r\n\r\n<h2>Method</h2>\r\n\r\n<p>The method for processing associations was taken from our previous work <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1004259\">2</a>]</span>, which describes it as follows (modifications afterwards):</p>\r\n\r\n<blockquote><p>Disease-gene associations were extracted from the GWAS Catalog <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkt1229\" class=\"citation\" data-key=\"10.1093/nar/gkt1229\">1</a>]</span>, a compilation of GWAS associations where <span class=\"math\">$$p . First, associations were segregated by disease. GWAS Catalog phenotypes were converted to Experimental Factor Ontology (EFO) terms using mappings produced by the European Bioinformatics Institute. Associations mapping to multiple EFO terms were excluded to eliminate cross-phenotype studies. We manually mapped EFO to DO terms (now included in the DO as cross-references) and annotated each DO term with its associations.</span></p><p>Associations were classified as either high or low-confidence, where exceeding two thresholds granted high-confidence status. First, <span class=\"math\">$$p \\leq 5 × 10^{-8}$$</span> corresponding to  <span class=\"math\">$$p \\leq 0.05$$</span> after Bonferroni adjustment for one million comparisons (an approximate upper bound for the number of independent SNPs evaluated by most GWAS). Second, a minimum sample size (counting both cases and controls) of 1,000 was required, since studies below this size are underpowered <span class=\"citation\">[<a href=\"https://doi.org/10.1093/brain/awn081\" class=\"citation\" data-key=\"10.1093/brain/awn081\">3</a>]</span>—i.e. any discovered associations are more likely than not to be false—for the majority of true effect size distributions commonly assumed to underlie complex disease etiology <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nrg2615\" class=\"citation\" data-key=\"10.1038/nrg2615\">4</a>]</span>.</p><p>Lead-SNPs were assigned windows—regions wherein the causal SNPs are assumed to lie—retrieved from the DAPPLE server <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pgen.1001273\" class=\"citation\" data-key=\"10.1371/journal.pgen.1001273\">5</a>]</span>. Windows were calculated for each lead-SNP by finding the furthest upstream and downstream SNPs where <span class=\"math\">$$r^2 &gt; 0.5$$</span> and extending outwards to the next recombination hotspot. Associations were ordered by confidence, sorting on following criteria: high/low confidence, p-value (low to high), and recency. In order of confidence, associations were overlapped by their windows into disease-specific loci. By organizing associations into loci, associations from multiple studies tagging the same underlying signal were condensed. A locus was classified as high-confidence if any of its composite associations were high-confidence and low-confidence otherwise.</p><p>For each disease-specific loci, we attempted to identify a primary gene. The primary gene was resolved in the following order:</p><ol><li>the mode author-reported gene</li><li>the containing gene for an intragenic lead-SNP</li><li>the mode author-reported gene for an intragenic lead-SNP (in the case of overlapping genes)</li><li>the mode author-reported gene of the most proximal up and downstream genes.</li></ol><p>Steps 2–4 were repeated on each association composing the loci, in order of confidence, until a single gene resolved as primary. Loci where ambiguity was unresolvable or where no genes were returned did not receive a primary gene. All non-primary genes—genes that were author-reported, overlapping the lead-SNP, or immediately up or downstream from the lead-SNP—were considered secondary.</p><p>Accordingly, four categories of processed associations were created: high-confidence primary, high-confidence secondary, low-confidence primary, and low-confidence secondary. We assume that our primary gene annotation for each loci represents the single causal gene responsible for the association.</p></blockquote>\r\n\r\n<h2>Method modifications</h2>\r\n\r\n<p>We <a href=\"http://thinklab.com/discussion/calculating-genomic-windows-for-gwas-lead-snps/71\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d71\">switched</a> from HapMap LD data provided by DAPPLE to 1000 Genomes LD data provided by SNAP and removed the recombination hotspot extensions. </p>",
      "body_md": "The [GWAS Catalog](https://www.ebi.ac.uk/gwas/) [@10.1093/nar/gkt1229] compiles SNP associations from published genome-wide studies. We converted the catalog from SNP associations to gene associations. We classify each gene association as high or low confidence and as primary or secondary (based on whether the gene is assumed to drive the signal at a loci).\r\n\r\nWe only extracted associations for diseases in [DO Slim](http://thinklab.com/discussion/unifying-disease-vocabularies/44#144), which should cover most diseases in the catalog while excluding traits. Genes are restricted to protein-coding.\r\n\r\n## External resources\r\n\r\n+ [**compiled gene associations**](https://github.com/dhimmel/gwas-catalog/blob/0617ea7ea8268f21f5ca1b8dbe487dd12671fc7b/data/gene-associations.tsv)\r\n+ summary files with [associations per disease](https://github.com/dhimmel/gwas-catalog/blob/0617ea7ea8268f21f5ca1b8dbe487dd12671fc7b/data/diseases.tsv) and [associations per gene](https://github.com/dhimmel/gwas-catalog/blob/0617ea7ea8268f21f5ca1b8dbe487dd12671fc7b/data/genes.tsv)\r\n+ [compiled SNP associations](https://github.com/dhimmel/gwas-catalog/blob/0617ea7ea8268f21f5ca1b8dbe487dd12671fc7b/data/snp-associations.tsv) -- a processed subset of the GWAS Catalog\r\n+ [notebook](https://github.com/dhimmel/gwas-catalog/blob/0617ea7ea8268f21f5ca1b8dbe487dd12671fc7b/loci.ipynb) for processing loci\r\n+ [discussion](http://thinklab.com/discussion/calculating-genomic-windows-for-gwas-lead-snps/71) and [notebook](https://github.com/dhimmel/gwas-catalog/blob/0617ea7ea8268f21f5ca1b8dbe487dd12671fc7b/windows.ipynb) for calculating lead-SNP windows\r\n\r\n## Method\r\n\r\nThe method for processing associations was taken from our previous work [@10.1371/journal.pcbi.1004259], which describes it as follows (modifications afterwards):\r\n\r\n> Disease-gene associations were extracted from the GWAS Catalog [@10.1093/nar/gkt1229], a compilation of GWAS associations where $$p < 10^{−5}$$. First, associations were segregated by disease. GWAS Catalog phenotypes were converted to Experimental Factor Ontology (EFO) terms using mappings produced by the European Bioinformatics Institute. Associations mapping to multiple EFO terms were excluded to eliminate cross-phenotype studies. We manually mapped EFO to DO terms (now included in the DO as cross-references) and annotated each DO term with its associations.\r\n\r\n> Associations were classified as either high or low-confidence, where exceeding two thresholds granted high-confidence status. First, $$p \\leq 5 × 10^{-8}$$ corresponding to  $$p \\leq 0.05$$ after Bonferroni adjustment for one million comparisons (an approximate upper bound for the number of independent SNPs evaluated by most GWAS). Second, a minimum sample size (counting both cases and controls) of 1,000 was required, since studies below this size are underpowered [@10.1093/brain/awn081]---i.e. any discovered associations are more likely than not to be false---for the majority of true effect size distributions commonly assumed to underlie complex disease etiology [@10.1038/nrg2615].\r\n\r\n> Lead-SNPs were assigned windows—regions wherein the causal SNPs are assumed to lie—retrieved from the DAPPLE server [@10.1371/journal.pgen.1001273]. Windows were calculated for each lead-SNP by finding the furthest upstream and downstream SNPs where $$r^2 > 0.5$$ and extending outwards to the next recombination hotspot. Associations were ordered by confidence, sorting on following criteria: high/low confidence, p-value (low to high), and recency. In order of confidence, associations were overlapped by their windows into disease-specific loci. By organizing associations into loci, associations from multiple studies tagging the same underlying signal were condensed. A locus was classified as high-confidence if any of its composite associations were high-confidence and low-confidence otherwise.\r\n\r\n> For each disease-specific loci, we attempted to identify a primary gene. The primary gene was resolved in the following order:\r\n>\r\n1. the mode author-reported gene\r\n2. the containing gene for an intragenic lead-SNP\r\n3. the mode author-reported gene for an intragenic lead-SNP (in the case of overlapping genes)\r\n4. the mode author-reported gene of the most proximal up and downstream genes.\r\n\r\n> Steps 2–4 were repeated on each association composing the loci, in order of confidence, until a single gene resolved as primary. Loci where ambiguity was unresolvable or where no genes were returned did not receive a primary gene. All non-primary genes—genes that were author-reported, overlapping the lead-SNP, or immediately up or downstream from the lead-SNP—were considered secondary.\r\n\r\n> Accordingly, four categories of processed associations were created: high-confidence primary, high-confidence secondary, low-confidence primary, and low-confidence secondary. We assume that our primary gene annotation for each loci represents the single causal gene responsible for the association.\r\n\r\n## Method modifications\r\n\r\nWe [switched](http://thinklab.com/discussion/calculating-genomic-windows-for-gwas-lead-snps/71) from HapMap LD data provided by DAPPLE to 1000 Genomes LD data provided by SNAP and removed the recombination hotspot extensions. ",
      "comment_id": 271,
      "profile_id": 17,
      "published": "2015-06-16T20:43:50.492291Z",
      "thread_id": 80,
      "url": "/discussion/extracting-disease-gene-associations-from-the-gwas-catalog/80"
    },
    {
      "body_html": "<p>We would to know the expression level of each gene in as many tissues and cell types as possible. Humans only for now. What are the best resources and methods to go about this?</p>\r\n\r\n<p>Here are some relevant resources we compiled (in order of preference):</p>\r\n\r\n<ol><li>The Genotype-Tissue Expression project (<a href=\"http://www.gtexportal.org/home/\">GTEx</a>) <span class=\"citation\">[<a href=\"https://doi.org/10.1126/science.aaa0355\" class=\"citation\" data-key=\"10.1126/science.aaa0355\">1</a>]</span></li><li>Baseline Expression Atlas (<a href=\"//www.ebi.ac.uk/gxa/help/baseline-atlas.html\">BEA</a>) <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkt1270\" class=\"citation\" data-key=\"10.1093/nar/gkt1270\">2</a>]</span></li><li>Human Protein Atlas (<a href=\"//www.proteinatlas.org/\">HPA</a>) <span class=\"citation\">[<a href=\"https://doi.org/10.1126/science.1260419\" class=\"citation\" data-key=\"10.1126/science.1260419\">3</a>]</span></li><li>GNF Gene Expression Atlas (<a href=\"http://biogps.org/dataset/1/geneatlas-u133a-gcrma/\">BodyMap</a>) <span class=\"citation\">[<a href=\"https://doi.org/10.1073/pnas.0400782101\" class=\"citation\" data-key=\"10.1073/pnas.0400782101\">4</a>]</span></li><li>Human Proteome Map (<a href=\"http://www.humanproteomemap.org/\">HPM</a>) <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nature13302\" class=\"citation\" data-key=\"10.1038/nature13302\">5</a>]</span></li><li>Gene Enrichment Profiler (<a href=\"//xavierlab2.mgh.harvard.edu/EnrichmentProfiler/\">GEP</a>) <span class=\"citation\">[<a href=\"https://doi.org/10.1182/blood-2010-01-263855\" class=\"citation\" data-key=\"10.1182/blood-2010-01-263855\">6</a>]</span></li><li>A global map of human gene expression (<a href=\"https://www.ebi.ac.uk/arrayexpress/experiments/E-MTAB-62/\">E-MTAB-62</a>) <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nbt0410-322\" class=\"citation\" data-key=\"10.1038/nbt0410-322\">7</a>]</span></li><li>Unveiling RNA Sample Annotation (<a href=\"//ursa.princeton.edu/\">USRA</a>) <span class=\"citation\">[<a href=\"https://doi.org/10.1093/bioinformatics/btt529\" class=\"citation\" data-key=\"10.1093/bioinformatics/btt529\">8</a>]</span></li><li>RNA-Seq Atlas <span class=\"citation\">[<a href=\"https://doi.org/10.1093/bioinformatics/bts084\" class=\"citation\" data-key=\"10.1093/bioinformatics/bts084\">9</a>]</span></li></ol>\r\n\r\n<p><strong>Additional resources found since initial post</strong>:</p>\r\n\r\n<ul><li><a href=\"http://bgee.unil.ch/\">Bgee</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1007/978-3-540-69828-9_12\" class=\"citation\" data-key=\"10.1007/978-3-540-69828-9_12\">10</a>]</span></li><li><a href=\"http://tissues.jensenlab.org/About\">TISSUES</a> <span class=\"citation\">[<a href=\"https://doi.org/10.7717/peerj.1054\" class=\"citation\" data-key=\"10.7717/peerj.1054\">11</a>]</span></li></ul>",
      "body_md": "We would to know the expression level of each gene in as many tissues and cell types as possible. Humans only for now. What are the best resources and methods to go about this?\r\n\r\nHere are some relevant resources we compiled (in order of preference):\r\n\r\n1. The Genotype-Tissue Expression project ([GTEx](http://www.gtexportal.org/home/)) [@10.1126/science.aaa0355]\r\n+ Baseline Expression Atlas ([BEA](//www.ebi.ac.uk/gxa/help/baseline-atlas.html)) [@10.1093/nar/gkt1270]\r\n+ Human Protein Atlas ([HPA](//www.proteinatlas.org/)) [@10.1126/science.1260419]\r\n+ GNF Gene Expression Atlas ([BodyMap](http://biogps.org/dataset/1/geneatlas-u133a-gcrma/)) [@10.1073/pnas.0400782101]\r\n+ Human Proteome Map ([HPM](http://www.humanproteomemap.org/)) [@10.1038/nature13302]\r\n+ Gene Enrichment Profiler ([GEP](//xavierlab2.mgh.harvard.edu/EnrichmentProfiler/)) [@10.1182/blood-2010-01-263855]\r\n+ A global map of human gene expression ([E-MTAB-62](https://www.ebi.ac.uk/arrayexpress/experiments/E-MTAB-62/)) [@10.1038/nbt0410-322]\r\n+ Unveiling RNA Sample Annotation ([USRA](//ursa.princeton.edu/)) [@10.1093/bioinformatics/btt529]\r\n+ RNA-Seq Atlas [@10.1093/bioinformatics/bts084]\r\n\r\n**Additional resources found since initial post**:\r\n\r\n+ [Bgee](http://bgee.unil.ch/) [@10.1007/978-3-540-69828-9_12]\r\n+ [TISSUES](http://tissues.jensenlab.org/About) [@10.7717/peerj.1054]",
      "comment_id": 272,
      "profile_id": 17,
      "published": "2015-06-17T18:56:26.669391Z",
      "thread_id": 81,
      "url": "/discussion/tissue-specific-gene-expression-resources/81"
    },
    {
      "body_html": "<p><a href=\"/u/marinasirota\" class=\"username\">@marinasirota</a> recommended GTEx because of the large number samples per tissue and the use of RNA-seq.</p>",
      "body_md": "@marinasirota recommended GTEx because of the large number samples per tissue and the use of RNA-seq.",
      "comment_id": 273,
      "profile_id": 17,
      "published": "2015-06-17T18:56:34.553541Z",
      "thread_id": 81,
      "url": "/discussion/tissue-specific-gene-expression-resources/81#2"
    },
    {
      "body_html": "<p>The Genotype-Tissue Expression project (<a href=\"http://www.gtexportal.org/home/\">GTEx</a>) RNA-sequenced <span class=\"citation\">[<a href=\"https://doi.org/10.1126/science.aaa0355\" class=\"citation\" data-key=\"10.1126/science.aaa0355\">1</a>]</span>:</p>\r\n\r\n<blockquote><p>1641 samples from 175 individuals representing 43 sites: 29 solid organ tissues, 11 brain subregions, whole blood, and two cell lines: Epstein-Barr virus–transformed lymphocytes (LCL) and cultured fibroblasts from skin.</p></blockquote>\r\n\r\n<p>The data is <a href=\"http://www.gtexportal.org/home/datasets2\">available online</a>. Specifically, we are interested in the <code>GTEx_Analysis_V4_RNA-seq_RNA-SeQCv1.1.8_gene_rpkm.gct.gz</code> file that contains RPKM expression values for each sample. We would like to calculate a single expression value for each gene-tissue pair. Expression values should be comparable across tissues, not just within tissues.</p>\r\n\r\n<p>We will post our questions here. Advice appreciated.</p>",
      "body_md": "The Genotype-Tissue Expression project ([GTEx](http://www.gtexportal.org/home/)) RNA-sequenced [@10.1126/science.aaa0355]:\r\n\r\n> 1641 samples from 175 individuals representing 43 sites: 29 solid organ tissues, 11 brain subregions, whole blood, and two cell lines: Epstein-Barr virus–transformed lymphocytes (LCL) and cultured fibroblasts from skin.\r\n\r\nThe data is [available online](http://www.gtexportal.org/home/datasets2). Specifically, we are interested in the `GTEx_Analysis_V4_RNA-seq_RNA-SeQCv1.1.8_gene_rpkm.gct.gz` file that contains RPKM expression values for each sample. We would like to calculate a single expression value for each gene-tissue pair. Expression values should be comparable across tissues, not just within tissues.\r\n\r\nWe will post our questions here. Advice appreciated.",
      "comment_id": 274,
      "profile_id": 17,
      "published": "2015-06-17T20:51:35.154243Z",
      "thread_id": 82,
      "url": "/discussion/processing-gtex-for-tissue-specific-gene-expression/82"
    },
    {
      "body_html": "<h1>Mapping GTEx sites to Uberon and CL</h1>\r\n\r\n<p>We <a href=\"//thinklab.com/discussion/tissue-node/41\">are using</a> <a href=\"https://uberon.github.io/\">Uberon</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1186/gb-2012-13-1-r5\" class=\"citation\" data-key=\"10.1186/gb-2012-13-1-r5\">1</a>]</span> terms to identify anatomical structures and <a href=\"https://github.com/obophenotype/cell-ontology\">Cell Ontology</a> (CL) <span class=\"citation\">[<a href=\"https://doi.org/10.1186/gb-2005-6-2-r21\" class=\"citation\" data-key=\"10.1186/gb-2005-6-2-r21\">2</a>]</span> terms to identify cell types. Thus, we need to map GTEx sites to their corresponding ontology terms.</p>\r\n\r\n<p>From the sample attribute documentation (<code>GTEx_Data_V4_Annotations_SampleAttributesDS.txt</code>), we <a href=\"https://github.com/dhimmel/gtex/blob/8acb90fea2613f8b27814401e361bb6ae4b29078/gtex.ipynb\">identified</a> 54 sites using the <code>SMTSD</code> attribute. I have mapped about half of the sites to Uberon. The remainder would benefit from a skilled anatomist or GTEx consortium member.</p>\r\n\r\n<p><strong>Bounty:</strong> Add or correct <a href=\"https://docs.google.com/spreadsheets/d/1aXm_RvD4aywXRpQdxVxjBxwPAR_YBBq9f3xkHQaLZXo/edit?usp=sharing\">our mappings using this spreadsheet</a> and put your Thinklab username. Then leave a comment in this discussion, and we will rate its value <span class=\"math\">$$\\geq $4 \\times n$$</span>, where <em>n</em> is the number of mappings provided.</p>\r\n\r\n<p>Some additional sample site information is available in Table S1 (p. 58) of the <a href=\"//www.sciencemag.org/content/suppl/2015/05/06/348.6235.660.DC1/Mele.SM.pdf\">supplement</a>.</p>",
      "body_md": "# Mapping GTEx sites to Uberon and CL\r\n\r\nWe [are using](//thinklab.com/discussion/tissue-node/41) [Uberon](https://uberon.github.io/) [@10.1186/gb-2012-13-1-r5] terms to identify anatomical structures and [Cell Ontology](https://github.com/obophenotype/cell-ontology) (CL) [@10.1186/gb-2005-6-2-r21] terms to identify cell types. Thus, we need to map GTEx sites to their corresponding ontology terms.\r\n\r\nFrom the sample attribute documentation (`GTEx_Data_V4_Annotations_SampleAttributesDS.txt`), we [identified](https://github.com/dhimmel/gtex/blob/8acb90fea2613f8b27814401e361bb6ae4b29078/gtex.ipynb) 54 sites using the `SMTSD` attribute. I have mapped about half of the sites to Uberon. The remainder would benefit from a skilled anatomist or GTEx consortium member.\r\n\r\n**Bounty:** Add or correct [our mappings using this spreadsheet](https://docs.google.com/spreadsheets/d/1aXm_RvD4aywXRpQdxVxjBxwPAR_YBBq9f3xkHQaLZXo/edit?usp=sharing) and put your Thinklab username. Then leave a comment in this discussion, and we will rate its value $$\\geq $4 \\times n$$, where *n* is the number of mappings provided.\r\n\r\nSome additional sample site information is available in Table S1 (p. 58) of the [supplement](//www.sciencemag.org/content/suppl/2015/05/06/348.6235.660.DC1/Mele.SM.pdf).",
      "comment_id": 275,
      "profile_id": 17,
      "published": "2015-06-17T21:22:53.938694Z",
      "thread_id": 82,
      "url": "/discussion/processing-gtex-for-tissue-specific-gene-expression/82#2"
    },
    {
      "body_html": "<p>So you probably don't want structures that are <em>uniquely</em> human or that evolved after the human-chimp common ancestor - there are probably only a handful of these, e.g. certain minor glands and brain regions.</p>\r\n\r\n<p>You probably want structures that are typically present in humans but not necessarily absent from other species. There are two ways to go about answering this, based on your tolerance for accidentally including a non-human structure vs accidentally excluding a human structure.</p>\r\n\r\n<ol><li>List structures that exclude those that are known not to be found in human</li><li>List structures for which there is evidence that the structure is found in humans.</li></ol>\r\n\r\n<p>Currently we are well geared up for answering (1), but you have to tolerate the occasional inclusion of some obscure brain region that was only actually observed in macaques or mice. We call these 'taxon modules'. We are not well geared up for (2) but this could be prioritized. Using cross-references to DHBA, EHDAA2, FMA, HBA, and HsapDv is a good start but you may still miss some things.</p>\r\n\r\n<p>Either way, you need to do something more specific than just look up the direct properties of the class. You need inference over both the anatomical graph, and the taxonomy graph. For (1) you need to make use of negative evidence, which intuitively 'reverses the flow' of inference. So if a larval stage is never found in amniotes, then any structure that necessarily exists at the larval stage is never found in any descendant of amniotes.</p>\r\n\r\n<p>You'd be better using an owl reasoner or some existing tooling for this.</p>\r\n\r\n<p>Some background on the taxon axioms:<br><a href=\"https://github.com/obophenotype/uberon/wiki/Taxon-constraints\">https://github.com/obophenotype/uberon/wiki/Taxon-constraints</a></p>\r\n\r\n<p>Hmm the taxon subsets files could do with better documentation:</p>\r\n\r\n<p><a href=\"http://uberon.github.io/downloads.html#subsets\">http://uberon.github.io/downloads.html#subsets</a></p>\r\n\r\n<p>(these follow (1) above) </p>\r\n\r\n<p>We should really make a ready-made human subset here. It would probably be more popular than the Aves one.</p>\r\n\r\n<p>These are built using <a href=\"https://github.com/owlcollab/owltools\">owltools</a></p>\r\n\r\n<p></p><pre><code class=\"no-highlight hljs\">owltools --use-catalog ext.owl--reasoner elk --make-species-subset -t NCBITaxon:9606 --remove-dangling --assert-inferred-subclass-axioms --useIsInferred --remove-dangling --set-ontology-id $(OBO)/uberon/subsets/human.owl -o human.owl</code></pre>",
      "body_md": "So you probably don't want structures that are *uniquely* human or that evolved after the human-chimp common ancestor - there are probably only a handful of these, e.g. certain minor glands and brain regions.\r\n\r\nYou probably want structures that are typically present in humans but not necessarily absent from other species. There are two ways to go about answering this, based on your tolerance for accidentally including a non-human structure vs accidentally excluding a human structure.\r\n\r\n 1. List structures that exclude those that are known not to be found in human\r\n 2. List structures for which there is evidence that the structure is found in humans.\r\n\r\nCurrently we are well geared up for answering (1), but you have to tolerate the occasional inclusion of some obscure brain region that was only actually observed in macaques or mice. We call these 'taxon modules'. We are not well geared up for (2) but this could be prioritized. Using cross-references to DHBA, EHDAA2, FMA, HBA, and HsapDv is a good start but you may still miss some things.\r\n\r\nEither way, you need to do something more specific than just look up the direct properties of the class. You need inference over both the anatomical graph, and the taxonomy graph. For (1) you need to make use of negative evidence, which intuitively 'reverses the flow' of inference. So if a larval stage is never found in amniotes, then any structure that necessarily exists at the larval stage is never found in any descendant of amniotes.\r\n\r\nYou'd be better using an owl reasoner or some existing tooling for this.\r\n\r\n\r\n\r\nSome background on the taxon axioms:\r\nhttps://github.com/obophenotype/uberon/wiki/Taxon-constraints\r\n\r\nHmm the taxon subsets files could do with better documentation:\r\n\r\nhttp://uberon.github.io/downloads.html#subsets\r\n\r\n(these follow (1) above) \r\n\r\nWe should really make a ready-made human subset here. It would probably be more popular than the Aves one.\r\n\r\nThese are built using [owltools](https://github.com/owlcollab/owltools)\r\n\r\n```\r\nowltools --use-catalog ext.owl--reasoner elk --make-species-subset -t NCBITaxon:9606 --remove-dangling --assert-inferred-subclass-axioms --useIsInferred --remove-dangling --set-ontology-id $(OBO)/uberon/subsets/human.owl -o human.owl\r\n```\r\n",
      "comment_id": 276,
      "profile_id": 109,
      "published": "2015-06-17T23:55:39.120211Z",
      "thread_id": 41,
      "url": "/discussion/tissue-node/41#11"
    },
    {
      "body_html": "<p><em>R is a data scientist's dream but a programmer's nightmare.</em></p>\r\n\r\n<p>Here I'll describe the R programming principles and practices that <a href=\"/u/leobrueggeman\" class=\"username\">@leobrueggeman</a> and I will try to adhere to for this project. We are big believers in the <a href=\"https://barryrowlingson.github.io/hadleyverse\">Hadleyverse</a> — a philosophy of R programming, data analysis, and visualization — spearheaded by <a href=\"http://had.co.nz/\">Hadley Wickham</a>. I'll describe the basics as well as our modifications below.</p>\r\n\r\n<h1>Style</h1>\r\n\r\n<p>We follow the <a href=\"http://adv-r.had.co.nz/Style.html\">Hadley style guide</a>, which builds off the older <a href=\"https://google-styleguide.googlecode.com/svn/trunk/Rguide.xml\">Google style guide</a>. When calling functions from a package (any non-base function), use double colons to clarify function provenance (i.e. <code>dplyr::filter()</code> rather than just <code>filter()</code>).</p>\r\n\r\n<h1>Data format</h1>\r\n\r\n<p>The preferred storage format for tabular data is tab-separated with the <code>.tsv</code> function. Column names should always be included. For compression, use gzip with a <code>.gz</code> extension.</p>\r\n\r\n<p>Tabular data in R should be in data frames. Avoid relying on row names by making a dedicated column for the attribute. <code>options(stringsAsFactors = FALSE)</code> is imperative but may not need to be explicitly called if reading data with <a href=\"https://github.com/hadley/readr\"><code>readr</code></a> and manipulating data with <a href=\"http://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html\"><code>dplyr</code></a> and <a href=\"https://github.com/hadley/tidyr\"><code>tidyr</code></a>. Create data frames using <code>dplyr::data_frame()</code>.</p>\r\n\r\n<p>Tables should be tidy <span class=\"citation\">[<a href=\"https://doi.org/10.18637/jss.v059.i10\" class=\"citation\" data-key=\"10.18637/jss.v059.i10\">1</a>]</span>:</p>\r\n\r\n<ol><li>Each variable forms a column.</li><li>Each observation forms a row.</li><li>Each type of observational unit forms a table.</li></ol>\r\n\r\n<h1>Piping</h1>\r\n\r\n<p>Consecutive commands should be chained together using the <a href=\"https://github.com/smbache/magrittr\"><code>magrittr</code></a> pipe (<code>%&gt;%</code>) when possible. Piping improves readability and avoids unnecessary variables cluttering the workspace.</p>\r\n\r\n<h1>Visualization</h1>\r\n\r\n<p><a href=\"http://docs.ggplot2.org/current/\"><code>ggplot2</code></a> is the preferred plotting package <span class=\"citation\">[<a href=\"https://doi.org/10.1002/wics.147\" class=\"citation\" data-key=\"10.1002/wics.147\">2</a>, <a href=\"https://doi.org/10.1198/jcgs.2009.07098\" class=\"citation\" data-key=\"10.1198/jcgs.2009.07098\">3</a>]</span>. Avoid the shortcut function <code>ggplot2::qplot()</code>. Consider <a href=\"http://cran.r-project.org/web/packages/cowplot/vignettes/introduction.html\"><code>cowplot</code></a> or <code>ggplot2::theme_bw()</code> to avoid the ugly default theme. Make sure all text is readable. If text is too small to read, remove it. Exporting to vector images (pdfs and svgs) is preferred unless intensive rendering requires png.</p>\r\n\r\n<h1>Development environment</h1>\r\n\r\n<p><a href=\"http://www.rstudio.com/products/RStudio/\">RStudio</a> is a mediocre mature development environment. For most prototyping work, notebooks are more powerful and straightforward. Consider using <a href=\"https://jupyter.org/\">Jupyter (IPython) notebooks</a> with <a href=\"https://irkernel.github.io/\">IRKernel</a>.</p>\r\n\r\n<h1>Version control</h1>\r\n\r\n<p>All code should be version controlled. We use <a href=\"https://git-scm.com/\">git</a> hosted on <a href=\"https://github.com/\">GitHub</a>. <a href=\"https://git-scm.com/videos\">These short videos</a> are recommended for inexperienced git users.</p>\r\n\r\n<p>Link to specific files on GitHub with the commit hash for immutability and durability.</p>\r\n\r\n<h1>Additional materials</h1>\r\n\r\n<p>Check out the rstudio <a href=\"https://github.com/rstudio/webinars\">webinars</a> as well as <a href=\"http://www.rstudio.com/resources/cheatsheets/\">cheatsheets</a>.</p>",
      "body_md": "*R is a data scientist's dream but a programmer's nightmare.*\r\n\r\nHere I'll describe the R programming principles and practices that @leobrueggeman and I will try to adhere to for this project. We are big believers in the [Hadleyverse](https://barryrowlingson.github.io/hadleyverse) -- a philosophy of R programming, data analysis, and visualization -- spearheaded by [Hadley Wickham](http://had.co.nz/). I'll describe the basics as well as our modifications below.\r\n\r\n# Style\r\n\r\nWe follow the [Hadley style guide](http://adv-r.had.co.nz/Style.html), which builds off the older [Google style guide](https://google-styleguide.googlecode.com/svn/trunk/Rguide.xml). When calling functions from a package (any non-base function), use double colons to clarify function provenance (i.e. `dplyr::filter()` rather than just `filter()`).\r\n\r\n# Data format\r\n\r\nThe preferred storage format for tabular data is tab-separated with the `.tsv` function. Column names should always be included. For compression, use gzip with a `.gz` extension.\r\n\r\nTabular data in R should be in data frames. Avoid relying on row names by making a dedicated column for the attribute. `options(stringsAsFactors = FALSE)` is imperative but may not need to be explicitly called if reading data with [`readr`](https://github.com/hadley/readr) and manipulating data with [`dplyr`](http://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html) and [`tidyr`](https://github.com/hadley/tidyr). Create data frames using `dplyr::data_frame()`.\r\n\r\nTables should be tidy [@10.18637/jss.v059.i10]:\r\n\r\n1. Each variable forms a column.\r\n2. Each observation forms a row.\r\n3. Each type of observational unit forms a table.\r\n\r\n# Piping\r\n\r\nConsecutive commands should be chained together using the [`magrittr`](https://github.com/smbache/magrittr) pipe (`%>%`) when possible. Piping improves readability and avoids unnecessary variables cluttering the workspace.\r\n\r\n# Visualization\r\n\r\n[`ggplot2`](http://docs.ggplot2.org/current/) is the preferred plotting package [@10.1002/wics.147 @10.1198/jcgs.2009.07098]. Avoid the shortcut function `ggplot2::qplot()`. Consider [`cowplot`](http://cran.r-project.org/web/packages/cowplot/vignettes/introduction.html) or `ggplot2::theme_bw()` to avoid the ugly default theme. Make sure all text is readable. If text is too small to read, remove it. Exporting to vector images (pdfs and svgs) is preferred unless intensive rendering requires png.\r\n\r\n# Development environment\r\n\r\n[RStudio](http://www.rstudio.com/products/RStudio/) is a mediocre mature development environment. For most prototyping work, notebooks are more powerful and straightforward. Consider using [Jupyter (IPython) notebooks](https://jupyter.org/) with [IRKernel](https://irkernel.github.io/).\r\n\r\n# Version control\r\n\r\nAll code should be version controlled. We use [git](https://git-scm.com/) hosted on [GitHub](https://github.com/). [These short videos](https://git-scm.com/videos) are recommended for inexperienced git users.\r\n\r\nLink to specific files on GitHub with the commit hash for immutability and durability.\r\n\r\n# Additional materials\r\n\r\nCheck out the rstudio [webinars](https://github.com/rstudio/webinars) as well as [cheatsheets](http://www.rstudio.com/resources/cheatsheets/).",
      "comment_id": 277,
      "profile_id": 17,
      "published": "2015-06-18T04:18:56.860002Z",
      "thread_id": 83,
      "url": "/discussion/r-best-practices/83"
    },
    {
      "body_html": "<h1>Bgee</h1>\r\n\r\n<p>On a GitHub issues discussion on mapping GTEx data to Uberon, <a href=\"https://github.com/obophenotype/uberon/issues/704#issuecomment-113134400\">Frederic Bastian suggested Bgee</a> as a database for human tissue-specific expression measurements under normal conditions — exactly what we're looking for.</p>\r\n\r\n<p><a href=\"http://bgee.unil.ch/\">Bgee</a> was designed for comparative genomics <span class=\"citation\">[<a href=\"https://doi.org/10.1007/978-3-540-69828-9_12\" class=\"citation\" data-key=\"10.1007/978-3-540-69828-9_12\">1</a>]</span> and therefore maps sample sites to standard vocabularies (like Uberon) and contains data for many species (not needed now but may be in the future).</p>\r\n\r\n<p>Genes are in Ensembl identifiers which we can easily convert to Entrez GeneIDs. Highly processed and relevant datasets <a href=\"http://bgee.unil.ch/?page=doc&amp;action=call_files#single_expr\">appear to be available</a>:</p>\r\n\r\n<ul><li>Presence/absence of expression</li><li>Over-/under-expression across anatomy or life stages</li></ul>\r\n\r\n<p>Specifically, we want to create three matrices with Entrez GeneID columns and Uberon/CL rows. We are interested in the adult development stage. The values should binary or continuous allowing us to pick an inclusion threshold later. The three desired matrices of tissue-specific expression are:</p>\r\n\r\n<ol><li>Transcript presence in adult </li><li>Transcript over-expression compared to other adult human sites</li><li>Transcript under-expression compared to other adult human sites</li></ol>\r\n\r\n<p>Bgee does not yet include GTEx RNA-Seq data but will integrate this data in the coming months. <strong>Question for Bgee team:</strong> do you compute transcript abundance from raw data? I am not stoked about the Flux Capacitor software used by GTEx for <a href=\"https://liorpachter.wordpress.com/2013/10/21/gtex/\">reasons pointed out by others</a>.</p>",
      "body_md": "# Bgee\r\n\r\nOn a GitHub issues discussion on mapping GTEx data to Uberon, [Frederic Bastian suggested Bgee](https://github.com/obophenotype/uberon/issues/704#issuecomment-113134400) as a database for human tissue-specific expression measurements under normal conditions -- exactly what we're looking for.\r\n\r\n[Bgee](http://bgee.unil.ch/) was designed for comparative genomics [@10.1007/978-3-540-69828-9_12] and therefore maps sample sites to standard vocabularies (like Uberon) and contains data for many species (not needed now but may be in the future).\r\n\r\nGenes are in Ensembl identifiers which we can easily convert to Entrez GeneIDs. Highly processed and relevant datasets [appear to be available](http://bgee.unil.ch/?page=doc&action=call_files#single_expr):\r\n\r\n+ Presence/absence of expression\r\n+ Over-/under-expression across anatomy or life stages\r\n\r\nSpecifically, we want to create three matrices with Entrez GeneID columns and Uberon/CL rows. We are interested in the adult development stage. The values should binary or continuous allowing us to pick an inclusion threshold later. The three desired matrices of tissue-specific expression are:\r\n\r\n1. Transcript presence in adult \r\n2. Transcript over-expression compared to other adult human sites\r\n3. Transcript under-expression compared to other adult human sites\r\n\r\nBgee does not yet include GTEx RNA-Seq data but will integrate this data in the coming months. **Question for Bgee team:** do you compute transcript abundance from raw data? I am not stoked about the Flux Capacitor software used by GTEx for [reasons pointed out by others](https://liorpachter.wordpress.com/2013/10/21/gtex/).",
      "comment_id": 278,
      "profile_id": 17,
      "published": "2015-06-18T16:33:27.976269Z",
      "thread_id": 81,
      "url": "/discussion/tissue-specific-gene-expression-resources/81#3"
    },
    {
      "body_html": "<h1>Human constraint: <em>positive</em> versus <em>no negative</em> evidence</h1>\r\n\r\n<p><a href=\"/u/chrismungall\" class=\"username\">@chrismungall</a>, could not have hoped for a more informative response!</p>\r\n\r\n<p>I am going to refer to your two methods as:</p>\r\n\r\n<ol><li>no negative evidence, which should include all human structures and some non-human structures</li><li>positive evidence, which should include some human structures and exclude all non-human structures</li></ol>\r\n\r\n<p>I created a comparison of the two methods for Uberon terms, using <a href=\"/u/fbastian\" class=\"username\">@fbastian</a>'s <a href=\"https://github.com/obophenotype/uberon/issues/703#issuecomment-113131156\">implementation</a> of <a href=\"/u/chrismungall\" class=\"username\">@chrismungall</a>'s owltools command <a href=\"#276\">above</a> for (1) and my <a href=\"https://github.com/dhimmel/uberon/blob/08cbf5beef80a68cf880a459a49097e39afade08/human-constraint.ipynb\">implementation</a> of <em>positive evidence</em> for (2). My implementation has not been vetted, and if there is an owltools command for this functionality, we should switch. </p>\r\n\r\n<p>I created two tsv files: one with <a href=\"https://github.com/dhimmel/uberon/blob/08cbf5beef80a68cf880a459a49097e39afade08/data/human-constraint.tsv\">all uberon terms</a> and another with only <a href=\"https://github.com/dhimmel/uberon/blob/08cbf5beef80a68cf880a459a49097e39afade08/data/mesh-map.tsv\">MeSH-mapping uberon terms</a>.</p>\r\n\r\n<p>Since I'm primarily concerned with terms in MeSH, I looked through MeSH-mapping uberon terms with no positive evidence (<code>positive_evidence == 0</code>) and also no negative evidence (<code>no_negative_evidence == 1</code>). Looking through this subset, there were a few notable terms where we would like negative evidence to exist:</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>uberon_id</th><th>uberon_name</th></tr></thead><tbody><tr><td>UBERON:0013196</td><td>strand of wool</td></tr><tr><td>UBERON:0002415</td><td>tail</td></tr><tr><td>UBERON:0007113</td><td>venom</td></tr><tr><td>UBERON:0005079</td><td>eggshell</td></tr><tr><td>UBERON:0001011</td><td>hemolymph</td></tr><tr><td>UBERON:0006378</td><td>strand of vibrissa hair</td></tr><tr><td>UBERON:0004758</td><td>salt gland</td></tr><tr><td>UBERON:0011123</td><td>stifle joint</td></tr></tbody></table>\r\n\r\n<p>However, overall the <em>no negative evidence</em> method appeared to have higher accuracy than the <em>positive evidence</em> method. Therefore, we will proceed using <em>no negative evidence</em>, which should improve over time as Uberon matures.</p>",
      "body_md": "# Human constraint: *positive* versus *no negative* evidence\r\n\r\n@chrismungall, could not have hoped for a more informative response!\r\n\r\nI am going to refer to your two methods as:\r\n\r\n1. no negative evidence, which should include all human structures and some non-human structures\r\n2. positive evidence, which should include some human structures and exclude all non-human structures\r\n\r\nI created a comparison of the two methods for Uberon terms, using @fbastian's [implementation](https://github.com/obophenotype/uberon/issues/703#issuecomment-113131156) of @chrismungall's owltools command [above](#276) for (1) and my [implementation](https://github.com/dhimmel/uberon/blob/08cbf5beef80a68cf880a459a49097e39afade08/human-constraint.ipynb) of *positive evidence* for (2). My implementation has not been vetted, and if there is an owltools command for this functionality, we should switch. \r\n\r\nI created two tsv files: one with [all uberon terms](https://github.com/dhimmel/uberon/blob/08cbf5beef80a68cf880a459a49097e39afade08/data/human-constraint.tsv) and another with only [MeSH-mapping uberon terms](https://github.com/dhimmel/uberon/blob/08cbf5beef80a68cf880a459a49097e39afade08/data/mesh-map.tsv).\r\n\r\nSince I'm primarily concerned with terms in MeSH, I looked through MeSH-mapping uberon terms with no positive evidence (`positive_evidence == 0`) and also no negative evidence (`no_negative_evidence == 1`). Looking through this subset, there were a few notable terms where we would like negative evidence to exist:\r\n\r\n| uberon_id | uberon_name |\r\n|----------------|-------------------------|\r\n| UBERON:0013196 | strand of wool |\r\n| UBERON:0002415 | tail |\r\n| UBERON:0007113 | venom |\r\n| UBERON:0005079 | eggshell |\r\n| UBERON:0001011 | hemolymph |\r\n| UBERON:0006378 | strand of vibrissa hair |\r\n| UBERON:0004758 | salt gland |\r\n| UBERON:0011123 | stifle joint |\r\n\r\nHowever, overall the *no negative evidence* method appeared to have higher accuracy than the *positive evidence* method. Therefore, we will proceed using *no negative evidence*, which should improve over time as Uberon matures.",
      "comment_id": 279,
      "profile_id": 17,
      "published": "2015-06-18T21:09:23.190526Z",
      "thread_id": 41,
      "url": "/discussion/tissue-node/41#12"
    },
    {
      "body_html": "<h1>Bgee parameters</h1>\r\n\r\n<p>The <a href=\"http://bgee.unil.ch/?page=download&amp;action=expr_calls#id9606\">Bgee human downloads</a> are user-friendly and should be easy to process. We just have a few questions:</p>\r\n\r\n<h2>Transcript presence</h2>\r\n\r\n<p>For determining expression presence, we want to pick a single and broad <strong>developmental stage</strong>, such as adult. The <a href=\"http://bgee.unil.ch/?page=doc&amp;action=call_files#single_expr\">propagation</a> up the developmental ontology means we don't need to pick a stage that has been directly assayed by many studies. Post-juvenile adult stage (<code>UBERON:0000113</code>) is used for the differential expression analysis. Which stage should we choose?</p>\r\n\r\n<p>Next, what <strong>evidence threshold</strong> should we require to consider a gene expressed I was thinking requiring <code>call_quality == 'high quality'</code> and <code>expression in {'present', 'low ambiguity'}</code>. We could also use a more complex metric on the <a href=\"http://bgee.unil.ch/?page=doc&amp;action=call_files#single_expr\">complete file</a>. </p>\r\n\r\n<h2>Differential expression</h2>\r\n\r\n<p>We would like to include two differential expression edges in our network: one for under-expression and one for over-expression. For the over-expression dataset, is <code>call_quality == 'high quality'</code> and <code>differential_expression  == 'over-expression'</code> the right filter?</p>",
      "body_md": "# Bgee parameters\r\n\r\nThe [Bgee human downloads](http://bgee.unil.ch/?page=download&action=expr_calls#id9606) are user-friendly and should be easy to process. We just have a few questions:\r\n\r\n## Transcript presence\r\n\r\nFor determining expression presence, we want to pick a single and broad **developmental stage**, such as adult. The [propagation](http://bgee.unil.ch/?page=doc&action=call_files#single_expr) up the developmental ontology means we don't need to pick a stage that has been directly assayed by many studies. Post-juvenile adult stage (`UBERON:0000113`) is used for the differential expression analysis. Which stage should we choose?\r\n\r\nNext, what **evidence threshold** should we require to consider a gene expressed I was thinking requiring `call_quality == 'high quality'` and `expression in {'present', 'low ambiguity'}`. We could also use a more complex metric on the [complete file](http://bgee.unil.ch/?page=doc&action=call_files#single_expr). \r\n\r\n## Differential expression\r\n\r\nWe would like to include two differential expression edges in our network: one for under-expression and one for over-expression. For the over-expression dataset, is `call_quality == 'high quality'` and `differential_expression  == 'over-expression'` the right filter?",
      "comment_id": 280,
      "profile_id": 17,
      "published": "2015-06-18T23:49:43.252238Z",
      "thread_id": 81,
      "url": "/discussion/tissue-specific-gene-expression-resources/81#4"
    },
    {
      "body_html": "<h1>Handing over GTEx processing responsibility to Bgee</h1>\r\n\r\n<p>We have <a href=\"http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#278\">decided to use Bgee</a> for tissue-specific transcript presence, over-, and under-expression. Bgee doesn't currently include GTEx data but <a href=\"https://github.com/obophenotype/uberon/issues/704#issuecomment-113134400\">will soon</a>.</p>\r\n\r\n<p>Therefore, we are not going to proceed with GTEx data directly for this project. However, we did already process the data into a usable gene × site format (<a href=\"https://github.com/dhimmel/gtex/blob/93c3800cef1ced48b100d57b8d6efab831f8533b/gtex.ipynb\">notebook</a>, <a href=\"https://github.com/dhimmel/gtex/blob/93c3800cef1ced48b100d57b8d6efab831f8533b/data/expression-SMTSD.tsv.gz\">download</a>). We converted genes to Entrez GeneIDs. The sites are still in GTEx strings rather than Uberon terms. Expression values are log-transformed. Check out the notebook for a visualization of tissue-specific transcript abundance distributions.</p>\r\n\r\n<p><strong>Bounty:</strong> we will keep the GTEx–Uberon mapping bounty going until June 25, 2015 because these mappings will help the Bgee team and eventually us. <a href=\"/u/chrismungall\" class=\"username\">@chrismungall</a>, do you want to add a comment here, so you can get rewarded for your 3 mappings?</p>",
      "body_md": "# Handing over GTEx processing responsibility to Bgee\r\n\r\nWe have [decided to use Bgee](http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#278) for tissue-specific transcript presence, over-, and under-expression. Bgee doesn't currently include GTEx data but [will soon](https://github.com/obophenotype/uberon/issues/704#issuecomment-113134400).\r\n\r\nTherefore, we are not going to proceed with GTEx data directly for this project. However, we did already process the data into a usable gene × site format ([notebook](https://github.com/dhimmel/gtex/blob/93c3800cef1ced48b100d57b8d6efab831f8533b/gtex.ipynb), [download](https://github.com/dhimmel/gtex/blob/93c3800cef1ced48b100d57b8d6efab831f8533b/data/expression-SMTSD.tsv.gz)). We converted genes to Entrez GeneIDs. The sites are still in GTEx strings rather than Uberon terms. Expression values are log-transformed. Check out the notebook for a visualization of tissue-specific transcript abundance distributions.\r\n\r\n**Bounty:** we will keep the GTEx--Uberon mapping bounty going until June 25, 2015 because these mappings will help the Bgee team and eventually us. @chrismungall, do you want to add a comment here, so you can get rewarded for your 3 mappings?",
      "comment_id": 281,
      "profile_id": 17,
      "published": "2015-06-19T00:00:40.757557Z",
      "thread_id": 82,
      "url": "/discussion/processing-gtex-for-tissue-specific-gene-expression/82#3"
    },
    {
      "body_html": "<p>I think the Bgee team will do a great job. Just a few general comments:</p>\r\n\r\n<p>most of the GTEx terms correspond to 'wild-type' structures as can be found in uberon/cl. There are however, two subclasses of skin: exposed and unexposed. We <em>could</em> add these as subclasses in uberon, but this would be unusual. It would be better to either post-compose these, or to have some kind of ancillary 'sample' ontology where this is composed.</p>\r\n\r\n<p>For 'hippocampus', the safest option is to map to the broadest term, 'hippocampal formation', but if it can be shown than the GTEx sample excludes bits of the dentate gyrus then the more specific 'ammons horn' can be used.</p>\r\n\r\n<p>Finally, it's always best when ontologies are used prospectively rather than retrospectively, maybe future rounds of GTEx will follow the lead of FANTOM5 and ENCODE in doing this.</p>",
      "body_md": "I think the Bgee team will do a great job. Just a few general comments:\r\n\r\nmost of the GTEx terms correspond to 'wild-type' structures as can be found in uberon/cl. There are however, two subclasses of skin: exposed and unexposed. We *could* add these as subclasses in uberon, but this would be unusual. It would be better to either post-compose these, or to have some kind of ancillary 'sample' ontology where this is composed.\r\n\r\nFor 'hippocampus', the safest option is to map to the broadest term, 'hippocampal formation', but if it can be shown than the GTEx sample excludes bits of the dentate gyrus then the more specific 'ammons horn' can be used.\r\n\r\nFinally, it's always best when ontologies are used prospectively rather than retrospectively, maybe future rounds of GTEx will follow the lead of FANTOM5 and ENCODE in doing this.",
      "comment_id": 282,
      "profile_id": 109,
      "published": "2015-06-19T00:12:47.995112Z",
      "thread_id": 82,
      "url": "/discussion/processing-gtex-for-tissue-specific-gene-expression/82#4"
    },
    {
      "body_html": "<p>IMO, the \"exposed/unexposed\" state is an experimental factor, and should not be annotated using a new anatomical term, it should be an additional \"column\" in an annotation (using, e.g., EFO).</p>\r\n\r\n<p>Daniel, we will discuss next week during our lab meeting the timescale to annotate GTEx data, but as you said, it should be fast. Our problem is that we requested access to the data, and are waiting for an answer. </p>\r\n\r\n<p>We could start working on the mapping you have, but we'd rather go through the information for each sample, to check for normality, etc. This is how we usually do. <br>(do they provide GEO or SRA identifiers for the samples BTW?)</p>",
      "body_md": "IMO, the \"exposed/unexposed\" state is an experimental factor, and should not be annotated using a new anatomical term, it should be an additional \"column\" in an annotation (using, e.g., EFO).\r\n\r\nDaniel, we will discuss next week during our lab meeting the timescale to annotate GTEx data, but as you said, it should be fast. Our problem is that we requested access to the data, and are waiting for an answer. \r\n\r\nWe could start working on the mapping you have, but we'd rather go through the information for each sample, to check for normality, etc. This is how we usually do. \r\n(do they provide GEO or SRA identifiers for the samples BTW?)",
      "comment_id": 283,
      "profile_id": 111,
      "published": "2015-06-19T12:48:14.856994Z",
      "thread_id": 82,
      "url": "/discussion/processing-gtex-for-tissue-specific-gene-expression/82#5"
    },
    {
      "body_html": "<blockquote><p>do you compute transcript abundance from raw data? I am not stoked about the Flux Capacitor software used by GTEx for reasons pointed out by others.</p></blockquote>\r\n\r\n<p>Yes, we do. We map reads to transcriptome using TopHat2; read counts extracted using HTseq; length of longest annotated transcript used.<br>(edit: woops, you said transcript abundance. We only provide expression data \"per gene\")</p>\r\n\r\n<p>Currently, we do not use TMM normalization between samples for the RPKM values we provide, but we will in the next release. We also want to get away from RPKM values, and provide TPM values (for motivation, see <span class=\"citation\">[<a href=\"https://doi.org/10.1007/s12064-012-0162-3\" class=\"citation\" data-key=\"10.1007/s12064-012-0162-3\">1</a>]</span>).</p>\r\n\r\n<p>To generate differential expression calls, we use TMM normalization, then voom + limma. This has been shown to perform well (see <span class=\"citation\">[<a href=\"https://doi.org/10.1093/bib/bbt086\" class=\"citation\" data-key=\"10.1093/bib/bbt086\">2</a>]</span>). </p>\r\n\r\n<p>We will provide complete documentation by July. </p>\r\n\r\n<blockquote><p>The values should binary or continuous allowing us to pick an inclusion threshold later.</p></blockquote>\r\n\r\n<p>So have you noticed that we also provide RPKM values, not only the qualitative \"calls\"?</p>\r\n\r\n<blockquote><p>Post-juvenile adult stage (UBERON:0000113) is used for the differential expression analysis. Which stage should we choose?</p></blockquote>\r\n\r\n<p>Post-juvenile in human also includes 13-18 yo, so I don't know if you want to include those. HsapDv:0000087 \"human adult stage\" would be a \"true\" adult stage. But I think we don't use it for \"differential expression across anatomy\", we could correct that if you need it. It should be correctly used for \"differential expression across development\", if we have the data. And of course it is correctly used for the \"presence/absence\" calls.</p>\r\n\r\n<p>Note that \"differential expression\" calls are not propagated, so you might still need to examine all stages for \"differential expression across development\". But for \"presence/absence\", you can safely rely on the propagation, and only retrieve results for your stage of interest. </p>\r\n\r\n<p>You might want to use the \"complete\" file, you will have more data propagated. Also, if you use the \"complete\" file, you might decide to rely only on RNA-Seq data, and avoid the \"ambiguity\" states.</p>\r\n\r\n<blockquote><p>what evidence threshold should we require to consider a gene expressed I was thinking requiring call_quality == 'high quality' and expression in {'present', 'low ambiguity'}. We could also use a more complex metric on the complete file. </p></blockquote>\r\n\r\n<p>Presence low quality seems also to give good results, but here it is up to you to decide whether you want to be more on the false negative side, or more on the false positive side.</p>\r\n\r\n<blockquote><p>For the over-expression dataset, is call_quality == 'high quality' and differential_expression == 'over-expression' the right filter?</p></blockquote>\r\n\r\n<p>I would definitely use the \"low quality\" as well here. Because the overall call generated is based on a voting system weighted by p-values, so even if it is \"low quality\" because of conflicting analyses, the best p-value has won anyway. <br>Again, if you use the \"complete\" file, you might decide to rely only on RNA-Seq data, and avoid the \"ambiguity\" states.</p>\r\n\r\n<p>Edit: oh, I didn't notice you where mentioning \"transcript abundance\". We only provide expression data \"per gene\", not \"per transcript\".</p>",
      "body_md": "> do you compute transcript abundance from raw data? I am not stoked about the Flux Capacitor software used by GTEx for reasons pointed out by others.\r\n\r\nYes, we do. We map reads to transcriptome using TopHat2; read counts extracted using HTseq; length of longest annotated transcript used.\r\n(edit: woops, you said transcript abundance. We only provide expression data \"per gene\")\r\n\r\nCurrently, we do not use TMM normalization between samples for the RPKM values we provide, but we will in the next release. We also want to get away from RPKM values, and provide TPM values (for motivation, see [@10.1007/s12064-012-0162-3]).\r\n\r\nTo generate differential expression calls, we use TMM normalization, then voom + limma. This has been shown to perform well (see [@10.1093/bib/bbt086]). \r\n\r\nWe will provide complete documentation by July. \r\n\r\n> The values should binary or continuous allowing us to pick an inclusion threshold later.\r\n\r\nSo have you noticed that we also provide RPKM values, not only the qualitative \"calls\"?\r\n\r\n> Post-juvenile adult stage (UBERON:0000113) is used for the differential expression analysis. Which stage should we choose?\r\n\r\nPost-juvenile in human also includes 13-18 yo, so I don't know if you want to include those. HsapDv:0000087 \"human adult stage\" would be a \"true\" adult stage. But I think we don't use it for \"differential expression across anatomy\", we could correct that if you need it. It should be correctly used for \"differential expression across development\", if we have the data. And of course it is correctly used for the \"presence/absence\" calls.\r\n\r\nNote that \"differential expression\" calls are not propagated, so you might still need to examine all stages for \"differential expression across development\". But for \"presence/absence\", you can safely rely on the propagation, and only retrieve results for your stage of interest. \r\n\r\nYou might want to use the \"complete\" file, you will have more data propagated. Also, if you use the \"complete\" file, you might decide to rely only on RNA-Seq data, and avoid the \"ambiguity\" states.\r\n\r\n> what evidence threshold should we require to consider a gene expressed I was thinking requiring call_quality == 'high quality' and expression in {'present', 'low ambiguity'}. We could also use a more complex metric on the complete file. \r\n\r\nPresence low quality seems also to give good results, but here it is up to you to decide whether you want to be more on the false negative side, or more on the false positive side.\r\n\r\n> For the over-expression dataset, is call_quality == 'high quality' and differential_expression == 'over-expression' the right filter?\r\n\r\nI would definitely use the \"low quality\" as well here. Because the overall call generated is based on a voting system weighted by p-values, so even if it is \"low quality\" because of conflicting analyses, the best p-value has won anyway. \r\nAgain, if you use the \"complete\" file, you might decide to rely only on RNA-Seq data, and avoid the \"ambiguity\" states.\r\n\r\nEdit: oh, I didn't notice you where mentioning \"transcript abundance\". We only provide expression data \"per gene\", not \"per transcript\".",
      "comment_id": 284,
      "profile_id": 111,
      "published": "2015-06-19T12:52:20.262962Z",
      "thread_id": 81,
      "url": "/discussion/tissue-specific-gene-expression-resources/81#5"
    },
    {
      "body_html": "<blockquote><p>do they provide GEO or SRA identifiers for the samples BTW?</p></blockquote>\r\n\r\n<p><a href=\"/u/fbastian\" class=\"username\">@fbastian</a>, I do not see any other sample identifiers than <code>SAMPID</code> (GTEx Public Sample ID) in the <a href=\"http://www.gtexportal.org/static/datasets/gtex_analysis_v4/annotations/GTEx_Data_V4_Annotations_SampleAttributesDD.xlsx\">sample attributes documentation spreadsheet</a>. The IDs are formatted like <code>GTEX-N7MS-0007-SM-2D7W1</code> — not sure whether that corresponds with other databases.</p>\r\n\r\n<blockquote><p>We could start working on the mapping you have, but we'd rather go through the information for each sample, to check for normality, etc.</p></blockquote>\r\n\r\n<p><a href=\"/u/fbastian\" class=\"username\">@fbastian</a>, do whatever is best for you! And let it be known that your painstaking and thorough integration efforts are appreciated.</p>\r\n\r\n<blockquote><p>There are however, two subclasses of skin: exposed and unexposed.</p></blockquote>\r\n\r\n<p><a href=\"/u/chrismungall\" class=\"username\">@chrismungall</a>, by post-compose do you mean contacting GTEx and asking for more details on the skin sample sites? That seems the best to me as I assume the sample collectors had specific instructions. The skin sites are specified as <em>suprapubic</em> for sun unexposed and <em>lower leg</em> for sun exposed.</p>",
      "body_md": "> do they provide GEO or SRA identifiers for the samples BTW?\r\n\r\n@fbastian, I do not see any other sample identifiers than `SAMPID` (GTEx Public Sample ID) in the [sample attributes documentation spreadsheet](http://www.gtexportal.org/static/datasets/gtex_analysis_v4/annotations/GTEx_Data_V4_Annotations_SampleAttributesDD.xlsx). The IDs are formatted like `GTEX-N7MS-0007-SM-2D7W1` -- not sure whether that corresponds with other databases.\r\n\r\n> We could start working on the mapping you have, but we'd rather go through the information for each sample, to check for normality, etc.\r\n\r\n@fbastian, do whatever is best for you! And let it be known that your painstaking and thorough integration efforts are appreciated.\r\n\r\n> There are however, two subclasses of skin: exposed and unexposed.\r\n\r\n@chrismungall, by post-compose do you mean contacting GTEx and asking for more details on the skin sample sites? That seems the best to me as I assume the sample collectors had specific instructions. The skin sites are specified as *suprapubic* for sun unexposed and *lower leg* for sun exposed.",
      "comment_id": 285,
      "profile_id": 17,
      "published": "2015-06-19T18:00:24.304953Z",
      "thread_id": 82,
      "url": "/discussion/processing-gtex-for-tissue-specific-gene-expression/82#6"
    },
    {
      "body_html": "<h1>Nomenclature</h1>\r\n\r\n<p>We have been referring to the metanode (node type) for uberon as Tissue. Is Tissue a misnomer? Does Tissue encompass all uberon nodes? If we add CL terms under the same metanode, what term can we use that encompass uberon terms and cell types?</p>\r\n\r\n<p>A single word is preferred to a compound term. Some options I can think of are</p>\r\n\r\n<ul><li>Tissue</li><li>Anatomy</li><li>Structure</li><li>Anatomical Structure</li></ul>\r\n\r\n<p><a href=\"/u/chrismungall\" class=\"username\">@chrismungall</a>, do you have an inclination?</p>",
      "body_md": "# Nomenclature\r\n\r\nWe have been referring to the metanode (node type) for uberon as Tissue. Is Tissue a misnomer? Does Tissue encompass all uberon nodes? If we add CL terms under the same metanode, what term can we use that encompass uberon terms and cell types?\r\n\r\nA single word is preferred to a compound term. Some options I can think of are\r\n\r\n+ Tissue\r\n+ Anatomy\r\n+ Structure\r\n+ Anatomical Structure\r\n\r\n@chrismungall, do you have an inclination?",
      "comment_id": 286,
      "profile_id": 17,
      "published": "2015-06-19T18:37:26.847611Z",
      "thread_id": 41,
      "url": "/discussion/tissue-node/41#13"
    },
    {
      "body_html": "<p>tissue is too specific, but people will still know what you mean. Uberon follows the CARO upper level ontology:</p>\r\n\r\n<ul><li><a href=\"http://purl.obolibrary.org/obo/CARO_0030000\">CARO:0030000</a> ! biological entity<ul><li><a href=\"http://purl.obolibrary.org/obo/CARO_0000000\">CARO:0000000</a> ! anatomical entity<ul><li><a href=\"http://purl.obolibrary.org/obo/CARO_0000006\">CARO:0000006</a> ! material anatomical entity<ul><li><a href=\"http://purl.obolibrary.org/obo/CARO_0000003\">CARO:0000003</a> ! connected anatomical structure (aka anatomical structure)<ul><li><a href=\"http://purl.obolibrary.org/obo/CARO_0000013\">CARO:0000013</a> ! cell </li><li><a href=\"http://purl.obolibrary.org/obo/CARO_0010000\">CARO:0010000</a> ! multicellular anatomical structure<ul><li><a href=\"http://purl.obolibrary.org/obo/CARO_0000043\">CARO:0000043</a> ! tissue  </li><li><a href=\"http://purl.obolibrary.org/obo/CARO_0020004\">CARO:0020004</a> ! organ  </li><li><a href=\"http://purl.obolibrary.org/obo/CARO_0000043\">CARO:0000043</a> ! tissue  </li></ul></li></ul></li></ul></li></ul></li></ul></li></ul>\r\n\r\n<p>So formally speaking 'anatomical structure' would exclude non-material entities such as lumens, 2D boundaries... but you should never have gene expression in any of these sites</p>",
      "body_md": "tissue is too specific, but people will still know what you mean. Uberon follows the CARO upper level ontology:\r\n\r\n *  [CARO:0030000](http://purl.obolibrary.org/obo/CARO_0030000) ! biological entity\r\n    *  [CARO:0000000](http://purl.obolibrary.org/obo/CARO_0000000) ! anatomical entity\r\n       *  [CARO:0000006](http://purl.obolibrary.org/obo/CARO_0000006) ! material anatomical entity\r\n          *  [CARO:0000003](http://purl.obolibrary.org/obo/CARO_0000003) ! connected anatomical structure (aka anatomical structure)\r\n              *  [CARO:0000013](http://purl.obolibrary.org/obo/CARO_0000013) ! cell \r\n              *  [CARO:0010000](http://purl.obolibrary.org/obo/CARO_0010000) ! multicellular anatomical structure\r\n                 *  [CARO:0000043](http://purl.obolibrary.org/obo/CARO_0000043) ! tissue  \r\n                 *  [CARO:0020004](http://purl.obolibrary.org/obo/CARO_0020004) ! organ  \r\n                 *  [CARO:0000043](http://purl.obolibrary.org/obo/CARO_0000043) ! tissue  \r\n\r\nSo formally speaking 'anatomical structure' would exclude non-material entities such as lumens, 2D boundaries... but you should never have gene expression in any of these sites",
      "comment_id": 287,
      "profile_id": 109,
      "published": "2015-06-19T19:07:48.480887Z",
      "thread_id": 41,
      "url": "/discussion/tissue-node/41#14"
    },
    {
      "body_html": "<p><a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a>, thanks for the information. Did your lab formally request access to the data to get the actual annotations? (GTEx_Data_V4_Annotations_SampleAttributesDS.txt in your notebook)</p>\r\n\r\n<p>Otherwise, Chris is speaking about ontology term post-composition, a way of creating a new ontology concept on-the-fly, that doesn't have any identifier or IRI (\"anonymous class expression\"), and that is made of the \"composition\" of several other terms. That would allow you to create on the fly a new concept for \"exposed skin\".</p>\r\n\r\n<p>See for instance, in zebrafish ontology: <a href=\"https://zfin.org/action/ontology/post-composed-term-detail?superTermID=ZFA:0001117&amp;subTermID=ZFA:0000155\">https://zfin.org/action/ontology/post-composed-term-detail?superTermID=ZFA:0001117&amp;subTermID=ZFA:0000155</a><br>There is no term \"post-vent region somite\" in the ontology, but the concept is represented by using the existing terms \"post-vent region\" and \"somite\".</p>",
      "body_md": "@dhimmel, thanks for the information. Did your lab formally request access to the data to get the actual annotations? (GTEx_Data_V4_Annotations_SampleAttributesDS.txt in your notebook)\r\n\r\nOtherwise, Chris is speaking about ontology term post-composition, a way of creating a new ontology concept on-the-fly, that doesn't have any identifier or IRI (\"anonymous class expression\"), and that is made of the \"composition\" of several other terms. That would allow you to create on the fly a new concept for \"exposed skin\".\r\n\r\nSee for instance, in zebrafish ontology: https://zfin.org/action/ontology/post-composed-term-detail?superTermID=ZFA:0001117&subTermID=ZFA:0000155\r\nThere is no term \"post-vent region somite\" in the ontology, but the concept is represented by using the existing terms \"post-vent region\" and \"somite\".",
      "comment_id": 288,
      "profile_id": 111,
      "published": "2015-06-20T01:04:36.970291Z",
      "thread_id": 82,
      "url": "/discussion/processing-gtex-for-tissue-specific-gene-expression/82#7"
    },
    {
      "body_html": "<p>We have done some initial analyses on the Bgee data (<a href=\"http://nbviewer.ipython.org/github/dhimmel/bgee/blob/b26d396bbe6b137372731f031f544c7da47e314c/bgee.ipynb\">notebook</a>). We stuck with the simple files because:</p>\r\n\r\n<ul><li>we would like to outsource as much of the difficult decision-making as possible.</li><li>we want a method that is resilient to changing technologies and Bgee revisions — not a method that is only optimal for a specific Bgee release.</li></ul>\r\n\r\n<p>Here are our initial findings.</p>\r\n\r\n<h2>Gene presence</h2>\r\n\r\n<p>We chose the filter:</p>\r\n\r\n<p></p><pre><code class=\"python\">call_quality in {'high quality', 'low quality'} and expression in {'present', 'low ambiguity'}</code></pre>\r\n\r\n<p>We chose a permissive filter that is not limited to RNA-Seq. In the future, when Bgee contains more sources, we could increase these thresholds.</p>\r\n\r\n<p>The developmental stage \"25-44 year-old human stage\" (<code>HsapDv:0000090</code>) has the most present genes. \"Human adult stage\" (<code>HsapDv:0000087</code>) is comparatively quite underpopulated with major organs like heart having no present genes (<a href=\"http://nbviewer.ipython.org/github/dhimmel/bgee/blob/b26d396bbe6b137372731f031f544c7da47e314c/bgee.ipynb#Figure-1:-Number-of-genes-present-by-developmental-stage-and-anatomical-entity\">Figure 1</a>). I was surprised because I thought adult would subsume 25-44 and the expression data would be propagated. <a href=\"/u/fbastian\" class=\"username\">@fbastian</a>, any idea what is going on? Should we take 25-44 as our developmental context or should we collapse data across adult developmental stages. Is the differential-expression data lacking if it's only calculated on \"post-juvenile adult stage\"?</p>\r\n\r\n<p>Compared to the distribution of expressed genes in the GNF Expression Atlas (<a href=\"http://nbviewer.ipython.org/github/dhimmel/bgee/blob/b26d396bbe6b137372731f031f544c7da47e314c/bgee.ipynb#Figure-3:-Distibution-of-genes-present-per-tissue-in-GNF-Expression-Atlas\">Figure 3</a>), Bgee had much more variation by tissue. This is expected since Bgee integrates diverse data of varied throughput and a is an acceptable sacrifice for broader input data.</p>\r\n\r\n<h2>Differential expression</h2>\r\n\r\n<p>We identified differential expression with <code>call_quality in {'low quality', 'high quality'}</code>. <a href=\"http://nbviewer.ipython.org/github/dhimmel/bgee/blob/b26d396bbe6b137372731f031f544c7da47e314c/bgee.ipynb#Figure-2:-Number-of-differntially-expressed-genes-present-by-anatomical-entity\">Figure 2</a> shows that we identified a large number of DE-genes across a variety of anatomical entities. Some tissues or cell types, such as leukocytes and testis, have over 10,000 under/over-expressed genes (almost every gene). Is this biologically meaningful or the result of data coverage or other experimental artifacts?</p>",
      "body_md": "We have done some initial analyses on the Bgee data ([notebook](http://nbviewer.ipython.org/github/dhimmel/bgee/blob/b26d396bbe6b137372731f031f544c7da47e314c/bgee.ipynb)). We stuck with the simple files because:\r\n\r\n+ we would like to outsource as much of the difficult decision-making as possible.\r\n+ we want a method that is resilient to changing technologies and Bgee revisions -- not a method that is only optimal for a specific Bgee release.\r\n\r\nHere are our initial findings.\r\n\r\n## Gene presence\r\n\r\nWe chose the filter:\r\n\r\n```python\r\ncall_quality in {'high quality', 'low quality'} and expression in {'present', 'low ambiguity'}\r\n```\r\n\r\nWe chose a permissive filter that is not limited to RNA-Seq. In the future, when Bgee contains more sources, we could increase these thresholds.\r\n\r\nThe developmental stage \"25-44 year-old human stage\" (`HsapDv:0000090`) has the most present genes. \"Human adult stage\" (`HsapDv:0000087`) is comparatively quite underpopulated with major organs like heart having no present genes ([Figure 1](http://nbviewer.ipython.org/github/dhimmel/bgee/blob/b26d396bbe6b137372731f031f544c7da47e314c/bgee.ipynb#Figure-1:-Number-of-genes-present-by-developmental-stage-and-anatomical-entity)). I was surprised because I thought adult would subsume 25-44 and the expression data would be propagated. @fbastian, any idea what is going on? Should we take 25-44 as our developmental context or should we collapse data across adult developmental stages. Is the differential-expression data lacking if it's only calculated on \"post-juvenile adult stage\"?\r\n\r\nCompared to the distribution of expressed genes in the GNF Expression Atlas ([Figure 3](http://nbviewer.ipython.org/github/dhimmel/bgee/blob/b26d396bbe6b137372731f031f544c7da47e314c/bgee.ipynb#Figure-3:-Distibution-of-genes-present-per-tissue-in-GNF-Expression-Atlas)), Bgee had much more variation by tissue. This is expected since Bgee integrates diverse data of varied throughput and a is an acceptable sacrifice for broader input data.\r\n\r\n## Differential expression\r\n\r\nWe identified differential expression with `call_quality in {'low quality', 'high quality'}`. [Figure 2](http://nbviewer.ipython.org/github/dhimmel/bgee/blob/b26d396bbe6b137372731f031f544c7da47e314c/bgee.ipynb#Figure-2:-Number-of-differntially-expressed-genes-present-by-anatomical-entity) shows that we identified a large number of DE-genes across a variety of anatomical entities. Some tissues or cell types, such as leukocytes and testis, have over 10,000 under/over-expressed genes (almost every gene). Is this biologically meaningful or the result of data coverage or other experimental artifacts?",
      "comment_id": 289,
      "profile_id": 17,
      "published": "2015-06-20T03:01:42.139093Z",
      "thread_id": 81,
      "url": "/discussion/tissue-specific-gene-expression-resources/81#6"
    },
    {
      "body_html": "<p><a href=\"/u/fbastian\" class=\"username\">@fbastian</a>, <code>GTEx_Data_V4_Annotations_SampleAttributesDS.txt</code> is available from the GTEx <a href=\"http://www.gtexportal.org/home/datasets2\">download page</a> which requires an account. However, <a href=\"http://www.gtexportal.org/static/datasets/gtex_analysis_v4/annotations/GTEx_Data_V4_Annotations_SampleAttributesDS.txt\">this direct link</a> circumvents the login page. How long has it been since you submitted the data access request?</p>",
      "body_md": "@fbastian, `GTEx_Data_V4_Annotations_SampleAttributesDS.txt` is available from the GTEx [download page](http://www.gtexportal.org/home/datasets2) which requires an account. However, [this direct link](http://www.gtexportal.org/static/datasets/gtex_analysis_v4/annotations/GTEx_Data_V4_Annotations_SampleAttributesDS.txt) circumvents the login page. How long has it been since you submitted the data access request?",
      "comment_id": 290,
      "profile_id": 17,
      "published": "2015-06-20T03:14:11.820349Z",
      "thread_id": 82,
      "url": "/discussion/processing-gtex-for-tissue-specific-gene-expression/82#8"
    },
    {
      "body_html": "<p>Not very long, a week or so.</p>\r\n\r\n<p>Just to anticipate, do they provide more detailed information somewhere else, like, e.g., <a href=\"http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM81022\">http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM81022</a> ? (extraction protocols, detailed information about the anatomical structure, etc)</p>",
      "body_md": "Not very long, a week or so.\r\n\r\nJust to anticipate, do they provide more detailed information somewhere else, like, e.g., http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM81022 ? (extraction protocols, detailed information about the anatomical structure, etc)",
      "comment_id": 291,
      "profile_id": 111,
      "published": "2015-06-20T11:51:59.295307Z",
      "thread_id": 82,
      "url": "/discussion/processing-gtex-for-tissue-specific-gene-expression/82#9"
    },
    {
      "body_html": "<p>(on a side note, I didn't know IPython/Jupyter, I discovered it thanks to you and I fell in love with it, this is amazing; also, it's great to have other people to investigate our data, and check their quality)</p>\r\n\r\n<blockquote><p>I was surprised because I thought adult would subsume 25-44 and the expression data would be propagated</p></blockquote>\r\n\r\n<p>So, we propagate the data, but in the simple file we only display conditions that were actually observed in experimental data (no conditions appearing from propagation only). It means that we never had an experiment studying \"heart\" at stage \"human adult stage\". Which makes sense, because annotating experimental data with such a broad term basically mean \"we know it was a heart from an adult, but no idea which age\"; we often have more detailed information.</p>\r\n\r\n<p>This is why the complete file would work better for you, as we also display conditions from \"propagation only\"; you should see lots of data for \"heart\" at \"human adult stage\". Of note, even in the complete file you get the \"global\" call generated by us, see column 7 and 8: <a href=\"http://bgee.org/?page=doc&amp;action=call_files#single_expr_complete\">http://bgee.org/?page=doc&amp;action=call_files#single_expr_complete</a><br>So you wouldn't have to do the decision-making, even when using the complete file.</p>\r\n\r\n<p>But your problem is interesting, maybe we should \"relax\" the filtering of conditions in the simple file, I will think about it.<br>This difference in filtering was explained in the documentation, should we clarify it?</p>\r\n\r\n<blockquote><p>Some tissues or cell types, such as leukocytes and testis, have over 10,000 under/over-expressed genes (almost every gene). Is this biologically meaningful or the result of data coverage or other experimental artifacts?</p></blockquote>\r\n\r\n<p>I think it is meaningful. First, it is not almost every gene, from the complete file (where you can also find genes never shown to have differential expression) you can see that we have about 20,000 genes tested for differential expression; so, in the majority of tissues you get a reasonable percentage of genes differentially expressed. Second, I'm not surprised by the outlier tissues you found, for instance we know that testis and brain have very specific expression. Third, you almost always found more genes under-expressed than over-expressed, and this is actually an interesting pattern, that we have observed by other methods.</p>\r\n\r\n<p>I will discuss this with my colleagues to be sure they get to the same conclusion, and will get back to you. But I think everything looks good. </p>",
      "body_md": "(on a side note, I didn't know IPython/Jupyter, I discovered it thanks to you and I fell in love with it, this is amazing; also, it's great to have other people to investigate our data, and check their quality)\r\n\r\n> I was surprised because I thought adult would subsume 25-44 and the expression data would be propagated\r\n\r\nSo, we propagate the data, but in the simple file we only display conditions that were actually observed in experimental data (no conditions appearing from propagation only). It means that we never had an experiment studying \"heart\" at stage \"human adult stage\". Which makes sense, because annotating experimental data with such a broad term basically mean \"we know it was a heart from an adult, but no idea which age\"; we often have more detailed information.\r\n\r\nThis is why the complete file would work better for you, as we also display conditions from \"propagation only\"; you should see lots of data for \"heart\" at \"human adult stage\". Of note, even in the complete file you get the \"global\" call generated by us, see column 7 and 8: http://bgee.org/?page=doc&action=call_files#single_expr_complete\r\nSo you wouldn't have to do the decision-making, even when using the complete file.\r\n\r\nBut your problem is interesting, maybe we should \"relax\" the filtering of conditions in the simple file, I will think about it.\r\nThis difference in filtering was explained in the documentation, should we clarify it?\r\n\r\n> Some tissues or cell types, such as leukocytes and testis, have over 10,000 under/over-expressed genes (almost every gene). Is this biologically meaningful or the result of data coverage or other experimental artifacts?\r\n\r\nI think it is meaningful. First, it is not almost every gene, from the complete file (where you can also find genes never shown to have differential expression) you can see that we have about 20,000 genes tested for differential expression; so, in the majority of tissues you get a reasonable percentage of genes differentially expressed. Second, I'm not surprised by the outlier tissues you found, for instance we know that testis and brain have very specific expression. Third, you almost always found more genes under-expressed than over-expressed, and this is actually an interesting pattern, that we have observed by other methods.\r\n\r\nI will discuss this with my colleagues to be sure they get to the same conclusion, and will get back to you. But I think everything looks good. ",
      "comment_id": 292,
      "profile_id": 111,
      "published": "2015-06-20T12:36:57.943554Z",
      "thread_id": 81,
      "url": "/discussion/tissue-specific-gene-expression-resources/81#7"
    },
    {
      "body_html": "<h1>Completed Bgee analysis — version 0</h1>\r\n\r\n<h2>Tissue-specific gene presence</h2>\r\n\r\n<blockquote><p>we propagate the data, but in the simple file we only display conditions that were actually observed in experimental data (no conditions appearing from propagation only)</p></blockquote>\r\n\r\n<p>Okay I switched to the complete file for presence/absence. The updated <a href=\"http://nbviewer.ipython.org/github/dhimmel/bgee/blob/bd50da6c931675a0316a71ab5c6d7d1bbd35f8bd/bgee.ipynb#Figure-1:-Number-of-genes-present-by-developmental-stage-and-anatomical-entity\">Figure 1</a> makes much more sense now. We chose to go with \"human adult stage\" (<code>HsapDv:0000087</code>) as the developmental stage, which now has broad coverage across tissues, however with fewer present genes than \"life cycle\" as expected. We converted to entrez genes and ended up with a matrix of 18,997 genes (16,278 coding) × 666 anatomical entities (<a href=\"https://github.com/dhimmel/bgee/blob/bd50da6c931675a0316a71ab5c6d7d1bbd35f8bd/data/present-in-adult.tsv.gz\">download</a>). On average, 41.1% of genes were expressed in a given anatomical entity.</p>\r\n\r\n<blockquote><p>But your problem is interesting, maybe we should \"relax\" the filtering of conditions in the simple file, I will think about it. This difference in filtering was explained in the documentation, should we clarify it?</p></blockquote>\r\n\r\n<p>I misinterpreted the <a href=\"http://bgee.unil.ch/?page=doc&amp;action=call_files#single_expr\">documentation</a> by assuming that if a developmental stage had any annotations, propagated values would be provided for all anatomies of that stage. Instead, propagated values are only included for stage–anatomy combinations with annotations. Perhaps the documentation should make it more clear that many use cases will require the complete file due to this issue. Another consideration is that processing the complete file was consuming up to 80 GB of RAM at points — not an issue <em>personally</em> but could be for others.</p>\r\n\r\n<h2>Tissue-specific differential expression</h2>\r\n\r\n<p>We converted the differential expression to entrez genes and ended up with a matrix of 18,620 genes (16,184 coding) × 98 anatomical entities (<a href=\"http://nbviewer.ipython.org/github/dhimmel/bgee/blob/bd50da6c931675a0316a71ab5c6d7d1bbd35f8bd/bgee.ipynb#Read-and-process-differential-expression-data\">notebook</a>, <a href=\"https://github.com/dhimmel/bgee/blob/bd50da6c931675a0316a71ab5c6d7d1bbd35f8bd/data/diffex.tsv.gz\">download</a>).</p>\r\n\r\n<h1>General Bgee feedback</h1>\r\n\r\n<p><a href=\"/u/fbastian\" class=\"username\">@fbastian</a>, in the presence download, for a given gene–stage–anatomy combination is there at most one row? For the anatomy-based differential expression download, for a given gene–anatomy combination is there at most one row? Better documentation of what uniquely defines an observation (row) would be helpful.</p>\r\n\r\n<p>Since the downloaded zip files only contain a single file, I think gzip compression makes more sense.</p>\r\n\r\n<p>Finally, I prefer lowercase column names with underscores rather than spaces. This naming convention avoids frustrating <a href=\"https://github.com/hadley/readr/blob/efd422504762d703bc8c67a40c36e52466e275b3/README.md#output\">R munging</a> and enables unquoted variable reference in R and python. Understandably, you may not want to change for compatibility issues.</p>",
      "body_md": "# Completed Bgee analysis -- version 0\r\n\r\n## Tissue-specific gene presence\r\n\r\n> we propagate the data, but in the simple file we only display conditions that were actually observed in experimental data (no conditions appearing from propagation only)\r\n\r\nOkay I switched to the complete file for presence/absence. The updated [Figure 1](http://nbviewer.ipython.org/github/dhimmel/bgee/blob/bd50da6c931675a0316a71ab5c6d7d1bbd35f8bd/bgee.ipynb#Figure-1:-Number-of-genes-present-by-developmental-stage-and-anatomical-entity) makes much more sense now. We chose to go with \"human adult stage\" (`HsapDv:0000087`) as the developmental stage, which now has broad coverage across tissues, however with fewer present genes than \"life cycle\" as expected. We converted to entrez genes and ended up with a matrix of 18,997 genes (16,278 coding) × 666 anatomical entities ([download](https://github.com/dhimmel/bgee/blob/bd50da6c931675a0316a71ab5c6d7d1bbd35f8bd/data/present-in-adult.tsv.gz)). On average, 41.1% of genes were expressed in a given anatomical entity.\r\n\r\n> But your problem is interesting, maybe we should \"relax\" the filtering of conditions in the simple file, I will think about it. This difference in filtering was explained in the documentation, should we clarify it?\r\n\r\nI misinterpreted the [documentation](http://bgee.unil.ch/?page=doc&action=call_files#single_expr) by assuming that if a developmental stage had any annotations, propagated values would be provided for all anatomies of that stage. Instead, propagated values are only included for stage--anatomy combinations with annotations. Perhaps the documentation should make it more clear that many use cases will require the complete file due to this issue. Another consideration is that processing the complete file was consuming up to 80 GB of RAM at points -- not an issue *personally* but could be for others.\r\n\r\n## Tissue-specific differential expression\r\n\r\nWe converted the differential expression to entrez genes and ended up with a matrix of 18,620 genes (16,184 coding) × 98 anatomical entities ([notebook](http://nbviewer.ipython.org/github/dhimmel/bgee/blob/bd50da6c931675a0316a71ab5c6d7d1bbd35f8bd/bgee.ipynb#Read-and-process-differential-expression-data), [download](https://github.com/dhimmel/bgee/blob/bd50da6c931675a0316a71ab5c6d7d1bbd35f8bd/data/diffex.tsv.gz)).\r\n\r\n# General Bgee feedback\r\n\r\n@fbastian, in the presence download, for a given gene--stage--anatomy combination is there at most one row? For the anatomy-based differential expression download, for a given gene--anatomy combination is there at most one row? Better documentation of what uniquely defines an observation (row) would be helpful.\r\n\r\nSince the downloaded zip files only contain a single file, I think gzip compression makes more sense.\r\n\r\nFinally, I prefer lowercase column names with underscores rather than spaces. This naming convention avoids frustrating [R munging](https://github.com/hadley/readr/blob/efd422504762d703bc8c67a40c36e52466e275b3/README.md#output) and enables unquoted variable reference in R and python. Understandably, you may not want to change for compatibility issues.",
      "comment_id": 293,
      "profile_id": 17,
      "published": "2015-06-20T20:46:05.585228Z",
      "thread_id": 81,
      "url": "/discussion/tissue-specific-gene-expression-resources/81#8"
    },
    {
      "body_html": "<blockquote><p>do they provide more detailed information somewhere else</p></blockquote>\r\n\r\n<p>No idea, I did email the GTEx support with a link to this thread, so perhaps they'll provide some clarification.</p>",
      "body_md": "> do they provide more detailed information somewhere else\r\n\r\nNo idea, I did email the GTEx support with a link to this thread, so perhaps they'll provide some clarification.",
      "comment_id": 294,
      "profile_id": 17,
      "published": "2015-06-20T22:26:16.860996Z",
      "thread_id": 82,
      "url": "/discussion/processing-gtex-for-tissue-specific-gene-expression/82#10"
    },
    {
      "body_html": "<blockquote><p>formally speaking 'anatomical structure' would exclude non-material entities such as lumens, 2D boundaries</p></blockquote>\r\n\r\n<p>Nodes that don't have expression may still be connected via a disease localization edge. These edges are currently <a href=\"http://thinklab.com/discussion/mining-knowledge-from-medline-articles-and-their-indexed-mesh-terms/67#229\">created via MEDLINE cooccurrence</a> and can connect any uberon or CL terms that map to MeSH.</p>\r\n\r\n<p>I am leaning towards calling the metanode <em>Anatomy</em>. We would end up with metapaths (path types) like: <strong>C</strong>ompound–<strong>t</strong>arget–<strong>G</strong>ene–<strong>e</strong>xpression–<strong>A</strong>natomy–<strong>l</strong>ocalization–<strong>D</strong>isease (abbreviated as <em>CtGeAlD</em>). This metapath refers to when a compound targets a gene that is expressed in an anatomy/tissue/cell-type where the disease is localized. Does that seem like a misuse of the word Anatomy?</p>",
      "body_md": "> formally speaking 'anatomical structure' would exclude non-material entities such as lumens, 2D boundaries\r\n\r\nNodes that don't have expression may still be connected via a disease localization edge. These edges are currently [created via MEDLINE cooccurrence](http://thinklab.com/discussion/mining-knowledge-from-medline-articles-and-their-indexed-mesh-terms/67#229) and can connect any uberon or CL terms that map to MeSH.\r\n\r\nI am leaning towards calling the metanode *Anatomy*. We would end up with metapaths (path types) like: **C**ompound--**t**arget--**G**ene--**e**xpression--**A**natomy--**l**ocalization--**D**isease (abbreviated as *CtGeAlD*). This metapath refers to when a compound targets a gene that is expressed in an anatomy/tissue/cell-type where the disease is localized. Does that seem like a misuse of the word Anatomy?",
      "comment_id": 295,
      "profile_id": 17,
      "published": "2015-06-20T23:02:20.747870Z",
      "thread_id": 41,
      "url": "/discussion/tissue-node/41#15"
    },
    {
      "body_html": "<p>FYI, our curator Anne Niknejad has started editing your mapping, she will also create the issues on the Uberon tracker to request new terms.</p>",
      "body_md": "FYI, our curator Anne Niknejad has started editing your mapping, she will also create the issues on the Uberon tracker to request new terms.",
      "comment_id": 296,
      "profile_id": 111,
      "published": "2015-06-22T11:50:04.721482Z",
      "thread_id": 82,
      "url": "/discussion/processing-gtex-for-tissue-specific-gene-expression/82#11"
    },
    {
      "body_html": "<blockquote><p>Some tissues or cell types, such as leukocytes and testis, have over 10,000 under/over-expressed genes (almost every gene). Is this biologically meaningful or the result of data coverage or other experimental artifacts?</p></blockquote>\r\n\r\n<p>I discussed this with my colleagues as promised, they agree that everything looks fine. We just get to the conclusion that maybe we could use a FDR correction over all analyses (currently, p-values are corrected on a \"per analysis\" basis), to decrease the number of differentially expressed genes in the most studied organs. </p>\r\n\r\n<blockquote><p>matrix of 18,997 genes (16,278 coding) × 666 anatomical entities</p></blockquote>\r\n\r\n<p>Great, I just want to warn you that lots of these structures are not independent (e.g., \"cerebellum\" is not independent from \"brain\"). I don't know what type of analyses you plan, but this can sometimes be problematic. If you need it, I can provide you a script accepting a list of organs as argument, and returning only the most-precise \"independent\" organs.</p>\r\n\r\n<blockquote><p>in the presence download, for a given gene–stage–anatomy combination is there at most one row</p></blockquote>\r\n\r\n<p>Yes.</p>\r\n\r\n<blockquote><p>For the anatomy-based differential expression download, for a given gene–anatomy combination is there at most one row?</p></blockquote>\r\n\r\n<p>No, because an analysis could compare organ A, B, C at stage embryo, another one compare the organs A, B, C at stage adult. So, for a given gene, you would have two entries for organ A: one at stage embryo, another one at stage adult.<br>So, it is as for presence download, it is at most one row for a given gene–stage–anatomy combination.</p>\r\n\r\n<blockquote><p>I think gzip compression makes more sense.</p></blockquote>\r\n\r\n<p>Not for Windows users (yes, it exists :p)</p>\r\n\r\n<p>Thank you for your feedback, we will take it into account, it is much appreciated. Notably we will remove the spaces in header, will update the documentation, and will change the filtering in simple files.</p>",
      "body_md": "> Some tissues or cell types, such as leukocytes and testis, have over 10,000 under/over-expressed genes (almost every gene). Is this biologically meaningful or the result of data coverage or other experimental artifacts?\r\n\r\nI discussed this with my colleagues as promised, they agree that everything looks fine. We just get to the conclusion that maybe we could use a FDR correction over all analyses (currently, p-values are corrected on a \"per analysis\" basis), to decrease the number of differentially expressed genes in the most studied organs. \r\n\r\n> matrix of 18,997 genes (16,278 coding) × 666 anatomical entities\r\n\r\nGreat, I just want to warn you that lots of these structures are not independent (e.g., \"cerebellum\" is not independent from \"brain\"). I don't know what type of analyses you plan, but this can sometimes be problematic. If you need it, I can provide you a script accepting a list of organs as argument, and returning only the most-precise \"independent\" organs.\r\n\r\n> in the presence download, for a given gene–stage–anatomy combination is there at most one row\r\n\r\nYes.\r\n\r\n> For the anatomy-based differential expression download, for a given gene–anatomy combination is there at most one row?\r\n\r\nNo, because an analysis could compare organ A, B, C at stage embryo, another one compare the organs A, B, C at stage adult. So, for a given gene, you would have two entries for organ A: one at stage embryo, another one at stage adult.\r\nSo, it is as for presence download, it is at most one row for a given gene–stage–anatomy combination.\r\n\r\n> I think gzip compression makes more sense.\r\n\r\nNot for Windows users (yes, it exists :p)\r\n\r\nThank you for your feedback, we will take it into account, it is much appreciated. Notably we will remove the spaces in header, will update the documentation, and will change the filtering in simple files.",
      "comment_id": 297,
      "profile_id": 111,
      "published": "2015-06-22T15:16:41.680643Z",
      "thread_id": 81,
      "url": "/discussion/tissue-specific-gene-expression-resources/81#9"
    },
    {
      "body_html": "<h1>1000 Genomes Phase 3 data</h1>\r\n\r\n<p>We have <a href=\"http://www.1000genomes.org/announcements/phase-3-variant-set-additional-allele-frequencies-functional-annotation-and-other-data\">become aware</a> that more recent and comprehensive 1000 Genomes data exists, it's just not included in SNAP. The phase 3 dataset contains ~2500 individuals with whole-genome sequencing.</p>\r\n\r\n<p>The phase 3 data was <a href=\"http://www.ensembl.info/blog/2015/06/18/1000-genomes-phase-3-frequencies-genotypes-and-ld-data/#comments\">recently added</a> to the Ensembl database. Ensembl has a <a href=\"http://uswest.ensembl.org/info/docs/api/variation/true\">perl API</a>, which should be able to find all SNPs in LD with a lead SNP.</p>\r\n\r\n<p>We found <a href=\"https://www.biostars.org/p/109785/#110102\">example code</a> and have <a href=\"https://www.biostars.org/p/109785/#147784\">reached out</a> for advice because our implementation is <a href=\"http://nbviewer.ipython.org/github/dhimmel/ensembl-api/blob/5ee80e036a8dd4e5416c2af6ddd5ae7a1a9c5a44/linkage.ipynb\">currently failing</a>.</p>",
      "body_md": "# 1000 Genomes Phase 3 data\r\n\r\nWe have [become aware](http://www.1000genomes.org/announcements/phase-3-variant-set-additional-allele-frequencies-functional-annotation-and-other-data) that more recent and comprehensive 1000 Genomes data exists, it's just not included in SNAP. The phase 3 dataset contains ~2500 individuals with whole-genome sequencing.\r\n\r\nThe phase 3 data was [recently added](http://www.ensembl.info/blog/2015/06/18/1000-genomes-phase-3-frequencies-genotypes-and-ld-data/#comments) to the Ensembl database. Ensembl has a [perl API](http://uswest.ensembl.org/info/docs/api/variation/true), which should be able to find all SNPs in LD with a lead SNP.\r\n\r\nWe found [example code](https://www.biostars.org/p/109785/#110102) and have [reached out](https://www.biostars.org/p/109785/#147784) for advice because our implementation is [currently failing](http://nbviewer.ipython.org/github/dhimmel/ensembl-api/blob/5ee80e036a8dd4e5416c2af6ddd5ae7a1a9c5a44/linkage.ipynb).",
      "comment_id": 298,
      "profile_id": 17,
      "published": "2015-06-23T18:26:55.244063Z",
      "thread_id": 71,
      "url": "/discussion/calculating-genomic-windows-for-gwas-lead-snps/71#6"
    },
    {
      "body_html": "<blockquote><p>we could use a FDR correction over all analyses</p></blockquote>\r\n\r\n<p>I support the correction for multiple testing.</p>\r\n\r\n<blockquote><p>So, it is as for presence download, it is at most one row for a given gene–stage–anatomy combination.</p></blockquote>\r\n\r\n<p>I thought all rows in the \"Over-/Under-expression across anatomy\" download were for \"post-juvenile adult stage\", so row uniqueness depends only on gene and anatomy?</p>\r\n\r\n<blockquote><p>lots of these structures are not independent (e.g., \"cerebellum\" is not independent from \"brain\"). I don't know what type of analyses you plan, but this can sometimes be problematic.</p></blockquote>\r\n\r\n<p>We enforce uniqueness for the metanodes where we are predicting edges (<a href=\"http://thinklab.com/discussion/unifying-drug-vocabularies/40#192\">compounds</a> and <a href=\"http://thinklab.com/discussion/unifying-disease-vocabularies/44#144\">diseases</a>). We are not planning on eradicating term overlap for other metanodes such as <a href=\"http://thinklab.com/discussion/compiling-gene-ontology-annotations-into-an-easy-to-use-format/39\">GO Domains</a>, <a href=\"http://thinklab.com/discussion/tissue-node/41#286\">Anatomy</a>, and <a href=\"http://thinklab.com/discussion/mining-knowledge-from-medline-articles-and-their-indexed-mesh-terms/67#222\">Symptom</a>. The consequence of this duplicity is unknown and something that <a href=\"http://het.io/hnep/\">HNEP</a> researchers should eventually confront.</p>\r\n\r\n<p>Our method downweights paths through high-degree nodes, which reduces the impact of highly-redundant supernodes such as \"anatomical entity\", \"anatomical structure\", and \"anatomical system\". However, our implementation has not been optimized and may get bogged down by all these expression edges. Therefore we may consider removing anatomies that are too broad to be meaningful. We could also consider pruning for independence.</p>\r\n\r\n<blockquote><p>If you need it, I can provide you a script accepting a list of organs as argument, and returning only the most-precise \"independent\" organs.</p></blockquote>\r\n\r\n<p>Yes, I don't <em>need</em> it but <em>want</em> to see the script out of interest. Primarily, I am curious about how your algorithm, since I often encounter these problems.</p>",
      "body_md": "> we could use a FDR correction over all analyses\r\n\r\nI support the correction for multiple testing.\r\n\r\n> So, it is as for presence download, it is at most one row for a given gene–stage–anatomy combination.\r\n\r\nI thought all rows in the \"Over-/Under-expression across anatomy\" download were for \"post-juvenile adult stage\", so row uniqueness depends only on gene and anatomy?\r\n\r\n> lots of these structures are not independent (e.g., \"cerebellum\" is not independent from \"brain\"). I don't know what type of analyses you plan, but this can sometimes be problematic.\r\n\r\nWe enforce uniqueness for the metanodes where we are predicting edges ([compounds](http://thinklab.com/discussion/unifying-drug-vocabularies/40#192) and [diseases](http://thinklab.com/discussion/unifying-disease-vocabularies/44#144)). We are not planning on eradicating term overlap for other metanodes such as [GO Domains](http://thinklab.com/discussion/compiling-gene-ontology-annotations-into-an-easy-to-use-format/39), [Anatomy](http://thinklab.com/discussion/tissue-node/41#286), and [Symptom](http://thinklab.com/discussion/mining-knowledge-from-medline-articles-and-their-indexed-mesh-terms/67#222). The consequence of this duplicity is unknown and something that [HNEP](http://het.io/hnep/) researchers should eventually confront.\r\n\r\nOur method downweights paths through high-degree nodes, which reduces the impact of highly-redundant supernodes such as \"anatomical entity\", \"anatomical structure\", and \"anatomical system\". However, our implementation has not been optimized and may get bogged down by all these expression edges. Therefore we may consider removing anatomies that are too broad to be meaningful. We could also consider pruning for independence.\r\n\r\n> If you need it, I can provide you a script accepting a list of organs as argument, and returning only the most-precise \"independent\" organs.\r\n\r\nYes, I don't *need* it but *want* to see the script out of interest. Primarily, I am curious about how your algorithm, since I often encounter these problems.",
      "comment_id": 299,
      "profile_id": 17,
      "published": "2015-06-23T19:29:01.737789Z",
      "thread_id": 81,
      "url": "/discussion/tissue-specific-gene-expression-resources/81#10"
    },
    {
      "body_html": "<p>Python is our first-line language because it is powerful, elegant, and widely adopted. In combination with <a href=\"https://jupyter.org/\">Jupyter notebooks</a>, python is a data science jackhammer, while also being general purpose.</p>\r\n\r\n<p>Python 3 was released in 2008 and contains small incompatibilities with Python 2. 3 is <a href=\"https://youtu.be/f_6vDi7ywuA\">superior</a> to 2. Many training resources and codebases are still in 2, but new users should begin with 3.</p>\r\n\r\n<h2>Installation</h2>\r\n\r\n<p>We will use Anaconda for package management. Anaconda makes installing packages easier and includes most important ones by default. It also supports environments — distinct and independent installations — which allow specific installations for specific purposes. Anaconda creates a default environment (root) that becomes your primary python distribution. Here, we create a root python 3 environment and an elective python 2 environment that can be activated when needed. </p>\r\n\r\n<p>Download <a href=\"http://continuum.io/downloads\">anaconda for python 3</a>. Avoid the graphical installer which installs unneeded GUI programs. Install according to the defaults. Once installed run the following terminal command for updates:</p>\r\n\r\n<pre><code class=\"no-highlight hljs\">conda update --all</code></pre>\r\n\r\n<p>When needed, additional packages should be installed like <code>conda install seaborn</code>, which installs the <a href=\"https://web.stanford.edu/~mwaskom/software/seaborn/\">seaborn</a> visualization package.</p>\r\n\r\n<p>To install python 2.7, we will create a new environment called <code>py27</code> with the following command:</p>\r\n\r\n<pre><code class=\"no-highlight hljs\">conda create -n py27 python=2.7 anaconda</code></pre>\r\n\r\n<p>Activate the python 2 environment with <code>source activate py27</code> on linux or mac and <code>activate py27</code> on windows. Once activated, run <code>conda update --all</code> to update packages and <code>jupyter kernelspec install-self --user</code> to make the Python 2 kernel available in Jupyter. Then run <code>source deactivate</code> (or <code>deactivate</code> on windows) to return to the default python 3 environment.</p>\r\n\r\n<p>Python 2 should only be used when necessitated by legacy codebases. Otherwise, we use Python 3.</p>\r\n\r\n<p>If you need <a href=\"http://www.rdkit.org/\">rdkit</a> for chemoinformatics, you should follow the installation <a href=\"https://github.com/rdkit/conda-rdkit\">instructions here</a>, which creates a dedicated rdkit environment with InChI support.</p>\r\n\r\n<h2>Usage</h2>\r\n\r\n<p>We recommend using Jupyter notebooks for most analyses. Launch jupyter by running <code>jupyter notebook</code> in the terminal. Dedicated .py files can be edited using the Jupyter text editor or <a href=\"https://atom.io/\">atom</a>.</p>\r\n\r\n<p>Familiarize yourself with the <a href=\"https://www.python.org/dev/peps/pep-0008/\">PEP 0008</a> style guide.</p>\r\n\r\n<h2>Local development</h2>\r\n\r\n<p>When developing a package locally, run <code>pip install -e .</code> from the package's root directory. The package will then be importable from within your conda environment. The <code>-e</code> flag specifies editable mode and makes the package automatically update when you modify the source.</p>\r\n\r\n<h2>Packages</h2>\r\n\r\n<ul><li><p><a href=\"http://pandas.pydata.org/\"><code>pandas</code></a> for dataframes — important functions include <a href=\"http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.merge.html\"><code>DataFrame.merge</code></a>, <a href=\"http://pandas.pydata.org/pandas-docs/stable/generated/pandas.melt.html\"><code>melt</code></a>, <a href=\"http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.pivot_table.html\"><code>DataFrame.pivot_table</code></a>, <a href=\"http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html\"><code>DataFrame.groupby</code></a>, <a href=\"http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_table.html\"><code>pandas.read_table</code></a>, <a href=\"http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_csv.html\"><code>DataFrame.to_csv(path, sep='\\t', index=False)</code></a>, <a href=\"http://pandas.pydata.org/pandas-docs/stable/generated/pandas.isnull.html\"><code>pandas.isnull</code></a>, and <a href=\"http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.head.html\"><code>DataFrame.head</code></a>. Be forewarned of <a href=\"http://pandas.pydata.org/pandas-docs/stable/gotchas.html#support-for-integer-na\">the horrors</a> of int to float conversion when missing values are present.</p></li><li><p><a href=\"https://web.stanford.edu/~mwaskom/software/seaborn/\"><code>seaborn</code></a> for data visualization.</p></li><li><p><a href=\"http://www.numpy.org/\"><code>numpy</code></a> for arrays and linear algebra.</p></li><li><p><a href=\"http://docs.python-requests.org/en/latest/\"><code>requests</code></a> for http calls.</p></li><li><p><a href=\"http://scikit-learn.org/stable/\"><code>sklearn</code></a> for machine learning and classification.</p></li></ul>\r\n\r\n<p>For example code, <a href=\"https://github.com/search?l=&amp;o=desc&amp;q=user%3Adhimmel+extension%3Aipynb&amp;ref=advsearch&amp;s=indexed&amp;type=Code&amp;utf8=%E2%9C%93\">check out</a> my notebooks.</p>",
      "body_md": "Python is our first-line language because it is powerful, elegant, and widely adopted. In combination with [Jupyter notebooks](https://jupyter.org/), python is a data science jackhammer, while also being general purpose.\r\n\r\nPython 3 was released in 2008 and contains small incompatibilities with Python 2. 3 is [superior](https://youtu.be/f_6vDi7ywuA) to 2. Many training resources and codebases are still in 2, but new users should begin with 3.\r\n\r\n## Installation\r\n\r\nWe will use Anaconda for package management. Anaconda makes installing packages easier and includes most important ones by default. It also supports environments -- distinct and independent installations -- which allow specific installations for specific purposes. Anaconda creates a default environment (root) that becomes your primary python distribution. Here, we create a root python 3 environment and an elective python 2 environment that can be activated when needed. \r\n\r\nDownload [anaconda for python 3](http://continuum.io/downloads). Avoid the graphical installer which installs unneeded GUI programs. Install according to the defaults. Once installed run the following terminal command for updates:\r\n\r\n```sh\r\nconda update --all\r\n```\r\n\r\nWhen needed, additional packages should be installed like `conda install seaborn`, which installs the [seaborn](https://web.stanford.edu/~mwaskom/software/seaborn/) visualization package.\r\n\r\nTo install python 2.7, we will create a new environment called `py27` with the following command:\r\n\r\n```sh\r\nconda create -n py27 python=2.7 anaconda\r\n```\r\n\r\nActivate the python 2 environment with `source activate py27` on linux or mac and `activate py27` on windows. Once activated, run `conda update --all` to update packages and `jupyter kernelspec install-self --user` to make the Python 2 kernel available in Jupyter. Then run `source deactivate` (or `deactivate` on windows) to return to the default python 3 environment.\r\n\r\nPython 2 should only be used when necessitated by legacy codebases. Otherwise, we use Python 3.\r\n\r\nIf you need [rdkit](http://www.rdkit.org/) for chemoinformatics, you should follow the installation [instructions here](https://github.com/rdkit/conda-rdkit), which creates a dedicated rdkit environment with InChI support.\r\n\r\n## Usage\r\n\r\nWe recommend using Jupyter notebooks for most analyses. Launch jupyter by running `jupyter notebook` in the terminal. Dedicated .py files can be edited using the Jupyter text editor or [atom](https://atom.io/).\r\n\r\nFamiliarize yourself with the [PEP 0008](https://www.python.org/dev/peps/pep-0008/) style guide.\r\n\r\n## Local development\r\n\r\nWhen developing a package locally, run `pip install -e .` from the package's root directory. The package will then be importable from within your conda environment. The `-e` flag specifies editable mode and makes the package automatically update when you modify the source.\r\n\r\n## Packages\r\n\r\n+ [`pandas`](http://pandas.pydata.org/) for dataframes -- important functions include [`DataFrame.merge`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.merge.html), [`melt`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.melt.html), [`DataFrame.pivot_table`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.pivot_table.html), [`DataFrame.groupby`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html), [`pandas.read_table`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_table.html), [`DataFrame.to_csv(path, sep='\\t', index=False)`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_csv.html), [`pandas.isnull`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.isnull.html), and [`DataFrame.head`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.head.html). Be forewarned of [the horrors](http://pandas.pydata.org/pandas-docs/stable/gotchas.html#support-for-integer-na) of int to float conversion when missing values are present.\r\n\r\n+ [`seaborn`](https://web.stanford.edu/~mwaskom/software/seaborn/) for data visualization.\r\n\r\n+ [`numpy`](http://www.numpy.org/) for arrays and linear algebra.\r\n\r\n+ [`requests`](http://docs.python-requests.org/en/latest/) for http calls.\r\n\r\n+ [`sklearn`](http://scikit-learn.org/stable/) for machine learning and classification.\r\n\r\nFor example code, [check out](https://github.com/search?l=&o=desc&q=user%3Adhimmel+extension%3Aipynb&ref=advsearch&s=indexed&type=Code&utf8=%E2%9C%93) my notebooks.",
      "comment_id": 300,
      "profile_id": 17,
      "published": "2015-06-24T05:08:18.216459Z",
      "thread_id": 84,
      "url": "/discussion/python-for-the-modern-biodata-scientist/84"
    },
    {
      "body_html": "<p>Thank you. This is very helpful.</p>",
      "body_md": "Thank you. This is very helpful.",
      "comment_id": 301,
      "profile_id": 113,
      "published": "2015-06-25T04:17:27.147552Z",
      "thread_id": 84,
      "url": "/discussion/python-for-the-modern-biodata-scientist/84#2"
    },
    {
      "body_html": "<h1>Initial human pathway collection</h1>\r\n\r\n<p>We have downloaded, parsing, and combined MSigDB and WikiPathways (<a href=\"https://github.com/dhimmel/pathways/blob/5eb835b33629ffed4e22978e98a702e30ebd7076/merge-resources.ipynb\">notebook</a>, <a href=\"https://github.com/dhimmel/pathways/blob/5eb835b33629ffed4e22978e98a702e30ebd7076/data/pathways.tsv\">tsv results</a>). In total we identified, 1,516 human pathways after removing a single duplicated pathway. Most pathways have below 100 genes but some have up to 1,000.</p>\r\n\r\n<h2>WikiPathways Method</h2>\r\n\r\n<p>We extracted pathways from the previously-suggested <a href=\"http://www.pathvisio.org/data/bots/gmt/wikipathways.gmt\">dump file</a>. We removed pathways without any human genes. From a total of 669 wikipathways, 187 were human. <a href=\"/u/alexanderpico\" class=\"username\">@alexanderpico</a>, can you confirm that these are the expected numbers?</p>\r\n\r\n<p>Above I asked:</p>\r\n\r\n<blockquote><p>Additionally, are non-gene entities identified as free text, or are they structured by a standardized vocabulary?</p></blockquote>\r\n\r\n<p>It appears that other entities besides genes are unstandardized in WikiPathway models. Therefore, we chose to not connect pathways to diseases, drugs, and tissues.</p>\r\n\r\n<h2>MSigDB Method</h2>\r\n\r\n<p>We used the <em>C2: CP</em> collection from MSigDB 5.0 which yielded 1,330 pathways. The sources and counts of these pathways are below:</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>MsigDB ID</th><th>Name</th><th>Pathways</th></tr></thead><tbody><tr><td>REACTOME</td><td><a href=\"http://www.reactome.org/\">Reactome</a></td><td>674</td></tr><tr><td>BIOCARTA</td><td><a href=\"http://www.biocarta.com/\">BioCarta</a></td><td>217</td></tr><tr><td>PID</td><td><a href=\"http://pid.nci.nih.gov/\">Pathway Interaction Database</a></td><td>196</td></tr><tr><td>KEGG</td><td><a href=\"http://www.genome.jp/kegg/\">KEGG</a></td><td>186</td></tr><tr><td>ST</td><td><a href=\"http://stke.sciencemag.org/\">Signaling Transduction KE</a></td><td>28</td></tr><tr><td>SA</td><td><a href=\"http://www.sigmaaldrich.com/life-science.html\">SigmaAldrich</a></td><td>10</td></tr><tr><td>NABA</td><td><a href=\"http://matrisomeproject.mit.edu/\">Matrisome</a></td><td>10</td></tr><tr><td>SIG</td><td><a href=\"http://www.signaling-gateway.org/molecule/\">Signaling Gateway</a></td><td>8</td></tr><tr><td>WNT</td><td><a href=\"http://superarray.com/\">SuperArray</a></td><td>1</td></tr></tbody></table>",
      "body_md": "# Initial human pathway collection\r\n\r\nWe have downloaded, parsing, and combined MSigDB and WikiPathways ([notebook](https://github.com/dhimmel/pathways/blob/5eb835b33629ffed4e22978e98a702e30ebd7076/merge-resources.ipynb), [tsv results](https://github.com/dhimmel/pathways/blob/5eb835b33629ffed4e22978e98a702e30ebd7076/data/pathways.tsv)). In total we identified, 1,516 human pathways after removing a single duplicated pathway. Most pathways have below 100 genes but some have up to 1,000.\r\n\r\n## WikiPathways Method\r\n\r\nWe extracted pathways from the previously-suggested [dump file](http://www.pathvisio.org/data/bots/gmt/wikipathways.gmt). We removed pathways without any human genes. From a total of 669 wikipathways, 187 were human. @alexanderpico, can you confirm that these are the expected numbers?\r\n\r\nAbove I asked:\r\n\r\n> Additionally, are non-gene entities identified as free text, or are they structured by a standardized vocabulary?\r\n\r\nIt appears that other entities besides genes are unstandardized in WikiPathway models. Therefore, we chose to not connect pathways to diseases, drugs, and tissues.\r\n\r\n## MSigDB Method\r\n\r\nWe used the *C2: CP* collection from MSigDB 5.0 which yielded 1,330 pathways. The sources and counts of these pathways are below:\r\n\r\n| MsigDB ID | Name | Pathways |\r\n|---------------------|--------------------------------------|----------|\r\n| REACTOME | [Reactome](http://www.reactome.org/) | 674 |\r\n| BIOCARTA | [BioCarta](http://www.biocarta.com/) | 217 |\r\n| PID | [Pathway Interaction Database](http://pid.nci.nih.gov/) | 196 |\r\n| KEGG | [KEGG](http://www.genome.jp/kegg/) | 186 |\r\n| ST | [Signaling Transduction KE](http://stke.sciencemag.org/) | 28 |\r\n| SA | [SigmaAldrich](http://www.sigmaaldrich.com/life-science.html) | 10 |\r\n| NABA | [Matrisome](http://matrisomeproject.mit.edu/) | 10 |\r\n| SIG | [Signaling Gateway](http://www.signaling-gateway.org/molecule/) | 8 |\r\n| WNT | [SuperArray](http://superarray.com/) | 1 |",
      "comment_id": 302,
      "profile_id": 17,
      "published": "2015-06-26T21:40:14.598959Z",
      "thread_id": 72,
      "url": "/discussion/adding-pathway-resources-to-your-network/72#6"
    },
    {
      "body_html": "<blockquote><p>We extracted pathways from the previously-suggested dump file. We removed pathways without any human genes. From a total of 669 wikipathways, 187 were human. <a href=\"/u/alexanderpico\" class=\"username\">@alexanderpico</a>, can you confirm that these are the expected numbers?</p></blockquote>\r\n\r\n<p>Hmm... You are correct that the dump file contains 187 human pathways (just did a browser FIND on the page for 'homo sapiens'), but there are ~293 human pathways in the standard collection. You can access these on the <a href=\"http://wikipathways.org/index.php/Download_Pathways\">bulk download page</a> in multiple formats, including plain text lists of (non-unified) datanode identifiers.  This number is climbing as folks continue to add new content. For example, we have over 300 additional human pathways that are in the works at various stages of completion (or disrepair) that are not included in these bulk downloads.</p>\r\n\r\n<p>Sorry for suggesting the dump file. I thought that would make it easier since the identifiers are unified to Entrez, but it's apparently incomplete. I'm not sure why...</p>",
      "body_md": "> We extracted pathways from the previously-suggested dump file. We removed pathways without any human genes. From a total of 669 wikipathways, 187 were human. @alexanderpico, can you confirm that these are the expected numbers?\r\n\r\nHmm... You are correct that the dump file contains 187 human pathways (just did a browser FIND on the page for 'homo sapiens'), but there are ~293 human pathways in the standard collection. You can access these on the [bulk download page](http://wikipathways.org/index.php/Download_Pathways) in multiple formats, including plain text lists of (non-unified) datanode identifiers.  This number is climbing as folks continue to add new content. For example, we have over 300 additional human pathways that are in the works at various stages of completion (or disrepair) that are not included in these bulk downloads.\r\n\r\nSorry for suggesting the dump file. I thought that would make it easier since the identifiers are unified to Entrez, but it's apparently incomplete. I'm not sure why...\r\n",
      "comment_id": 303,
      "profile_id": 104,
      "published": "2015-06-27T17:57:03.429585Z",
      "thread_id": 72,
      "url": "/discussion/adding-pathway-resources-to-your-network/72#7"
    },
    {
      "body_html": "<p>The WikiPathways team found the error, corrected it and updated the dump file, which now contains 290 human pathways with gene identifiers unified to Entrez. Same location: <a href=\"http://www.pathvisio.org/data/bots/gmt/wikipathways.gmt\">http://www.pathvisio.org/data/bots/gmt/wikipathways.gmt</a></p>",
      "body_md": "The WikiPathways team found the error, corrected it and updated the dump file, which now contains 290 human pathways with gene identifiers unified to Entrez. Same location: http://www.pathvisio.org/data/bots/gmt/wikipathways.gmt\r\n\r\n",
      "comment_id": 304,
      "profile_id": 104,
      "published": "2015-06-29T01:34:02.291021Z",
      "thread_id": 72,
      "url": "/discussion/adding-pathway-resources-to-your-network/72#8"
    },
    {
      "body_html": "<h1>Human pathway collection revision</h1>\r\n\r\n<p>We updated our pathway resource with the updated WikiPathways data (<a href=\"https://github.com/dhimmel/pathways/blob/032036f91a8395eabd0dab2d9d1ee3252ba140f8/merge-resources.ipynb\">notebook</a>, <a href=\"https://github.com/dhimmel/pathways/blob/032036f91a8395eabd0dab2d9d1ee3252ba140f8/data/pathways.tsv\">tsv results</a>). The new total for human pathways is 1,619 with 289 of those from WikiPathways.</p>",
      "body_md": "# Human pathway collection revision\r\n\r\nWe updated our pathway resource with the updated WikiPathways data ([notebook](https://github.com/dhimmel/pathways/blob/032036f91a8395eabd0dab2d9d1ee3252ba140f8/merge-resources.ipynb), [tsv results](https://github.com/dhimmel/pathways/blob/032036f91a8395eabd0dab2d9d1ee3252ba140f8/data/pathways.tsv)). The new total for human pathways is 1,619 with 289 of those from WikiPathways.",
      "comment_id": 305,
      "profile_id": 17,
      "published": "2015-06-29T17:19:07.142553Z",
      "thread_id": 72,
      "url": "/discussion/adding-pathway-resources-to-your-network/72#9"
    },
    {
      "body_html": "<p><a href=\"/u/fbastian\" class=\"username\">@fbastian</a> and Anne Niknejad.</p>\r\n\r\n<p>On June 17th I emailed <code>gtex-help@broadinstitute.org</code> asking for a GTEX–Uberon mapping. Today, Tim Sullivan responded and attached <a href=\"https://github.com/dhimmel/gtex/blob/30096fb519efba939eeb0c5681ba20ad8d43660a/download/GTEx_Uberon_Terms.xlsx\">this mapping file</a>.</p>\r\n\r\n<p>He didn't mention the methodology used, but you may want to crosscheck your work.</p>\r\n\r\n<p>I've reproduced Tim's mapping below for quick reference:</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>Tissue Site Detail</th><th>Uberon Code</th><th>Uberon Term</th></tr></thead><tbody><tr><td>Adipose - Subcutaneous</td><td>0002190</td><td>subcutaneous adipose tissue</td></tr><tr><td>Adipose - Visceral (Omentum)</td><td>0010414</td><td>omental fat pad</td></tr><tr><td>Adrenal Gland</td><td>0002369</td><td>adrenal gland</td></tr><tr><td>Artery - Aorta</td><td>0001496</td><td>ascending aorta</td></tr><tr><td>Artery - Coronary</td><td>0001621</td><td>coronary artery</td></tr><tr><td>Artery - Tibial</td><td>0001323</td><td>tibial nerve</td></tr><tr><td>Artery - Tibial</td><td>0007610</td><td>tibial artery</td></tr><tr><td>Bladder</td><td>0001255</td><td>urinary bladder</td></tr><tr><td>Brain - Amygdala</td><td>0001876</td><td>amygdala</td></tr><tr><td>Brain - Anterior cingulate cortex (BA24)</td><td>0009835</td><td>anterior cingulate cortex</td></tr><tr><td>Brain - Caudate (basal ganglia)</td><td>0001873</td><td>caudate nucleus</td></tr><tr><td>Brain - Cerebellar Hemisphere</td><td>0002037</td><td>cerebellum</td></tr><tr><td>Brain - Cerebellum</td><td>0002037</td><td>cerebellum</td></tr><tr><td>Brain - Cortex</td><td>0001870</td><td>frontal cortex</td></tr><tr><td>Brain - Frontal Cortex (BA9)</td><td>0009834</td><td>dorsolateral prefrontal cortex</td></tr><tr><td>Brain - Hippocampus</td><td>0001954</td><td>Ammon's horn</td></tr><tr><td>Brain - Hypothalamus</td><td>0001898</td><td>hypothalamus</td></tr><tr><td>Brain - Nucleus accumbens (basal ganglia)</td><td>0001882</td><td>nucleus accumbens</td></tr><tr><td>Brain - Putamen (basal ganglia)</td><td>0001874</td><td>putamen</td></tr><tr><td>Brain - Spinal cord (cervical c-1)</td><td>0006469</td><td>first cervical spinal cord segment</td></tr><tr><td>Brain - Substantia nigra</td><td>0002038</td><td>substantia nigra</td></tr><tr><td>Breast - Mammary Tissue</td><td>0008367</td><td>breast epithelium</td></tr><tr><td>Cells - EBV-transformed lymphocytes</td><td>EFO_0000572</td><td>lymphoblast</td></tr><tr><td>Cells - Leukemia cell line (CML)</td><td>EFO_0002067</td><td>K562</td></tr><tr><td>Cells - Transformed fibroblasts</td><td>EFO_0000496</td><td>fibroblast</td></tr><tr><td>Cervix - Ectocervix</td><td>0012249</td><td>ectocervix</td></tr><tr><td>Cervix - Endocervix</td><td>0000458</td><td>endocervix</td></tr><tr><td>Colon - Sigmoid</td><td>0001159</td><td>sigmoid colon</td></tr><tr><td>Colon - Transverse</td><td>0001157</td><td>transverse colon</td></tr><tr><td>Esophagus - Gastroesophageal Junction</td><td>0004550</td><td>gastroesophageal sphincter</td></tr><tr><td>Esophagus - Mucosa</td><td>0006920</td><td>esophagus squamous epithelium</td></tr><tr><td>Esophagus - Muscularis</td><td>0004648</td><td>esophagus muscularis mucosa</td></tr><tr><td>Fallopian Tube</td><td>0003889</td><td>fallopian tube</td></tr><tr><td>Heart - Atrial Appendage</td><td>0006631</td><td>right atrium auricular region</td></tr><tr><td>Heart - Left Ventricle</td><td>0006566</td><td>left ventricle myocardium</td></tr><tr><td>Kidney - Cortex</td><td>0001225</td><td>cortex of kidney</td></tr><tr><td>Liver</td><td>0001114</td><td>right lobe of liver</td></tr><tr><td>Lung</td><td>0008952</td><td>upper lobe of left lung</td></tr><tr><td>Minor Salivary Gland</td><td>0006330</td><td>anterior lingual gland</td></tr><tr><td>Muscle - Skeletal</td><td>0011907</td><td>gastrocnemius medialis</td></tr><tr><td>Nerve - Tibial</td><td>0001323</td><td>tibial nerve</td></tr><tr><td>Nerve - Tibial</td><td>0007610</td><td>tibial artery</td></tr><tr><td>Ovary</td><td>0002119</td><td>left ovary</td></tr><tr><td>Pancreas</td><td>0001150</td><td>body of pancreas</td></tr><tr><td>Pituitary</td><td>0000007</td><td>pituitary gland</td></tr><tr><td>Prostate</td><td>0002367</td><td>prostate gland</td></tr><tr><td>Skin - Not Sun Exposed (Suprapubic)</td><td>0001416</td><td>skin of abdomen</td></tr><tr><td>Skin - Sun Exposed (Lower leg)</td><td>0001511</td><td>skin of leg</td></tr><tr><td>Small Intestine - Terminal Ileum</td><td>0001211</td><td>Peyer's patch</td></tr><tr><td>Spleen</td><td>0002106</td><td>spleen</td></tr><tr><td>Stomach</td><td>0000945</td><td>stomach</td></tr><tr><td>Testis</td><td>0000473</td><td>testis</td></tr><tr><td>Thyroid</td><td>0002046</td><td>thyroid gland</td></tr><tr><td>Uterus</td><td>0000995</td><td>uterus</td></tr><tr><td>Vagina</td><td>0000996</td><td>vagina</td></tr><tr><td>Whole Blood</td><td>0013756</td><td>venous blood</td></tr></tbody></table>",
      "body_md": "@fbastian and Anne Niknejad.\r\n\r\nOn June 17th I emailed `gtex-help@broadinstitute.org` asking for a GTEX--Uberon mapping. Today, Tim Sullivan responded and attached [this mapping file](https://github.com/dhimmel/gtex/blob/30096fb519efba939eeb0c5681ba20ad8d43660a/download/GTEx_Uberon_Terms.xlsx).\r\n\r\nHe didn't mention the methodology used, but you may want to crosscheck your work.\r\n\r\nI've reproduced Tim's mapping below for quick reference:\r\n\r\n| Tissue Site Detail | Uberon Code | Uberon Term |\r\n|-------------------------------------------|-------------|------------------------------------|\r\n| Adipose - Subcutaneous | 0002190 | subcutaneous adipose tissue |\r\n| Adipose - Visceral (Omentum) | 0010414 | omental fat pad |\r\n| Adrenal Gland | 0002369 | adrenal gland |\r\n| Artery - Aorta | 0001496 | ascending aorta |\r\n| Artery - Coronary | 0001621 | coronary artery |\r\n| Artery - Tibial | 0001323 | tibial nerve |\r\n| Artery - Tibial | 0007610 | tibial artery |\r\n| Bladder | 0001255 | urinary bladder |\r\n| Brain - Amygdala | 0001876 | amygdala |\r\n| Brain - Anterior cingulate cortex (BA24) | 0009835 | anterior cingulate cortex |\r\n| Brain - Caudate (basal ganglia) | 0001873 | caudate nucleus |\r\n| Brain - Cerebellar Hemisphere | 0002037 | cerebellum |\r\n| Brain - Cerebellum | 0002037 | cerebellum |\r\n| Brain - Cortex | 0001870 | frontal cortex |\r\n| Brain - Frontal Cortex (BA9) | 0009834 | dorsolateral prefrontal cortex |\r\n| Brain - Hippocampus | 0001954 | Ammon's horn |\r\n| Brain - Hypothalamus | 0001898 | hypothalamus |\r\n| Brain - Nucleus accumbens (basal ganglia) | 0001882 | nucleus accumbens |\r\n| Brain - Putamen (basal ganglia) | 0001874 | putamen |\r\n| Brain - Spinal cord (cervical c-1) | 0006469 | first cervical spinal cord segment |\r\n| Brain - Substantia nigra | 0002038 | substantia nigra |\r\n| Breast - Mammary Tissue | 0008367 | breast epithelium |\r\n| Cells - EBV-transformed lymphocytes | EFO_0000572 | lymphoblast |\r\n| Cells - Leukemia cell line (CML) | EFO_0002067 | K562 |\r\n| Cells - Transformed fibroblasts | EFO_0000496 | fibroblast |\r\n| Cervix - Ectocervix | 0012249 | ectocervix |\r\n| Cervix - Endocervix | 0000458 | endocervix |\r\n| Colon - Sigmoid | 0001159 | sigmoid colon |\r\n| Colon - Transverse | 0001157 | transverse colon |\r\n| Esophagus - Gastroesophageal Junction | 0004550 | gastroesophageal sphincter |\r\n| Esophagus - Mucosa | 0006920 | esophagus squamous epithelium |\r\n| Esophagus - Muscularis | 0004648 | esophagus muscularis mucosa |\r\n| Fallopian Tube | 0003889 | fallopian tube |\r\n| Heart - Atrial Appendage | 0006631 | right atrium auricular region |\r\n| Heart - Left Ventricle | 0006566 | left ventricle myocardium |\r\n| Kidney - Cortex | 0001225 | cortex of kidney |\r\n| Liver | 0001114 | right lobe of liver |\r\n| Lung | 0008952 | upper lobe of left lung |\r\n| Minor Salivary Gland | 0006330 | anterior lingual gland |\r\n| Muscle - Skeletal | 0011907 | gastrocnemius medialis |\r\n| Nerve - Tibial | 0001323 | tibial nerve |\r\n| Nerve - Tibial | 0007610 | tibial artery |\r\n| Ovary | 0002119 | left ovary |\r\n| Pancreas | 0001150 | body of pancreas |\r\n| Pituitary | 0000007 | pituitary gland |\r\n| Prostate | 0002367 | prostate gland |\r\n| Skin - Not Sun Exposed (Suprapubic) | 0001416 | skin of abdomen |\r\n| Skin - Sun Exposed (Lower leg) | 0001511 | skin of leg |\r\n| Small Intestine - Terminal Ileum | 0001211 | Peyer's patch |\r\n| Spleen | 0002106 | spleen |\r\n| Stomach | 0000945 | stomach |\r\n| Testis | 0000473 | testis |\r\n| Thyroid | 0002046 | thyroid gland |\r\n| Uterus | 0000995 | uterus |\r\n| Vagina | 0000996 | vagina |\r\n| Whole Blood | 0013756 | venous blood |",
      "comment_id": 306,
      "profile_id": 17,
      "published": "2015-06-30T19:15:05.994937Z",
      "thread_id": 82,
      "url": "/discussion/processing-gtex-for-tissue-specific-gene-expression/82#12"
    },
    {
      "body_html": "<p>This is very helpful and something I can use to improve my python workflow. </p>",
      "body_md": "This is very helpful and something I can use to improve my python workflow. ",
      "comment_id": 307,
      "profile_id": 35,
      "published": "2015-06-30T20:00:13.809016Z",
      "thread_id": 84,
      "url": "/discussion/python-for-the-modern-biodata-scientist/84#3"
    },
    {
      "body_html": "<p>Some seem slightly more specific than the label suggests - sometimes the increased specificity is trivial (ie their ovary sample was from a left ovary), sometimes relevant (their representative skeletal muscle sample was from gastrocnemius medialis, the esophagus mucosa sample was taken from the epithelium rather than lamina propria).</p>",
      "body_md": "Some seem slightly more specific than the label suggests - sometimes the increased specificity is trivial (ie their ovary sample was from a left ovary), sometimes relevant (their representative skeletal muscle sample was from gastrocnemius medialis, the esophagus mucosa sample was taken from the epithelium rather than lamina propria).",
      "comment_id": 308,
      "profile_id": 109,
      "published": "2015-07-01T14:32:41.223751Z",
      "thread_id": 82,
      "url": "/discussion/processing-gtex-for-tissue-specific-gene-expression/82#13"
    },
    {
      "body_html": "<p>We would like to create a catalog of interactions between proteins (PPIs). I am currently leaning towards focusing on physical interactions, since other types of interactions will be captured by other metanodes and metaedges. If some non-physical interactions are included that is acceptable but not the goal.</p>\r\n\r\n<p>Some previous studies have compiled PPI catalogs:</p>\r\n\r\n<ul><li><p>the Incomplete Interactome (II) <span class=\"citation\">[<a href=\"https://doi.org/10.1126/science.1257601\" class=\"citation\" data-key=\"10.1126/science.1257601\">1</a>]</span> — compiled protein interactions of seven types</p></li><li><p>the Human Interaction Database (<a href=\"http://interactome.dfci.harvard.edu/H_sapiens/index.php?page=download\">HID</a>) <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.cell.2014.10.050\" class=\"citation\" data-key=\"10.1016/j.cell.2014.10.050\">2</a>]</span> — systematic experimental approach for identifying PPIs</p></li><li><p>our disease-gene association study (<a href=\"http://het.io/disease-genes/downloads/\">hetio</a>) <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1004259\">3</a>]</span> — interactions from <a href=\"http://irefindex.org/wiki/index.php?title=iRefIndex\">iRefIndex</a>, which compiles records from primary databases, processed using <a href=\"http://www.ncbi.nlm.nih.gov/CBBresearch/Yu/downloads/ppiTrim.html\">ppiTrim</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/database/bar036\" class=\"citation\" data-key=\"10.1093/database/bar036\">4</a>]</span>.</p></li></ul>\r\n\r\n<p>Suggestions for other resources are welcome.</p>",
      "body_md": "We would like to create a catalog of interactions between proteins (PPIs). I am currently leaning towards focusing on physical interactions, since other types of interactions will be captured by other metanodes and metaedges. If some non-physical interactions are included that is acceptable but not the goal.\r\n\r\nSome previous studies have compiled PPI catalogs:\r\n\r\n+ the Incomplete Interactome (II) [@10.1126/science.1257601] --- compiled protein interactions of seven types\r\n\r\n+ the Human Interaction Database ([HID](http://interactome.dfci.harvard.edu/H_sapiens/index.php?page=download)) [@10.1016/j.cell.2014.10.050] --- systematic experimental approach for identifying PPIs\r\n\r\n+ our disease-gene association study ([hetio](http://het.io/disease-genes/downloads/)) [@10.1371/journal.pcbi.1004259] -- interactions from [iRefIndex](http://irefindex.org/wiki/index.php?title=iRefIndex), which compiles records from primary databases, processed using [ppiTrim](http://www.ncbi.nlm.nih.gov/CBBresearch/Yu/downloads/ppiTrim.html) [@10.1093/database/bar036].\r\n\r\nSuggestions for other resources are welcome.",
      "comment_id": 309,
      "profile_id": 17,
      "published": "2015-07-02T00:44:39.854416Z",
      "thread_id": 85,
      "url": "/discussion/creating-a-catalog-of-protein-interactions/85"
    },
    {
      "body_html": "<h1>Methods for the <em>Incomplete Interactome</em> PPI catalog</h1>\r\n\r\n<p><em>Here, we reproduce the methods section from the <a href=\"http://www.sciencemag.org/content/suppl/2015/02/18/347.6224.1257601.DC1/Menche_SM.pdf\">supplement</a> of the Incomplete Interactome publication <span class=\"citation\">[<a href=\"https://doi.org/10.1126/science.1257601\" class=\"citation\" data-key=\"10.1126/science.1257601\">1</a>]</span> describing how their PPI catalog was constructed:</em></p>\r\n\r\n<p>In building the interactome, we rely only physical protein interactions with experimental support, hence we do not include interactions extracted from gene expression data or evolutionary considerations. In order to obtain an interactome as complete as currently feasible, we combine several databases with various kinds of physical interactions:</p>\r\n\r\n<ol><li><strong>Regulatory interactions</strong>: We use the TRANSFAC database <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkg108\" class=\"citation\" data-key=\"10.1093/nar/gkg108\">2</a>]</span> that lists interactions derived from the presence of a transcription factor binding site in the promoter region of a certain gene. The resulting network consists of 271 transcription factors regulating 564 genes via 1,335 interactions.</li><li><strong>Binary interactions</strong>: We combine several yeast-two-hybrid high-throughput datasets <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.cell.2014.10.050\" class=\"citation\" data-key=\"10.1016/j.cell.2014.10.050\">3</a>, <a href=\"https://doi.org/10.1038/nmeth.1280\" class=\"citation\" data-key=\"10.1038/nmeth.1280\">4</a>, <a href=\"https://doi.org/10.1016/j.cell.2005.08.029\" class=\"citation\" data-key=\"10.1016/j.cell.2005.08.029\">5</a>, <a href=\"https://doi.org/10.1038/nmeth.1597\" class=\"citation\" data-key=\"10.1038/nmeth.1597\">6</a>, <a href=\"https://doi.org/10.1038/nature04209\" class=\"citation\" data-key=\"10.1038/nature04209\">7</a>, <a href=\"\" class=\"citation\" data-key=\"55\">8</a>]</span> with binary interactions from IntAct <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkp878\" class=\"citation\" data-key=\"10.1093/nar/gkp878\">9</a>]</span> and MINT databases <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkp983\" class=\"citation\" data-key=\"10.1093/nar/gkp983\">10</a>]</span>. The sum of these data sources yields 28,653 interactions between 8,120 proteins. Note that IntAct and MINT provide interactions derived from both literature curation and direct submissions. </li><li><strong>Literature curated interactions</strong>: These interactions, typically obtained by low throughput experiments, are manually curated from the literature. We use IntAct <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkp878\" class=\"citation\" data-key=\"10.1093/nar/gkp878\">9</a>]</span>, MINT <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkp983\" class=\"citation\" data-key=\"10.1093/nar/gkp983\">10</a>]</span>, BioGRID <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkq1116\" class=\"citation\" data-key=\"10.1093/nar/gkq1116\">11</a>]</span> and HPRD <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkn892\" class=\"citation\" data-key=\"10.1093/nar/gkn892\">12</a>]</span>, resulting in 88,349 interactions between 11,798 proteins.</li><li><strong>Metabolic enzyme-coupled interactions</strong>: Two enzymes are assumed to be coupled if they share adjacent reactions in the KEGG and BIGG databases. In total, we use 5,325 such metabolic links between 921 enzymes from <span class=\"citation\">[<a href=\"https://doi.org/10.1073/pnas.0802208105\" class=\"citation\" data-key=\"10.1073/pnas.0802208105\">13</a>]</span>.</li><li><strong>Protein complexes</strong>: Protein complexes are single molecular units that integrate multiple gene products. The CORUM database <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkp914\" class=\"citation\" data-key=\"10.1093/nar/gkp914\">14</a>]</span> is a collection of mammalian complexes derived from a variety of experimental tools, from co-immunoprecipitation to co-sedimentation and ion exchange chromatography. In total, CORUM yields 2,837 complexes with 2,069 proteins connected by 31,276 links.</li><li><strong>Kinase network (kinase-substrate pairs)</strong>: Protein kinases are important regulators in different biological processes, such as signal transduction. PhosphositePlus <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkr1122\" class=\"citation\" data-key=\"10.1093/nar/gkr1122\">15</a>]</span> provides a network of peptides that can be bound by kinases, yielding in total 6,066 interactions between 1,843 proteins.</li><li><strong>Signaling interactions</strong>: The dataset from <span class=\"citation\">[<a href=\"https://doi.org/10.1126/scisignal.2001699\" class=\"citation\" data-key=\"10.1126/scisignal.2001699\">16</a>]</span> provides 32,706 interactions between 6,339 proteins that integrate several sources, both high-throughput and literature curation, into a directed network in which cellular signals are transmitted by proteins-protein interactions.</li></ol>\r\n\r\n<p>The union of all interactions obtained from (i)-(vii) yields a network of 13,460 proteins that are interconnected by 141,296 physical interactions. Note that we treat the interactome as an undirected network (see Section 2.3 for a discussion of the impact of directionality). The interactome is approximately scale-free (Figure S1a) and shows other typical characteristics as observed previously in many other biological networks <span class=\"citation\">[<a href=\"https://doi.org/10.1103/RevModPhys.74.47\" class=\"citation\" data-key=\"10.1103/RevModPhys.74.47\">17</a>, <a href=\"https://doi.org/10.1137/S003614450342480\" class=\"citation\" data-key=\"10.1137/S003614450342480\">18</a>]</span>, such as high clustering and short pathlengths (Figure S1c)</p>\r\n\r\n<p></p>",
      "body_md": "# Methods for the *Incomplete Interactome* PPI catalog\r\n\r\n*Here, we reproduce the methods section from the [supplement](http://www.sciencemag.org/content/suppl/2015/02/18/347.6224.1257601.DC1/Menche_SM.pdf) of the Incomplete Interactome publication [@10.1126/science.1257601] describing how their PPI catalog was constructed:*\r\n\r\nIn building the interactome, we rely only physical protein interactions with experimental support, hence we do not include interactions extracted from gene expression data or evolutionary considerations. In order to obtain an interactome as complete as currently feasible, we combine several databases with various kinds of physical interactions:\r\n\r\n1. **Regulatory interactions**: We use the TRANSFAC database [@10.1093/nar/gkg108] that lists interactions derived from the presence of a transcription factor binding site in the promoter region of a certain gene. The resulting network consists of 271 transcription factors regulating 564 genes via 1,335 interactions.\r\n+ **Binary interactions**: We combine several yeast-two-hybrid high-throughput datasets [@10.1016/j.cell.2014.10.050 @10.1038/nmeth.1280 @10.1016/j.cell.2005.08.029 @10.1038/nmeth.1597 @10.1038/nature04209 @55] with binary interactions from IntAct [@10.1093/nar/gkp878] and MINT databases [@10.1093/nar/gkp983]. The sum of these data sources yields 28,653 interactions between 8,120 proteins. Note that IntAct and MINT provide interactions derived from both literature curation and direct submissions. \r\n+ **Literature curated interactions**: These interactions, typically obtained by low throughput experiments, are manually curated from the literature. We use IntAct [@10.1093/nar/gkp878], MINT [@10.1093/nar/gkp983], BioGRID [@10.1093/nar/gkq1116] and HPRD [@10.1093/nar/gkn892], resulting in 88,349 interactions between 11,798 proteins.\r\n+ **Metabolic enzyme-coupled interactions**: Two enzymes are assumed to be coupled if they share adjacent reactions in the KEGG and BIGG databases. In total, we use 5,325 such metabolic links between 921 enzymes from [@10.1073/pnas.0802208105].\r\n+ **Protein complexes**: Protein complexes are single molecular units that integrate multiple gene products. The CORUM database [@10.1093/nar/gkp914] is a collection of mammalian complexes derived from a variety of experimental tools, from co-immunoprecipitation to co-sedimentation and ion exchange chromatography. In total, CORUM yields 2,837 complexes with 2,069 proteins connected by 31,276 links.\r\n+ **Kinase network (kinase-substrate pairs)**: Protein kinases are important regulators in different biological processes, such as signal transduction. PhosphositePlus [@10.1093/nar/gkr1122] provides a network of peptides that can be bound by kinases, yielding in total 6,066 interactions between 1,843 proteins.\r\n+ **Signaling interactions**: The dataset from [@10.1126/scisignal.2001699] provides 32,706 interactions between 6,339 proteins that integrate several sources, both high-throughput and literature curation, into a directed network in which cellular signals are transmitted by proteins-protein interactions.\r\n\r\nThe union of all interactions obtained from (i)-(vii) yields a network of 13,460 proteins that are interconnected by 141,296 physical interactions. Note that we treat the interactome as an undirected network (see Section 2.3 for a discussion of the impact of directionality). The interactome is approximately scale-free (Figure S1a) and shows other typical characteristics as observed previously in many other biological networks [@10.1103/RevModPhys.74.47 @10.1137/S003614450342480], such as high clustering and short pathlengths (Figure S1c)\r\n\r\n[@55]: \"Center for Cancer Systems Biology, Hi-2012 prepublication\"",
      "comment_id": 310,
      "profile_id": 17,
      "published": "2015-07-02T00:47:21.811599Z",
      "thread_id": 85,
      "url": "/discussion/creating-a-catalog-of-protein-interactions/85#2"
    },
    {
      "body_html": "<h1>GWAS associations for all DO diseases</h1>\r\n\r\n<p>We repeated the above analysis for all diseases, not just DO slim diseases. The EFO terms added to the GWAS Catalog by the EBI are still converted to DO terms: therefore, associations whose EFO terms are not cross-referenced in the DO are omitted.</p>\r\n\r\n<p>In total, the dataset contains 1447 high-confidence primary gene-disease associations. Counting both confidence levels, associations exist for 124 diseases and 4142 genes.</p>\r\n\r\n<p>Download the <a href=\"https://github.com/dhimmel/gwas-catalog/blob/a5aa4910708a3995501ebe4136d8b9d601463fa1/data/gene-associations.tsv\">compiled gene associations</a> or see the <a href=\"https://github.com/dhimmel/gwas-catalog/tree/a5aa4910708a3995501ebe4136d8b9d601463fa1\">repository</a> for more information.</p>",
      "body_md": "# GWAS associations for all DO diseases\r\n\r\nWe repeated the above analysis for all diseases, not just DO slim diseases. The EFO terms added to the GWAS Catalog by the EBI are still converted to DO terms: therefore, associations whose EFO terms are not cross-referenced in the DO are omitted.\r\n\r\nIn total, the dataset contains 1447 high-confidence primary gene-disease associations. Counting both confidence levels, associations exist for 124 diseases and 4142 genes.\r\n\r\nDownload the [compiled gene associations](https://github.com/dhimmel/gwas-catalog/blob/a5aa4910708a3995501ebe4136d8b9d601463fa1/data/gene-associations.tsv) or see the [repository](https://github.com/dhimmel/gwas-catalog/tree/a5aa4910708a3995501ebe4136d8b9d601463fa1) for more information.",
      "comment_id": 313,
      "profile_id": 17,
      "published": "2015-07-09T20:59:26.433170Z",
      "thread_id": 80,
      "url": "/discussion/extracting-disease-gene-associations-from-the-gwas-catalog/80#2"
    },
    {
      "body_html": "<p>Last week a seminal paper on tissue-specificity of the transciptome, proteome, knowledgeome, and literome was published <span class=\"citation\">[<a href=\"https://doi.org/10.7717/peerj.1054\" class=\"citation\" data-key=\"10.7717/peerj.1054\">1</a>]</span>, along with an <a href=\"http://tissues.jensenlab.org/\">accompanying webapp</a>. This study is notable for intelligently merging expression studies and performing informative comparisons between studies and data types.</p>\r\n\r\n<p>We have already <a href=\"http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#8\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d81\">processed Bgee</a> for anatomy-specific transcription. Compared to Bgee, the anatomical coverage of TISSUES is much lower, but edges are likely of higher quality. Therefore I think Bgee and TISSUES will be complimentary. Additionally, TISSUES contains other measures of tissue-specific gene expression such as UniProtKB, proteomics, and literature mining. We are particularly interested in including these data sources.</p>\r\n\r\n<p>Our first step is to retrieve the data for each of the four methods. We want entities encoded using identifiers rather than names or symbols. We will need to pick a confidence threshold. And for each method, we would like the broadest tissue coverage permitted by that method. Advice appreciated!</p>",
      "body_md": "Last week a seminal paper on tissue-specificity of the transciptome, proteome, knowledgeome, and literome was published [@10.7717/peerj.1054], along with an [accompanying webapp](http://tissues.jensenlab.org/). This study is notable for intelligently merging expression studies and performing informative comparisons between studies and data types.\r\n\r\nWe have already [processed Bgee](http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#8) for anatomy-specific transcription. Compared to Bgee, the anatomical coverage of TISSUES is much lower, but edges are likely of higher quality. Therefore I think Bgee and TISSUES will be complimentary. Additionally, TISSUES contains other measures of tissue-specific gene expression such as UniProtKB, proteomics, and literature mining. We are particularly interested in including these data sources.\r\n\r\nOur first step is to retrieve the data for each of the four methods. We want entities encoded using identifiers rather than names or symbols. We will need to pick a confidence threshold. And for each method, we would like the broadest tissue coverage permitted by that method. Advice appreciated!",
      "comment_id": 318,
      "profile_id": 17,
      "published": "2015-07-10T18:15:03.724833Z",
      "thread_id": 91,
      "url": "/discussion/the-tissues-resource-for-the-tissue-specificity-of-genes/91"
    },
    {
      "body_html": "<h1>SciPy 2015</h1>\r\n\r\n<p>Some incredible presentations and materials are being unleashed at the <a href=\"http://scipy2015.scipy.org/\">SciPy 2015 conference</a> as I type. The full <a href=\"https://www.youtube.com/playlist?list=PLYx7XA2nY5Gcpabmu61kKcToLz0FapmHu\">playlist of presentations</a> is on YouTube.</p>\r\n\r\n<p>One excellent presentation is <em>State of the Stack</em> (<a href=\"https://youtu.be/5GlNDD7qbP4\">video</a>, <a href=\"https://speakerdeck.com/jakevdp/the-state-of-the-stack-scipy-2015-keynote\">slides</a>) by Jake Vanderplas, which details the latest developments in python tools for data science.</p>\r\n\r\n<p>Some additional projects of interest are:</p>\r\n\r\n<ul><li><a href=\"https://youtu.be/X0pAhJgySxk\">xray</a></li><li><a href=\"https://youtu.be/iMPfLz6kKv8\">beaker notebook</a></li></ul>",
      "body_md": "# SciPy 2015\r\n\r\nSome incredible presentations and materials are being unleashed at the [SciPy 2015 conference](http://scipy2015.scipy.org/) as I type. The full [playlist of presentations](https://www.youtube.com/playlist?list=PLYx7XA2nY5Gcpabmu61kKcToLz0FapmHu) is on YouTube.\r\n\r\nOne excellent presentation is *State of the Stack* ([video](https://youtu.be/5GlNDD7qbP4), [slides](https://speakerdeck.com/jakevdp/the-state-of-the-stack-scipy-2015-keynote)) by Jake Vanderplas, which details the latest developments in python tools for data science.\r\n\r\nSome additional projects of interest are:\r\n\r\n+ [xray](https://youtu.be/X0pAhJgySxk)\r\n+ [beaker notebook](https://youtu.be/iMPfLz6kKv8)",
      "comment_id": 319,
      "profile_id": 17,
      "published": "2015-07-10T19:06:19.048687Z",
      "thread_id": 84,
      "url": "/discussion/python-for-the-modern-biodata-scientist/84#4"
    },
    {
      "body_html": "<h1>Human Interaction Database</h1>\r\n\r\n<p>The Human Interaction Database (HID) 2014 <a href=\"http://interactome.dfci.harvard.edu/H_sapiens/index.php?page=download\">release</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.cell.2014.10.050\" class=\"citation\" data-key=\"10.1016/j.cell.2014.10.050\">1</a>]</span> contained two PPI datasets:</p>\r\n\r\n<ul><li><code>HI-II-14</code> — 13,944 interactions — proteome-scale map of the human binary interactome network generated by systematically screening Space-II</li><li><code>Lit-BM-13</code> — 11,045 interactions — high-quality recurated literature binary interactions extracted from 7 public repository in 2013</li></ul>\r\n\r\n<p>We <a href=\"https://github.com/dhimmel/ppi/blob/77862798448c4272c55e9c718323a3ec5d8db571/compile-PPIs.ipynb\">compared</a> interactions from HID to interactions from the Incomplete Interactome (II). We found that <code>HI-II-14</code> was a subset of <code>II_binary</code>. However, only 78.2% of <code>Lit-BM-13</code> was included in <code>II_literature</code>.</p>\r\n\r\n<p><em>To better understand <code>Lit-BM-13</code>, we have added the relevant sections of the paper <a href=\"http://www.sciencedirect.com/science/MiamiMultiMediaURL/1-s2.0-S0092867414014226/1-s2.0-S0092867414014226-mmc1.pdf/272196/html/S0092867414014226/2b892ecda8f249667d75023be6d13c7b/mmc1.pdf\">supplement</a> below, omitting the \"assignment of experimental method\" sections <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.cell.2014.10.050\" class=\"citation\" data-key=\"10.1016/j.cell.2014.10.050\">1</a>]</span>:</em></p>\r\n\r\n<p><strong>Literature datasets:</strong> We generated two datasets from literature-curated protein-protein interactions. A first dataset was generated in 2010 and used for all experiments, concomitantly with our mapping experiment, and a second dataset was extracted in 2013 to provide an updated version for all computational analyses.</p>\r\n\r\n<p><strong>Obtaining the Lit-2010 dataset:</strong> The Lit-2010 dataset extracts human protein-protein interactions (PPIs), annotated through December 2010, from seven primary source databases: BIND <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkg056\" class=\"citation\" data-key=\"10.1093/nar/gkg056\">2</a>]</span>, BioGRID <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gks1158\" class=\"citation\" data-key=\"10.1093/nar/gks1158\">3</a>]</span>, DIP <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkh086\" class=\"citation\" data-key=\"10.1093/nar/gkh086\">4</a>]</span>, HPRD <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkn892\" class=\"citation\" data-key=\"10.1093/nar/gkn892\">5</a>]</span>, MINT <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkr930\" class=\"citation\" data-key=\"10.1093/nar/gkr930\">6</a>]</span>, IntAct <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkr1088\" class=\"citation\" data-key=\"10.1093/nar/gkr1088\">7</a>]</span> and PDB <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/28.1.235\" class=\"citation\" data-key=\"10.1093/nar/28.1.235\">8</a>]</span>. For each reported PPI the interacting proteins were mapped to UniProt protein identifiers and then converted to NCBI Entrez gene ID pairs using an ID mapping table downloaded on January 12, 2012 from uniprot.org. Information about the specific publications reporting each interaction was retained and reported interactions that did not have an associated PubMed ID (PMID) were not included in the Lit-2010 dataset.</p>\r\n\r\n<p><strong>Identification of binary interactions:</strong> We divided Lit-2010 into the PPIs reported by<br>systematic high-throughput binary human interactome mapping efforts <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nature04209\" class=\"citation\" data-key=\"10.1038/nature04209\">9</a>, <a href=\"https://doi.org/10.1016/j.cell.2005.08.029\" class=\"citation\" data-key=\"10.1016/j.cell.2005.08.029\">10</a>, <a href=\"https://doi.org/10.1038/nmeth.1280\" class=\"citation\" data-key=\"10.1038/nmeth.1280\">11</a>]</span> and those detected in small- or medium-scale experiments. A small number of PPIs that had been detected in both systematic and other studies could appear in both datasets. Removing the PPIs only seen in systematic studies resulted in a dataset of 56,743 human PPIs.</p>\r\n\r\n<p>Next we attempted to distinguish binary interactions (direct biophysical contact between two proteins) <span class=\"citation\">[<a href=\"https://doi.org/10.1002/pmic.201100598\" class=\"citation\" data-key=\"10.1002/pmic.201100598\">12</a>, <a href=\"https://doi.org/10.1002/pmic.201100563\" class=\"citation\" data-key=\"10.1002/pmic.201100563\">13</a>]</span> from indirect associations (associations between two proteins that are in the same complex, but may or may not directly interact) <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.sbi.2013.02.008\" class=\"citation\" data-key=\"10.1016/j.sbi.2013.02.008\">14</a>]</span>. We evaluated each experimental interaction detection method in the PSI-MI 2.5 and classified them as binary, that is, primarily detects binary interactions, versus indirect, that is, primarily detects association of proteins within a complex (Table S1C). Where an experimental method could be viewed as either, depending on the specific experimental implementation then the method was conservatively classified as indirect. Fewer methods were classified as binary here than in previous <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nmeth.1284\" class=\"citation\" data-key=\"10.1038/nmeth.1284\">15</a>, <a href=\"https://doi.org/10.1126/science.1158684\" class=\"citation\" data-key=\"10.1126/science.1158684\">16</a>]</span> or parallel <span class=\"citation\">[<a href=\"https://doi.org/10.1186/1752-0509-6-92\" class=\"citation\" data-key=\"10.1186/1752-0509-6-92\">17</a>]</span> efforts to ensure the highest confidence binary Lit dataset possible.</p>\r\n\r\n<p>After parsing all PPI data from the source databases we obtained a binary human<br>dataset of 13,962 PPIs that contained at least one piece of binary evidence supporting each PPI (there could be other pieces of experimental evidences that were either binary or indirect) and a non-binary dataset containing 42,781 PPIs for which none of the experimental methods are binary (Lit-NB-10).</p>\r\n\r\n<p>A paper curated independently by two or more different PPI databases is commonly annotated to different PSI-MI terms, generally to terms of different depth on the same branch of the PSI-MI ontology tree <span class=\"citation\">[<a href=\"https://doi.org/10.1093/database/baq026\" class=\"citation\" data-key=\"10.1093/database/baq026\">18</a>, <a href=\"https://doi.org/10.1038/nbt.1867\" class=\"citation\" data-key=\"10.1038/nbt.1867\">19</a>]</span>. If not corrected for, these annotations would count as two or more pieces of evidence for the PPI, when actually there is only one piece of supporting evidence. For example, a yeast two-hybrid experiment might be annotated to the deeper term “two hybrid prey pooling approach” (MI:1112) by one PPI database but to the parent term “two hybrid” (MI:0018) by another database; a coimmunoprecipitation (co-IP) experiment might be annotated to the deeper term “anti-tag coimmunoprecipitation” (MI:0007) by one database but to the parent term “affinity chromatography technology” (MI:0004) by another. To compensate for variability in the annotated methods, when the same paper with the same PMID had different MI terms in two databases, we reassigned the deeper term “up” to the corresponding parent binary or nonbinary term on the same PSI-MI branch. In the examples given, the two Y2H annotations collapse to the single ID MI:0018, while the two co-IP annotations collapse to the single ID MI:0004.</p>\r\n\r\n<p>The binary human dataset was next separated into “binary multiple” (Lit-BM-10) (Table S1A), containing all interactions supported by two or more pieces of experimental evidence, at least one of which was binary (4,906 PPIs); versus “binary single”, containing all interactions supported by exactly one piece of binary experimental evidence (Lit-BS-10) (9,056 PPIs).</p>\r\n\r\n<p><strong>Updating the Lit dataset to 2013:</strong> To construct Lit-2013 (Figure S1B and Table S1B) we downloaded, on August 5, 2013, the updated curated PPI content of the same seven PPI databases used for Lit-2010.</p>",
      "body_md": "# Human Interaction Database\r\n\r\nThe Human Interaction Database (HID) 2014 [release](http://interactome.dfci.harvard.edu/H_sapiens/index.php?page=download) [@10.1016/j.cell.2014.10.050] contained two PPI datasets:\r\n\r\n+ `HI-II-14` -- 13,944 interactions -- proteome-scale map of the human binary interactome network generated by systematically screening Space-II\r\n+ `Lit-BM-13` -- 11,045 interactions -- high-quality recurated literature binary interactions extracted from 7 public repository in 2013\r\n\r\nWe [compared](https://github.com/dhimmel/ppi/blob/77862798448c4272c55e9c718323a3ec5d8db571/compile-PPIs.ipynb) interactions from HID to interactions from the Incomplete Interactome (II). We found that `HI-II-14` was a subset of `II_binary`. However, only 78.2% of `Lit-BM-13` was included in `II_literature`.\r\n\r\n*To better understand `Lit-BM-13`, we have added the relevant sections of the paper [supplement](http://www.sciencedirect.com/science/MiamiMultiMediaURL/1-s2.0-S0092867414014226/1-s2.0-S0092867414014226-mmc1.pdf/272196/html/S0092867414014226/2b892ecda8f249667d75023be6d13c7b/mmc1.pdf) below, omitting the \"assignment of experimental method\" sections [@10.1016/j.cell.2014.10.050]:*\r\n\r\n**Literature datasets:** We generated two datasets from literature-curated protein-protein interactions. A first dataset was generated in 2010 and used for all experiments, concomitantly with our mapping experiment, and a second dataset was extracted in 2013 to provide an updated version for all computational analyses.\r\n\r\n**Obtaining the Lit-2010 dataset:** The Lit-2010 dataset extracts human protein-protein interactions (PPIs), annotated through December 2010, from seven primary source databases: BIND [@10.1093/nar/gkg056], BioGRID [@10.1093/nar/gks1158], DIP [@10.1093/nar/gkh086], HPRD [@10.1093/nar/gkn892], MINT [@10.1093/nar/gkr930], IntAct [@10.1093/nar/gkr1088] and PDB [@10.1093/nar/28.1.235]. For each reported PPI the interacting proteins were mapped to UniProt protein identifiers and then converted to NCBI Entrez gene ID pairs using an ID mapping table downloaded on January 12, 2012 from uniprot.org. Information about the specific publications reporting each interaction was retained and reported interactions that did not have an associated PubMed ID (PMID) were not included in the Lit-2010 dataset.\r\n\r\n**Identification of binary interactions:** We divided Lit-2010 into the PPIs reported by\r\nsystematic high-throughput binary human interactome mapping efforts [@10.1038/nature04209 @10.1016/j.cell.2005.08.029 @10.1038/nmeth.1280] and those detected in small- or medium-scale experiments. A small number of PPIs that had been detected in both systematic and other studies could appear in both datasets. Removing the PPIs only seen in systematic studies resulted in a dataset of 56,743 human PPIs.\r\n\r\nNext we attempted to distinguish binary interactions (direct biophysical contact between two proteins) [@10.1002/pmic.201100598 @10.1002/pmic.201100563] from indirect associations (associations between two proteins that are in the same complex, but may or may not directly interact) [@10.1016/j.sbi.2013.02.008]. We evaluated each experimental interaction detection method in the PSI-MI 2.5 and classified them as binary, that is, primarily detects binary interactions, versus indirect, that is, primarily detects association of proteins within a complex (Table S1C). Where an experimental method could be viewed as either, depending on the specific experimental implementation then the method was conservatively classified as indirect. Fewer methods were classified as binary here than in previous [@10.1038/nmeth.1284 @10.1126/science.1158684] or parallel [@10.1186/1752-0509-6-92] efforts to ensure the highest confidence binary Lit dataset possible.\r\n\r\nAfter parsing all PPI data from the source databases we obtained a binary human\r\ndataset of 13,962 PPIs that contained at least one piece of binary evidence supporting each PPI (there could be other pieces of experimental evidences that were either binary or indirect) and a non-binary dataset containing 42,781 PPIs for which none of the experimental methods are binary (Lit-NB-10).\r\n\r\nA paper curated independently by two or more different PPI databases is commonly annotated to different PSI-MI terms, generally to terms of different depth on the same branch of the PSI-MI ontology tree [@10.1093/database/baq026 @10.1038/nbt.1867]. If not corrected for, these annotations would count as two or more pieces of evidence for the PPI, when actually there is only one piece of supporting evidence. For example, a yeast two-hybrid experiment might be annotated to the deeper term “two hybrid prey pooling approach” (MI:1112) by one PPI database but to the parent term “two hybrid” (MI:0018) by another database; a coimmunoprecipitation (co-IP) experiment might be annotated to the deeper term “anti-tag coimmunoprecipitation” (MI:0007) by one database but to the parent term “affinity chromatography technology” (MI:0004) by another. To compensate for variability in the annotated methods, when the same paper with the same PMID had different MI terms in two databases, we reassigned the deeper term “up” to the corresponding parent binary or nonbinary term on the same PSI-MI branch. In the examples given, the two Y2H annotations collapse to the single ID MI:0018, while the two co-IP annotations collapse to the single ID MI:0004.\r\n\r\nThe binary human dataset was next separated into “binary multiple” (Lit-BM-10) (Table S1A), containing all interactions supported by two or more pieces of experimental evidence, at least one of which was binary (4,906 PPIs); versus “binary single”, containing all interactions supported by exactly one piece of binary experimental evidence (Lit-BS-10) (9,056 PPIs).\r\n\r\n**Updating the Lit dataset to 2013:** To construct Lit-2013 (Figure S1B and Table S1B) we downloaded, on August 5, 2013, the updated curated PPI content of the same seven PPI databases used for Lit-2010.",
      "comment_id": 323,
      "profile_id": 17,
      "published": "2015-07-13T21:36:11.923036Z",
      "thread_id": 85,
      "url": "/discussion/creating-a-catalog-of-protein-interactions/85#3"
    },
    {
      "body_html": "<h1><em>hetio</em> interactions</h1>\r\n\r\n<p>Previously, we used the following method to catalog protein interactions <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1004259\">1</a>]</span>:</p>\r\n\r\n<blockquote><p>Physical protein-protein interactions (<a href=\"http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004259#pcbi.1004259.s020\">S8 Data</a>) were extracted from iRefIndex 12.0, a compilation of 15 primary interaction databases <span class=\"citation\">[<a href=\"https://doi.org/10.1186/1471-2105-9-405\" class=\"citation\" data-key=\"10.1186/1471-2105-9-405\">2</a>]</span>. The iRefIndex was processed with ppiTrim to convert proteins to genes, remove protein complexes, and condense duplicated entries <span class=\"citation\">[<a href=\"https://doi.org/10.1093/database/bar036\" class=\"citation\" data-key=\"10.1093/database/bar036\">3</a>]</span>.</p></blockquote>\r\n\r\n<p>The method contributed 97,938 interactions to our network of protein-coding genes. For this project, we converted these interactions to entrez genes. Prior to filtering for coding genes, 98,119 interactions were in the hetio dataset.</p>\r\n\r\n<p>The hetio interactions overlapped most with <code>Lit-BM-13</code>, <code>II_literature</code>, and <code>II_signaling</code> (<a href=\"https://github.com/dhimmel/ppi/blob/919264e834a95bf8724c7177b8657af9de8622fd/compile-PPIs.ipynb\">notebook</a>).</p>",
      "body_md": "# *hetio* interactions\r\n\r\nPreviously, we used the following method to catalog protein interactions [@10.1371/journal.pcbi.1004259]:\r\n\r\n> Physical protein-protein interactions ([S8 Data](http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004259#pcbi.1004259.s020)) were extracted from iRefIndex 12.0, a compilation of 15 primary interaction databases [@10.1186/1471-2105-9-405]. The iRefIndex was processed with ppiTrim to convert proteins to genes, remove protein complexes, and condense duplicated entries [@10.1093/database/bar036].\r\n\r\nThe method contributed 97,938 interactions to our network of protein-coding genes. For this project, we converted these interactions to entrez genes. Prior to filtering for coding genes, 98,119 interactions were in the hetio dataset.\r\n\r\nThe hetio interactions overlapped most with `Lit-BM-13`, `II_literature`, and `II_signaling` ([notebook](https://github.com/dhimmel/ppi/blob/919264e834a95bf8724c7177b8657af9de8622fd/compile-PPIs.ipynb)).",
      "comment_id": 324,
      "profile_id": 17,
      "published": "2015-07-13T23:21:46.024878Z",
      "thread_id": 85,
      "url": "/discussion/creating-a-catalog-of-protein-interactions/85#4"
    },
    {
      "body_html": "<p>We have <a href=\"http://thinklab.com/d/67\">adopted a literature mining scheme</a> for term relations based on cooccurrence of MeSH topics in MEDLINE. Of <a href=\"http://thinklab.com/discussion/unifying-disease-vocabularies/44#144\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d44\">DO Slim</a> diseases, 133 out of 137 have a MeSH cross-reference. For each disease, we identified all studies assigned that topic and then computed pairwise cooccurrences (<a href=\"https://github.com/dhimmel/medline/blob/54a621d7fc360a2ad623d2cb3180f60485aff37f/diseases.ipynb\">notebook</a>, <a href=\"https://github.com/dhimmel/medline/blob/54a621d7fc360a2ad623d2cb3180f60485aff37f/data/disease-disease-cooccurrence.tsv\">tsv</a>).</p>\r\n\r\n<p>Since disease topics seemed averse to cooccurrence, we did not enforce the major topic filter. Even so, diseases cooccurred less than would be expected by chance. This makes sense given that papers often focus on a single disease only but means that our p-values are likely conservative.</p>",
      "body_md": "We have [adopted a literature mining scheme](http://thinklab.com/d/67) for term relations based on cooccurrence of MeSH topics in MEDLINE. Of [DO Slim](http://thinklab.com/discussion/unifying-disease-vocabularies/44#144) diseases, 133 out of 137 have a MeSH cross-reference. For each disease, we identified all studies assigned that topic and then computed pairwise cooccurrences ([notebook](https://github.com/dhimmel/medline/blob/54a621d7fc360a2ad623d2cb3180f60485aff37f/diseases.ipynb), [tsv](https://github.com/dhimmel/medline/blob/54a621d7fc360a2ad623d2cb3180f60485aff37f/data/disease-disease-cooccurrence.tsv)).\r\n\r\nSince disease topics seemed averse to cooccurrence, we did not enforce the major topic filter. Even so, diseases cooccurred less than would be expected by chance. This makes sense given that papers often focus on a single disease only but means that our p-values are likely conservative.",
      "comment_id": 325,
      "profile_id": 17,
      "published": "2015-07-14T19:30:52.174618Z",
      "thread_id": 93,
      "url": "/discussion/disease-similarity-from-medline-topic-cooccurrence/93"
    },
    {
      "body_html": "<h1>Disease–Disease Relationships</h1>\r\n\r\n<p>We computed disease similarities based on MEDLINE cooccurrences. Refer to <a href=\"http://thinklab.com/discussion/disease-similarity-from-medline-topic-cooccurrence/93\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d93\">this discussion</a> for more information.</p>",
      "body_md": "# Disease--Disease Relationships\r\n\r\nWe computed disease similarities based on MEDLINE cooccurrences. Refer to [this discussion](http://thinklab.com/discussion/disease-similarity-from-medline-topic-cooccurrence/93) for more information.",
      "comment_id": 326,
      "profile_id": 17,
      "published": "2015-07-14T19:32:41.490015Z",
      "thread_id": 67,
      "url": "/discussion/mining-knowledge-from-medline-articles-and-their-indexed-mesh-terms/67#6"
    },
    {
      "body_html": "<p><a href=\"http://doa.nubic.northwestern.edu/pages/search.php\">DOAF</a>, the Disease Ontology Annotation Framework <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pone.0049686\" class=\"citation\" data-key=\"10.1371/journal.pone.0049686\">1</a>]</span>, provides gene–disease relationships extracted from GeneRIF. <a href=\"http://www.ncbi.nlm.nih.gov/gene/about-generif\">GeneRIF</a> is a crowdsourced database of functional gene annotations that is integrated into NCBI's Entrez Gene. DOAF describes the resources <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pone.0049686\" class=\"citation\" data-key=\"10.1371/journal.pone.0049686\">1</a>]</span>:</p>\r\n\r\n<blockquote><p>GeneRIF contains brief textual descriptions of genes (up to 250 characters) and are available from the NCBI <span class=\"citation\">[<a href=\"https://doi.org/10.1186/1471-2105-9-s3-s9\" class=\"citation\" data-key=\"10.1186/1471-2105-9-s3-s9\">2</a>]</span>, <span class=\"citation\">[<a href=\"https://doi.org/10.1142/9789812772435_0026\" class=\"citation\" data-key=\"10.1142/9789812772435_0026\">3</a>]</span>. Every GeneRIF entry is associated with a PubMed ID, providing published evidence for each description.</p></blockquote>\r\n\r\n<h2>Processing</h2>\r\n\r\n<p>We converted the <code>IDMappings.txt</code> <a href=\"http://doa.nubic.northwestern.edu/pages/download.php\">data release</a> into a tsv with a single row per disease–gene pair (<a href=\"https://github.com/dhimmel/doaf/blob/bbe1c326aa385416e36d02b144e89e2b99e700b6/doaf.ipynb\">notebook</a>, <a href=\"https://github.com/dhimmel/doaf/blob/bbe1c326aa385416e36d02b144e89e2b99e700b6/data/doaf.tsv\">tsv</a>). Genes are in entrez identifiers and diseases are DO terms.</p>\r\n\r\n<p>Overall, we identified 50,863 gene–disease functional annotations.</p>",
      "body_md": "[DOAF](http://doa.nubic.northwestern.edu/pages/search.php), the Disease Ontology Annotation Framework [@10.1371/journal.pone.0049686], provides gene--disease relationships extracted from GeneRIF. [GeneRIF](http://www.ncbi.nlm.nih.gov/gene/about-generif) is a crowdsourced database of functional gene annotations that is integrated into NCBI's Entrez Gene. DOAF describes the resources [@10.1371/journal.pone.0049686]:\r\n\r\n> GeneRIF contains brief textual descriptions of genes (up to 250 characters) and are available from the NCBI [@10.1186/1471-2105-9-s3-s9], [@10.1142/9789812772435_0026]. Every GeneRIF entry is associated with a PubMed ID, providing published evidence for each description.\r\n\r\n## Processing\r\n\r\nWe converted the `IDMappings.txt` [data release](http://doa.nubic.northwestern.edu/pages/download.php) into a tsv with a single row per disease--gene pair ([notebook](https://github.com/dhimmel/doaf/blob/bbe1c326aa385416e36d02b144e89e2b99e700b6/doaf.ipynb), [tsv](https://github.com/dhimmel/doaf/blob/bbe1c326aa385416e36d02b144e89e2b99e700b6/data/doaf.tsv)). Genes are in entrez identifiers and diseases are DO terms.\r\n\r\nOverall, we identified 50,863 gene--disease functional annotations.",
      "comment_id": 327,
      "profile_id": 17,
      "published": "2015-07-14T19:55:24.483842Z",
      "thread_id": 94,
      "url": "/discussion/functional-disease-annotations-for-genes-using-doaf/94"
    },
    {
      "body_html": "<h2>Latest indication catalog</h2>\r\n\r\n<p>We have <a href=\"http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#191\">completed</a> a first-draft of our indication catalog. Recently, we updated the catalog with some <a href=\"http://thinklab.com/discussion/disease-ontology-feature-requests/68#221\">fresh</a> disease cross-references. The latest catalog is now online (<a href=\"https://cdn.rawgit.com/dhimmel/indications/7c2b17f463babafcf4ec441e720b831340b186fe/merge.html#indication-table\">webpage</a>, <a href=\"https://github.com/dhimmel/indications/blob/7c2b17f463babafcf4ec441e720b831340b186fe/data/indications.tsv\">tsv</a>, <a href=\"https://github.com/dhimmel/indications/tree/7c2b17f463babafcf4ec441e720b831340b186fe\">repository</a>).</p>\r\n\r\n<p>The catalog includes 1,388 high-confidence indications from four resources — MEDI-HPS <span class=\"citation\">[<a href=\"https://doi.org/10.1136/amiajnl-2012-001431\" class=\"citation\" data-key=\"10.1136/amiajnl-2012-001431\">1</a>]</span>, ehrlink <span class=\"citation\">[<a href=\"https://doi.org/10.1136/amiajnl-2012-000852\" class=\"citation\" data-key=\"10.1136/amiajnl-2012-000852\">2</a>]</span>, LabeledIn <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.jbi.2014.08.004\" class=\"citation\" data-key=\"10.1016/j.jbi.2014.08.004\">3</a>, <a href=\"https://doi.org/10.1093/database/bav016\" class=\"citation\" data-key=\"10.1093/database/bav016\">4</a>]</span>, and PREDICT <span class=\"citation\">[<a href=\"https://doi.org/10.1038/msb.2011.26\" class=\"citation\" data-key=\"10.1038/msb.2011.26\">5</a>]</span> — and 1,114 low-confidence indications from MEDI-LPS <span class=\"citation\">[<a href=\"https://doi.org/10.1136/amiajnl-2012-001431\" class=\"citation\" data-key=\"10.1136/amiajnl-2012-001431\">1</a>]</span>. We are primarily concerned about the high-confidence associations which connect 108 diseases from <a href=\"http://thinklab.com/discussion/unifying-disease-vocabularies/44#144\">DO Slim</a> and 744 small molecules from <a href=\"http://thinklab.com/discussion/unifying-drug-vocabularies/40#192\">Drugbank Slim</a>.</p>\r\n\r\n<h2>Problematic indications</h2>\r\n\r\n<p>The source databases have a loose definition of indication — symptomatic treatments are often considered indications. For example, a narcolepsy drug approved for MS-induced fatigue is indicated for MS in our catalog. However, we are primarily interested in disease-modifying therapies. Since our method trains itself from this catalog, our predictions will recapitulate the types of indications included.</p>\r\n\r\n<h2>Seeking an expert</h2>\r\n\r\n<p>We are <strong>seeking an expert physician</strong> to manually review our 1,388 high-confidence indications and identify the disease-modifying subset. Since the classification is <em>unlikely</em> to be straightforward, we are looking for someone who can conceptualize the task from a high-throughput systems pharmacology perspective. We are happy to offer project authorship for a job well done.</p>",
      "body_md": "## Latest indication catalog\r\n\r\nWe have [completed](http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#191) a first-draft of our indication catalog. Recently, we updated the catalog with some [fresh](http://thinklab.com/discussion/disease-ontology-feature-requests/68#221) disease cross-references. The latest catalog is now online ([webpage](https://cdn.rawgit.com/dhimmel/indications/7c2b17f463babafcf4ec441e720b831340b186fe/merge.html#indication-table), [tsv](https://github.com/dhimmel/indications/blob/7c2b17f463babafcf4ec441e720b831340b186fe/data/indications.tsv), [repository](https://github.com/dhimmel/indications/tree/7c2b17f463babafcf4ec441e720b831340b186fe)).\r\n\r\nThe catalog includes 1,388 high-confidence indications from four resources -- MEDI-HPS [@10.1136/amiajnl-2012-001431], ehrlink [@10.1136/amiajnl-2012-000852], LabeledIn [@10.1016/j.jbi.2014.08.004 @10.1093/database/bav016], and PREDICT [@10.1038/msb.2011.26] -- and 1,114 low-confidence indications from MEDI-LPS [@10.1136/amiajnl-2012-001431]. We are primarily concerned about the high-confidence associations which connect 108 diseases from [DO Slim](http://thinklab.com/discussion/unifying-disease-vocabularies/44#144) and 744 small molecules from [Drugbank Slim](http://thinklab.com/discussion/unifying-drug-vocabularies/40#192).\r\n\r\n## Problematic indications\r\n\r\nThe source databases have a loose definition of indication -- symptomatic treatments are often considered indications. For example, a narcolepsy drug approved for MS-induced fatigue is indicated for MS in our catalog. However, we are primarily interested in disease-modifying therapies. Since our method trains itself from this catalog, our predictions will recapitulate the types of indications included.\r\n\r\n## Seeking an expert\r\n\r\nWe are **seeking an expert physician** to manually review our 1,388 high-confidence indications and identify the disease-modifying subset. Since the classification is *unlikely* to be straightforward, we are looking for someone who can conceptualize the task from a high-throughput systems pharmacology perspective. We are happy to offer project authorship for a job well done.",
      "comment_id": 328,
      "profile_id": 17,
      "published": "2015-07-14T21:45:53.225564Z",
      "thread_id": 95,
      "url": "/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95"
    },
    {
      "body_html": "<h1>Expert curation of the indication catalog</h1>\r\n\r\n<p>We have decided to filter our catalog for disease-modifying indications and are seeking an expert curator to assist with this task. We <a href=\"http://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d95\">started a new discussion</a> for this next step.</p>\r\n\r\n<p><a href=\"/u/allisonmccoy\" class=\"username\">@allisonmccoy</a>, have you thought more about releasing the data from your recent publication <span class=\"citation\">[<a href=\"https://doi.org/10.4338/ACI-2015-01-RA-0010\" class=\"citation\" data-key=\"10.4338/ACI-2015-01-RA-0010\">1</a>]</span>? If you can do this in the next week or two, we would be thrilled to include this data. Otherwise we will have to move ahead with only the <a href=\"http://thinklab.com/discussion/extracting-indications-from-the-ehrlink-resource/62\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d62\">ehrlink data</a> from your initial study <span class=\"citation\">[<a href=\"https://doi.org/10.1136/amiajnl-2012-000852\" class=\"citation\" data-key=\"10.1136/amiajnl-2012-000852\">2</a>]</span>.</p>",
      "body_md": "# Expert curation of the indication catalog\r\n\r\nWe have decided to filter our catalog for disease-modifying indications and are seeking an expert curator to assist with this task. We [started a new discussion](http://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95) for this next step.\r\n\r\n@allisonmccoy, have you thought more about releasing the data from your recent publication [@10.4338/ACI-2015-01-RA-0010]? If you can do this in the next week or two, we would be thrilled to include this data. Otherwise we will have to move ahead with only the [ehrlink data](http://thinklab.com/discussion/extracting-indications-from-the-ehrlink-resource/62) from your initial study [@10.1136/amiajnl-2012-000852].",
      "comment_id": 329,
      "profile_id": 17,
      "published": "2015-07-14T21:55:43.335809Z",
      "thread_id": 21,
      "url": "/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#23"
    },
    {
      "body_html": "<h1>Signaling PPI</h1>\r\n\r\n<p><em>The incomplete interactome paper includes interactions from a signaling study <span class=\"citation\">[<a href=\"https://doi.org/10.1126/scisignal.2001699\" class=\"citation\" data-key=\"10.1126/scisignal.2001699\">1</a>]</span>. We report the sources of this <code>HPPI1</code> network from the original paper's <a href=\"http://stke.sciencemag.org/content/sigtrans/suppl/2011/09/01/4.189.rs8.DC1/4_rs8_SM.pdf\">supplement</a>:</em></p>\r\n\r\n<p><strong>Table S3</strong>: Human PPI interaction data sets used to construct the HPPI1 network. A comprehensive HPPI1 network was created by unifying the data sets listed. Name of the data set, publication reference, number of proteins and number of interactions in the data set (after mapping to NCBI Entrez GeneID) are given. </p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>PPI Data sets</th><th>Reference</th><th>Proteins</th><th>Interactions</th></tr></thead><tbody><tr><td>Human Protein Reference Database V7.0</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1007/978-1-60761-232-2_6\" class=\"citation\" data-key=\"10.1007/978-1-60761-232-2_6\">2</a>]</span></td><td>9305</td><td>35021</td></tr><tr><td>Genome-wide Y2H screen and literature-derived PPI data</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1038/nature04209\" class=\"citation\" data-key=\"10.1038/nature04209\">3</a>]</span></td><td>3024</td><td>6221</td></tr><tr><td>Y2H screen for inherited ataxia and literature-derived PPI data</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.cell.2006.03.032\" class=\"citation\" data-key=\"10.1016/j.cell.2006.03.032\">4</a>]</span></td><td>2909</td><td>5440</td></tr><tr><td>Genome-wide Y2H screen</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.cell.2005.08.029\" class=\"citation\" data-key=\"10.1016/j.cell.2005.08.029\">5</a>]</span></td><td>1699</td><td>3150</td></tr><tr><td>Y2H PPIs</td><td>This study</td><td>1126</td><td>2626</td></tr><tr><td>Mouse signaling PPI data from AfCS</td><td><a href=\"http://www.signalinggateway.org/\">http://www.signalinggateway.org/</a></td><td>857</td><td>1004</td></tr><tr><td>Network for Smad signaling</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1101/gr.2334104\" class=\"citation\" data-key=\"10.1101/gr.2334104\">6</a>]</span></td><td>623</td><td>874</td></tr><tr><td>PPIs of proteins in MHC class III region and mRNA decay</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1101/gr.2122004\" class=\"citation\" data-key=\"10.1101/gr.2122004\">7</a>, <a href=\"https://doi.org/10.1016/S0888-7543%2803%2900235-0\" class=\"citation\" data-key=\"10.1016/S0888-7543(03)00235-0\">8</a>]</span></td><td>300</td><td>376</td></tr><tr><td>Network of nuclear receptors</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1074/mcp.M400169-MCP200\" class=\"citation\" data-key=\"10.1074/mcp.M400169-MCP200\">9</a>]</span></td><td>134</td><td>288</td></tr><tr><td>Huntingtin’s disease PPI network</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.molcel.2004.09.016\" class=\"citation\" data-key=\"10.1016/j.molcel.2004.09.016\">10</a>]</span></td><td>64</td><td>156</td></tr><tr><td>PPIs between KIAA proteins</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1101/gr.406902\" class=\"citation\" data-key=\"10.1101/gr.406902\">11</a>]</span></td><td>94</td><td>84</td></tr><tr><td>Total</td><td></td><td>9832</td><td>39641</td></tr></tbody></table>",
      "body_md": "# Signaling PPI\r\n\r\n*The incomplete interactome paper includes interactions from a signaling study [@10.1126/scisignal.2001699]. We report the sources of this `HPPI1` network from the original paper's [supplement](http://stke.sciencemag.org/content/sigtrans/suppl/2011/09/01/4.189.rs8.DC1/4_rs8_SM.pdf):*\r\n\r\n\r\n**Table S3**: Human PPI interaction data sets used to construct the HPPI1 network. A comprehensive HPPI1 network was created by unifying the data sets listed. Name of the data set, publication reference, number of proteins and number of interactions in the data set (after mapping to NCBI Entrez GeneID) are given. \r\n\r\n| PPI Data sets | Reference | Proteins | Interactions |\r\n|--------------------|---------------|----------|--------------|\r\n| Human Protein Reference Database V7.0 | [@10.1007/978-1-60761-232-2_6] | 9305 | 35021 |\r\n| Genome-wide Y2H screen and literature-derived PPI data | [@10.1038/nature04209] | 3024 | 6221 |\r\n| Y2H screen for inherited ataxia and literature-derived PPI data | [@10.1016/j.cell.2006.03.032] | 2909 | 5440 |\r\n| Genome-wide Y2H screen | [@10.1016/j.cell.2005.08.029] | 1699 | 3150 |\r\n| Y2H PPIs | This study | 1126 | 2626 |\r\n| Mouse signaling PPI data from AfCS | http://www.signalinggateway.org/ | 857 | 1004 |\r\n| Network for Smad signaling | [@10.1101/gr.2334104] | 623 | 874 |\r\n| PPIs of proteins in MHC class III region and mRNA decay | [@10.1101/gr.2122004 @10.1016/S0888-7543(03)00235-0] | 300 | 376 |\r\n| Network of nuclear receptors | [@10.1074/mcp.M400169-MCP200] | 134 | 288 |\r\n| Huntingtin’s disease PPI network | [@10.1016/j.molcel.2004.09.016] | 64 | 156 |\r\n| PPIs between KIAA proteins | [@10.1101/gr.406902] | 94 | 84 |\r\n| Total |  | 9832 | 39641 |",
      "comment_id": 330,
      "profile_id": 17,
      "published": "2015-07-15T00:58:47.066661Z",
      "thread_id": 85,
      "url": "/discussion/creating-a-catalog-of-protein-interactions/85#5"
    },
    {
      "body_html": "<h1>Migrating to owltools</h1>\r\n\r\n<p>We are in the decade of the ontology: the pace of development and growth of this field is incredible. Therefore, I would like to outsource the ontology reasoning and inference to established software projects, namely <a href=\"https://github.com/owlcollab/owltools\">owltools</a>.</p>\r\n\r\n<p>The first step will be to load GO with <code>owltools http://purl.obolibrary.org/obo/go.owl</code>. Beyond this step I am stuck and haven't found sufficient documentation. <a href=\"/u/chrismungall\" class=\"username\">@chrismungall</a> or <a href=\"/u/fbastian\" class=\"username\">@fbastian</a> perhaps you could help me with the below queries or point me to a good tutorial:</p>\r\n\r\n<ol><li><strong>Adding annotations</strong>: we would like to add human gene annotations to GO terms.</li><li><strong>Propagating annotations</strong>: we would like to propagate annotations up <code>is_a</code> and <code>part_of</code> edges. Negative (<code>NOT</code>) annotations should short-circuit annotation propagation. </li><li><strong>Filter overly broad terms</strong>: Remove the \"<a href=\"http://geneontology.org/ontology/subsets/gocheck_do_not_annotate.obo\">do not annotate</a>\" terms for GO.</li><li><strong>Output:</strong> Write the propagated annotations to a text file</li></ol>\r\n\r\n<p>If it's not possible to perform all of these steps in one command, then we can work on a piecemeal approach.</p>",
      "body_md": "# Migrating to owltools\r\n\r\nWe are in the decade of the ontology: the pace of development and growth of this field is incredible. Therefore, I would like to outsource the ontology reasoning and inference to established software projects, namely [owltools](https://github.com/owlcollab/owltools).\r\n\r\nThe first step will be to load GO with `owltools http://purl.obolibrary.org/obo/go.owl`. Beyond this step I am stuck and haven't found sufficient documentation. @chrismungall or @fbastian perhaps you could help me with the below queries or point me to a good tutorial:\r\n\r\n1. **Adding annotations**: we would like to add human gene annotations to GO terms.\r\n2. **Propagating annotations**: we would like to propagate annotations up `is_a` and `part_of` edges. Negative (`NOT`) annotations should short-circuit annotation propagation. \r\n3. **Filter overly broad terms**: Remove the \"[do not annotate](http://geneontology.org/ontology/subsets/gocheck_do_not_annotate.obo)\" terms for GO.\r\n4. **Output:** Write the propagated annotations to a text file\r\n\r\nIf it's not possible to perform all of these steps in one command, then we can work on a piecemeal approach.",
      "comment_id": 331,
      "profile_id": 17,
      "published": "2015-07-15T18:31:30.951908Z",
      "thread_id": 39,
      "url": "/discussion/compiling-gene-ontology-annotations-into-an-easy-to-use-format/39#6"
    },
    {
      "body_html": "<p>You should definitely check with Chris, GO annotation/propagation is not really my area of expertise. And it is indeed possible to do a lot of things in a single command using owltools. </p>",
      "body_md": "You should definitely check with Chris, GO annotation/propagation is not really my area of expertise. And it is indeed possible to do a lot of things in a single command using owltools. ",
      "comment_id": 332,
      "profile_id": 111,
      "published": "2015-07-17T00:15:58.471609Z",
      "thread_id": 39,
      "url": "/discussion/compiling-gene-ontology-annotations-into-an-easy-to-use-format/39#7"
    },
    {
      "body_html": "<p>Actually, for some mappings we needed to request for new terms in Uberon, e.g.: <a href=\"https://github.com/obophenotype/uberon/issues/725\">https://github.com/obophenotype/uberon/issues/725</a></p>\r\n\r\n<p>Things will be slow until mid-August on our side. </p>",
      "body_md": "Actually, for some mappings we needed to request for new terms in Uberon, e.g.: https://github.com/obophenotype/uberon/issues/725\r\n\r\nThings will be slow until mid-August on our side. ",
      "comment_id": 333,
      "profile_id": 111,
      "published": "2015-07-17T00:21:40.270939Z",
      "thread_id": 82,
      "url": "/discussion/processing-gtex-for-tissue-specific-gene-expression/82#14"
    },
    {
      "body_html": "<p>Have you seen <a href=\"http://interactome.dfci.harvard.edu/H_sapiens/\">Human Interactome</a> out of Harvard.  I used them for my <a href=\"http://www.nature.com/ncomms/2014/140606/ncomms5074/full/ncomms5074.html\">PPI work for CNVs in GWAS for Autism</a> and worked out quite well.  They seem to have at least some of the ones you have already listed, although I think your list looks more extensive.  You want to be careful of integrating genome-wide PPI (i.e. Y2H) vs targeted PPI datasets.  It may mess up interpreting the statistics if the evidence for PPI is biased vs genome-wide.</p>",
      "body_md": "Have you seen [Human Interactome](http://interactome.dfci.harvard.edu/H_sapiens/) out of Harvard.  I used them for my [PPI work for CNVs in GWAS for Autism](http://www.nature.com/ncomms/2014/140606/ncomms5074/full/ncomms5074.html) and worked out quite well.  They seem to have at least some of the ones you have already listed, although I think your list looks more extensive.  You want to be careful of integrating genome-wide PPI (i.e. Y2H) vs targeted PPI datasets.  It may mess up interpreting the statistics if the evidence for PPI is biased vs genome-wide.",
      "comment_id": 334,
      "profile_id": 121,
      "published": "2015-07-28T19:29:02.651491Z",
      "thread_id": 85,
      "url": "/discussion/creating-a-catalog-of-protein-interactions/85#6"
    },
    {
      "body_html": "<p>A 2011 study <span class=\"citation\">[<a href=\"https://doi.org/10.1126/scitranslmed.3001318\" class=\"citation\" data-key=\"10.1126/scitranslmed.3001318\">1</a>]</span> introduced the idea of large-scale drug repurposing based disease expression profiles. However, the field has faced a great impediment: results from differential expression experiments are only available on a <em>per study</em> basis. Our project requires a consensus signature (that aggregates many experiments) for <em>each of 137</em> diseases.</p>\r\n\r\n<p>A forthcoming project called <a href=\"http://dev.stargeo.io/\">STARGEO</a> aims to provide disease-specific expression signatures on a broad scale. The webapp crowdsources <a href=\"http://www.ncbi.nlm.nih.gov/geo/\">GEO</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gks1193\" class=\"citation\" data-key=\"10.1093/nar/gks1193\">2</a>, <a href=\"https://doi.org/10.1093/nar/30.1.207\" class=\"citation\" data-key=\"10.1093/nar/30.1.207\">3</a>]</span> annotation and performs case-control analyses based on user queries. The following video introduces the project:</p>\r\n\r\n<p></p><div class=\"iframe-container\"><iframe src=\"https://www.youtube.com/embed/61lw_d6Eoik\" frameborder=\"0\" allowfullscreen=\"true\"></iframe></div>\r\n\r\n<p>We now join forces with STARGEO and welcome its creator <a href=\"/u/idrdex\" class=\"username\">@idrdex</a> to the team! The first stage will be tagging all GEO datasets containing <a href=\"http://thinklab.com/discussion/unifying-disease-vocabularies/44#144\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d44\">DO Slim</a> diseases. STARGEO's current DO Slim coverage is <a href=\"https://github.com/dhimmel/stargeo/blob/master/data/DO-tag-mapping.tsv\">available here</a>.</p>",
      "body_md": "A 2011 study [@10.1126/scitranslmed.3001318] introduced the idea of large-scale drug repurposing based disease expression profiles. However, the field has faced a great impediment: results from differential expression experiments are only available on a *per study* basis. Our project requires a consensus signature (that aggregates many experiments) for *each of 137* diseases.\r\n\r\nA forthcoming project called [STARGEO](http://dev.stargeo.io/) aims to provide disease-specific expression signatures on a broad scale. The webapp crowdsources [GEO](http://www.ncbi.nlm.nih.gov/geo/) [@10.1093/nar/gks1193 @10.1093/nar/30.1.207] annotation and performs case-control analyses based on user queries. The following video introduces the project:\r\n\r\n![:youtube](61lw_d6Eoik)\r\n\r\nWe now join forces with STARGEO and welcome its creator @idrdex to the team! The first stage will be tagging all GEO datasets containing [DO Slim](http://thinklab.com/discussion/unifying-disease-vocabularies/44#144) diseases. STARGEO's current DO Slim coverage is [available here](https://github.com/dhimmel/stargeo/blob/master/data/DO-tag-mapping.tsv).",
      "comment_id": 335,
      "profile_id": 17,
      "published": "2015-07-28T21:14:07.077429Z",
      "thread_id": 96,
      "url": "/discussion/stargeo-expression-signatures-for-disease-using-crowdsourced-geo-annotation/96"
    },
    {
      "body_html": "<p><a href=\"/u/idrdex\" class=\"username\">@idrdex</a>, we're referring to this data as the Human Interaction Database (HID) and found that the systematic datasets were wholly included in the Incomplete Interactome (<code>II</code>) data (<a href=\"#323\">comment</a>, <a href=\"https://github.com/dhimmel/ppi/blob/77862798448c4272c55e9c718323a3ec5d8db571/compile-PPIs.ipynb\">notebook</a>).</p>\r\n\r\n<p>You are right that once we introduce PPIs from targeted or curated analyses, we have introduce knowledge bias. While we prefer systematic data, we <a href=\"http://thinklab.com/discussion/text-as-a-resource-for-network-population/48#120\">decided to incorporate</a> biased knowledge. We will likely perform a parallel analysis on an network built from only unbiased data sources. For this analysis, we'll use the Y2H datasets used in your autism study <span class=\"citation\">[<a href=\"https://doi.org/10.1038/ncomms5074\" class=\"citation\" data-key=\"10.1038/ncomms5074\">1</a>]</span>.</p>",
      "body_md": "@idrdex, we're referring to this data as the Human Interaction Database (HID) and found that the systematic datasets were wholly included in the Incomplete Interactome (`II`) data ([comment](#323), [notebook](https://github.com/dhimmel/ppi/blob/77862798448c4272c55e9c718323a3ec5d8db571/compile-PPIs.ipynb)).\r\n\r\nYou are right that once we introduce PPIs from targeted or curated analyses, we have introduce knowledge bias. While we prefer systematic data, we [decided to incorporate](http://thinklab.com/discussion/text-as-a-resource-for-network-population/48#120) biased knowledge. We will likely perform a parallel analysis on an network built from only unbiased data sources. For this analysis, we'll use the Y2H datasets used in your autism study [@10.1038/ncomms5074].",
      "comment_id": 336,
      "profile_id": 17,
      "published": "2015-07-28T21:32:56.762735Z",
      "thread_id": 85,
      "url": "/discussion/creating-a-catalog-of-protein-interactions/85#7"
    },
    {
      "body_html": "<h1>Similarities between associated genes in drug compounds</h1>\r\n\r\n<p><a href=\"https://github.com/sabrinalchen/drugbank-similarity/blob/912848e1d13fc0648ae33e022308d1da719f5a1a/similarities.ipynb\">Notebook</a></p>\r\n\r\n<h2>Objective:</h2>\r\n\r\n<p>We wanted to visualize the similarities among the associated genes for drug pairs in each of the four types of drug-bank interaction categories. To do so we extracted data from various sources to compile drugs with associated genes and the compound similarities between pairs of drugs compounds. </p>\r\n\r\n<h2>The Data:</h2>\r\n\r\n<p>We extracted <a href=\"https://raw.githubusercontent.com/dhimmel/drugbank/3e87872db5fca5ac427ce27464ab945c0ceb4ec6/data/proteins.tsv\">DrugBank-protein relationships</a> which lists drug types and associated genes, as well as <a href=\"http://nbviewer.ipython.org/github/dhimmel/drugbank/blob/9eb1e15ada5e6579e5aea1cae784c10602037b05/similarity.ipynb\">compound similarity data</a> which gives a value between zero and one based on the chemical similarity of a pair of drugs. </p>\r\n\r\n<h2>Jaccard Values and Initial Visualization:</h2>\r\n\r\n<p>Our first step was to create a dataframe with combination of compound pairs. Each compound is associated with a certain number of genes and we were able to define a Jaccard function to calculate the Jaccard value of the overlapping genes in each compound pair. It was noted – as expected — that the wide majority of the compound pairs had no similar genes, with a Jaccard value of zero. The drug-protein interactions were then categorized into four subgroups: carrier, enzyme, target and transporter. The similarity data was added for each compound pair. All five categories were graphed on a Seaborn PairGrid using a histogram on the univariate level and a hexbin scatterplot on the bivariate level.</p>\r\n\r\n<h2>Analysis of PairGrid Jaccard Value Visualization:</h2>\r\n\r\n<p>The data for each of the graphs did indeed center around zero, meaning that most compounds had no genes in common. In fact, the data was so skewed in the histogram that we needed to use logarithmic bins. Though the data was skewed right towards zero and dipped around 0.9 for each category, the histograms showed that there was also significant data for the Jaccard value of one, so that the graphs had U-shaped figures. This means that there are some compound pairs with all genes in common. In terms of the hexbin scatterplots, the darkest areas were zero and one, which reflected what was observed in the histograms. One other interesting trend to note are that for carrier and transporter, the data also concentrated around 0.5 and 0.33. </p>\r\n\r\n<p><img src=\"https://raw.githubusercontent.com/sabrinalchen/drugbank-similarity/ad3edac94b5c8d00e81395095468c7cce621e9d6/figure/similarity.png\" alt=\"\"></p>\r\n\r\n<h5>Figure 1: Compares Jaccard values for each drug-protein interaction category and chemical similarity</h5>\r\n\r\n<h2>Mean Jaccard Pointplot:</h2>\r\n\r\n<p>We used the Seaborn <a href=\"https://github.com/sabrinalchen/drugbank-similarity/blob/22bf54916d14b933be846bf52ad93237d54394c9/figure/similarity_mean.png\">Pointplot</a> to visualize the data in a different way. The means of Jaccard values were calculated for each of the four protein-interaction categories. With the similarity on the x-axis and the mean of Jaccard on the y-axis, it was concluded that the mean Jaccard peaked when the similarity was about 0.8 to 0.9. The general upwards trend was expected, as increased compound similarity should indicate an increase of gene overlap. By far, the target category had the most dramatic increase in mean Jaccard value. Though it started with a pretty flat mean Jaccard value at zero, it increased rapidly to hit a mean Jaccard value of nearly 0.5 at similarity=0.8. </p>\r\n\r\n<p><img src=\"https://raw.githubusercontent.com/sabrinalchen/drugbank-similarity/912848e1d13fc0648ae33e022308d1da719f5a1a/figure/similarity_mean.png\" alt=\"\"></p>\r\n\r\n<h5>Figure 2: Demonstrates relationship between chemical similarity of compounds and the mean Jaccard values</h5>\r\n\r\n<h2>Similarity Threshold:</h2>\r\n\r\n<p>The final visualization we created was a series of complex barplots to compare a similarity threshold among the four category groups. The similarity values were replaced with zero or one depending on whether the original value was greater or less than 0.5. Next, contingency tables were created for each category so that relative frequencies could be calculated. </p>\r\n\r\n<p>The visualization showed that similar compounds are likely to have common targets. For example, if two compounds shared a transporter, they also shared a carrier 25% of the time, compared to 5% of the time if they did not.  This trend continued throughout each of the bar graphs and was particularly notable in the comparisons with similarity. Note that the y-axis’s are labeled differently for easier reading. </p>\r\n\r\n<p><img src=\"https://raw.githubusercontent.com/sabrinalchen/drugbank-similarity/ad3edac94b5c8d00e81395095468c7cce621e9d6/figure/output.png\" alt=\"\"></p>\r\n\r\n<h5>Figure 3: Illustrates similarity threshold among the drug-protein interaction categories and chemical similarity</h5>",
      "body_md": "#Similarities between associated genes in drug compounds\r\n\r\n[Notebook](https://github.com/sabrinalchen/drugbank-similarity/blob/912848e1d13fc0648ae33e022308d1da719f5a1a/similarities.ipynb)\r\n\r\n##Objective: \r\nWe wanted to visualize the similarities among the associated genes for drug pairs in each of the four types of drug-bank interaction categories. To do so we extracted data from various sources to compile drugs with associated genes and the compound similarities between pairs of drugs compounds. \r\n\r\n##The Data: \r\nWe extracted [DrugBank-protein relationships](https://raw.githubusercontent.com/dhimmel/drugbank/3e87872db5fca5ac427ce27464ab945c0ceb4ec6/data/proteins.tsv) which lists drug types and associated genes, as well as [compound similarity data](http://nbviewer.ipython.org/github/dhimmel/drugbank/blob/9eb1e15ada5e6579e5aea1cae784c10602037b05/similarity.ipynb) which gives a value between zero and one based on the chemical similarity of a pair of drugs. \r\n\r\n##Jaccard Values and Initial Visualization:\r\nOur first step was to create a dataframe with combination of compound pairs. Each compound is associated with a certain number of genes and we were able to define a Jaccard function to calculate the Jaccard value of the overlapping genes in each compound pair. It was noted – as expected -- that the wide majority of the compound pairs had no similar genes, with a Jaccard value of zero. The drug-protein interactions were then categorized into four subgroups: carrier, enzyme, target and transporter. The similarity data was added for each compound pair. All five categories were graphed on a Seaborn PairGrid using a histogram on the univariate level and a hexbin scatterplot on the bivariate level.\r\n\r\n##Analysis of PairGrid Jaccard Value Visualization:\r\nThe data for each of the graphs did indeed center around zero, meaning that most compounds had no genes in common. In fact, the data was so skewed in the histogram that we needed to use logarithmic bins. Though the data was skewed right towards zero and dipped around 0.9 for each category, the histograms showed that there was also significant data for the Jaccard value of one, so that the graphs had U-shaped figures. This means that there are some compound pairs with all genes in common. In terms of the hexbin scatterplots, the darkest areas were zero and one, which reflected what was observed in the histograms. One other interesting trend to note are that for carrier and transporter, the data also concentrated around 0.5 and 0.33. \r\n\r\n![](https://raw.githubusercontent.com/sabrinalchen/drugbank-similarity/ad3edac94b5c8d00e81395095468c7cce621e9d6/figure/similarity.png)\r\n#####Figure 1: Compares Jaccard values for each drug-protein interaction category and chemical similarity\r\n\r\n##Mean Jaccard Pointplot:\r\nWe used the Seaborn [Pointplot](https://github.com/sabrinalchen/drugbank-similarity/blob/22bf54916d14b933be846bf52ad93237d54394c9/figure/similarity_mean.png) to visualize the data in a different way. The means of Jaccard values were calculated for each of the four protein-interaction categories. With the similarity on the x-axis and the mean of Jaccard on the y-axis, it was concluded that the mean Jaccard peaked when the similarity was about 0.8 to 0.9. The general upwards trend was expected, as increased compound similarity should indicate an increase of gene overlap. By far, the target category had the most dramatic increase in mean Jaccard value. Though it started with a pretty flat mean Jaccard value at zero, it increased rapidly to hit a mean Jaccard value of nearly 0.5 at similarity=0.8. \r\n\r\n![](https://raw.githubusercontent.com/sabrinalchen/drugbank-similarity/912848e1d13fc0648ae33e022308d1da719f5a1a/figure/similarity_mean.png)\r\n#####Figure 2: Demonstrates relationship between chemical similarity of compounds and the mean Jaccard values\r\n\r\n##Similarity Threshold:\r\nThe final visualization we created was a series of complex barplots to compare a similarity threshold among the four category groups. The similarity values were replaced with zero or one depending on whether the original value was greater or less than 0.5. Next, contingency tables were created for each category so that relative frequencies could be calculated. \r\n\r\nThe visualization showed that similar compounds are likely to have common targets. For example, if two compounds shared a transporter, they also shared a carrier 25% of the time, compared to 5% of the time if they did not.  This trend continued throughout each of the bar graphs and was particularly notable in the comparisons with similarity. Note that the y-axis’s are labeled differently for easier reading. \r\n\r\n![](https://raw.githubusercontent.com/sabrinalchen/drugbank-similarity/ad3edac94b5c8d00e81395095468c7cce621e9d6/figure/output.png)\r\n#####Figure 3: Illustrates similarity threshold among the drug-protein interaction categories and chemical similarity",
      "comment_id": 338,
      "profile_id": 112,
      "published": "2015-07-28T22:03:29.420605Z",
      "thread_id": 65,
      "url": "/discussion/protein-target-carrier-transporter-and-enzyme-interactions-in-drugbank/65#2"
    },
    {
      "body_html": "<h1>Migration cancelled</h1>\r\n\r\n<p>In the interest of time, we did not switch to owltools. The OWL ecosystem codebases rely on a completely different stack than our current python workflow, and the documentation is often incomplete. We <a href=\"https://github.com/owlcollab/owltools/issues/129\">asked</a> our usage questions on GitHub and will consider migrating in the future with clearer guidance.</p>\r\n\r\n<h1>Updated annotations framework</h1>\r\n\r\n<p>We revamped the analysis behind our <a href=\"http://git.dhimmel.com/gene-ontology/\">user-friendly GO annotation utility</a> <span class=\"citation\">[<a href=\"https://doi.org/10.5281/zenodo.21711\" class=\"citation\" data-key=\"10.5281/zenodo.21711\">1</a>]</span>.</p>\r\n\r\n<p>We made the following changes:</p>\r\n\r\n<ul><li>an option to discard annotations without experimental evidence</li><li>propagation along <code>part_of</code> (as well as <code>is_a</code>) relationships</li><li>direct annotations short-circuit the propagation of conflicting annotations. This occurs only when negative (<code>NOT</code>) and positive annotations conflict.</li><li>exclude terms in the <code>goantislim_grouping</code>, <code>gocheck_do_not_annotate</code>, or <code>gocheck_do_not_manually_annotate</code> subsets</li></ul>\r\n\r\n<p>We removed the \"protein-coding genes only\" option and made a single download with gene identifiers and symbols.</p>",
      "body_md": "# Migration cancelled\r\n\r\nIn the interest of time, we did not switch to owltools. The OWL ecosystem codebases rely on a completely different stack than our current python workflow, and the documentation is often incomplete. We [asked](https://github.com/owlcollab/owltools/issues/129) our usage questions on GitHub and will consider migrating in the future with clearer guidance.\r\n\r\n# Updated annotations framework\r\n\r\nWe revamped the analysis behind our [user-friendly GO annotation utility](http://git.dhimmel.com/gene-ontology/) [@10.5281/zenodo.21711].\r\n\r\nWe made the following changes:\r\n\r\n+ an option to discard annotations without experimental evidence\r\n+ propagation along `part_of` (as well as `is_a`) relationships\r\n+ direct annotations short-circuit the propagation of conflicting annotations. This occurs only when negative (`NOT`) and positive annotations conflict.\r\n+ exclude terms in the `goantislim_grouping`, `gocheck_do_not_annotate`, or `gocheck_do_not_manually_annotate` subsets\r\n\r\nWe removed the \"protein-coding genes only\" option and made a single download with gene identifiers and symbols.",
      "comment_id": 339,
      "profile_id": 17,
      "published": "2015-07-29T17:06:14.274108Z",
      "thread_id": 39,
      "url": "/discussion/compiling-gene-ontology-annotations-into-an-easy-to-use-format/39#8"
    },
    {
      "body_html": "<h1>Phenotype–Disease Associations</h1>\r\n\r\n<p>A recent paper titled \"The Human Phenotype Ontology: Semantic Unification of Common and Rare Disease\" <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.ajhg.2015.05.020\" class=\"citation\" data-key=\"10.1016/j.ajhg.2015.05.020\">1</a>]</span> constructed a catalog of 132,006 phenotypic annotations for common diseases.</p>\r\n\r\n<p>The approach relied on text mining of PubMed abstracts. Abstracts were annotated with diseases using MEDLINE topics. Phenotype annotation, however, relied on concept recognition. Thus the method appears to produce similar results to our <a href=\"http://thinklab.com/discussion/mining-knowledge-from-medline-articles-and-their-indexed-mesh-terms/67#2\">disease–symptom MEDLINE approach</a>. The difference being that their approach achieves greater phenotype/symptom coverage by substituting manual topic annotation with concept recognition.</p>\r\n\r\n<p>The data is <a href=\"http://pubmed-browser.human-phenotype-ontology.org/hp_common_annotations_all.tab\">online</a>. The column names for the dataset, provided by Tudor Groza in personal communication, are:</p>\r\n\r\n<ul><li>MeSH ID</li><li>MeSH descriptor</li><li>Disease Ontology ID</li><li>HPO ID</li><li>HPO label</li><li>Ranking score of the HPO concept in the context of the MeSH term - this is a modified version of TF-IDF (as per the paper)</li><li>Number of Publications containing this association</li><li>5 PMIDs (of the total number listed above) referring to this association</li></ul>\r\n\r\n<p>I am still slightly unclear on what a phenotype means in the context of human disease, but we will keep this dataset on hand.</p>",
      "body_md": "# Phenotype--Disease Associations\r\n\r\nA recent paper titled \"The Human Phenotype Ontology: Semantic Unification of Common and Rare Disease\" [@10.1016/j.ajhg.2015.05.020] constructed a catalog of 132,006 phenotypic annotations for common diseases.\r\n\r\nThe approach relied on text mining of PubMed abstracts. Abstracts were annotated with diseases using MEDLINE topics. Phenotype annotation, however, relied on concept recognition. Thus the method appears to produce similar results to our [disease--symptom MEDLINE approach](http://thinklab.com/discussion/mining-knowledge-from-medline-articles-and-their-indexed-mesh-terms/67#2). The difference being that their approach achieves greater phenotype/symptom coverage by substituting manual topic annotation with concept recognition.\r\n\r\nThe data is [online](http://pubmed-browser.human-phenotype-ontology.org/hp_common_annotations_all.tab). The column names for the dataset, provided by Tudor Groza in personal communication, are:\r\n\r\n* MeSH ID\r\n* MeSH descriptor\r\n* Disease Ontology ID\r\n* HPO ID\r\n* HPO label\r\n* Ranking score of the HPO concept in the context of the MeSH term - this is a modified version of TF-IDF (as per the paper)\r\n* Number of Publications containing this association\r\n* 5 PMIDs (of the total number listed above) referring to this association\r\n\r\nI am still slightly unclear on what a phenotype means in the context of human disease, but we will keep this dataset on hand.",
      "comment_id": 345,
      "profile_id": 17,
      "published": "2015-07-30T20:42:18.764501Z",
      "thread_id": 22,
      "url": "/discussion/suggestions-for-additional-information-types/22#3"
    },
    {
      "body_html": "<p>A recent study <span class=\"citation\">[<a href=\"https://doi.org/10.1038/ng.3314\" class=\"citation\" data-key=\"10.1038/ng.3314\">1</a>]</span> found disease-associated genes are mildly predictive of effective drug targets, which is in line with the findings of a preceding but less rigorous study <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nbt.3183\" class=\"citation\" data-key=\"10.1038/nbt.3183\">2</a>]</span>.</p>\r\n\r\n<p>The data supplement for  \"The support of human genetic evidence for approved drug indications\" contains two potentially useful resources:</p>\r\n\r\n<p><strong>Gene-disease associations</strong> from GWAS and OMIM. Compared to <a href=\"http://dx.doi.org/10.15363/thinklab.d80\">our approach</a> for converting from SNP to gene, their method incorporates experimental genomic evidence.</p>\r\n\r\n<p><strong>Disease-target combinations</strong> extracted from <a href=\"https://citeline.com/products/pharmaprojects/\">Pharmaprojects</a>, a commercial database. As per the paper: </p>\r\n\r\n<blockquote><p>A target was defined as successful in treating an indication if a drug targeting that gene product was approved for the corresponding indication in the United States or the European Union, as annotated in Pharmaprojects.</p></blockquote>\r\n\r\n<p>Unfortunately, this dataset is a step abstracted from the <em>real deal</em> (separate databases of drug targets and drug indications).</p>\r\n\r\n<p>We performed some basic manipulation of their data, which is <a href=\"https://github.com/dhimmel/nelson/blob/af1066df8f8d2b599869864a2a5d7935cf67c1ba/process.ipynb\">available here</a>.</p>",
      "body_md": "A recent study [@10.1038/ng.3314] found disease-associated genes are mildly predictive of effective drug targets, which is in line with the findings of a preceding but less rigorous study [@10.1038/nbt.3183].\r\n\r\nThe data supplement for  \"The support of human genetic evidence for approved drug indications\" contains two potentially useful resources:\r\n\r\n**Gene-disease associations** from GWAS and OMIM. Compared to [our approach](http://dx.doi.org/10.15363/thinklab.d80) for converting from SNP to gene, their method incorporates experimental genomic evidence.\r\n\r\n**Disease-target combinations** extracted from [Pharmaprojects](https://citeline.com/products/pharmaprojects/), a commercial database. As per the paper: \r\n> A target was defined as successful in treating an indication if a drug targeting that gene product was approved for the corresponding indication in the United States or the European Union, as annotated in Pharmaprojects.\r\n\r\nUnfortunately, this dataset is a step abstracted from the *real deal* (separate databases of drug targets and drug indications).\r\n\r\nWe performed some basic manipulation of their data, which is [available here](https://github.com/dhimmel/nelson/blob/af1066df8f8d2b599869864a2a5d7935cf67c1ba/process.ipynb).",
      "comment_id": 346,
      "profile_id": 17,
      "published": "2015-07-31T18:00:29.433790Z",
      "thread_id": 22,
      "url": "/discussion/suggestions-for-additional-information-types/22#4"
    },
    {
      "body_html": "<p>What do you think about implementing high-throughput data from RNA interference screenings? RNAi is an alternative, more precise way to control gene expression and it should have less off-target effects compared to pharmacological inhibition.</p>",
      "body_md": "What do you think about implementing high-throughput data from RNA interference screenings? RNAi is an alternative, more precise way to control gene expression and it should have less off-target effects compared to pharmacological inhibition.",
      "comment_id": 347,
      "profile_id": 82,
      "published": "2015-07-31T20:43:01.711330Z",
      "thread_id": 22,
      "url": "/discussion/suggestions-for-additional-information-types/22#5"
    },
    {
      "body_html": "<h1>Set of anatomy nodes</h1>\r\n\r\n<p>We have settled on 402 Uberon terms to use as our anatomy vocabulary (<a href=\"https://github.com/dhimmel/uberon/blob/134f23479186abba03ba340fc6dc90e16c781920/data/hetio-slim.tsv\">tsv</a>, <a href=\"https://github.com/dhimmel/uberon/blob/134f23479186abba03ba340fc6dc90e16c781920/process.ipynb\">notebook</a>).</p>\r\n\r\n<p>We included terms that met the following conditions:</p>\r\n\r\n<ul><li>were in the <code>uberon_slim</code> subset.</li><li>were not in the <code>non_informative</code>, <code>upper_level</code>, or <code>grouping_class</code> subsets. See this related <a href=\"https://github.com/obophenotype/uberon/issues/1133\">GitHub issue</a>.</li><li>contained a MeSH cross-reference</li><li>were human-relevant based on the <a href=\"#12\">no negative evidence</a> standard.</li></ul>\r\n\r\n<p>We chose a restrictive subset of Uberon terms because the vast extent of tissue-specific gene expression edges can become computationally troubling. We did not include cell types from the Cell Ontology because this ontology lags behind Uberon in terms of subset assignments, cross-references, and documentation.</p>",
      "body_md": "# Set of anatomy nodes\r\n\r\nWe have settled on 402 Uberon terms to use as our anatomy vocabulary ([tsv](https://github.com/dhimmel/uberon/blob/134f23479186abba03ba340fc6dc90e16c781920/data/hetio-slim.tsv), [notebook](https://github.com/dhimmel/uberon/blob/134f23479186abba03ba340fc6dc90e16c781920/process.ipynb)).\r\n\r\nWe included terms that met the following conditions:\r\n\r\n+ were in the `uberon_slim` subset.\r\n+ were not in the `non_informative`, `upper_level`, or `grouping_class` subsets. See this related [GitHub issue](https://github.com/obophenotype/uberon/issues/1133).\r\n+ contained a MeSH cross-reference\r\n+ were human-relevant based on the [no negative evidence](#12) standard.\r\n\r\nWe chose a restrictive subset of Uberon terms because the vast extent of tissue-specific gene expression edges can become computationally troubling. We did not include cell types from the Cell Ontology because this ontology lags behind Uberon in terms of subset assignments, cross-references, and documentation.",
      "comment_id": 349,
      "profile_id": 17,
      "published": "2015-08-03T23:26:00.170473Z",
      "thread_id": 41,
      "url": "/discussion/tissue-node/41#16"
    },
    {
      "body_html": "<h1>Relationship between transcriptional and chemical similarity</h1>\r\n\r\n<p><a href=\"https://github.com/sabrinalchen/drugbank-similarity/blob/master/L1000.ipynb\">Notebook</a></p>\r\n\r\n<h2>Objective:</h2>\r\n\r\n<p>Determine the correlation and visualize the relationship between L1000 transcriptional and chemical compound similarity.</p>\r\n\r\n<h2>The data:</h2>\r\n\r\n<p>We extracted <a href=\"http://files.figshare.com/2166122/consensus_drugbank.tsv.gz\">L1000 perturbation data</a> which lists drug types with perturbation IDs and <a href=\"http://nbviewer.ipython.org/github/dhimmel/drugbank/blob/9eb1e15ada5e6579e5aea1cae784c10602037b05/similarity.ipynb\">similarity data</a> which gives a value between zero and one based on the chemical similarity of a pair of drugs. </p>\r\n\r\n<h2>Jointplot comparing chemical and transcriptional similarities:</h2>\r\n\r\n<p>From the imported L1000 perturbation data, we calculated the spearman correlation values for each combination of pair of drugs. This correlation value was labeled as the \"transcriptional similarity.\" This value was graphed against the imported similarity data for each drug pair. From the Jointplot, (which plots both bivariate data on a hexbin plot and univariate data on a histogram,) we concluded that there was no strong correlation visually. The darkest parts of the hexbin graph were grouped at the bottom left of the grid and the graph showed no real positive pattern. Nevertheless, the graph had an extremely small p-value, indicating significance, and leading to a small effect. </p>\r\n\r\n<p><img src=\"https://raw.githubusercontent.com/sabrinalchen/drugbank-similarity/master/figure/similarity2.png\" alt=\"\"></p>\r\n\r\n<h5>Figure 1: Compares transcriptional similarity for each drug pair and chemical similarity</h5>\r\n\r\n<h2>Rounded chemical similarity pointplot:</h2>\r\n\r\n<p>To visualize the correlation a different way, the chemical similarity data was rounded off to the nearest tenth and the mean transcriptional value was found for each subset. This data was graphed on a pointplot which demonstrated a clear positive correlation, especially when the chemical similarity reached 0.5. After this point, the correlation was even stronger, increasing steadily as the chemical similarity reached 1.0. It should be noted that as the chemical similarity increased, there were less and less data points to be used in graphing. In fact, the last data point where chemical similarity was 1.0 had only a single data point (as seen in the table of rounded values shown in the cell before the pointplot.)</p>\r\n\r\n<p><img src=\"https://raw.githubusercontent.com/sabrinalchen/drugbank-similarity/master/figure/similarity_mean2.png\" alt=\"\"></p>\r\n\r\n<h5>Figure 2: Demonstrates relationship between chemical similarity of compounds and the mean transcriptional similarity values</h5>",
      "body_md": "#Relationship between transcriptional and chemical similarity\r\n\r\n[Notebook](https://github.com/sabrinalchen/drugbank-similarity/blob/master/L1000.ipynb)\r\n\r\n##Objective:\r\nDetermine the correlation and visualize the relationship between L1000 transcriptional and chemical compound similarity.\r\n\r\n##The data:\r\nWe extracted [L1000 perturbation data](\r\nhttp://files.figshare.com/2166122/consensus_drugbank.tsv.gz) which lists drug types with perturbation IDs and [similarity data](http://nbviewer.ipython.org/github/dhimmel/drugbank/blob/9eb1e15ada5e6579e5aea1cae784c10602037b05/similarity.ipynb) which gives a value between zero and one based on the chemical similarity of a pair of drugs. \r\n\r\n##Jointplot comparing chemical and transcriptional similarities:\r\nFrom the imported L1000 perturbation data, we calculated the spearman correlation values for each combination of pair of drugs. This correlation value was labeled as the \"transcriptional similarity.\" This value was graphed against the imported similarity data for each drug pair. From the Jointplot, (which plots both bivariate data on a hexbin plot and univariate data on a histogram,) we concluded that there was no strong correlation visually. The darkest parts of the hexbin graph were grouped at the bottom left of the grid and the graph showed no real positive pattern. Nevertheless, the graph had an extremely small p-value, indicating significance, and leading to a small effect. \r\n\r\n![](https://raw.githubusercontent.com/sabrinalchen/drugbank-similarity/master/figure/similarity2.png)\r\n#####Figure 1: Compares transcriptional similarity for each drug pair and chemical similarity\r\n\r\n##Rounded chemical similarity pointplot:\r\nTo visualize the correlation a different way, the chemical similarity data was rounded off to the nearest tenth and the mean transcriptional value was found for each subset. This data was graphed on a pointplot which demonstrated a clear positive correlation, especially when the chemical similarity reached 0.5. After this point, the correlation was even stronger, increasing steadily as the chemical similarity reached 1.0. It should be noted that as the chemical similarity increased, there were less and less data points to be used in graphing. In fact, the last data point where chemical similarity was 1.0 had only a single data point (as seen in the table of rounded values shown in the cell before the pointplot.)\r\n\r\n![](https://raw.githubusercontent.com/sabrinalchen/drugbank-similarity/master/figure/similarity_mean2.png)\r\n#####Figure 2: Demonstrates relationship between chemical similarity of compounds and the mean transcriptional similarity values",
      "comment_id": 350,
      "profile_id": 112,
      "published": "2015-08-03T23:33:50.805103Z",
      "thread_id": 70,
      "url": "/discussion/calculating-molecular-similarities-between-drugbank-compounds/70#2"
    },
    {
      "body_html": "<p>Great work <a href=\"/u/sabrinachen\" class=\"username\">@sabrinachen</a>! Your analysis reveals many interesting findings.</p>\r\n\r\n<p>First, chemical similarity is a strong indicator that two compounds share a target (Figure 2). One of the most successful target prediction algorithms, named the Similarity Ensemble Approach (SEA) <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nature08506\" class=\"citation\" data-key=\"10.1038/nature08506\">1</a>]</span>, is based on this very observation. Our data shows an enrichment of shared protein interactions above a chemical similarity threshold of 0.5. Interestingly, when binarizing chemical similarity scores, SEA also chose a cutoff of 0.5 (<a href=\"http://salilab.org/~nkhuri/files/systems-pharmacology-lecture4-01262015.pdf#page=19\">source</a>).</p>\r\n\r\n<p>Second, when two proteins share proteins of a specific category, they are more likely to share proteins of other categories (Figure 3). For example, when two compounds share a transporter, they have a 14% chance of sharing an enzyme, compared to 3% otherwise. This trend applies to all categories but is most pronounced between chemical similarity and target similarity.</p>\r\n\r\n<p>Finally, it would be interesting to know how many compound pairs were included for each chemical similarity bin in Figure 2.</p>",
      "body_md": "Great work @sabrinachen! Your analysis reveals many interesting findings.\r\n\r\nFirst, chemical similarity is a strong indicator that two compounds share a target (Figure 2). One of the most successful target prediction algorithms, named the Similarity Ensemble Approach (SEA) [@10.1038/nature08506], is based on this very observation. Our data shows an enrichment of shared protein interactions above a chemical similarity threshold of 0.5. Interestingly, when binarizing chemical similarity scores, SEA also chose a cutoff of 0.5 ([source](http://salilab.org/~nkhuri/files/systems-pharmacology-lecture4-01262015.pdf#page=19)).\r\n\r\nSecond, when two proteins share proteins of a specific category, they are more likely to share proteins of other categories (Figure 3). For example, when two compounds share a transporter, they have a 14% chance of sharing an enzyme, compared to 3% otherwise. This trend applies to all categories but is most pronounced between chemical similarity and target similarity.\r\n\r\nFinally, it would be interesting to know how many compound pairs were included for each chemical similarity bin in Figure 2.",
      "comment_id": 351,
      "profile_id": 17,
      "published": "2015-08-04T18:40:15.210241Z",
      "thread_id": 65,
      "url": "/discussion/protein-target-carrier-transporter-and-enzyme-interactions-in-drugbank/65#3"
    },
    {
      "body_html": "<p>Nice analysis. Chemical similarity appears to be a <em>weak</em> predictor of transcriptional similarity (Figure 1, <span class=\"math\">$$\\rho = 0.02, p = 10 ^ {-66}$$</span>). However, this correlation is highly influenced by the majority of compound pairs where chemical similarity is less than 0.5. As we have <a href=\"http://thinklab.com/discussion/protein-target-carrier-transporter-and-enzyme-interactions-in-drugbank/65#3\">previously noticed</a>, chemical similarity becomes predictive of other types of similarity above 0.5. As seen in Figure 2, the same trend applies to transcriptional similarity. Therefore, within the meaningful range of chemical similarity values, the association looks stronger.</p>\r\n\r\n<p>Nice catch that the highest bin (chemical similarity ≥ 0.95) only has a single compound pair. This is due to our <a href=\"http://thinklab.com/discussion/unifying-drug-vocabularies/40#5\">selection criteria</a> for compounds which aims to avoid redundancy. We have computed chemical similarities for the entire LINCS L1000 perturbation set, so we could rerun this analysis with all perturbagens.</p>",
      "body_md": "Nice analysis. Chemical similarity appears to be a *weak* predictor of transcriptional similarity (Figure 1, $$\\rho = 0.02, p = 10 ^ {-66}$$). However, this correlation is highly influenced by the majority of compound pairs where chemical similarity is less than 0.5. As we have [previously noticed](http://thinklab.com/discussion/protein-target-carrier-transporter-and-enzyme-interactions-in-drugbank/65#3), chemical similarity becomes predictive of other types of similarity above 0.5. As seen in Figure 2, the same trend applies to transcriptional similarity. Therefore, within the meaningful range of chemical similarity values, the association looks stronger.\r\n\r\nNice catch that the highest bin (chemical similarity ≥ 0.95) only has a single compound pair. This is due to our [selection criteria](http://thinklab.com/discussion/unifying-drug-vocabularies/40#5) for compounds which aims to avoid redundancy. We have computed chemical similarities for the entire LINCS L1000 perturbation set, so we could rerun this analysis with all perturbagens.",
      "comment_id": 352,
      "profile_id": 17,
      "published": "2015-08-04T19:13:17.098008Z",
      "thread_id": 70,
      "url": "/discussion/calculating-molecular-similarities-between-drugbank-compounds/70#3"
    },
    {
      "body_html": "<h1>Chemical similarity association with side effect and indication similarity</h1>\r\n\r\n<p><a href=\"https://github.com/sabrinalchen/drugbank-similarity/blob/master/side-effect.ipynb\">Notebook</a></p>\r\n\r\n<h2>Objective:</h2>\r\n\r\n<p>To determine the relationship between side effect similarity and chemical similarity as well as drug indication and chemical similarity</p>\r\n\r\n<h2>Data:</h2>\r\n\r\n<p>We extracted <a href=\"https://github.com/dhimmel/SIDER2/blob/9d585685dbeaba3bbac58024c814ac87521122ad/data/similarities.txt.gz\">side effect and indication similarity data</a> which lists drug pairs (pubchem ID,) and their associated side effect similarity and indication similarity. Side effect similarity deals with the similarity of the side effect when a drug is used to treat a protein. Indication is the term doctors use when a drug treats a disease.In addition, <a href=\"https://github.com/dhimmel/drugbank/blob/e8567eed2dd48ae0694a0960c518763a777845ff/data/mapping/pubchem.tsv\">drugbank data</a> was extracted to convert pubchem ID into drugbank ID. Finally, we extracted <a href=\"http://nbviewer.ipython.org/github/dhimmel/drugbank/blob/9eb1e15ada5e6579e5aea1cae784c10602037b05/similarity.ipynb\">chemical similarity data</a> which gives a value between zero and one based on the chemical similarity of a pair of drugs. </p>\r\n\r\n<h2>Chemical similarity vs substructure jointplot</h2>\r\n\r\n<p>As predicted, a positive correlation was found between these two variables. It seemed from the graph that the two were strongly correlated, especially since the p-value was zero. An interesting trend to note was that the data seemed to be banded and centered around certain values. The smaller bands could be due to the fact that substructure data was rounded off to the nearest hundredth place. However, we are not sure of what the large horizontal bands indicate. </p>\r\n\r\n<p><img src=\"https://raw.githubusercontent.com/sabrinalchen/drugbank-similarity/master/figure/substructure.png\" alt=\"\"></p>\r\n\r\n<h5>Figure 1: Compares chemical similarity to substructure and demonstrates a positive correlation</h5>\r\n\r\n<h2>Chemical similarity vs side effect similarity jointplot</h2>\r\n\r\n<p>The graph demonstrated a positive correlation between chemical compound similarity and side effect similarity. To make it easier to read, we took the square root of side effect similarity values and also used logarithmic bins. With the data transformed this way, the correlation was clearer.  Though the correlation coefficient was less than that of the previous comparison, the p-value was zero. </p>\r\n\r\n<p><img src=\"https://raw.githubusercontent.com/sabrinalchen/drugbank-similarity/master/figure/side_effect.png\" alt=\"\"></p>\r\n\r\n<h5>Figure 2: Compares chemical similarity to side effect similarity</h5>\r\n\r\n<h2>Chemical similarity vs indication similarity jointplot</h2>\r\n\r\n<p>Though this graph was slightly harder to read than the previous two because of the skewed indication similarity data, the zero p-value showed some degree of significance. Most of the indication values were zero, so even by taking the square root of the values, it was difficult to visualize the positive correlation. We decided to use a different visualization for clearer analysis (see pointplot below.)</p>\r\n\r\n<p><img src=\"https://raw.githubusercontent.com/sabrinalchen/drugbank-similarity/master/figure/indication.png\" alt=\"\"></p>\r\n\r\n<h5>Figure 3: Compares chemical similarity to indication similarity</h5>\r\n\r\n<h2>Pointplot</h2>\r\n\r\n<p>Because the correlation was a bit difficult to read in previous graphs (especially in the indication jointplot,) we used a pointplot for a different visualization. The chemical similarity data was rounded off to the nearest tenth and the mean values for both side effect similarity and indication similarity was found for each subset. This data was graphed on a pointplot which demonstrated a clear positive correlation, especially when the chemical similarity passed 0.4. For the side effect similarity, it was easy to see a steady positive correlation, apart from the fall between 0.9 and 1.0 on the chemical similarity axis. This could be attributed to the small number of data points, however. For the indication similarity, the graph showed no real correlation between 0.0 and 0.3, but a steady upward trend began starting from 0.4. From our graphs we concluded that increased chemical compound similarity did indeed indicate an increase for side effect similarity and indication similarity.</p>\r\n\r\n<p><img src=\"https://raw.githubusercontent.com/sabrinalchen/drugbank-similarity/master/figure/combined_similarity_mean.png\" alt=\"\"></p>\r\n\r\n<h5>Figure 4: A clearer representation of the association between chemical compound similarity and side effect and indication similarity</h5>",
      "body_md": "#Chemical similarity association with side effect and indication similarity\r\n\r\n[Notebook](https://github.com/sabrinalchen/drugbank-similarity/blob/master/side-effect.ipynb)\r\n\r\n##Objective:\r\nTo determine the relationship between side effect similarity and chemical similarity as well as drug indication and chemical similarity\r\n\r\n##Data:\r\nWe extracted [side effect and indication similarity data](https://github.com/dhimmel/SIDER2/blob/9d585685dbeaba3bbac58024c814ac87521122ad/data/similarities.txt.gz) which lists drug pairs (pubchem ID,) and their associated side effect similarity and indication similarity. Side effect similarity deals with the similarity of the side effect when a drug is used to treat a protein. Indication is the term doctors use when a drug treats a disease.In addition, [drugbank data](https://github.com/dhimmel/drugbank/blob/e8567eed2dd48ae0694a0960c518763a777845ff/data/mapping/pubchem.tsv) was extracted to convert pubchem ID into drugbank ID. Finally, we extracted [chemical similarity data](http://nbviewer.ipython.org/github/dhimmel/drugbank/blob/9eb1e15ada5e6579e5aea1cae784c10602037b05/similarity.ipynb) which gives a value between zero and one based on the chemical similarity of a pair of drugs. \r\n\r\n##Chemical similarity vs substructure jointplot\r\nAs predicted, a positive correlation was found between these two variables. It seemed from the graph that the two were strongly correlated, especially since the p-value was zero. An interesting trend to note was that the data seemed to be banded and centered around certain values. The smaller bands could be due to the fact that substructure data was rounded off to the nearest hundredth place. However, we are not sure of what the large horizontal bands indicate. \r\n\r\n![](https://raw.githubusercontent.com/sabrinalchen/drugbank-similarity/master/figure/substructure.png)\r\n#####Figure 1: Compares chemical similarity to substructure and demonstrates a positive correlation\r\n\r\n##Chemical similarity vs side effect similarity jointplot\r\nThe graph demonstrated a positive correlation between chemical compound similarity and side effect similarity. To make it easier to read, we took the square root of side effect similarity values and also used logarithmic bins. With the data transformed this way, the correlation was clearer.  Though the correlation coefficient was less than that of the previous comparison, the p-value was zero. \r\n\r\n![](https://raw.githubusercontent.com/sabrinalchen/drugbank-similarity/master/figure/side_effect.png)\r\n#####Figure 2: Compares chemical similarity to side effect similarity\r\n\r\n##Chemical similarity vs indication similarity jointplot\r\nThough this graph was slightly harder to read than the previous two because of the skewed indication similarity data, the zero p-value showed some degree of significance. Most of the indication values were zero, so even by taking the square root of the values, it was difficult to visualize the positive correlation. We decided to use a different visualization for clearer analysis (see pointplot below.)\r\n\r\n![](https://raw.githubusercontent.com/sabrinalchen/drugbank-similarity/master/figure/indication.png)\r\n#####Figure 3: Compares chemical similarity to indication similarity\r\n\r\n##Pointplot \r\nBecause the correlation was a bit difficult to read in previous graphs (especially in the indication jointplot,) we used a pointplot for a different visualization. The chemical similarity data was rounded off to the nearest tenth and the mean values for both side effect similarity and indication similarity was found for each subset. This data was graphed on a pointplot which demonstrated a clear positive correlation, especially when the chemical similarity passed 0.4. For the side effect similarity, it was easy to see a steady positive correlation, apart from the fall between 0.9 and 1.0 on the chemical similarity axis. This could be attributed to the small number of data points, however. For the indication similarity, the graph showed no real correlation between 0.0 and 0.3, but a steady upward trend began starting from 0.4. From our graphs we concluded that increased chemical compound similarity did indeed indicate an increase for side effect similarity and indication similarity.\r\n\r\n![](https://raw.githubusercontent.com/sabrinalchen/drugbank-similarity/master/figure/combined_similarity_mean.png)\r\n#####Figure 4: A clearer representation of the association between chemical compound similarity and side effect and indication similarity",
      "comment_id": 353,
      "profile_id": 112,
      "published": "2015-08-04T21:19:36.253694Z",
      "thread_id": 30,
      "url": "/discussion/assessing-the-quality-and-applicability-of-the-sider-2-resource/30#3"
    },
    {
      "body_html": "<p>I contacted Mike Keiser, the human intellect behind SEA, regarding chemical similarity thresholding. Below and with permission, I've posted his reply to our <a href=\"#3\">above</a> comment:</p>\r\n\r\n<blockquote><p>The <a href=\"http://salilab.org/~nkhuri/files/systems-pharmacology-lecture4-01262015.pdf#page=19\">0.5 measure</a> refers to a tanimoto coefficient on daylight path-based fingerprints. It'd be in the supplemental materials and/or methods of Keiser et al, Nat Biotechnol, 2007 <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nbt1284\" class=\"citation\" data-key=\"10.1038/nbt1284\">1</a>]</span>. So I think the closest equivalent in rdkit would be tanimoto instead of dice coefficient, or rdkit-path fingerprints. Using ECFP4 (i.e., Morgan with radius 2 in rdkit) and a tanimoto coefficient, we found cutoffs more around 0.28 (the range can vary pretty substantially depending on fingerprint type used). In general, 0.5 is considered pretty high similarity for ECFP/Morgan fingerprints at least with tanimoto coefficients (I'm less sure of the Dice coefficient equivalents, off-hand).</p></blockquote>",
      "body_md": "I contacted Mike Keiser, the human intellect behind SEA, regarding chemical similarity thresholding. Below and with permission, I've posted his reply to our [above](#3) comment:\r\n\r\n> The [0.5 measure](http://salilab.org/~nkhuri/files/systems-pharmacology-lecture4-01262015.pdf#page=19) refers to a tanimoto coefficient on daylight path-based fingerprints. It'd be in the supplemental materials and/or methods of Keiser et al, Nat Biotechnol, 2007 [@10.1038/nbt1284]. So I think the closest equivalent in rdkit would be tanimoto instead of dice coefficient, or rdkit-path fingerprints. Using ECFP4 (i.e., Morgan with radius 2 in rdkit) and a tanimoto coefficient, we found cutoffs more around 0.28 (the range can vary pretty substantially depending on fingerprint type used). In general, 0.5 is considered pretty high similarity for ECFP/Morgan fingerprints at least with tanimoto coefficients (I'm less sure of the Dice coefficient equivalents, off-hand).",
      "comment_id": 354,
      "profile_id": 17,
      "published": "2015-08-05T20:35:16.257715Z",
      "thread_id": 65,
      "url": "/discussion/protein-target-carrier-transporter-and-enzyme-interactions-in-drugbank/65#4"
    },
    {
      "body_html": "<p>Please note that <a href=\"http://sider-beta.embl.de/\">SIDER 4</a> has just been released.</p>\r\n\r\n<p>Before anyone asks: no there has never been a SIDER 3. We decided to jump to version 4 to make SIDER version numbers consistent with STITCH. This means that compound IDs of SIDER 4 are consistent with those of STITCH 4, and that SIDER 5 will be consistent with STITCH 5 etc.</p>\r\n\r\n<p>I am a bit surprised to see that you use SIDER as a source of drug indications. As is hopefully clear, the focus of SIDER is very much on side effect information. It should thus be no surprise that the quality of the drug indication information is presumably lower than the side effect information.</p>",
      "body_md": "Please note that [SIDER 4](http://sider-beta.embl.de/) has just been released.\r\n\r\nBefore anyone asks: no there has never been a SIDER 3. We decided to jump to version 4 to make SIDER version numbers consistent with STITCH. This means that compound IDs of SIDER 4 are consistent with those of STITCH 4, and that SIDER 5 will be consistent with STITCH 5 etc.\r\n\r\nI am a bit surprised to see that you use SIDER as a source of drug indications. As is hopefully clear, the focus of SIDER is very much on side effect information. It should thus be no surprise that the quality of the drug indication information is presumably lower than the side effect information.",
      "comment_id": 356,
      "profile_id": 125,
      "published": "2015-08-08T16:15:09.942557Z",
      "thread_id": 30,
      "url": "/discussion/assessing-the-quality-and-applicability-of-the-sider-2-resource/30#4"
    },
    {
      "body_html": "<p>It may be worth noting that the work on SIDER actually started as part of a drug-repurposing / off-target-prediction project at EMBL <span class=\"citation\">[<a href=\"https://doi.org/10.1126/science.1158140\" class=\"citation\" data-key=\"10.1126/science.1158140\">1</a>]</span>.</p>\r\n\r\n<p>I do not want to be overly negative, but there is a reason why we only made use of side effects and not indications to calculate drug similarity: it seems very unlikely to me that you would be able to make non-obvious predictions based on the known indications. If drug X is approved for indications A, B, C and D, and drug Y is approved for indications A, B and C, I would consider the prediction that drug Y might also work for indication D to be trivial. Especially if drugs X and Y are similar chemical compounds.</p>\r\n\r\n<p>I believe this is the biggest challenge in computational drug repurposing: how do you predict something that is correct and not obvious? In my experience, this turns out to be much, much harder than to predict something that is just correct.</p>",
      "body_md": "It may be worth noting that the work on SIDER actually started as part of a drug-repurposing / off-target-prediction project at EMBL [@10.1126/science.1158140].\r\n\r\nI do not want to be overly negative, but there is a reason why we only made use of side effects and not indications to calculate drug similarity: it seems very unlikely to me that you would be able to make non-obvious predictions based on the known indications. If drug X is approved for indications A, B, C and D, and drug Y is approved for indications A, B and C, I would consider the prediction that drug Y might also work for indication D to be trivial. Especially if drugs X and Y are similar chemical compounds.\r\n\r\nI believe this is the biggest challenge in computational drug repurposing: how do you predict something that is correct and not obvious? In my experience, this turns out to be much, much harder than to predict something that is just correct.",
      "comment_id": 357,
      "profile_id": 125,
      "published": "2015-08-08T16:18:22.874851Z",
      "thread_id": 30,
      "url": "/discussion/assessing-the-quality-and-applicability-of-the-sider-2-resource/30#5"
    },
    {
      "body_html": "<p>The TISSUES resource uses the proteins in the latest version of <a href=\"http://string-db.org/\">STRING</a> as baseline. If you need to map the <a href=\"http://www.ensembl.org/\">Ensembl</a> protein identifiers to other database identifiers, the best thing to do is thus to use either the <a href=\"http://string-db.org/newstring_download/protein.aliases.v10.txt.gz\">STRING alias file</a> or one of the specific mapping files available <a href=\"ftp://string-db.org/STRING/10.0/mapping_files/\">here</a>.</p>",
      "body_md": "The TISSUES resource uses the proteins in the latest version of [STRING](http://string-db.org/) as baseline. If you need to map the [Ensembl](http://www.ensembl.org/) protein identifiers to other database identifiers, the best thing to do is thus to use either the [STRING alias file](http://string-db.org/newstring_download/protein.aliases.v10.txt.gz) or one of the specific mapping files available [here](ftp://string-db.org/STRING/10.0/mapping_files/).",
      "comment_id": 358,
      "profile_id": 125,
      "published": "2015-08-08T16:28:14.150286Z",
      "thread_id": 91,
      "url": "/discussion/the-tissues-resource-for-the-tissue-specificity-of-genes/91#2"
    },
    {
      "body_html": "<p>Introducing a score cutoff does not sound like the right way to go about it to me. The problem is that there is no right cutoff; wherever you put it, what scores just above the cutoff is almost exactly as reliable as what scores just below the cutoff.</p>\r\n\r\n<p>I know that life is much simpler if you do not have to deal with confidence scores. However, the moment you take associations with confidence scores and make them binary by applying an arbitrary cutoff, you are throwing away information. For this reason, you will almost always be better off having a method that can deal with confidence scores in a sensible manner and only apply a cutoff on your predictions in the very end after all available evidence has been combined.</p>",
      "body_md": "Introducing a score cutoff does not sound like the right way to go about it to me. The problem is that there is no right cutoff; wherever you put it, what scores just above the cutoff is almost exactly as reliable as what scores just below the cutoff.\r\n\r\nI know that life is much simpler if you do not have to deal with confidence scores. However, the moment you take associations with confidence scores and make them binary by applying an arbitrary cutoff, you are throwing away information. For this reason, you will almost always be better off having a method that can deal with confidence scores in a sensible manner and only apply a cutoff on your predictions in the very end after all available evidence has been combined.",
      "comment_id": 359,
      "profile_id": 125,
      "published": "2015-08-08T16:28:42.632510Z",
      "thread_id": 91,
      "url": "/discussion/the-tissues-resource-for-the-tissue-specificity-of-genes/91#3"
    },
    {
      "body_html": "<p><a href=\"/u/larsjuhljensen\" class=\"username\">@larsjuhljensen</a>, great timing and thanks for the heads up!</p>\r\n\r\n<blockquote><p>I am a bit surprised to see that you use SIDER as a source of drug indications.</p></blockquote>\r\n\r\n<p>SIDER was one of the first resources we played with for this project. At the time, we decided to investigate the indications because 1) they were there and 2) we were unaware of other indication databases.</p>\r\n\r\n<p>Since then we've spent considerable time on <a href=\"http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d21\">creating a catalog of indications</a>. We ended up combining four indication databases, one of which (<a href=\"http://knowledgemap.mc.vanderbilt.edu/research/content/MEDI\">MEDI</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1136/amiajnl-2014-002954\" class=\"citation\" data-key=\"10.1136/amiajnl-2014-002954\">1</a>]</span>) uses SIDER 2 as an input. We have now moved on to a final stage of <a href=\"http://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d95\">expert curation</a>.</p>\r\n\r\n<blockquote><p>it seems very unlikely to me that you would be able to make non-obvious predictions based on the known indications.</p></blockquote>\r\n\r\n<p>Our heterogeneous network edge prediction <a href=\"http://het.io/hnep/\">method</a> is a supervised method. Therefore, we need efficacious indications to train our model. However, I do have hope for some metapaths containing an indication metaedge to produce non-obvious predictions. For example, </p>\r\n\r\n<ul><li>disease A has 3 indicated drugs (X, Y, Z)</li><li>X, Y, Z elicit similar transcriptional responses (in <a href=\"http://thinklab.com/discussion/computing-consensus-transcriptional-profiles-for-compounds-using-lincs/43\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d43\">LINCS L1000 data</a>)</li><li>W elicits a similar transcriptional response to X, Y, and Z</li><li>drug W may treat disease A</li></ul>\r\n\r\n<p>I agree that repurposing using only the bipartite indication network will produce mostly obvious predictions. However, our approach is capable of much more!</p>",
      "body_md": "@larsjuhljensen, great timing and thanks for the heads up!\r\n\r\n> I am a bit surprised to see that you use SIDER as a source of drug indications.\r\n\r\nSIDER was one of the first resources we played with for this project. At the time, we decided to investigate the indications because 1) they were there and 2) we were unaware of other indication databases.\r\n\r\nSince then we've spent considerable time on [creating a catalog of indications](http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21). We ended up combining four indication databases, one of which ([MEDI](http://knowledgemap.mc.vanderbilt.edu/research/content/MEDI) [@10.1136/amiajnl-2014-002954]) uses SIDER 2 as an input. We have now moved on to a final stage of [expert curation](http://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95).\r\n\r\n> it seems very unlikely to me that you would be able to make non-obvious predictions based on the known indications.\r\n\r\nOur heterogeneous network edge prediction [method](http://het.io/hnep/) is a supervised method. Therefore, we need efficacious indications to train our model. However, I do have hope for some metapaths containing an indication metaedge to produce non-obvious predictions. For example, \r\n\r\n+ disease A has 3 indicated drugs (X, Y, Z)\r\n+ X, Y, Z elicit similar transcriptional responses (in [LINCS L1000 data](http://thinklab.com/discussion/computing-consensus-transcriptional-profiles-for-compounds-using-lincs/43))\r\n+ W elicits a similar transcriptional response to X, Y, and Z\r\n+ drug W may treat disease A\r\n\r\nI agree that repurposing using only the bipartite indication network will produce mostly obvious predictions. However, our approach is capable of much more!",
      "comment_id": 360,
      "profile_id": 17,
      "published": "2015-08-08T16:39:10.962107Z",
      "thread_id": 30,
      "url": "/discussion/assessing-the-quality-and-applicability-of-the-sider-2-resource/30#6"
    },
    {
      "body_html": "<blockquote><p>Introducing a score cutoff does not sound like the right way to go about it to me.</p></blockquote>\r\n\r\n<p>I totally agree that cutoffs are suboptimal because they require arbitrary decision-making, conflate levels of confidence, and throw away information. In the long term, we hope to modify our method to enable weighted edge and to investigate other methods that allow weights (such as data fusion <span class=\"citation\">[<a href=\"https://doi.org/10.1109/TPAMI.2014.2343973\" class=\"citation\" data-key=\"10.1109/TPAMI.2014.2343973\">1</a>, <a href=\"https://doi.org/10.1038/srep03202\" class=\"citation\" data-key=\"10.1038/srep03202\">2</a>]</span>). However, in the short term, I want to proceed with unweighted edges and understand the sacrifice.</p>\r\n\r\n<p><a href=\"/u/larsjuhljensen\" class=\"username\">@larsjuhljensen</a>, you may disagree with implementing cutoffs, but by providing \"confidence scores that are comparable between datasets\" <span class=\"citation\">[<a href=\"https://doi.org/10.7717/peerj.1054\" class=\"citation\" data-key=\"10.7717/peerj.1054\">3</a>]</span>, you have made the life of binners like me much more pleasant (:</p>\r\n\r\n<p>For the experimental dataset from TISSUES, one cutoff I envision is 2 or more sources reporting scores ≥ 3 per gene–tissue relation. Does this sound reasonable?</p>\r\n\r\n<blockquote><p>The TISSUES resource uses the proteins in the latest version of STRING as baseline.</p></blockquote>\r\n\r\n<p>We have begun processing the TISSUES datasets (<a href=\"https://github.com/dhimmel/tissues/blob/b7711d18e51ff1a8e91837354415d271bf975907/tissues.ipynb\">notebook</a>). I was mapping Ensembl proteins using <a href=\"https://github.com/hammerlab/pyensembl\"><code>pyensembl</code></a>, but will switch to the <a href=\"ftp://string-db.org/STRING/10.0/mapping_files/entrez_mappings/\">mapping</a> suggested by <a href=\"/u/larsjuhljensen\" class=\"username\">@larsjuhljensen</a>.</p>",
      "body_md": "> Introducing a score cutoff does not sound like the right way to go about it to me.\r\n\r\nI totally agree that cutoffs are suboptimal because they require arbitrary decision-making, conflate levels of confidence, and throw away information. In the long term, we hope to modify our method to enable weighted edge and to investigate other methods that allow weights (such as data fusion [@10.1109/TPAMI.2014.2343973 @10.1038/srep03202]). However, in the short term, I want to proceed with unweighted edges and understand the sacrifice.\r\n\r\n@larsjuhljensen, you may disagree with implementing cutoffs, but by providing \"confidence scores that are comparable between datasets\" [@10.7717/peerj.1054], you have made the life of binners like me much more pleasant (:\r\n\r\nFor the experimental dataset from TISSUES, one cutoff I envision is 2 or more sources reporting scores ≥ 3 per gene--tissue relation. Does this sound reasonable?\r\n\r\n> The TISSUES resource uses the proteins in the latest version of STRING as baseline.\r\n\r\nWe have begun processing the TISSUES datasets ([notebook](https://github.com/dhimmel/tissues/blob/b7711d18e51ff1a8e91837354415d271bf975907/tissues.ipynb)). I was mapping Ensembl proteins using [`pyensembl`](https://github.com/hammerlab/pyensembl), but will switch to the [mapping](ftp://string-db.org/STRING/10.0/mapping_files/entrez_mappings/) suggested by @larsjuhljensen.",
      "comment_id": 361,
      "profile_id": 17,
      "published": "2015-08-08T17:15:00.985960Z",
      "thread_id": 91,
      "url": "/discussion/the-tissues-resource-for-the-tissue-specificity-of-genes/91#4"
    },
    {
      "body_html": "<p>My gut feeling is that your cutoff is too stringent. If you want support from at least two different experimental datasets, I would not put the cutoff at 3. I would at most put it at 2.</p>\r\n\r\n<p>However, I think there are more fundamental problems with that approach than just the numeric cutoff. Not all tissues were included in all datasets. This means that some tissues will be entirely lost if you require support from two datasets. Also, I do not understand why you would want to exclude the other channels (knowledge and text mining). Having, for example, text mining to support something that would otherwise be based on only a single dataset is very valuable.</p>\r\n\r\n<p>If you want to enforce a hard cutoff to make things binary, I would urge you to at least take the integrated scores that takes everything into account and apply the cutoff to that. In this case a score of 3 might be appropriate. Applying cutoffs to the scores of individual datasets before combining them is in my opinion a fundamentally bad idea.</p>",
      "body_md": "My gut feeling is that your cutoff is too stringent. If you want support from at least two different experimental datasets, I would not put the cutoff at 3. I would at most put it at 2.\r\n\r\nHowever, I think there are more fundamental problems with that approach than just the numeric cutoff. Not all tissues were included in all datasets. This means that some tissues will be entirely lost if you require support from two datasets. Also, I do not understand why you would want to exclude the other channels (knowledge and text mining). Having, for example, text mining to support something that would otherwise be based on only a single dataset is very valuable.\r\n\r\nIf you want to enforce a hard cutoff to make things binary, I would urge you to at least take the integrated scores that takes everything into account and apply the cutoff to that. In this case a score of 3 might be appropriate. Applying cutoffs to the scores of individual datasets before combining them is in my opinion a fundamentally bad idea.",
      "comment_id": 362,
      "profile_id": 125,
      "published": "2015-08-08T17:41:25.920080Z",
      "thread_id": 91,
      "url": "/discussion/the-tissues-resource-for-the-tissue-specificity-of-genes/91#5"
    },
    {
      "body_html": "<h1>Initial release of consensus signatures</h1>\r\n\r\n<p>We have computed consensus transcriptional signatures for LINCS L1000 perturbations. We have released <a href=\"https://github.com/dhimmel/lincs/tree/b36dfd82b6b1aa0b0c45ec905cb2548ddf7dc53e/data/consensi\">datasets</a> <span class=\"citation\">[<a href=\"https://doi.org/10.5281/zenodo.27229\" class=\"citation\" data-key=\"10.5281/zenodo.27229\">1</a>]</span> for the following pertubation sets:</p>\r\n\r\n<ul><li>LINCS pert_ids: 38,327 consensi (<a href=\"https://github.com/dhimmel/lincs/blob/b36dfd82b6b1aa0b0c45ec905cb2548ddf7dc53e/data/consensi/consensi-pert_id.tsv.gz\">download</a>)</li><li>DrugBank compounds: 1,170 consensi (<a href=\"https://github.com/dhimmel/lincs/blob/b36dfd82b6b1aa0b0c45ec905cb2548ddf7dc53e/data/consensi/consensi-drugbank.tsv.gz\">download</a>)</li><li>Gene knockdowns: 4,363 consensi (<a href=\"https://github.com/dhimmel/lincs/blob/b36dfd82b6b1aa0b0c45ec905cb2548ddf7dc53e/data/consensi/consensi-knockdown.tsv.gz\">download</a>)</li><li>Gene over-expressions: 2,471 consensi (<a href=\"https://github.com/dhimmel/lincs/blob/b36dfd82b6b1aa0b0c45ec905cb2548ddf7dc53e/data/consensi/consensi-overexpression.tsv.gz\">download</a>)</li></ul>\r\n\r\n<p>The datasets are tsv-formatted with perturbations as rows and genes as columns. We only report expression values for the 978 assayed genes. Non-gold signatures were omitted. We set a <a href=\"#4\">minimum signature weight</a> of 0.05 and combined z-scores using <a href=\"#5\">Stouffer's method</a>.</p>",
      "body_md": "# Initial release of consensus signatures\r\n\r\nWe have computed consensus transcriptional signatures for LINCS L1000 perturbations. We have released [datasets](https://github.com/dhimmel/lincs/tree/b36dfd82b6b1aa0b0c45ec905cb2548ddf7dc53e/data/consensi) [@10.5281/zenodo.27229] for the following pertubation sets:\r\n\r\n+ LINCS pert_ids: 38,327 consensi ([download](https://github.com/dhimmel/lincs/blob/b36dfd82b6b1aa0b0c45ec905cb2548ddf7dc53e/data/consensi/consensi-pert_id.tsv.gz))\r\n+ DrugBank compounds: 1,170 consensi ([download](https://github.com/dhimmel/lincs/blob/b36dfd82b6b1aa0b0c45ec905cb2548ddf7dc53e/data/consensi/consensi-drugbank.tsv.gz))\r\n+ Gene knockdowns: 4,363 consensi ([download](https://github.com/dhimmel/lincs/blob/b36dfd82b6b1aa0b0c45ec905cb2548ddf7dc53e/data/consensi/consensi-knockdown.tsv.gz))\r\n+ Gene over-expressions: 2,471 consensi ([download](https://github.com/dhimmel/lincs/blob/b36dfd82b6b1aa0b0c45ec905cb2548ddf7dc53e/data/consensi/consensi-overexpression.tsv.gz))\r\n\r\nThe datasets are tsv-formatted with perturbations as rows and genes as columns. We only report expression values for the 978 assayed genes. Non-gold signatures were omitted. We set a [minimum signature weight](#4) of 0.05 and combined z-scores using [Stouffer's method](#5).",
      "comment_id": 363,
      "profile_id": 17,
      "published": "2015-08-08T20:12:51.051081Z",
      "thread_id": 43,
      "url": "/discussion/computing-consensus-transcriptional-profiles-for-lincs-l1000-perturbations/43#6"
    },
    {
      "body_html": "<h1>Genetic perturbation edges</h1>\r\n\r\n<p><a href=\"/u/alessandrodidonna\" class=\"username\">@alessandrodidonna</a>, thanks for the recommendation. You have motivated to us to add four new gene–gene metaedges:</p>\r\n\r\n<ul><li>Gene → knockdown downregulates → Gene</li><li>Gene → knockdown upregulates → Gene</li><li>Gene → overexpression downregulates → Gene</li><li>Gene → overexpression upregulates → Gene</li></ul>\r\n\r\n<p>These will be our first directed edges, so it will be exciting to stress test our support for directed edges, a feature that we <a href=\"https://github.com/dhimmel/hetio/blob/340b5f3572e29a766cb103b0883796323f983e97/hetio/graph.py#L322\">designed</a> our implementation to support.</p>\r\n\r\n<p>We'll be taking the data from <a href=\"http://www.lincscloud.org/\">LINCS L1000</a> which contains a large number of genetic perturbation experiments:</p>\r\n\r\n<p><img src=\"https://raw.githubusercontent.com/dhimmel/rephetio/b4ccfe08be839a4caa4b4a0e2b918b03d50cde65/figure/lincs-l1000-synopsys.png\" alt=\"\"></p>\r\n\r\n<p><a href=\"http://thinklab.com/discussion/computing-consensus-transcriptional-profiles-for-compounds-using-lincs/43#6\">Read more</a> about our consensus signatures for gene knockdowns (of 4,363 genes) and overexpressions (of 2,471 genes).</p>",
      "body_md": "# Genetic perturbation edges\r\n\r\n@alessandrodidonna, thanks for the recommendation. You have motivated to us to add four new gene--gene metaedges:\r\n\r\n+ Gene → knockdown downregulates → Gene\r\n+ Gene → knockdown upregulates → Gene\r\n+ Gene → overexpression downregulates → Gene\r\n+ Gene → overexpression upregulates → Gene\r\n\r\nThese will be our first directed edges, so it will be exciting to stress test our support for directed edges, a feature that we [designed](https://github.com/dhimmel/hetio/blob/340b5f3572e29a766cb103b0883796323f983e97/hetio/graph.py#L322) our implementation to support.\r\n\r\nWe'll be taking the data from [LINCS L1000](http://www.lincscloud.org/) which contains a large number of genetic perturbation experiments:\r\n\r\n![](https://raw.githubusercontent.com/dhimmel/rephetio/b4ccfe08be839a4caa4b4a0e2b918b03d50cde65/figure/lincs-l1000-synopsys.png)\r\n\r\n[Read more](http://thinklab.com/discussion/computing-consensus-transcriptional-profiles-for-compounds-using-lincs/43#6) about our consensus signatures for gene knockdowns (of 4,363 genes) and overexpressions (of 2,471 genes).",
      "comment_id": 364,
      "profile_id": 17,
      "published": "2015-08-08T20:37:06.568177Z",
      "thread_id": 22,
      "url": "/discussion/suggestions-for-additional-information-types/22#6"
    },
    {
      "body_html": "<h1>Knowledge biased and unbiased edges</h1>\r\n\r\n<p>Thanks to <a href=\"/u/b_good\" class=\"username\">@b_good</a>'s suggestion for text mining and curated databases, we have incorporated several edges that are subject to knowledge bias.</p>\r\n\r\n<p>Text mining edges include:</p>\r\n\r\n<ul><li><em>Disease — causation — Symptom</em> edges from MEDLINE <a href=\"http://thinklab.com/discussion/mining-knowledge-from-medline-articles-and-their-indexed-mesh-terms/67#4\">topic cooccurrence</a></li><li><em>Disease — similarity — Disease</em> edges from MEDLINE <a href=\"http://thinklab.com/discussion/disease-similarity-from-medline-topic-cooccurrence/93\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d93\">topic cooccurrence</a></li><li><em>Disease — localization — Anatomy</em> edges from MEDLINE <a href=\"http://thinklab.com/discussion/mining-knowledge-from-medline-articles-and-their-indexed-mesh-terms/67#5\">topic cooccurrence</a></li></ul>\r\n\r\n<p>Literature curation edges include:</p>\r\n\r\n<ul><li><em>Compound — target — Gene</em> edges from <a href=\"http://thinklab.com/discussion/protein-target-carrier-transporter-and-enzyme-interactions-in-drugbank/65\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d65\">DrugBank</a> and <a href=\"http://thinklab.com/discussion/integrating-drug-target-information-from-bindingdb/53\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d53\">BindingDB</a></li><li><em>Gene — interaction — Gene</em> edges from <a href=\"http://thinklab.com/discussion/creating-a-catalog-of-protein-interactions/85\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d85\">curated databases</a></li><li><em>Gene — membership — Pathway</em> edges from <a href=\"http://thinklab.com/discussion/adding-pathway-resources-to-your-network/72\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d72\">WikiPathways and MSigDB</a></li><li><em>Gene — membership — GO Domain</em> edges from the <a href=\"http://thinklab.com/discussion/compiling-gene-ontology-annotations-into-an-easy-to-use-format/39#8\">Gene Ontology</a> annotations</li><li><em>Gene — function — Disease</em> edges from the <a href=\"http://thinklab.com/discussion/functional-disease-annotations-for-genes-using-doaf/94\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d94\">DOAF</a></li></ul>\r\n\r\n<p>And we have several edges from systematic technologies that are not subject to knowledge biases.</p>\r\n\r\n<ul><li><em>Disease — expression — Anatomy</em> edges from <a href=\"http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#8\">Bgee</a> and <a href=\"http://thinklab.com/discussion/the-tissues-resource-for-the-tissue-specificity-of-genes/91\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d91\">TISSUES</a></li><li><em>Disease — up/down-regulation — Gene</em> edges from <a href=\"http://thinklab.com/discussion/stargeo-expression-signatures-for-disease-using-crowdsourced-geo-annotation/96\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d96\">STARGEO</a></li><li><em>Gene — membership — Perturbation Gene Set</em> edges from MSigDB</li><li><em>Gene — interaction — Gene</em> edges from <a href=\"http://thinklab.com/discussion/creating-a-catalog-of-protein-interactions/85#7\">Y2H experiments</a></li><li><em>Gene — evolution — Gene</em> edges from <a href=\"http://thinklab.com/discussion/selecting-informative-erc-evolutionary-rate-covariation-values-between-genes/57\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d57\">evolutionary rate covariation</a></li><li><em>Gene — knowdown up/down-reglulation — Gene</em> edges from <a href=\"http://thinklab.com/discussion/suggestions-for-additional-information-types/22#6\">LINCS L1000</a></li><li><em>Compound — up/down-regulation — Gene</em> from <a href=\"http://thinklab.com/discussion/computing-consensus-transcriptional-profiles-for-compounds-using-lincs/43#6\">LINCS L1000</a></li></ul>\r\n\r\n<p>Thus, for each edge we will create an <code>unbiased</code> attribute which takes a <code>True</code> or <code>False</code> value. <strong>Using our network masking feature, we can easily switch between using the whole network or only the knowledge-unbiased portion.</strong></p>\r\n\r\n<p>Some metaedges will contain a mix of biased and unbiased edges. For example, protein interactions based on their source database. When both a biased and unbiased source contribute an edge, we will give precedence to the unbiased designation.</p>",
      "body_md": "# Knowledge biased and unbiased edges\r\n\r\nThanks to @b_good's suggestion for text mining and curated databases, we have incorporated several edges that are subject to knowledge bias.\r\n\r\nText mining edges include:\r\n\r\n+ *Disease -- causation -- Symptom* edges from MEDLINE [topic cooccurrence](http://thinklab.com/discussion/mining-knowledge-from-medline-articles-and-their-indexed-mesh-terms/67#4)\r\n+ *Disease -- similarity -- Disease* edges from MEDLINE [topic cooccurrence](http://thinklab.com/discussion/disease-similarity-from-medline-topic-cooccurrence/93)\r\n+ *Disease -- localization -- Anatomy* edges from MEDLINE [topic cooccurrence](http://thinklab.com/discussion/mining-knowledge-from-medline-articles-and-their-indexed-mesh-terms/67#5)\r\n\r\nLiterature curation edges include:\r\n\r\n+  *Compound -- target -- Gene* edges from [DrugBank](http://thinklab.com/discussion/protein-target-carrier-transporter-and-enzyme-interactions-in-drugbank/65) and [BindingDB](http://thinklab.com/discussion/integrating-drug-target-information-from-bindingdb/53)\r\n+ *Gene -- interaction -- Gene* edges from [curated databases](http://thinklab.com/discussion/creating-a-catalog-of-protein-interactions/85)\r\n+ *Gene -- membership -- Pathway* edges from [WikiPathways and MSigDB](http://thinklab.com/discussion/adding-pathway-resources-to-your-network/72)\r\n+ *Gene -- membership -- GO Domain* edges from the [Gene Ontology](http://thinklab.com/discussion/compiling-gene-ontology-annotations-into-an-easy-to-use-format/39#8) annotations\r\n+ *Gene -- function -- Disease* edges from the [DOAF](http://thinklab.com/discussion/functional-disease-annotations-for-genes-using-doaf/94)\r\n\r\nAnd we have several edges from systematic technologies that are not subject to knowledge biases.\r\n\r\n+ *Disease -- expression -- Anatomy* edges from [Bgee](http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#8) and [TISSUES](http://thinklab.com/discussion/the-tissues-resource-for-the-tissue-specificity-of-genes/91)\r\n+ *Disease -- up/down-regulation -- Gene* edges from [STARGEO](http://thinklab.com/discussion/stargeo-expression-signatures-for-disease-using-crowdsourced-geo-annotation/96)\r\n+ *Gene -- membership -- Perturbation Gene Set* edges from MSigDB\r\n+ *Gene -- interaction -- Gene* edges from [Y2H experiments](http://thinklab.com/discussion/creating-a-catalog-of-protein-interactions/85#7)\r\n+ *Gene -- evolution -- Gene* edges from [evolutionary rate covariation](http://thinklab.com/discussion/selecting-informative-erc-evolutionary-rate-covariation-values-between-genes/57)\r\n+ *Gene -- knowdown up/down-reglulation -- Gene* edges from [LINCS L1000](http://thinklab.com/discussion/suggestions-for-additional-information-types/22#6)\r\n+ *Compound -- up/down-regulation -- Gene* from [LINCS L1000](http://thinklab.com/discussion/computing-consensus-transcriptional-profiles-for-compounds-using-lincs/43#6)\r\n\r\nThus, for each edge we will create an `unbiased` attribute which takes a `True` or `False` value. **Using our network masking feature, we can easily switch between using the whole network or only the knowledge-unbiased portion.**\r\n\r\nSome metaedges will contain a mix of biased and unbiased edges. For example, protein interactions based on their source database. When both a biased and unbiased source contribute an edge, we will give precedence to the unbiased designation.",
      "comment_id": 365,
      "profile_id": 17,
      "published": "2015-08-08T22:27:20.277476Z",
      "thread_id": 48,
      "url": "/discussion/text-as-a-resource-for-network-population/48#3"
    },
    {
      "body_html": "<p><a href=\"/u/larsjuhljensen\" class=\"username\">@larsjuhljensen</a>, we will use the integrated dataset as the primary resource. However, the integrated dataset is subject to knowledge biases (stemming from text mining and UniProtKB). Since we <a href=\"http://thinklab.com/discussion/text-as-a-resource-for-network-population/48#3\">want the option</a> to subset the network to only include knowledge-unbaised edges, we would also like a consolidated score using only the experimental dataset.</p>\r\n\r\n<p>In other words, if a gene–tissue edge scores above the cutoff in the consolidated experimental dataset, it's considered unbiased. However, if it only passes the cutoff in the integrated dataset, it's considered biased.</p>\r\n\r\n<p>So that leaves one remaining question: <strong>how to create an integrated score using only experimental evidence?</strong></p>\r\n\r\n<blockquote><p>some tissues will be entirely lost if you require support from two datasets.</p></blockquote>\r\n\r\n<p>Let's not worry to much about uniform coverage of tissues. Our approach can handle nonuniform network sparsity and uniform coverage is unfeasible in most cases.</p>",
      "body_md": "@larsjuhljensen, we will use the integrated dataset as the primary resource. However, the integrated dataset is subject to knowledge biases (stemming from text mining and UniProtKB). Since we [want the option](http://thinklab.com/discussion/text-as-a-resource-for-network-population/48#3) to subset the network to only include knowledge-unbaised edges, we would also like a consolidated score using only the experimental dataset.\r\n\r\nIn other words, if a gene--tissue edge scores above the cutoff in the consolidated experimental dataset, it's considered unbiased. However, if it only passes the cutoff in the integrated dataset, it's considered biased.\r\n\r\nSo that leaves one remaining question: **how to create an integrated score using only experimental evidence?**\r\n\r\n> some tissues will be entirely lost if you require support from two datasets.\r\n\r\nLet's not worry to much about uniform coverage of tissues. Our approach can handle nonuniform network sparsity and uniform coverage is unfeasible in most cases.",
      "comment_id": 366,
      "profile_id": 17,
      "published": "2015-08-08T22:39:34.502949Z",
      "thread_id": 91,
      "url": "/discussion/the-tissues-resource-for-the-tissue-specificity-of-genes/91#6"
    },
    {
      "body_html": "<p>SIDER is a project to extract side effects from drug labels <span class=\"citation\">[<a href=\"https://doi.org/10.1038/msb.2009.98\" class=\"citation\" data-key=\"10.1038/msb.2009.98\">1</a>]</span>, originally motivated by off-target prediction <span class=\"citation\">[<a href=\"https://doi.org/10.1126/science.1158140\" class=\"citation\" data-key=\"10.1126/science.1158140\">2</a>]</span>. We <a href=\"http://thinklab.com/discussion/assessing-the-quality-and-applicability-of-the-sider-2-resource/30#1\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d30\">evaluated version 2</a> and produced an <a href=\"http://git.dhimmel.com/SIDER2/\">online tutorial</a>. We found that side effect similarity was a <a href=\"http://thinklab.com/discussion/assessing-the-quality-and-applicability-of-the-sider-2-resource/30#3\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d30\">weak predictor</a> of chemical and indication similarity.</p>\r\n\r\n<p>Just two days ago, <a href=\"http://sideeffects.embl.de/\">version 4</a> was released. Here, we will detail our extraction of side effects from SIDER4.</p>",
      "body_md": "SIDER is a project to extract side effects from drug labels [@10.1038/msb.2009.98], originally motivated by off-target prediction [@10.1126/science.1158140]. We [evaluated version 2](http://thinklab.com/discussion/assessing-the-quality-and-applicability-of-the-sider-2-resource/30#1) and produced an [online tutorial](http://git.dhimmel.com/SIDER2/). We found that side effect similarity was a [weak predictor](http://thinklab.com/discussion/assessing-the-quality-and-applicability-of-the-sider-2-resource/30#3) of chemical and indication similarity.\r\n\r\nJust two days ago, [version 4](http://sideeffects.embl.de/) was released. Here, we will detail our extraction of side effects from SIDER4.",
      "comment_id": 367,
      "profile_id": 17,
      "published": "2015-08-08T23:36:57.882948Z",
      "thread_id": 97,
      "url": "/discussion/extracting-side-effects-from-sider-4/97"
    },
    {
      "body_html": "<h1>Data release formatting</h1>\r\n\r\n<p>We ran into some issues when parsing the SIDER4 datasets. In defense of the creators, version 4 is still in beta and hasn't become the default version (the url was <a href=\"http://thinklab.com/discussion/assessing-the-quality-and-applicability-of-the-sider-2-resource/30#4\">provided to us</a> by a project member).</p>\r\n\r\n<p>The remainder of the post refers to <a href=\"https://github.com/dhimmel/SIDER4/blob/master/SIDER4.ipynb\">this notebook</a>. I ran into the following issues:</p>\r\n\r\n<ul><li><code>label_mapping.tsv.gz</code> is strangely encoded and/or is improperly tab-delimited</li><li><code>meddra_all_indications.tsv.gz</code> is not documented in the README</li></ul>\r\n\r\n<p><a href=\"/u/larsjuhljensen\" class=\"username\">@larsjuhljensen</a>, are you the right contact for this project?</p>",
      "body_md": "# Data release formatting\r\n\r\nWe ran into some issues when parsing the SIDER4 datasets. In defense of the creators, version 4 is still in beta and hasn't become the default version (the url was [provided to us](http://thinklab.com/discussion/assessing-the-quality-and-applicability-of-the-sider-2-resource/30#4) by a project member).\r\n\r\nThe remainder of the post refers to [this notebook](https://github.com/dhimmel/SIDER4/blob/master/SIDER4.ipynb). I ran into the following issues:\r\n\r\n+ `label_mapping.tsv.gz` is strangely encoded and/or is improperly tab-delimited\r\n+ `meddra_all_indications.tsv.gz` is not documented in the README\r\n\r\n@larsjuhljensen, are you the right contact for this project?",
      "comment_id": 368,
      "profile_id": 17,
      "published": "2015-08-08T23:49:37.750250Z",
      "thread_id": 97,
      "url": "/discussion/extracting-side-effects-from-sider-4/97#2"
    },
    {
      "body_html": "<p>The way we currently calculate the integrated score can obviously be applied to any subset of evidence channels and sources (e.g. all sources in the experiments channel, or all sources in the experiments channel except HPA-IHC).</p>\r\n\r\n<p>First, we convert all the confidence scores (<span class=\"math\">$$s_{ijk}$$</span>) between 0 and 5 to pseudo-probabilities (<span class=\"math\">$$p_{ijk}$$</span>) between 0 and 1 by simply dividing with 5. Here <span class=\"math\">$$i$$</span> and <span class=\"math\">$$j$$</span> are the two entities (proteins, tissues, diseases, etc.) and <span class=\"math\">$$k$$</span> is the channel or source. Next, assuming independence between the different types of evidence, we define the combined pseudo-probability for two entities as:</p>\r\n\r\n<div class=\"math\">$$$p_{ij} = 1-\\prod_{k}{(1-p_{ijk})}$$$</div>\r\n\r\n<p>Finally, we convert <span class=\"math\">$$p_{ij}$$</span> back to <span class=\"math\">$$s_{ij}$$</span> by simply multiplying with 5.</p>\r\n\r\n<p>This is admitted <em>ad hoc</em> and has not yet been benchmarked or otherwise compared to other alternatives. The major assumption here is that you can convert confidence scores to some sort of probabilities by simply dividing with 5, which is obviously an oversimplification. There is also the assumption of independence, but I believe this is less of a problem. The formula for combining probabilities is very similar to the <a href=\"http://string-db.org/\">STRING</a> scoring scheme, which has been extensively tested.</p>",
      "body_md": "The way we currently calculate the integrated score can obviously be applied to any subset of evidence channels and sources (e.g. all sources in the experiments channel, or all sources in the experiments channel except HPA-IHC).\r\n\r\nFirst, we convert all the confidence scores ($$s_{ijk}$$) between 0 and 5 to pseudo-probabilities ($$p_{ijk}$$) between 0 and 1 by simply dividing with 5. Here $$i$$ and $$j$$ are the two entities (proteins, tissues, diseases, etc.) and $$k$$ is the channel or source. Next, assuming independence between the different types of evidence, we define the combined pseudo-probability for two entities as:\r\n\r\n$$$p_{ij} = 1-\\prod_{k}{(1-p_{ijk})}$$$\r\n\r\nFinally, we convert $$p_{ij}$$ back to $$s_{ij}$$ by simply multiplying with 5.\r\n\r\nThis is admitted *ad hoc* and has not yet been benchmarked or otherwise compared to other alternatives. The major assumption here is that you can convert confidence scores to some sort of probabilities by simply dividing with 5, which is obviously an oversimplification. There is also the assumption of independence, but I believe this is less of a problem. The formula for combining probabilities is very similar to the [STRING](http://string-db.org/) scoring scheme, which has been extensively tested.",
      "comment_id": 372,
      "profile_id": 125,
      "published": "2015-08-09T08:47:44.404612Z",
      "thread_id": 91,
      "url": "/discussion/the-tissues-resource-for-the-tissue-specificity-of-genes/91#7"
    },
    {
      "body_html": "<h1>Initial release of processed TISSUES data</h1>\r\n\r\n<p>We have completed an initial processing of the TISSUES data (<a href=\"https://github.com/dhimmel/tissues/tree/93cd71464ee9673661bc4ddadfc6a8e0e219cd7b\">repository</a>, <a href=\"https://github.com/dhimmel/tissues/blob/93cd71464ee9673661bc4ddadfc6a8e0e219cd7b/tissues.ipynb\">notebook</a>) <span class=\"citation\">[<a href=\"https://doi.org/10.5281/zenodo.27244\" class=\"citation\" data-key=\"10.5281/zenodo.27244\">1</a>]</span>. The main output of our analysis is <a href=\"https://github.com/dhimmel/tissues/blob/93cd71464ee9673661bc4ddadfc6a8e0e219cd7b/data/merged.tsv.gz\"><code>merged.tsv.gz</code></a>, a table where each row is a tissue (Uberon)–gene (Entrez) pair. For each pair, we provide 5 scores:</p>\r\n\r\n<ul><li><code>score_text</code>: score from the text mining channel</li><li><code>score_knowledge</code>: score from the UniProtKB/knowledge channel</li><li><code>score_experiment</code>: integrated score from the experimental channel</li><li><code>score_experiment_unbiased</code>: integrated score from the experimental channel without immunohistochemical staining data from the Human Protein Atlas</li><li><code>score_integrated</code>:  integrated score combining everything</li></ul>\r\n\r\n<p>Integrations (<code>score_experiment</code> and <code>score_experiment_unbiased</code>) were calculated using the <a href=\"#7\">above formula</a>.</p>\r\n\r\n<h2>Visualizing channel concordance</h2>\r\n\r\n<p>We visualized the relationships between scores. The off-diagonal plots show a 2D histogram, using hexagonal bins. The diagonal of the grid contains 1D histograms for the x-variable. Bin counts for all panels are log-transformed.</p>\r\n\r\n<p><img src=\"https://raw.githubusercontent.com/dhimmel/tissues/93cd71464ee9673661bc4ddadfc6a8e0e219cd7b/figure/channel-histograms.png\" alt=\"\"></p>\r\n\r\n<p>You may be surprised to see points where <code>y &lt; x</code> for the integrated 2D histograms. This occurs because Uberon and Entrez Gene mappings are not always one-to-one.</p>",
      "body_md": "# Initial release of processed TISSUES data\r\n\r\nWe have completed an initial processing of the TISSUES data ([repository](https://github.com/dhimmel/tissues/tree/93cd71464ee9673661bc4ddadfc6a8e0e219cd7b), [notebook](https://github.com/dhimmel/tissues/blob/93cd71464ee9673661bc4ddadfc6a8e0e219cd7b/tissues.ipynb)) [@10.5281/zenodo.27244]. The main output of our analysis is [`merged.tsv.gz`](https://github.com/dhimmel/tissues/blob/93cd71464ee9673661bc4ddadfc6a8e0e219cd7b/data/merged.tsv.gz), a table where each row is a tissue (Uberon)--gene (Entrez) pair. For each pair, we provide 5 scores:\r\n\r\n+ `score_text`: score from the text mining channel\r\n+ `score_knowledge`: score from the UniProtKB/knowledge channel\r\n+ `score_experiment`: integrated score from the experimental channel\r\n+ `score_experiment_unbiased`: integrated score from the experimental channel without immunohistochemical staining data from the Human Protein Atlas\r\n+ `score_integrated`:  integrated score combining everything\r\n\r\nIntegrations (`score_experiment` and `score_experiment_unbiased`) were calculated using the [above formula](#7).\r\n\r\n## Visualizing channel concordance\r\n\r\nWe visualized the relationships between scores. The off-diagonal plots show a 2D histogram, using hexagonal bins. The diagonal of the grid contains 1D histograms for the x-variable. Bin counts for all panels are log-transformed.\r\n\r\n![](https://raw.githubusercontent.com/dhimmel/tissues/93cd71464ee9673661bc4ddadfc6a8e0e219cd7b/figure/channel-histograms.png)\r\n\r\nYou may be surprised to see points where `y < x` for the integrated 2D histograms. This occurs because Uberon and Entrez Gene mappings are not always one-to-one.",
      "comment_id": 375,
      "profile_id": 17,
      "published": "2015-08-09T19:42:47.394553Z",
      "thread_id": 91,
      "url": "/discussion/the-tissues-resource-for-the-tissue-specificity-of-genes/91#8"
    },
    {
      "body_html": "<h2>Updated datasets</h2>\r\n\r\n<p>We modified the code and formats for our merged indication datasets (<a href=\"https://cdn.rawgit.com/dhimmel/indications/6375b195df61b6e0d44c4690abfa2ac0710bc690//merge.html#indication-table\">website</a>, <a href=\"https://github.com/dhimmel/indications/tree/6375b195df61b6e0d44c4690abfa2ac0710bc690/data\">downloads</a>). The underlying indications have not changed from <a href=\"#1\">above</a>.</p>\r\n\r\n<h2>Pilot on 50 indications</h2>\r\n\r\n<p>We created a <a href=\"https://github.com/dhimmel/indications/blob/6375b195df61b6e0d44c4690abfa2ac0710bc690/data/curation.tsv\">simpler tsv file</a> as a curation template. As a start, we are going to have two UCSF physicians each classify a <a href=\"https://github.com/dhimmel/indications/blob/6375b195df61b6e0d44c4690abfa2ac0710bc690/data/curation-subset.tsv\">random subset</a> of 50 indications. These indications will be a pilot to see if the task is well-defined or needs revision.</p>\r\n\r\n<p>The curators will independently do a first pass. Then they will come to a consensus on conflicting classifications. We'll report back with our experience on the pilot. </p>",
      "body_md": "## Updated datasets\r\n\r\nWe modified the code and formats for our merged indication datasets ([website](https://cdn.rawgit.com/dhimmel/indications/6375b195df61b6e0d44c4690abfa2ac0710bc690//merge.html#indication-table), [downloads](https://github.com/dhimmel/indications/tree/6375b195df61b6e0d44c4690abfa2ac0710bc690/data)). The underlying indications have not changed from [above](#1).\r\n\r\n## Pilot on 50 indications\r\n\r\nWe created a [simpler tsv file](https://github.com/dhimmel/indications/blob/6375b195df61b6e0d44c4690abfa2ac0710bc690/data/curation.tsv) as a curation template. As a start, we are going to have two UCSF physicians each classify a [random subset](https://github.com/dhimmel/indications/blob/6375b195df61b6e0d44c4690abfa2ac0710bc690/data/curation-subset.tsv) of 50 indications. These indications will be a pilot to see if the task is well-defined or needs revision.\r\n\r\nThe curators will independently do a first pass. Then they will come to a consensus on conflicting classifications. We'll report back with our experience on the pilot. ",
      "comment_id": 376,
      "profile_id": 17,
      "published": "2015-08-09T21:05:19.849811Z",
      "thread_id": 95,
      "url": "/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95#2"
    },
    {
      "body_html": "<h1>SIDER 4</h1>\r\n\r\n<p>We have begun working with SIDER 4. See <a href=\"http://thinklab.com/discussion/extracting-side-effects-from-sider4/97\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d97\">the dedicated discussion</a> for more information.</p>",
      "body_md": "# SIDER 4\r\n\r\nWe have begun working with SIDER 4. See [the dedicated discussion](http://thinklab.com/discussion/extracting-side-effects-from-sider4/97) for more information.",
      "comment_id": 382,
      "profile_id": 17,
      "published": "2015-08-10T18:14:36.201349Z",
      "thread_id": 30,
      "url": "/discussion/assessing-the-quality-and-applicability-of-the-sider-2-resource/30#7"
    },
    {
      "body_html": "<h1>Initial processing complete</h1>\r\n\r\n<p>We've completed a first pass off the SIDER 4 data processing (<a href=\"https://github.com/dhimmel/SIDER4/blob/2acca0b065e736bc99702906024efd4718e502ee/SIDER4.ipynb\">notebook</a>, <a href=\"https://github.com/dhimmel/SIDER4/tree/2acca0b065e736bc99702906024efd4718e502ee/data\">downloads</a>). Our analysis consisted of mapping <a href=\"http://stitch.embl.de/\">STICH</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkt1207\" class=\"citation\" data-key=\"10.1093/nar/gkt1207\">1</a>, <a href=\"https://doi.org/10.1093/nar/gkm795\" class=\"citation\" data-key=\"10.1093/nar/gkm795\">2</a>]</span> compounds to DrugBank and consolidating duplicate rows. </p>\r\n\r\n<p>We added the side effects extracted from <code>meddra_all_se.tsv.gz</code> to our network. Overall, the resource <a href=\"https://github.com/dhimmel/integrate/blob/9986ecb2ad62f0e08044334d74d63a9590e4eafd/integrate.ipynb\">contributed</a> 139,235 compound-side effect relationships for 5,745 side effects.</p>\r\n\r\n<h2>Data quality</h2>\r\n\r\n<p>Compared to version 2, I subjectively noticed a considerable quality improvement. However, many of the <a href=\"http://thinklab.com/discussion/assessing-the-quality-and-applicability-of-the-sider-2-resource/30#2\">problems</a> inherent to label based NLP extraction remain. I think there are two potential methods for extracting higher confidence side effects:</p>\r\n\r\n<ol><li><strong>Number of labels approach</strong>: Most drugs have multiple labels. Side effects reported by more labels may be of higher quality. <a href=\"http://sideeffects.embl.de/drugs/3007/\">Amphetamine</a> is a good example.</li><li><strong>Frequency approach</strong>: Some side effects have associated frequency information. Placebo comparisons are also sometimes present. Thus enrichment in frequency compared to placebo, other drugs, or a cutoff is feasible. <a href=\"http://sideeffects.embl.de/drugs/3672/\">Ibuprofen</a> is a good example. </li></ol>\r\n\r\n<p>The current data release may be insufficient to apply these methods. More documentation is needed. Judging from the webapp the underlying database would support both methods. </p>",
      "body_md": "# Initial processing complete\r\n\r\nWe've completed a first pass off the SIDER 4 data processing ([notebook](https://github.com/dhimmel/SIDER4/blob/2acca0b065e736bc99702906024efd4718e502ee/SIDER4.ipynb), [downloads](https://github.com/dhimmel/SIDER4/tree/2acca0b065e736bc99702906024efd4718e502ee/data)). Our analysis consisted of mapping [STICH](http://stitch.embl.de/) [@10.1093/nar/gkt1207 @10.1093/nar/gkm795] compounds to DrugBank and consolidating duplicate rows. \r\n\r\nWe added the side effects extracted from `meddra_all_se.tsv.gz` to our network. Overall, the resource [contributed](https://github.com/dhimmel/integrate/blob/9986ecb2ad62f0e08044334d74d63a9590e4eafd/integrate.ipynb) 139,235 compound-side effect relationships for 5,745 side effects.\r\n\r\n## Data quality\r\n\r\nCompared to version 2, I subjectively noticed a considerable quality improvement. However, many of the [problems](http://thinklab.com/discussion/assessing-the-quality-and-applicability-of-the-sider-2-resource/30#2) inherent to label based NLP extraction remain. I think there are two potential methods for extracting higher confidence side effects:\r\n\r\n1. **Number of labels approach**: Most drugs have multiple labels. Side effects reported by more labels may be of higher quality. [Amphetamine](http://sideeffects.embl.de/drugs/3007/) is a good example.\r\n2. **Frequency approach**: Some side effects have associated frequency information. Placebo comparisons are also sometimes present. Thus enrichment in frequency compared to placebo, other drugs, or a cutoff is feasible. [Ibuprofen](http://sideeffects.embl.de/drugs/3672/) is a good example. \r\n\r\nThe current data release may be insufficient to apply these methods. More documentation is needed. Judging from the webapp the underlying database would support both methods. \r\n\r\n\r\n",
      "comment_id": 386,
      "profile_id": 17,
      "published": "2015-08-11T06:05:43.190878Z",
      "thread_id": 97,
      "url": "/discussion/extracting-side-effects-from-sider-4/97#3"
    },
    {
      "body_html": "<p>A recently published study <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkv810\" class=\"citation\" data-key=\"10.1093/nar/gkv810\">1</a>]</span>, which calls itself <a href=\"http://acgt.cs.tau.ac.il/adeptus/download.html\">ADEPTUS</a>, calculated differential expression profiles for 14 diseases.</p>\r\n\r\n<p>Their disease concepts are broad, so only 3 match a <a href=\"http://thinklab.com/discussion/unifying-disease-vocabularies/44#6\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d44\">DO Slim</a> disease (<a href=\"https://github.com/dhimmel/adeptus/blob/4169d25bbc99177d88d0cbd428ae02e886a2d2f9/adeptus.ipynb\">notebook</a>, <a href=\"https://github.com/dhimmel/adeptus/tree/4169d25bbc99177d88d0cbd428ae02e886a2d2f9/data\">downloads</a>). Those diseases along with the corresponding number of up and down-regulated genes are:</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>disease id</th><th>disease name</th><th>genes down</th><th>genes up</th></tr></thead><tbody><tr><td>DOID:1324</td><td>lung cancer</td><td>101</td><td>211</td></tr><tr><td>DOID:1612</td><td>breast cancer</td><td>61</td><td>68</td></tr><tr><td>DOID:2531</td><td>hematologic cancer</td><td>512</td><td>631</td></tr></tbody></table>\r\n\r\n<p>We're included these edges in our network as a placeholder until <a href=\"http://thinklab.com/discussion/stargeo-expression-signatures-for-disease-using-crowdsourced-geo-annotation/96\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d96\">STARGEO is ready</a>. STARGEO currently <a href=\"http://dev.stargeo.io/\">contains</a> 463,824 sample annotations (tags) whereas ADEPTUS contains only 14,840.</p>",
      "body_md": "A recently published study [@10.1093/nar/gkv810], which calls itself [ADEPTUS](http://acgt.cs.tau.ac.il/adeptus/download.html), calculated differential expression profiles for 14 diseases.\r\n\r\nTheir disease concepts are broad, so only 3 match a [DO Slim](http://thinklab.com/discussion/unifying-disease-vocabularies/44#6) disease ([notebook](https://github.com/dhimmel/adeptus/blob/4169d25bbc99177d88d0cbd428ae02e886a2d2f9/adeptus.ipynb), [downloads](https://github.com/dhimmel/adeptus/tree/4169d25bbc99177d88d0cbd428ae02e886a2d2f9/data)). Those diseases along with the corresponding number of up and down-regulated genes are:\r\n\r\n| disease id | disease name | genes down | genes up |\r\n|-----------|--------------------|------|-----|\r\n| DOID:1324 | lung cancer | 101 | 211 |\r\n| DOID:1612 | breast cancer | 61 | 68 |\r\n| DOID:2531 | hematologic cancer | 512 | 631 |\r\n\r\nWe're included these edges in our network as a placeholder until [STARGEO is ready](http://thinklab.com/discussion/stargeo-expression-signatures-for-disease-using-crowdsourced-geo-annotation/96). STARGEO currently [contains](http://dev.stargeo.io/) 463,824 sample annotations (tags) whereas ADEPTUS contains only 14,840.",
      "comment_id": 387,
      "profile_id": 17,
      "published": "2015-08-12T23:40:14.883645Z",
      "thread_id": 101,
      "url": "/discussion/the-adeptus-resource-for-expression-signatures-of-disease/101"
    },
    {
      "body_html": "<h1>Ontologies for disease-centric GEO annotation</h1>\r\n\r\n<p>STARGEO allows users to define arbitrary \"tags\" for sample annotation. We have been adding Disease Ontology (DO) IDs to our tag descriptions. This suffices for simple case-control comparisons, but is insufficient for more complex comparisons.</p>\r\n\r\n<p>For example, many cancer studies, will compare tumors to healthy tissue but all samples are from cases. Therefore the contrast is not case versus control, but healthy versus diseased tissue. In general, we will want to incorporate these contrasts into our disease-specific expression signatures.</p>\r\n\r\n<p><a href=\"/u/fbastian\" class=\"username\">@fbastian</a> and <a href=\"/u/chrismungall\" class=\"username\">@chrismungall</a>, do you know of any ontologies that could help with our annotation task? I know that Bgee focuses on healthy tissue, but I though you may be able to direct us in the right direction.</p>\r\n\r\n<p><strong>Summary</strong>: we are gathering disease-specific expression signatures. What terminologies should we use to create contrast between samples within a study (GEO Series)?</p>",
      "body_md": "# Ontologies for disease-centric GEO annotation\r\n\r\nSTARGEO allows users to define arbitrary \"tags\" for sample annotation. We have been adding Disease Ontology (DO) IDs to our tag descriptions. This suffices for simple case-control comparisons, but is insufficient for more complex comparisons.\r\n\r\nFor example, many cancer studies, will compare tumors to healthy tissue but all samples are from cases. Therefore the contrast is not case versus control, but healthy versus diseased tissue. In general, we will want to incorporate these contrasts into our disease-specific expression signatures.\r\n\r\n@fbastian and @chrismungall, do you know of any ontologies that could help with our annotation task? I know that Bgee focuses on healthy tissue, but I though you may be able to direct us in the right direction.\r\n\r\n**Summary**: we are gathering disease-specific expression signatures. What terminologies should we use to create contrast between samples within a study (GEO Series)?",
      "comment_id": 390,
      "profile_id": 17,
      "published": "2015-08-12T03:41:52.524912Z",
      "thread_id": 96,
      "url": "/discussion/stargeo-expression-signatures-for-disease-using-crowdsourced-geo-annotation/96#2"
    },
    {
      "body_html": "<h1>Unbiased PPI datasets</h1>\r\n\r\n<p>Since we now include a <a href=\"http://thinklab.com/d/48#3\">edge attribute for bias</a> in our network, we need to identify a subset of our PPIs that are derived from hypothesis free, i.e. unbiased, experiments.</p>\r\n\r\n<p>The <em>Incomplete Interactome</em> <span class=\"citation\">[<a href=\"https://doi.org/10.1126/science.1257601\" class=\"citation\" data-key=\"10.1126/science.1257601\">1</a>]</span> <a href=\"http://www.sciencemag.org/content/suppl/2015/02/18/347.6224.1257601.DC1/Menche_SM.pdf#page=5\">describes</a> their creation of an unbiased interactome:</p>\r\n\r\n<blockquote><p>Since our interactome includes data from literature curation, it is inherently biased towards much studied disease-associated proteins and their interactions. We, therefore, complement our analysis using only interactions from well controlled and completely unbiased high-throughput yeast two-hybrid (y2h) datasets <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.cell.2014.10.050\" class=\"citation\" data-key=\"10.1016/j.cell.2014.10.050\">2</a>, <a href=\"https://doi.org/10.1038/nmeth.1280\" class=\"citation\" data-key=\"10.1038/nmeth.1280\">3</a>, <a href=\"https://doi.org/10.1038/nmeth.1597\" class=\"citation\" data-key=\"10.1038/nmeth.1597\">4</a>, <a href=\"https://doi.org/10.1038/nature04209\" class=\"citation\" data-key=\"10.1038/nature04209\">5</a>, <a href=\"\" class=\"citation\" data-key=\"55\">6</a>]</span>.</p></blockquote>\r\n\r\n<p>Minus the last citation <span class=\"citation\">[<a href=\"\" class=\"citation\" data-key=\"55\">6</a>]</span> which is prepublication, we can use the other four resources <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.cell.2014.10.050\" class=\"citation\" data-key=\"10.1016/j.cell.2014.10.050\">2</a>, <a href=\"https://doi.org/10.1038/nmeth.1280\" class=\"citation\" data-key=\"10.1038/nmeth.1280\">3</a>, <a href=\"https://doi.org/10.1038/nmeth.1597\" class=\"citation\" data-key=\"10.1038/nmeth.1597\">4</a>, <a href=\"https://doi.org/10.1038/nature04209\" class=\"citation\" data-key=\"10.1038/nature04209\">5</a>]</span>, two of which were used by <a href=\"/u/idrdex\" class=\"username\">@idrdex</a> in his study <span class=\"citation\">[<a href=\"https://doi.org/10.1038/ncomms5074\" class=\"citation\" data-key=\"10.1038/ncomms5074\">7</a>]</span>.</p>\r\n\r\n<p></p>",
      "body_md": "# Unbiased PPI datasets\r\n\r\nSince we now include a [edge attribute for bias](http://thinklab.com/d/48#3) in our network, we need to identify a subset of our PPIs that are derived from hypothesis free, i.e. unbiased, experiments.\r\n\r\nThe *Incomplete Interactome* [@10.1126/science.1257601] [describes](http://www.sciencemag.org/content/suppl/2015/02/18/347.6224.1257601.DC1/Menche_SM.pdf#page=5) their creation of an unbiased interactome:\r\n\r\n> Since our interactome includes data from literature curation, it is inherently biased towards much studied disease-associated proteins and their interactions. We, therefore, complement our analysis using only interactions from well controlled and completely unbiased high-throughput yeast two-hybrid (y2h) datasets [@10.1016/j.cell.2014.10.050 @10.1038/nmeth.1280 @10.1038/nmeth.1597 @10.1038/nature04209 @55].\r\n\r\nMinus the last citation [@55] which is prepublication, we can use the other four resources [@10.1016/j.cell.2014.10.050 @10.1038/nmeth.1280 @10.1038/nmeth.1597 @10.1038/nature04209], two of which were used by @idrdex in his study [@10.1038/ncomms5074].\r\n \r\n[@55]: \"Center for Cancer Systems Biology, Hi-2012 prepublication\"",
      "comment_id": 391,
      "profile_id": 17,
      "published": "2015-08-12T18:23:34.548120Z",
      "thread_id": 85,
      "url": "/discussion/creating-a-catalog-of-protein-interactions/85#8"
    },
    {
      "body_html": "<h1>Completed PPI catalog</h1>\r\n\r\n<p>We have completed an initial version of our protein interaction catalog for this project <span class=\"citation\">[<a href=\"https://doi.org/10.5281/zenodo.48443\" class=\"citation\" data-key=\"10.5281/zenodo.48443\">1</a>]</span>, named <code>hetio-ind</code>. We defined interaction as <em>two genes whose protein products physically interact</em>. Physical associations from protein complexes were minimized.</p>\r\n\r\n<p>Interactions were taken from the following sources:</p>\r\n\r\n<ul><li><strong>Human Interactome Database</strong> (<a href=\"http://interactome.dfci.harvard.edu/H_sapiens/index.php?page=download\">HID</a>): specifically the <code>HI-I-05</code> <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nature04209\" class=\"citation\" data-key=\"10.1038/nature04209\">2</a>]</span>, <code>Venkatesan-09</code> <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nmeth.1280\" class=\"citation\" data-key=\"10.1038/nmeth.1280\">3</a>]</span>, <code>Yu-11</code> <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nmeth.1597\" class=\"citation\" data-key=\"10.1038/nmeth.1597\">4</a>]</span>, <code>HI-II-14</code> <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.cell.2014.10.050\" class=\"citation\" data-key=\"10.1016/j.cell.2014.10.050\">5</a>]</span>, <code>Lit-BM-13</code> <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.cell.2014.10.050\" class=\"citation\" data-key=\"10.1016/j.cell.2014.10.050\">5</a>]</span> datasets.</li><li><strong>Incomplete Interactome</strong> <span class=\"citation\">[<a href=\"https://doi.org/10.1126/science.1257601\" class=\"citation\" data-key=\"10.1126/science.1257601\">6</a>]</span>: specifically the <code>II_binary</code> and <code>II_literature</code> <a href=\"#2\">subsets</a>.</li><li><strong>hetio-dag</strong> <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1004259\">7</a>]</span>: our previous project (<a href=\"#4\">details</a>). We removed all interactions that were not physical associations (<a href=\"http://www.ebi.ac.uk/ontology-lookup/browse.do?ontName=MI&amp;termId=MI%3A0915&amp;termName=physical%20association\"><code>MI:0195</code></a>). This step excluded genetic and colocalization interactions.</li></ul>\r\n\r\n<p>16,526 interactions reported by <code>HI-I-05</code> <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nature04209\" class=\"citation\" data-key=\"10.1038/nature04209\">2</a>]</span>, <code>Venkatesan-09</code> <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nmeth.1280\" class=\"citation\" data-key=\"10.1038/nmeth.1280\">3</a>]</span>, <code>Yu-11</code> <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nmeth.1597\" class=\"citation\" data-key=\"10.1038/nmeth.1597\">4</a>]</span>, or <code>HI-II-14</code> <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.cell.2014.10.050\" class=\"citation\" data-key=\"10.1016/j.cell.2014.10.050\">5</a>]</span> were considered unbiased. The 135,203 other interactions were considered biased.</p>\r\n\r\n<p>In total our dataset contains 151,729 protein interactions (<a href=\"https://github.com/dhimmel/ppi/blob/4012fe7af1699222539844256e3639782ae72695/compile-PPIs.ipynb\">notebook</a>, <a href=\"https://github.com/dhimmel/ppi/tree/4012fe7af1699222539844256e3639782ae72695/data\">downloads</a>).</p>",
      "body_md": "# Completed PPI catalog\r\n\r\nWe have completed an initial version of our protein interaction catalog for this project [@10.5281/zenodo.48443], named `hetio-ind`. We defined interaction as *two genes whose protein products physically interact*. Physical associations from protein complexes were minimized.\r\n\r\nInteractions were taken from the following sources:\r\n\r\n+ **Human Interactome Database** ([HID](http://interactome.dfci.harvard.edu/H_sapiens/index.php?page=download)): specifically the `HI-I-05` [@10.1038/nature04209], `Venkatesan-09` [@10.1038/nmeth.1280], `Yu-11` [@10.1038/nmeth.1597], `HI-II-14` [@10.1016/j.cell.2014.10.050], `Lit-BM-13` [@10.1016/j.cell.2014.10.050] datasets.\r\n+ **Incomplete Interactome** [@10.1126/science.1257601]: specifically the `II_binary` and `II_literature` [subsets](#2).\r\n+ **hetio-dag** [@10.1371/journal.pcbi.1004259]: our previous project ([details](#4)). We removed all interactions that were not physical associations ([`MI:0195`](http://www.ebi.ac.uk/ontology-lookup/browse.do?ontName=MI&termId=MI%3A0915&termName=physical%20association)). This step excluded genetic and colocalization interactions.\r\n\r\n16,526 interactions reported by `HI-I-05` [@10.1038/nature04209], `Venkatesan-09` [@10.1038/nmeth.1280], `Yu-11` [@10.1038/nmeth.1597], or `HI-II-14` [@10.1016/j.cell.2014.10.050] were considered unbiased. The 135,203 other interactions were considered biased.\r\n\r\nIn total our dataset contains 151,729 protein interactions ([notebook](https://github.com/dhimmel/ppi/blob/4012fe7af1699222539844256e3639782ae72695/compile-PPIs.ipynb), [downloads](https://github.com/dhimmel/ppi/tree/4012fe7af1699222539844256e3639782ae72695/data)).",
      "comment_id": 392,
      "profile_id": 17,
      "published": "2015-08-12T21:01:31.686816Z",
      "thread_id": 85,
      "url": "/discussion/creating-a-catalog-of-protein-interactions/85#9"
    },
    {
      "body_html": "<h1>Jupyter 1.0.0 released</h1>\r\n\r\n<p>Last Wednesday <a href=\"http://blog.jupyter.org/2015/08/12/first-release-of-jupyter/\">marked a historic day</a> for biodata science. The language agnostic parts of IPython, including the notebook, have been <a href=\"https://blog.jupyter.org/2015/04/15/the-big-split/\">repackaged</a> as Jupyter. The big split was necessary because the project now supports <a href=\"https://github.com/ipython/ipython/wiki/IPython-kernels-for-other-languages\">many languages</a> not just python.</p>\r\n\r\n<p>I am updating the <a href=\"#1\">above</a> guide, by replacing <code>ipython</code> with <code>jupyter</code> in code snippets. The revised guidance will apply to new installations. If you have an existing Anaconda installation, you can <a href=\"http://jupyter.readthedocs.org/en/latest/install.html\">install Jupyter</a> with <code>conda install jupyter</code>.</p>\r\n\r\n<p>Now who is excited for <a href=\"https://www.python.org/dev/peps/pep-0478/\">September 13th</a> and the <a href=\"https://github.com/takluyver/talks/blob/master/Python%203.5%20lightning%20talk.ipynb\">features</a> this day will bring!</p>",
      "body_md": "# Jupyter 1.0.0 released\r\n\r\nLast Wednesday [marked a historic day](http://blog.jupyter.org/2015/08/12/first-release-of-jupyter/) for biodata science. The language agnostic parts of IPython, including the notebook, have been [repackaged](https://blog.jupyter.org/2015/04/15/the-big-split/) as Jupyter. The big split was necessary because the project now supports [many languages](https://github.com/ipython/ipython/wiki/IPython-kernels-for-other-languages) not just python.\r\n\r\nI am updating the [above](#1) guide, by replacing `ipython` with `jupyter` in code snippets. The revised guidance will apply to new installations. If you have an existing Anaconda installation, you can [install Jupyter](http://jupyter.readthedocs.org/en/latest/install.html) with `conda install jupyter`.\r\n\r\nNow who is excited for [September 13th](https://www.python.org/dev/peps/pep-0478/) and the [features](https://github.com/takluyver/talks/blob/master/Python%203.5%20lightning%20talk.ipynb) this day will bring!",
      "comment_id": 393,
      "profile_id": 17,
      "published": "2015-08-16T23:53:59.216980Z",
      "thread_id": 84,
      "url": "/discussion/python-for-the-modern-biodata-scientist/84#5"
    },
    {
      "body_html": "<p>To annotate the condition of a sample, you can use the Experimental Factor Ontology (EFO). But not sure what you mean by \"contrast between samples\" (do you want to annotate each sample, or have terms directly representing, e.g. \"healthy vs. diseased contrast\")</p>",
      "body_md": "To annotate the condition of a sample, you can use the Experimental Factor Ontology (EFO). But not sure what you mean by \"contrast between samples\" (do you want to annotate each sample, or have terms directly representing, e.g. \"healthy vs. diseased contrast\")\r\n\r\n",
      "comment_id": 395,
      "profile_id": 111,
      "published": "2015-08-14T11:05:20.654050Z",
      "thread_id": 96,
      "url": "/discussion/stargeo-expression-signatures-for-disease-using-crowdsourced-geo-annotation/96#3"
    },
    {
      "body_html": "<h1>Network version 1.0</h1>\r\n\r\n<p>We have completed an initial version of our network (<a href=\"https://github.com/dhimmel/integrate/blob/2256f1d6d01758c8bab59212a68d890ecb42bb7f/integrate.ipynb\">notebook</a>, <a href=\"https://github.com/dhimmel/integrate/blob/2256f1d6d01758c8bab59212a68d890ecb42bb7f/data/graph.json.gz\">download</a>) <span class=\"citation\">[<a href=\"https://doi.org/10.5281/zenodo.28040\" class=\"citation\" data-key=\"10.5281/zenodo.28040\">1</a>]</span>.</p>\r\n\r\n<p>The network consists of 10 types of nodes (metanodes) and 27 types of edges (metaedges). It contains 49,427 nodes and 2,997,892 edges (1,488,312 of which are <a href=\"http://thinklab.com/discussion/text-as-a-resource-for-network-population/48#3\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d48\">unbiased</a>). The network is visualized below, laid out by metanode and colored by metaedge (only a subset of edges are drawn for efficiency):</p>\r\n\r\n<p><img src=\"https://raw.githubusercontent.com/dhimmel/rephetio/eaad6455815c3886a47aeddf76931fcf1779e090/figure/network-v1.0-labeled.png\" alt=\"\"></p>\r\n\r\n<p>For additional information, see the <a href=\"https://github.com/dhimmel/integrate/blob/2256f1d6d01758c8bab59212a68d890ecb42bb7f/data/summary/metanodes.tsv\">summary of nodes</a>, <a href=\"https://github.com/dhimmel/integrate/blob/2256f1d6d01758c8bab59212a68d890ecb42bb7f/data/summary/metaedges.tsv\">summary of edges</a>, or <a href=\"https://github.com/dhimmel/integrate/blob/2256f1d6d01758c8bab59212a68d890ecb42bb7f/viz/degrees.pdf\">visualization of degree distributions</a>. Network existence (SHA256 checksum for <code>graph.json.gz</code>) is <a href=\"https://blockchain.info/tx/092f81abd7bb5c59e52e2d8e794de6cee4a1cd701f7a87d2bc11cfefe97d4923?show_adv=true\">proven</a> in Bitcoin block 369,898.</p>\r\n\r\n<h2>Future changes</h2>\r\n\r\n<p>There are a few changes we hope to make in the near future. First, replacing <a href=\"http://thinklab.com/discussion/the-adeptus-resource-for-expression-signatures-of-disease/101\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d101\">ADEPTUS</a> with <a href=\"http://thinklab.com/discussion/stargeo-expression-signatures-for-disease-using-crowdsourced-geo-annotation/96\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d96\">STARGEO</a> for expression signatures of disease. Second, updating our indications with a <a href=\"http://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d95\">manually curated</a> subset. As always, suggestions for additional information types are <a href=\"http://thinklab.com/discussion/suggestions-for-additional-information-types/22\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d22\">welcome here</a>.</p>",
      "body_md": "# Network version 1.0\r\n\r\nWe have completed an initial version of our network ([notebook](https://github.com/dhimmel/integrate/blob/2256f1d6d01758c8bab59212a68d890ecb42bb7f/integrate.ipynb), [download](https://github.com/dhimmel/integrate/blob/2256f1d6d01758c8bab59212a68d890ecb42bb7f/data/graph.json.gz)) [@10.5281/zenodo.28040].\r\n\r\nThe network consists of 10 types of nodes (metanodes) and 27 types of edges (metaedges). It contains 49,427 nodes and 2,997,892 edges (1,488,312 of which are [unbiased](http://thinklab.com/discussion/text-as-a-resource-for-network-population/48#3)). The network is visualized below, laid out by metanode and colored by metaedge (only a subset of edges are drawn for efficiency):\r\n\r\n![](https://raw.githubusercontent.com/dhimmel/rephetio/eaad6455815c3886a47aeddf76931fcf1779e090/figure/network-v1.0-labeled.png)\r\n\r\nFor additional information, see the [summary of nodes](https://github.com/dhimmel/integrate/blob/2256f1d6d01758c8bab59212a68d890ecb42bb7f/data/summary/metanodes.tsv), [summary of edges](https://github.com/dhimmel/integrate/blob/2256f1d6d01758c8bab59212a68d890ecb42bb7f/data/summary/metaedges.tsv), or [visualization of degree distributions](https://github.com/dhimmel/integrate/blob/2256f1d6d01758c8bab59212a68d890ecb42bb7f/viz/degrees.pdf). Network existence (SHA256 checksum for `graph.json.gz`) is [proven](https://blockchain.info/tx/092f81abd7bb5c59e52e2d8e794de6cee4a1cd701f7a87d2bc11cfefe97d4923?show_adv=true) in Bitcoin block 369,898.\r\n\r\n## Future changes\r\n\r\nThere are a few changes we hope to make in the near future. First, replacing [ADEPTUS](http://thinklab.com/discussion/the-adeptus-resource-for-expression-signatures-of-disease/101) with [STARGEO](http://thinklab.com/discussion/stargeo-expression-signatures-for-disease-using-crowdsourced-geo-annotation/96) for expression signatures of disease. Second, updating our indications with a [manually curated](http://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95) subset. As always, suggestions for additional information types are [welcome here](http://thinklab.com/discussion/suggestions-for-additional-information-types/22).",
      "comment_id": 396,
      "profile_id": 17,
      "published": "2015-08-14T22:24:08.088663Z",
      "thread_id": 102,
      "url": "/discussion/one-network-to-rule-them-all/102"
    },
    {
      "body_html": "<p>Nice of you to share this big network with everyone; however, I think you need to take care not to get yourself into legal trouble here.</p>\r\n\r\n<p>I looked into the JSON network file and found the following:<br>- Gene membership of all KEGG maps. If you look at the <a href=\"http://www.kegg.jp/kegg/legal.html\">KEGG license</a>, it is questionable if you can do that at all, and very clear that you cannot allow commercial use.<br>- Side effect data from (I assume) SIDER. The SIDER download files are distributed under the <a href=\"http://creativecommons.org/licenses/by-nc-sa/3.0/\">CC-BY-NC-SA license</a>, which means that you are only allowed to redistribute if you give attribution and attach the same license to the derived work.</p>\r\n\r\n<p>Given earlier posts, I assume that you also import associations from the <a href=\"http://tissues.jensenlab.org/\">TISSUES database</a>. Even though I distribute this resource under the very permissive <a href=\"http://creativecommons.org/licenses/by/4.0/\">CC-BY license</a>, you are still required to give attribution. This could, for example, be done by including relevant linkouts under \"data\" : { \"url\" : \"...\" }.</p>\r\n\r\n<p>I am not trying to cause trouble here - just the contrary. When making a meta-resource, licenses and copyright law are not something you can afford to ignore. I regularly leave out certain data sources from my resources for legal reasons. For example, <a href=\"http://www.omim.org/\">OMIM</a> is not included in <a href=\"http://diseases.jensenlab.org/\">DISEASES</a> due to <a href=\"http://www.omim.org/help/agreement\">its restrictive license</a>.</p>",
      "body_md": "Nice of you to share this big network with everyone; however, I think you need to take care not to get yourself into legal trouble here.\r\n\r\nI looked into the JSON network file and found the following:\r\n- Gene membership of all KEGG maps. If you look at the [KEGG license](http://www.kegg.jp/kegg/legal.html), it is questionable if you can do that at all, and very clear that you cannot allow commercial use.\r\n- Side effect data from (I assume) SIDER. The SIDER download files are distributed under the [CC-BY-NC-SA license](http://creativecommons.org/licenses/by-nc-sa/3.0/), which means that you are only allowed to redistribute if you give attribution and attach the same license to the derived work.\r\n\r\nGiven earlier posts, I assume that you also import associations from the [TISSUES database](http://tissues.jensenlab.org/). Even though I distribute this resource under the very permissive [CC-BY license](http://creativecommons.org/licenses/by/4.0/), you are still required to give attribution. This could, for example, be done by including relevant linkouts under \"data\" : { \"url\" : \"...\" }.\r\n\r\nI am not trying to cause trouble here - just the contrary. When making a meta-resource, licenses and copyright law are not something you can afford to ignore. I regularly leave out certain data sources from my resources for legal reasons. For example, [OMIM](http://www.omim.org/) is not included in [DISEASES](http://diseases.jensenlab.org/) due to [its restrictive license](http://www.omim.org/help/agreement).",
      "comment_id": 397,
      "profile_id": 125,
      "published": "2015-08-16T07:35:00.051806Z",
      "thread_id": 102,
      "url": "/discussion/one-network-to-rule-them-all/102#2"
    },
    {
      "body_html": "<p>Related to the license issues, it is wise that you solicit advice from legal experts. However, as long as you are dealing with databases created by researchers in academia, the risk of actually getting sued is pretty minimal. The most important question that you should be asking yourself is thus not \"what can I technically do without risking to get sued?\", but rather \"what was the intent of the license?\". If you frequently do things that may be technically legal but clearly go against the intent of other researchers, you will quickly make many enemies.</p>\r\n\r\n<p>Just friendly words of advise :-)</p>",
      "body_md": "Related to the license issues, it is wise that you solicit advice from legal experts. However, as long as you are dealing with databases created by researchers in academia, the risk of actually getting sued is pretty minimal. The most important question that you should be asking yourself is thus not \"what can I technically do without risking to get sued?\", but rather \"what was the intent of the license?\". If you frequently do things that may be technically legal but clearly go against the intent of other researchers, you will quickly make many enemies.\r\n\r\nJust friendly words of advise :-)",
      "comment_id": 398,
      "profile_id": 125,
      "published": "2015-08-16T09:28:46.591169Z",
      "thread_id": 102,
      "url": "/discussion/one-network-to-rule-them-all/102#3"
    },
    {
      "body_html": "<p>We have been developing <a href=\"https://github.com/dhimmel/hetio\">tools</a> and <a href=\"http://het.io\">applications</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1004259\">1</a>, <a href=\"/p/rephetio\" class=\"citation\" data-key=\"10.15363/thinklab.4\">2</a>]</span> for <em>graphs with multiple node and edge types with optional directionality declared by the edge type</em>. Now, we would like to choose the best term for this definition.</p>\r\n\r\n<p>We have adopted a <a href=\"https://dx.doi.org/10.1371/journal.pcbi.1004259#article1.body1.sec4.sec2.p1\">nomenclature</a> where graph elements (nodes, edges, paths) are prepended with meta when referring to their type (metanodes, metaedges, metapaths). Support for directionality is necessitated by certain metaedges that connect a metanode to itself (<a href=\"http://thinklab.com/discussion/suggestions-for-additional-information-types/22#6\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d22\">example</a>). Whether our conception of directionality should be mandated by the definition is open for discussion.</p>\r\n\r\n<h2>Potential names</h2>\r\n\r\n<ul><li><strong>heterogeneous information network</strong> — the term used by the foundational works in social network analysis <span class=\"citation\">[<a href=\"https://doi.org/10.2200/S00433ED1V01Y201207DMK005\" class=\"citation\" data-key=\"10.2200/S00433ED1V01Y201207DMK005\">3</a>, <a href=\"https://doi.org/10.1109/ASONAM.2011.112\" class=\"citation\" data-key=\"10.1109/ASONAM.2011.112\">4</a>, <a href=\"https://doi.org/10.1109/ASONAM.2011.107\" class=\"citation\" data-key=\"10.1109/ASONAM.2011.107\">5</a>]</span> to describe a graph with typed nodes and edges. The 397 <a href=\"https://scholar.google.com/scholar?hl=en&amp;q=%22heterogeneous+information+network%22\">occurrences</a> in Google Scholar are of high precision. My major complaints with this term are its verbosity and drabness.</li><li><strong>heterogeneous network</strong> — the term we are currently using but that has a <a href=\"https://en.wikipedia.org/wiki/Heterogeneous_network\">preexisting meaning</a> in computer networking. The term retrieves 2,930 Google Scholar <a href=\"https://scholar.google.com/scholar?q=%22heterogeneous+network%22&amp;as_ylo=2015\">occurrences</a> since 2015 with precision below 50%. I dislike this term's ambiguity and use of \"heterogeneous\" which is lengthy and esoteric.</li><li><strong>other options</strong>: we would like suggestions for other names. The following criteria are important: brevity, precision (once adopted), intuitiveness, cheer, and accessibility.</li></ul>\r\n\r\n<h2>Related terms</h2>\r\n\r\n<p>Below, I list several graph types (out of many <span class=\"citation\">[<a href=\"https://doi.org/10.1002/bult.2010.1720360610\" class=\"citation\" data-key=\"10.1002/bult.2010.1720360610\">6</a>]</span>) that are related to but distinct from our definition:</p>\r\n\r\n<ul><li><a href=\"https://en.wikipedia.org/wiki/Multipartite_graph\">multipartite graphs</a> — graphs with typed nodes but without typed edges. Sometimes <span class=\"citation\">[<a href=\"https://doi.org/10.1103/physreve.79.036113\" class=\"citation\" data-key=\"10.1103/physreve.79.036113\">7</a>]</span> referred to as <em>multitype networks</em>.</li><li><a href=\"https://en.wikipedia.org/wiki/Multigraph\">multigraph</a> — graphs allowing multiple edges between the same source and target nodes but without typed edges. </li><li><a href=\"http://neo4j.com/docs/stable/cypher-cookbook-multirelational-social-network.html\">multi-relational graphs</a> — graphs with multiple edge types  </li><li><a href=\"https://github.com/tinkerpop/gremlin/wiki/Defining-a-Property-Graph\">property graphs</a> — directed multi-relational graphs with edge attributes.</li></ul>\r\n\r\n<h2>Seeking input</h2>\r\n\r\n<p>We would like input and suggestions. Some possibilities are polynets, hetnets, multigraphs, typednets, typedgraphs, and multitype networks.</p>\r\n\r\n<p>Collectively, we are pioneering a branch of network analysis that will play a prominent role going forward. We do not want to be hindered by vocabulary.</p>",
      "body_md": "We have been developing [tools](https://github.com/dhimmel/hetio) and [applications](http://het.io) [@10.1371/journal.pcbi.1004259 @10.15363/thinklab.4] for *graphs with multiple node and edge types with optional directionality declared by the edge type*. Now, we would like to choose the best term for this definition.\r\n\r\nWe have adopted a [nomenclature](https://dx.doi.org/10.1371/journal.pcbi.1004259#article1.body1.sec4.sec2.p1) where graph elements (nodes, edges, paths) are prepended with meta when referring to their type (metanodes, metaedges, metapaths). Support for directionality is necessitated by certain metaedges that connect a metanode to itself ([example](http://thinklab.com/discussion/suggestions-for-additional-information-types/22#6)). Whether our conception of directionality should be mandated by the definition is open for discussion.\r\n\r\n## Potential names\r\n\r\n+ **heterogeneous information network** -- the term used by the foundational works in social network analysis [@10.2200/S00433ED1V01Y201207DMK005 @10.1109/ASONAM.2011.112 @10.1109/ASONAM.2011.107] to describe a graph with typed nodes and edges. The 397 [occurrences](https://scholar.google.com/scholar?hl=en&q=%22heterogeneous+information+network%22) in Google Scholar are of high precision. My major complaints with this term are its verbosity and drabness.\r\n+ **heterogeneous network** -- the term we are currently using but that has a [preexisting meaning](https://en.wikipedia.org/wiki/Heterogeneous_network) in computer networking. The term retrieves 2,930 Google Scholar [occurrences](https://scholar.google.com/scholar?q=%22heterogeneous+network%22&as_ylo=2015) since 2015 with precision below 50%. I dislike this term's ambiguity and use of \"heterogeneous\" which is lengthy and esoteric.\r\n+ **other options**: we would like suggestions for other names. The following criteria are important: brevity, precision (once adopted), intuitiveness, cheer, and accessibility.\r\n\r\n## Related terms\r\n\r\nBelow, I list several graph types (out of many [@10.1002/bult.2010.1720360610]) that are related to but distinct from our definition:\r\n\r\n+ [multipartite graphs](https://en.wikipedia.org/wiki/Multipartite_graph) -- graphs with typed nodes but without typed edges. Sometimes [@10.1103/physreve.79.036113] referred to as *multitype networks*.\r\n+ [multigraph](https://en.wikipedia.org/wiki/Multigraph) -- graphs allowing multiple edges between the same source and target nodes but without typed edges. \r\n+ [multi-relational graphs](http://neo4j.com/docs/stable/cypher-cookbook-multirelational-social-network.html) -- graphs with multiple edge types  \r\n+ [property graphs](https://github.com/tinkerpop/gremlin/wiki/Defining-a-Property-Graph) -- directed multi-relational graphs with edge attributes.\r\n\r\n## Seeking input\r\n\r\nWe would like input and suggestions. Some possibilities are polynets, hetnets, multigraphs, typednets, typedgraphs, and multitype networks.\r\n\r\nCollectively, we are pioneering a branch of network analysis that will play a prominent role going forward. We do not want to be hindered by vocabulary.",
      "comment_id": 400,
      "profile_id": 17,
      "published": "2015-08-17T02:56:46.391930Z",
      "thread_id": 104,
      "url": "/discussion/renaming-heterogeneous-networks-to-a-more-concise-and-catchy-term/104"
    },
    {
      "body_html": "<p>Thanks to a suggestion by <a href=\"/u/janispi\" class=\"username\">@janispi</a>, we have begun processing <a href=\"http://www.disgenet.org/web/DisGeNET/menu/home\">DisGeNET</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/database/bav028\" class=\"citation\" data-key=\"10.1093/database/bav028\">1</a>, <a href=\"https://doi.org/10.1371/journal.pone.0020284\" class=\"citation\" data-key=\"10.1371/journal.pone.0020284\">2</a>, <a href=\"https://doi.org/10.1093/bioinformatics/btq538\" class=\"citation\" data-key=\"10.1093/bioinformatics/btq538\">3</a>]</span> to include as a disease–gene edge in our network.</p>\r\n\r\n<p>DisGeNET integrates <a href=\"http://www.disgenet.org/web/DisGeNET/menu/dbinfo#ontology\">associations</a> from many <a href=\"http://www.disgenet.org/web/DisGeNET/menu/dbinfo#sources\">sources</a> and provides a unified <a href=\"http://www.disgenet.org/web/DisGeNET/menu/dbinfo#score\">score</a> for each gene–disease pair.</p>\r\n\r\n<p>We will likely replace or merge the function edge we <a href=\"http://thinklab.com/discussion/functional-disease-annotations-for-genes-using-doaf/94\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d94\">extracted from DOAF</a> with DisGeNET.</p>\r\n\r\n<p>Diseases in DisGeNET are identified with UMLS identifiers. We were <a href=\"https://github.com/dhimmel/disgenet/blob/2154cd74307f92d00d2ed192c584cfb33733d7da/disgenet.ipynb\">able to map</a> 125 out of 137 of our <a href=\"http://thinklab.com/discussion/unifying-disease-vocabularies/44#6\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d44\">DO Slim</a> diseases.</p>",
      "body_md": "Thanks to a suggestion by @janispi, we have begun processing [DisGeNET](http://www.disgenet.org/web/DisGeNET/menu/home) [@10.1093/database/bav028 @10.1371/journal.pone.0020284 @10.1093/bioinformatics/btq538] to include as a disease--gene edge in our network.\r\n\r\nDisGeNET integrates [associations](http://www.disgenet.org/web/DisGeNET/menu/dbinfo#ontology) from many [sources](http://www.disgenet.org/web/DisGeNET/menu/dbinfo#sources) and provides a unified [score](http://www.disgenet.org/web/DisGeNET/menu/dbinfo#score) for each gene--disease pair.\r\n\r\nWe will likely replace or merge the function edge we [extracted from DOAF](http://thinklab.com/discussion/functional-disease-annotations-for-genes-using-doaf/94) with DisGeNET.\r\n\r\nDiseases in DisGeNET are identified with UMLS identifiers. We were [able to map](https://github.com/dhimmel/disgenet/blob/2154cd74307f92d00d2ed192c584cfb33733d7da/disgenet.ipynb) 125 out of 137 of our [DO Slim](http://thinklab.com/discussion/unifying-disease-vocabularies/44#6) diseases.",
      "comment_id": 401,
      "profile_id": 17,
      "published": "2015-08-18T03:46:33.049097Z",
      "thread_id": 105,
      "url": "/discussion/processing-disgenet-for-disease-gene-relationships/105"
    },
    {
      "body_html": "<h1>Data format suggestion</h1>\r\n\r\n<p>The datasets on the <a href=\"http://www.disgenet.org/web/DisGeNET/menu/downloads\">download page</a> are gzipped tarballs but only contain a single text file. Using <code>zless</code> or <code>pandas.read_table()</code> on the <code>tar.gz</code> file led to strange behavior. I ended up extracting the file from the tarball and then gzipping it again to reduce filesize (<a href=\"https://github.com/dhimmel/disgenet/blob/2154cd74307f92d00d2ed192c584cfb33733d7da/download/all_gene_disease_associations.txt.gz\">new file</a>).</p>\r\n\r\n<p><a href=\"/u/janispi\" class=\"username\">@janispi</a>, would it make sense to remove the tarball at your end and go with a plain <code>.txt.gz</code> or <code>.tsv.gz</code> extension?</p>",
      "body_md": "# Data format suggestion\r\n\r\nThe datasets on the [download page](http://www.disgenet.org/web/DisGeNET/menu/downloads) are gzipped tarballs but only contain a single text file. Using `zless` or `pandas.read_table()` on the `tar.gz` file led to strange behavior. I ended up extracting the file from the tarball and then gzipping it again to reduce filesize ([new file](https://github.com/dhimmel/disgenet/blob/2154cd74307f92d00d2ed192c584cfb33733d7da/download/all_gene_disease_associations.txt.gz)).\r\n\r\n@janispi, would it make sense to remove the tarball at your end and go with a plain `.txt.gz` or `.tsv.gz` extension?",
      "comment_id": 402,
      "profile_id": 17,
      "published": "2015-08-18T03:55:14.132455Z",
      "thread_id": 105,
      "url": "/discussion/processing-disgenet-for-disease-gene-relationships/105#2"
    },
    {
      "body_html": "<p>you should not be having problems, but maybe you should just untar the file and then load it? <br>Let me know how it goes, so if there is any issue, we will take care of it. </p>",
      "body_md": "you should not be having problems, but maybe you should just untar the file and then load it? \r\nLet me know how it goes, so if there is any issue, we will take care of it. ",
      "comment_id": 403,
      "profile_id": 129,
      "published": "2015-08-18T08:08:19.392686Z",
      "thread_id": 105,
      "url": "/discussion/processing-disgenet-for-disease-gene-relationships/105#3"
    },
    {
      "body_html": "<p>I ended up doing the following steps to strip out the tarball:</p>\r\n\r\n<pre><code class=\"no-highlight hljs\">tar -xzf all_gene_disease_associations.tar.gz\r\ngzip all_gene_disease_associations.txt\r\nrm all_gene_disease_associations.tar.gz</code></pre>\r\n\r\n<p>The procedure isn't difficult, but you could save users some time by doing away with the tarball, since it only contains a single file.</p>",
      "body_md": "I ended up doing the following steps to strip out the tarball:\r\n\r\n```shell\r\ntar -xzf all_gene_disease_associations.tar.gz\r\ngzip all_gene_disease_associations.txt\r\nrm all_gene_disease_associations.tar.gz\r\n```\r\n\r\nThe procedure isn't difficult, but you could save users some time by doing away with the tarball, since it only contains a single file.",
      "comment_id": 404,
      "profile_id": 17,
      "published": "2015-08-18T17:15:29.535230Z",
      "thread_id": 105,
      "url": "/discussion/processing-disgenet-for-disease-gene-relationships/105#4"
    },
    {
      "body_html": "<h1>Choosing a score threshold</h1>\r\n\r\n<p>DisGeNET includes a <a href=\"http://www.disgenet.org/web/DisGeNET/menu/dbinfo#score\">score</a> for reported gene–disease relationships, described as <span class=\"citation\">[<a href=\"https://doi.org/10.1093/database/bav028\" class=\"citation\" data-key=\"10.1093/database/bav028\">1</a>]</span>:</p>\r\n\r\n<blockquote><p>The score ranges from 0 to 1 and is computed according to the formula described in ‘Methods’ section. The DisGeNET score allows obtaining a ranking of GDAs and a straightforward classification of curated vs predicted vs literature-based associations since it stratifies the associations based on their level of evidence. For instance, associations only reported by UniProt or CTD, which have been curated by experts, have higher scores (i.e. associations with S ≥ 0.3) than those only supported by animal models or text-mining based sources.</p></blockquote>\r\n\r\n<p>We will need to choose a <a href=\"http://thinklab.com/discussion/the-tissues-resource-for-the-tissue-specificity-of-genes/91#4\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d91\">minumum threshold</a> for edge inclusion in our network. <a href=\"/u/janispi\" class=\"username\">@janispi</a>, can you give us some more information regarding scores? Specifically,</p>\r\n\r\n<ul><li>how do scores correspond to precision (the probability of the relationship being real)?</li><li>what is a reasonable cutoff to eliminate junk? Does any relationship with score &gt; 0 already have acceptable confidence?</li></ul>\r\n\r\n<p>We would like a permissive threshold, allowing up to a ~30% false discovery rate.</p>",
      "body_md": "# Choosing a score threshold\r\n\r\nDisGeNET includes a [score](http://www.disgenet.org/web/DisGeNET/menu/dbinfo#score) for reported gene--disease relationships, described as [@10.1093/database/bav028]:\r\n\r\n> The score ranges from 0 to 1 and is computed according to the formula described in ‘Methods’ section. The DisGeNET score allows obtaining a ranking of GDAs and a straightforward classification of curated vs predicted vs literature-based associations since it stratifies the associations based on their level of evidence. For instance, associations only reported by UniProt or CTD, which have been curated by experts, have higher scores (i.e. associations with S ≥ 0.3) than those only supported by animal models or text-mining based sources.\r\n\r\nWe will need to choose a [minumum threshold](http://thinklab.com/discussion/the-tissues-resource-for-the-tissue-specificity-of-genes/91#4) for edge inclusion in our network. @janispi, can you give us some more information regarding scores? Specifically,\r\n\r\n+ how do scores correspond to precision (the probability of the relationship being real)?\r\n+ what is a reasonable cutoff to eliminate junk? Does any relationship with score > 0 already have acceptable confidence?\r\n\r\nWe would like a permissive threshold, allowing up to a ~30% false discovery rate.",
      "comment_id": 405,
      "profile_id": 17,
      "published": "2015-08-18T17:44:36.017043Z",
      "thread_id": 105,
      "url": "/discussion/processing-disgenet-for-disease-gene-relationships/105#5"
    },
    {
      "body_html": "<h1>Naming disease–gene metaedges</h1>\r\n\r\n<p>Up till now, we have been calling our <a href=\"http://thinklab.com/discussion/extracting-disease-gene-associations-from-the-gwas-catalog/80\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d80\">edges from GWAS</a> \"associations\" and our <a href=\"http://thinklab.com/discussion/functional-disease-annotations-for-genes-using-doaf/94\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d94\">edges from DOAF</a> \"functions\".</p>\r\n\r\n<p>DisGeNET uses a different <a href=\"http://www.disgenet.org/web/DisGeNET/menu/dbinfo#ontology\">nomenclature</a>. 'Association' refers to all disease–gene relationships while 'genetic variation' is more in line with what we call 'association'.</p>\r\n\r\n<p>Should we continue to call our GWAS edge 'association' and put DisGeNET into our 'function' edge? Or we could rename 'function' to 'relationship' to be more general? Or we could switch our GWAS edge to 'variation'.</p>",
      "body_md": "# Naming disease--gene metaedges\r\n\r\nUp till now, we have been calling our [edges from GWAS](http://thinklab.com/discussion/extracting-disease-gene-associations-from-the-gwas-catalog/80) \"associations\" and our [edges from DOAF](http://thinklab.com/discussion/functional-disease-annotations-for-genes-using-doaf/94) \"functions\".\r\n\r\nDisGeNET uses a different [nomenclature](http://www.disgenet.org/web/DisGeNET/menu/dbinfo#ontology). 'Association' refers to all disease--gene relationships while 'genetic variation' is more in line with what we call 'association'.\r\n\r\nShould we continue to call our GWAS edge 'association' and put DisGeNET into our 'function' edge? Or we could rename 'function' to 'relationship' to be more general? Or we could switch our GWAS edge to 'variation'.",
      "comment_id": 406,
      "profile_id": 17,
      "published": "2015-08-18T17:56:25.861851Z",
      "thread_id": 105,
      "url": "/discussion/processing-disgenet-for-disease-gene-relationships/105#6"
    },
    {
      "body_html": "<p>I'm a fan of HetNets. It's short and catchy. It does seem to be used for wireless networking but if it's relatively unique in bioinformatics I think the short and catchy part is a big advantage.</p>",
      "body_md": "I'm a fan of HetNets. It's short and catchy. It does seem to be used for wireless networking but if it's relatively unique in bioinformatics I think the short and catchy part is a big advantage.",
      "comment_id": 407,
      "profile_id": 22,
      "published": "2015-08-18T19:01:30.203903Z",
      "thread_id": 104,
      "url": "/discussion/renaming-heterogeneous-networks-to-a-more-concise-and-catchy-term/104#2"
    },
    {
      "body_html": "<p>I would recommend using the same criteria as in DisGeNET. \"Genetic Variation\" would be equivalent to GWAS.</p>",
      "body_md": "I would recommend using the same criteria as in DisGeNET. \"Genetic Variation\" would be equivalent to GWAS.",
      "comment_id": 408,
      "profile_id": 129,
      "published": "2015-08-19T09:22:09.808177Z",
      "thread_id": 105,
      "url": "/discussion/processing-disgenet-for-disease-gene-relationships/105#7"
    },
    {
      "body_html": "<p><a href=\"/u/fbastian\" class=\"username\">@fbastian</a></p>\r\n\r\n<p>For now STARGEO annotations really funnel towards performing classical meta-analysis across studies given an standardized set of \"cases\" vs \"controls\".  This kind of fits with micro-array experimental design which usually \"contrast\" some type of case vs control.  So there is a concept of a control for a disease which may or may not be a \"healthy\" control.</p>",
      "body_md": "@fbastian\r\n\r\nFor now STARGEO annotations really funnel towards performing classical meta-analysis across studies given an standardized set of \"cases\" vs \"controls\".  This kind of fits with micro-array experimental design which usually \"contrast\" some type of case vs control.  So there is a concept of a control for a disease which may or may not be a \"healthy\" control.",
      "comment_id": 409,
      "profile_id": 121,
      "published": "2015-08-19T18:11:25.554602Z",
      "thread_id": 96,
      "url": "/discussion/stargeo-expression-signatures-for-disease-using-crowdsourced-geo-annotation/96#4"
    },
    {
      "body_html": "<p><a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a> </p>\r\n\r\n<p>We will soon have analyses working on the dev site: <a href=\"http://dev.stargeo.io\">http://dev.stargeo.io</a>.  We will probably shut down the old site by the end of the month.</p>",
      "body_md": "@dhimmel \r\n\r\nWe will soon have analyses working on the dev site: http://dev.stargeo.io.  We will probably shut down the old site by the end of the month.",
      "comment_id": 410,
      "profile_id": 121,
      "published": "2015-08-19T18:12:42.999473Z",
      "thread_id": 96,
      "url": "/discussion/stargeo-expression-signatures-for-disease-using-crowdsourced-geo-annotation/96#5"
    },
    {
      "body_html": "<p>The Experimental Factor Ontology (<a href=\"http://www.ebi.ac.uk/efo/\">EFO</a>) <span class=\"citation\">[<a href=\"https://doi.org/10.1093/bioinformatics/btq099\" class=\"citation\" data-key=\"10.1093/bioinformatics/btq099\">1</a>]</span> has a few terms related to what we need. For example,</p>\r\n\r\n<ul><li>case control design (<a href=\"http://www.ebi.ac.uk/efo/EFO_0001427\"><code>EFO:0001427</code></a>)</li><li>control (<a href=\"http://www.ebi.ac.uk/efo/EFO_0001461\"><code>EFO:0001461</code></a>)</li><li>individual (<a href=\"http://www.ebi.ac.uk/efo/EFO_0000542\"><code>EFO:0000542</code></a>)</li><li>tissue specimen (<a href=\"http://purl.obolibrary.org/obo/OBI_0001479\"><code>OBI:0001479</code></a>)</li></ul>\r\n\r\n<p>Ultimately, for a given disease, we want to be able to differentiate the following:</p>\r\n\r\n<ul><li>a healthy sample from healthy individual</li><li>a healthy sample from diseased individual</li><li>a disease sample from diseased individual</li></ul>\r\n\r\n<p>Essentially, we want to support two types of case-control analyses based on a single set of annotations:</p>\r\n\r\n<ol><li>samples from healthy individuals versus diseased individuals</li><li>samples from healthy tissue versus diseased tissue, where all samples may come from diseased individuals</li></ol>\r\n\r\n<p>It seems that most existing ontologies are good at describing the characteristics of a single sample — for example, its tissue of origin, the developmental stage of the donor, the phenotypes/diseases of the donor — but they are not good at allowing tagging for the sole purpose of contrast.</p>\r\n\r\n<p><a href=\"/u/idrdex\" class=\"username\">@idrdex</a> suggested that we could use \"qualifiers for the tags: like <code>PC_individual_case</code> vs <code>PC_individual_control</code> or <code>PC_tissue_case</code> vs <code>PC_tissue_control</code>\" I like this idea and think it is a good immediate solution.</p>",
      "body_md": "The Experimental Factor Ontology ([EFO](http://www.ebi.ac.uk/efo/)) [@10.1093/bioinformatics/btq099] has a few terms related to what we need. For example,\r\n\r\n+ case control design ([`EFO:0001427`](http://www.ebi.ac.uk/efo/EFO_0001427))\r\n+ control ([`EFO:0001461`](http://www.ebi.ac.uk/efo/EFO_0001461))\r\n+ individual ([`EFO:0000542`](http://www.ebi.ac.uk/efo/EFO_0000542))\r\n+ tissue specimen ([`OBI:0001479`](http://purl.obolibrary.org/obo/OBI_0001479))\r\n\r\nUltimately, for a given disease, we want to be able to differentiate the following:\r\n\r\n+ a healthy sample from healthy individual\r\n+ a healthy sample from diseased individual\r\n+ a disease sample from diseased individual\r\n\r\nEssentially, we want to support two types of case-control analyses based on a single set of annotations:\r\n\r\n1. samples from healthy individuals versus diseased individuals\r\n2. samples from healthy tissue versus diseased tissue, where all samples may come from diseased individuals\r\n\r\nIt seems that most existing ontologies are good at describing the characteristics of a single sample -- for example, its tissue of origin, the developmental stage of the donor, the phenotypes/diseases of the donor -- but they are not good at allowing tagging for the sole purpose of contrast.\r\n\r\n@idrdex suggested that we could use \"qualifiers for the tags: like `PC_individual_case` vs `PC_individual_control` or `PC_tissue_case` vs `PC_tissue_control`\" I like this idea and think it is a good immediate solution.",
      "comment_id": 411,
      "profile_id": 17,
      "published": "2015-08-19T18:53:33.878396Z",
      "thread_id": 96,
      "url": "/discussion/stargeo-expression-signatures-for-disease-using-crowdsourced-geo-annotation/96#6"
    },
    {
      "body_html": "<blockquote><p>Do the names on these edges actually matter based on how you are using the network?</p></blockquote>\r\n\r\n<p><a href=\"/u/b_good\" class=\"username\">@b_good</a>, for predicting the probability of efficacy of a compound–disease pair, the metaedge names do not matter. The <a href=\"http://het.io/hnep\">algorithm</a> only considers the structure of the network. The names are used to assist with interpretability. For example, the <em>CtGad</em> feature (capturing when a compound targets genes that are associated with the disease) may be predictive. In this case, we would conclude that disease-associated genes are informative for repurposing. If what <a href=\"http://thinklab.com/discussion/processing-disgenet-for-disease-gene-relationships/105#6\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d105\">we call</a> an 'association' is actually some other type of relationship, then the interpretation that associations are influential will be unfounded.</p>\r\n\r\n<p>When we have multiple metaedges between the same metanodes, we hope there is a difference in the type of information encoded. Otherwise, we would be better off having only a single metaedge. For example, we included <a href=\"http://thinklab.com/discussion/integrating-drug-target-information-from-bindingdb/53#5\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d53\">binding</a> and <a href=\"http://thinklab.com/discussion/protein-target-carrier-transporter-and-enzyme-interactions-in-drugbank/65#1\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d65\">target</a> edges between compounds and genes. It is unclear whether merging these edges would be beneficial, because it's difficult to know how they differ. Therefore, a good understanding what information each metaedge captures will assist with metagraph design. Accurate metaedge names can help with understanding edge content and therefore network design decisions.</p>\r\n\r\n<blockquote><p>Would also like to see how the result of other text-ming approaches would influence the outcome. e.g. would it change things if you swapped in the relations from semmedDB?</p></blockquote>\r\n\r\n<p>Currently, I am happy with the quality of our <a href=\"http://thinklab.com/discussion/mining-knowledge-from-medline-articles-and-their-indexed-mesh-terms/67\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d67\">MEDLINE topic cooccurrence</a> approach. I assume that you highlight <a href=\"http://skr3.nlm.nih.gov/SemMedDB/\">SemMedDB</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/bioinformatics/bts591\" class=\"citation\" data-key=\"10.1093/bioinformatics/bts591\">1</a>]</span> because it has the ability to extract the type of relationship. I agree this could be a valuable addition. However, in the interest of time, this will most likely have to wait till a successive project.</p>",
      "body_md": "> Do the names on these edges actually matter based on how you are using the network?\r\n\r\n@b_good, for predicting the probability of efficacy of a compound--disease pair, the metaedge names do not matter. The [algorithm](http://het.io/hnep) only considers the structure of the network. The names are used to assist with interpretability. For example, the *CtGad* feature (capturing when a compound targets genes that are associated with the disease) may be predictive. In this case, we would conclude that disease-associated genes are informative for repurposing. If what [we call](http://thinklab.com/discussion/processing-disgenet-for-disease-gene-relationships/105#6) an 'association' is actually some other type of relationship, then the interpretation that associations are influential will be unfounded.\r\n\r\nWhen we have multiple metaedges between the same metanodes, we hope there is a difference in the type of information encoded. Otherwise, we would be better off having only a single metaedge. For example, we included [binding](http://thinklab.com/discussion/integrating-drug-target-information-from-bindingdb/53#5) and [target](http://thinklab.com/discussion/protein-target-carrier-transporter-and-enzyme-interactions-in-drugbank/65#1) edges between compounds and genes. It is unclear whether merging these edges would be beneficial, because it's difficult to know how they differ. Therefore, a good understanding what information each metaedge captures will assist with metagraph design. Accurate metaedge names can help with understanding edge content and therefore network design decisions.\r\n\r\n> Would also like to see how the result of other text-ming approaches would influence the outcome. e.g. would it change things if you swapped in the relations from semmedDB?\r\n\r\nCurrently, I am happy with the quality of our [MEDLINE topic cooccurrence](http://thinklab.com/discussion/mining-knowledge-from-medline-articles-and-their-indexed-mesh-terms/67) approach. I assume that you highlight [SemMedDB](http://skr3.nlm.nih.gov/SemMedDB/) [@10.1093/bioinformatics/bts591] because it has the ability to extract the type of relationship. I agree this could be a valuable addition. However, in the interest of time, this will most likely have to wait till a successive project.",
      "comment_id": 412,
      "profile_id": 17,
      "published": "2015-08-20T06:09:34.741046Z",
      "thread_id": 48,
      "url": "/discussion/text-as-a-resource-for-network-population/48#4"
    },
    {
      "body_html": "<p><a href=\"/u/idrdex\" class=\"username\">@idrdex</a>: We've been doing some extensive curation (i.e. back to the literature describing the experiments) on ~1000 samples that matter a lot to a project that we're working on. A couple questions about STARGEO:<br>1) Is it going to/does it also include samples from organisms other than human?<br>2) What's the best way to contribute these annotations? Anything programmatic and/or spreadsheet friendly?<br>3) What's the API like to extract annotations?</p>\r\n\r\n<p>Thanks!<br>Casey</p>",
      "body_md": "@idrdex: We've been doing some extensive curation (i.e. back to the literature describing the experiments) on ~1000 samples that matter a lot to a project that we're working on. A couple questions about STARGEO:\r\n1) Is it going to/does it also include samples from organisms other than human?\r\n2) What's the best way to contribute these annotations? Anything programmatic and/or spreadsheet friendly?\r\n3) What's the API like to extract annotations?\r\n\r\nThanks!\r\nCasey",
      "comment_id": 413,
      "profile_id": 22,
      "published": "2015-08-20T16:26:43.227203Z",
      "thread_id": 96,
      "url": "/discussion/stargeo-expression-signatures-for-disease-using-crowdsourced-geo-annotation/96#7"
    },
    {
      "body_html": "<p>Analysis is working now here: <a href=\"http://dev.stargeo.io/analysis/\">http://dev.stargeo.io/analysis/</a></p>",
      "body_md": "Analysis is working now here: http://dev.stargeo.io/analysis/",
      "comment_id": 414,
      "profile_id": 121,
      "published": "2015-08-20T17:07:44.875916Z",
      "thread_id": 96,
      "url": "/discussion/stargeo-expression-signatures-for-disease-using-crowdsourced-geo-annotation/96#8"
    },
    {
      "body_html": "<h1>Preliminary processing complete</h1>\r\n\r\n<p>We processed DisGeNET by converting to DO Slim diseases (<a href=\"https://github.com/dhimmel/disgenet/blob/b21553d7fced15c309f0a7aa15fc68e4d3edaa03/disgenet.ipynb\">notebook</a>, <a href=\"https://github.com/dhimmel/disgenet/blob/b21553d7fced15c309f0a7aa15fc68e4d3edaa03/data/consolidated.tsv\">download</a>). We used propagated mappings, so for example relationships with relapsing-remitting multiple sclerosis would be included for multiple sclerosis.</p>\r\n\r\n<p>The result was 82,833 gene–disease associations. After filtering for scores ≥ 0.06, 7,779 associations remained with large variability in the number of associations per disease. Additionally, many of the associations appear to be 'genetic variation' edges, which may be captured by our <a href=\"http://thinklab.com/discussion/extracting-disease-gene-associations-from-the-gwas-catalog/80\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d80\">GWAS edge</a>. As a reminder, the 0.06 score threshold includes the following (thanks <a href=\"/u/janispi\" class=\"username\">@janispi</a>):</p>\r\n\r\n<blockquote><p>If you choose score ≥ 0.06, then you will be including associations reporting by curated sources, or having animal models supporting them, or being reported by several papers (20–200).</p></blockquote>\r\n\r\n<p>We mapped DO Slim terms to DisGeNET using UMLS cross-references. The UMLS cross-references in the DO were often non-exact, so one DO term would reference many UMLS terms. Several <a href=\"https://github.com/dhimmel/disgenet/blob/master/data/unmapped-umls.tsv\">UMLS terms</a> referenced by the DO were not in DisGeNET.</p>",
      "body_md": "# Preliminary processing complete\r\n\r\nWe processed DisGeNET by converting to DO Slim diseases ([notebook](https://github.com/dhimmel/disgenet/blob/b21553d7fced15c309f0a7aa15fc68e4d3edaa03/disgenet.ipynb), [download](https://github.com/dhimmel/disgenet/blob/b21553d7fced15c309f0a7aa15fc68e4d3edaa03/data/consolidated.tsv)). We used propagated mappings, so for example relationships with relapsing-remitting multiple sclerosis would be included for multiple sclerosis.\r\n\r\nThe result was 82,833 gene--disease associations. After filtering for scores ≥ 0.06, 7,779 associations remained with large variability in the number of associations per disease. Additionally, many of the associations appear to be 'genetic variation' edges, which may be captured by our [GWAS edge](http://thinklab.com/discussion/extracting-disease-gene-associations-from-the-gwas-catalog/80). As a reminder, the 0.06 score threshold includes the following (thanks @janispi):\r\n\r\n> If you choose score ≥ 0.06, then you will be including associations reporting by curated sources, or having animal models supporting them, or being reported by several papers (20--200).\r\n\r\nWe mapped DO Slim terms to DisGeNET using UMLS cross-references. The UMLS cross-references in the DO were often non-exact, so one DO term would reference many UMLS terms. Several [UMLS terms](https://github.com/dhimmel/disgenet/blob/master/data/unmapped-umls.tsv) referenced by the DO were not in DisGeNET.",
      "comment_id": 415,
      "profile_id": 17,
      "published": "2015-08-20T20:58:18.326439Z",
      "thread_id": 105,
      "url": "/discussion/processing-disgenet-for-disease-gene-relationships/105#8"
    },
    {
      "body_html": "<p>We are looking into <a href=\"http://diseases.jensenlab.org/Search\">DISEASES</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.ymeth.2014.11.020\" class=\"citation\" data-key=\"10.1016/j.ymeth.2014.11.020\">1</a>]</span> as a resource for gene–disease relationships. This database is produced by <a href=\"/u/larsjuhljensen\" class=\"username\">@larsjuhljensen</a>'s group and follows similar protocols as <a href=\"http://tissues.jensenlab.org/Search\">TISSUES</a> <span class=\"citation\">[<a href=\"https://doi.org/10.7717/peerj.1054\" class=\"citation\" data-key=\"10.7717/peerj.1054\">2</a>]</span>, which we have <a href=\"http://thinklab.com/discussion/the-tissues-resource-for-the-tissue-specificity-of-genes/91\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d91\">already processed</a>.</p>\r\n\r\n<p>DISEASES includes three types of evidence:</p>\r\n\r\n<ul><li><strong>text mining</strong>: using named entity recognition to look for disease–protein cooccurrences in abstracts and sentences. <a href=\"/u/larsjuhljensen\" class=\"username\">@larsjuhljensen</a>, which literature corpus was used?</li><li><strong>knowledge</strong>: curated relationships from <a href=\"http://ghr.nlm.nih.gov/\">GHR</a> and <a href=\"http://www.uniprot.org/uniprot/\">UniProtKB</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkt1140\" class=\"citation\" data-key=\"10.1093/nar/gkt1140\">3</a>]</span></li><li><strong>experiments</strong>: cancer mutation data from <a href=\"http://cancer.sanger.ac.uk/cosmic\">COSMIC</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gku1075\" class=\"citation\" data-key=\"10.1093/nar/gku1075\">4</a>, <a href=\"https://doi.org/10.1002/0471142905.hg1011s57\" class=\"citation\" data-key=\"10.1002/0471142905.hg1011s57\">5</a>]</span> and GWAS data from <a href=\"http://distild.jensenlab.org/about.html\">DistiLD</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkr899\" class=\"citation\" data-key=\"10.1093/nar/gkr899\">6</a>]</span></li></ul>\r\n\r\n<p>We did a preliminary processing of the integrated dataset, which yielded 81,499 gene–disease relationships for <a href=\"http://thinklab.com/discussion/unifying-disease-vocabularies/44#6\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d44\">DO Slim</a> diseases (<a href=\"https://github.com/dhimmel/diseases/blob/9ffce4c46d243392a66192ec879df153b2f6830a/diseases.ipynb\">notebook</a>, <a href=\"https://github.com/dhimmel/diseases/blob/9ffce4c46d243392a66192ec879df153b2f6830a/data/integrated.tsv\">download</a>). Filtering for scores ≥ 3, resulted in 2,441 relationships.</p>\r\n\r\n<p><a href=\"/u/larsjuhljensen\" class=\"username\">@larsjuhljensen</a>, are scores in DISEASES comparable between datasets? In other words, are confidence scores standardized to a common gold standard?</p>\r\n\r\n<p>We may consider creating an <a href=\"http://thinklab.com/discussion/the-tissues-resource-for-the-tissue-specificity-of-genes/91#7\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d91\">integrated score</a> excluding DistiLD, since we have a <a href=\"http://thinklab.com/discussion/extracting-disease-gene-associations-from-the-gwas-catalog/80\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d80\">distinct GWAS edge</a>.</p>",
      "body_md": "We are looking into [DISEASES](http://diseases.jensenlab.org/Search) [@10.1016/j.ymeth.2014.11.020] as a resource for gene--disease relationships. This database is produced by @larsjuhljensen's group and follows similar protocols as [TISSUES](http://tissues.jensenlab.org/Search) [@10.7717/peerj.1054], which we have [already processed](http://thinklab.com/discussion/the-tissues-resource-for-the-tissue-specificity-of-genes/91).\r\n\r\nDISEASES includes three types of evidence:\r\n\r\n+ **text mining**: using named entity recognition to look for disease--protein cooccurrences in abstracts and sentences. @larsjuhljensen, which literature corpus was used?\r\n+ **knowledge**: curated relationships from [GHR](http://ghr.nlm.nih.gov/) and [UniProtKB](http://www.uniprot.org/uniprot/) [@10.1093/nar/gkt1140]\r\n+ **experiments**: cancer mutation data from [COSMIC](http://cancer.sanger.ac.uk/cosmic) [@10.1093/nar/gku1075 @10.1002/0471142905.hg1011s57] and GWAS data from [DistiLD](http://distild.jensenlab.org/about.html) [@10.1093/nar/gkr899]\r\n\r\nWe did a preliminary processing of the integrated dataset, which yielded 81,499 gene–disease relationships for [DO Slim](http://thinklab.com/discussion/unifying-disease-vocabularies/44#6) diseases ([notebook](https://github.com/dhimmel/diseases/blob/9ffce4c46d243392a66192ec879df153b2f6830a/diseases.ipynb), [download](https://github.com/dhimmel/diseases/blob/9ffce4c46d243392a66192ec879df153b2f6830a/data/integrated.tsv)). Filtering for scores ≥ 3, resulted in 2,441 relationships.\r\n\r\n@larsjuhljensen, are scores in DISEASES comparable between datasets? In other words, are confidence scores standardized to a common gold standard?\r\n\r\nWe may consider creating an [integrated score](http://thinklab.com/discussion/the-tissues-resource-for-the-tissue-specificity-of-genes/91#7) excluding DistiLD, since we have a [distinct GWAS edge](http://thinklab.com/discussion/extracting-disease-gene-associations-from-the-gwas-catalog/80).",
      "comment_id": 416,
      "profile_id": 17,
      "published": "2015-08-20T21:45:22.268315Z",
      "thread_id": 106,
      "url": "/discussion/processing-the-diseases-resource-for-diseasegene-relationships/106"
    },
    {
      "body_html": "<h1>Network overview</h1>\r\n\r\n<p>We recently released the <a href=\"http://thinklab.com/discussion/one-network-to-rule-them-all/102\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d102\">first version</a> of our network containing 10 node types and 27 edge types. The network contains data (nodes and edges) extracted from <a href=\"https://github.com/dhimmel/integrate/tree/0e343d8745a98757c86e73f645b41353f52b82b5/licenses\">28 resources</a>. Many of these 28 resources have themselves compiled data from disparately-licensed resources. In addition:</p>\r\n\r\n<ul><li>12 lack any licensing information</li><li>10 use standard licenses</li><li>6 use custom licenses</li><li>3 resources are publication supplements</li><li>6 forbid commercial use</li><li>2 forbid any redistribution of the data</li></ul>\r\n\r\n<h1>Why an open network</h1>\r\n\r\n<p>We <a href=\"http://thinklab.com/discussion/enabling-reproducibility-and-reuse/23#6\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d23\">are committed</a> to performing an open project, where all code, data, analyses, and results are maximally reproducible and reusable. The foundation of our research is that datasets are more informative when placed in a broader context. Through integration, we create a resource that is more informative and versatile than the 28 separate sources.</p>\r\n\r\n<p>However, data integration is challenging and time intensive. Thus far, our integration effort consists of an 8 month time investment, 41 Thinklab <a href=\"http://thinklab.com/p/rephetio/discussion\">discussions</a>, and 35 GitHub <a href=\"https://github.com/dhimmel?tab=repositories\">repositories</a>. By making our network public and extensible, other researchers can avoid this laborious process while harnessing the benefits of integration.</p>\r\n\r\n<h1>The licensing problem</h1>\r\n\r\n<p>We initially released our network under the <a href=\"https://creativecommons.org/publicdomain/zero/1.0/\">CC0</a> (public domain) license, but <a href=\"/u/larsjuhljensen\" class=\"username\">@larsjuhljensen</a> <a href=\"http://thinklab.com/discussion/one-network-to-rule-them-all/102#2\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d102\">pointed out</a> that this may violate many sources' licensing. While we used only publicly available resources — funded primarily by the public — many resources are burdened by restrictive licenses. We now must integrate data with incompatible licenses that require legal expertise to understand and operate in jurisdiction dependent manners.</p>\r\n\r\n<h1>Compliance and caveats</h1>\r\n\r\n<p>We are seeking expert advice on how to proceed. We would like to achieve the following:</p>\r\n\r\n<ul><li>a network that is publicly available in full and maximally unrestricted</li><li>public domain findings. Foremost, unencumbered predictions of drug efficacy</li><li>legal compliance</li><li>normative compliance that respects the intent of the data creators</li><li>minimal pruning of the current network to preserve our investment</li></ul>\r\n\r\n<p>We plan to add node/edge-specific attribution and license information to our network, but will await expert advice before proceeding.</p>",
      "body_md": "# Network overview\r\n\r\nWe recently released the [first version](http://thinklab.com/discussion/one-network-to-rule-them-all/102) of our network containing 10 node types and 27 edge types. The network contains data (nodes and edges) extracted from [28 resources](https://github.com/dhimmel/integrate/tree/0e343d8745a98757c86e73f645b41353f52b82b5/licenses). Many of these 28 resources have themselves compiled data from disparately-licensed resources. In addition:\r\n\r\n+ 12 lack any licensing information\r\n+ 10 use standard licenses\r\n+ 6 use custom licenses\r\n+ 3 resources are publication supplements\r\n+ 6 forbid commercial use\r\n+ 2 forbid any redistribution of the data\r\n\r\n# Why an open network\r\n\r\nWe [are committed](http://thinklab.com/discussion/enabling-reproducibility-and-reuse/23#6) to performing an open project, where all code, data, analyses, and results are maximally reproducible and reusable. The foundation of our research is that datasets are more informative when placed in a broader context. Through integration, we create a resource that is more informative and versatile than the 28 separate sources.\r\n\r\nHowever, data integration is challenging and time intensive. Thus far, our integration effort consists of an 8 month time investment, 41 Thinklab [discussions](http://thinklab.com/p/rephetio/discussion), and 35 GitHub [repositories](https://github.com/dhimmel?tab=repositories). By making our network public and extensible, other researchers can avoid this laborious process while harnessing the benefits of integration.\r\n\r\n# The licensing problem\r\n\r\nWe initially released our network under the [CC0](https://creativecommons.org/publicdomain/zero/1.0/) (public domain) license, but @larsjuhljensen [pointed out](http://thinklab.com/discussion/one-network-to-rule-them-all/102#2) that this may violate many sources' licensing. While we used only publicly available resources -- funded primarily by the public -- many resources are burdened by restrictive licenses. We now must integrate data with incompatible licenses that require legal expertise to understand and operate in jurisdiction dependent manners.\r\n\r\n#  Compliance and caveats\r\n\r\nWe are seeking expert advice on how to proceed. We would like to achieve the following:\r\n\r\n+ a network that is publicly available in full and maximally unrestricted\r\n+ public domain findings. Foremost, unencumbered predictions of drug efficacy\r\n+ legal compliance\r\n+ normative compliance that respects the intent of the data creators\r\n+ minimal pruning of the current network to preserve our investment\r\n\r\nWe plan to add node/edge-specific attribution and license information to our network, but will await expert advice before proceeding.",
      "comment_id": 417,
      "profile_id": 17,
      "published": "2015-08-28T19:10:38.921394Z",
      "thread_id": 107,
      "url": "/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107"
    },
    {
      "body_html": "<p>Regarding the scores, they are designed to be as comparable as we could make them; however, it was not possible to do so purely through benchmarking, since a high-quality unbiased benchmark set does not exist.</p>\r\n\r\n<p>If you already have GWAS from another source, I would exclude DistiLD too. You already import mutation data from e.g. COSMIC, I would exclude the experiments channel entirely. This also makes comparability of scores much less of an issue, since you're left with only automatically text-mined associations, which are scores the same way as tissue associations, and manually curated associations, which are inherently highly reliable.</p>",
      "body_md": "Regarding the scores, they are designed to be as comparable as we could make them; however, it was not possible to do so purely through benchmarking, since a high-quality unbiased benchmark set does not exist.\r\n\r\nIf you already have GWAS from another source, I would exclude DistiLD too. You already import mutation data from e.g. COSMIC, I would exclude the experiments channel entirely. This also makes comparability of scores much less of an issue, since you're left with only automatically text-mined associations, which are scores the same way as tissue associations, and manually curated associations, which are inherently highly reliable.",
      "comment_id": 418,
      "profile_id": 125,
      "published": "2015-08-21T05:35:20.574451Z",
      "thread_id": 106,
      "url": "/discussion/processing-the-diseases-resource-for-diseasegene-relationships/106#2"
    },
    {
      "body_html": "<h1>Completed processing</h1>\r\n\r\n<p>We have completed an initial processing of DISEASES (<a href=\"https://github.com/dhimmel/diseases/blob/e0089ef89a56348d7d4e0684a9c51c5747b16237/diseases.ipynb\">notebook</a>). The output is a tsv of gene–disease pairs (<a href=\"https://github.com/dhimmel/diseases/blob/e0089ef89a56348d7d4e0684a9c51c5747b16237/data/merged.tsv.gz\">download</a>) with scores for following channels:</p>\r\n\r\n<ul><li>text mining</li><li>knowledge</li><li>cosmic — the COSMIC subset of the experiments channel</li><li>distild — the DistiLD subset of the experiments channel</li><li>integrated_no_distild — the integration of the four aforementioned scores</li><li>integrated — the integrated score calculated by the DISEASES team, without any exclusions</li></ul>\r\n\r\n<p>Genes were converted to Entrez identifiers using the STRING 9.1 mapping (<a href=\"ftp://string-db.org/STRING/9.1/mapping_files/Entrez_mappings/entrez_gene_id.vs.string.v9.05.28122012.txt\"><code>entrez_gene_id.vs.string.v9.05.28122012.txt</code></a>). We also created a dataset with only <a href=\"http://thinklab.com/discussion/unifying-disease-vocabularies/44#6\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d44\">DO Slim</a> diseases (<a href=\"https://github.com/dhimmel/diseases/blob/e0089ef89a56348d7d4e0684a9c51c5747b16237/data/merged-slim.tsv\">download</a>). For this file, we propagated scores from subsumed diseases and reported the max.</p>\r\n\r\n<h2>Visualizing channel concordance</h2>\r\n\r\n<p>We visualized the relationships between scores on the full dataset. The off-diagonal plots show a 2D histogram, using hexagonal bins. The diagonal of the grid contains 1D histograms for the x-variable. Bin counts for all panels are log-transformed.</p>\r\n\r\n<p><img src=\"https://raw.githubusercontent.com/dhimmel/diseases/e0089ef89a56348d7d4e0684a9c51c5747b16237/figure/channel-histograms.png\" alt=\"\"></p>",
      "body_md": "# Completed processing\r\n\r\nWe have completed an initial processing of DISEASES ([notebook](https://github.com/dhimmel/diseases/blob/e0089ef89a56348d7d4e0684a9c51c5747b16237/diseases.ipynb)). The output is a tsv of gene--disease pairs ([download](https://github.com/dhimmel/diseases/blob/e0089ef89a56348d7d4e0684a9c51c5747b16237/data/merged.tsv.gz)) with scores for following channels:\r\n\r\n+ text mining\r\n+ knowledge\r\n+ cosmic -- the COSMIC subset of the experiments channel\r\n+ distild -- the DistiLD subset of the experiments channel\r\n+ integrated_no_distild -- the integration of the four aforementioned scores\r\n+ integrated -- the integrated score calculated by the DISEASES team, without any exclusions\r\n\r\nGenes were converted to Entrez identifiers using the STRING 9.1 mapping ([`entrez_gene_id.vs.string.v9.05.28122012.txt`](ftp://string-db.org/STRING/9.1/mapping_files/Entrez_mappings/entrez_gene_id.vs.string.v9.05.28122012.txt)). We also created a dataset with only [DO Slim](http://thinklab.com/discussion/unifying-disease-vocabularies/44#6) diseases ([download](https://github.com/dhimmel/diseases/blob/e0089ef89a56348d7d4e0684a9c51c5747b16237/data/merged-slim.tsv)). For this file, we propagated scores from subsumed diseases and reported the max.\r\n\r\n## Visualizing channel concordance\r\n\r\nWe visualized the relationships between scores on the full dataset. The off-diagonal plots show a 2D histogram, using hexagonal bins. The diagonal of the grid contains 1D histograms for the x-variable. Bin counts for all panels are log-transformed.\r\n\r\n![](https://raw.githubusercontent.com/dhimmel/diseases/e0089ef89a56348d7d4e0684a9c51c5747b16237/figure/channel-histograms.png)",
      "comment_id": 419,
      "profile_id": 17,
      "published": "2015-08-21T20:49:59.898726Z",
      "thread_id": 106,
      "url": "/discussion/processing-the-diseases-resource-for-diseasegene-relationships/106#3"
    },
    {
      "body_html": "<p>You may also want to consider splitting the network into multiple files. For example, you may have a base file that includes, for example, only public domain and CC-BY content. The edges with SA and/or NC clauses could be in \"add-on\" files. This partially avoids the problem that your complete network file becomes subject to the lowest common denominator.</p>\r\n\r\n<p>Having multiple files will allow people to \"pick their poison\", so to speak. If they need the most permissive license, they will get a less complete network. If they want the most complete network, they will have to live with a less permissive license.</p>",
      "body_md": "You may also want to consider splitting the network into multiple files. For example, you may have a base file that includes, for example, only public domain and CC-BY content. The edges with SA and/or NC clauses could be in \"add-on\" files. This partially avoids the problem that your complete network file becomes subject to the lowest common denominator.\r\n\r\nHaving multiple files will allow people to \"pick their poison\", so to speak. If they need the most permissive license, they will get a less complete network. If they want the most complete network, they will have to live with a less permissive license.",
      "comment_id": 420,
      "profile_id": 125,
      "published": "2015-08-28T19:37:36.448537Z",
      "thread_id": 107,
      "url": "/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#2"
    },
    {
      "body_html": "<p>Regarding the 12 that completely lack any licensing information, I would contact the authors. For academic databases/datasets, this is usually due to people not knowing that when it comes to copyright, the default is \"all rights reserved\". Academics often put things on the internet, thinking that this makes it \"public domain\". If you ask them, they will likely be happy to put a CC0 waiver or CC-BY license on it.</p>",
      "body_md": "Regarding the 12 that completely lack any licensing information, I would contact the authors. For academic databases/datasets, this is usually due to people not knowing that when it comes to copyright, the default is \"all rights reserved\". Academics often put things on the internet, thinking that this makes it \"public domain\". If you ask them, they will likely be happy to put a CC0 waiver or CC-BY license on it.",
      "comment_id": 421,
      "profile_id": 125,
      "published": "2015-08-28T21:19:52.274011Z",
      "thread_id": 107,
      "url": "/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#3"
    },
    {
      "body_html": "<h1>Conda for R</h1>\r\n\r\n<p>Conda is an awesome package manager that <a href=\"http://thinklab.com/discussion/python-for-the-modern-biodata-scientist/84\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d84\">we've been using</a> for Python. In most cases, conda alleviates the horror of installation errors and dependencies.</p>\r\n\r\n<p>Now conda is <a href=\"http://continuum.io/conda-for-R\">available for R</a>. In other words, you can install R using the following command:</p>\r\n\r\n<pre><code class=\"no-highlight hljs\">conda install --channel r r</code></pre>\r\n\r\n<p>I found many of my favorite R packages were available in conda's r channel, usually with <code>r-</code> prepended to their lowercased name. For example, I installed <code>r-ggplot2</code>, <code>r-tidyr</code>, <code>r-dplyr</code>, <code>r-caret</code>, and <code>r-glmnet</code>. For notebook support, I installed <code>rpy2</code> and <code>r-irkernel</code>.</p>\r\n\r\n<p>Installing R packages that are not included in conda's channel became more difficult after the switch to conda management. For example, <code>devtools::install_github()</code> was failing, and when doing traditional package installation, I had to specify the repos argument because the GUI popup was broken:</p>\r\n\r\n<pre><code class=\"r\">install.packages('readr', repos='http://cran.us.r-project.org')</code></pre>\r\n\r\n<p>Conda can definitely save R users lots of frustration, but I suggest the general user wait for greater maturity before adoption.</p>",
      "body_md": "# Conda for R\r\n\r\nConda is an awesome package manager that [we've been using](http://thinklab.com/discussion/python-for-the-modern-biodata-scientist/84) for Python. In most cases, conda alleviates the horror of installation errors and dependencies.\r\n\r\nNow conda is [available for R](http://continuum.io/conda-for-R). In other words, you can install R using the following command:\r\n\r\n```shell\r\nconda install --channel r r\r\n```\r\n\r\nI found many of my favorite R packages were available in conda's r channel, usually with `r-` prepended to their lowercased name. For example, I installed `r-ggplot2`, `r-tidyr`, `r-dplyr`, `r-caret`, and `r-glmnet`. For notebook support, I installed `rpy2` and `r-irkernel`.\r\n\r\nInstalling R packages that are not included in conda's channel became more difficult after the switch to conda management. For example, `devtools::install_github()` was failing, and when doing traditional package installation, I had to specify the repos argument because the GUI popup was broken:\r\n\r\n```r\r\ninstall.packages('readr', repos='http://cran.us.r-project.org')\r\n```\r\n\r\nConda can definitely save R users lots of frustration, but I suggest the general user wait for greater maturity before adoption.",
      "comment_id": 422,
      "profile_id": 17,
      "published": "2015-08-29T19:43:43.418204Z",
      "thread_id": 83,
      "url": "/discussion/r-best-practices/83#2"
    },
    {
      "body_html": "<h1>Workflow details</h1>\r\n\r\n<p>Our data workflow consists of three major stages. Each stage invokes various <a href=\"http://www.smashingmagazine.com/2011/06/understanding-copyright-and-licenses/\">aspects of copyright</a> as described below</p>\r\n\r\n<h2>1) Resource processing</h2>\r\n\r\n<p>Most resources require processing before they can be added to the network. Common steps include terminology conversion, quality control, subsetting, and record merging.</p>\r\n\r\n<p>Our general procedure is to create a public GitHub repository for each resource (examples <a href=\"https://github.com/dhimmel/diseases\">1</a>, <a href=\"https://github.com/dhimmel/SIDER4\">2</a>, <a href=\"https://github.com/dhimmel/lincs\">3</a>, <a href=\"https://github.com/dhimmel/uberon\">4</a>, <a href=\"https://github.com/dhimmel/drugbank\">5</a>). Separate repositories help keep the project modular and reusable. Each repository contains a <code>download</code> directory where we store the unmodified input. Having the local copy is important for reproducibility because the original download location may become unavailable or serve an updated dataset. Therefore, our <code>download</code> directory redistributes unmodified data.</p>\r\n\r\n<p>Next, we process data from the <code>download</code> directory and save the resulting datasets in the <code>data</code> directory. The processing steps generally change the database model and field names and include a substantial portion of the original data. However, the original data has usually been transformed in some regard.</p>\r\n\r\n<p><strong>Proposed action</strong>: apply the source's license to the contents of <code>download</code>. For the contents of <code>data</code>, apply either the source's license or CC0 if the underlying data is not <a href=\"http://www.bitlaw.com/copyright/database.html\">subject to copyright</a> or the derivative work qualifies as fair use. Resources without a license or that explicitly forbid redistribution are problematic. We propose contacting the creators of these resources for permission or licensing clarification. Components in these repositories that do not derive from protected resources will be released as CC0.</p>\r\n\r\n<h2>2) Integrative network</h2>\r\n\r\n<p>Our <a href=\"https://github.com/dhimmel/integrate\"><code>integrate</code></a> repository combines the resource-specific data from stage 1 into a single network. The <a href=\"https://github.com/dhimmel/integrate/tree/master/compile\"><code>compile</code></a> directory merges resources with the same type of information. The creation of the network is performed by <a href=\"https://github.com/dhimmel/integrate/blob/master/integrate.ipynb\"><code>integrate.ipynb</code></a>. We have <a href=\"https://github.com/dhimmel/integrate/tree/master/licenses\">compiled</a> the licenses for each resource. The network is saved as text files in the <a href=\"https://github.com/dhimmel/integrate/tree/master/data\"><code>data</code></a> directory with <a href=\"https://github.com/dhimmel/integrate/blob/master/data/hetnet.json.gz\"><code>hetnet.json.gz</code></a> as the main release. In this integrated network, the database model and field names from the original resource are not present, just derived data.</p>\r\n\r\n<p><strong>Proposed action</strong>: Adopt a per node/edge licensing framework. Identify which nodes and edges, if any, are eligible for CC0 release. CC0 release may be possible if the creators chose a permissive license or give us permission, the network is fair use, or if the underlying content is not subject to copyright.</p>\r\n\r\n<h2>3) Network analyses</h2>\r\n\r\n<p>Next, we use the integrated network from stage 2 for data mining. The purpose of the data mining is to evaluate methods, extract insights, and make predictions. As an example, see <a href=\"https://github.com/dhimmel/snplentiful\">this analysis</a> <span class=\"citation\">[<a href=\"https://doi.org/10.5281/zenodo.30105\" class=\"citation\" data-key=\"10.5281/zenodo.30105\">1</a>]</span> of the network that <a href=\"/u/caseygreene\" class=\"username\">@caseygreene</a> and I recently did for a separate project.</p>\r\n\r\n<p>Here, it is crucial that findings from analyses on the network are fair use and can be placed in the public domain. Since, the network contains data with <a href=\"https://wiki.creativecommons.org/wiki/Wiki/cc_license_compatibility\">incompatible</a> licenses such as CC-BY-SA and CC-BY-NC, data mining will be impossible if not considered fair use. In the US, <a href=\"http://www.arl.org/storage/documents/TDM-5JUNE2015.pdf\">precedent</a> implies our network analyses qualify as fair use. </p>\r\n\r\n<p><strong>Proposed action</strong>: Identify whether our network analyses qualify as fair use and whether our results can be released as CC0. Evaluate when and if we are subject to European copyright laws, which are less favorable for content users.</p>\r\n\r\n<h1>Expert feedback requested</h1>\r\n\r\n<p>We are seeking expert advice. Specifically, are the proposed actions compliant with copyright law? Regarding the three stages, are we on the right track? Will network analyses count as fair use?</p>",
      "body_md": "# Workflow details\r\n\r\nOur data workflow consists of three major stages. Each stage invokes various [aspects of copyright](http://www.smashingmagazine.com/2011/06/understanding-copyright-and-licenses/) as described below\r\n\r\n## 1) Resource processing\r\n\r\nMost resources require processing before they can be added to the network. Common steps include terminology conversion, quality control, subsetting, and record merging.\r\n\r\nOur general procedure is to create a public GitHub repository for each resource (examples [1](https://github.com/dhimmel/diseases), [2](https://github.com/dhimmel/SIDER4), [3](https://github.com/dhimmel/lincs), [4](https://github.com/dhimmel/uberon), [5](https://github.com/dhimmel/drugbank)). Separate repositories help keep the project modular and reusable. Each repository contains a `download` directory where we store the unmodified input. Having the local copy is important for reproducibility because the original download location may become unavailable or serve an updated dataset. Therefore, our `download` directory redistributes unmodified data.\r\n\r\nNext, we process data from the `download` directory and save the resulting datasets in the `data` directory. The processing steps generally change the database model and field names and include a substantial portion of the original data. However, the original data has usually been transformed in some regard.\r\n\r\n**Proposed action**: apply the source's license to the contents of `download`. For the contents of `data`, apply either the source's license or CC0 if the underlying data is not [subject to copyright](http://www.bitlaw.com/copyright/database.html) or the derivative work qualifies as fair use. Resources without a license or that explicitly forbid redistribution are problematic. We propose contacting the creators of these resources for permission or licensing clarification. Components in these repositories that do not derive from protected resources will be released as CC0.\r\n\r\n## 2) Integrative network\r\n\r\nOur [`integrate`](https://github.com/dhimmel/integrate) repository combines the resource-specific data from stage 1 into a single network. The [`compile`](https://github.com/dhimmel/integrate/tree/master/compile) directory merges resources with the same type of information. The creation of the network is performed by [`integrate.ipynb`](https://github.com/dhimmel/integrate/blob/master/integrate.ipynb). We have [compiled](https://github.com/dhimmel/integrate/tree/master/licenses) the licenses for each resource. The network is saved as text files in the [`data`](https://github.com/dhimmel/integrate/tree/master/data) directory with [`hetnet.json.gz`](https://github.com/dhimmel/integrate/blob/master/data/hetnet.json.gz) as the main release. In this integrated network, the database model and field names from the original resource are not present, just derived data.\r\n\r\n**Proposed action**: Adopt a per node/edge licensing framework. Identify which nodes and edges, if any, are eligible for CC0 release. CC0 release may be possible if the creators chose a permissive license or give us permission, the network is fair use, or if the underlying content is not subject to copyright.\r\n\r\n## 3) Network analyses\r\n\r\nNext, we use the integrated network from stage 2 for data mining. The purpose of the data mining is to evaluate methods, extract insights, and make predictions. As an example, see [this analysis](https://github.com/dhimmel/snplentiful) [@10.5281/zenodo.30105] of the network that @caseygreene and I recently did for a separate project.\r\n\r\nHere, it is crucial that findings from analyses on the network are fair use and can be placed in the public domain. Since, the network contains data with [incompatible](https://wiki.creativecommons.org/wiki/Wiki/cc_license_compatibility) licenses such as CC-BY-SA and CC-BY-NC, data mining will be impossible if not considered fair use. In the US, [precedent](http://www.arl.org/storage/documents/TDM-5JUNE2015.pdf) implies our network analyses qualify as fair use. \r\n\r\n**Proposed action**: Identify whether our network analyses qualify as fair use and whether our results can be released as CC0. Evaluate when and if we are subject to European copyright laws, which are less favorable for content users.\r\n\r\n# Expert feedback requested\r\n\r\nWe are seeking expert advice. Specifically, are the proposed actions compliant with copyright law? Regarding the three stages, are we on the right track? Will network analyses count as fair use?",
      "comment_id": 423,
      "profile_id": 17,
      "published": "2015-09-05T00:49:45.249465Z",
      "thread_id": 107,
      "url": "/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#4"
    },
    {
      "body_html": "<h1>Licensing and copyright</h1>\r\n\r\n<p>Thanks <a href=\"/u/larsjuhljensen\" class=\"username\">@larsjuhljensen</a> for your helpful advice. We have created a <a href=\"http://thinklab.com/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#4\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d107\">separate discussion</a> for licensing and copyright to continue the conversation.</p>",
      "body_md": "# Licensing and copyright\r\n\r\nThanks @larsjuhljensen for your helpful advice. We have created a [separate discussion](http://thinklab.com/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#4) for licensing and copyright to continue the conversation.",
      "comment_id": 424,
      "profile_id": 17,
      "published": "2015-09-05T00:58:52.840593Z",
      "thread_id": 102,
      "url": "/discussion/one-network-to-rule-them-all/102#4"
    },
    {
      "body_html": "<h1>Network name</h1>\r\n\r\n<p>We've realized it's a major impediment to not have a name for the network. We are tentatively calling the network <code>hetio-ind</code>. However, <code>rephetio</code> — the current Thinklab handle for the project — is also an option. Will update when the name is finalized.</p>",
      "body_md": "# Network name\r\n\r\nWe've realized it's a major impediment to not have a name for the network. We are tentatively calling the network `hetio-ind`. However, `rephetio` -- the current Thinklab handle for the project -- is also an option. Will update when the name is finalized.",
      "comment_id": 425,
      "profile_id": 17,
      "published": "2015-09-05T01:01:19.214381Z",
      "thread_id": 102,
      "url": "/discussion/one-network-to-rule-them-all/102#5"
    },
    {
      "body_html": "<p>To keep you posted: we were recently given access to the GTEx data, so we have started annotating/analyzing the data. We hope to have a new release of Bgee including these data in about 2 months.</p>",
      "body_md": "To keep you posted: we were recently given access to the GTEx data, so we have started annotating/analyzing the data. We hope to have a new release of Bgee including these data in about 2 months.",
      "comment_id": 426,
      "profile_id": 111,
      "published": "2015-09-07T11:10:57.149929Z",
      "thread_id": 82,
      "url": "/discussion/processing-gtex-for-tissue-specific-gene-expression/82#15"
    },
    {
      "body_html": "<p>Your analysis of the situation looks great — you've correctly described the difficulty of combining incompatible licenses and the data they cover, and the potential of fair use (for extracting data subsets and data mining) for what you're trying to do. And for the datasets that lack a license, you know that in many cases they aren't protected by copyright so you're free to do what you want. Federal government agencies are notorious for refusing to assign licenses or rights waivers to the data they release, claiming that everything they have and do is in the public domain and we should all just know that, so sometimes no license means you're fine. Your goal of making it clear to users what rights and licenses apply to which datasets is laudable.</p>\r\n\r\n<p>The one thing I didn't see you covering is liability. I can't figure out who actually owns the work that you're doing — you want to put it in the public domain, which is great, but do you personally have the right to do that? Are you working on a grant project or employed by a university that might claim \"ownership\" of your results? This is usually dealt with by the licenses. Apache open source software licenses include the language \"Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\" Even CC licenses include language like \"No warranties are given. The license may not give you all of the permissions necessary for your intended use. For example, other rights such as publicity, privacy, or moral rights may limit how you use the material.\" So if you're using CC0 wherever you can, you might want a separate statement of warranty (or lack thereof) unless you want to be liable, or implicate your institution, if you do accidentally screw up (easy enough to do, in such a complex project, even when you've done everything you can). </p>",
      "body_md": "Your analysis of the situation looks great -- you've correctly described the difficulty of combining incompatible licenses and the data they cover, and the potential of fair use (for extracting data subsets and data mining) for what you're trying to do. And for the datasets that lack a license, you know that in many cases they aren't protected by copyright so you're free to do what you want. Federal government agencies are notorious for refusing to assign licenses or rights waivers to the data they release, claiming that everything they have and do is in the public domain and we should all just know that, so sometimes no license means you're fine. Your goal of making it clear to users what rights and licenses apply to which datasets is laudable.\r\n\r\nThe one thing I didn't see you covering is liability. I can't figure out who actually owns the work that you're doing -- you want to put it in the public domain, which is great, but do you personally have the right to do that? Are you working on a grant project or employed by a university that might claim \"ownership\" of your results? This is usually dealt with by the licenses. Apache open source software licenses include the language \"Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.\" Even CC licenses include language like \"No warranties are given. The license may not give you all of the permissions necessary for your intended use. For example, other rights such as publicity, privacy, or moral rights may limit how you use the material.\" So if you're using CC0 wherever you can, you might want a separate statement of warranty (or lack thereof) unless you want to be liable, or implicate your institution, if you do accidentally screw up (easy enough to do, in such a complex project, even when you've done everything you can). ",
      "comment_id": 427,
      "profile_id": 135,
      "published": "2015-09-08T02:16:42.932187Z",
      "thread_id": 107,
      "url": "/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#5"
    },
    {
      "body_html": "<h1>Who owns the created work</h1>\r\n\r\n<p>After some background <a href=\"http://www.d.umn.edu/~pschoff/documents/ElliotR05WhoOwnsScientificDatapdf.pdf\">reading</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1087/0953151053584984\" class=\"citation\" data-key=\"10.1087/0953151053584984\">1</a>]</span> and <a href=\"https://www.youtube.com/playlist?list=PLYTiwx6hV33tXEfueCk5k7xyLePcqj4XK\">video watching</a>, who owns the work we're creating is not straightforward.</p>\r\n\r\n<p>I am a graduate student at UCSF and my PI, <a href=\"/u/sergiobaranzini\" class=\"username\">@sergiobaranzini</a>, is a professor at UCSF. I am largely, but not completely, funded by an NSF Graduate Research Fellowship whose conditions <a href=\"http://www.nsf.gov/pubs/2015/nsf15597/nsf15597.htm\">state</a>:</p>\r\n\r\n<blockquote><p>The National Science Foundation claims no rights to any inventions or writings that might result from its fellowship or traineeship grants.</p></blockquote>\r\n\r\n<h2>Copyright and the UC</h2>\r\n\r\n<p>The UC's 1992 <a href=\"http://copyright.universityofcalifornia.edu/resources/copyright-ownership.html\">'copyright ownership' policy</a> stipulates ownership by category of work. Several of these categories may apply:</p>\r\n\r\n<ul><li><p>academic appointee originator ownership of \"scholarly/aesthetic work\"</p><blockquote><p>A scholarly/aesthetic work is a work originated by a designated academic appointee resulting from independent academic effort. Ownership of copyrights to scholarly/aesthetic works shall reside with the designated academic appointee originator, unless they are also sponsored works or contracted facilities works, or unless the designated academic appointee agrees to participate in a project which has special provisions on copyright ownership pursuant to Section V.C. of this Policy.</p></blockquote></li><li><p>originator ownership of \"personal work\"</p><blockquote><p>A personal work is a work that is prepared outside the course and scope of University employment (except for permissible non-University consulting activities) without the use of University Resources. Ownership of copyrights to Personal works shall reside with the originator.</p></blockquote></li><li><p>originator ownership of \"student work\":</p><blockquote><p>A student work is a work produced by a registered student without the use of University funds (other than Student Financial Aid), that is produced outside any University employment, and is not a sponsored, contracted facilities, or commissioned work. Ownership of copyrights to student works shall reside with the originator.</p></blockquote></li><li><p>university ownership of \"institutional work\":</p><blockquote><p>Except as otherwise provided in this Policy, the University shall own all copyrights to works made by University employees in the course and scope of their employment and shall own all copyrights to works made with the use of University resources.</p></blockquote></li></ul>\r\n\r\n<p>Therefore, UC's asserted ownership is dependent on which categories our work falls under. Additional guidance <a href=\"http://copyright.universityofcalifornia.edu/ownership/works-created-at-uc.html\">states</a>:</p>\r\n\r\n<blockquote><p>University staff who create works within the scope of their employment generally do not own the copyright to the work. A work prepared by an employee within the scope of his or her employment is considered a \"work made for hire.\"  When a work qualifies as a work made for hire, the employer or commissioning party is considered its author. Under UC policies, some written works created by certain categories of UC faculty, graduate students, and staff are considered works made for hire. </p></blockquote>\r\n\r\n<p>Thus, the University's assertion of ownership may be contradicted by the <a href=\"http://chronicle.com/article/Employees-or-Not-/145573/\">strong argument</a> that graduate students, such as myself, are not employees and do not produce \"work made for hire\". Furthermore, the policies and guidelines are outdated and not well tailored towards the collaborative, digital, online, and open approach our project takes. The work I perform goes beyond the sole purposes of studentship, employment, and institutional work. And the academic community has established norms and precedent for allowing creators to transfer copyright and choose licensing — the foremost examples being academic publishing and open source software contribution.</p>\r\n\r\n<h2>Data and the UC</h2>\r\n\r\n<p>The UC <a href=\"http://copyright.universityofcalifornia.edu/resources/copyright-ownership.html\">'copyright ownership' policy</a> explicitly states that it only:</p>\r\n\r\n<blockquote><p>addresses ownership of copyright; it does not address ownership or access to the underlying research results or data, as covered in Academic Personnel Manual Section 020. </p></blockquote>\r\n\r\n<p>The Academic Personnel Manual <a href=\"http://www.ucop.edu/academic-personnel-programs/_files/apm/apm-020.pdf\">Section 020</a>, dated in 1953, provides little clarification:</p>\r\n\r\n<blockquote><p>All such research shall be conducted so as to be as generally useful as possible. To this end, the right of publication is reserved by the University. The University may itself publish the material or may authorize, in any specific case, a member or members of the faculty to publish it through some recognized scientific or professional medium of publication. A report detailing the essential data and presenting the final results must be filed with the University. Notebooks and other original records of the research are the property of the University.</p></blockquote>\r\n\r\n<p>Outside of official policy, UC appears to claim ownership of results and data. Quoting from a <a href=\"https://youtu.be/QQOEG_PyRWY\">talk</a> by <a href=\"/u/mackenziesmith\" class=\"username\">@mackenziesmith</a>:</p>\r\n\r\n<blockquote><p>The University of California posits that it actually has a contractual obligation to maintain the ownership of all research data produced from grant funded projects by any researcher at UC, especially federally funded grants. So they claim that the university owns the data.</p></blockquote>\r\n\r\n<p>Additionally, a <a href=\"http://ucsd.libguides.com/c.php?g=90957&amp;p=585144\">UCSD guide</a> states:</p>\r\n\r\n<blockquote><ul><li>Data produced by UC researchers belong to the Regents of the University of California.</li><li>To promote sharing and unlimited use of your data, make your data available under a Creative Commons <a href=\"http://creativecommons.org/choose/zero\">CC0 Declaration</a>.</li></ul></blockquote>\r\n\r\n<p>These seemingly contradictory statements imply that UC may own the data but that its creators are free to release it into the public domain.</p>\r\n\r\n<h2>Resolutions</h2>\r\n\r\n<p>We are looking for suggested courses of action to address the ambiguity and potential multiplicity of claims regarding ownership. Two possible actions are:</p>\r\n\r\n<ul><li>applying a <em>without warranty</em> clause to our licensing to limit our liability.</li><li>identifying all potential parties that may claim ownership and request permission to release the work as freely as possible given the <a href=\"#4\">aforementioned considerations</a>.</li></ul>",
      "body_md": "# Who owns the created work\r\n\r\nAfter some background [reading](http://www.d.umn.edu/~pschoff/documents/ElliotR05WhoOwnsScientificDatapdf.pdf) [@10.1087/0953151053584984] and [video watching](https://www.youtube.com/playlist?list=PLYTiwx6hV33tXEfueCk5k7xyLePcqj4XK), who owns the work we're creating is not straightforward.\r\n\r\nI am a graduate student at UCSF and my PI, @sergiobaranzini, is a professor at UCSF. I am largely, but not completely, funded by an NSF Graduate Research Fellowship whose conditions [state](http://www.nsf.gov/pubs/2015/nsf15597/nsf15597.htm):\r\n\r\n> The National Science Foundation claims no rights to any inventions or writings that might result from its fellowship or traineeship grants.\r\n\r\n## Copyright and the UC\r\n\r\nThe UC's 1992 ['copyright ownership' policy](http://copyright.universityofcalifornia.edu/resources/copyright-ownership.html) stipulates ownership by category of work. Several of these categories may apply:\r\n\r\n+ academic appointee originator ownership of \"scholarly/aesthetic work\"\r\n> A scholarly/aesthetic work is a work originated by a designated academic appointee resulting from independent academic effort. Ownership of copyrights to scholarly/aesthetic works shall reside with the designated academic appointee originator, unless they are also sponsored works or contracted facilities works, or unless the designated academic appointee agrees to participate in a project which has special provisions on copyright ownership pursuant to Section V.C. of this Policy.\r\n\r\n+ originator ownership of \"personal work\"\r\n> A personal work is a work that is prepared outside the course and scope of University employment (except for permissible non-University consulting activities) without the use of University Resources. Ownership of copyrights to Personal works shall reside with the originator.\r\n\r\n+ originator ownership of \"student work\":\r\n> A student work is a work produced by a registered student without the use of University funds (other than Student Financial Aid), that is produced outside any University employment, and is not a sponsored, contracted facilities, or commissioned work. Ownership of copyrights to student works shall reside with the originator.\r\n\r\n+ university ownership of \"institutional work\":\r\n> Except as otherwise provided in this Policy, the University shall own all copyrights to works made by University employees in the course and scope of their employment and shall own all copyrights to works made with the use of University resources.\r\n\r\nTherefore, UC's asserted ownership is dependent on which categories our work falls under. Additional guidance [states](http://copyright.universityofcalifornia.edu/ownership/works-created-at-uc.html):\r\n\r\n> University staff who create works within the scope of their employment generally do not own the copyright to the work. A work prepared by an employee within the scope of his or her employment is considered a \"work made for hire.\"  When a work qualifies as a work made for hire, the employer or commissioning party is considered its author. Under UC policies, some written works created by certain categories of UC faculty, graduate students, and staff are considered works made for hire. \r\n\r\nThus, the University's assertion of ownership may be contradicted by the [strong argument](http://chronicle.com/article/Employees-or-Not-/145573/) that graduate students, such as myself, are not employees and do not produce \"work made for hire\". Furthermore, the policies and guidelines are outdated and not well tailored towards the collaborative, digital, online, and open approach our project takes. The work I perform goes beyond the sole purposes of studentship, employment, and institutional work. And the academic community has established norms and precedent for allowing creators to transfer copyright and choose licensing -- the foremost examples being academic publishing and open source software contribution.\r\n\r\n## Data and the UC\r\n\r\nThe UC ['copyright ownership' policy](http://copyright.universityofcalifornia.edu/resources/copyright-ownership.html) explicitly states that it only:\r\n\r\n> addresses ownership of copyright; it does not address ownership or access to the underlying research results or data, as covered in Academic Personnel Manual Section 020. \r\n\r\nThe Academic Personnel Manual [Section 020](http://www.ucop.edu/academic-personnel-programs/_files/apm/apm-020.pdf), dated in 1953, provides little clarification:\r\n\r\n> All such research shall be conducted so as to be as generally useful as possible. To this end, the right of publication is reserved by the University. The University may itself publish the material or may authorize, in any specific case, a member or members of the faculty to publish it through some recognized scientific or professional medium of publication. A report detailing the essential data and presenting the final results must be filed with the University. Notebooks and other original records of the research are the property of the University.\r\n\r\nOutside of official policy, UC appears to claim ownership of results and data. Quoting from a [talk](https://youtu.be/QQOEG_PyRWY) by @mackenziesmith:\r\n\r\n> The University of California posits that it actually has a contractual obligation to maintain the ownership of all research data produced from grant funded projects by any researcher at UC, especially federally funded grants. So they claim that the university owns the data.\r\n\r\nAdditionally, a [UCSD guide](http://ucsd.libguides.com/c.php?g=90957&p=585144) states:\r\n\r\n> + Data produced by UC researchers belong to the Regents of the University of California.\r\n> + To promote sharing and unlimited use of your data, make your data available under a Creative Commons [CC0 Declaration](http://creativecommons.org/choose/zero).\r\n\r\nThese seemingly contradictory statements imply that UC may own the data but that its creators are free to release it into the public domain.\r\n\r\n## Resolutions\r\n\r\nWe are looking for suggested courses of action to address the ambiguity and potential multiplicity of claims regarding ownership. Two possible actions are:\r\n\r\n+ applying a *without warranty* clause to our licensing to limit our liability.\r\n+ identifying all potential parties that may claim ownership and request permission to release the work as freely as possible given the [aforementioned considerations](#4).",
      "comment_id": 428,
      "profile_id": 17,
      "published": "2015-09-09T05:39:13.885633Z",
      "thread_id": 107,
      "url": "/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#8"
    },
    {
      "body_html": "<p>Regarding the problem of incompatible licenses, it is very important that you are clear on the difference between redistribution and data mining.</p>\r\n\r\n<p>You write that \"Since, the network contains data with incompatible licenses such as CC-BY-SA and CC-BY-NC, data mining will be impossible if not considered fair use\". This is to my knowledge simply not true. There is no problem whatsoever in combining material from these incompatible licenses and mining it in any way that you want. The reason is that copyright purely has to do with how you are allow to redistribute things. And if the data mining leads to some results that are substantially different and not effectively a copy of the original material, there is also no problem in redistributing the results.</p>\r\n\r\n<p>The problem comes when you want to make what is effectively a meta-resource that combines material from a lot of databases and redistributes it. In this case, you are redistributing something that is effectively a reformatted version of the material. In my opinion, your network falls squarely in that category</p>\r\n\r\n<p>However, the solution is very simple. As I have suggested before, you can split the network into subnetworks, that are all redistributed under their respective licenses. You can bundle everything CC-BY-SA in one file and redistribute it under CC-BY-SA. You can bundle everything CC-BY-NC in another file and redistribute it under CC-BY-NC. And as described above, nothing prevents anyone in the world from legally downloading both files, combining them, and mining the data as they please.</p>\r\n\r\n<p>To make it simpler, let me make an analogy from the world of text mining, where the situation is somewhat more clearcut, since there is no doubt that articles are subject to copyright law. I can download some articles under CC-BY-SA and some others under CC-BY-NC. I can run text mining on all of them despite the licenses being incompatible, and I can redistribute the results of my efforts under any license I please, because the results are my results, which are not simply a reformatting of the original text. However, I cannot take all the articles, combine them into a text corpus, and release it under CC0.</p>\r\n\r\n<p>Caveats: I am not a lawyer, this does constitute legal advice etc.</p>",
      "body_md": "Regarding the problem of incompatible licenses, it is very important that you are clear on the difference between redistribution and data mining.\r\n\r\nYou write that \"Since, the network contains data with incompatible licenses such as CC-BY-SA and CC-BY-NC, data mining will be impossible if not considered fair use\". This is to my knowledge simply not true. There is no problem whatsoever in combining material from these incompatible licenses and mining it in any way that you want. The reason is that copyright purely has to do with how you are allow to redistribute things. And if the data mining leads to some results that are substantially different and not effectively a copy of the original material, there is also no problem in redistributing the results.\r\n\r\nThe problem comes when you want to make what is effectively a meta-resource that combines material from a lot of databases and redistributes it. In this case, you are redistributing something that is effectively a reformatted version of the material. In my opinion, your network falls squarely in that category\r\n\r\nHowever, the solution is very simple. As I have suggested before, you can split the network into subnetworks, that are all redistributed under their respective licenses. You can bundle everything CC-BY-SA in one file and redistribute it under CC-BY-SA. You can bundle everything CC-BY-NC in another file and redistribute it under CC-BY-NC. And as described above, nothing prevents anyone in the world from legally downloading both files, combining them, and mining the data as they please.\r\n\r\nTo make it simpler, let me make an analogy from the world of text mining, where the situation is somewhat more clearcut, since there is no doubt that articles are subject to copyright law. I can download some articles under CC-BY-SA and some others under CC-BY-NC. I can run text mining on all of them despite the licenses being incompatible, and I can redistribute the results of my efforts under any license I please, because the results are my results, which are not simply a reformatting of the original text. However, I cannot take all the articles, combine them into a text corpus, and release it under CC0.\r\n\r\nCaveats: I am not a lawyer, this does constitute legal advice etc.",
      "comment_id": 429,
      "profile_id": 125,
      "published": "2015-09-08T05:32:04.663666Z",
      "thread_id": 107,
      "url": "/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#6"
    },
    {
      "body_html": "<p><a href=\"/u/mackenziesmith\" class=\"username\">@mackenziesmith</a> makes a very good point about liability, which in my opinion is why you should not attempt to take copyrighted material, claim fair use under US law, and slap a CC0 waiver on it.</p>\r\n\r\n<p>Imagine someone in Europe were to download your network, assume that everything was free of copyright (which is what CC0 effectively promises), take all the SIDER data, and redistribute it under CC0. Since SIDER is covered by European <em>sui generis</em> database rights, they could get sued and would likely lose. Subsequently, they could choose to sue you for liabilities.</p>\r\n\r\n<p>Caveats: I am not a lawyer, this does constitute legal advice etc.</p>",
      "body_md": "@mackenziesmith makes a very good point about liability, which in my opinion is why you should not attempt to take copyrighted material, claim fair use under US law, and slap a CC0 waiver on it.\r\n\r\nImagine someone in Europe were to download your network, assume that everything was free of copyright (which is what CC0 effectively promises), take all the SIDER data, and redistribute it under CC0. Since SIDER is covered by European *sui generis* database rights, they could get sued and would likely lose. Subsequently, they could choose to sue you for liabilities.\r\n\r\nCaveats: I am not a lawyer, this does constitute legal advice etc.",
      "comment_id": 430,
      "profile_id": 125,
      "published": "2015-09-08T05:32:43.986923Z",
      "thread_id": 107,
      "url": "/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#7"
    },
    {
      "body_html": "<p>At a workshop I organized at UC Davis last year — Data Rights and Data Wrongs — senior counsel from the UC Office of General Counsel (i.e., the university's lawyers) was very clear that UC retains ownership rights to original data as the official 'grantee' and to insure compliance with federal laws for research conduct, etc. I think the relevant policy is here <a href=\"http://www.ucop.edu/raohome/cgmemos/84-31.html\">http://www.ucop.edu/raohome/cgmemos/84-31.html</a> (old but still in effect). So I think your assessment is right that UC asserts ownership but allows you to release the data under reasonable terms, including CC0. However most of the data you're working with isn't original to you, so what UC 'owns' is your own findings and if you did something wrong, the university is liable to some extent. </p>\r\n\r\n<p>Of course, finding all the rights holders and getting their explicit permission to do what you're doing would be ideal, but is that practical? Do you even know who holds the rights to all the data sources? I disagree with the point that you can't rely on Fair Use and release your results under a CC0 waiver — I believe that's what Fair Use is for, if it's truly transformative — but you might want to be explicit about the waiver of liability. Especially given how gray the area you're working in is, legally speaking.</p>",
      "body_md": "At a workshop I organized at UC Davis last year -- Data Rights and Data Wrongs -- senior counsel from the UC Office of General Counsel (i.e., the university's lawyers) was very clear that UC retains ownership rights to original data as the official 'grantee' and to insure compliance with federal laws for research conduct, etc. I think the relevant policy is here http://www.ucop.edu/raohome/cgmemos/84-31.html (old but still in effect). So I think your assessment is right that UC asserts ownership but allows you to release the data under reasonable terms, including CC0. However most of the data you're working with isn't original to you, so what UC 'owns' is your own findings and if you did something wrong, the university is liable to some extent. \r\n\r\nOf course, finding all the rights holders and getting their explicit permission to do what you're doing would be ideal, but is that practical? Do you even know who holds the rights to all the data sources? I disagree with the point that you can't rely on Fair Use and release your results under a CC0 waiver -- I believe that's what Fair Use is for, if it's truly transformative -- but you might want to be explicit about the waiver of liability. Especially given how gray the area you're working in is, legally speaking.",
      "comment_id": 431,
      "profile_id": 135,
      "published": "2015-09-09T14:49:37.330926Z",
      "thread_id": 107,
      "url": "/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#9"
    },
    {
      "body_html": "<p>Most people I have discussed this with, would understand what heterogeneous networks mean without much ambiguity. I realize that it may not be completely specific to the kind of work we are doing here, but a balance between specificity and name simplicity needs to be reached. In my view, HetNets does it. </p>",
      "body_md": "Most people I have discussed this with, would understand what heterogeneous networks mean without much ambiguity. I realize that it may not be completely specific to the kind of work we are doing here, but a balance between specificity and name simplicity needs to be reached. In my view, HetNets does it. ",
      "comment_id": 434,
      "profile_id": 20,
      "published": "2015-09-16T20:27:18.620784Z",
      "thread_id": 104,
      "url": "/discussion/renaming-heterogeneous-networks-to-a-more-concise-and-catchy-term/104#3"
    },
    {
      "body_html": "<h1>Preliminary adoption of 'hetnet'</h1>\r\n\r\n<p>I agree with the previous two comments that \"hetnet\" is a good term. The term transforms \"heterogeneous network\" into a <a href=\"https://en.wikipedia.org/wiki/English_compound#Types_of_compound_nouns\">solid compound noun</a>.</p>\r\n\r\n<p>However, I prefer <a href=\"https://en.wikipedia.org/wiki/Letter_case#Sentence_case\">sentence case</a> (hetnet) to <a href=\"https://en.wikipedia.org/wiki/CamelCase\">camel case</a> (HetNet). Removing the camel case improves the aesthetics and differentiates the term from its <a href=\"https://en.wikipedia.org/w/index.php?title=Heterogeneous_network&amp;oldid=629383185#HetNet\">computer networking usage</a>.</p>\r\n\r\n<p>The term respects its lineage through compatibility with \"heterogeneous network\" and \"heterogeneous information network\".</p>\r\n\r\n<p>I have begun publicly using the term hetnet. For example, I <a href=\"https://github.com/dhimmel/hetio/commit/869a67858086c9168ae50d693393ade2308f51ce\">renamed</a>  the<code>hetio.graph</code> module to <code>hetio.hetnet</code> to better describe the content. I also <a href=\"https://github.com/dhimmel/hetio/commit/a006a862d1501ec322bd172dc55cb6f3fe83301a\">now</a> describe the hetio <a href=\"https://github.com/dhimmel/hetio\">package</a> as \"Hetnets in Python\".</p>",
      "body_md": "# Preliminary adoption of 'hetnet'\r\n\r\nI agree with the previous two comments that \"hetnet\" is a good term. The term transforms \"heterogeneous network\" into a [solid compound noun](https://en.wikipedia.org/wiki/English_compound#Types_of_compound_nouns).\r\n\r\nHowever, I prefer [sentence case](https://en.wikipedia.org/wiki/Letter_case#Sentence_case) (hetnet) to [camel case](https://en.wikipedia.org/wiki/CamelCase) (HetNet). Removing the camel case improves the aesthetics and differentiates the term from its [computer networking usage](https://en.wikipedia.org/w/index.php?title=Heterogeneous_network&oldid=629383185#HetNet).\r\n\r\nThe term respects its lineage through compatibility with \"heterogeneous network\" and \"heterogeneous information network\".\r\n\r\nI have begun publicly using the term hetnet. For example, I [renamed](https://github.com/dhimmel/hetio/commit/869a67858086c9168ae50d693393ade2308f51ce)  the`hetio.graph` module to `hetio.hetnet` to better describe the content. I also [now](https://github.com/dhimmel/hetio/commit/a006a862d1501ec322bd172dc55cb6f3fe83301a) describe the hetio [package](https://github.com/dhimmel/hetio) as \"Hetnets in Python\".",
      "comment_id": 435,
      "profile_id": 17,
      "published": "2015-09-16T21:29:39.630331Z",
      "thread_id": 104,
      "url": "/discussion/renaming-heterogeneous-networks-to-a-more-concise-and-catchy-term/104#4"
    },
    {
      "body_html": "<h1>Curation pilot results</h1>\r\n\r\n<p><a href=\"/u/sergiobaranzini\" class=\"username\">@sergiobaranzini</a> recruited two UCSF physicians — <a href=\"http://greenlab.ucsf.edu/ari-j-green-md\">Ari Green</a> (AJG) and <a href=\"http://profiles.ucsf.edu/christine.hessler\">Christine Hessler</a> (CSH) — for the curation task. We asked the curators to independently classify 50 random indications as disease modifying or symptomatic. See the raw results for <a href=\"https://github.com/dhimmel/indications/blob/49efba793216dcaf739fe22a32f60c4549aa3f7a/curation/pilot/ajg.tsv\">AJG</a> and <a href=\"https://github.com/dhimmel/indications/blob/49efba793216dcaf739fe22a32f60c4549aa3f7a/curation/pilot/csh.tsv\">CSH</a>.</p>\r\n\r\n<h2>Combined results</h2>\r\n\r\n<p>While we did not specify that \"not an indication\" was an option, both curators identified these instances. While our indication dataset derives from high precision datasets, non-indications will be present. Thus, going forward we will include \"not an indication\" as a classification.</p>\r\n\r\n<p>I cleaned the curators free text into 3 classifications: <code>DM</code> for disease modifying, <code>SYM</code> for symptomatic, and <code>NOT</code> for not an indication. This cleaning step required some inference on my part and thus could have introduced a minor bias. The <a href=\"https://github.com/dhimmel/indications/blob/49efba793216dcaf739fe22a32f60c4549aa3f7a/curation/pilot/combined.tsv\">combined results</a> show 66% agreement, with the following breakdown by curator:</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>class</th><th>ajg</th><th>csh</th></tr></thead><tbody><tr><td>DM</td><td>26</td><td>32</td></tr><tr><td>SYM</td><td>20</td><td>17</td></tr><tr><td>NOT</td><td>4</td><td>1</td></tr></tbody></table>\r\n\r\n<p>The pilot suggests that the compiled indications are ~58% disease modifying, ~37% symptomatic, and ~5% non-indications.</p>\r\n\r\n<h2>Definitions</h2>\r\n\r\n<p>We did not provide the curators with clear definitions of disease modifying and symptomatic. Our plan is to use the pilot experience to help define the categories. Preferably, these definitions should be crafted by the physicians.</p>\r\n\r\n<p>Informally, CSH defined disease modifying as:</p>\r\n\r\n<blockquote><p>any agent that changes the course of the illness or complications of the illness (not necessarily curing the disease, but preventing \"flares\" or complications). I'd ask myself, \"is it poor form not to prescribe this medication to my patient with disease y and could I be sued for it?\"</p></blockquote>\r\n\r\n<p>And symptomatic as:</p>\r\n\r\n<blockquote><p>agents that are used purely for patient's comfort and don't alter the course of the disease at all. </p></blockquote>\r\n\r\n<h2>Cocaine and cavities</h2>\r\n\r\n<p>One bizarre indication was <a href=\"http://www.drugbank.ca/drugs/DB00907\">cocaine</a> and <a href=\"http://www.disease-ontology.org/term/DOID%3A216\">dental carries</a>, which was contributed <a href=\"https://cdn.rawgit.com/dhimmel/indications/6375b195df61b6e0d44c4690abfa2ac0710bc690//merge.html#indication-table\">by</a> MEDI-HPS <span class=\"citation\">[<a href=\"https://doi.org/10.1136/amiajnl-2012-001431\" class=\"citation\" data-key=\"10.1136/amiajnl-2012-001431\">1</a>]</span>. Since MEDI doesn't report its sources for individual indications and the authors <a href=\"http://thinklab.com/discussion/medi-indications-data-discrepancy-in-resource-specific-counts/31#2\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d31\">did not release</a> this data upon request, tracking down the provenance of this indication is difficult. However, MEDI does <a href=\"https://cdn.rawgit.com/dhimmel/indications/6375b195df61b6e0d44c4690abfa2ac0710bc690/medi/\">specify</a> that this indication existed in SIDER 2 <span class=\"citation\">[<a href=\"https://doi.org/10.1038/msb.2009.98\" class=\"citation\" data-key=\"10.1038/msb.2009.98\">2</a>]</span>, which text mined drug labels. Presumably, <a href=\"http://www.drugs.com/pro/cocaine-hydrochloride-topical-solution.html\">this label</a> for Cocaine Hydrochloride Topical Solution (brand name C-Topical) was the source for the cocaine–cavities indication. The label states the solution \"is indicated for introduction of local (topical) anesthesia of accessible mucous membranes of the oral, laryngeal and nasal cavities.\" This suggests a non-indication or at most a symptomatic indication between cocaine and dental caries. However, for a SIDER 2 indication to be included in MEDI-HPS, at least one other source must report the indication. AJG informally suggested that the \"reason for the hit is that cocaine accelerates dental caries and might therefore be considered disease modifying (but in a bad way).\"</p>\r\n\r\n<h2>Next steps</h2>\r\n\r\n<p>The pilot experience proved the importance of expert curation of our compiled indication catalog. Before proceeding with the remaining indications, we should formally define the three classifications (DM, SYM, NOT). Clear definitions may increase the agreement between curators, but a final resolution stage for conflicts will be necessary.</p>",
      "body_md": "# Curation pilot results\r\n\r\n@sergiobaranzini recruited two UCSF physicians -- [Ari Green](http://greenlab.ucsf.edu/ari-j-green-md) (AJG) and [Christine Hessler](http://profiles.ucsf.edu/christine.hessler) (CSH) -- for the curation task. We asked the curators to independently classify 50 random indications as disease modifying or symptomatic. See the raw results for [AJG](https://github.com/dhimmel/indications/blob/49efba793216dcaf739fe22a32f60c4549aa3f7a/curation/pilot/ajg.tsv) and [CSH](https://github.com/dhimmel/indications/blob/49efba793216dcaf739fe22a32f60c4549aa3f7a/curation/pilot/csh.tsv).\r\n\r\n## Combined results\r\n\r\nWhile we did not specify that \"not an indication\" was an option, both curators identified these instances. While our indication dataset derives from high precision datasets, non-indications will be present. Thus, going forward we will include \"not an indication\" as a classification.\r\n\r\nI cleaned the curators free text into 3 classifications: `DM` for disease modifying, `SYM` for symptomatic, and `NOT` for not an indication. This cleaning step required some inference on my part and thus could have introduced a minor bias. The [combined results](https://github.com/dhimmel/indications/blob/49efba793216dcaf739fe22a32f60c4549aa3f7a/curation/pilot/combined.tsv) show 66% agreement, with the following breakdown by curator:\r\n\r\n| class | ajg | csh |\r\n|-------|-----|-----|\r\n| DM | 26 | 32 |\r\n| SYM | 20 | 17 |\r\n| NOT | 4 | 1 |\r\n\r\nThe pilot suggests that the compiled indications are ~58% disease modifying, ~37% symptomatic, and ~5% non-indications.\r\n\r\n## Definitions\r\n\r\nWe did not provide the curators with clear definitions of disease modifying and symptomatic. Our plan is to use the pilot experience to help define the categories. Preferably, these definitions should be crafted by the physicians.\r\n\r\nInformally, CSH defined disease modifying as:\r\n\r\n> any agent that changes the course of the illness or complications of the illness (not necessarily curing the disease, but preventing \"flares\" or complications). I'd ask myself, \"is it poor form not to prescribe this medication to my patient with disease y and could I be sued for it?\"\r\n\r\nAnd symptomatic as:\r\n\r\n> agents that are used purely for patient's comfort and don't alter the course of the disease at all. \r\n\r\n## Cocaine and cavities\r\n\r\nOne bizarre indication was [cocaine](http://www.drugbank.ca/drugs/DB00907) and [dental carries](http://www.disease-ontology.org/term/DOID%3A216), which was contributed [by](https://cdn.rawgit.com/dhimmel/indications/6375b195df61b6e0d44c4690abfa2ac0710bc690//merge.html#indication-table) MEDI-HPS [@10.1136/amiajnl-2012-001431]. Since MEDI doesn't report its sources for individual indications and the authors [did not release](http://thinklab.com/discussion/medi-indications-data-discrepancy-in-resource-specific-counts/31#2) this data upon request, tracking down the provenance of this indication is difficult. However, MEDI does [specify](https://cdn.rawgit.com/dhimmel/indications/6375b195df61b6e0d44c4690abfa2ac0710bc690/medi/) that this indication existed in SIDER 2 [@10.1038/msb.2009.98], which text mined drug labels. Presumably, [this label](http://www.drugs.com/pro/cocaine-hydrochloride-topical-solution.html) for Cocaine Hydrochloride Topical Solution (brand name C-Topical) was the source for the cocaine--cavities indication. The label states the solution \"is indicated for introduction of local (topical) anesthesia of accessible mucous membranes of the oral, laryngeal and nasal cavities.\" This suggests a non-indication or at most a symptomatic indication between cocaine and dental caries. However, for a SIDER 2 indication to be included in MEDI-HPS, at least one other source must report the indication. AJG informally suggested that the \"reason for the hit is that cocaine accelerates dental caries and might therefore be considered disease modifying (but in a bad way).\"\r\n\r\n## Next steps\r\n\r\nThe pilot experience proved the importance of expert curation of our compiled indication catalog. Before proceeding with the remaining indications, we should formally define the three classifications (DM, SYM, NOT). Clear definitions may increase the agreement between curators, but a final resolution stage for conflicts will be necessary.",
      "comment_id": 436,
      "profile_id": 17,
      "published": "2015-09-19T17:41:55.442799Z",
      "thread_id": 95,
      "url": "/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95#3"
    },
    {
      "body_html": "<p>Recently, I went a two-part meetup series on the graph database <a href=\"http://neo4j.com/\">neo4j</a>. <a href=\"http://nicolewhite.github.io/\">Nicole White</a> led the meetups and her materials are online:</p>\r\n\r\n<ol><li>neo4j: Intro to Graphs (<a href=\"https://www.dropbox.com/s/zv0s4lwc6gvwxjy/Galvanize.pptx?dl=0\">slides</a>, <a href=\"http://www.meetup.com/SF-Data-Science/events/224956828\">meetup</a>)</li><li>Data Science with Python and Neo4j (<a href=\"http://nicolewhite.github.io/neo4j-jupyter/main.html\">tutorial</a>, <a href=\"https://github.com/nicolewhite/neo4j-jupyter\">repository</a>, <a href=\"http://www.meetup.com/SF-Data-Science/events/224406352\">meetup</a>)</li></ol>\r\n\r\n<p>Currently, we store our hetnets in compressed json text files. To perform any computation or graph analyses, we must load the network into memory, a process that takes from 2–5 minutes for version one of our <a href=\"http://thinklab.com/discussion/one-network-to-rule-them-all/102#1\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d102\">network</a>. In contrast neo4j provides persistent storage with immediate access.</p>\r\n\r\n<p>Additional benefits of neo4j include a mature <a href=\"https://github.com/GraphGeeks/awesome-neo4j\">ecosystem</a> offering broad functionality. The <a href=\"http://neo4j.com/developer/cypher-query-language/\">Cyper</a> query language is especially exciting. Cypher uses an ASCII-art based syntax to enable advanced graph lookups and traversals with little boilerplate.</p>\r\n\r\n<h2>Comparison to hetio</h2>\r\n\r\n<p>There are a few differences between neo4j and our python package <a href=\"https://github.com/dhimmel/hetio\">hetio</a> <span class=\"citation\">[<a href=\"https://doi.org/10.5281/zenodo.31763\" class=\"citation\" data-key=\"10.5281/zenodo.31763\">1</a>]</span> with regards to hetnets:</p>\r\n\r\n<ul><li><strong>nomenclature</strong> — an edge in hetio is called a relationship in neo4j. hetio calls itself a <a href=\"http://thinklab.com/discussion/renaming-heterogeneous-networks-to-a-more-concise-and-catchy-term/104\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d104\">hetnet</a>, while neo4j calls itself a <a href=\"http://neo4j.com/developer/graph-database/#property-graph\">property graph</a></li><li><strong>node type</strong> — in hetio each node belongs to one metanode representing its type. in neo4j node are annotated with a label to indicate type, and a node can have ≥ 0 labels</li><li><strong>directionality</strong> — in hetio metaedges are either directed or undirected and edges conform to their metaedge's directionality. neo4j doesn't support undirected edges. The <a href=\"http://graphaware.com/neo4j/2013/10/11/neo4j-bidirectional-relationships.html\">suggested workaround</a> is to arbitrarily choose a direction upon creation and ignore the direction when querying</li><li><strong>type graph</strong> — hetio requires a predefined graph of types called a metagraph. neo4j does not enforce or explicitly support a graph of type definitions</li><li><strong>inverted edges</strong> — hetio internally stores two copies of each edge (inverses of each other)</li></ul>\r\n\r\n<p>We plan to create export functionality from hetio to neo4j, so we can leverage the strengths of neo4j.</p>",
      "body_md": "Recently, I went a two-part meetup series on the graph database [neo4j](http://neo4j.com/). [Nicole White](http://nicolewhite.github.io/) led the meetups and her materials are online:\r\n\r\n1.  neo4j: Intro to Graphs ([slides](https://www.dropbox.com/s/zv0s4lwc6gvwxjy/Galvanize.pptx?dl=0), [meetup](http://www.meetup.com/SF-Data-Science/events/224956828))\r\n2. Data Science with Python and Neo4j ([tutorial](http://nicolewhite.github.io/neo4j-jupyter/main.html), [repository](https://github.com/nicolewhite/neo4j-jupyter), [meetup](http://www.meetup.com/SF-Data-Science/events/224406352))\r\n\r\nCurrently, we store our hetnets in compressed json text files. To perform any computation or graph analyses, we must load the network into memory, a process that takes from 2--5 minutes for version one of our [network](http://thinklab.com/discussion/one-network-to-rule-them-all/102#1). In contrast neo4j provides persistent storage with immediate access.\r\n\r\nAdditional benefits of neo4j include a mature [ecosystem](https://github.com/GraphGeeks/awesome-neo4j) offering broad functionality. The [Cyper](http://neo4j.com/developer/cypher-query-language/) query language is especially exciting. Cypher uses an ASCII-art based syntax to enable advanced graph lookups and traversals with little boilerplate.\r\n\r\n## Comparison to hetio\r\n\r\nThere are a few differences between neo4j and our python package [hetio](https://github.com/dhimmel/hetio) [@10.5281/zenodo.31763] with regards to hetnets:\r\n\r\n+ **nomenclature** -- an edge in hetio is called a relationship in neo4j. hetio calls itself a [hetnet](http://thinklab.com/discussion/renaming-heterogeneous-networks-to-a-more-concise-and-catchy-term/104), while neo4j calls itself a [property graph](http://neo4j.com/developer/graph-database/#property-graph)\r\n+ **node type** -- in hetio each node belongs to one metanode representing its type. in neo4j node are annotated with a label to indicate type, and a node can have ≥ 0 labels\r\n+ **directionality** -- in hetio metaedges are either directed or undirected and edges conform to their metaedge's directionality. neo4j doesn't support undirected edges. The [suggested workaround](http://graphaware.com/neo4j/2013/10/11/neo4j-bidirectional-relationships.html) is to arbitrarily choose a direction upon creation and ignore the direction when querying\r\n+ **type graph** -- hetio requires a predefined graph of types called a metagraph. neo4j does not enforce or explicitly support a graph of type definitions\r\n+ **inverted edges** -- hetio internally stores two copies of each edge (inverses of each other)\r\n\r\nWe plan to create export functionality from hetio to neo4j, so we can leverage the strengths of neo4j.",
      "comment_id": 437,
      "profile_id": 17,
      "published": "2015-10-02T22:20:16.909046Z",
      "thread_id": 112,
      "url": "/discussion/using-the-neo4j-graph-database-for-hetnets/112"
    },
    {
      "body_html": "<p>Hi all,<br>I am <strong>a</strong> lawyer, but not <strong>your</strong> lawyer (or UC’s lawyer), and this isn’t legal advice. Also, I’m not yet familiar with the data sources or the project at a high level of detail - but here’s what I can say about the general issues.</p>\r\n\r\n<h1>I. U.S. law</h1>\r\n\r\n<h2>A. Layers of copyright</h2>\r\n\r\n<ol><li>I notice that you’ve generally got a single assessment of copyright/licensing issues associated with each data source. I could see each one having up to three. For instance, you could have facts that both the original distributor and the downstream user agree are in the public domain - layer 1, you can do anything with those if you’ve extracted them and rearranged them. They could be collected and shared in a database that’s licensed under something like CC BY-SA, and the terms of that license would need to be followed when distributing the whole database, or parts of it, in such a way that you were copying &amp; distributing the licensor’s copyrightable arrangement/selection/original authorship. The database is layer 2. Then you might have special software created by the data distributor to access and manipulate the data and/or the database, and that might be licensed separately, either with a CC license or with an open source software license like MIT or BSD. That’s layer 3. Without being an expert on these particular databases, I’m guessing 2 and 3 are often going to be the same thing, but it’s best not to just assume that.</li><li>If no license terms are posted, the underlying facts are in the public domain, and any copyrightable expression like software, or creative arrangement, is copyright default’s “all rights reserved.”</li><li>Why am I bothering to spell this out? Depending on the terms of these things and how you want to use/redistribute them, it’s possible that something like the GSEA/MIT terms that look really restrictive may not be a hurdle. I read that one to limit what you can do with layers 2 (“the DATABASE”) and 3 (“the PROGRAM”), but less so layer 1. If you’re committed to redistribution of layer 2 wholesale, then yeah, we’ve got barriers.</li></ol>\r\n\r\n<h2>B. Particular licenses</h2>\r\n\r\n<ol><li>Software licenses are more commonly used for software than CC licenses are, although either would theoretically work. UC recommends BSD and MIT licenses in particular, because they don’t say anything about patents.</li><li>There’s some interesting stuff in the fine print of the CC licenses that might be helpful. For instance, the SA requirement has to be retained by the original material, and has to be attached to any “Adapted Material.” But not every use of a work is “Adapted Material.” Compilations generally aren’t an adaptation, so maybe there’s some creative thinking to be done around that. Attribution requirements can be satisfied in “any reasonable manner based on the medium, means, and context,” and maybe we could do some thinking about what’s a reasonable manner in <em>this</em> context.</li></ol>\r\n\r\n<h2>C. The CC0 dedication</h2>\r\n\r\n<ol><li>Like the CC licenses, the CC0 dedication only applies to … what it <em>can</em> apply to. Just the things the licensor has the ability to waive rights to. Here’s the language:<br><em>Affirmer disclaims responsibility for clearing rights of other persons that may apply to the Work or any use thereof, including without limitation any person's Copyright and Related Rights in the Work. Further, Affirmer disclaims responsibility for obtaining any necessary consents, permissions or other rights required for any use of the Work.</em><br>On the bright side this means that theoretically, you can just release your own layer/contributions/authorship as CC0, without affecting the things you reference or incorporate. Unfortunately, this isn’t so helpful for downstream users who have to try to figure out what the CC0 applies to and what other rights are lurking there. Lots of explanation, labeling, help pages, etc. can be useful if people read them.</li></ol>\r\n\r\n<h2>D. UC and data “ownership”</h2>\r\n\r\n<ol><li>I’m going to keep putting “ownership” in quotes until something official explains to me, to my satisfaction, exactly what UC is claiming to own. The APM policy they seem to rely on from the 50s talks about records, like notebooks. Data can only be owned to the extent there’s intellectual property involved, like patent, copyright, or trade secrets. If none of those are present, there’s nothing to own. There may be contractual restrictions about what you can or must do with something, that you’ve agreed to as part of an employment agreement or a grant agreement, but that’s a different animal, and will be more explicit than the automatic rights involved in copyright.</li><li>Depending on how this project is funded I think any copyrightable work here - the software, for instance - could be student work, personal work, or institutional work, under the 1992 Copyright Ownership Policy. It’s unlikely to be a scholarly/aesthetic work because of the definition of “designated academic appointee,” but I don’t know who the co-authors are.</li><li>UC’s lawyers - OGC and general counsel - will generally weigh in to assess legal risk to the university or disposition of university intellectual property. They will not/cannot provide advice about liability to an individual, or assessment of their personal intellectual property.</li><li>Each campus has a designated authority who is authorized to approve licensing decisions and the like on that campus. I believe UCSF’s is Karin Immergluck. In my experience, if we get to a place where we decide “well, this project includes copyrights owned by UCSF, but we want to license them CC BY or dedicate them to the public domain,” an email to the relevant campus person explaining the rationale (and preferably why this isn’t something the university would make money off of) results in a quick approval.</li></ol>\r\n\r\n<h2>E. Contracts</h2>\r\n\r\n<ol><li>U.S. copyright law includes all kinds of rights for users, including fair use, and the fact that certain things are in the public domain. But you can sign a contract giving away any of these rights. To the extent that you have to agree to restrictive terms to get access to a data set, those terms may effectively limit your rights to reuse even factual data. It’s like when libraries sign a license for a ProQuest database and promise not to make any copies of newspaper articles from the 1800s.</li></ol>\r\n\r\n<h1>II. International law</h1>\r\n\r\n<h2>A. Database protection generally</h2>\r\n\r\n<p>Lots of countries protect a database, but not the underlying facts, with copyright law. I see you found the Bitlaw page on this, which is where I would have sent you.</p>\r\n\r\n<h2>B. European database directive</h2>\r\n\r\n<p>I’ve never had occasion to deal with this before, but there’s a parallel thing in some countries like Italy for, e.g. digitizing old manuscripts. Limited protection as an incentive to create the thing or make it accessible. It sounds like enough of a pain that it’s probably worth figuring out which of the proposed sources are covered. That may be time consuming and difficult - so, something for further discussion/research.</p>\r\n\r\n<h2>C. International liability for potential copyright infringement</h2>\r\n\r\n<p>This is a tricky issue, and a fun subject for law review articles. Most of them revolve around <em>selling</em> things internationally, for a couple reasons. First, that’s when you’re likely to make people mad enough to bother with suing you. Second, there are jurisdictional issues about how much you have to do in a country to subject yourself to a lawsuit there. All I can say is that internet plus free distribution doesn’t automatically equal global legal risk. But that may not matter much because...</p>\r\n\r\n<h1>II. There’s law, and then there’s politics.</h1>\r\n\r\n<p>If we were looking at hundreds of sources, contacting them individually would be a horrible thing to contemplate. With a couple dozen, it might be worth it to put together a form letter to let people know about the project, to avoid burning bridges with current colleagues and potential future collaborators. This could address the things these folks are most likely to be concerned about: what is this project doing with the data sources? How will downstream users be able to tell the source of the data? What things will facilitate or burden commercial use? And there could be a few different versions depending on the legal assessment of the underlying rights and which ones the project implicates - maybe a letter to US sources is more of an FYI, and one to European sources asks them to reply granting permission. Or maybe if the project really wants <em>everything</em> to be as open as possible, you just actually get permission from everyone to a release of some version of their data, in this context, under your chosen license. Just because they make it available to the world under, e.g., CC BY-SA doesn’t mean they can’t make it available to you under different terms. There are options. None of them are as easy as “just use it,” but if people have tried to restrict how their stuff is used you have to decide the relative value you place on maximizing your rights under the law vs. maintaining goodwill.</p>",
      "body_md": "Hi all,\r\nI am **a** lawyer, but not **your** lawyer (or UC’s lawyer), and this isn’t legal advice. Also, I’m not yet familiar with the data sources or the project at a high level of detail - but here’s what I can say about the general issues.\r\n\r\n#I. U.S. law\r\n##   A. Layers of copyright\r\n1. I notice that you’ve generally got a single assessment of copyright/licensing issues associated with each data source. I could see each one having up to three. For instance, you could have facts that both the original distributor and the downstream user agree are in the public domain - layer 1, you can do anything with those if you’ve extracted them and rearranged them. They could be collected and shared in a database that’s licensed under something like CC BY-SA, and the terms of that license would need to be followed when distributing the whole database, or parts of it, in such a way that you were copying & distributing the licensor’s copyrightable arrangement/selection/original authorship. The database is layer 2. Then you might have special software created by the data distributor to access and manipulate the data and/or the database, and that might be licensed separately, either with a CC license or with an open source software license like MIT or BSD. That’s layer 3. Without being an expert on these particular databases, I’m guessing 2 and 3 are often going to be the same thing, but it’s best not to just assume that.\r\n2. If no license terms are posted, the underlying facts are in the public domain, and any copyrightable expression like software, or creative arrangement, is copyright default’s “all rights reserved.”\r\n3. Why am I bothering to spell this out? Depending on the terms of these things and how you want to use/redistribute them, it’s possible that something like the GSEA/MIT terms that look really restrictive may not be a hurdle. I read that one to limit what you can do with layers 2 (“the DATABASE”) and 3 (“the PROGRAM”), but less so layer 1. If you’re committed to redistribution of layer 2 wholesale, then yeah, we’ve got barriers.\r\n##   B. Particular licenses\r\n1.  Software licenses are more commonly used for software than CC licenses are, although either would theoretically work. UC recommends BSD and MIT licenses in particular, because they don’t say anything about patents.\r\n2. There’s some interesting stuff in the fine print of the CC licenses that might be helpful. For instance, the SA requirement has to be retained by the original material, and has to be attached to any “Adapted Material.” But not every use of a work is “Adapted Material.” Compilations generally aren’t an adaptation, so maybe there’s some creative thinking to be done around that. Attribution requirements can be satisfied in “any reasonable manner based on the medium, means, and context,” and maybe we could do some thinking about what’s a reasonable manner in *this* context.\r\n##   C. The CC0 dedication\r\n1. Like the CC licenses, the CC0 dedication only applies to … what it *can* apply to. Just the things the licensor has the ability to waive rights to. Here’s the language:\r\n*Affirmer disclaims responsibility for clearing rights of other persons that may apply to the Work or any use thereof, including without limitation any person's Copyright and Related Rights in the Work. Further, Affirmer disclaims responsibility for obtaining any necessary consents, permissions or other rights required for any use of the Work.*\r\nOn the bright side this means that theoretically, you can just release your own layer/contributions/authorship as CC0, without affecting the things you reference or incorporate. Unfortunately, this isn’t so helpful for downstream users who have to try to figure out what the CC0 applies to and what other rights are lurking there. Lots of explanation, labeling, help pages, etc. can be useful if people read them.\r\n##   D. UC and data “ownership”\r\n1. I’m going to keep putting “ownership” in quotes until something official explains to me, to my satisfaction, exactly what UC is claiming to own. The APM policy they seem to rely on from the 50s talks about records, like notebooks. Data can only be owned to the extent there’s intellectual property involved, like patent, copyright, or trade secrets. If none of those are present, there’s nothing to own. There may be contractual restrictions about what you can or must do with something, that you’ve agreed to as part of an employment agreement or a grant agreement, but that’s a different animal, and will be more explicit than the automatic rights involved in copyright.\r\n2. Depending on how this project is funded I think any copyrightable work here - the software, for instance - could be student work, personal work, or institutional work, under the 1992 Copyright Ownership Policy. It’s unlikely to be a scholarly/aesthetic work because of the definition of “designated academic appointee,” but I don’t know who the co-authors are.\r\n3. UC’s lawyers - OGC and general counsel - will generally weigh in to assess legal risk to the university or disposition of university intellectual property. They will not/cannot provide advice about liability to an individual, or assessment of their personal intellectual property.\r\n4. Each campus has a designated authority who is authorized to approve licensing decisions and the like on that campus. I believe UCSF’s is Karin Immergluck. In my experience, if we get to a place where we decide “well, this project includes copyrights owned by UCSF, but we want to license them CC BY or dedicate them to the public domain,” an email to the relevant campus person explaining the rationale (and preferably why this isn’t something the university would make money off of) results in a quick approval.\r\n##   E. Contracts\r\n1. U.S. copyright law includes all kinds of rights for users, including fair use, and the fact that certain things are in the public domain. But you can sign a contract giving away any of these rights. To the extent that you have to agree to restrictive terms to get access to a data set, those terms may effectively limit your rights to reuse even factual data. It’s like when libraries sign a license for a ProQuest database and promise not to make any copies of newspaper articles from the 1800s.\r\n#II. International law\r\n##   A. Database protection generally\r\nLots of countries protect a database, but not the underlying facts, with copyright law. I see you found the Bitlaw page on this, which is where I would have sent you.\r\n##   B. European database directive\r\nI’ve never had occasion to deal with this before, but there’s a parallel thing in some countries like Italy for, e.g. digitizing old manuscripts. Limited protection as an incentive to create the thing or make it accessible. It sounds like enough of a pain that it’s probably worth figuring out which of the proposed sources are covered. That may be time consuming and difficult - so, something for further discussion/research.\r\n##   C. International liability for potential copyright infringement\r\nThis is a tricky issue, and a fun subject for law review articles. Most of them revolve around *selling* things internationally, for a couple reasons. First, that’s when you’re likely to make people mad enough to bother with suing you. Second, there are jurisdictional issues about how much you have to do in a country to subject yourself to a lawsuit there. All I can say is that internet plus free distribution doesn’t automatically equal global legal risk. But that may not matter much because...\r\n#II. There’s law, and then there’s politics.\r\nIf we were looking at hundreds of sources, contacting them individually would be a horrible thing to contemplate. With a couple dozen, it might be worth it to put together a form letter to let people know about the project, to avoid burning bridges with current colleagues and potential future collaborators. This could address the things these folks are most likely to be concerned about: what is this project doing with the data sources? How will downstream users be able to tell the source of the data? What things will facilitate or burden commercial use? And there could be a few different versions depending on the legal assessment of the underlying rights and which ones the project implicates - maybe a letter to US sources is more of an FYI, and one to European sources asks them to reply granting permission. Or maybe if the project really wants *everything* to be as open as possible, you just actually get permission from everyone to a release of some version of their data, in this context, under your chosen license. Just because they make it available to the world under, e.g., CC BY-SA doesn’t mean they can’t make it available to you under different terms. There are options. None of them are as easy as “just use it,” but if people have tried to restrict how their stuff is used you have to decide the relative value you place on maximizing your rights under the law vs. maintaining goodwill.\r\n\r\n",
      "comment_id": 438,
      "profile_id": 137,
      "published": "2015-09-22T20:42:41.586272Z",
      "thread_id": 107,
      "url": "/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#10"
    },
    {
      "body_html": "<p>We currently rely on <a href=\"http://www.broadinstitute.org/gsea/msigdb/index.jsp\">MSigDB</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1073/pnas.0506580102\" class=\"citation\" data-key=\"10.1073/pnas.0506580102\">1</a>, <a href=\"https://doi.org/10.1093/bioinformatics/btr260\" class=\"citation\" data-key=\"10.1093/bioinformatics/btr260\">2</a>]</span>, the Molecular Signatures Database, for perturbation gene sets and pathways. Since the <a href=\"https://github.com/dhimmel/integrate/blob/afe1c049e4a088bc266533332e6e00499e3d2e20/licenses/custom/MSigDB.asciidoc\">license</a> is highly restrictive, we have emailed the creators with the below message. We will post any updates regarding MSigDB licensing or permissions on this discussion.</p>\r\n\r\n<hr>\r\n\r\n<p>Greetings MSigDB Team,</p>\r\n\r\n<p>I am a graduate student at UCSF, and I have been using <a href=\"http://www.broadinstitute.org/gsea/msigdb/index.jsp\">MSigDB</a> for my research. My project aims to predict new uses for existing drugs by integrating many different types of biomedical information. Recently, the issue of database copyright and licensing <a href=\"http://thinklab.com/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d107\">came up</a>, and we are now trying to ensure that we have sufficient permissions for each of the 28 databases we're integrating.</p>\r\n\r\n<p>I was surprised to learn of MSigDB's restrictive <a href=\"http://www.broadinstitute.org/cancer/software/gsea/wiki/index.php/License_info\">license</a> that forbids redistribution, especially given the projects <a href=\"http://grantome.com/grant/NIH/R01-CA121941-06A1\">public funding</a>. Currently, several resources I have created may be non-compliant with the license:</p>\r\n\r\n<p>My GitHub repository (<a href=\"https://github.com/dhimmel/msigdb\"><code>dhimmel/msigdb</code></a>) for parsing the MSigDB database contains:</p>\r\n\r\n<ul><li>unmodified MSigDB downloads</li><li>a reformatted version of the underlying data</li></ul>\r\n\r\n<p>My GitHub repository (<a href=\"https://github.com/dhimmel/pathways\"><code>dhimmel/pathways</code></a>) for combining pathway databases contains:</p>\r\n\r\n<ul><li>the reformatted version of C2:CP from <code>dhimmel/msigdb</code> and a derived dataset containing pathways from other resources</li></ul>\r\n\r\n<p>My GitHub repository (<a href=\"https://github.com/dhimmel/integrate\"><code>dhimmel/integrate</code></a>) for integrating many resources into a single network contains:</p>\r\n\r\n<ul><li>the majority of MSigDB 5.0 C2:CP and C2:CGP data stored as network nodes and edges.</li></ul>\r\n\r\n<p>My <a href=\"http://het.io/disease-genes/downloads/\">website</a> for a previous project <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1004259\">3</a>]</span> contains:</p>\r\n\r\n<ul><li>a network download formatted as in <code>dhimmel/integrate</code>, but containing data from most collections in MSigDB version 3.0.</li></ul>\r\n\r\n<p>The public availability of the aforementioned resources is important so others can reproduce and build off of our work. Thus, we request permission for our current redistribution and derivative works of MSigDB. Ideally, we could be granted permission to release MSigDB data under a <a href=\"https://creativecommons.org/licenses/\">Creative Commons license</a> without a No Derivatives restriction. Applying a CC license would lessen the burden on downstream users.</p>\r\n\r\n<p>Thanks for your consideration. Our research is academic in nature, and we suspect it falls under the intended use of MSigDB but perhaps not the license.</p>\r\n\r\n<p>Finally, we're performing our project using an open science platform called Thinklab. I've <a href=\"#1\">posted a copy</a> of this email on Thinklab and will update the discussion with our progress. Alternatively, feel free to respond via Thinklab rather than email. By detailing each step of our research process publicly, we're hoping to create a valuable resource and explore a more holistic and collaborative medium of publication.</p>\r\n\r\n<p>Sincerely,<br>Daniel</p>",
      "body_md": "We currently rely on [MSigDB](http://www.broadinstitute.org/gsea/msigdb/index.jsp) [@10.1073/pnas.0506580102 @10.1093/bioinformatics/btr260], the Molecular Signatures Database, for perturbation gene sets and pathways. Since the [license](https://github.com/dhimmel/integrate/blob/afe1c049e4a088bc266533332e6e00499e3d2e20/licenses/custom/MSigDB.asciidoc) is highly restrictive, we have emailed the creators with the below message. We will post any updates regarding MSigDB licensing or permissions on this discussion.\r\n\r\n***\r\n\r\nGreetings MSigDB Team,\r\n\r\nI am a graduate student at UCSF, and I have been using [MSigDB](http://www.broadinstitute.org/gsea/msigdb/index.jsp) for my research. My project aims to predict new uses for existing drugs by integrating many different types of biomedical information. Recently, the issue of database copyright and licensing [came up](http://thinklab.com/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107), and we are now trying to ensure that we have sufficient permissions for each of the 28 databases we're integrating.\r\n\r\nI was surprised to learn of MSigDB's restrictive [license](http://www.broadinstitute.org/cancer/software/gsea/wiki/index.php/License_info) that forbids redistribution, especially given the projects [public funding](http://grantome.com/grant/NIH/R01-CA121941-06A1). Currently, several resources I have created may be non-compliant with the license:\r\n\r\nMy GitHub repository ([`dhimmel/msigdb`](https://github.com/dhimmel/msigdb)) for parsing the MSigDB database contains:\r\n\r\n+ unmodified MSigDB downloads\r\n+ a reformatted version of the underlying data\r\n\r\nMy GitHub repository ([`dhimmel/pathways`](https://github.com/dhimmel/pathways)) for combining pathway databases contains:\r\n\r\n+ the reformatted version of C2:CP from `dhimmel/msigdb` and a derived dataset containing pathways from other resources\r\n\r\nMy GitHub repository ([`dhimmel/integrate`](https://github.com/dhimmel/integrate)) for integrating many resources into a single network contains:\r\n\r\n+ the majority of MSigDB 5.0 C2:CP and C2:CGP data stored as network nodes and edges.\r\n\r\nMy [website](http://het.io/disease-genes/downloads/) for a previous project [@10.1371/journal.pcbi.1004259] contains:\r\n\r\n+ a network download formatted as in `dhimmel/integrate`, but containing data from most collections in MSigDB version 3.0.\r\n\r\nThe public availability of the aforementioned resources is important so others can reproduce and build off of our work. Thus, we request permission for our current redistribution and derivative works of MSigDB. Ideally, we could be granted permission to release MSigDB data under a [Creative Commons license](https://creativecommons.org/licenses/) without a No Derivatives restriction. Applying a CC license would lessen the burden on downstream users.\r\n\r\nThanks for your consideration. Our research is academic in nature, and we suspect it falls under the intended use of MSigDB but perhaps not the license.\r\n\r\nFinally, we're performing our project using an open science platform called Thinklab. I've [posted a copy](#1) of this email on Thinklab and will update the discussion with our progress. Alternatively, feel free to respond via Thinklab rather than email. By detailing each step of our research process publicly, we're hoping to create a valuable resource and explore a more holistic and collaborative medium of publication.\r\n\r\nSincerely,\r\nDaniel",
      "comment_id": 439,
      "profile_id": 17,
      "published": "2015-09-28T18:33:52.869612Z",
      "thread_id": 108,
      "url": "/discussion/msigdb-licensing/108"
    },
    {
      "body_html": "<h1>Mixed copyright licensing</h1>\r\n\r\n<p>As explained <a href=\"#4\">above</a>, we have created resources (mostly GitHub repositories) that contain content with varying licenses and restrictions. Therefore, we need to:</p>\r\n\r\n<ul><li>license different files from the same repository under different licenses</li><li>license different portions within a single file under different licenses</li></ul>\r\n\r\n<p>It appears that there is not a rigid formula for how to specify mixed copyright. I found a few examples including the <a href=\"https://github.com/neo4j/neo4j/blob/5f991933fa531f7dd901d4b6570fe78d73f8bb3c/README.asciidoc\">neo4j source code</a> and a <a href=\"https://github.com/lucidv01d/samasy/blob/32148fdd01c1993a991787d23f4c851ff26f7c01/LICENSE\">license</a> the <a href=\"https://ita.ucsf.edu/\">UCSF Office of Innovation, Technology &amp; Alliances</a> created for my classmate.</p>\r\n\r\n<p>In the later case, my classmate asked the ITA to assist him in creating an open source license. As <a href=\"/u/mackenziesmith\" class=\"username\">@mackenziesmith</a> predicted, UC asserted ownership of the content and forbid any for-profit usage. As an aside, I am highly confident that UC does not own my work, because it is not <em>work made for hire</em>, and I never agreed to any transfer of ownership.</p>\r\n\r\n<h2>Proposed license for the SIDER4 repository</h2>\r\n\r\n<p>SIDER 4 is a resource <a href=\"http://thinklab.com/discussion/extracting-side-effects-from-sider-4/97\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d97\">we're using</a> for drug side effects. I propose the <a href=\"https://github.com/dhimmel/SIDER4/blob/45d0ba626e406ae3ce6f8f503f09d5af9b4b7b63/LICENSE.md\">following license</a> for the repository:</p>\r\n\r\n<blockquote><p>SIDER 4 data is <a href=\"http://sideeffects.embl.de/download/\">released</a> under a <a href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">CC-BY-NC-SA</a> license. Therefore, all redistributed and derived content from SIDER 4 is <a href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">CC-BY-NC-SA</a>. All original content is released under <a href=\"https://creativecommons.org/publicdomain/zero/1.0/\">CC0</a>.</p><p>Accordingly, the following files are <a href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">CC-BY-NC-SA</a>:</p><ul><li><code>download/meddra_all_indications.tsv.gz</code></li><li><code>download/meddra_all_se.tsv.gz</code></li><li><code>download/meddra_freq.tsv.gz</code></li><li><code>data/indication.tsv</code></li><li><code>data/side-effects.tsv</code></li></ul><p><strong>Disclaimer</strong>: The repository is provided \"as is\", without warranty of any kind, express or implied, including but not limited to the warranties of merchantability, fitness for a particular purpose and noninfringement. In no event shall the authors or copyright holders be liable for any claim, damages or other liability, whether in an action of contract, tort or otherwise, arising from, out of or in connection with the repository or the use or other dealings in the repository.</p></blockquote>\r\n\r\n<p>We added the disclaimer to limit our liability as <a href=\"#4\">suggested</a> by <a href=\"/u/mackenziesmith\" class=\"username\">@mackenziesmith</a>. Does the proposed license seem adequate? Is it clear? <a href=\"/u/katiefortney\" class=\"username\">@katiefortney</a>, any suggestions?</p>",
      "body_md": "# Mixed copyright licensing\r\n\r\nAs explained [above](#4), we have created resources (mostly GitHub repositories) that contain content with varying licenses and restrictions. Therefore, we need to:\r\n\r\n+ license different files from the same repository under different licenses\r\n+ license different portions within a single file under different licenses\r\n\r\nIt appears that there is not a rigid formula for how to specify mixed copyright. I found a few examples including the [neo4j source code](https://github.com/neo4j/neo4j/blob/5f991933fa531f7dd901d4b6570fe78d73f8bb3c/README.asciidoc) and a [license](https://github.com/lucidv01d/samasy/blob/32148fdd01c1993a991787d23f4c851ff26f7c01/LICENSE) the [UCSF Office of Innovation, Technology & Alliances](https://ita.ucsf.edu/) created for my classmate.\r\n\r\nIn the later case, my classmate asked the ITA to assist him in creating an open source license. As @mackenziesmith predicted, UC asserted ownership of the content and forbid any for-profit usage. As an aside, I am highly confident that UC does not own my work, because it is not *work made for hire*, and I never agreed to any transfer of ownership.\r\n\r\n## Proposed license for the SIDER4 repository\r\n\r\nSIDER 4 is a resource [we're using](http://thinklab.com/discussion/extracting-side-effects-from-sider-4/97) for drug side effects. I propose the [following license](https://github.com/dhimmel/SIDER4/blob/45d0ba626e406ae3ce6f8f503f09d5af9b4b7b63/LICENSE.md) for the repository:\r\n\r\n> SIDER 4 data is [released](http://sideeffects.embl.de/download/) under a [CC-BY-NC-SA](http://creativecommons.org/licenses/by-nc-sa/4.0/) license. Therefore, all redistributed and derived content from SIDER 4 is [CC-BY-NC-SA](http://creativecommons.org/licenses/by-nc-sa/4.0/). All original content is released under [CC0](https://creativecommons.org/publicdomain/zero/1.0/).\r\n\r\n> Accordingly, the following files are [CC-BY-NC-SA](http://creativecommons.org/licenses/by-nc-sa/4.0/):\r\n\r\n>\r\n+ `download/meddra_all_indications.tsv.gz`\r\n+ `download/meddra_all_se.tsv.gz`\r\n+ `download/meddra_freq.tsv.gz`\r\n+ `data/indication.tsv`\r\n+ `data/side-effects.tsv`\r\n\r\n> **Disclaimer**: The repository is provided \"as is\", without warranty of any kind, express or implied, including but not limited to the warranties of merchantability, fitness for a particular purpose and noninfringement. In no event shall the authors or copyright holders be liable for any claim, damages or other liability, whether in an action of contract, tort or otherwise, arising from, out of or in connection with the repository or the use or other dealings in the repository.\r\n\r\nWe added the disclaimer to limit our liability as [suggested](#4) by @mackenziesmith. Does the proposed license seem adequate? Is it clear? @katiefortney, any suggestions?",
      "comment_id": 440,
      "profile_id": 17,
      "published": "2015-09-28T18:06:50.053385Z",
      "thread_id": 107,
      "url": "/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#11"
    },
    {
      "body_html": "<p>We're currently using LINCS L1000 data for compound–gene and gene–gene edges in our <a href=\"http://thinklab.com/discussion/one-network-to-rule-them-all/102\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d102\">network</a>. Thus far we have developed methods for computing <a href=\"http://thinklab.com/discussion/computing-consensus-transcriptional-profiles-for-compounds-using-lincs/43\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d43\">consensus expression signatures</a> and <a href=\"http://thinklab.com/discussion/unichem-mapping-to-lincs-small-molecules/51\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d51\">mapping LINCS compounds</a> to other identifier systems. However, <a href=\"/u/larsjuhljensen\" class=\"username\">@larsjuhljensen</a> <a href=\"http://thinklab.com/discussion/one-network-to-rule-them-all/102#2\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d102\">pointed out</a> that the <a href=\"https://github.com/dhimmel/integrate/blob/afe1c049e4a088bc266533332e6e00499e3d2e20/licenses/custom/L1000.md\">license</a> requires permission for redistribution:</p>\r\n\r\n<blockquote><p>If you have a derivative work that is significantly different from what we provide and you would like to distribute it, please contact us with the details. Our goal is to encourage significant improvements while maintaining provenance and reproducible research standards.</p></blockquote>\r\n\r\n<p>Therefore, we have emailed the LINCS L1000 team with the following permission request. We will post any updates regarding licensing or permissions on this discussion.</p>\r\n\r\n<hr>\r\n\r\n<p>Greetings LINCS L1000 Team,</p>\r\n\r\n<p>I am a graduate student at UCSF, and I have been using <a href=\"http://www.lincscloud.org/\">LINCS L1000</a> for my research. My project aims to predict new uses for existing drugs by integrating many different types of biomedical information. Recently, the issue of database copyright and licensing <a href=\"http://thinklab.com/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d107\">came up</a>, and we are now trying to ensure that we have sufficient permissions for each of the 28 databases we're integrating.</p>\r\n\r\n<p>Currently, several resources I have created may be non-compliant with the license.</p>\r\n\r\n<p>My GitHub repository (<a href=\"https://github.com/dhimmel/lincs\"><code>dhimmel/lincs</code></a>) contains:</p>\r\n\r\n<ul><li>Python code from <a href=\"https://github.com/cmap/l1ktools/tree/7f1752e87bbaeeedfce18c68f84c4e1feb331e9e/python/cmap\"><code>cmap/l1ktools/python/cmap</code></a></li><li><a href=\"https://github.com/dhimmel/lincs/tree/69956dec590ce4caace9df31f5b60c978f321fdc/data\">Data</a> retrieved from the <a href=\"http://api.lincscloud.org/\">API</a> in an unmodified json format and a condensed tsv format.</li><li><a href=\"https://github.com/dhimmel/lincs/tree/69956dec590ce4caace9df31f5b60c978f321fdc/data/consensi\">Consensus signatures</a> for DrugBank compounds, gene overexpressions, gene knockdowns, and perturbations. Our consensus signatures combine <em>z</em>-scores from multiple signatures. We <a href=\"http://thinklab.com/discussion/computing-consensus-transcriptional-profiles-for-compounds-using-lincs/43#6\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d43\">computed</a> our signatures using a method suggested to us during LINCS office hours, with some modifications.</li><li>Our <a href=\"https://github.com/dhimmel/lincs/blob/69956dec590ce4caace9df31f5b60c978f321fdc/.gitignore\"><code>.gitignore</code></a> file prevents the following items from being uploaded to the repository: our private API key, <code>modzs.gctx</code>, and a local database (<code>l1000.db</code>) that is too large for GitHub.</li><li>An archived version of this repository is <a href=\"https://doi.org/10.5281/zenodo.27229\">hosted</a> on Zenodo <span class=\"citation\">[<a href=\"https://doi.org/10.5281/zenodo.27229\" class=\"citation\" data-key=\"10.5281/zenodo.27229\">1</a>]</span>.</li></ul>\r\n\r\n<p>My GitHub repository (<a href=\"https://github.com/dhimmel/integrate\"><code>dhimmel/integrate</code></a>) for integrating many resources into a single network contains:</p>\r\n\r\n<ul><li>Consensus signatures for DrugBank compounds and genetic perturbations (gene overexpressions and knowdowns) encoded as network nodes and edges.</li></ul>\r\n\r\n<p><a href=\"/u/leobrueggeman\" class=\"username\">@leobrueggeman</a> assisted with the LINCS analysis. His GitHub repository (<a href=\"https://github.com/LABrueggs/L1000/tree/8720f12c25bdc46ef789785c474b8f0af9200fcf\"><code>LABrueggs/L1000</code></a>) contains elements similar to <code>dhimmel/lincs</code> discussed above. Two files of consensus signatures from his repository are <a href=\"https://doi.org/10.6084/m9.figshare.1476293\">posted</a> to figshare <span class=\"citation\">[<a href=\"https://doi.org/10.6084/m9.figshare.1476293\" class=\"citation\" data-key=\"10.6084/m9.figshare.1476293\">2</a>]</span>.</p>\r\n\r\n<p>The public availability of the aforementioned resources is important so others can reproduce and build off of our work. We have attempted to provide sufficient information for provenance and reproducibility but are happy to make any modifications to assist in these regards.</p>\r\n\r\n<p>Thus, we request permission for our current usage of LINCS L1000 data. Ideally, we could be granted permission to release the data under a <a href=\"https://creativecommons.org/licenses/\">Creative Commons license</a> without a No Derivatives restriction. Applying a CC license would lessen the burden on downstream users.</p>\r\n\r\n<p>Thanks for your consideration. Our research is academic in nature, and we suspect it is in line with the intended use of LINCS.</p>\r\n\r\n<p>Finally, we're performing our project using an open science platform called Thinklab. I've <a href=\"#1\">posted a copy</a> of this email on Thinklab and will update the discussion with our progress. Alternatively, feel free to respond via Thinklab rather than email. By detailing each step of our research process publicly, we're hoping to create a valuable resource and explore a more holistic and collaborative medium of publication.</p>\r\n\r\n<p>Sincerely,<br>Daniel</p>",
      "body_md": "We're currently using LINCS L1000 data for compound--gene and gene--gene edges in our [network](http://thinklab.com/discussion/one-network-to-rule-them-all/102). Thus far we have developed methods for computing [consensus expression signatures](http://thinklab.com/discussion/computing-consensus-transcriptional-profiles-for-compounds-using-lincs/43) and [mapping LINCS compounds](http://thinklab.com/discussion/unichem-mapping-to-lincs-small-molecules/51) to other identifier systems. However, @larsjuhljensen [pointed out](http://thinklab.com/discussion/one-network-to-rule-them-all/102#2) that the [license](https://github.com/dhimmel/integrate/blob/afe1c049e4a088bc266533332e6e00499e3d2e20/licenses/custom/L1000.md) requires permission for redistribution:\r\n\r\n> If you have a derivative work that is significantly different from what we provide and you would like to distribute it, please contact us with the details. Our goal is to encourage significant improvements while maintaining provenance and reproducible research standards.\r\n\r\nTherefore, we have emailed the LINCS L1000 team with the following permission request. We will post any updates regarding licensing or permissions on this discussion.\r\n\r\n***\r\n\r\nGreetings LINCS L1000 Team,\r\n\r\nI am a graduate student at UCSF, and I have been using [LINCS L1000](http://www.lincscloud.org/) for my research. My project aims to predict new uses for existing drugs by integrating many different types of biomedical information. Recently, the issue of database copyright and licensing [came up](http://thinklab.com/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107), and we are now trying to ensure that we have sufficient permissions for each of the 28 databases we're integrating.\r\n\r\nCurrently, several resources I have created may be non-compliant with the license.\r\n\r\nMy GitHub repository ([`dhimmel/lincs`](https://github.com/dhimmel/lincs)) contains:\r\n\r\n+ Python code from [`cmap/l1ktools/python/cmap`](https://github.com/cmap/l1ktools/tree/7f1752e87bbaeeedfce18c68f84c4e1feb331e9e/python/cmap)\r\n+ [Data](https://github.com/dhimmel/lincs/tree/69956dec590ce4caace9df31f5b60c978f321fdc/data) retrieved from the [API](http://api.lincscloud.org/) in an unmodified json format and a condensed tsv format.\r\n+ [Consensus signatures](https://github.com/dhimmel/lincs/tree/69956dec590ce4caace9df31f5b60c978f321fdc/data/consensi) for DrugBank compounds, gene overexpressions, gene knockdowns, and perturbations. Our consensus signatures combine *z*-scores from multiple signatures. We [computed](http://thinklab.com/discussion/computing-consensus-transcriptional-profiles-for-compounds-using-lincs/43#6) our signatures using a method suggested to us during LINCS office hours, with some modifications.\r\n+ Our [`.gitignore`](https://github.com/dhimmel/lincs/blob/69956dec590ce4caace9df31f5b60c978f321fdc/.gitignore) file prevents the following items from being uploaded to the repository: our private API key, `modzs.gctx`, and a local database (`l1000.db`) that is too large for GitHub.\r\n+ An archived version of this repository is [hosted](https://doi.org/10.5281/zenodo.27229) on Zenodo [@10.5281/zenodo.27229].\r\n\r\nMy GitHub repository ([`dhimmel/integrate`](https://github.com/dhimmel/integrate)) for integrating many resources into a single network contains:\r\n\r\n+ Consensus signatures for DrugBank compounds and genetic perturbations (gene overexpressions and knowdowns) encoded as network nodes and edges.\r\n\r\n@leobrueggeman assisted with the LINCS analysis. His GitHub repository ([`LABrueggs/L1000`](https://github.com/LABrueggs/L1000/tree/8720f12c25bdc46ef789785c474b8f0af9200fcf)) contains elements similar to `dhimmel/lincs` discussed above. Two files of consensus signatures from his repository are [posted](https://doi.org/10.6084/m9.figshare.1476293) to figshare [@10.6084/m9.figshare.1476293].\r\n\r\nThe public availability of the aforementioned resources is important so others can reproduce and build off of our work. We have attempted to provide sufficient information for provenance and reproducibility but are happy to make any modifications to assist in these regards.\r\n\r\nThus, we request permission for our current usage of LINCS L1000 data. Ideally, we could be granted permission to release the data under a [Creative Commons license](https://creativecommons.org/licenses/) without a No Derivatives restriction. Applying a CC license would lessen the burden on downstream users.\r\n\r\nThanks for your consideration. Our research is academic in nature, and we suspect it is in line with the intended use of LINCS.\r\n\r\nFinally, we're performing our project using an open science platform called Thinklab. I've [posted a copy](#1) of this email on Thinklab and will update the discussion with our progress. Alternatively, feel free to respond via Thinklab rather than email. By detailing each step of our research process publicly, we're hoping to create a valuable resource and explore a more holistic and collaborative medium of publication.\r\n\r\nSincerely,\r\nDaniel",
      "comment_id": 441,
      "profile_id": 17,
      "published": "2015-09-28T22:59:26.416850Z",
      "thread_id": 110,
      "url": "/discussion/lincs-l1000-licensing/110"
    },
    {
      "body_html": "<h1>Entrez Gene <em>Homo sapiens</em> gotcha</h1>\r\n\r\n<p>The <code>Homo_sapiens.gene_info.gz</code> <a href=\"ftp://ftp.ncbi.nih.gov/gene/DATA/GENE_INFO/Mammalia/\">download</a> from Entrez Gene contains a potential <a href=\"https://en.wikipedia.org/wiki/Gotcha_%28programming%29\">gotcha</a>. A small number of records at the end of the file are for:</p>\r\n\r\n<ul><li>Neanderthal (<a href=\"http://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?mode=Info&amp;id=63221\"><code>tax_id = 63221</code></a>)</li><li>Denisovan (<a href=\"http://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?mode=Info&amp;id=741158\"><code>tax_id = 741158</code></a>)</li></ul>\r\n\r\n<p>We only want genes for non-extinct <em>Homo sapiens</em> (<a href=\"http://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?mode=Info&amp;id=9606\"><code>tax_id = 9606</code></a>). We've <a href=\"https://github.com/dhimmel/entrez-gene/commit/1ff24cce1cbabfb7029704426b5dc4b654e484a4\">updated</a> our Entrez Gene processing to filter for a 9606 tax_id.</p>\r\n\r\n<p>The downstream effects of this update should be minimal, since only 73 genes were removed (all mitochondrial). However, we may rebuild some of our resources if necessary. The inclusion of these genes should only present problems when matching by symbol rather than GeneID. We avoid matching by symbol whenever possible.</p>",
      "body_md": "# Entrez Gene *Homo sapiens* gotcha\r\n\r\nThe `Homo_sapiens.gene_info.gz` [download](ftp://ftp.ncbi.nih.gov/gene/DATA/GENE_INFO/Mammalia/) from Entrez Gene contains a potential [gotcha](https://en.wikipedia.org/wiki/Gotcha_%28programming%29). A small number of records at the end of the file are for:\r\n\r\n+ Neanderthal ([`tax_id = 63221`](http://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?mode=Info&id=63221))\r\n+ Denisovan ([`tax_id = 741158`](http://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?mode=Info&id=741158))\r\n\r\nWe only want genes for non-extinct *Homo sapiens* ([`tax_id = 9606`](http://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?mode=Info&id=9606)). We've [updated](https://github.com/dhimmel/entrez-gene/commit/1ff24cce1cbabfb7029704426b5dc4b654e484a4) our Entrez Gene processing to filter for a 9606 tax_id.\r\n\r\nThe downstream effects of this update should be minimal, since only 73 genes were removed (all mitochondrial). However, we may rebuild some of our resources if necessary. The inclusion of these genes should only present problems when matching by symbol rather than GeneID. We avoid matching by symbol whenever possible.",
      "comment_id": 443,
      "profile_id": 17,
      "published": "2015-09-29T14:19:20.369515Z",
      "thread_id": 34,
      "url": "/discussion/using-entrez-gene-as-our-gene-vocabulary/34#9"
    },
    {
      "body_html": "<h1>Chronicling licensing and permission requests</h1>\r\n\r\n<p>Inspired by the story of Max Haeussler <span class=\"citation\">[<a href=\"https://doi.org/10.1038/483134a\" class=\"citation\" data-key=\"10.1038/483134a\">1</a>]</span> who <a href=\"http://text.soe.ucsc.edu/progress.html\">publicly documented</a> his permission requests to publishers to text mine their corpora, I will be chronicling our licensing efforts that require contact. We will therefore release summaries and statistics pertaining to three types of requests:</p>\r\n\r\n<ul><li>permission requests to resources with licenses that <strong>forbid redistribution or derivatives</strong>. We have begun by posting our requests to <a href=\"http://thinklab.com/discussion/msigdb-licensing/108\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d108\">MSigDB</a> and <a href=\"http://thinklab.com/discussion/lincs-l1000-licensing/110\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d110\">LINCS L1000</a>.</li><li>requests to post licenses for resources <strong>without licensing information</strong>. Resources for which we could not find license information are <a href=\"https://github.com/dhimmel/integrate/tree/0e343d8745a98757c86e73f645b41353f52b82b5/licenses\">available here</a>. We have already emailed the creators of these resources and will report back with progress.</li><li>for datasets obtained from <strong>publication supplements</strong>, license clarification or permission requests to the journal.</li></ul>",
      "body_md": "# Chronicling licensing and permission requests\r\n\r\nInspired by the story of Max Haeussler [@10.1038/483134a] who [publicly documented](http://text.soe.ucsc.edu/progress.html) his permission requests to publishers to text mine their corpora, I will be chronicling our licensing efforts that require contact. We will therefore release summaries and statistics pertaining to three types of requests:\r\n\r\n+ permission requests to resources with licenses that **forbid redistribution or derivatives**. We have begun by posting our requests to [MSigDB](http://thinklab.com/discussion/msigdb-licensing/108) and [LINCS L1000](http://thinklab.com/discussion/lincs-l1000-licensing/110).\r\n+ requests to post licenses for resources **without licensing information**. Resources for which we could not find license information are [available here](https://github.com/dhimmel/integrate/tree/0e343d8745a98757c86e73f645b41353f52b82b5/licenses). We have already emailed the creators of these resources and will report back with progress.\r\n+ for datasets obtained from **publication supplements**, license clarification or permission requests to the journal.",
      "comment_id": 445,
      "profile_id": 17,
      "published": "2015-09-30T17:04:25.075087Z",
      "thread_id": 107,
      "url": "/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#12"
    },
    {
      "body_html": "<h2>Definitions</h2>\r\n\r\n<p>In a meeting yesterday, we (Ari Green, Christine Hessler, <a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a>, <a href=\"/u/sergiobaranzini\" class=\"username\">@sergiobaranzini</a>) discussed the pilot experience and definitions. </p>\r\n\r\n<p>AJG pointed out that the term \"disease modifying\" is primarily used for rheumatology and multiple sclerosis. With this caveat in mind, we set out to identify a general definition that could apply broadly to complex disease. </p>\r\n\r\n<p>When considering possible definitions, <a href=\"/u/sergiobaranzini\" class=\"username\">@sergiobaranzini</a> and I stressed the following quality of a \"disease modifying\" indication:</p>\r\n\r\n<blockquote><p>If we predicted this indication, would the disease be considered an appropriate and precise application of the drug.</p></blockquote>\r\n\r\n<h3>We agreed on the following definitions:</h3>\r\n\r\n<ul><li><strong>disease modifying</strong> (<code>DM</code>) — a drug that therapeutically changes the underlying or downstream biology of the disease</li><li><strong>symptomatic</strong> (<code>SYM</code>) — a drug that treats a significant symptom of the disease</li><li><strong>non-indication</strong> (<code>NOT</code>) — a drug that neither therapeutically changes the underlying or downstream biology nor treats a significant symptom of the disease</li></ul>\r\n\r\n<p>We also agreed on the following <strong>guidelines</strong>:</p>\r\n\r\n<ul><li><strong>reasonable evidence</strong> of efficacy is required to be classified as disease modifying or symptomatic</li><li>if no classification accurately describes an indication, the <strong>most appropriate</strong> (although imperfect) classification should be chosen</li></ul>\r\n\r\n<h2>Next steps</h2>\r\n\r\n<p>AJG and CSH found many of their disagreements on the pilot indications resolved once a common definition was reached. With these definitions, we will now move onto the full set of indications, which AJG and CSH have agreed to curate.</p>",
      "body_md": "## Definitions\r\n\r\nIn a meeting yesterday, we (Ari Green, Christine Hessler, @dhimmel, @sergiobaranzini) discussed the pilot experience and definitions. \r\n\r\nAJG pointed out that the term \"disease modifying\" is primarily used for rheumatology and multiple sclerosis. With this caveat in mind, we set out to identify a general definition that could apply broadly to complex disease. \r\n\r\nWhen considering possible definitions, @sergiobaranzini and I stressed the following quality of a \"disease modifying\" indication:\r\n\r\n> If we predicted this indication, would the disease be considered an appropriate and precise application of the drug.\r\n\r\n### We agreed on the following definitions:\r\n\r\n+ **disease modifying** (`DM`) -- a drug that therapeutically changes the underlying or downstream biology of the disease\r\n+ **symptomatic** (`SYM`) -- a drug that treats a significant symptom of the disease\r\n+ **non-indication** (`NOT`) -- a drug that neither therapeutically changes the underlying or downstream biology nor treats a significant symptom of the disease\r\n\r\nWe also agreed on the following **guidelines**:\r\n\r\n+ **reasonable evidence** of efficacy is required to be classified as disease modifying or symptomatic\r\n+ if no classification accurately describes an indication, the **most appropriate** (although imperfect) classification should be chosen\r\n\r\n## Next steps\r\n\r\nAJG and CSH found many of their disagreements on the pilot indications resolved once a common definition was reached. With these definitions, we will now move onto the full set of indications, which AJG and CSH have agreed to curate.",
      "comment_id": 446,
      "profile_id": 17,
      "published": "2015-10-01T23:23:51.066177Z",
      "thread_id": 95,
      "url": "/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95#4"
    },
    {
      "body_html": "<p>Our protein interaction catalog includes data from the supplementary material of the Incomplete Interactome publication <span class=\"citation\">[<a href=\"https://doi.org/10.1126/science.1257601\" class=\"citation\" data-key=\"10.1126/science.1257601\">1</a>]</span>. Specifically, <a href=\"http://thinklab.com/discussion/creating-a-catalog-of-protein-interactions/85#9\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d85\">we incorporate</a> a subset of <code>DataS1_interactome.tsv</code>.</p>\r\n\r\n<p>The <a href=\"http://www.sciencemag.org/site/feature/contribinfo/prep/4__2014LicensetoPublish_Final_6MAR2014.pdf\">License to Publish</a> agreement for <em>Science</em>, which authors must sign, states that:</p>\r\n\r\n<blockquote><p>In consideration of publication by AAAS in one of its Science journals of the work currently titled [title] and <strong>all associated supplemental materials, data</strong>, audio and/or video files (the \"Work\") and authored by [author] (\"Author\"), the <strong>sole and exclusive, irrevocable right</strong> is hereby granted to AAAS to <strong>publish, reproduce, distribute, transmit, display, store, translate, create derivative works</strong> from and otherwise use the Work in any form, manner, format, or medium, whether now known or hereafter developed, throughout the world and in any language, for the entire duration of any such right and any renewal or extension thereof and to permit/sublicense others to do any or all of the foregoing as well.</p></blockquote>\r\n\r\n<p>I bolded the relevant phrases that lead me to believe that we require the permission of the AAAS rather than the dataset authors. <em>Science's</em> <a href=\"http://www.sciencemag.org/site/about/permissions.xhtml\">reprints and permissions page</a> suggested using the Copyright Clearance Center's Rightslink service. I made an account, but my request was not supported by Rightslink. Therefore, I emailed the AAAS Permissions Department with my special request. This is our first <a href=\"http://thinklab.com/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#12\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d107\">request to a publisher</a> regarding supplementary data. The email is below.</p>\r\n\r\n<hr>\r\n\r\n<p>Dear AAAS Permissions Department,</p>\r\n\r\n<p>I am a graduate student at UCSF, and I have been using supplementary data from <a href=\"https://doi.org/10.1126/science.1257601\">Menche et. al 2015</a> for my research. My project aims to predict new uses for existing drugs by integrating many different types of biomedical information. Recently, the issue of database copyright and licensing <a href=\"http://thinklab.com/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d107\">came up</a>, and we are now trying to ensure that we have sufficient permissions for each of the 28 databases we're integrating.</p>\r\n\r\n<p>Currently, several resources I have created may be non-compliant with your terms.</p>\r\n\r\n<p>My GitHub repository (<a href=\"https://github.com/dhimmel/ppi\"><code>dhimmel/ppi</code></a>) contains:</p>\r\n\r\n<ul><li>an <a href=\"https://github.com/dhimmel/ppi/blob/master/download/ii/Datasets_S1-S4.zip\">unmodified copy</a> of <code>Datasets_S1-S4.zip</code> download from the Additional Data section <a href=\"https://www.sciencemag.org/content/347/6224/1257601/suppl/DC1\">online</a></li><li><a href=\"https://github.com/dhimmel/ppi/tree/master/data\">reformatted versions</a> of the data from <code>DataS1_interactome.tsv</code>, a file inside <code>Datasets_S1-S4.zip</code>.</li></ul>\r\n\r\n<p>My GitHub repository (<a href=\"https://github.com/dhimmel/integrate\"><code>dhimmel/integrate</code></a>) for integrating many resources into a single network contains:</p>\r\n\r\n<ul><li>a subset of the protein interactions from the supplement stored as network nodes and edges.</li></ul>\r\n\r\n<p><a href=\"/u/leobrueggeman\" class=\"username\">@leobrueggeman</a> assisted with parts of the analysis. His GitHub repository  (<a href=\"https://github.com/LABrueggs/incomplete-interactome\"><code>LABrueggs/incomplete-interactome</code></a>) contains:</p>\r\n\r\n<ul><li>datasets of disease names derived from the supplement</li></ul>\r\n\r\n<p>The public availability of the aforementioned resources is important so others can reproduce and build off of our work. Thus, we request permission for our aforementioned redistribution and derivative works of the publication's supplemental data. Ideally, we could be granted permission to release the supplemental data under a <a href=\"https://creativecommons.org/licenses/\">Creative Commons license</a> without a No Derivatives restriction. Applying a CC license would lessen the burden on downstream users.</p>\r\n\r\n<p>Thanks for your consideration. Our research is academic in nature, and we suspect it falls under the intended use of supplemental materials but perhaps not your <a href=\"http://www.sciencemag.org/site/about/copyright.xhtml\">terms and conditions</a>.</p>\r\n\r\n<p>Finally, we're performing our project using an open science platform called Thinklab. I've <a href=\"#1\">posted a copy</a> of this email on Thinklab and will update the discussion with our progress. Alternatively, feel free to respond via Thinklab rather than email. By detailing each step of our research process publicly, we're hoping to create a valuable resource and explore a more holistic and collaborative medium of publication.</p>\r\n\r\n<p>Sincerely,<br>Daniel Himmelstein<br>Graduate Student<br>University of California, San Francisco</p>",
      "body_md": "Our protein interaction catalog includes data from the supplementary material of the Incomplete Interactome publication [@10.1126/science.1257601]. Specifically, [we incorporate](http://thinklab.com/discussion/creating-a-catalog-of-protein-interactions/85#9) a subset of `DataS1_interactome.tsv`.\r\n\r\nThe [License to Publish](http://www.sciencemag.org/site/feature/contribinfo/prep/4__2014LicensetoPublish_Final_6MAR2014.pdf) agreement for *Science*, which authors must sign, states that:\r\n\r\n> In consideration of publication by AAAS in one of its Science journals of the work currently titled [title] and **all associated supplemental materials, data**, audio and/or video files (the \"Work\") and authored by [author] (\"Author\"), the **sole and exclusive, irrevocable right** is hereby granted to AAAS to **publish, reproduce, distribute, transmit, display, store, translate, create derivative works** from and otherwise use the Work in any form, manner, format, or medium, whether now known or hereafter developed, throughout the world and in any language, for the entire duration of any such right and any renewal or extension thereof and to permit/sublicense others to do any or all of the foregoing as well.\r\n\r\nI bolded the relevant phrases that lead me to believe that we require the permission of the AAAS rather than the dataset authors. *Science's* [reprints and permissions page](http://www.sciencemag.org/site/about/permissions.xhtml) suggested using the Copyright Clearance Center's Rightslink service. I made an account, but my request was not supported by Rightslink. Therefore, I emailed the AAAS Permissions Department with my special request. This is our first [request to a publisher](http://thinklab.com/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#12) regarding supplementary data. The email is below.\r\n\r\n***\r\n\r\nDear AAAS Permissions Department,\r\n\r\nI am a graduate student at UCSF, and I have been using supplementary data from [Menche et. al 2015](https://doi.org/10.1126/science.1257601) for my research. My project aims to predict new uses for existing drugs by integrating many different types of biomedical information. Recently, the issue of database copyright and licensing [came up](http://thinklab.com/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107), and we are now trying to ensure that we have sufficient permissions for each of the 28 databases we're integrating.\r\n\r\nCurrently, several resources I have created may be non-compliant with your terms.\r\n\r\nMy GitHub repository ([`dhimmel/ppi`](https://github.com/dhimmel/ppi)) contains:\r\n\r\n+ an [unmodified copy](https://github.com/dhimmel/ppi/blob/master/download/ii/Datasets_S1-S4.zip) of `Datasets_S1-S4.zip` download from the Additional Data section [online](https://www.sciencemag.org/content/347/6224/1257601/suppl/DC1)\r\n+ [reformatted versions](https://github.com/dhimmel/ppi/tree/master/data) of the data from `DataS1_interactome.tsv`, a file inside `Datasets_S1-S4.zip`.\r\n\r\nMy GitHub repository ([`dhimmel/integrate`](https://github.com/dhimmel/integrate)) for integrating many resources into a single network contains:\r\n\r\n+ a subset of the protein interactions from the supplement stored as network nodes and edges.\r\n\r\n@leobrueggeman assisted with parts of the analysis. His GitHub repository  ([`LABrueggs/incomplete-interactome`](https://github.com/LABrueggs/incomplete-interactome)) contains:\r\n\r\n+ datasets of disease names derived from the supplement\r\n\r\nThe public availability of the aforementioned resources is important so others can reproduce and build off of our work. Thus, we request permission for our aforementioned redistribution and derivative works of the publication's supplemental data. Ideally, we could be granted permission to release the supplemental data under a [Creative Commons license](https://creativecommons.org/licenses/) without a No Derivatives restriction. Applying a CC license would lessen the burden on downstream users.\r\n\r\nThanks for your consideration. Our research is academic in nature, and we suspect it falls under the intended use of supplemental materials but perhaps not your [terms and conditions](http://www.sciencemag.org/site/about/copyright.xhtml).\r\n\r\nFinally, we're performing our project using an open science platform called Thinklab. I've [posted a copy](#1) of this email on Thinklab and will update the discussion with our progress. Alternatively, feel free to respond via Thinklab rather than email. By detailing each step of our research process publicly, we're hoping to create a valuable resource and explore a more holistic and collaborative medium of publication.\r\n\r\nSincerely,\r\nDaniel Himmelstein\r\nGraduate Student\r\nUniversity of California, San Francisco",
      "comment_id": 448,
      "profile_id": 17,
      "published": "2015-10-02T01:58:42.602421Z",
      "thread_id": 111,
      "url": "/discussion/incomplete-interactome-licensing/111"
    },
    {
      "body_html": "<h1>Preliminary feature computation</h1>\r\n\r\n<h2>Background</h2>\r\n\r\n<p>Our method for <a href=\"http://het.io/hnep\">hetnet edge prediction</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1004259\">1</a>]</span> works by quantifying the connectivity between a source and target node. For this project, source nodes are compounds and target nodes are diseases. To extract a feature from the network, we quantify the prevalence of a specific type of paths (metapath) for each compound–disease pair. We use a metric called the <a href=\"https://doi.org/10.1371/journal.pcbi.1004259#article1.body1.sec2.sec2.p1\">degree weighted path count</a> (<em>DWPC</em>) to quantify the extent that that a path of the specified type connects a compound and disease. The <em>DWPC</em> downweights paths through high degree nodes, which are less specific and therefore likely less informative. Thus each metapath yields a feature. We evaluate the predictiveness of a feature by whether it discriminates indicated from non-indicated compound–disease pairs.</p>\r\n\r\n<h2>Methods</h2>\r\n\r\n<p>We computed features for the 261 metapaths with length ≤ 3 for all <a href=\"http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#191\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d21\">1,386 indications</a> and 4,227 non-indications. The 4,227 non-indications were randomly selected from all non-indications. We computed features for 2%, rather than 100%, of non-indications to decrease computation time. This compromise allows us to quickly assess feature-specific performance via <a href=\"https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve\">AUROC</a>, but does not allow us to make comprehensive predictions or provide reliable estimates of measures that depend the balance between positives and negatives, such as <a href=\"https://en.wikipedia.org/wiki/Precision_and_recall\">AUPRC</a> and properly-scaled predicted probabilities.</p>\r\n\r\n<p>We separately assessed the performance of each of the 261 features (<a href=\"https://github.com/dhimmel/learn/blob/eabff6bdbe777cb21ad731a7b788720eb1d622f8/learn.ipynb\">notebook</a>). We used the <em>DWPC</em> with <span class=\"math\">$$w = 0.4$$</span> — the dampening exponent to control the downweighting of paths through high degree nodes. We chose <span class=\"math\">$$w = 0.4$$</span> because that was optimal in our previous study <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1004259\">1</a>]</span> and performance <a href=\"https://doi.org/10.1371/journal.pcbi.1004259.s003\">was stable</a> for surrounding parameter choices.</p>\r\n\r\n<h2>Results</h2>\r\n\r\n<p>We created a <a href=\"https://github.com/dhimmel/learn/blob/eabff6bdbe777cb21ad731a7b788720eb1d622f8/data/auc.tsv\">table of feature performance</a>. Scroll to the bottom of <a href=\"https://github.com/dhimmel/learn/blob/eabff6bdbe777cb21ad731a7b788720eb1d622f8/learn.ipynb\">this notebook</a> for the abbreviation system used in the <code>metapath</code> column. <code>nonzero</code> indicates the proportion of compound–disease pairs that had at least one path for that metapath. <code>auroc</code> represents the chance that a random indication received a higher <em>DWPC</em> than a random non-indication. Stay tuned to this discussion for further analysis.</p>\r\n\r\n<h2>Limitations</h2>\r\n\r\n<p>There are still a few steps remaining before we can draw conclusions on the mechanisms of efficacy:</p>\r\n\r\n<ul><li>Our expert curated indication catalog is not yet ready. Therefore, an <a href=\"http://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95#3\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d95\">estimated 42%</a> the 1,386 indications are symptomatic or non-indications.</li><li>We haven't yet created permuted networks to compute feature performance on. <a href=\"https://doi.org/10.1371/journal.pcbi.1004259.s003#article1.body1.sec2.sec6.p1\">Permuted networks</a> preserve degree but destroy edge specificity. Much of the current performance is likely attributable to node degree rather than edge specificity. For example, compounds that are indicated for many other diseases are more likely to be indicated for the target disease. Many of our 261 features will capture this effect.</li></ul>",
      "body_md": "# Preliminary feature computation\r\n\r\n## Background\r\n\r\nOur method for [hetnet edge prediction](http://het.io/hnep) [@10.1371/journal.pcbi.1004259] works by quantifying the connectivity between a source and target node. For this project, source nodes are compounds and target nodes are diseases. To extract a feature from the network, we quantify the prevalence of a specific type of paths (metapath) for each compound--disease pair. We use a metric called the [degree weighted path count](https://doi.org/10.1371/journal.pcbi.1004259#article1.body1.sec2.sec2.p1) (*DWPC*) to quantify the extent that that a path of the specified type connects a compound and disease. The *DWPC* downweights paths through high degree nodes, which are less specific and therefore likely less informative. Thus each metapath yields a feature. We evaluate the predictiveness of a feature by whether it discriminates indicated from non-indicated compound--disease pairs.\r\n\r\n## Methods\r\n\r\nWe computed features for the 261 metapaths with length ≤ 3 for all [1,386 indications](http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#191) and 4,227 non-indications. The 4,227 non-indications were randomly selected from all non-indications. We computed features for 2%, rather than 100%, of non-indications to decrease computation time. This compromise allows us to quickly assess feature-specific performance via [AUROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve), but does not allow us to make comprehensive predictions or provide reliable estimates of measures that depend the balance between positives and negatives, such as [AUPRC](https://en.wikipedia.org/wiki/Precision_and_recall) and properly-scaled predicted probabilities.\r\n\r\nWe separately assessed the performance of each of the 261 features ([notebook](https://github.com/dhimmel/learn/blob/eabff6bdbe777cb21ad731a7b788720eb1d622f8/learn.ipynb)). We used the *DWPC* with $$w = 0.4$$ -- the dampening exponent to control the downweighting of paths through high degree nodes. We chose $$w = 0.4$$ because that was optimal in our previous study [@10.1371/journal.pcbi.1004259] and performance [was stable](https://doi.org/10.1371/journal.pcbi.1004259.s003) for surrounding parameter choices.\r\n\r\n## Results\r\n\r\nWe created a [table of feature performance](https://github.com/dhimmel/learn/blob/eabff6bdbe777cb21ad731a7b788720eb1d622f8/data/auc.tsv). Scroll to the bottom of [this notebook](https://github.com/dhimmel/learn/blob/eabff6bdbe777cb21ad731a7b788720eb1d622f8/learn.ipynb) for the abbreviation system used in the `metapath` column. `nonzero` indicates the proportion of compound--disease pairs that had at least one path for that metapath. `auroc` represents the chance that a random indication received a higher *DWPC* than a random non-indication. Stay tuned to this discussion for further analysis.\r\n\r\n## Limitations\r\n\r\nThere are still a few steps remaining before we can draw conclusions on the mechanisms of efficacy:\r\n\r\n+ Our expert curated indication catalog is not yet ready. Therefore, an [estimated 42%](http://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95#3) the 1,386 indications are symptomatic or non-indications.\r\n+ We haven't yet created permuted networks to compute feature performance on. [Permuted networks](https://doi.org/10.1371/journal.pcbi.1004259.s003#article1.body1.sec2.sec6.p1) preserve degree but destroy edge specificity. Much of the current performance is likely attributable to node degree rather than edge specificity. For example, compounds that are indicated for many other diseases are more likely to be indicated for the target disease. Many of our 261 features will capture this effect.",
      "comment_id": 450,
      "profile_id": 17,
      "published": "2015-10-04T18:59:32.043511Z",
      "thread_id": 115,
      "url": "/discussion/assessing-the-informativeness-of-features/115"
    },
    {
      "body_html": "<p>Today is October 3, 2015. <a href=\"http://www.eventbrite.com/e/bay-area-open-access-week-event-for-generation-open-tickets-13233113599\">345 days ago</a>, I first met <a href=\"/u/jspauld\" class=\"username\">@jspauld</a> and learned of Thinklab. 330 days ago, <a href=\"/u/sergiobaranzini\" class=\"username\">@sergiobaranzini</a> and I agreed to try out the platform, and 264 days ago we posted an initial draft of our proposal.</p>\r\n\r\n<p>Since then our project <a href=\"http://slides.com/dhimmel/greene-lab-interview#/5/1\">has</a> recruited 22 reviewers and started 47 discussions containing 266 comments. Currently, our proposal has 641 views and our most highly viewed discussions have <a href=\"http://thinklab.com/discussion/python-for-the-modern-biodata-scientist/84\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d84\">175</a> and <a href=\"http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d21\">173</a> views. These view counts rely on Google Analytics and  are therefore <a href=\"https://peerj.com/blog/post/115284878007/using-big-data-tools-for-small-data-how-peerj-moved-from-google-analytics-to-emr/\">just estimates</a>.</p>\r\n\r\n<p>We are pleased with the current progress on Thinklab and expect continued growth as the platform matures. In this thread, we will also post instances of reuse, citation, and publicity received outside of Thinklab.</p>",
      "body_md": "Today is October 3, 2015. [345 days ago](http://www.eventbrite.com/e/bay-area-open-access-week-event-for-generation-open-tickets-13233113599), I first met @jspauld and learned of Thinklab. 330 days ago, @sergiobaranzini and I agreed to try out the platform, and 264 days ago we posted an initial draft of our proposal.\r\n\r\nSince then our project [has](http://slides.com/dhimmel/greene-lab-interview#/5/1) recruited 22 reviewers and started 47 discussions containing 266 comments. Currently, our proposal has 641 views and our most highly viewed discussions have [175](http://thinklab.com/discussion/python-for-the-modern-biodata-scientist/84) and [173](http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21) views. These view counts rely on Google Analytics and  are therefore [just estimates](https://peerj.com/blog/post/115284878007/using-big-data-tools-for-small-data-how-peerj-moved-from-google-analytics-to-emr/).\r\n\r\nWe are pleased with the current progress on Thinklab and expect continued growth as the platform matures. In this thread, we will also post instances of reuse, citation, and publicity received outside of Thinklab.",
      "comment_id": 451,
      "profile_id": 17,
      "published": "2015-10-03T20:51:26.605713Z",
      "thread_id": 113,
      "url": "/discussion/tracking-project-reuse-citation-and-publicity/113"
    },
    {
      "body_html": "<h1>Initial network release covered by the <em>Drug Repurposing Portal</em></h1>\r\n\r\n<p>On August 6th 2015, the <a href=\"http://thinklab.com/discussion/one-network-to-rule-them-all/102#1\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d102\">initial release</a> <span class=\"citation\">[<a href=\"https://doi.org/10.5281/zenodo.28040\" class=\"citation\" data-key=\"10.5281/zenodo.28040\">1</a>]</span> of our network was <a href=\"http://drugrepurposingportal.com/drug-repurposing-news.php?query=Himmelstein\">covered</a> by the <em>Drug Repurposing Portal</em>. This site <a href=\"http://drugrepurposingportal.com/\">describes</a> itself as a</p>\r\n\r\n<blockquote><p>first of its kind one-stop-shop platform for intelligent information on Drug Repurposing</p></blockquote>\r\n\r\n<p>The site also includes a <a href=\"http://drugrepurposingportal.com/repurposed-drug-database.php\">database</a> of over 300 instances of repurposing. While the database is unstructured text (so currently unsuitable for computational analyses), it provides a nice human-readable reference.</p>",
      "body_md": "# Initial network release covered by the *Drug Repurposing Portal*\r\n\r\nOn August 6th 2015, the [initial release](http://thinklab.com/discussion/one-network-to-rule-them-all/102#1) [@10.5281/zenodo.28040] of our network was [covered](http://drugrepurposingportal.com/drug-repurposing-news.php?query=Himmelstein) by the *Drug Repurposing Portal*. This site [describes](http://drugrepurposingportal.com/) itself as a\r\n\r\n> first of its kind one-stop-shop platform for intelligent information on Drug Repurposing\r\n\r\nThe site also includes a [database](http://drugrepurposingportal.com/repurposed-drug-database.php) of over 300 instances of repurposing. While the database is unstructured text (so currently unsuitable for computational analyses), it provides a nice human-readable reference.",
      "comment_id": 452,
      "profile_id": 17,
      "published": "2015-10-03T21:12:10.146650Z",
      "thread_id": 113,
      "url": "/discussion/tracking-project-reuse-citation-and-publicity/113#2"
    },
    {
      "body_html": "<h1>Protein-coding Entrez Genes with duplicate symbols</h1>\r\n\r\n<p>After <a href=\"#9\">restricting</a> to <em>Homo sapiens</em>, we found four protein-coding genes with duplicate symbols:</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>tax_id</th><th>GeneID</th><th>Symbol</th><th>chromosome</th><th>map_location</th><th>type_of_gene</th><th>description</th></tr></thead><tbody><tr><td>9606</td><td><a href=\"http://www.ncbi.nlm.nih.gov/gene/?term=266553\">266553</a></td><td>OFCC1</td><td>6</td><td>6p24.3</td><td>protein-coding</td><td>orofacial cleft 1 candidate 1</td></tr><tr><td>9606</td><td><a href=\"http://www.ncbi.nlm.nih.gov/gene/?term=105369145\">105369145</a></td><td>OFCC1</td><td>6</td><td></td><td>protein-coding</td><td>orofacial cleft 1 candidate 1</td></tr><tr><td>9606</td><td><a href=\"http://www.ncbi.nlm.nih.gov/gene/?term=2867\">2867</a></td><td>FFAR2</td><td>19</td><td>19q13.1</td><td>protein-coding</td><td>free fatty acid receptor 2</td></tr><tr><td>9606</td><td><a href=\"http://www.ncbi.nlm.nih.gov/gene/?term=105372382\">105372382</a></td><td>FFAR2</td><td>19</td><td></td><td>protein-coding</td><td>free fatty acid receptor 2</td></tr></tbody></table>\r\n\r\n<p>We will reach out to Entrez Gene to inquire about this unexpected occurrence.</p>",
      "body_md": "# Protein-coding Entrez Genes with duplicate symbols\r\n\r\nAfter [restricting](#9) to *Homo sapiens*, we found four protein-coding genes with duplicate symbols:\r\n\r\n| tax_id | GeneID | Symbol | chromosome | map_location | type_of_gene | description |\r\n|--------|-----------|--------|------------|--------------|----------------|-------------------------------|\r\n| 9606 | [266553](http://www.ncbi.nlm.nih.gov/gene/?term=266553) | OFCC1 | 6 | 6p24.3 | protein-coding | orofacial cleft 1 candidate 1 |\r\n| 9606 | [105369145](http://www.ncbi.nlm.nih.gov/gene/?term=105369145) | OFCC1 | 6 |  | protein-coding | orofacial cleft 1 candidate 1 |\r\n| 9606 | [2867](http://www.ncbi.nlm.nih.gov/gene/?term=2867) | FFAR2 | 19 | 19q13.1 | protein-coding | free fatty acid receptor 2 |\r\n| 9606 | [105372382](http://www.ncbi.nlm.nih.gov/gene/?term=105372382) | FFAR2 | 19 |  | protein-coding | free fatty acid receptor 2 |\r\n\r\nWe will reach out to Entrez Gene to inquire about this unexpected occurrence.",
      "comment_id": 453,
      "profile_id": 17,
      "published": "2015-10-04T00:25:02.158277Z",
      "thread_id": 34,
      "url": "/discussion/using-entrez-gene-as-our-gene-vocabulary/34#10"
    },
    {
      "body_html": "<h1>Project Altmetrics</h1>\r\n\r\n<p>Our project has an <a href=\"https://www.altmetric.com/details/4273971\">Altmetric page</a>, which tracks online attention. Currently, some of the project metadata is wrong, and most mentioning content is missing. <a href=\"/u/jspauld\" class=\"username\">@jspauld</a>, perhaps you could investigate improving Altmetric integration?</p>",
      "body_md": "# Project Altmetrics\r\n\r\nOur project has an [Altmetric page](https://www.altmetric.com/details/4273971), which tracks online attention. Currently, some of the project metadata is wrong, and most mentioning content is missing. @jspauld, perhaps you could investigate improving Altmetric integration?",
      "comment_id": 454,
      "profile_id": 17,
      "published": "2015-10-04T02:49:12.228632Z",
      "thread_id": 113,
      "url": "/discussion/tracking-project-reuse-citation-and-publicity/113#3"
    },
    {
      "body_html": "<h1>Exporting hetio hetnets to neo4j</h1>\r\n\r\n<p>We've <a href=\"https://github.com/dhimmel/hetio/commit/1860faadb455c1f20546ce7923b5b78fd74796b3\">added</a> neo4j export capability to hetio. Our implementation uses the <a href=\"http://py2neo.org/2.0/\">py2neo</a> toolkit to interact with the neo4j server. </p>\r\n\r\n<p>Adding edges is quite slow and the database size is large. However, the neo4j browser combined with cypher is great for exploratory analyses. In a short amount of time, I discovered 4 issues with our network (<a href=\"https://github.com/dhimmel/integrate/issues/4\">1</a>, <a href=\"https://github.com/dhimmel/integrate/issues/5\">2</a>, <a href=\"https://github.com/dhimmel/integrate/issues/6\">3</a>, <a href=\"https://github.com/dhimmel/integrate/issues/7\">4</a>) and created a <a href=\"https://twitter.com/dhimmel/status/650558967492444160\">sneak-preview visualization</a>.</p>",
      "body_md": "# Exporting hetio hetnets to neo4j\r\n\r\nWe've [added](https://github.com/dhimmel/hetio/commit/1860faadb455c1f20546ce7923b5b78fd74796b3) neo4j export capability to hetio. Our implementation uses the [py2neo](http://py2neo.org/2.0/) toolkit to interact with the neo4j server. \r\n\r\nAdding edges is quite slow and the database size is large. However, the neo4j browser combined with cypher is great for exploratory analyses. In a short amount of time, I discovered 4 issues with our network ([1](https://github.com/dhimmel/integrate/issues/4), [2](https://github.com/dhimmel/integrate/issues/5), [3](https://github.com/dhimmel/integrate/issues/6), [4](https://github.com/dhimmel/integrate/issues/7)) and created a [sneak-preview visualization](https://twitter.com/dhimmel/status/650558967492444160).",
      "comment_id": 455,
      "profile_id": 17,
      "published": "2015-10-04T06:50:05.515658Z",
      "thread_id": 112,
      "url": "/discussion/using-the-neo4j-graph-database-for-hetnets/112#2"
    },
    {
      "body_html": "<h1>Version 1.0</h1>\r\n\r\n<p>Our compilation of pathway gene sets is now <a href=\"https://github.com/dhimmel/pathways/tree/1dc7c744d0d1a8fa17a079f739195e6d3c15117e\">released</a> (version 1.0) <span class=\"citation\">[<a href=\"https://doi.org/10.5281/zenodo.31834\" class=\"citation\" data-key=\"10.5281/zenodo.31834\">1</a>]</span>. Gene sets (<a href=\"https://github.com/dhimmel/pathways/blob/1dc7c744d0d1a8fa17a079f739195e6d3c15117e/data/pathways.tsv\">download</a>) are compiled from WikiPathways and MSigDB. This updated version contains 1,617 pathways.</p>",
      "body_md": "# Version 1.0\r\n\r\nOur compilation of pathway gene sets is now [released](https://github.com/dhimmel/pathways/tree/1dc7c744d0d1a8fa17a079f739195e6d3c15117e) (version 1.0) [@10.5281/zenodo.31834]. Gene sets ([download](https://github.com/dhimmel/pathways/blob/1dc7c744d0d1a8fa17a079f739195e6d3c15117e/data/pathways.tsv)) are compiled from WikiPathways and MSigDB. This updated version contains 1,617 pathways.",
      "comment_id": 457,
      "profile_id": 17,
      "published": "2015-10-06T18:45:14.620139Z",
      "thread_id": 72,
      "url": "/discussion/adding-pathway-resources-to-your-network/72#10"
    },
    {
      "body_html": "<h1>Resolution of Entrez Genes with duplicate symbols</h1>\r\n\r\n<p>Mike Murphy — RefSeq Curator at NCBI\\NLM\\NIH — responded to our inquiry regarding the <a href=\"#10\">duplicate symbols</a>. With permission, we've copied his response below:</p>\r\n\r\n<blockquote><p>Thank you for your notification of two cases where the same symbol is used to represent different human GeneIDs. In each case, one of the symbols is \"official\" (as determined by the Human Gene Nomenclature Committee) and the other is \"unofficial\". We consistently use official nomenclature for the gene feature, when available. Unfortunately, situations do arise where the same symbol is used in an official and unofficial capacity on different loci. It is our general policy to retain shared symbols and names on different loci for query and retrieval purposes by various users of our database. However, in both of the cases you pointed out, the two genes with the same symbol really represent the same gene. Therefore, I merged GeneID 105369145 into GeneID 266553, and I merged GeneID 105372382 into GeneID 2867. These updates should be publicly visible within a couple of days.</p></blockquote>",
      "body_md": "# Resolution of Entrez Genes with duplicate symbols\r\n\r\nMike Murphy -- RefSeq Curator at NCBI\\NLM\\NIH -- responded to our inquiry regarding the [duplicate symbols](#10). With permission, we've copied his response below:\r\n\r\n> Thank you for your notification of two cases where the same symbol is used to represent different human GeneIDs. In each case, one of the symbols is \"official\" (as determined by the Human Gene Nomenclature Committee) and the other is \"unofficial\". We consistently use official nomenclature for the gene feature, when available. Unfortunately, situations do arise where the same symbol is used in an official and unofficial capacity on different loci. It is our general policy to retain shared symbols and names on different loci for query and retrieval purposes by various users of our database. However, in both of the cases you pointed out, the two genes with the same symbol really represent the same gene. Therefore, I merged GeneID 105369145 into GeneID 266553, and I merged GeneID 105372382 into GeneID 2867. These updates should be publicly visible within a couple of days.\r\n",
      "comment_id": 458,
      "profile_id": 17,
      "published": "2015-10-05T21:32:26.910271Z",
      "thread_id": 34,
      "url": "/discussion/using-entrez-gene-as-our-gene-vocabulary/34#11"
    },
    {
      "body_html": "<p>We <a href=\"https://github.com/dhimmel/integrate/blob/8d93f5409a5fba85ee1109b470bbf2bb2b1a67e6/neo4j.ipynb\">exported</a> the <a href=\"https://github.com/dhimmel/integrate/tree/8d93f5409a5fba85ee1109b470bbf2bb2b1a67e6\">current version</a> of our network, which contains 49,399 nodes and 2,997,246 edges, to neo4j. The export took 10 hours and resulted in a 3.04 GB database.</p>\r\n\r\n<p>The <code>data/graph.db/</code>, which stores the database, contained the following files with sizes over 1 MB:</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>file</th><th>size</th></tr></thead><tbody><tr><td><code>messages.log</code></td><td>1.3 GB</td></tr><tr><td><code>data/graph.db/neostore.transaction.db.1</code></td><td>262 MB</td></tr><tr><td><code>data/graph.db/neostore.transaction.db.2</code></td><td>262 MB</td></tr><tr><td><code>data/graph.db/neostore.transaction.db.3</code></td><td>262 MB</td></tr><tr><td><code>data/graph.db/neostore.transaction.db.4</code></td><td>262 MB</td></tr><tr><td><code>data/graph.db/neostore.transaction.db.5</code></td><td>262 MB</td></tr><tr><td><code>data/graph.db/neostore.transaction.db.6</code></td><td>262 MB</td></tr><tr><td><code>data/graph.db/neostore.transaction.db.7</code></td><td>113 MB</td></tr><tr><td><code>neostore.propertystore.db</code></td><td>127.9 MB</td></tr><tr><td><code>neostore.relationshipstore.db</code></td><td>102 MB</td></tr><tr><td><code>neostore.propertystore.db.strings</code></td><td>25 MB</td></tr><tr><td><code>neostore.relationshipgroupstore.db</code></td><td>3.2 MB</td></tr><tr><td><code>rrd</code></td><td>2.0 MB</td></tr><tr><td><code>neostore.propertystore.db.arrays</code></td><td>1.5 MB</td></tr><tr><td><code>neostore.nodestore.db</code></td><td>1.5 MB</td></tr></tbody></table>\r\n\r\n<p>We will look into ways to speed up our write times and reduce storage.</p>",
      "body_md": "We [exported](https://github.com/dhimmel/integrate/blob/8d93f5409a5fba85ee1109b470bbf2bb2b1a67e6/neo4j.ipynb) the [current version](https://github.com/dhimmel/integrate/tree/8d93f5409a5fba85ee1109b470bbf2bb2b1a67e6) of our network, which contains 49,399 nodes and 2,997,246 edges, to neo4j. The export took 10 hours and resulted in a 3.04 GB database.\r\n\r\nThe `data/graph.db/`, which stores the database, contained the following files with sizes over 1 MB:\r\n\r\n| file | size |\r\n|-------------------------------------------|----------|\r\n| `messages.log` | 1.3 GB |\r\n| `data/graph.db/neostore.transaction.db.1` | 262 MB |\r\n| `data/graph.db/neostore.transaction.db.2` | 262 MB |\r\n| `data/graph.db/neostore.transaction.db.3` | 262 MB |\r\n| `data/graph.db/neostore.transaction.db.4` | 262 MB |\r\n| `data/graph.db/neostore.transaction.db.5` | 262 MB |\r\n| `data/graph.db/neostore.transaction.db.6` | 262 MB |\r\n| `data/graph.db/neostore.transaction.db.7` | 113 MB |\r\n| `neostore.propertystore.db` | 127.9 MB |\r\n| `neostore.relationshipstore.db` | 102 MB |\r\n| `neostore.propertystore.db.strings` | 25 MB |\r\n| `neostore.relationshipgroupstore.db` | 3.2 MB |\r\n| `rrd` | 2.0 MB |\r\n| `neostore.propertystore.db.arrays` | 1.5 MB |\r\n| `neostore.nodestore.db` | 1.5 MB |\r\n\r\nWe will look into ways to speed up our write times and reduce storage.",
      "comment_id": 460,
      "profile_id": 17,
      "published": "2015-10-06T16:18:22.407699Z",
      "thread_id": 112,
      "url": "/discussion/using-the-neo4j-graph-database-for-hetnets/112#3"
    },
    {
      "body_html": "<p>Can you add into the <a href=\"https://github.com/dhimmel/integrate/blob/0e343d8745a98757c86e73f645b41353f52b82b5/licenses/README.md\">table</a> the corporate or institutional affiliation of the project and the funding agency to each of the data sources?</p>",
      "body_md": "Can you add into the [table] (https://github.com/dhimmel/integrate/blob/0e343d8745a98757c86e73f645b41353f52b82b5/licenses/README.md) the corporate or institutional affiliation of the project and the funding agency to each of the data sources?",
      "comment_id": 462,
      "profile_id": 79,
      "published": "2015-10-08T19:04:14.999349Z",
      "thread_id": 107,
      "url": "/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#13"
    },
    {
      "body_html": "<h1>General assessment</h1>\r\n\r\n<p>We assessed general performance trends on our <a href=\"#1\">preliminary</a> set of 261 features (<a href=\"http://nbviewer.ipython.org/github/dhimmel/learn/blob/ed022ecd93f0599887a359486f3e8849ecda1a03/feature-assess.ipynb\">interactive notebook</a>). We discuss the findings below:</p>\r\n\r\n<p>All <a href=\"https://github.com/dhimmel/learn/blob/ed022ecd93f0599887a359486f3e8849ecda1a03/data/auc.tsv\">features</a> yielded AUROCs ≥ 0.5. In other words, no features were negatively associated with indication status: greater path prevalence between a compound and disease never resulted in a lower therapeutic likelihood. The lack of negatively associated features is unsurprising given that our network is primarily composed of general relationships. For example, we have a compound–gene edge for <a href=\"https://en.wikipedia.org/wiki/Biological_target#Drug_targets\">targeting</a> but not for <a href=\"https://en.wikipedia.org/wiki/Agonist\">agonism</a> or <a href=\"https://en.wikipedia.org/wiki/Receptor_antagonist\">antagonism</a>.</p>\r\n\r\n<p>The majority of features had AUROC ≤ 0.53. In other words, most features performed only slightly better than random. However, a quarter of the features had AUROC ≥ 0.60, and five features had AUROC ≥ 0.80. The strong performance of a subset of features is encouraging.</p>\r\n\r\n<p>We <a href=\"http://nbviewer.ipython.org/github/dhimmel/learn/blob/ed022ecd93f0599887a359486f3e8849ecda1a03/feature-assess.ipynb#Performance-by-path-length\">did not observe</a> major differences in the distributions of AUROCs for features with length 2 versus length 3 metapaths. However, since there are many more metapaths with length 3 than 2, the top performing features were mostly of length 3.</p>\r\n\r\n<p>Performance <a href=\"http://nbviewer.ipython.org/github/dhimmel/learn/blob/ed022ecd93f0599887a359486f3e8849ecda1a03/feature-assess.ipynb#Feature-AUROC-versus-non-zero-fraction\">strongly correlated</a> with the fraction of nonzero values per feature. Metapaths traversing sparsely connected areas of the hetnet performed poorly because they yielded <span class=\"math\">$$DWPC = 0$$</span> for almost all compound–disease pairs.</p>\r\n\r\n<p>AUROC and AUPRC <a href=\"http://nbviewer.ipython.org/github/dhimmel/learn/blob/ed022ecd93f0599887a359486f3e8849ecda1a03/feature-assess.ipynb#Feature-AUPRC-versus-AUROC\">were</a> positively correlated. However, features with AUROCs near 0.5 (the random expectation) often had AUPRCs considerably above 0.25 (the random expectation). These features were often &gt; 99% zero. Therefore, we suspect the low-AUROC features produced decent top predictions but poor comprehensive predictions due to sparsity, leading to discordance between AUROCs and AUPRCs <span class=\"citation\">[<a href=\"https://doi.org/10.1145/1143844.1143874\" class=\"citation\" data-key=\"10.1145/1143844.1143874\">1</a>, <a href=\"https://doi.org/10.1371/journal.pone.0009202\" class=\"citation\" data-key=\"10.1371/journal.pone.0009202\">2</a>]</span>.</p>\r\n\r\n<p>One reason we primarily rely on AUROC rather than AUPRC is to enable comparisons across different prevalences. We may consider using the AUCROC (area under the condensed ROC  <span class=\"citation\">[<a href=\"https://doi.org/10.1093/bioinformatics/btq140\" class=\"citation\" data-key=\"10.1093/bioinformatics/btq140\">3</a>]</span>) to emphasize top predictions while remaining balance-agnostic.</p>",
      "body_md": "# General assessment\r\n\r\nWe assessed general performance trends on our [preliminary](#1) set of 261 features ([interactive notebook](http://nbviewer.ipython.org/github/dhimmel/learn/blob/ed022ecd93f0599887a359486f3e8849ecda1a03/feature-assess.ipynb)). We discuss the findings below:\r\n\r\nAll [features](https://github.com/dhimmel/learn/blob/ed022ecd93f0599887a359486f3e8849ecda1a03/data/auc.tsv) yielded AUROCs ≥ 0.5. In other words, no features were negatively associated with indication status: greater path prevalence between a compound and disease never resulted in a lower therapeutic likelihood. The lack of negatively associated features is unsurprising given that our network is primarily composed of general relationships. For example, we have a compound--gene edge for [targeting](https://en.wikipedia.org/wiki/Biological_target#Drug_targets) but not for [agonism](https://en.wikipedia.org/wiki/Agonist) or [antagonism](https://en.wikipedia.org/wiki/Receptor_antagonist).\r\n\r\nThe majority of features had AUROC ≤ 0.53. In other words, most features performed only slightly better than random. However, a quarter of the features had AUROC ≥ 0.60, and five features had AUROC ≥ 0.80. The strong performance of a subset of features is encouraging.\r\n\r\nWe [did not observe](http://nbviewer.ipython.org/github/dhimmel/learn/blob/ed022ecd93f0599887a359486f3e8849ecda1a03/feature-assess.ipynb#Performance-by-path-length) major differences in the distributions of AUROCs for features with length 2 versus length 3 metapaths. However, since there are many more metapaths with length 3 than 2, the top performing features were mostly of length 3.\r\n\r\nPerformance [strongly correlated](http://nbviewer.ipython.org/github/dhimmel/learn/blob/ed022ecd93f0599887a359486f3e8849ecda1a03/feature-assess.ipynb#Feature-AUROC-versus-non-zero-fraction) with the fraction of nonzero values per feature. Metapaths traversing sparsely connected areas of the hetnet performed poorly because they yielded $$DWPC = 0$$ for almost all compound--disease pairs.\r\n\r\nAUROC and AUPRC [were](http://nbviewer.ipython.org/github/dhimmel/learn/blob/ed022ecd93f0599887a359486f3e8849ecda1a03/feature-assess.ipynb#Feature-AUPRC-versus-AUROC) positively correlated. However, features with AUROCs near 0.5 (the random expectation) often had AUPRCs considerably above 0.25 (the random expectation). These features were often > 99% zero. Therefore, we suspect the low-AUROC features produced decent top predictions but poor comprehensive predictions due to sparsity, leading to discordance between AUROCs and AUPRCs [@10.1145/1143844.1143874 @10.1371/journal.pone.0009202].\r\n\r\nOne reason we primarily rely on AUROC rather than AUPRC is to enable comparisons across different prevalences. We may consider using the AUCROC (area under the condensed ROC  [@10.1093/bioinformatics/btq140]) to emphasize top predictions while remaining balance-agnostic.",
      "comment_id": 476,
      "profile_id": 17,
      "published": "2015-10-10T23:28:06.090764Z",
      "thread_id": 115,
      "url": "/discussion/assessing-the-informativeness-of-features/115#2"
    },
    {
      "body_html": "<p>On October 14, Aravind Subramanian, a member of the LINCS team at the Broad, replied to our email. He wrote (posted here with permission):</p>\r\n\r\n<blockquote><p>You are free to redistribute your re-processing of the Broad LINCS data. We are working on a manuscript describing L1000 and the dataset.</p></blockquote>\r\n\r\n<p>And continued:</p>\r\n\r\n<blockquote><p>But if you believe your work would be valuable, we don't want our publication needs to hold up access for the field, so kindly proceed as you see fit</p></blockquote>\r\n\r\n<p>Aravind took the position that there is no formal license from the Broad Institute and that the LINCS L1000 licensing is determined by the NIH — the Broad and L1000 team do not apply any additional restrictions. While the <a href=\"https://github.com/dhimmel/integrate/blob/3633a6db23996f58ea1d75ada5537b53bb99597c/licenses/custom/L1000.md\">original</a> license from <a href=\"http://www.lincscloud.org/license/\">www.lincscloud.org/license/</a> suggested otherwise, the following update was <a href=\"https://github.com/dhimmel/integrate/blob/7459896115b477301af83310de667ffeeca61f66/licenses/custom/L1000.md\">added</a>: </p>\r\n\r\n<blockquote><p><strong>Update - October 14, 2015</strong></p><p>All LINCS Production Phase L1000 data generated by the Broad Institute is posted at the NCBIs Gene Expression Omnibus (GEO). Standard NIH data access rules apply - data is freely accessible by anyone (GEO BioProject ID PRJNA290347)</p><p>The website lincscloud.org, a Broad Institute developed resource for analysis of LINCS Phase 1 (2011-2014) data, will be deprecated in 2015 as the NIH has recently funded a separate LINCS Data Coordination and Integration Center (DCIC).</p><p>Our historic license is given below for reference, but the official information on access to all LINCS resources via the DCIC is available at lincsproject.org.</p></blockquote>\r\n\r\n<p>The update specifies that LINCS data will be deposited in <a href=\"http://www.ncbi.nlm.nih.gov/geo/\">GEO</a>. However, GEO availability does not grant usage rights <a href=\"https://github.com/dhimmel/integrate/blob/3b16651051ae12129ddc2250e8d3e6d4050dd349/licenses/custom/GEO.md\">since</a>,</p>\r\n\r\n<blockquote><p>some submitters may claim patent, copyright, or other intellectual property rights in all or a portion of the data they have submitted.</p></blockquote>\r\n\r\n<p>The update further specifies that the DCIC is the authoritative source for LINCS licensing. Their data release policy <a href=\"https://github.com/dhimmel/integrate/blob/3b16651051ae12129ddc2250e8d3e6d4050dd349/licenses/custom/LINCS.md\">states</a>:</p>\r\n\r\n<blockquote><p>LINCS data are released with the sole restriction that they must be correctly cited so that others can establish provenance and access the original data</p></blockquote>\r\n\r\n<h2>Conclusion</h2>\r\n\r\n<p>We have permission to distribute our L1000 datasets. The formal LINCS data policy, which covers the L1000 project, requires attribution. Therefore, we will release our LINCS datasets as <a href=\"https://creativecommons.org/licenses/by/4.0/\">CC-BY</a>.</p>\r\n\r\n<p>The LINCS project and the <a href=\"http://www.lincscloud.org/team/\">L1000 team</a> especially have done a laudable job sharing their data and providing support. Clearly and explicitly specifying the license of all public datasets will help remove any uncertainty and avoid laborious permission requests.</p>",
      "body_md": "On October 14, Aravind Subramanian, a member of the LINCS team at the Broad, replied to our email. He wrote (posted here with permission):\r\n\r\n> You are free to redistribute your re-processing of the Broad LINCS data. We are working on a manuscript describing L1000 and the dataset.\r\n\r\nAnd continued:\r\n\r\n> But if you believe your work would be valuable, we don't want our publication needs to hold up access for the field, so kindly proceed as you see fit\r\n\r\nAravind took the position that there is no formal license from the Broad Institute and that the LINCS L1000 licensing is determined by the NIH --- the Broad and L1000 team do not apply any additional restrictions. While the [original](https://github.com/dhimmel/integrate/blob/3633a6db23996f58ea1d75ada5537b53bb99597c/licenses/custom/L1000.md) license from www.lincscloud.org/license/ suggested otherwise, the following update was [added](https://github.com/dhimmel/integrate/blob/7459896115b477301af83310de667ffeeca61f66/licenses/custom/L1000.md): \r\n\r\n> **Update - October 14, 2015**\r\n\r\n> All LINCS Production Phase L1000 data generated by the Broad Institute is posted at the NCBIs Gene Expression Omnibus (GEO). Standard NIH data access rules apply - data is freely accessible by anyone (GEO BioProject ID PRJNA290347)\r\n\r\n> The website lincscloud.org, a Broad Institute developed resource for analysis of LINCS Phase 1 (2011-2014) data, will be deprecated in 2015 as the NIH has recently funded a separate LINCS Data Coordination and Integration Center (DCIC).\r\n\r\n> Our historic license is given below for reference, but the official information on access to all LINCS resources via the DCIC is available at lincsproject.org.\r\n\r\nThe update specifies that LINCS data will be deposited in [GEO](http://www.ncbi.nlm.nih.gov/geo/). However, GEO availability does not grant usage rights [since](https://github.com/dhimmel/integrate/blob/3b16651051ae12129ddc2250e8d3e6d4050dd349/licenses/custom/GEO.md),\r\n\r\n> some submitters may claim patent, copyright, or other intellectual property rights in all or a portion of the data they have submitted.\r\n\r\nThe update further specifies that the DCIC is the authoritative source for LINCS licensing. Their data release policy [states](https://github.com/dhimmel/integrate/blob/3b16651051ae12129ddc2250e8d3e6d4050dd349/licenses/custom/LINCS.md):\r\n\r\n> LINCS data are released with the sole restriction that they must be correctly cited so that others can establish provenance and access the original data\r\n\r\n## Conclusion\r\n\r\nWe have permission to distribute our L1000 datasets. The formal LINCS data policy, which covers the L1000 project, requires attribution. Therefore, we will release our LINCS datasets as [CC-BY](https://creativecommons.org/licenses/by/4.0/).\r\n\r\nThe LINCS project and the [L1000 team](http://www.lincscloud.org/team/) especially have done a laudable job sharing their data and providing support. Clearly and explicitly specifying the license of all public datasets will help remove any uncertainty and avoid laborious permission requests.",
      "comment_id": 480,
      "profile_id": 17,
      "published": "2015-10-19T23:10:30.482600Z",
      "thread_id": 110,
      "url": "/discussion/lincs-l1000-licensing/110#2"
    },
    {
      "body_html": "<h1><em>DWPC</em> in Cypher</h1>\r\n\r\n<p>We've <a href=\"https://github.com/dhimmel/hetio/blob/3150399c8d2570c2c6c93f1e3866d6b7c6bac2f3/hetio/neo4j.py#L135\">implemented</a> the degree-weighted path count (<em>DWPC</em> <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1004259\">1</a>]</span>) in <a href=\"http://neo4j.com/developer/cypher-query-language/\">Cypher</a>. Our implementation produces a different query for each metapath, but specifies the source node (<code>source</code>), target node (<code>target</code>), and damping exponent (<code>w</code>) as <a href=\"http://neo4j.com/docs/2.2.6/cypher-parameters.html\">parameters</a>.</p>\r\n\r\n<p>Below is the query for the <em>CsCuGod&gt;GuD</em> metapath:</p>\r\n\r\n<pre><code class=\"no-highlight hljs\">MATCH p = (n0:Compound)-[:SIMILARITY]-(n1:Compound)-[:UPREGULATION]-(n2:Gene)-[:OVEREXPRESSION_DOWNREGULATION]-&gt;(n3:Gene)-[:UPREGULATION]-(n4:Disease)\r\nWHERE n0.name = { source }\r\nAND n4.name = { target }\r\nWITH [size((n0)-[:SIMILARITY]-(:Compound)),\r\nsize((:Compound)-[:SIMILARITY]-(n1)),\r\nsize((n1)-[:UPREGULATION]-(:Gene)),\r\nsize((:Compound)-[:UPREGULATION]-(n2)),\r\nsize((n2)-[:OVEREXPRESSION_DOWNREGULATION]-&gt;(:Gene)),\r\nsize((:Gene)-[:OVEREXPRESSION_DOWNREGULATION]-&gt;(n3)),\r\nsize((n3)-[:UPREGULATION]-(:Disease)),\r\nsize((:Gene)-[:UPREGULATION]-(n4))] AS degrees\r\nRETURN sum(reduce(pdp = 1.0, d in degrees| pdp * d ^ -{ w }))</code></pre>\r\n\r\n<p>The <em>DWPC</em> for this metapath measures the extent that compounds similar to the query compound upregulate genes whose overpression downregulates genes upregulated by the query disease. The <code>MATCH</code> clause identifies paths corresponding to the metapath. The <code>WITH</code> clause computes degrees along each path and the <code>RETURN</code> clause computes path degree products (<em>PDPs</em>) and sums them to get the <em>DWPC</em>.</p>\r\n\r\n<h2>Comparison to hetio</h2>\r\n\r\n<p>We configure our hetio queries to exclude paths with duplicate nodes. However, neo4j <a href=\"http://neo4j.com/docs/2.2.6/cypherdoc-uniqueness.html\">excludes</a> duplicate relationships. Additionally, when computing features for an indicated compound–disease pair, we configure our hetio queries to ignore that indication. Our current cypher framework does not support this exclusion.</p>\r\n\r\n<p>Our preliminary experience is that <em>DWPC</em> computations in neo4j run approximately twice as quickly as <a href=\"https://github.com/dhimmel/hetio/blob/3150399c8d2570c2c6c93f1e3866d6b7c6bac2f3/hetio/pathtools.py\">in hetio</a>. However, hetio may have more room for improvement, since we haven't implemented path caching yet.</p>",
      "body_md": "# *DWPC* in Cypher\r\n\r\nWe've [implemented](https://github.com/dhimmel/hetio/blob/3150399c8d2570c2c6c93f1e3866d6b7c6bac2f3/hetio/neo4j.py#L135) the degree-weighted path count (*DWPC* [@10.1371/journal.pcbi.1004259]) in [Cypher](http://neo4j.com/developer/cypher-query-language/). Our implementation produces a different query for each metapath, but specifies the source node (`source`), target node (`target`), and damping exponent (`w`) as [parameters](http://neo4j.com/docs/2.2.6/cypher-parameters.html).\r\n\r\nBelow is the query for the *CsCuGod>GuD* metapath:\r\n\r\n```cypher\r\nMATCH p = (n0:Compound)-[:SIMILARITY]-(n1:Compound)-[:UPREGULATION]-(n2:Gene)-[:OVEREXPRESSION_DOWNREGULATION]->(n3:Gene)-[:UPREGULATION]-(n4:Disease)\r\nWHERE n0.name = { source }\r\nAND n4.name = { target }\r\nWITH [size((n0)-[:SIMILARITY]-(:Compound)),\r\nsize((:Compound)-[:SIMILARITY]-(n1)),\r\nsize((n1)-[:UPREGULATION]-(:Gene)),\r\nsize((:Compound)-[:UPREGULATION]-(n2)),\r\nsize((n2)-[:OVEREXPRESSION_DOWNREGULATION]->(:Gene)),\r\nsize((:Gene)-[:OVEREXPRESSION_DOWNREGULATION]->(n3)),\r\nsize((n3)-[:UPREGULATION]-(:Disease)),\r\nsize((:Gene)-[:UPREGULATION]-(n4))] AS degrees\r\nRETURN sum(reduce(pdp = 1.0, d in degrees| pdp * d ^ -{ w }))        \r\n```\r\n\r\nThe *DWPC* for this metapath measures the extent that compounds similar to the query compound upregulate genes whose overpression downregulates genes upregulated by the query disease. The `MATCH` clause identifies paths corresponding to the metapath. The `WITH` clause computes degrees along each path and the `RETURN` clause computes path degree products (*PDPs*) and sums them to get the *DWPC*.\r\n\r\n## Comparison to hetio\r\n\r\nWe configure our hetio queries to exclude paths with duplicate nodes. However, neo4j [excludes](http://neo4j.com/docs/2.2.6/cypherdoc-uniqueness.html) duplicate relationships. Additionally, when computing features for an indicated compound--disease pair, we configure our hetio queries to ignore that indication. Our current cypher framework does not support this exclusion.\r\n\r\nOur preliminary experience is that *DWPC* computations in neo4j run approximately twice as quickly as [in hetio](https://github.com/dhimmel/hetio/blob/3150399c8d2570c2c6c93f1e3866d6b7c6bac2f3/hetio/pathtools.py). However, hetio may have more room for improvement, since we haven't implemented path caching yet.",
      "comment_id": 481,
      "profile_id": 17,
      "published": "2015-10-16T22:00:04.098141Z",
      "thread_id": 112,
      "url": "/discussion/using-the-neo4j-graph-database-for-hetnets/112#4"
    },
    {
      "body_html": "<h1>GraphConnect 2015</h1>\r\n\r\n<p>Today I attended <a href=\"http://graphconnect.com/\">GraphConnect</a> — a conference focused on neo4j. CEO, Emil Eifrem, kicked the event off with several exciting announcements:</p>\r\n\r\n<ul><li>Neo4j 2.3 has been released bringing speed and scalability <a href=\"http://neo4j.com/release-notes/neo4j-2-3-0/\">improvements</a>. Specifically, the caching infrastructure has been rewritten to <a href=\"http://neo4j.com/blog/new-on-neo4j-the-neo4j-2-3-0-milestone-2-release-is-here/\">provide</a> \"significant (up to 2-3x) improvements in concurrent read scaling.\"</li><li>Neo4j 3.0 is in the works and will bring unified and official drivers across languages. The initial release will include a Python but not R driver.</li><li>Cypher <a href=\"http://neo4j.com/blog/open-cypher-sql-for-graphs/\">will be</a> open sourced as <a href=\"http://www.opencypher.org/\">openCypher</a>. This will hopefully give rise to a standard query language for all graph databases.</li></ul>\r\n\r\n<h2>Select learnings</h2>\r\n\r\n<p>Neo4j is designed for <strong>deep traversals</strong>. Other graph databases preferentially support big data (networks with billions of nodes) over efficient traversal. Since our network is small but our edge prediction method requires deep traversal, neo4j is a good fit for our application.</p>\r\n\r\n<p>Neo4j doesn't enforce or specifically support a type graph (also called a schema, <strong>metagraph</strong>, or graph model). However, a metagraph can <a href=\"http://neo4j.com/blog/rvb-2-2-meta-graph/\">easily be created</a> from an already populated graph. While neo4j won't innately reason based on the created metagraph, it can be convenient from a user standpoint.</p>",
      "body_md": "# GraphConnect 2015\r\n\r\nToday I attended [GraphConnect](http://graphconnect.com/) -- a conference focused on neo4j. CEO, Emil Eifrem, kicked the event off with several exciting announcements:\r\n\r\n+ Neo4j 2.3 has been released bringing speed and scalability [improvements](http://neo4j.com/release-notes/neo4j-2-3-0/). Specifically, the caching infrastructure has been rewritten to [provide](http://neo4j.com/blog/new-on-neo4j-the-neo4j-2-3-0-milestone-2-release-is-here/) \"significant (up to 2-3x) improvements in concurrent read scaling.\"\r\n+ Neo4j 3.0 is in the works and will bring unified and official drivers across languages. The initial release will include a Python but not R driver.\r\n+ Cypher [will be](http://neo4j.com/blog/open-cypher-sql-for-graphs/) open sourced as [openCypher](http://www.opencypher.org/). This will hopefully give rise to a standard query language for all graph databases.\r\n\r\n## Select learnings\r\n\r\nNeo4j is designed for **deep traversals**. Other graph databases preferentially support big data (networks with billions of nodes) over efficient traversal. Since our network is small but our edge prediction method requires deep traversal, neo4j is a good fit for our application.\r\n\r\nNeo4j doesn't enforce or specifically support a type graph (also called a schema, **metagraph**, or graph model). However, a metagraph can [easily be created](http://neo4j.com/blog/rvb-2-2-meta-graph/) from an already populated graph. While neo4j won't innately reason based on the created metagraph, it can be convenient from a user standpoint.",
      "comment_id": 484,
      "profile_id": 17,
      "published": "2015-10-21T22:04:05.279822Z",
      "thread_id": 112,
      "url": "/discussion/using-the-neo4j-graph-database-for-hetnets/112#5"
    },
    {
      "body_html": "<h1>LDlink</h1>\r\n\r\n<p>A recently-published <a href=\"http://analysistools.nci.nih.gov/LDlink/\">webapp called LDlink</a> calculates SNPs in LD for a given lead SNP using 1000 Genomes Phase 3 data <span class=\"citation\">[<a href=\"https://doi.org/10.1093/bioinformatics/btv402\" class=\"citation\" data-key=\"10.1093/bioinformatics/btv402\">1</a>]</span>. The LDproxy feature allows specifying a lead SNP and reference population. The resulting table of proxy SNPs is downloadable as a tsv.</p>\r\n\r\n<p>Unfortunately, the service doesn't release a public API. Therefore, querying at scale could be difficult.</p>",
      "body_md": "# LDlink\r\n\r\nA recently-published [webapp called LDlink](http://analysistools.nci.nih.gov/LDlink/) calculates SNPs in LD for a given lead SNP using 1000 Genomes Phase 3 data [@10.1093/bioinformatics/btv402]. The LDproxy feature allows specifying a lead SNP and reference population. The resulting table of proxy SNPs is downloadable as a tsv.\r\n\r\nUnfortunately, the service doesn't release a public API. Therefore, querying at scale could be difficult.",
      "comment_id": 536,
      "profile_id": 17,
      "published": "2015-11-02T15:53:59.980194Z",
      "thread_id": 71,
      "url": "/discussion/calculating-genomic-windows-for-gwas-lead-snps/71#7"
    },
    {
      "body_html": "<p><a href=\"http://bgee.org\">Bgee</a> is an integrative and comparative resource for gene expression <span class=\"citation\">[<a href=\"https://doi.org/10.1007/978-3-540-69828-9_12\" class=\"citation\" data-key=\"10.1007/978-3-540-69828-9_12\">1</a>]</span>. We extract the following edges from Bgee for our network:</p>\r\n\r\n<ul><li>Gene–Anatomy <strong>expression</strong> — whether a gene is present in an anatomy</li><li>Gene–Anatomy <strong>upregulation</strong> — whether a gene is upregulated (overexpressed) in an anatomy</li><li>Gene–Anatomy <strong>downregulation</strong> — whether a gene is downregulated (underexpressed) in an anatomy</li></ul>\r\n\r\n<p>We have already substantially discussed Bgee on <em>Thinklab</em> in a more general gene expression thread <span class=\"citation\">[<a href=\"/discussion/tissue-specific-gene-expression-resources/81\" class=\"citation\" data-key=\"10.15363/thinklab.d81\">2</a>]</span>. The comments consisted of:</p>\r\n\r\n<ul><li>an <a href=\"http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#3\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d81\">introduction</a> by <a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a> </li><li><a href=\"http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#4\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d81\">questions</a> on processing parameters by <a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a></li><li><a href=\"http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#5\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d81\">answers</a> by <a href=\"/u/fbastian\" class=\"username\">@fbastian</a> </li><li>preliminary <a href=\"http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#6\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d81\">analysis</a> by <a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a></li><li>additional <a href=\"http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#7\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d81\">guidance</a> by <a href=\"/u/fbastian\" class=\"username\">@fbastian</a> </li><li>an initial <a href=\"http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#8\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d81\">complete analysis</a> and feedback by <a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a> </li><li><a href=\"http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#9\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d81\">response</a> to feedback by <a href=\"/u/fbastian\" class=\"username\">@fbastian</a> </li><li><a href=\"http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#10\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d81\">tying up</a> loose ends by <a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a></li></ul>\r\n\r\n<p>We are revisiting our Bgee analysis. Since the original discussion has become cluttered and covers a general topic, we are starting a designated Bgee discussion. Stay tuned.</p>",
      "body_md": "[Bgee](http://bgee.org) is an integrative and comparative resource for gene expression [@10.1007/978-3-540-69828-9_12]. We extract the following edges from Bgee for our network:\r\n\r\n+ Gene--Anatomy **expression** -- whether a gene is present in an anatomy\r\n+ Gene--Anatomy **upregulation** -- whether a gene is upregulated (overexpressed) in an anatomy\r\n+ Gene--Anatomy **downregulation** -- whether a gene is downregulated (underexpressed) in an anatomy\r\n\r\nWe have already substantially discussed Bgee on *Thinklab* in a more general gene expression thread [@10.15363/thinklab.d81]. The comments consisted of:\r\n\r\n+ an [introduction](http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#3) by @dhimmel \r\n+ [questions](http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#4) on processing parameters by @dhimmel\r\n+ [answers](http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#5) by @fbastian \r\n+ preliminary [analysis](http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#6) by @dhimmel\r\n+ additional [guidance](http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#7) by @fbastian \r\n+ an initial [complete analysis](http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#8) and feedback by @dhimmel \r\n+ [response](http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#9) to feedback by @fbastian \r\n+ [tying up](http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#10) loose ends by @dhimmel\r\n\r\nWe are revisiting our Bgee analysis. Since the original discussion has become cluttered and covers a general topic, we are starting a designated Bgee discussion. Stay tuned.",
      "comment_id": 538,
      "profile_id": 17,
      "published": "2015-11-04T02:25:25.483825Z",
      "thread_id": 124,
      "url": "/discussion/processing-bgee-for-tissue-specific-gene-presence-and-overunder-expression/124"
    },
    {
      "body_html": "<h1>Bgee discussion migrating</h1>\r\n\r\n<p>I started a <a href=\"http://thinklab.com/discussion/processing-bgee-for-tissue-specific-gene-presence-and-overunder-expression/124\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d124\">designated discussion</a> for Bgee. Please direct further Bgee attention there.</p>",
      "body_md": "# Bgee discussion migrating\r\n\r\nI started a [designated discussion](http://thinklab.com/discussion/processing-bgee-for-tissue-specific-gene-presence-and-overunder-expression/124) for Bgee. Please direct further Bgee attention there.",
      "comment_id": 539,
      "profile_id": 17,
      "published": "2015-11-04T02:27:37.960982Z",
      "thread_id": 81,
      "url": "/discussion/tissue-specific-gene-expression-resources/81#11"
    },
    {
      "body_html": "<h1>Quality control filters</h1>\r\n\r\n<p>Initially, we <a href=\"http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#5\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d81\">chose permissive filters</a> for including Bgee edges based largely on the <a href=\"http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#5\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d81\">recommendations</a> of <a href=\"/u/fbastian\" class=\"username\">@fbastian</a>. Several developments are making us reevaluate our permissiveness:</p>\r\n\r\n<ol><li><em>Gene–expression–Anatomy</em> edges are the most prevalent type in the network (see last figure in <a href=\"https://github.com/dhimmel/integrate/blob/1a43ef2718283cbfc9ae869aee1856bf20e2ad6e/integrate.ipynb\">this notebook</a>). Now that we're traversing the network to extract paths, we're noticing high-degree nodes are computationally problematic. Several anatomies have 20,000 expressed genes and 5000 differentially expressed genes (see <a href=\"https://github.com/dhimmel/integrate/blob/1a43ef2718283cbfc9ae869aee1856bf20e2ad6e/viz/degrees.pdf\">page 2 here</a>). Therefore downstream constraints favor rigorous thresholds for extremely high-degree edge types.</li><li>We <a href=\"http://doi.org/10.15363/thinklab.d91\">also extract</a> <em>Gene–expression–Anatomy</em> edges from <a href=\"http://tissues.jensenlab.org/About\">TISSUES</a> <span class=\"citation\">[<a href=\"https://doi.org/10.7717/peerj.1054\" class=\"citation\" data-key=\"10.7717/peerj.1054\">1</a>]</span>. <a href=\"https://github.com/dhimmel/tissues/blob/d6b0c99352db27469f2c3399cecb6f9fae2db547/bgee-combine.ipynb\">Currently</a>, TISSUES contributes 321,516 expression edges, while Bgee contributes 5,406,177. I suspect our TISSUES inclusion threshold (score ≥ 3) is much more stringent than our <a href=\"http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#6\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d81\">Bgee theshold</a>.</li><li>TISSUES provides a score for each tissue–gene relationship. These scores have been calibrated on a gold standard allowing evidence-based weighting of each study. In contrast, Bgee has different categories of evidence based on ambiguity and quality. These measures are codependent and have been difficult to understand. Therefore, it's difficult to conclude whether low quality or high ambiguity relationships have merit.</li></ol>\r\n\r\n<h2>Ambiguity and call quality</h2>\r\n\r\n<p>We <a href=\"https://github.com/dhimmel/bgee/blob/add20b29b8f926004ce69b9bacff2edf69cd383c/bgee.ipynb\">looked into</a> the relationship between ambiguity and call quality.</p>\r\n\r\n<p>Below, we show the contingency table for <code>Expression</code> (columns) and <code>Call quality</code> (rows) in the <code>Homo_sapiens_expr-complete</code> dataset (<a href=\"http://bgee.org/?page=doc&amp;action=call_files#single_expr_complete_col7\">documentation</a>). Each cell contains the percentage of observations in the corresponding category:</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th></th><th>absent</th><th>high ambiguity</th><th>low ambiguity</th><th>present</th></tr></thead><tbody><tr><td>NA</td><td>0</td><td>0.001</td><td>0.001</td><td>0</td></tr><tr><td>poor quality</td><td>0</td><td>0</td><td>0</td><td>0.23</td></tr><tr><td>high quality</td><td>0.11</td><td>0</td><td>0</td><td>0.67</td></tr></tbody></table>\r\n\r\n<p>Below, we show the contingency table for <code>Differential expression</code> (columns) and <code>Call quality</code> (rows) in the <code>Homo_sapiens_diffexpr-anatomy-simple</code> dataset (<a href=\"http://bgee.org/?page=doc&amp;action=call_files#single_diff_simple_col7\">documentation</a>). Each cell contains the percentage of observations in the corresponding category:</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th></th><th>high ambiguity</th><th>low ambiguity</th><th>over-expression</th><th>under-expression</th></tr></thead><tbody><tr><td>NA</td><td>0.025</td><td>0.16</td><td>0</td><td>0</td></tr><tr><td>low quality</td><td>0</td><td>0</td><td>0.18</td><td>0.24</td></tr><tr><td>high quality</td><td>0</td><td>0</td><td>0.21</td><td>0.20</td></tr></tbody></table>\r\n\r\n<h2>Conclusions</h2>\r\n\r\n<p><strong>Presence:</strong> <code>Homo_sapiens_expr-complete</code> uses the value <code>poor quality</code> while <code>Homo_sapiens_diffexpr-anatomy-simple</code> uses <code>low quality</code>. In our previous processing, we used <code>low quality</code> as the value for both datasets. Therefore, we accidentally omitted the 23% of observations that were <code>present</code> with <code>poor quality</code>. Our proposed solution is to take only <code>high quality</code> and <code>present</code> observations. The observations with ambiguous call qualities are rare, and thus I am not worried about excluding them for simplicity.</p>\r\n\r\n<p><strong>Differential expression:</strong> In <code>Homo_sapiens_diffexpr-anatomy-simple</code> differentially expressed observations are split between low and high quality. Low quality is <a href=\"http://bgee.org/?page=doc&amp;action=call_files#single_diff_simple_col8\">explained as</a>:</p>\r\n\r\n<blockquote><p>differential expression reported as low quality, or there exists a conflict for the same gene, anatomical entity and developmental stage, from different analyses of a same data type (conflicts between different data types are treated differently). For instance, an analysis showed a gene to be over-expressed in a condition, while another analysis showed the same gene to be under-expressed or not differentially expressed in the same condition. Such conflicts are resolved by a voting system based on the number of conditions compared, weighted by p-value. Note that in one case, this quality level is used to reconcile conflicting calls from different data types: when a data type produced an under-expression call, while a different data type has shown that the same gene was never seen as expressed in the same condition. In that case, the overall summary is under-expression low quality.</p></blockquote>\r\n\r\n<p>We are undecided whether to omit low quality differential expression edges.</p>",
      "body_md": "# Quality control filters\r\n\r\nInitially, we [chose permissive filters](http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#5) for including Bgee edges based largely on the [recommendations](http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#5) of @fbastian. Several developments are making us reevaluate our permissiveness:\r\n\r\n1. *Gene--expression--Anatomy* edges are the most prevalent type in the network (see last figure in [this notebook](https://github.com/dhimmel/integrate/blob/1a43ef2718283cbfc9ae869aee1856bf20e2ad6e/integrate.ipynb)). Now that we're traversing the network to extract paths, we're noticing high-degree nodes are computationally problematic. Several anatomies have 20,000 expressed genes and 5000 differentially expressed genes (see [page 2 here](https://github.com/dhimmel/integrate/blob/1a43ef2718283cbfc9ae869aee1856bf20e2ad6e/viz/degrees.pdf)). Therefore downstream constraints favor rigorous thresholds for extremely high-degree edge types.\r\n2. We [also extract](http://doi.org/10.15363/thinklab.d91) *Gene--expression--Anatomy* edges from [TISSUES](http://tissues.jensenlab.org/About) [@10.7717/peerj.1054]. [Currently](https://github.com/dhimmel/tissues/blob/d6b0c99352db27469f2c3399cecb6f9fae2db547/bgee-combine.ipynb), TISSUES contributes 321,516 expression edges, while Bgee contributes 5,406,177. I suspect our TISSUES inclusion threshold (score ≥ 3) is much more stringent than our [Bgee theshold](http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#6).\r\n3. TISSUES provides a score for each tissue--gene relationship. These scores have been calibrated on a gold standard allowing evidence-based weighting of each study. In contrast, Bgee has different categories of evidence based on ambiguity and quality. These measures are codependent and have been difficult to understand. Therefore, it's difficult to conclude whether low quality or high ambiguity relationships have merit.\r\n\r\n## Ambiguity and call quality\r\n\r\nWe [looked into](https://github.com/dhimmel/bgee/blob/add20b29b8f926004ce69b9bacff2edf69cd383c/bgee.ipynb) the relationship between ambiguity and call quality.\r\n\r\nBelow, we show the contingency table for `Expression` (columns) and `Call quality` (rows) in the `Homo_sapiens_expr-complete` dataset ([documentation](http://bgee.org/?page=doc&action=call_files#single_expr_complete_col7)). Each cell contains the percentage of observations in the corresponding category:\r\n\r\n|  | absent | high ambiguity | low ambiguity | present |\r\n|--------|--------|-----------|---------|----------|\r\n| NA | 0 | 0.001 | 0.001 | 0 |\r\n| poor quality | 0 | 0 | 0 | 0.23 |\r\n| high quality | 0.11 | 0 | 0 | 0.67 |\r\n\r\nBelow, we show the contingency table for `Differential expression` (columns) and `Call quality` (rows) in the `Homo_sapiens_diffexpr-anatomy-simple` dataset ([documentation](http://bgee.org/?page=doc&action=call_files#single_diff_simple_col7)). Each cell contains the percentage of observations in the corresponding category:\r\n\r\n|  | high ambiguity | low ambiguity | over-expression | under-expression |\r\n|-------------------------|----------------|---------------|-----------------|------------------|\r\n| NA | 0.025 | 0.16 | 0 | 0 |\r\n| low quality | 0 | 0 | 0.18 | 0.24 |\r\n| high quality | 0 | 0 | 0.21 | 0.20 |\r\n\r\n## Conclusions\r\n\r\n**Presence:** `Homo_sapiens_expr-complete` uses the value `poor quality` while `Homo_sapiens_diffexpr-anatomy-simple` uses `low quality`. In our previous processing, we used `low quality` as the value for both datasets. Therefore, we accidentally omitted the 23% of observations that were `present` with `poor quality`. Our proposed solution is to take only `high quality` and `present` observations. The observations with ambiguous call qualities are rare, and thus I am not worried about excluding them for simplicity.\r\n\r\n**Differential expression:** In `Homo_sapiens_diffexpr-anatomy-simple` differentially expressed observations are split between low and high quality. Low quality is [explained as](http://bgee.org/?page=doc&action=call_files#single_diff_simple_col8):\r\n\r\n> differential expression reported as low quality, or there exists a conflict for the same gene, anatomical entity and developmental stage, from different analyses of a same data type (conflicts between different data types are treated differently). For instance, an analysis showed a gene to be over-expressed in a condition, while another analysis showed the same gene to be under-expressed or not differentially expressed in the same condition. Such conflicts are resolved by a voting system based on the number of conditions compared, weighted by p-value. Note that in one case, this quality level is used to reconcile conflicting calls from different data types: when a data type produced an under-expression call, while a different data type has shown that the same gene was never seen as expressed in the same condition. In that case, the overall summary is under-expression low quality.\r\n\r\nWe are undecided whether to omit low quality differential expression edges.",
      "comment_id": 540,
      "profile_id": 17,
      "published": "2015-11-04T03:54:30.810471Z",
      "thread_id": 124,
      "url": "/discussion/processing-bgee-for-tissue-specific-gene-presence-and-overunder-expression/124#2"
    },
    {
      "body_html": "<p>For expression calls, besides being more stringent, it is also possible to discard anatomical entities close to the root of the ontology, that are less informative, and that benefits from the propagation from lots of substructures. See also <a href=\"https://github.com/owlcollab/owltools/issues/145\">https://github.com/owlcollab/owltools/issues/145</a> for a related discussion.</p>\r\n\r\n<p>For differential expression, well, as said before, I'm not really surprised with this number of 5,000 differentially expressed genes in some structures. We are still willing to update our FDR computation to take into account all analyses, as mentionned <a href=\"http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#9\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d81\">here</a> (we are currently updating our differential expression pipeline).</p>",
      "body_md": "For expression calls, besides being more stringent, it is also possible to discard anatomical entities close to the root of the ontology, that are less informative, and that benefits from the propagation from lots of substructures. See also https://github.com/owlcollab/owltools/issues/145 for a related discussion.\r\n\r\nFor differential expression, well, as said before, I'm not really surprised with this number of 5,000 differentially expressed genes in some structures. We are still willing to update our FDR computation to take into account all analyses, as mentionned [here](http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#9) (we are currently updating our differential expression pipeline).",
      "comment_id": 541,
      "profile_id": 111,
      "published": "2015-11-04T10:43:40.342850Z",
      "thread_id": 124,
      "url": "/discussion/processing-bgee-for-tissue-specific-gene-presence-and-overunder-expression/124#3"
    },
    {
      "body_html": "<p>Emilie David — Assistant Director, Copyright, Licensing and Special Projects at AAAS — responded to our request. She indicated that AAAS does not generally allow <em>Science</em> content to be republished under Creative Commons licenses. However for Supporting Online Materials, authors are able to authorize use.</p>\r\n\r\n<p>I looked deeper into the <a href=\"http://www.sciencemag.org/site/feature/contribinfo/prep/4__2014LicensetoPublish_Final_6MAR2014.pdf\">License to Publish</a> and found the relevant section:</p>\r\n\r\n<blockquote><p>Author also retains the non-exclusive right to use the Work in the following ways without further permission but only after publication of the Work by AAAS and subject to the requirement that credit be given to its first publication in the appropriate issue of the applicable Science journal:</p><p>9) Author may use or authorize use of Supporting Online Material associated with the Work for any purpose and in any format.</p></blockquote>\r\n\r\n<p>Thus, we will proceed by requesting permission from the authors.</p>",
      "body_md": "Emilie David -- Assistant Director, Copyright, Licensing and Special Projects at AAAS -- responded to our request. She indicated that AAAS does not generally allow *Science* content to be republished under Creative Commons licenses. However for Supporting Online Materials, authors are able to authorize use.\r\n\r\nI looked deeper into the [License to Publish](http://www.sciencemag.org/site/feature/contribinfo/prep/4__2014LicensetoPublish_Final_6MAR2014.pdf) and found the relevant section:\r\n\r\n> Author also retains the non-exclusive right to use the Work in the following ways without further permission but only after publication of the Work by AAAS and subject to the requirement that credit be given to its first publication in the appropriate issue of the applicable Science journal:\r\n\r\n> 9) Author may use or authorize use of Supporting Online Material associated with the Work for any purpose and in any format.\r\n\r\nThus, we will proceed by requesting permission from the authors.",
      "comment_id": 545,
      "profile_id": 17,
      "published": "2015-11-11T22:43:29.686872Z",
      "thread_id": 111,
      "url": "/discussion/incomplete-interactome-licensing/111#2"
    },
    {
      "body_html": "<h1>Update to October 2015 release</h1>\r\n\r\n<p>We updated our analysis <span class=\"citation\">[<a href=\"https://doi.org/10.5281/zenodo.33987\" class=\"citation\" data-key=\"10.5281/zenodo.33987\">1</a>]</span> to the latest BindingDB release (<code>BindingDB_All_2015m10.tsv</code>) and made several implementation <a href=\"https://github.com/dhimmel/bindingdb/commit/36097bc715420827ffd06dd64e05edf95e75f038\">enhancements</a>. Now, our collapsed datasets retain source and pubmed information to help with licensing and attribution.</p>\r\n\r\n<p>For more information, see the <a href=\"https://github.com/dhimmel/bindingdb/blob/28dc70275103a233a2f02024082adcea45102a96/process.ipynb\">notebook</a> for processing the BindingDB export, the rmarkdown <a href=\"https://htmlpreview.github.io/?https://github.com/dhimmel/bindingdb/blob/28dc70275103a233a2f02024082adcea45102a96/collapse.html\">output</a> for collapsing to compound–gene relationships, and the data download <a href=\"https://github.com/dhimmel/bindingdb/tree/28dc70275103a233a2f02024082adcea45102a96/data\">directory</a>.</p>\r\n\r\n<h2>Issue feedback</h2>\r\n\r\n<p>A few issues arose which were not present for <code>BindingDB_All_2015m3.tsv</code>. Paging <a href=\"/u/mkgilson\" class=\"username\">@mkgilson</a>:</p>\r\n\r\n<ul><li>Rows 192304–192473 (one indexed) start off with SMILES rather than reactant set IDs.</li><li>Numeric binding affinities could not be extracted for 19 rows.</li></ul>\r\n\r\n<p>I recommend switching from the ragged tsv to a format that can handle nested structure, such as json or xml.</p>",
      "body_md": "# Update to October 2015 release\r\n\r\nWe updated our analysis [@10.5281/zenodo.33987] to the latest BindingDB release (`BindingDB_All_2015m10.tsv`) and made several implementation [enhancements](https://github.com/dhimmel/bindingdb/commit/36097bc715420827ffd06dd64e05edf95e75f038). Now, our collapsed datasets retain source and pubmed information to help with licensing and attribution.\r\n\r\nFor more information, see the [notebook](https://github.com/dhimmel/bindingdb/blob/28dc70275103a233a2f02024082adcea45102a96/process.ipynb) for processing the BindingDB export, the rmarkdown [output](https://htmlpreview.github.io/?https://github.com/dhimmel/bindingdb/blob/28dc70275103a233a2f02024082adcea45102a96/collapse.html) for collapsing to compound--gene relationships, and the data download [directory](https://github.com/dhimmel/bindingdb/tree/28dc70275103a233a2f02024082adcea45102a96/data).\r\n\r\n## Issue feedback\r\n\r\nA few issues arose which were not present for `BindingDB_All_2015m3.tsv`. Paging @mkgilson:\r\n\r\n+ Rows 192304--192473 (one indexed) start off with SMILES rather than reactant set IDs.\r\n+ Numeric binding affinities could not be extracted for 19 rows.\r\n\r\nI recommend switching from the ragged tsv to a format that can handle nested structure, such as json or xml.",
      "comment_id": 549,
      "profile_id": 17,
      "published": "2015-11-19T02:02:39.722976Z",
      "thread_id": 53,
      "url": "/discussion/integrating-drug-target-information-from-bindingdb/53#6"
    },
    {
      "body_html": "<h1>Author permission</h1>\r\n\r\n<p>Yesterday, I emailed the authors, and first author, Jörg Menche, promptly responded.</p>\r\n\r\n<p>He indicated that they published the supporting data with the hope that others would find it useful. As far as they're concerned, we are free to use it anyway we like.</p>\r\n\r\n<p>He also mentioned that they compiled their interactions from a variety of resources (<a href=\"http://thinklab.com/discussion/creating-a-catalog-of-protein-interactions/85#2\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d85\">as discussed here</a>). Jörg was unsure whether this placed any restrictions on the downstream use of their dataset.</p>",
      "body_md": "# Author permission\r\n\r\nYesterday, I emailed the authors, and first author, Jörg Menche, promptly responded.\r\n\r\nHe indicated that they published the supporting data with the hope that others would find it useful. As far as they're concerned, we are free to use it anyway we like.\r\n\r\nHe also mentioned that they compiled their interactions from a variety of resources ([as discussed here](http://thinklab.com/discussion/creating-a-catalog-of-protein-interactions/85#2)). Jörg was unsure whether this placed any restrictions on the downstream use of their dataset.",
      "comment_id": 550,
      "profile_id": 17,
      "published": "2015-11-23T18:11:33.331297Z",
      "thread_id": 111,
      "url": "/discussion/incomplete-interactome-licensing/111#3"
    },
    {
      "body_html": "<h1>Query Optimization</h1>\r\n\r\n<p>Above, we <a href=\"#4\">debuted</a> <em>DWPC</em> (degree-weighted path count) computation using Cypher. I noticed that looking up the degrees along each path was a major timesink. This finding was surprising because node degree lookup should be trivial compared to path traversal.</p>\r\n\r\n<p>In a stroke of genius, <a href=\"/u/alizee\" class=\"username\">@alizee</a> <a href=\"https://twitter.com/dhimmel/status/662415810825056256\">hypothesized</a> our inclusion of node labels was to blame. For our diagnostic query, removing node labels <a href=\"https://twitter.com/dhimmel/status/662440818398007296\">reduced</a> database hits by 1339 fold and runtime by 8 fold.</p>\r\n\r\n<p>Michael Hunger, caretaker general of the neo4j community, <a href=\"https://twitter.com/mesirii/status/662463621335818240\">explained</a>:</p>\r\n\r\n<blockquote><p><code>size(pattern)</code> uses <code>node.getDegree()</code> if pattern only contains relationship type &amp; direction</p></blockquote>\r\n\r\n<p>More explanation is <a href=\"http://neo4j.com/blog/neo4j-2-2-query-tuning/\">available here</a>, but the essential insight is that by using only direction and relationship type to lookup node degree, we no longer need to lookup the label on the other end of each edge.</p>\r\n\r\n<h2>Database changes</h2>\r\n\r\n<p>To support this optimization, we need to ensure that no two metaedges that touch a common metanode have the same relationship type. Our current hetnet is noncompliant in this regard: for example, the three Gene Ontology metaedges all have kind 'participation':</p>\r\n\r\n<ol><li>Gene–participation–Biological Process</li><li>Gene–participation–Molecular Function</li><li>Gene–participation–Cellular Component</li></ol>\r\n\r\n<p>Therefore, we have implemented unique neo4j relationship types for each metaedge (<a href=\"https://github.com/dhimmel/hetio/commit/8107d783e1b86a33123b9fb3273edf51695b5e82\">primary commit</a> and bugfixes <a href=\"https://github.com/dhimmel/hetio/commit/d4b5f4ef223a26eb5bce23245a10b403cccf9fe5\">1</a> and <a href=\"https://github.com/dhimmel/hetio/commit/98121d64feeba829214652960322f00bffcc6b75\">2</a>) by appending the standardized metaedge abbreviation to its kind. With this change, the relationship types for the Gene Ontology metaedges become:</p>\r\n\r\n<ol><li><code>PARTICIPATION_BPpG</code></li><li><code>PARTICIPATION_GpMF</code></li><li><code>PARTICIPATION_CCpG</code></li></ol>\r\n\r\n<h2>Example query</h2>\r\n\r\n<p>With the updated database, the query for calculating the <em>DWPC</em> between goserelin and lung cancer for the <code>CcSEcCdGuD</code> metapath is:</p>\r\n\r\n<pre><code class=\"no-highlight hljs\">MATCH paths = (n0:Compound)-[:CAUSATION_CcSE]-(n1)-[:CAUSATION_CcSE]-(n2)-[:DOWNREGULATION_CdG]-(n3)-[:UPREGULATION_DuG]-(n4:Disease)\r\n  WHERE n0.identifier = 'DB00014' // Goserelin\r\n  AND n4.identifier = 'DOID:1324' // lung cancer\r\nWITH [\r\n  size((n0)-[:CAUSATION_CcSE]-()),\r\n  size(()-[:CAUSATION_CcSE]-(n1)),\r\n  size((n1)-[:CAUSATION_CcSE]-()),\r\n  size(()-[:CAUSATION_CcSE]-(n2)),\r\n  size((n2)-[:DOWNREGULATION_CdG]-()),\r\n  size(()-[:DOWNREGULATION_CdG]-(n3)),\r\n  size((n3)-[:UPREGULATION_DuG]-()),\r\n  size(()-[:UPREGULATION_DuG]-(n4))\r\n  ] AS degrees, paths\r\nRETURN\r\n  COUNT(paths) AS PC,\r\n  sum(reduce(pdp = 1.0, d in degrees| pdp * d ^ -0.4)) AS DWPC</code></pre>",
      "body_md": "# Query Optimization\r\n\r\nAbove, we [debuted](#4) *DWPC* (degree-weighted path count) computation using Cypher. I noticed that looking up the degrees along each path was a major timesink. This finding was surprising because node degree lookup should be trivial compared to path traversal.\r\n\r\nIn a stroke of genius, @alizee [hypothesized](https://twitter.com/dhimmel/status/662415810825056256) our inclusion of node labels was to blame. For our diagnostic query, removing node labels [reduced](https://twitter.com/dhimmel/status/662440818398007296) database hits by 1339 fold and runtime by 8 fold.\r\n\r\nMichael Hunger, caretaker general of the neo4j community, [explained](https://twitter.com/mesirii/status/662463621335818240):\r\n\r\n> `size(pattern)` uses `node.getDegree()` if pattern only contains relationship type & direction\r\n\r\nMore explanation is [available here](http://neo4j.com/blog/neo4j-2-2-query-tuning/), but the essential insight is that by using only direction and relationship type to lookup node degree, we no longer need to lookup the label on the other end of each edge.\r\n\r\n## Database changes\r\n\r\nTo support this optimization, we need to ensure that no two metaedges that touch a common metanode have the same relationship type. Our current hetnet is noncompliant in this regard: for example, the three Gene Ontology metaedges all have kind 'participation':\r\n\r\n1. Gene--participation--Biological Process\r\n2. Gene--participation--Molecular Function\r\n3. Gene--participation--Cellular Component\r\n\r\nTherefore, we have implemented unique neo4j relationship types for each metaedge ([primary commit](https://github.com/dhimmel/hetio/commit/8107d783e1b86a33123b9fb3273edf51695b5e82) and bugfixes [1](https://github.com/dhimmel/hetio/commit/d4b5f4ef223a26eb5bce23245a10b403cccf9fe5) and [2](https://github.com/dhimmel/hetio/commit/98121d64feeba829214652960322f00bffcc6b75)) by appending the standardized metaedge abbreviation to its kind. With this change, the relationship types for the Gene Ontology metaedges become:\r\n\r\n1. `PARTICIPATION_BPpG`\r\n2. `PARTICIPATION_GpMF`\r\n3. `PARTICIPATION_CCpG`\r\n\r\n## Example query\r\n\r\nWith the updated database, the query for calculating the *DWPC* between goserelin and lung cancer for the `CcSEcCdGuD` metapath is:\r\n\r\n```cypher\r\nMATCH paths = (n0:Compound)-[:CAUSATION_CcSE]-(n1)-[:CAUSATION_CcSE]-(n2)-[:DOWNREGULATION_CdG]-(n3)-[:UPREGULATION_DuG]-(n4:Disease)\r\n  WHERE n0.identifier = 'DB00014' // Goserelin\r\n  AND n4.identifier = 'DOID:1324' // lung cancer\r\nWITH [\r\n  size((n0)-[:CAUSATION_CcSE]-()),\r\n  size(()-[:CAUSATION_CcSE]-(n1)),\r\n  size((n1)-[:CAUSATION_CcSE]-()),\r\n  size(()-[:CAUSATION_CcSE]-(n2)),\r\n  size((n2)-[:DOWNREGULATION_CdG]-()),\r\n  size(()-[:DOWNREGULATION_CdG]-(n3)),\r\n  size((n3)-[:UPREGULATION_DuG]-()),\r\n  size(()-[:UPREGULATION_DuG]-(n4))\r\n  ] AS degrees, paths\r\nRETURN\r\n  COUNT(paths) AS PC,\r\n  sum(reduce(pdp = 1.0, d in degrees| pdp * d ^ -0.4)) AS DWPC\r\n```",
      "comment_id": 552,
      "profile_id": 17,
      "published": "2015-11-26T17:20:29.192990Z",
      "thread_id": 112,
      "url": "/discussion/using-the-neo4j-graph-database-for-hetnets/112#6"
    },
    {
      "body_html": "<h1>Concurrent queries using py2neo</h1>\r\n\r\n<p>As <a href=\"https://twitter.com/darthvader42/status/670154181064400897\">explained</a> by Stefan Armbruster, a single cypher query is limited to a single core. However, multiple queries can be fulfilled in parallel:</p>\r\n\r\n<blockquote><p>With current versions of Neo4j, a Cypher query traverses the graph in single threaded mode. Since most graph applications out there are concurrently used by multiple users, this model saturates the available cores. [<a href=\"http://stackoverflow.com/a/27578860/4651668\">source</a>]</p></blockquote>\r\n\r\n<p>Currently, we perform a separate query for each compound–disease–metapath combination. Depending on the number of compound–disease pairs and metapaths considered, we will need to compute between 1 million and 1 billion <em>DWPCs</em>. </p>\r\n\r\n<p>Our software package for hetnets, <a href=\"https://github.com/dhimmel/hetio\">hetio</a> <span class=\"citation\">[<a href=\"https://doi.org/10.5281/zenodo.31763\" class=\"citation\" data-key=\"10.5281/zenodo.31763\">1</a>]</span>, is built in python. Despite migrating to neo4j, we are still dependent on hetio for:</p>\r\n\r\n<ul><li>metagraph operations</li><li>edge directionality</li><li>metapath abbreviation</li><li>constructing cypher queries</li></ul>\r\n\r\n<p>Therefore, we're using python to construct and execute queries with the <a href=\"http://py2neo.org/2.0/\">py2neo</a> package.</p>\r\n\r\n<p>To enable concurrent queries, we initially used the <a href=\"https://docs.python.org/3.5/library/multiprocessing.html\">multiprocessing</a> module (<a href=\"https://github.com/dhimmel/learn/blob/affb391ac35cd726e1377f08557b060f4098144f/neo4j-compute.ipynb\">notebook</a>), which enables parallelism by creating subprocesses. However, subprocesses require substantial overhead. Since the majority of computation is performed outside of python by the neo4j sever, we switched to the <a href=\"https://docs.python.org/3.5/library/threading.html\">threading</a> module (<a href=\"https://github.com/dhimmel/learn/blob/bfc0b4b3adef8ee9bab73676181b84298f6b16fe/neo4j-compute.ipynb\">notebook</a>). Threading has less overhead than multiprocessing, but is limited to a single process of pure python. However, since the cypher query releases the <a href=\"https://docs.python.org/3.5/glossary.html#term-global-interpreter-lock\">global interpreter lock</a>, the restriction to a single process is not a time-limiting step.</p>\r\n\r\n<p>In the end, we used <a href=\"https://docs.python.org/3.5/library/concurrent.futures.html#threadpoolexecutor\">concurrent.futures</a> to make threading easier (<a href=\"https://github.com/dhimmel/learn/blob/0867341ac64e5875390532e1aa31bd3b6f38c0ad/neo4j-compute.ipynb\">notebook</a>). We encountered a <a href=\"https://github.com/nigelsmall/py2neo/issues/449\">small hiccup</a> where our queue of queries waiting to be executed grew large and consumed substantial memory. We addressed the issue by postponing new query submission until the queue dropped below a given size.</p>\r\n\r\n<p>Performing concurrent queries led to ~1000% processor usage by neo4j, equivalent to 10 cores at full load. This benchmark was performed on a 16 core machine running neo4j-community-2.3.1 on Ubuntu 15.10. Increasing the number of concurrent python workers above 16 did not increase the ~1000% usage figure. Let us know of any methods to increase processor saturation.</p>",
      "body_md": "# Concurrent queries using py2neo\r\n\r\nAs [explained](https://twitter.com/darthvader42/status/670154181064400897) by Stefan Armbruster, a single cypher query is limited to a single core. However, multiple queries can be fulfilled in parallel:\r\n\r\n> With current versions of Neo4j, a Cypher query traverses the graph in single threaded mode. Since most graph applications out there are concurrently used by multiple users, this model saturates the available cores. [[source](http://stackoverflow.com/a/27578860/4651668)]\r\n\r\nCurrently, we perform a separate query for each compound--disease--metapath combination. Depending on the number of compound--disease pairs and metapaths considered, we will need to compute between 1 million and 1 billion *DWPCs*. \r\n\r\nOur software package for hetnets, [hetio](https://github.com/dhimmel/hetio) [@10.5281/zenodo.31763], is built in python. Despite migrating to neo4j, we are still dependent on hetio for:\r\n\r\n+ metagraph operations\r\n+ edge directionality\r\n+ metapath abbreviation\r\n+ constructing cypher queries\r\n\r\nTherefore, we're using python to construct and execute queries with the [py2neo](http://py2neo.org/2.0/) package.\r\n\r\nTo enable concurrent queries, we initially used the [multiprocessing](https://docs.python.org/3.5/library/multiprocessing.html) module ([notebook](https://github.com/dhimmel/learn/blob/affb391ac35cd726e1377f08557b060f4098144f/neo4j-compute.ipynb)), which enables parallelism by creating subprocesses. However, subprocesses require substantial overhead. Since the majority of computation is performed outside of python by the neo4j sever, we switched to the [threading](https://docs.python.org/3.5/library/threading.html) module ([notebook](https://github.com/dhimmel/learn/blob/bfc0b4b3adef8ee9bab73676181b84298f6b16fe/neo4j-compute.ipynb)). Threading has less overhead than multiprocessing, but is limited to a single process of pure python. However, since the cypher query releases the [global interpreter lock](https://docs.python.org/3.5/glossary.html#term-global-interpreter-lock), the restriction to a single process is not a time-limiting step.\r\n\r\nIn the end, we used [concurrent.futures](https://docs.python.org/3.5/library/concurrent.futures.html#threadpoolexecutor) to make threading easier ([notebook](https://github.com/dhimmel/learn/blob/0867341ac64e5875390532e1aa31bd3b6f38c0ad/neo4j-compute.ipynb)). We encountered a [small hiccup](https://github.com/nigelsmall/py2neo/issues/449) where our queue of queries waiting to be executed grew large and consumed substantial memory. We addressed the issue by postponing new query submission until the queue dropped below a given size.\r\n\r\nPerforming concurrent queries led to ~1000% processor usage by neo4j, equivalent to 10 cores at full load. This benchmark was performed on a 16 core machine running neo4j-community-2.3.1 on Ubuntu 15.10. Increasing the number of concurrent python workers above 16 did not increase the ~1000% usage figure. Let us know of any methods to increase processor saturation.",
      "comment_id": 553,
      "profile_id": 17,
      "published": "2015-11-26T22:54:11.765140Z",
      "thread_id": 112,
      "url": "/discussion/using-the-neo4j-graph-database-for-hetnets/112#7"
    },
    {
      "body_html": "<p>We're building an open project to predict new uses for existing drugs. The core of our project is a network with multiple types of nodes and relationships (hetnet) <span class=\"citation\">[<a href=\"/discussion/one-network-to-rule-them-all/102\" class=\"citation\" data-key=\"10.15363/thinklab.d102\">1</a>]</span>. We <a href=\"http://thinklab.com/discussion/using-the-neo4j-graph-database-for-hetnets/112\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d112\">use neo4j</a> to store, explore, and quantify this hetnet. </p>\r\n\r\n<p>With regards to licensing, there are several ways we plan to use the software: </p>\r\n\r\n<ol><li><p><strong>distributing the hetnet</strong> — we strive to make our hetnet reusable and extensible. Therefore, we need convenient and reliable formats for distributing the network. One format we'd like to use for distribution is an archive file of the database. For example, a tarball of <code>data/graph.db/</code>. In addition to an archive of just the database location, we would like to distribute an archive of the binary with the database included. So for example, a user could extract a single archive containing the neo4j server with our database and configuration already loaded.</p></li><li><p><strong>quantifying the hetnet</strong> — our method for relationship prediction relies on extracting network features, which quantify the prevalence of specific path types between two nodes. We <a href=\"http://thinklab.com/discussion/using-the-neo4j-graph-database-for-hetnets/112#4\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d112\">implemented</a> the algorithm in cypher. We <a href=\"http://neo4j.com/neo4j-scales-web-enterprise/\">read that</a> the enterprise version's high-performance cache \"can provide up to 10x the performance under concurrent load.\" However, for our application the enterprise edition did not provide a performance improvement over the community edition (<a href=\"https://github.com/dhimmel/learn/blob/6b81cd8eccaabf7d90bdedde66c28d8a88483cc6/neo4j-comparison.ipynb\">notebook</a>). Therefore, we are inclined to stick to the community version, but may consider enterprise to scale up our query throughput via the high-availability cluster.</p></li><li><p><strong>exploring the hetnet</strong> — we have been using the neo4j browser as a GUI to interact with the network. Eventually, we would like to host a publicly-accessible neo4j server which allows anyone to interact with our hetnet from their web browser.</p></li></ol>\r\n\r\n<p>We try to adhere to the following project ground-rules:</p>\r\n\r\n<ul><li>releasing all of our original data and source code as CC0.</li><li>avoiding dependencies that forbid distribution, to prevent situations where others cannot reproduce our science due to access issues.</li></ul>\r\n\r\n<p>Neo4j comes in two <a href=\"http://neo4j.com/editions/\">editions</a>: <em>community</em> which is <a href=\"http://opensource.org/licenses/GPL-3.0\">GPLv3</a> licensed and <em>enterprise</em> which is <a href=\"http://opensource.org/licenses/AGPL-3.0\">AGPLv3</a> licensed. Exactly what these licenses mean with respect to neo4j server is <a href=\"http://stackoverflow.com/q/6500925\">subject to debate</a>. A <a href=\"https://project.nordu.net/secure/attachment/12828/Fair+Trade+Software+Licensing.pdf\">guidance document</a> by neo4j states:</p>\r\n\r\n<blockquote><p>Simply, if you are open source, then Neo4j is open source; if you are closed source, then Neo4j is commercial. </p></blockquote>\r\n\r\n<p>Our project is open source, although we use CC0 rather than a copyleft license. We do not modify neo4j's source code, although we do want to distribute the compiled version (see 1 above). Finally, it's unclear exactly which aspects of our project are affected by neo4j's license.</p>\r\n\r\n<p>Given these complexities, we will reach out to neo4j for guidance. Specifically, we're interested in what restrictions neo4j's license places on our three use cases. And if there are restriction, could we obtain an educational or research license permitting our use?</p>",
      "body_md": "We're building an open project to predict new uses for existing drugs. The core of our project is a network with multiple types of nodes and relationships (hetnet) [@10.15363/thinklab.d102]. We [use neo4j](http://thinklab.com/discussion/using-the-neo4j-graph-database-for-hetnets/112) to store, explore, and quantify this hetnet. \r\n\r\nWith regards to licensing, there are several ways we plan to use the software: \r\n\r\n1. **distributing the hetnet** -- we strive to make our hetnet reusable and extensible. Therefore, we need convenient and reliable formats for distributing the network. One format we'd like to use for distribution is an archive file of the database. For example, a tarball of `data/graph.db/`. In addition to an archive of just the database location, we would like to distribute an archive of the binary with the database included. So for example, a user could extract a single archive containing the neo4j server with our database and configuration already loaded.\r\n\r\n+ **quantifying the hetnet** -- our method for relationship prediction relies on extracting network features, which quantify the prevalence of specific path types between two nodes. We [implemented](http://thinklab.com/discussion/using-the-neo4j-graph-database-for-hetnets/112#4) the algorithm in cypher. We [read that](http://neo4j.com/neo4j-scales-web-enterprise/) the enterprise version's high-performance cache \"can provide up to 10x the performance under concurrent load.\" However, for our application the enterprise edition did not provide a performance improvement over the community edition ([notebook](https://github.com/dhimmel/learn/blob/6b81cd8eccaabf7d90bdedde66c28d8a88483cc6/neo4j-comparison.ipynb)). Therefore, we are inclined to stick to the community version, but may consider enterprise to scale up our query throughput via the high-availability cluster.\r\n\r\n+ **exploring the hetnet** -- we have been using the neo4j browser as a GUI to interact with the network. Eventually, we would like to host a publicly-accessible neo4j server which allows anyone to interact with our hetnet from their web browser.\r\n\r\nWe try to adhere to the following project ground-rules:\r\n\r\n+ releasing all of our original data and source code as CC0.\r\n+ avoiding dependencies that forbid distribution, to prevent situations where others cannot reproduce our science due to access issues.\r\n\r\nNeo4j comes in two [editions](http://neo4j.com/editions/): *community* which is [GPLv3](http://opensource.org/licenses/GPL-3.0) licensed and *enterprise* which is [AGPLv3](http://opensource.org/licenses/AGPL-3.0) licensed. Exactly what these licenses mean with respect to neo4j server is [subject to debate](http://stackoverflow.com/q/6500925). A [guidance document](https://project.nordu.net/secure/attachment/12828/Fair+Trade+Software+Licensing.pdf) by neo4j states:\r\n\r\n> Simply, if you are open source, then Neo4j is open source; if you are closed source, then Neo4j is commercial. \r\n\r\nOur project is open source, although we use CC0 rather than a copyleft license. We do not modify neo4j's source code, although we do want to distribute the compiled version (see 1 above). Finally, it's unclear exactly which aspects of our project are affected by neo4j's license.\r\n\r\nGiven these complexities, we will reach out to neo4j for guidance. Specifically, we're interested in what restrictions neo4j's license places on our three use cases. And if there are restriction, could we obtain an educational or research license permitting our use?",
      "comment_id": 556,
      "profile_id": 17,
      "published": "2015-11-30T20:04:57.718617Z",
      "thread_id": 130,
      "url": "/discussion/licensing-neo4j/130"
    },
    {
      "body_html": "<h1>Concurrency for data science</h1>\r\n\r\n<p>Processors are now multicore and our code should take advantage of this opportunity. If execution time is not an issue, don't waste time optimizing. But if you find yourself waiting for your program to finish and your computation can be parallelized, look no further than <code>concurrent.futures</code>.</p>\r\n\r\n<p><code>concurrent.futures</code> gives you easy, no <a href=\"https://en.wikipedia.org/wiki/Boilerplate_code\">boilerplate</a>, access to the two methods of concurrency in python. The methods are:</p>\r\n\r\n<h2><a href=\"https://docs.python.org/3/library/threading.html\"><code>threading</code></a></h2>\r\n\r\n<p>Threads allow multiple paths of execution within a single program. Each thread has access to the global data space, which makes threads convenient for programming. However, proceed with caution: since a single object can be altered by multiple threads simultaneously, there is danger. Avoid the danger by using <a href=\"https://docs.python.org/3/library/threading.html#lock-objects\">locks</a> (via <a href=\"https://docs.python.org/3/library/threading.html#using-locks-conditions-and-semaphores-in-the-with-statement\"><code>with</code></a> for convenience) whenever a thread writes to a communal resource.</p>\r\n\r\n<p>The main drawback of threading is the global interpreter lock (<a href=\"https://docs.python.org/3/glossary.html#term-global-interpreter-lock\">GIL</a>) meaning that \"only one thread can execute Python code at once.\" Therefore, if you want to reap the benefits of multiple cores, you need to make sure your code isn't limited by the GIL. You can escape the GIL by moving the time intensive computations outside of python by:</p>\r\n\r\n<ol><li>Using code written in other languages such as C. Many functions implement their core features outside of python. Additionally, many operations rely on external resources such as database or web queries.</li><li>Using <a href=\"http://numba.pydata.org/\"><code>numba</code></a> to automatically compile your code with the <a href=\"http://numba.pydata.org/numba-doc/0.21.0/user/jit.html#nogil\"><code>@numba.jit(nogil=True)</code></a> decorator.</li></ol>\r\n\r\n<h2><a href=\"https://docs.python.org/3/library/multiprocessing.html\"><code>multiprocessing</code></a></h2>\r\n\r\n<p>When your code isn't amenable to releasing the GIL, try multiprocessing. Multiprocessing spawns new python instances for each task. Therefore, any needed data must be serialized via pickling and dispatched to the subprocess. This creates large overhead. Try to send the minimum amount of data required for your application to each process to reduce this overhead.</p>\r\n\r\n<h2><a href=\"https://docs.python.org/3/library/concurrent.futures.html\"><code>concurrent.futures</code></a></h2>\r\n\r\n<p><code>concurrent.futures</code> provides a queue-based system for executing functions in parallel. To use, first initiate an Executor using <code>concurrent.futures.ThreadPoolExecutor()</code> for threading or <code>concurrent.futures.ProcessPoolExecutor()</code> for multiprocessing. Both constructors accept a <code>max_workers</code> argument for the maximum number of threads/processes you would like to devote to the task.</p>\r\n\r\n<p>You can interact with the Executor in the following ways:</p>\r\n\r\n<ul><li><code>Executor.submit()</code> which submits a <em>single</em> job to the queue</li><li><code>Executor.map()</code> which submits <em>many</em> jobs to the queue</li><li><code>Executor.shutdown()</code> which shuts down the executor. The default parameter <code>wait=True</code> means this method will wait for all jobs to finish before returning.</li></ul>\r\n\r\n<p>Cheers to a concurrent future!</p>",
      "body_md": "# Concurrency for data science\r\n\r\nProcessors are now multicore and our code should take advantage of this opportunity. If execution time is not an issue, don't waste time optimizing. But if you find yourself waiting for your program to finish and your computation can be parallelized, look no further than `concurrent.futures`.\r\n\r\n`concurrent.futures` gives you easy, no [boilerplate](https://en.wikipedia.org/wiki/Boilerplate_code), access to the two methods of concurrency in python. The methods are:\r\n\r\n## [`threading`](https://docs.python.org/3/library/threading.html)\r\n\r\nThreads allow multiple paths of execution within a single program. Each thread has access to the global data space, which makes threads convenient for programming. However, proceed with caution: since a single object can be altered by multiple threads simultaneously, there is danger. Avoid the danger by using [locks](https://docs.python.org/3/library/threading.html#lock-objects) (via [`with`](https://docs.python.org/3/library/threading.html#using-locks-conditions-and-semaphores-in-the-with-statement) for convenience) whenever a thread writes to a communal resource.\r\n\r\nThe main drawback of threading is the global interpreter lock ([GIL](https://docs.python.org/3/glossary.html#term-global-interpreter-lock)) meaning that \"only one thread can execute Python code at once.\" Therefore, if you want to reap the benefits of multiple cores, you need to make sure your code isn't limited by the GIL. You can escape the GIL by moving the time intensive computations outside of python by:\r\n\r\n1. Using code written in other languages such as C. Many functions implement their core features outside of python. Additionally, many operations rely on external resources such as database or web queries.\r\n2. Using [`numba`](http://numba.pydata.org/) to automatically compile your code with the [`@numba.jit(nogil=True)`](http://numba.pydata.org/numba-doc/0.21.0/user/jit.html#nogil) decorator.\r\n\r\n## [`multiprocessing`](https://docs.python.org/3/library/multiprocessing.html)\r\n\r\nWhen your code isn't amenable to releasing the GIL, try multiprocessing. Multiprocessing spawns new python instances for each task. Therefore, any needed data must be serialized via pickling and dispatched to the subprocess. This creates large overhead. Try to send the minimum amount of data required for your application to each process to reduce this overhead.\r\n\r\n## [`concurrent.futures`](https://docs.python.org/3/library/concurrent.futures.html)\r\n\r\n`concurrent.futures` provides a queue-based system for executing functions in parallel. To use, first initiate an Executor using `concurrent.futures.ThreadPoolExecutor()` for threading or `concurrent.futures.ProcessPoolExecutor()` for multiprocessing. Both constructors accept a `max_workers` argument for the maximum number of threads/processes you would like to devote to the task.\r\n\r\nYou can interact with the Executor in the following ways:\r\n\r\n+ `Executor.submit()` which submits a *single* job to the queue\r\n+ `Executor.map()` which submits *many* jobs to the queue\r\n+ `Executor.shutdown()` which shuts down the executor. The default parameter `wait=True` means this method will wait for all jobs to finish before returning.\r\n\r\nCheers to a concurrent future!",
      "comment_id": 566,
      "profile_id": 17,
      "published": "2015-12-02T23:01:57.635743Z",
      "thread_id": 84,
      "url": "/discussion/python-for-the-modern-biodata-scientist/84#6"
    },
    {
      "body_html": "<p>Our algorithm relies on extracting paths of a certain type (metapath) between a source and target node. For our previous project where we predicted gene–disease associations, we placed two restrictions on paths <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1004259\">1</a>]</span>:</p>\r\n\r\n<blockquote><p>paths with duplicate nodes were excluded, and, if present, the association edge between the source gene and target disease was masked.</p></blockquote>\r\n\r\n<p>However, since <a href=\"http://thinklab.com/discussion/using-the-neo4j-graph-database-for-hetnets/112\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d112\">migrating to neo4j</a>, we have not added extra path restrictions beyond the builtin restriction that paths cannot contain duplicate relationships.</p>\r\n\r\n<p>So in total, we have relied on three different conditions for excluding a path:</p>\r\n\r\n<ol><li>duplicated nodes</li><li>duplicated edges</li><li>contains the prediction edge</li></ol>\r\n\r\n<p>It turns out that 1 implies 2 and 3 (1 ⇒ 2, 1 ⇒ 3). In other words, when we exclude paths with duplicate nodes, we also exclude paths with duplicate edges. And since we omit the length-one metapath that is simply the metaedge being modeled, all paths containing the prediction edge will contain either the source or target node at least twice.</p>\r\n\r\n<p>You may have noticed above that for hetio-dag <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1004259\">1</a>]</span>, we masked the prediction edge if present. Masking an edge temporarily removes it from the network. Masking the prediction edge not only eliminates paths containing that edge, but also can affect path degrees, which go into the <em>DWPC</em> (degree-weighted path count).</p>\r\n\r\n<p>This discussion will focus on identifying the most sensible path restrictions and whether masking is warranted.</p>",
      "body_md": "Our algorithm relies on extracting paths of a certain type (metapath) between a source and target node. For our previous project where we predicted gene--disease associations, we placed two restrictions on paths [@10.1371/journal.pcbi.1004259]:\r\n\r\n> paths with duplicate nodes were excluded, and, if present, the association edge between the source gene and target disease was masked.\r\n\r\nHowever, since [migrating to neo4j](http://thinklab.com/discussion/using-the-neo4j-graph-database-for-hetnets/112), we have not added extra path restrictions beyond the builtin restriction that paths cannot contain duplicate relationships.\r\n\r\nSo in total, we have relied on three different conditions for excluding a path:\r\n\r\n1. duplicated nodes\r\n2. duplicated edges\r\n3. contains the prediction edge\r\n\r\nIt turns out that 1 implies 2 and 3 (1 ⇒ 2, 1 ⇒ 3). In other words, when we exclude paths with duplicate nodes, we also exclude paths with duplicate edges. And since we omit the length-one metapath that is simply the metaedge being modeled, all paths containing the prediction edge will contain either the source or target node at least twice.\r\n\r\nYou may have noticed above that for hetio-dag [@10.1371/journal.pcbi.1004259], we masked the prediction edge if present. Masking an edge temporarily removes it from the network. Masking the prediction edge not only eliminates paths containing that edge, but also can affect path degrees, which go into the *DWPC* (degree-weighted path count).\r\n\r\nThis discussion will focus on identifying the most sensible path restrictions and whether masking is warranted.",
      "comment_id": 571,
      "profile_id": 17,
      "published": "2015-12-09T02:51:40.932445Z",
      "thread_id": 134,
      "url": "/discussion/path-exclusion-conditions/134"
    },
    {
      "body_html": "<h1>Cypher implementations of duplicate node exclusion</h1>\r\n\r\n<p>With help from Christophe Willemsen, <a href=\"/u/alizee\" class=\"username\">@alizee</a> and I <a href=\"https://twitter.com/dhimmel/status/674487386949087232\">identified</a> two methods for excluding paths with duplicate nodes in a Cypher query.</p>\r\n\r\n<p>We <a href=\"https://github.com/dhimmel/hetio/commit/f6deae3294c1d90ba9ba92153c91a40791d4ae8d\">implemented</a> both methods. Here, we'll describe them in the context of a length-four path matched using <code>MATCH paths = (n0)--(n1)--(n2)--(n3)--(n4)</code>.</p>\r\n\r\n<p>The <strong>nested</strong> method adds a <code>WHERE</code> clause specifying:</p>\r\n\r\n<pre><code class=\"no-highlight hljs\">ALL (x IN nodes(paths) WHERE size(filter(z IN nodes(paths) WHERE z = x)) = 1)</code></pre>\r\n\r\n<p>This method uses <a href=\"http://neo4j.com/docs/2.3.1/syntax-collections.html#_list_comprehension\">list comprehension</a> to iterate over each node in a path and ensure that it only occurs once. This clause can be applied to paths of any length and does not require assigning nodes to identifiers.</p>\r\n\r\n<p>The <strong>expanded</strong> method adds a <code>WHERE</code> clause specifying:</p>\r\n\r\n<pre><code class=\"no-highlight hljs\">NOT (n0=n1 OR n0=n2 OR n0=n3 OR n0=n4 OR n1=n2 OR n1=n3 OR n1=n4 OR n2=n3 OR n2=n4 OR n3=n4)</code></pre>\r\n\r\n<p>The method checks that no two nodes are equal by explicitly evaluating all combinations of two nodes. The method requires assigning node identifiers and is path-length dependent. However, it is intuitive and amenable to query plan optimization since filtering can be front-loaded to avoid expanding on illegitimate paths.</p>\r\n\r\n<h2>Alternative implementations</h2>\r\n\r\n<p>Another general solution would be to check whether the number of distinct nodes equals the length of the full path. We currently are unaware of a Cypher implementation for this <strong>distinct</strong> method, but <a href=\"https://twitter.com/A_Lizee/status/674655287899348992\">suspect</a> it could scale to longer paths better than the nested method.</p>\r\n\r\n<p>One final variant of the expanded method, called <strong>labeled</strong>, would avoid comparing nodes with different labels, as these nodes are implicitly different. This method requires the greatest <em>a priori</em> knowledge of path characteristics.</p>",
      "body_md": "# Cypher implementations of duplicate node exclusion\r\n\r\nWith help from Christophe Willemsen, @alizee and I [identified](https://twitter.com/dhimmel/status/674487386949087232) two methods for excluding paths with duplicate nodes in a Cypher query.\r\n\r\nWe [implemented](https://github.com/dhimmel/hetio/commit/f6deae3294c1d90ba9ba92153c91a40791d4ae8d) both methods. Here, we'll describe them in the context of a length-four path matched using `MATCH paths = (n0)--(n1)--(n2)--(n3)--(n4)`.\r\n\r\nThe **nested** method adds a `WHERE` clause specifying:\r\n\r\n```\r\nALL (x IN nodes(paths) WHERE size(filter(z IN nodes(paths) WHERE z = x)) = 1)\r\n```\r\n\r\nThis method uses [list comprehension](http://neo4j.com/docs/2.3.1/syntax-collections.html#_list_comprehension) to iterate over each node in a path and ensure that it only occurs once. This clause can be applied to paths of any length and does not require assigning nodes to identifiers.\r\n\r\nThe **expanded** method adds a `WHERE` clause specifying:\r\n\r\n```\r\nNOT (n0=n1 OR n0=n2 OR n0=n3 OR n0=n4 OR n1=n2 OR n1=n3 OR n1=n4 OR n2=n3 OR n2=n4 OR n3=n4)\r\n```\r\n\r\nThe method checks that no two nodes are equal by explicitly evaluating all combinations of two nodes. The method requires assigning node identifiers and is path-length dependent. However, it is intuitive and amenable to query plan optimization since filtering can be front-loaded to avoid expanding on illegitimate paths.\r\n\r\n## Alternative implementations\r\n\r\nAnother general solution would be to check whether the number of distinct nodes equals the length of the full path. We currently are unaware of a Cypher implementation for this **distinct** method, but [suspect](https://twitter.com/A_Lizee/status/674655287899348992) it could scale to longer paths better than the nested method.\r\n\r\nOne final variant of the expanded method, called **labeled**, would avoid comparing nodes with different labels, as these nodes are implicitly different. This method requires the greatest *a priori* knowledge of path characteristics.",
      "comment_id": 572,
      "profile_id": 17,
      "published": "2015-12-13T23:30:33.944307Z",
      "thread_id": 134,
      "url": "/discussion/path-exclusion-conditions/134#2"
    },
    {
      "body_html": "<h1>Optimization dataset</h1>\r\n\r\n<p>To help optimize our cypher queries, we computed features for 347 positives and 317 negatives for the 1979 metapaths with length ≤ 4 (<a href=\"https://github.com/dhimmel/learn/blob/5d932818e58963b4f5ae5095294853f5bafbe729/unique-nodes/unique-nodes-extract.ipynb\">notebook</a>, <a href=\"https://github.com/dhimmel/learn/blob/5d932818e58963b4f5ae5095294853f5bafbe729/unique-nodes/dwpc.tsv.gz\">features</a>). Positives were randomly selected indications, while negatives were randomly selected non-indications. We computed the <em>PC</em> (path count) and <em>DWPC</em> for each compound–disease–metapath combination using each of three node uniqueness methods described <a href=\"#2\">above</a>. In addition, we computed features without excluding duplicate nodes.</p>\r\n\r\n<h1>Runtimes for duplicate node exclusions</h1>\r\n\r\n<p>We compared the average query runtime for each node uniqueness method (<a href=\"https://github.com/dhimmel/learn/blob/5d932818e58963b4f5ae5095294853f5bafbe729/unique-nodes/runtime-comparison.ipynb\">notebook</a>):</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th><code>unique_nodes</code> method</th><th>average query runtime</th><th>runtime_hit</th></tr></thead><tbody><tr><td><code>False</code></td><td>129.41 ms</td><td>0.0%</td></tr><tr><td><code>labeled</code></td><td>143.56 ms</td><td>10.9%</td></tr><tr><td><code>expanded</code></td><td>173.43 ms</td><td>34.0%</td></tr><tr><td><code>nested</code></td><td>179.76 ms</td><td>38.9%</td></tr></tbody></table>\r\n\r\n<p>We found that not performing any duplicate node exclusion was fastest. The most efficient method for exclusion was <code>labeled</code>, which explicitly checks that node pairs of the same label are not duplicates. This method only slowed down runtime by 11%, a very acceptable hit.</p>\r\n\r\n<p>The <code>nested</code> method was on average slightly slower than <code>expanded</code>. However, in the overwhelming majority of instances, <code>nested</code> was faster than <code>expected</code>, yet poor worst case runtime pushed <code>nested</code> to last place. This observation underscores the vast asymmetry in runtimes: most queries finish quickly, while a small percentage of queries form a long tail that contributes disproportionately to overall runtime.</p>\r\n\r\n<p>Remember that these findings are highly context-dependent. Here they are in the context of a subset of queries chosen to be representative of our specific HNEP (hetnet edge prediction) task.</p>\r\n\r\n<p>In conclusion, if excluding paths with duplicate nodes is desired, we will use the <code>labeled</code> method.</p>",
      "body_md": "# Optimization dataset\r\n\r\nTo help optimize our cypher queries, we computed features for 347 positives and 317 negatives for the 1979 metapaths with length ≤ 4 ([notebook](https://github.com/dhimmel/learn/blob/5d932818e58963b4f5ae5095294853f5bafbe729/unique-nodes/unique-nodes-extract.ipynb), [features](https://github.com/dhimmel/learn/blob/5d932818e58963b4f5ae5095294853f5bafbe729/unique-nodes/dwpc.tsv.gz)). Positives were randomly selected indications, while negatives were randomly selected non-indications. We computed the *PC* (path count) and *DWPC* for each compound--disease--metapath combination using each of three node uniqueness methods described [above](#2). In addition, we computed features without excluding duplicate nodes.\r\n\r\n# Runtimes for duplicate node exclusions\r\n\r\nWe compared the average query runtime for each node uniqueness method ([notebook](https://github.com/dhimmel/learn/blob/5d932818e58963b4f5ae5095294853f5bafbe729/unique-nodes/runtime-comparison.ipynb)):\r\n\r\n| `unique_nodes` method | average query runtime | runtime_hit |\r\n|---------------------|--------------------|---------------|\r\n| `False` | 129.41 ms | 0.0% |\r\n| `labeled` | 143.56 ms | 10.9% |\r\n| `expanded` | 173.43 ms | 34.0% |\r\n| `nested` | 179.76 ms | 38.9% |\r\n\r\nWe found that not performing any duplicate node exclusion was fastest. The most efficient method for exclusion was `labeled`, which explicitly checks that node pairs of the same label are not duplicates. This method only slowed down runtime by 11%, a very acceptable hit.\r\n\r\nThe `nested` method was on average slightly slower than `expanded`. However, in the overwhelming majority of instances, `nested` was faster than `expected`, yet poor worst case runtime pushed `nested` to last place. This observation underscores the vast asymmetry in runtimes: most queries finish quickly, while a small percentage of queries form a long tail that contributes disproportionately to overall runtime.\r\n\r\nRemember that these findings are highly context-dependent. Here they are in the context of a subset of queries chosen to be representative of our specific HNEP (hetnet edge prediction) task.\r\n\r\nIn conclusion, if excluding paths with duplicate nodes is desired, we will use the `labeled` method.",
      "comment_id": 575,
      "profile_id": 17,
      "published": "2015-12-15T19:46:16.116618Z",
      "thread_id": 134,
      "url": "/discussion/path-exclusion-conditions/134#3"
    },
    {
      "body_html": "<h1>The effect of duplicate node exclusion on features</h1>\r\n\r\n<p><a href=\"#3\">Above</a>, we described computing features for 664 compound–disease pairs × 1,979 metapaths. In this comment, we'll investigate the effect of excluding paths with duplicate nodes on this dataset.</p>\r\n\r\n<p>Paths without the unique node constraint are still subject to neo4j's unique relationship constraint. In essence, the node uniqueness constraint determines whether paths containing a cycle are permitted.</p>\r\n\r\n<p>As <a href=\"#1\">previously discussed</a> the node uniqueness constraint also excludes paths containing the prediction edge. In our case, the prediction edge is an indication between the source compound and target disease.</p>\r\n\r\n<p>Therefore, feature performance could decline after applying the unique constraint because:</p>\r\n\r\n<ol><li>paths with cycles convey meaningful information that the unique node constraint overlooks</li><li>paths including the prediction edge cause overfitting by incorporating the outcome (indication status) into the predictor (<em>DWPC</em>)</li></ol>\r\n\r\n<p>For the 1,961 features that contained a duplicate metanode, we calculated the decline in AUROC of the <em>DWPC</em> resulting from duplicate node exclusion (<a href=\"http://nbviewer.ipython.org/github/dhimmel/learn/blob/2eb24875c5dc5d1017b0eaa6759562fc38c33e7c/unique-nodes/feature-comparison.ipynb\">notebook</a>, <a href=\"https://github.com/dhimmel/learn/blob/2eb24875c5dc5d1017b0eaa6759562fc38c33e7c/unique-nodes/metapaths.tsv\">table</a>). We investigated the occurrence of 1 and 2 by segregating metapaths based on whether they include an indication metaedge. If a metapath doesn't include an indication metaedge, then any change in performance must be due to 1. The distributions of AUROC declines identify 2 (overfitting) as a major factor, while showing 1 is at most a very minor factor.</p>\r\n\r\n<p><img src=\"https://raw.githubusercontent.com/dhimmel/learn/2eb24875c5dc5d1017b0eaa6759562fc38c33e7c/unique-nodes/AUROC-violins.png\" alt=\"\"></p>\r\n\r\n<h2>Conclusion</h2>\r\n\r\n<p>Therefore, we will adopt the unique node constraint because it omits paths that include the prediction edge, which leads to overfitting. Absent their potential for overfitting, paths with duplicate nodes did not contribute greatly to <em>DWPC</em> performance. Finally, paths that are excluded because they contain a cycle will still be incorporated into <em>DWPCs</em> for shorter metapaths that bypass the cyclical segment.</p>",
      "body_md": "# The effect of duplicate node exclusion on features \r\n\r\n[Above](#3), we described computing features for 664 compound--disease pairs × 1,979 metapaths. In this comment, we'll investigate the effect of excluding paths with duplicate nodes on this dataset.\r\n\r\nPaths without the unique node constraint are still subject to neo4j's unique relationship constraint. In essence, the node uniqueness constraint determines whether paths containing a cycle are permitted.\r\n\r\nAs [previously discussed](#1) the node uniqueness constraint also excludes paths containing the prediction edge. In our case, the prediction edge is an indication between the source compound and target disease.\r\n\r\nTherefore, feature performance could decline after applying the unique constraint because:\r\n\r\n1. paths with cycles convey meaningful information that the unique node constraint overlooks\r\n2. paths including the prediction edge cause overfitting by incorporating the outcome (indication status) into the predictor (*DWPC*)\r\n\r\nFor the 1,961 features that contained a duplicate metanode, we calculated the decline in AUROC of the *DWPC* resulting from duplicate node exclusion ([notebook](http://nbviewer.ipython.org/github/dhimmel/learn/blob/2eb24875c5dc5d1017b0eaa6759562fc38c33e7c/unique-nodes/feature-comparison.ipynb), [table](https://github.com/dhimmel/learn/blob/2eb24875c5dc5d1017b0eaa6759562fc38c33e7c/unique-nodes/metapaths.tsv)). We investigated the occurrence of 1 and 2 by segregating metapaths based on whether they include an indication metaedge. If a metapath doesn't include an indication metaedge, then any change in performance must be due to 1. The distributions of AUROC declines identify 2 (overfitting) as a major factor, while showing 1 is at most a very minor factor.\r\n\r\n![](https://raw.githubusercontent.com/dhimmel/learn/2eb24875c5dc5d1017b0eaa6759562fc38c33e7c/unique-nodes/AUROC-violins.png)\r\n\r\n## Conclusion\r\n\r\nTherefore, we will adopt the unique node constraint because it omits paths that include the prediction edge, which leads to overfitting. Absent their potential for overfitting, paths with duplicate nodes did not contribute greatly to *DWPC* performance. Finally, paths that are excluded because they contain a cycle will still be incorporated into *DWPCs* for shorter metapaths that bypass the cyclical segment.",
      "comment_id": 578,
      "profile_id": 17,
      "published": "2015-12-21T19:20:05.708973Z",
      "thread_id": 134,
      "url": "/discussion/path-exclusion-conditions/134#4"
    },
    {
      "body_html": "<p>Network permutation randomizes edges in a graph to remove signal. Metrics computed on permuted networks provide a baseline to evaluate the extent of signal contained in the network. Different types of permutations destroy different aspects of the information encoded by a network.</p>\r\n\r\n<p>The method we've <a href=\"https://doi.org/10.1371/journal.pcbi.1004259#article1.body1.sec2.sec6.p1\">previously used</a> selects two random edges and swaps the endpoints (labeled <code>XSwap</code> in <span class=\"citation\">[<a href=\"https://doi.org/10.1137/1.9781611972795.67\" class=\"citation\" data-key=\"10.1137/1.9781611972795.67\">1</a>]</span>). This method preserves node degree while destroying edge specificity.</p>\r\n\r\n<p>We <a href=\"https://github.com/dhimmel/hetio/blob/1aa1964f92881c54da652cda0c1162ee6e4664b9/hetio/permute.py\">adapted</a> the edge swapping technique to hetnets by permuting each metaedge separately—edges are only swapped with other edges of the same type. We found the permutation yielded valuable insights on which aspects of the network were informative and the quality of our predictions <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1004259\">2</a>]</span>.</p>\r\n\r\n<p>We've subsequently <a href=\"http://thinklab.com/discussion/using-the-neo4j-graph-database-for-hetnets/112\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d112\">migrated</a> to neo4j, so are now looking to implement hetnet permutation in cypher. We <a href=\"https://twitter.com/dhimmel/status/677260913200644096\">tweeted</a> this problem, and Michael Hunger <a href=\"http://jexp.github.io/graphgist/?dropbox-14493611%2Fedge_swap_cypher.adoc\">started</a> us on the right track.</p>\r\n\r\n<p>We created a <a href=\"http://portal.graphgist.org/graph_gists/by_url?url=https://gist.github.com/dhimmel/f69730d8bdfb880c15ed/6663d64be53e5b8c438d0a2d55a5778676ccf0b1\">graphgist</a> with potential implementations and cypher questions.</p>",
      "body_md": "Network permutation randomizes edges in a graph to remove signal. Metrics computed on permuted networks provide a baseline to evaluate the extent of signal contained in the network. Different types of permutations destroy different aspects of the information encoded by a network.\r\n\r\nThe method we've [previously used](https://doi.org/10.1371/journal.pcbi.1004259#article1.body1.sec2.sec6.p1) selects two random edges and swaps the endpoints (labeled `XSwap` in [@10.1137/1.9781611972795.67]). This method preserves node degree while destroying edge specificity.\r\n\r\nWe [adapted](https://github.com/dhimmel/hetio/blob/1aa1964f92881c54da652cda0c1162ee6e4664b9/hetio/permute.py) the edge swapping technique to hetnets by permuting each metaedge separately---edges are only swapped with other edges of the same type. We found the permutation yielded valuable insights on which aspects of the network were informative and the quality of our predictions [@10.1371/journal.pcbi.1004259].\r\n\r\nWe've subsequently [migrated](http://thinklab.com/discussion/using-the-neo4j-graph-database-for-hetnets/112) to neo4j, so are now looking to implement hetnet permutation in cypher. We [tweeted](https://twitter.com/dhimmel/status/677260913200644096) this problem, and Michael Hunger [started](http://jexp.github.io/graphgist/?dropbox-14493611%2Fedge_swap_cypher.adoc) us on the right track.\r\n\r\nWe created a [graphgist](http://portal.graphgist.org/graph_gists/by_url?url=https://gist.github.com/dhimmel/f69730d8bdfb880c15ed/6663d64be53e5b8c438d0a2d55a5778676ccf0b1) with potential implementations and cypher questions.",
      "comment_id": 584,
      "profile_id": 17,
      "published": "2015-12-22T01:25:50.982403Z",
      "thread_id": 136,
      "url": "/discussion/permuting-hetnets-and-implementing-randomized-edge-swaps-in-cypher/136"
    },
    {
      "body_html": "<h1>Official adoption of 'hetnet'</h1>\r\n\r\n<p>For the past four months, I have been widely using the term 'hetnet'. I now rarely use the term 'heterogeneous network'. If I think an audience will be unfamiliar with my usage, I'll clarify by saying \"a network with multiple types of nodes or edges\". Even when I don't explicitly define the term, unfamiliar recipients seem to instinctively understand the concept. And perhaps most importantly, I haven't encountered any objections. Hence, our adoption of hetnet is now official.</p>\r\n\r\n<p>In the spirit of this announcement, we'll be changing our project's title from \"Repurposing drugs on a heterogeneous network\" to \"Repurposing drugs on a hetnet\".</p>\r\n\r\n<p>Meanwhile, the community continues to use an assortment of terms to express the concept. For example, a recent study used the \"multiplex network\" <span class=\"citation\">[<a href=\"https://doi.org/10.7717/peerj.1525\" class=\"citation\" data-key=\"10.7717/peerj.1525\">1</a>]</span>. The field appears ripe for standardized terminology to emerge.</p>",
      "body_md": "# Official adoption of 'hetnet'\r\n\r\nFor the past four months, I have been widely using the term 'hetnet'. I now rarely use the term 'heterogeneous network'. If I think an audience will be unfamiliar with my usage, I'll clarify by saying \"a network with multiple types of nodes or edges\". Even when I don't explicitly define the term, unfamiliar recipients seem to instinctively understand the concept. And perhaps most importantly, I haven't encountered any objections. Hence, our adoption of hetnet is now official.\r\n\r\nIn the spirit of this announcement, we'll be changing our project's title from \"Repurposing drugs on a heterogeneous network\" to \"Repurposing drugs on a hetnet\".\r\n\r\nMeanwhile, the community continues to use an assortment of terms to express the concept. For example, a recent study used the \"multiplex network\" [@10.7717/peerj.1525]. The field appears ripe for standardized terminology to emerge.",
      "comment_id": 585,
      "profile_id": 17,
      "published": "2016-01-28T01:39:58.688429Z",
      "thread_id": 104,
      "url": "/discussion/renaming-heterogeneous-networks-to-a-more-concise-and-catchy-term/104#5"
    },
    {
      "body_html": "<h1>Partial Cypher solutions</h1>\r\n\r\n<p>We've made some headway implementing <code>XSwap</code> in Cypher. But first, here's the general algorithm we're aiming for:</p>\r\n\r\n<ol><li>Randomly select two relationships of the specified type</li><li>If valid, XSwap the two relationships</li><li>Repeat 1 and 2 until a certain number of swaps have succeeded</li></ol>\r\n\r\n<p>We <a href=\"https://gist.github.com/dhimmel/f69730d8bdfb880c15ed#gistcomment-1657527\">initially attempted</a> to implement the above steps in a single cypher query. However, as Michael Hunger <a href=\"https://gist.github.com/dhimmel/f69730d8bdfb880c15ed#gistcomment-1662589\">explained</a>, the eagerness behavior of cypher prevents looping 1 and 2. Instead of <code>1, 2, 1, 2, 1, 2</code>, cypher will do <code>1, 1, 1, 2, 2, 2</code>, which fails because our technique randomizes iteratively.</p>\r\n\r\n<p>Therefore, we switched to python for managing steps 1 and 3, while keeping step 2 in cypher. This external method is now <a href=\"https://github.com/dhimmel/hetio/blob/9facc4bd609d536e733c5297f76a75f8123dc042/hetio/neo4j.py#L257\">implemented in hetio</a>. The function starts by retrieving the ids for all relationships of the specified type. Next, iteration begins:</p>\r\n\r\n<ol><li>Two relationships ids are randomly selected and sent as parameters to a cypher query.</li><li>If the swap is invalid, the cypher query returns no rows. Otherwise, the query returns the ids for the two created relationships and the python id list is updated.</li></ol>\r\n\r\n<p>There are two outstanding issues with this method:</p>\r\n\r\n<p>First, retrieving ids for all relationships of a given type could become problematic for extremely abundant relationship types. Currently this is not a problem as we can retrieve over 1 million ids using py2neo without failure. If problematic, we could create an identity property to each relationship with an existence constraint for efficient lookup. Indexed property values are a practical must for this solution, yet are <a href=\"https://gist.github.com/dhimmel/f69730d8bdfb880c15ed#gistcomment-1655807\">currently</a> only available with Enterprise.</p>\r\n\r\n<p>Second, the rule planner in 2.3.1 does not do an indexed lookup of relationship by id—instead it scans all relationships. The cost planner works as desired with a <code>DirectedRelationshipByIdSeekPipe</code>. However the 2.3.1 cost planner doesn't support write operations (3.0 is <a href=\"https://github.com/neo4j/neo4j/wiki/Neo4j-3.0-changelog#300-m01\">slated to add</a> this functionality).</p>\r\n\r\n<p>So in conclusion, we are close to a workable solution for permuting a neo4j hetnet. Depending on developments, we'll choose whether to adopt a solution discussed here or permute outside of neo4j with the legacy <a href=\"https://github.com/dhimmel/hetio/blob/1aa1964f92881c54da652cda0c1162ee6e4664b9/hetio/permute.py\">hetio functionality</a>.</p>",
      "body_md": "# Partial Cypher solutions\r\n\r\nWe've made some headway implementing `XSwap` in Cypher. But first, here's the general algorithm we're aiming for:\r\n\r\n1. Randomly select two relationships of the specified type\r\n2. If valid, XSwap the two relationships\r\n3. Repeat 1 and 2 until a certain number of swaps have succeeded\r\n\r\nWe [initially attempted](https://gist.github.com/dhimmel/f69730d8bdfb880c15ed#gistcomment-1657527) to implement the above steps in a single cypher query. However, as Michael Hunger [explained](https://gist.github.com/dhimmel/f69730d8bdfb880c15ed#gistcomment-1662589), the eagerness behavior of cypher prevents looping 1 and 2. Instead of `1, 2, 1, 2, 1, 2`, cypher will do `1, 1, 1, 2, 2, 2`, which fails because our technique randomizes iteratively.\r\n\r\nTherefore, we switched to python for managing steps 1 and 3, while keeping step 2 in cypher. This external method is now [implemented in hetio](https://github.com/dhimmel/hetio/blob/9facc4bd609d536e733c5297f76a75f8123dc042/hetio/neo4j.py#L257). The function starts by retrieving the ids for all relationships of the specified type. Next, iteration begins:\r\n\r\n1. Two relationships ids are randomly selected and sent as parameters to a cypher query.\r\n2. If the swap is invalid, the cypher query returns no rows. Otherwise, the query returns the ids for the two created relationships and the python id list is updated.\r\n\r\nThere are two outstanding issues with this method:\r\n\r\nFirst, retrieving ids for all relationships of a given type could become problematic for extremely abundant relationship types. Currently this is not a problem as we can retrieve over 1 million ids using py2neo without failure. If problematic, we could create an identity property to each relationship with an existence constraint for efficient lookup. Indexed property values are a practical must for this solution, yet are [currently](https://gist.github.com/dhimmel/f69730d8bdfb880c15ed#gistcomment-1655807) only available with Enterprise.\r\n\r\nSecond, the rule planner in 2.3.1 does not do an indexed lookup of relationship by id---instead it scans all relationships. The cost planner works as desired with a `DirectedRelationshipByIdSeekPipe`. However the 2.3.1 cost planner doesn't support write operations (3.0 is [slated to add](https://github.com/neo4j/neo4j/wiki/Neo4j-3.0-changelog#300-m01) this functionality).\r\n\r\nSo in conclusion, we are close to a workable solution for permuting a neo4j hetnet. Depending on developments, we'll choose whether to adopt a solution discussed here or permute outside of neo4j with the legacy [hetio functionality](https://github.com/dhimmel/hetio/blob/1aa1964f92881c54da652cda0c1162ee6e4664b9/hetio/permute.py).",
      "comment_id": 586,
      "profile_id": 17,
      "published": "2016-01-06T19:17:34.818794Z",
      "thread_id": 136,
      "url": "/discussion/permuting-hetnets-and-implementing-randomized-edge-swaps-in-cypher/136#2"
    },
    {
      "body_html": "<h1>Licensing and usage options</h1>\r\n\r\n<p><a href=\"http://neo4j.com/blog/contributor/trey-knowles/\">Trey Knowles</a>, the Startup Community Manager at Neo Technology, assisted us with our licensing questions.</p>\r\n\r\n<p>To clarify the situation, we specified four licensing options:</p>\r\n\r\n<p>A. Community edition with the default GPLv3 license<br>B. Community edition with a contractual education license<br>C. Enterprise edition with the default AGPLv3 license<br>D. Enterprise edition with a contractual education license</p>\r\n\r\n<p>And then we specified four desired uses of Neo4j for our project:</p>\r\n\r\n<ol><li>distribute the neo4j binaries with our network preloaded</li><li>run internal database queries</li><li>make a publicly-accessible neo4j server instance</li><li>release all of our code and data as CC0</li></ol>\r\n\r\n<p>Trey provided the following answer, reproduced here with permission, on which of our desired uses are allowed by each license:</p>\r\n\r\n<blockquote><p>A. Community edition with the default GPLv3 license</p><ul><li>2 (single server, no clustering / live backups) </li><li>3 (single server, no clustering / live backups) </li><li>4 </li></ul><p>B. Community edition with a contractual education license</p><ul><li>Neo Technology offers no contracts with respect to CE</li></ul><p>C. Enterprise edition with the default AGPLv3 license</p><ul><li>1 provided you license your work as AGPLv3</li><li>2 provided you license your work as AGPLv3</li><li>3 provided you license your work as AGPLv3</li><li>4 provided you license your work as AGPLv3</li></ul><p>D. Enterprise edition with a contractual education license</p><ul><li>1</li><li>2</li><li>3</li><li>4<em> </em>(pending legal review from Neo team)</li></ul></blockquote>\r\n\r\n<p>Since AGPLv3 would place undesirable restrictions on our work compared to CC0, C is not a good option for us. Therefore, we'll choose between A and D. We will default to A (GPLv3-licensed community edition) unless enterprise features are needed in which case we'll explore D (contractually-licensed enterprise edition). Sticking with the community edition whenever possible will lessen the burden on anyone wanting to replicate or reuse or work.</p>",
      "body_md": "# Licensing and usage options\r\n\r\n[Trey Knowles](http://neo4j.com/blog/contributor/trey-knowles/), the Startup Community Manager at Neo Technology, assisted us with our licensing questions.\r\n\r\nTo clarify the situation, we specified four licensing options:\r\n\r\nA. Community edition with the default GPLv3 license\r\nB. Community edition with a contractual education license\r\nC. Enterprise edition with the default AGPLv3 license\r\nD. Enterprise edition with a contractual education license\r\n\r\nAnd then we specified four desired uses of Neo4j for our project:\r\n \r\n1. distribute the neo4j binaries with our network preloaded\r\n2. run internal database queries\r\n3. make a publicly-accessible neo4j server instance\r\n4. release all of our code and data as CC0\r\n\r\nTrey provided the following answer, reproduced here with permission, on which of our desired uses are allowed by each license:\r\n\r\n> A. Community edition with the default GPLv3 license\r\n>\r\n+ 2 (single server, no clustering / live backups) \r\n+ 3 (single server, no clustering / live backups) \r\n+ 4 \r\n\r\n> B. Community edition with a contractual education license\r\n>\r\n+ Neo Technology offers no contracts with respect to CE\r\n\r\n> C. Enterprise edition with the default AGPLv3 license\r\n>\r\n+ 1 provided you license your work as AGPLv3\r\n+ 2 provided you license your work as AGPLv3\r\n+ 3 provided you license your work as AGPLv3\r\n+ 4 provided you license your work as AGPLv3\r\n\r\n> D. Enterprise edition with a contractual education license\r\n>\r\n+ 1\r\n+ 2\r\n+ 3\r\n+ 4* *(pending legal review from Neo team)\r\n\r\nSince AGPLv3 would place undesirable restrictions on our work compared to CC0, C is not a good option for us. Therefore, we'll choose between A and D. We will default to A (GPLv3-licensed community edition) unless enterprise features are needed in which case we'll explore D (contractually-licensed enterprise edition). Sticking with the community edition whenever possible will lessen the burden on anyone wanting to replicate or reuse or work.",
      "comment_id": 587,
      "profile_id": 17,
      "published": "2016-01-11T19:57:18.731078Z",
      "thread_id": 130,
      "url": "/discussion/licensing-neo4j/130#2"
    },
    {
      "body_html": "<h1>Results from first two curators</h1>\r\n\r\n<p>The curations from <a href=\"https://github.com/dhimmel/indications/blob/2e4d9be7ef911e48fdd10d99628b22098010d935/curation/ajg/curation-AJG.tsv\" title=\"Ari Green's classifications\">AJG</a> and <a href=\"https://github.com/dhimmel/indications/blob/2e4d9be7ef911e48fdd10d99628b22098010d935/curation/csh/curation-CSH.csv\" title=\"Christine Hessler classifications\">CSH</a> (<a href=\"/u/chrissyhessler\" class=\"username\">@chrissyhessler</a>) are in. Both curators went through and classified each of the 1,388 compound–disease pairs. The breakdown of their classifications are as follows:</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>class</th><th>AJG</th><th>CSH</th><th>AJG (as %)</th><th>CSH (as %)</th></tr></thead><tbody><tr><td>DM</td><td>599</td><td>593</td><td>43.2%</td><td>42.7%</td></tr><tr><td>SYM</td><td>514</td><td>517</td><td>37.0%</td><td>37.2%</td></tr><tr><td>NOT</td><td>275</td><td>278</td><td>19.8%</td><td>20.0%</td></tr></tbody></table>\r\n\r\n<p>Compared to the <a href=\"#3\">pilot</a>, the curators classified a higher percentage of pairs as non-indications, while classifying a lower percentage as disease-modifying. Similar to the pilot, the curators agreed 68.0% percent of the time. The Cohen's kappa coefficient <span class=\"citation\">[<a href=\"https://doi.org/10.1177/001316446002000104\" class=\"citation\" data-key=\"10.1177/001316446002000104\">1</a>, <a href=\"https://doi.org/10.11613/BM.2012.031\" class=\"citation\" data-key=\"10.11613/BM.2012.031\">2</a>]</span> between AJG and CSH was 49.9% (<a href=\"https://github.com/dhimmel/indications/blob/2e4d9be7ef911e48fdd10d99628b22098010d935/curation/tiebreaker-template.ipynb\">notebook</a>), indicating <a href=\"http://www.stfm.org/fmhub/fm2005/May/Anthony360.pdf#page=3\">moderate</a> agreement.</p>\r\n\r\n<p>Looking at only the 944 agreements, there were 447 disease-modifying, 351 symptomatic, and 146 non-indications. For the remaining <a href=\"https://github.com/dhimmel/indications/blob/2e4d9be7ef911e48fdd10d99628b22098010d935/curation/pk/template-pk.tsv\">444 disagreements</a>, we plan to have a third curator break the tie.</p>",
      "body_md": "# Results from first two curators\r\n\r\nThe curations from [AJG](https://github.com/dhimmel/indications/blob/2e4d9be7ef911e48fdd10d99628b22098010d935/curation/ajg/curation-AJG.tsv \"Ari Green's classifications\") and [CSH](https://github.com/dhimmel/indications/blob/2e4d9be7ef911e48fdd10d99628b22098010d935/curation/csh/curation-CSH.csv \"Christine Hessler classifications\") (@chrissyhessler) are in. Both curators went through and classified each of the 1,388 compound--disease pairs. The breakdown of their classifications are as follows:\r\n\r\n| class | AJG | CSH | AJG (as %) | CSH (as %) |\r\n|-------|-----|-----|------------|------------|\r\n| DM | 599 | 593 | 43.2% | 42.7% |\r\n| SYM | 514 | 517 | 37.0% | 37.2% |\r\n| NOT | 275 | 278 | 19.8% | 20.0% |\r\n\r\nCompared to the [pilot](#3), the curators classified a higher percentage of pairs as non-indications, while classifying a lower percentage as disease-modifying. Similar to the pilot, the curators agreed 68.0% percent of the time. The Cohen's kappa coefficient [@10.1177/001316446002000104 @10.11613/BM.2012.031] between AJG and CSH was 49.9% ([notebook](https://github.com/dhimmel/indications/blob/2e4d9be7ef911e48fdd10d99628b22098010d935/curation/tiebreaker-template.ipynb)), indicating [moderate](http://www.stfm.org/fmhub/fm2005/May/Anthony360.pdf#page=3) agreement.\r\n\r\nLooking at only the 944 agreements, there were 447 disease-modifying, 351 symptomatic, and 146 non-indications. For the remaining [444 disagreements](https://github.com/dhimmel/indications/blob/2e4d9be7ef911e48fdd10d99628b22098010d935/curation/pk/template-pk.tsv), we plan to have a third curator break the tie.",
      "comment_id": 675,
      "profile_id": 17,
      "published": "2016-01-27T22:28:02.019578Z",
      "thread_id": 95,
      "url": "/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95#5"
    },
    {
      "body_html": "<h1>Recruitment of a third curator</h1>\r\n\r\n<p>We have recruited a third curator, Pouya Khankhanian, to break ties. Pouya is a resident physician in neurology at Penn. He received his in MD at UCSF.</p>\r\n\r\n<p>When learning of the task and before seeing this discussion and the three classifications, Pouya asked a few questions about what qualifies as an indication. While some of these may be cleared up by the <a href=\"#4\">definitions</a> we decided on, I thought it would be helpful to post his questions here along my opinions.</p>\r\n\r\n<blockquote><p>Suppose a drug was indicated for treatment of seizures 10 years ago, but now we have a new drug that is more efficacious and has fewer side effects, so the old drug is no longer \"indicated\" in clinical practice. However, I suppose for the purposes of your study you would still want to call this \"indicated\"?</p></blockquote>\r\n\r\n<p>I would not disqualify this indication because it's no longer optimal. It still treats the disease and will therefore be helpful in training and validating our model.</p>\r\n\r\n<blockquote><p>Or, suppose a drug is clinically used for a disease, but is not actually indicated. Classic example is that almost all of our MS drugs are \"not indicated\" for treatment of progressive MS (meaning no trial has ever shown efficacy), but as you know most of our progressive MS patients get treated.</p></blockquote>\r\n\r\n<p>Off-label usages are acceptable as long as there's <em>reasonable evidence</em> of efficacy from a clinical perspective.</p>\r\n\r\n<blockquote><p>Or suppose a drug is like fifth line, and is only indicated if someone is medically refractory (i.e. they have failed the first four lines of drugs). Would you consider this \"indicated\"?</p></blockquote>\r\n\r\n<p>I don't think being far down the line should be a disqualifying factor for the reasons above.</p>",
      "body_md": "# Recruitment of a third curator\r\n\r\nWe have recruited a third curator, Pouya Khankhanian, to break ties. Pouya is a resident physician in neurology at Penn. He received his in MD at UCSF.\r\n\r\nWhen learning of the task and before seeing this discussion and the three classifications, Pouya asked a few questions about what qualifies as an indication. While some of these may be cleared up by the [definitions](#4) we decided on, I thought it would be helpful to post his questions here along my opinions.\r\n\r\n> Suppose a drug was indicated for treatment of seizures 10 years ago, but now we have a new drug that is more efficacious and has fewer side effects, so the old drug is no longer \"indicated\" in clinical practice. However, I suppose for the purposes of your study you would still want to call this \"indicated\"?\r\n\r\nI would not disqualify this indication because it's no longer optimal. It still treats the disease and will therefore be helpful in training and validating our model.\r\n\r\n> Or, suppose a drug is clinically used for a disease, but is not actually indicated. Classic example is that almost all of our MS drugs are \"not indicated\" for treatment of progressive MS (meaning no trial has ever shown efficacy), but as you know most of our progressive MS patients get treated.\r\n\r\nOff-label usages are acceptable as long as there's _reasonable evidence_ of efficacy from a clinical perspective.\r\n\r\n> Or suppose a drug is like fifth line, and is only indicated if someone is medically refractory (i.e. they have failed the first four lines of drugs). Would you consider this \"indicated\"?\r\n\r\nI don't think being far down the line should be a disqualifying factor for the reasons above.",
      "comment_id": 676,
      "profile_id": 17,
      "published": "2016-01-28T00:06:41.656343Z",
      "thread_id": 95,
      "url": "/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95#6"
    },
    {
      "body_html": "<p>Anaïs Baudot, coauthor of the <em>PeerJ</em> paper <span class=\"citation\">[<a href=\"https://doi.org/10.7717/peerj.1525\" class=\"citation\" data-key=\"10.7717/peerj.1525\">1</a>]</span> mentioned in my <a href=\"#5\">previous post</a>, informed me of a fantastically thorough article <span class=\"citation\">[<a href=\"https://doi.org/10.1093/comnet/cnu016\" class=\"citation\" data-key=\"10.1093/comnet/cnu016\">2</a>]</span> on the terminology of complex networks. Quoting from the article's introduction:</p>\r\n\r\n<blockquote><p>In the last couple of years, it has suddenly become very fashionable to study networks with multiple layers (or multiple types of edges) and networks of networks. Unfortunately, the sudden and immense explosion of papers on multilayer networks has produced an equally immense explosion of disparate terminology, and the lack of a consensus (or even generally accepted) set of terminology and mathematical framework for studying multilayer networks is extremely problematic. Additionally, research on generalizing monoplex-network concepts such as degree, transitivity, centrality and diffusion is only in its infancy. We also expect that it will be necessary to define many concepts that are intrinsic to multilayer networks.</p></blockquote>\r\n\r\n<p>This study adopts the term \"multilayer network\" as a general term for networks with multiple layers. From my understanding a layer is an edge type. However, the definition gets quite technical — the study is coming from a math/physics angle. So while the term multilayer definitely encompasses our concept of a hetnet, I think it fails in terms of simplicity. We like the term heterogeneous because it expresses the underlying and distinguishing feature of our networks: different types. Multilayer feels less intuitive: not everyone conceptualizes different types as layers.</p>\r\n\r\n<h2>A simple definition of hetnet</h2>\r\n\r\n<p>Whereas the authors of <em>Multilayer networks</em> have nailed the technical details, I think it's important to have easily accessible definitions to unite the field and help it grow. Therefore I propose the following simple and encompassing definition of hetnet:</p>\r\n\r\n<blockquote><p><strong>hetnet</strong> — a network with multiple node or edge types</p></blockquote>\r\n\r\n<p>Depending on your field, 'network' can be replaced with 'graph', 'node' with 'vertex' or 'entity', and 'edge' with 'link', 'arc', or 'relationship'.</p>\r\n\r\n<h2>The terminology nightmare</h2>\r\n\r\n<p>The authors of <em>Multilayer networks</em> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/comnet/cnu016\" class=\"citation\" data-key=\"10.1093/comnet/cnu016\">2</a>]</span> performed an extremely thorough review of existing terminology. I reproduced their Table 1 of network types that multilayer networks encompass below because it does a great job illustrating the terminology nightmare we face. Not only are there many names for the same concept, but the same name often refers to many concepts. Second, I wanted to make their extensive compilation of references extra accessible. One contributing factor to the lack of standards is poor communication between fields. I'm hoping this <em>Thinklab</em> discussion will help bridge the gaps. And what better way to start the ball rolling than by citing the studies that paved the way for the hetnet.</p>\r\n\r\n<p>The columns are defined as follows (see the study <span class=\"citation\">[<a href=\"https://doi.org/10.1093/comnet/cnu016\" class=\"citation\" data-key=\"10.1093/comnet/cnu016\">2</a>]</span> for more information):</p>\r\n\r\n<blockquote><ul><li><strong>Aligned</strong>: Is the network node-aligned (all nodes are shared between all layers)?</li><li><strong>Disj.</strong>: Is the network layer-disjoint (each node is present only in a single layer)?</li><li><strong>Eq. Size</strong>: Do all of the layers have the same number of nodes?</li><li><strong>Diag.</strong>: Are the couplings diagonal?</li><li><strong>Lcoup.</strong>: Do the inter-layer couplings consist of layer couplings?</li><li><strong>Cat.</strong>: Are the inter-layer couplings categorical?</li><li><strong>|<em>L</em>|</strong> denotes the number of possible layers</li><li><strong><em>d</em></strong> denotes the number of ‘aspects’ (i.e. the ‘dimensionality’ of the layers)</li></ul></blockquote>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>Name</th><th>Aligned</th><th>Disj.</th><th>Eq. Size</th><th>Diag.</th><th>Lcoup.</th><th>Cat.</th><th>|<em>L</em>|</th><th><em>d</em></th><th>Example refs.</th></tr></thead><tbody><tr><td>Multilayer network</td><td></td><td></td><td></td><td>✓</td><td>✓</td><td>✓</td><td>Any</td><td>1</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1140/epjst/e2013-01712-8\" class=\"citation\" data-key=\"68\">3</a>]</span></td></tr><tr><td></td><td>✓</td><td></td><td>✓</td><td></td><td></td><td></td><td>Any</td><td>1</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1103/physrevx.3.041022\" class=\"citation\" data-key=\"67\">4</a>]</span></td></tr><tr><td>Multiplex network</td><td>✓</td><td></td><td>✓</td><td>✓</td><td></td><td></td><td>Any</td><td>1</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1073/pnas.1318469111\" class=\"citation\" data-key=\"69\">5</a>, <a href=\"https://doi.org/10.1103/physrevx.3.041022\" class=\"citation\" data-key=\"67\">4</a>]</span></td></tr><tr><td></td><td>✓</td><td></td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>Any</td><td>1</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1103/PhysRevE.86.036103\" class=\"citation\" data-key=\"70\">6</a>, <a href=\"https://doi.org/10.1103/PhysRevE.85.045102\" class=\"citation\" data-key=\"71\">7</a>, <a href=\"https://doi.org/10.1103/PhysRevLett.111.058701\" class=\"citation\" data-key=\"72\">8</a>, <a href=\"https://doi.org/10.1103/PhysRevE.87.062806\" class=\"citation\" data-key=\"73\">9</a>, <a href=\"https://doi.org/10.1103/PhysRevE.88.052811\" class=\"citation\" data-key=\"74\">10</a>, <a href=\"https://doi.org/10.1103/PhysRevE.89.032804\" class=\"citation\" data-key=\"75\">11</a>, <a href=\"https://doi.org/10.1109/asonam.2012.101\" class=\"citation\" data-key=\"76\">12</a>]</span></td></tr><tr><td></td><td>✓</td><td></td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>2</td><td>1</td><td><span class=\"citation\">[<a href=\"http://arxiv.org/abs/1307.2967\" class=\"citation\" data-key=\"77\">13</a>, <a href=\"https://doi.org/10.1088/1367-2630/14/3/033027\" class=\"citation\" data-key=\"78\">14</a>, <a href=\"https://doi.org/10.1103/PhysRevE.89.042811\" class=\"citation\" data-key=\"79\">15</a>]</span></td></tr><tr><td></td><td></td><td></td><td></td><td>✓</td><td>✓</td><td>✓</td><td>Any</td><td>1</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1103/PhysRevE.86.036115\" class=\"citation\" data-key=\"80\">16</a>]</span></td></tr><tr><td></td><td>✓</td><td></td><td>✓</td><td>✓</td><td>✓</td><td></td><td>Any</td><td>1</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1103/PhysRevE.88.032807\" class=\"citation\" data-key=\"81\">17</a>, <a href=\"https://doi.org/10.1103/PhysRevE.88.050801\" class=\"citation\" data-key=\"82\">18</a>, <a href=\"https://doi.org/10.1063/1.4818544\" class=\"citation\" data-key=\"83\">19</a>]</span></td></tr><tr><td>Multivariate network</td><td>✓</td><td></td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>Any</td><td>1</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1348/000711099159053\" class=\"citation\" data-key=\"31\">20</a>]</span></td></tr><tr><td>Multinetwork</td><td>✓</td><td></td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>Any</td><td>1</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1103/PhysRevE.81.046104\" class=\"citation\" data-key=\"84\">21</a>]</span></td></tr><tr><td></td><td>✓</td><td></td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>Any</td><td>2</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.physa.2011.02.004\" class=\"citation\" data-key=\"85\">22</a>]</span></td></tr><tr><td>Multirelational network</td><td>✓</td><td></td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>Any</td><td>1</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1017/cbo9780511815478\" class=\"citation\" data-key=\"2\">23</a>, <a href=\"https://doi.org/10.1007/11564126_44\" class=\"citation\" data-key=\"50\">24</a>, <a href=\"https://doi.org/10.1109/asonam.2012.100\" class=\"citation\" data-key=\"86\">25</a>, <a href=\"https://doi.org/10.1109/cse.2009.69\" class=\"citation\" data-key=\"87\">26</a>]</span></td></tr><tr><td>Multirelational data</td><td>✓</td><td></td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>Any</td><td>1</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1137/1.9781611972825.13\" class=\"citation\" data-key=\"88\">27</a>, <a href=\"https://doi.org/10.1145/2020408.2020594\" class=\"citation\" data-key=\"89\">28</a>]</span></td></tr><tr><td>Multilayered network</td><td>✓</td><td></td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>Any</td><td>1</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1063/1.4818544\" class=\"citation\" data-key=\"83\">19</a>, <a href=\"https://doi.org/10.1007/978-3-642-16318-0_27\" class=\"citation\" data-key=\"90\">29</a>, <a href=\"https://doi.org/10.1109/asonam.2011.67\" class=\"citation\" data-key=\"91\">30</a>, <a href=\"https://doi.org/10.1080/18756891.2012.696922\" class=\"citation\" data-key=\"92\">31</a>]</span></td></tr><tr><td>Multidimensional network</td><td>✓</td><td></td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>Any</td><td>1</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.jocs.2011.05.009\" class=\"citation\" data-key=\"93\">32</a>, <a href=\"https://doi.org/10.1007/s10618-013-0331-0\" class=\"citation\" data-key=\"94\">33</a>, <a href=\"https://doi.org/10.1007/s11280-012-0190-4\" class=\"citation\" data-key=\"95\">34</a>, <a href=\"https://doi.org/10.1007/s10618-011-0231-0\" class=\"citation\" data-key=\"96\">35</a>, <a href=\"https://doi.org/10.1098/rstb.2012.0113\" class=\"citation\" data-key=\"97\">36</a>, <a href=\"https://doi.org/10.1109/TSMCA.2011.2132707\" class=\"citation\" data-key=\"98\">37</a>, <a href=\"https://doi.org/10.1145/2492517.2492537\" class=\"citation\" data-key=\"99\">38</a>]</span></td></tr><tr><td></td><td>✓</td><td></td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>Any</td><td>3</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1007/978-3-642-23935-9_37\" class=\"citation\" data-key=\"100\">39</a>]</span></td></tr><tr><td>Multislice network</td><td>✓</td><td></td><td>✓</td><td>✓</td><td></td><td></td><td>Any</td><td>1</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1126/science.1184819\" class=\"citation\" data-key=\"66\">40</a>, <a href=\"https://doi.org/10.1063/1.3518696\" class=\"citation\" data-key=\"101\">41</a>, <a href=\"https://doi.org/10.1007/978-3-642-25501-4_19\" class=\"citation\" data-key=\"102\">42</a>, <a href=\"https://doi.org/10.1063/1.4790830\" class=\"citation\" data-key=\"103\">43</a>]</span></td></tr><tr><td>Multiplex of interdependent networks</td><td>✓</td><td></td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>Any</td><td>1</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1038/srep00620\" class=\"citation\" data-key=\"104\">44</a>]</span></td></tr><tr><td>Hypernetwork</td><td>✓</td><td></td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>Any</td><td>1</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1103/PhysRevE.86.056102\" class=\"citation\" data-key=\"105\">45</a>, <a href=\"https://doi.org/10.1088/1367-2630/14/3/033035\" class=\"citation\" data-key=\"106\">46</a>]</span></td></tr><tr><td>Overlay network</td><td>✓</td><td></td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>2</td><td>1</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1103/PhysRevE.81.036118\" class=\"citation\" data-key=\"107\">47</a>, <a href=\"https://doi.org/10.1103/PhysRevE.84.026105\" class=\"citation\" data-key=\"108\">48</a>]</span></td></tr><tr><td>Composite network</td><td>✓</td><td></td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>2</td><td>1</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1145/2378956.2378958\" class=\"citation\" data-key=\"109\">49</a>]</span></td></tr><tr><td>Multilevel network</td><td></td><td>✓</td><td></td><td></td><td></td><td></td><td>Any</td><td>1</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.socnet.2013.01.004\" class=\"citation\" data-key=\"110\">50</a>, <a href=\"https://doi.org/10.1016/j.socnet.2008.02.001\" class=\"citation\" data-key=\"111\">51</a>]</span></td></tr><tr><td></td><td></td><td></td><td></td><td>✓</td><td>✓</td><td>✓</td><td>Any</td><td>1</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1103/PhysRevE.86.036115\" class=\"citation\" data-key=\"80\">16</a>, <a href=\"https://doi.org/10.1080/00207160.2011.577212\" class=\"citation\" data-key=\"112\">52</a>]</span></td></tr><tr><td>Multiweighted graph</td><td>✓</td><td></td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>Any</td><td>1</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1080/15427951.2012.678191\" class=\"citation\" data-key=\"113\">53</a>]</span></td></tr><tr><td>Heterogeneous network</td><td></td><td>✓</td><td></td><td></td><td></td><td></td><td>2</td><td>1</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1109/icdm.2007.57\" class=\"citation\" data-key=\"49\">54</a>, <a href=\"https://doi.org/10.1007/11564126_44\" class=\"citation\" data-key=\"50\">24</a>]</span></td></tr><tr><td>Multitype network</td><td></td><td>✓</td><td></td><td></td><td></td><td></td><td>Any</td><td>1</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1103/PhysRevE.88.012809\" class=\"citation\" data-key=\"114\">55</a>, <a href=\"https://doi.org/10.1103/PhysRevE.79.036113\" class=\"citation\" data-key=\"115\">56</a>, <a href=\"https://doi.org/10.1103/PhysRevE.74.066114\" class=\"citation\" data-key=\"65\">57</a>]</span></td></tr><tr><td>Interconnected networks</td><td></td><td>✓</td><td>✓</td><td></td><td></td><td></td><td>2</td><td>1</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1103/PhysRevE.85.066109\" class=\"citation\" data-key=\"116\">58</a>, <a href=\"https://doi.org/10.1038/srep03289\" class=\"citation\" data-key=\"117\">59</a>]</span></td></tr><tr><td></td><td></td><td>✓</td><td></td><td></td><td></td><td></td><td>2</td><td>1</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1103/PhysRevE.86.026106\" class=\"citation\" data-key=\"118\">60</a>, <a href=\"https://doi.org/10.1109/acc.2013.6580178\" class=\"citation\" data-key=\"119\">61</a>]</span></td></tr><tr><td>Interdependent networks</td><td></td><td>✓</td><td>✓</td><td></td><td></td><td></td><td>2</td><td>1</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1038/nature08932\" class=\"citation\" data-key=\"57\">62</a>]</span></td></tr><tr><td></td><td></td><td>✓</td><td></td><td></td><td></td><td></td><td>2</td><td>1</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1103/PhysRevLett.105.048701\" class=\"citation\" data-key=\"120\">63</a>]</span></td></tr><tr><td></td><td></td><td></td><td>✓</td><td></td><td></td><td></td><td>2</td><td>1</td><td><span class=\"citation\">[<a href=\"http://arxiv.org/abs/1304.4731\" class=\"citation\" data-key=\"121\">64</a>]</span></td></tr><tr><td></td><td></td><td>✓</td><td></td><td></td><td></td><td></td><td>2</td><td>1</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1073/pnas.1110586109\" class=\"citation\" data-key=\"122\">65</a>, <a href=\"https://doi.org/10.1038/nphys2727\" class=\"citation\" data-key=\"123\">66</a>]</span></td></tr><tr><td></td><td>✓</td><td></td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td>Any</td><td>1</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1103/PhysRevLett.109.248701\" class=\"citation\" data-key=\"124\">67</a>]</span></td></tr><tr><td>Partially interdependent networks</td><td></td><td>✓</td><td></td><td></td><td></td><td></td><td>2</td><td>1</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1103/PhysRevE.87.052812\" class=\"citation\" data-key=\"125\">68</a>]</span></td></tr><tr><td>Network of networks</td><td></td><td></td><td>✓</td><td></td><td></td><td></td><td>Any</td><td>1</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1103/PhysRevLett.107.195701\" class=\"citation\" data-key=\"126\">69</a>]</span></td></tr><tr><td>Coupled networks</td><td></td><td></td><td></td><td>✓</td><td>✓</td><td>✓</td><td>Any</td><td>1</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1109/JSAC.2013.130606\" class=\"citation\" data-key=\"127\">70</a>]</span></td></tr><tr><td>Interconnecting networks</td><td></td><td></td><td></td><td>✓</td><td>✓</td><td>✓</td><td>2</td><td>1</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1209/0295-5075/93/68002\" class=\"citation\" data-key=\"128\">71</a>]</span></td></tr><tr><td>Interacting networks</td><td></td><td>✓</td><td></td><td></td><td></td><td></td><td>Any</td><td>1</td><td><span class=\"citation\">[<a href=\"http://arxiv.org/abs/0907.0894\" class=\"citation\" data-key=\"56\">72</a>, <a href=\"https://doi.org/10.1140/epjb/e2011-10795-8\" class=\"citation\" data-key=\"129\">73</a>]</span></td></tr><tr><td></td><td></td><td>✓</td><td></td><td></td><td></td><td></td><td>2</td><td>1</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1073/pnas.1110586109\" class=\"citation\" data-key=\"122\">65</a>]</span></td></tr><tr><td>Heterogenous information network</td><td></td><td></td><td></td><td></td><td></td><td></td><td>Any</td><td>2</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1145/2481244.2481248\" class=\"citation\" data-key=\"51\">74</a>, <a href=\"https://doi.org/10.1109/asonam.2011.107\" class=\"citation\" data-key=\"130\">75</a>, <a href=\"http://www-dev.ccs.neu.edu/home/yzsun/papers/vldb11_topKSim.pdf\" class=\"citation\" data-key=\"131\">76</a>, <a href=\"http://hdl.handle.net/2142/42366\" class=\"citation\" data-key=\"132\">77</a>]</span></td></tr><tr><td></td><td></td><td>✓</td><td></td><td></td><td></td><td></td><td>Any</td><td>1</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1145/1557019.1557107\" class=\"citation\" data-key=\"133\">78</a>]</span></td></tr><tr><td>Meta-matrix, meta-network</td><td></td><td></td><td></td><td></td><td></td><td></td><td>Any</td><td>2</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1140/epjst/e2013-01712-8\" class=\"citation\" data-key=\"34\">79</a>, <a href=\"https://doi.org/10.1016/j.dss.2006.04.003\" class=\"citation\" data-key=\"134\">80</a>, <a href=\"http://oai.dtic.mil/oai/oai?verb=getRecord&metadataPrefix=html&identifier=ADA459444\" class=\"citation\" data-key=\"135\">81</a>]</span></td></tr></tbody></table>\r\n\r\n",
      "body_md": "Anaïs Baudot, coauthor of the _PeerJ_ paper [@10.7717/peerj.1525] mentioned in my [previous post](#5), informed me of a fantastically thorough article [@10.1093/comnet/cnu016] on the terminology of complex networks. Quoting from the article's introduction:\r\n\r\n> In the last couple of years, it has suddenly become very fashionable to study networks with multiple layers (or multiple types of edges) and networks of networks. Unfortunately, the sudden and immense explosion of papers on multilayer networks has produced an equally immense explosion of disparate terminology, and the lack of a consensus (or even generally accepted) set of terminology and mathematical framework for studying multilayer networks is extremely problematic. Additionally, research on generalizing monoplex-network concepts such as degree, transitivity, centrality and diffusion is only in its infancy. We also expect that it will be necessary to define many concepts that are intrinsic to multilayer networks.\r\n\r\nThis study adopts the term \"multilayer network\" as a general term for networks with multiple layers. From my understanding a layer is an edge type. However, the definition gets quite technical -- the study is coming from a math/physics angle. So while the term multilayer definitely encompasses our concept of a hetnet, I think it fails in terms of simplicity. We like the term heterogeneous because it expresses the underlying and distinguishing feature of our networks: different types. Multilayer feels less intuitive: not everyone conceptualizes different types as layers.\r\n\r\n## A simple definition of hetnet\r\n\r\nWhereas the authors of _Multilayer networks_ have nailed the technical details, I think it's important to have easily accessible definitions to unite the field and help it grow. Therefore I propose the following simple and encompassing definition of hetnet:\r\n\r\n> **hetnet** -- a network with multiple node or edge types\r\n\r\nDepending on your field, 'network' can be replaced with 'graph', 'node' with 'vertex' or 'entity', and 'edge' with 'link', 'arc', or 'relationship'.\r\n\r\n## The terminology nightmare\r\n\r\nThe authors of _Multilayer networks_ [@10.1093/comnet/cnu016] performed an extremely thorough review of existing terminology. I reproduced their Table 1 of network types that multilayer networks encompass below because it does a great job illustrating the terminology nightmare we face. Not only are there many names for the same concept, but the same name often refers to many concepts. Second, I wanted to make their extensive compilation of references extra accessible. One contributing factor to the lack of standards is poor communication between fields. I'm hoping this _Thinklab_ discussion will help bridge the gaps. And what better way to start the ball rolling than by citing the studies that paved the way for the hetnet.\r\n\r\nThe columns are defined as follows (see the study [@10.1093/comnet/cnu016] for more information):\r\n\r\n>\r\n+ **Aligned**: Is the network node-aligned (all nodes are shared between all layers)?\r\n+ **Disj.**: Is the network layer-disjoint (each node is present only in a single layer)?\r\n+ **Eq. Size**: Do all of the layers have the same number of nodes?\r\n+ **Diag.**: Are the couplings diagonal?\r\n+ **Lcoup.**: Do the inter-layer couplings consist of layer couplings?\r\n+ **Cat.**: Are the inter-layer couplings categorical?\r\n+ **|_L_|** denotes the number of possible layers\r\n+ **_d_** denotes the number of ‘aspects’ (i.e. the ‘dimensionality’ of the layers)\r\n\r\n| Name | Aligned | Disj. | Eq. Size | Diag. | Lcoup. | Cat. | \\|_L_\\| | _d_ | Example refs. |\r\n|-----------|---------|-------|----------|-------|--------|------|-----|---|-------|\r\n| Multilayer network |  |  |  | ✓ | ✓ | ✓ | Any | 1 | [@68] |\r\n|  | ✓ |  | ✓ |  |  |  | Any | 1 | [@67] |\r\n| Multiplex network | ✓ |  | ✓ | ✓ |  |  | Any | 1 | [@69 @67] |\r\n|  | ✓ |  | ✓ | ✓ | ✓ | ✓ | Any | 1 | [@70 @71 @72 @73 @74 @75 @76] |\r\n|  | ✓ |  | ✓ | ✓ | ✓ | ✓ | 2 | 1 | [@77 @78 @79] |\r\n|  |  |  |  | ✓ | ✓ | ✓ | Any | 1 | [@80] |\r\n|  | ✓ |  | ✓ | ✓ | ✓ |  | Any | 1 | [@81 @82 @83] |\r\n| Multivariate network | ✓ |  | ✓ | ✓ | ✓ | ✓ | Any | 1 | [@31] |\r\n| Multinetwork | ✓ |  | ✓ | ✓ | ✓ | ✓ | Any | 1 | [@84] |\r\n|  | ✓ |  | ✓ | ✓ | ✓ | ✓ | Any | 2 | [@85] |\r\n| Multirelational network | ✓ |  | ✓ | ✓ | ✓ | ✓ | Any | 1 | [@2 @50 @86 @87] |\r\n| Multirelational data | ✓ |  | ✓ | ✓ | ✓ | ✓ | Any | 1 | [@88 @89] |\r\n| Multilayered network | ✓ |  | ✓ | ✓ | ✓ | ✓ | Any | 1 | [@83 @90 @91 @92] |\r\n| Multidimensional network | ✓ |  | ✓ | ✓ | ✓ | ✓ | Any | 1 | [@93 @94 @95 @96 @97 @98 @99] |\r\n|  | ✓ |  | ✓ | ✓ | ✓ | ✓ | Any | 3 | [@100] |\r\n| Multislice network | ✓ |  | ✓ | ✓ |  |  | Any | 1 | [@66 @101 @102 @103] |\r\n| Multiplex of interdependent networks | ✓ |  | ✓ | ✓ | ✓ | ✓ | Any | 1 | [@104] |\r\n| Hypernetwork | ✓ |  | ✓ | ✓ | ✓ | ✓ | Any | 1 | [@105 @106] |\r\n| Overlay network | ✓ |  | ✓ | ✓ | ✓ | ✓ | 2 | 1 | [@107 @108] |\r\n| Composite network | ✓ |  | ✓ | ✓ | ✓ | ✓ | 2 | 1 | [@109] |\r\n| Multilevel network |  | ✓ |  |  |  |  | Any | 1 | [@110 @111] |\r\n|  |  |  |  | ✓ | ✓ | ✓ | Any | 1 | [@80 @112] |\r\n| Multiweighted graph | ✓ |  | ✓ | ✓ | ✓ | ✓ | Any | 1 | [@113] |\r\n| Heterogeneous network |  | ✓ |  |  |  |  | 2 | 1 | [@49 @50] |\r\n| Multitype network |  | ✓ |  |  |  |  | Any | 1 | [@114 @115 @65] |\r\n| Interconnected networks |  | ✓ | ✓ |  |  |  | 2 | 1 | [@116 @117] |\r\n|  |  | ✓ |  |  |  |  | 2 | 1 | [@118 @119] |\r\n| Interdependent networks |  | ✓ | ✓ |  |  |  | 2 | 1 | [@57] |\r\n|  |  | ✓ |  |  |  |  | 2 | 1 | [@120] |\r\n|  |  |  | ✓ |  |  |  | 2 | 1 | [@121] |\r\n|  |  | ✓ |  |  |  |  | 2 | 1 | [@122 @123] |\r\n|  | ✓ |  | ✓ | ✓ | ✓ | ✓ | Any | 1 | [@124] |\r\n| Partially interdependent networks |  | ✓ |  |  |  |  | 2 | 1 | [@125] |\r\n| Network of networks |  |  | ✓ |  |  |  | Any | 1 | [@126] |\r\n| Coupled networks |  |  |  | ✓ | ✓ | ✓ | Any | 1 | [@127] |\r\n| Interconnecting networks |  |  |  | ✓ | ✓ | ✓ | 2 | 1 | [@128] |\r\n| Interacting networks |  | ✓ |  |  |  |  | Any | 1 | [@56 @129] |\r\n|  |  | ✓ |  |  |  |  | 2 | 1 | [@122] |\r\n| Heterogenous information network |  |  |  |  |  |  | Any | 2 | [@51 @130 @131 @132] |\r\n|  |  | ✓ |  |  |  |  | Any | 1 | [@133] |\r\n| Meta-matrix, meta-network |  |  |  |  |  |  | Any | 2 | [@34 @134 @135] |\r\n\r\n[@2]: 10.1017/cbo9780511815478\r\n[@31]: 10.1348/000711099159053\r\n[@34]: 10.1140/epjst/e2013-01712-8\r\n[@49]: 10.1109/icdm.2007.57\r\n[@50]: 10.1007/11564126_44\r\n[@51]: 10.1145/2481244.2481248\r\n[@56]: http://arxiv.org/abs/0907.0894 \"Leicht E. A., D'Souza R. M. Percolation on interacting networks. 2009. arXiv:0907.0894\"\r\n[@57]: 10.1038/nature08932\r\n[@65]: 10.1103/PhysRevE.74.066114\r\n[@66]: 10.1126/science.1184819\r\n[@67]: 10.1103/physrevx.3.041022\r\n[@68]: 10.1140/epjst/e2013-01712-8\r\n[@69]: 10.1073/pnas.1318469111\r\n[@70]: 10.1103/PhysRevE.86.036103\r\n[@71]: 10.1103/PhysRevE.85.045102\r\n[@72]: 10.1103/PhysRevLett.111.058701\r\n[@73]: 10.1103/PhysRevE.87.062806\r\n[@74]: 10.1103/PhysRevE.88.052811\r\n[@75]: 10.1103/PhysRevE.89.032804\r\n[@76]: 10.1109/asonam.2012.101\r\n[@77]: http://arxiv.org/abs/1307.2967 \"Min B., Goh K.-I. Layer-crossing overhead and information spreading in multiplex social networks. 2013. arXiv:1307.2967\"\r\n[@78]: 10.1088/1367-2630/14/3/033027\r\n[@79]: 10.1103/PhysRevE.89.042811\r\n[@80]: 10.1103/PhysRevE.86.036115\r\n[@81]: 10.1103/PhysRevE.88.032807\r\n[@82]: 10.1103/PhysRevE.88.050801\r\n[@83]: 10.1063/1.4818544\r\n[@84]: 10.1103/PhysRevE.81.046104\r\n[@85]: 10.1016/j.physa.2011.02.004\r\n[@86]: 10.1109/asonam.2012.100\r\n[@87]: 10.1109/cse.2009.69\r\n[@88]: 10.1137/1.9781611972825.13\r\n[@89]: 10.1145/2020408.2020594\r\n[@90]: 10.1007/978-3-642-16318-0_27\r\n[@91]: 10.1109/asonam.2011.67\r\n[@92]: 10.1080/18756891.2012.696922\r\n[@93]: 10.1016/j.jocs.2011.05.009\r\n[@94]: 10.1007/s10618-013-0331-0\r\n[@95]: 10.1007/s11280-012-0190-4\r\n[@96]: 10.1007/s10618-011-0231-0\r\n[@97]: 10.1098/rstb.2012.0113\r\n[@98]: 10.1109/TSMCA.2011.2132707\r\n[@99]: 10.1145/2492517.2492537\r\n[@100]: 10.1007/978-3-642-23935-9_37\r\n[@101]: 10.1063/1.3518696\r\n[@102]: 10.1007/978-3-642-25501-4_19\r\n[@103]: 10.1063/1.4790830\r\n[@104]: 10.1038/srep00620\r\n[@105]: 10.1103/PhysRevE.86.056102\r\n[@106]: 10.1088/1367-2630/14/3/033035\r\n[@107]: 10.1103/PhysRevE.81.036118\r\n[@108]: 10.1103/PhysRevE.84.026105\r\n[@109]: 10.1145/2378956.2378958\r\n[@110]: 10.1016/j.socnet.2013.01.004\r\n[@111]: 10.1016/j.socnet.2008.02.001\r\n[@112]: 10.1080/00207160.2011.577212\r\n[@113]: 10.1080/15427951.2012.678191\r\n[@114]: 10.1103/PhysRevE.88.012809\r\n[@115]: 10.1103/PhysRevE.79.036113\r\n[@116]: 10.1103/PhysRevE.85.066109\r\n[@117]: 10.1038/srep03289\r\n[@118]: 10.1103/PhysRevE.86.026106\r\n[@119]: 10.1109/acc.2013.6580178\r\n[@120]: 10.1103/PhysRevLett.105.048701\r\n[@121]: http://arxiv.org/abs/1304.4731 \"Martin-Hernandez J., Wang H., Van Mieghem P., D'Agostino G. On synchronization of interdependent networks. 2013. arXiv:1304.4731\"\r\n[@122]: 10.1073/pnas.1110586109\r\n[@123]: 10.1038/nphys2727\r\n[@124]: 10.1103/PhysRevLett.109.248701\r\n[@125]: 10.1103/PhysRevE.87.052812\r\n[@126]: 10.1103/PhysRevLett.107.195701\r\n[@127]: 10.1109/JSAC.2013.130606\r\n[@128]: 10.1209/0295-5075/93/68002\r\n[@129]: 10.1140/epjb/e2011-10795-8\r\n[@130]: 10.1109/asonam.2011.107\r\n[@131]: http://www-dev.ccs.neu.edu/home/yzsun/papers/vldb11_topKSim.pdf \"Sun Y., Han J., Yan X., Yu P. S., Wu T. PathSim: meta path-based top-k similarity search in heterogeneous information networks. Proceeding of the 2011 International Conference on Very Large Data Based (VLDB 2011) 2011. Seattle, WA.\"\r\n[@132]: http://hdl.handle.net/2142/42366 \"Sun Y. Mining heterogeneous information networks. Ph.D. Thesis 2012. University of Illinois at Urbana-Champaign.\"\r\n[@133]: 10.1145/1557019.1557107\r\n[@134]: 10.1016/j.dss.2006.04.003\r\n[@135]: http://oai.dtic.mil/oai/oai?verb=getRecord&metadataPrefix=html&identifier=ADA459444 \"Tsvetovat M., Reminga J., Carley K. M. DyNetML: interchange format for rich social network data. CASOS Technical Report 2004. Carnegie Mellon University, School of Computer Science, Institute for Software Research International, CMU-ISRI-04-105.\"",
      "comment_id": 678,
      "profile_id": 17,
      "published": "2016-01-28T19:43:54.578535Z",
      "thread_id": 104,
      "url": "/discussion/renaming-heterogeneous-networks-to-a-more-concise-and-catchy-term/104#6"
    },
    {
      "body_html": "<h1>2016 GraphGist Challenge</h1>\r\n\r\n<p>Neo4j is hosting a GraphGist <a href=\"http://portal.graphgist.org/challenge/index.html\" title=\"GraphGist Challenge\">challenge</a>. GraphGists provide the <a href=\"http://portal.graphgist.org/about\" title=\"What is a GraphGist?\">following</a>:</p>\r\n\r\n<blockquote><p>With Neo4j GraphGists you can describe and model your domain in a simple text file (AsciiDoc) and render it as a rich, interactive, database-backed page in any browser. It is perfect to document a specific domain, use-case, question or graph problem.</p></blockquote>\r\n\r\n<p>This years competition is Star Wars themed — a theme we adhered to in <a href=\"http://portal.graphgist.org/graph_gists/drug-repurposing-by-hetnet-relationship-prediction-a-new-hope\" title=\"Drug repurposing by hetnet relationship prediction: a new hope\"><strong>our submission</strong></a>. To give you a taste, our prologue begins with:</p>\r\n\r\n<blockquote><p>A long time ago in a galaxy far, far away…​. It is a dark time for drug discovery. The Empire spends over a billion dollars in R&amp;D per new drug approval. The process takes decades, 9 out of 10 attempts fail, and the cost has been doubling every 9 years since 1970. But, a small band of Rebel scientists pursue an alternative. Using public data and open source software, the Rebels are predicting new uses for existing drugs.</p></blockquote>\r\n\r\n<p>Our goal in creating a submission was twofold. First, we're excited to interact with other members of the neo4j community who are doing complimentary work. Second, we designed the GraphGist to be a good introduction to our project and hetnet relationship prediction in general.</p>",
      "body_md": "# 2016 GraphGist Challenge\r\n\r\nNeo4j is hosting a GraphGist [challenge](http://portal.graphgist.org/challenge/index.html \"GraphGist Challenge\"). GraphGists provide the [following](http://portal.graphgist.org/about \"What is a GraphGist?\"):\r\n\r\n> With Neo4j GraphGists you can describe and model your domain in a simple text file (AsciiDoc) and render it as a rich, interactive, database-backed page in any browser. It is perfect to document a specific domain, use-case, question or graph problem.\r\n\r\nThis years competition is Star Wars themed -- a theme we adhered to in [**our submission**](http://portal.graphgist.org/graph_gists/drug-repurposing-by-hetnet-relationship-prediction-a-new-hope \"Drug repurposing by hetnet relationship prediction: a new hope\"). To give you a taste, our prologue begins with:\r\n\r\n> A long time ago in a galaxy far, far away…​. It is a dark time for drug discovery. The Empire spends over a billion dollars in R&D per new drug approval. The process takes decades, 9 out of 10 attempts fail, and the cost has been doubling every 9 years since 1970. But, a small band of Rebel scientists pursue an alternative. Using public data and open source software, the Rebels are predicting new uses for existing drugs.\r\n\r\nOur goal in creating a submission was twofold. First, we're excited to interact with other members of the neo4j community who are doing complimentary work. Second, we designed the GraphGist to be a good introduction to our project and hetnet relationship prediction in general.",
      "comment_id": 679,
      "profile_id": 17,
      "published": "2016-01-29T18:38:18.936111Z",
      "thread_id": 112,
      "url": "/discussion/using-the-neo4j-graph-database-for-hetnets/112#8"
    },
    {
      "body_html": "<p>After an additional round of emails on February 4, 2016, Jill Mesirov got back to me. Dr. Mesirov was the principal investigator for the MSigDB project while at the Broad but has since moved to UCSD. She mentioned that they received permission to distribute certain parts of the database but that they did not receive permission to pass on those rights. She also added Helga Thorvaldsdottir — the MSigDB project manager at the Broad — to the conversation.</p>\r\n\r\n<p>I responded with the following message:</p>\r\n\r\n<blockquote><p>Dear Dr. Mesirov et al,</p><p>Thanks for the reply and involving Helga. Hopefully, we can now locate the appropriate parties to handle our request.</p><p>I had guessed that non-transferable distribution rights were part of the issue. I appreciate wanting to build the most comprehensive resource, even when that necessitates stricter licensing.</p><p>Do you know which resources forbid downstream distribution? Perhaps we could be given permission to redistribute the unencumbered portions of the database? And for encumbered portions, we could seek the needed additional permissions from the content owners.</p><p>We feel that distribution fulfills an important scientific need. We're integrating over 30 resources into a single network that we envision becoming a widely used community dataset. Much like MSigDB did with gene sets, our network will enable novel analyses that are only possible once the data has been unified into a single resource. Additionally, forbidding distribution has troubling consequences for reproducibility. See for example <a href=\"http://wpo.st/NUj91\" title=\"What happened when a group of researchers tried to repeat a headline-grabbing study\">this instance</a> where data copyright interfered with replication.</p><p>Given these considerations, we would appreciate help in finding a solution that allows us to distribute MSigDB data, even if only a subset of the database.</p><p>Best,<br>Daniel</p></blockquote>\r\n\r\n<p>In short, I asked if they could look into granting us permission to distribute the unencumbered portions of the database. Ms. Thorvaldsdottir responded that they will be meeting with the IP/Licensing team to discuss my request.</p>",
      "body_md": "After an additional round of emails on February 4, 2016, Jill Mesirov got back to me. Dr. Mesirov was the principal investigator for the MSigDB project while at the Broad but has since moved to UCSD. She mentioned that they received permission to distribute certain parts of the database but that they did not receive permission to pass on those rights. She also added Helga Thorvaldsdottir -- the MSigDB project manager at the Broad -- to the conversation.\r\n\r\nI responded with the following message:\r\n\r\n> Dear Dr. Mesirov et al,\r\n\r\n> Thanks for the reply and involving Helga. Hopefully, we can now locate the appropriate parties to handle our request.\r\n\r\n> I had guessed that non-transferable distribution rights were part of the issue. I appreciate wanting to build the most comprehensive resource, even when that necessitates stricter licensing.\r\n\r\n> Do you know which resources forbid downstream distribution? Perhaps we could be given permission to redistribute the unencumbered portions of the database? And for encumbered portions, we could seek the needed additional permissions from the content owners.\r\n\r\n> We feel that distribution fulfills an important scientific need. We're integrating over 30 resources into a single network that we envision becoming a widely used community dataset. Much like MSigDB did with gene sets, our network will enable novel analyses that are only possible once the data has been unified into a single resource. Additionally, forbidding distribution has troubling consequences for reproducibility. See for example [this instance](http://wpo.st/NUj91 \"What happened when a group of researchers tried to repeat a headline-grabbing study\") where data copyright interfered with replication.\r\n\r\n> Given these considerations, we would appreciate help in finding a solution that allows us to distribute MSigDB data, even if only a subset of the database.\r\n\r\n> Best,\r\n> Daniel\r\n\r\nIn short, I asked if they could look into granting us permission to distribute the unencumbered portions of the database. Ms. Thorvaldsdottir responded that they will be meeting with the IP/Licensing team to discuss my request.",
      "comment_id": 760,
      "profile_id": 17,
      "published": "2016-02-19T19:49:47.864072Z",
      "thread_id": 108,
      "url": "/discussion/msigdb-licensing/108#2"
    },
    {
      "body_html": "<h1>Gene handling quality control</h1>\r\n\r\n<p>Currently, we have STARGEO case-control queries for 66 of our diseases. Of these 66 queries, 37 return differential expression results. The rest either have insufficient samples or fail <a href=\"https://github.com/idrdex/star_api/issues/13#issue-123599787\" title=\"idrdex/star_geo#13 Specific failing analyses\">due to errors</a>.</p>\r\n\r\n<p>In the past, I remember coming across a STARGEO output (gene rows × meta-analysis columns) where many rows contained duplicate gene symbols. <a href=\"/u/idrdex\" class=\"username\">@idrdex</a> had also mentioned to me that mapping the probe/gene names deposited in GEO can get complicated. Therefore, I wanted to do a few quality controls before proceeding.</p>\r\n\r\n<p>I checked into our current STARGEO analysis of differential expression for 37 diseases. I looked for three occurrences which could be due to problems with gene handling (<a href=\"https://github.com/dhimmel/stargeo/blob/6c5a348f2ea22edf475dc14a5eed93eb95290d7d/gene-fidelity.ipynb\">notebook</a>):</p>\r\n\r\n<ul><li>GeneID–Symbol mappings that don't exist in Entrez Gene (<a href=\"https://github.com/dhimmel/stargeo/blob/6c5a348f2ea22edf475dc14a5eed93eb95290d7d/diagnose/discord.tsv\">results</a>). There were 2,274 ID-Symbol pairs that didn't exist in my parsing of Entrez Gene. However, most of these were not protein-coding and appeared to stem from updates to the database over time.</li><li>Rows with duplicate GeneIDs (<a href=\"https://github.com/dhimmel/stargeo/blob/6c5a348f2ea22edf475dc14a5eed93eb95290d7d/diagnose/duplicate_ids.tsv\">results</a>). Only two rows were affected by this issue.</li><li>Rows with duplicate symbols (<a href=\"https://github.com/dhimmel/stargeo/blob/6c5a348f2ea22edf475dc14a5eed93eb95290d7d/diagnose/duplicate_symbols.tsv\">results</a>). 72 rows were affected by this issue. It did seem however that many gene symbols were not the approved symbols but rather synonyms. Since we <a href=\"http://thinklab.com/discussion/using-entrez-gene-as-our-gene-vocabulary/34\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d34\">use Entrez Gene</a> IDs for mapping, synonyms are not a major concern for us.</li></ul>\r\n\r\n<p>So in conclusion, I didn't detect any major issues with the gene handling in STARGEO. These quality controls do not assess the probe–gene mapping, but instead whether the gene information reported for the meta-analyses makes sense.</p>",
      "body_md": "# Gene handling quality control\r\n\r\nCurrently, we have STARGEO case-control queries for 66 of our diseases. Of these 66 queries, 37 return differential expression results. The rest either have insufficient samples or fail [due to errors](https://github.com/idrdex/star_api/issues/13#issue-123599787 \"idrdex/star_geo#13 Specific failing analyses\").\r\n\r\nIn the past, I remember coming across a STARGEO output (gene rows × meta-analysis columns) where many rows contained duplicate gene symbols. @idrdex had also mentioned to me that mapping the probe/gene names deposited in GEO can get complicated. Therefore, I wanted to do a few quality controls before proceeding.\r\n\r\nI checked into our current STARGEO analysis of differential expression for 37 diseases. I looked for three occurrences which could be due to problems with gene handling ([notebook](https://github.com/dhimmel/stargeo/blob/6c5a348f2ea22edf475dc14a5eed93eb95290d7d/gene-fidelity.ipynb)):\r\n\r\n+ GeneID--Symbol mappings that don't exist in Entrez Gene ([results](https://github.com/dhimmel/stargeo/blob/6c5a348f2ea22edf475dc14a5eed93eb95290d7d/diagnose/discord.tsv)). There were 2,274 ID-Symbol pairs that didn't exist in my parsing of Entrez Gene. However, most of these were not protein-coding and appeared to stem from updates to the database over time.\r\n+ Rows with duplicate GeneIDs ([results](https://github.com/dhimmel/stargeo/blob/6c5a348f2ea22edf475dc14a5eed93eb95290d7d/diagnose/duplicate_ids.tsv)). Only two rows were affected by this issue.\r\n+ Rows with duplicate symbols ([results](https://github.com/dhimmel/stargeo/blob/6c5a348f2ea22edf475dc14a5eed93eb95290d7d/diagnose/duplicate_symbols.tsv)). 72 rows were affected by this issue. It did seem however that many gene symbols were not the approved symbols but rather synonyms. Since we [use Entrez Gene](http://thinklab.com/discussion/using-entrez-gene-as-our-gene-vocabulary/34) IDs for mapping, synonyms are not a major concern for us.\r\n\r\nSo in conclusion, I didn't detect any major issues with the gene handling in STARGEO. These quality controls do not assess the probe--gene mapping, but instead whether the gene information reported for the meta-analyses makes sense.",
      "comment_id": 796,
      "profile_id": 17,
      "published": "2016-02-10T01:59:27.854907Z",
      "thread_id": 96,
      "url": "/discussion/stargeo-expression-signatures-for-disease-using-crowdsourced-geo-annotation/96#9"
    },
    {
      "body_html": "<h1><em>Nature News</em> mentions our use of <em>Thinklab</em> to avoid publishing delays</h1>\r\n\r\n<p>A <em>Nature News</em> <a href=\"https://doi.org/10.1038/530148a\" title=\"The Waiting Game\">feature</a> published today <span class=\"citation\">[<a href=\"https://doi.org/10.1038/530148a\" class=\"citation\" data-key=\"10.1038/530148a\">1</a>]</span> mentions our Thinklab project:</p>\r\n\r\n<blockquote><p>Some scientists are going a step further, and using platforms such as GitHub, Zenodo and figshare to publish each hypothesis, data collection or figure as they go along. Each file can be given a DOI, so that it is citable and trackable. Himmelstein, who already publishes his papers as preprints, has been using the Thinklab platform to progressively write up and publish the results of a new project since January 2015. “I push 'publish' and it gets a DOI with no delay,” he says. “Am I really gaining that much by publishing [in a conventional journal]? Or is it better to do what is fastest and most efficient to get your research out there?”</p></blockquote>\r\n\r\n<p>The feature also covers my <a href=\"http://blog.dhimmel.com/history-of-delays/\" title=\"The history of publishing delays\">blog post</a> on the history of publishing delays. Using data from PubMed, I found a median time from submission to acceptance of ~100 days and a median time from acceptance to online publication of ~25 days. Since we post most content on <em>Thinklab</em> several months before it will ever be submitted, we're getting our work out 200+ days sooner by using realtime open notebook publishing.</p>",
      "body_md": "# _Nature News_ mentions our use of _Thinklab_ to avoid publishing delays\r\n\r\nA *Nature News* [feature](https://doi.org/10.1038/530148a \"The Waiting Game\") published today [@10.1038/530148a] mentions our Thinklab project:\r\n\r\n> Some scientists are going a step further, and using platforms such as GitHub, Zenodo and figshare to publish each hypothesis, data collection or figure as they go along. Each file can be given a DOI, so that it is citable and trackable. Himmelstein, who already publishes his papers as preprints, has been using the Thinklab platform to progressively write up and publish the results of a new project since January 2015. “I push 'publish' and it gets a DOI with no delay,” he says. “Am I really gaining that much by publishing [in a conventional journal]? Or is it better to do what is fastest and most efficient to get your research out there?”\r\n\r\nThe feature also covers my [blog post](http://blog.dhimmel.com/history-of-delays/ \"The history of publishing delays\") on the history of publishing delays. Using data from PubMed, I found a median time from submission to acceptance of ~100 days and a median time from acceptance to online publication of ~25 days. Since we post most content on *Thinklab* several months before it will ever be submitted, we're getting our work out 200+ days sooner by using realtime open notebook publishing.",
      "comment_id": 797,
      "profile_id": 17,
      "published": "2016-02-10T11:59:49.322011Z",
      "thread_id": 113,
      "url": "/discussion/tracking-project-reuse-citation-and-publicity/113#4"
    },
    {
      "body_html": "<p>We've created a <a href=\"http://thinklab.com/discussion/one-network-to-rule-them-all/102\" title=\"Preliminary hetnet release\">preliminary network</a> with 10 types of nodes (metanodes) and 27 types of edges (metaedges). Now an important detail is naming node and edge types appropriately.</p>\r\n\r\n<p>For each metanode and metaedge, we also need abbreviations. We use the abbreviations to make writing out complete paths less cumbersome. For example, in our previous project, we <a href=\"https://doi.org/10.1371/journal.pcbi.1004259.s010\" title=\"S1 Table. Features · Hetnet-Based Prioritization of Disease Associations\">abbreviated</a> the <code>Gene - interaction - Gene - expression - Tissue - localization - Disease</code> path to <code>GiGeTlD</code> <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004259.s010\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1004259.s010\">1</a>]</span>.</p>\r\n\r\n<p>We have several conventions for naming and abbreviations, but they haven't been publicly explained or discussed. This discussion is now home to these topics.</p>",
      "body_md": "We've created a [preliminary network](http://thinklab.com/discussion/one-network-to-rule-them-all/102 \"Preliminary hetnet release\") with 10 types of nodes (metanodes) and 27 types of edges (metaedges). Now an important detail is naming node and edge types appropriately.\r\n\r\nFor each metanode and metaedge, we also need abbreviations. We use the abbreviations to make writing out complete paths less cumbersome. For example, in our previous project, we [abbreviated](https://doi.org/10.1371/journal.pcbi.1004259.s010 \"S1 Table. Features · Hetnet-Based Prioritization of Disease Associations\") the `Gene - interaction - Gene - expression - Tissue - localization - Disease` path to `GiGeTlD` [@10.1371/journal.pcbi.1004259.s010].\r\n\r\nWe have several conventions for naming and abbreviations, but they haven't been publicly explained or discussed. This discussion is now home to these topics.",
      "comment_id": 802,
      "profile_id": 17,
      "published": "2016-02-17T19:43:44.550722Z",
      "thread_id": 162,
      "url": "/discussion/data-nomenclature-naming-and-abbreviating-our-network-types/162"
    },
    {
      "body_html": "<h1>Naming according to parts of speech</h1>\r\n\r\n<p>According to <a href=\"https://en.wikipedia.org/w/index.php?title=Entity%E2%80%93relationship_model&amp;oldid=704204795#Mapping_natural_language\" title=\"Mapping natural language · Entity–relationship model · Wikipedia\">Chen's rules of thumb</a>, we should use parts of speech as follows <span class=\"citation\">[<a href=\"https://doi.org/10.1016/s0169-023x(97)00017-7\" class=\"citation\" data-key=\"10.1016/s0169-023x(97)00017-7\">1</a>]</span>:</p>\r\n\r\n<ul><li><em>common nouns</em> for node labels (types)</li><li><em>proper nouns</em> for node names</li><li><em>transitive verbs</em> for relationship (edge) types</li><li><em>intransitive verbs</em> for property (attribute) types</li><li><em>adjectives</em> for node properties</li><li><em>adverbs</em> for relationship properties</li></ul>\r\n\r\n<p>I'm not convinced about the last three, since our properties (data attributes for nodes and relationships) are often highly technical. However, I think we should adhere to the first three rules when possible.</p>\r\n\r\n<p>Our node labels are already common nouns. Our node names are already proper nouns. However, we were using common nouns for relationship types. Thus, I switched to transitive verbs for relationship types (<a href=\"https://github.com/dhimmel/integrate/commit/8ca7c9e971ce5a85c7729b3f1df7db54beb19d18\">commit</a>). The table below shows the noun (old) and verb (new) relationship type.</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>Source</th><th>Target</th><th>Metaedge (noun)</th><th>Metaedge (verb)</th></tr></thead><tbody><tr><td>compound</td><td>gene</td><td>binding</td><td>binds</td></tr><tr><td>compound</td><td>side effect</td><td>causation</td><td>causes</td></tr><tr><td>compound</td><td>gene</td><td>downregulation</td><td>downregulates</td></tr><tr><td>compound</td><td>disease</td><td>indication</td><td>palliates</td></tr><tr><td>compound</td><td>compound</td><td>similarity</td><td>resembles</td></tr><tr><td>compound</td><td>disease</td><td>indication</td><td>treats</td></tr><tr><td>compound</td><td>gene</td><td>upregulation</td><td>upregulates</td></tr><tr><td>disease</td><td>gene</td><td>association</td><td>associates</td></tr><tr><td>disease</td><td>gene</td><td>downregulation</td><td>downregulates</td></tr><tr><td>disease</td><td>anatomy</td><td>localization</td><td>localizes</td></tr><tr><td>disease</td><td>symptom</td><td>presence</td><td>presents</td></tr><tr><td>disease</td><td>disease</td><td>similarity</td><td>resembles</td></tr><tr><td>disease</td><td>gene</td><td>upregulation</td><td>upregulates</td></tr><tr><td>gene</td><td>anatomy</td><td>downregulation</td><td>downregulates</td></tr><tr><td>gene</td><td>gene</td><td>evolution</td><td>evolves</td></tr><tr><td>gene</td><td>anatomy</td><td>expression</td><td>expresses</td></tr><tr><td>gene</td><td>gene</td><td>interaction</td><td>interacts</td></tr><tr><td>gene</td><td>biological process</td><td>participation</td><td>participates</td></tr><tr><td>gene</td><td>cellular component</td><td>participation</td><td>participates</td></tr><tr><td>gene</td><td>molecular function</td><td>participation</td><td>participates</td></tr><tr><td>gene</td><td>pathway</td><td>participation</td><td>participates</td></tr><tr><td>gene</td><td>perturbation</td><td>regulation</td><td>regulates</td></tr><tr><td>gene</td><td>anatomy</td><td>upregulation</td><td>upregulates</td></tr><tr><td>gene</td><td>gene</td><td>knockdown downregulation</td><td>knockdown downregulates</td></tr><tr><td>gene</td><td>gene</td><td>knockdown upregulation</td><td>knockdown upregulates</td></tr><tr><td>gene</td><td>gene</td><td>overexpression downregulation</td><td>overexpression downregulates</td></tr><tr><td>gene</td><td>gene</td><td>overexpression upregulation</td><td>overexpression upregulates</td></tr></tbody></table>\r\n\r\n<p>In several cases, switching from noun to verb cut out several characters — a welcome occurrence. Switching relationship types to verbs also makes sense as part of our <a href=\"http://thinklab.com/discussion/using-the-neo4j-graph-database-for-hetnets/112\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d112\">migration to neo4j</a>. The neo4j convention is to use verbs for relationship types. In fact, a neo4j company <a href=\"https://www.graphstory.com/elements-of-a-graph-database\">explains relationships</a> by saying:</p>\r\n\r\n<blockquote><p>Where nodes can be thought of as nouns, relationships can be thought of as verbs.</p></blockquote>",
      "body_md": "# Naming according to parts of speech\r\n\r\nAccording to [Chen's rules of thumb](https://en.wikipedia.org/w/index.php?title=Entity%E2%80%93relationship_model&oldid=704204795#Mapping_natural_language \"Mapping natural language · Entity–relationship model · Wikipedia\"), we should use parts of speech as follows [@10.1016/s0169-023x(97)00017-7]:\r\n\r\n+ _common nouns_ for node labels (types)\r\n+ _proper nouns_ for node names\r\n+ _transitive verbs_ for relationship (edge) types\r\n+ _intransitive verbs_ for property (attribute) types\r\n+ _adjectives_ for node properties\r\n+ _adverbs_ for relationship properties\r\n\r\nI'm not convinced about the last three, since our properties (data attributes for nodes and relationships) are often highly technical. However, I think we should adhere to the first three rules when possible.\r\n\r\nOur node labels are already common nouns. Our node names are already proper nouns. However, we were using common nouns for relationship types. Thus, I switched to transitive verbs for relationship types ([commit](https://github.com/dhimmel/integrate/commit/8ca7c9e971ce5a85c7729b3f1df7db54beb19d18)). The table below shows the noun (old) and verb (new) relationship type.\r\n\r\n| Source | Target | Metaedge (noun) | Metaedge (verb) |\r\n|----------|------------|--------|------------|\r\n| compound | gene | binding | binds |\r\n| compound | side effect | causation | causes |\r\n| compound | gene | downregulation | downregulates |\r\n| compound | disease | indication | palliates |\r\n| compound | compound | similarity | resembles |\r\n| compound | disease | indication | treats |\r\n| compound | gene | upregulation | upregulates |\r\n| disease | gene | association | associates |\r\n| disease | gene | downregulation | downregulates |\r\n| disease | anatomy | localization | localizes |\r\n| disease | symptom | presence | presents |\r\n| disease | disease | similarity | resembles |\r\n| disease | gene | upregulation | upregulates |\r\n| gene | anatomy | downregulation | downregulates |\r\n| gene | gene | evolution | evolves |\r\n| gene | anatomy | expression | expresses |\r\n| gene | gene | interaction | interacts |\r\n| gene | biological process | participation | participates |\r\n| gene | cellular component | participation | participates |\r\n| gene | molecular function | participation | participates |\r\n| gene | pathway | participation | participates |\r\n| gene | perturbation | regulation | regulates |\r\n| gene | anatomy | upregulation | upregulates |\r\n| gene | gene | knockdown downregulation | knockdown downregulates |\r\n| gene | gene | knockdown upregulation | knockdown upregulates |\r\n| gene | gene | overexpression downregulation | overexpression downregulates |\r\n| gene | gene | overexpression upregulation | overexpression upregulates |\r\n\r\nIn several cases, switching from noun to verb cut out several characters -- a welcome occurrence. Switching relationship types to verbs also makes sense as part of our [migration to neo4j](http://thinklab.com/discussion/using-the-neo4j-graph-database-for-hetnets/112). The neo4j convention is to use verbs for relationship types. In fact, a neo4j company [explains relationships](https://www.graphstory.com/elements-of-a-graph-database) by saying:\r\n\r\n> Where nodes can be thought of as nouns, relationships can be thought of as verbs.",
      "comment_id": 804,
      "profile_id": 17,
      "published": "2016-02-17T22:39:04.375084Z",
      "thread_id": 162,
      "url": "/discussion/data-nomenclature-naming-and-abbreviating-our-network-types/162#2"
    },
    {
      "body_html": "<p>The compound-gene associations are not intuitive to me. I assume that when, for example, a compound downregulates a gene, it is supposed to mean that the compound inhibits the protein product encoded by the gene. However, if read at face value, it would mean that the compound binds to something else that through some signaling results in down-regulation of the gene (i.e. less transcription).</p>\r\n\r\n<p>The gene-gene association \"evolves\" is bit of a misnomer, I think. Unless you are looking at ancestral genes, one gene will not have evolved from another gene. Rather two genes will share ancestry. In that case, the term \"homology\" is would be much clearer. Also, you probably want to be able to distinguish between orthologs and paralogs in your network.</p>\r\n\r\n<p>Are the gene-anatomy relationships not backwards? I can understand what it means that means that the liver \"upregulates\" a gene (I assume it means that the gene is higher expressed in the liver than elsewhere). But I cannot comprehend what it would mean that a gene upregulates the liver.</p>\r\n\r\n<p>Same goes for gene-pertubation relationships. I can understand that a pertubation regulates a gene, but how can a gene regulate a pertubation? And why is this type of association not divided into up- and down-regulation like everything else?</p>\r\n\r\n<p>I am not entirely sure how useful the \"knockdown downregulates\" etc. types are. Usually \"knockdown downregulates\" would be interpreted to mean \"upregulates\" etc.</p>",
      "body_md": "The compound-gene associations are not intuitive to me. I assume that when, for example, a compound downregulates a gene, it is supposed to mean that the compound inhibits the protein product encoded by the gene. However, if read at face value, it would mean that the compound binds to something else that through some signaling results in down-regulation of the gene (i.e. less transcription).\r\n\r\nThe gene-gene association \"evolves\" is bit of a misnomer, I think. Unless you are looking at ancestral genes, one gene will not have evolved from another gene. Rather two genes will share ancestry. In that case, the term \"homology\" is would be much clearer. Also, you probably want to be able to distinguish between orthologs and paralogs in your network.\r\n\r\nAre the gene-anatomy relationships not backwards? I can understand what it means that means that the liver \"upregulates\" a gene (I assume it means that the gene is higher expressed in the liver than elsewhere). But I cannot comprehend what it would mean that a gene upregulates the liver.\r\n\r\nSame goes for gene-pertubation relationships. I can understand that a pertubation regulates a gene, but how can a gene regulate a pertubation? And why is this type of association not divided into up- and down-regulation like everything else?\r\n\r\nI am not entirely sure how useful the \"knockdown downregulates\" etc. types are. Usually \"knockdown downregulates\" would be interpreted to mean \"upregulates\" etc.",
      "comment_id": 814,
      "profile_id": 125,
      "published": "2016-02-18T06:21:08.503360Z",
      "thread_id": 162,
      "url": "/discussion/data-nomenclature-naming-and-abbreviating-our-network-types/162#3"
    },
    {
      "body_html": "<blockquote><p>I assume that when, for example, a compound downregulates a gene, it is supposed to mean that the compound inhibits the protein product encoded by the gene. However, if read at face value, it would mean that the compound binds to something else that through some signaling results in down-regulation of the gene (i.e. less transcription).</p></blockquote>\r\n\r\n<p>Your face value interpretation is correct. Compound–downregulates–Gene means the compound decreases the transcriptional expression of the gene. We <a href=\"http://thinklab.com/discussion/computing-consensus-transcriptional-profiles-for-compounds-using-lincs/43#6\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d43\">extracted these relationships</a> from LINCS L1000.</p>\r\n\r\n<blockquote><p>The gene-gene association \"evolves\" is bit of a misnomer</p></blockquote>\r\n\r\n<p>I agree, \"evolves\" is not good. This edge signifies <a href=\"http://thinklab.com/discussion/selecting-informative-erc-evolutionary-rate-covariation-values-between-genes/57\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d57\">evolutionary rate covariation</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pgen.1004967\" class=\"citation\" data-key=\"10.1371/journal.pgen.1004967\">1</a>]</span>. It's a mouthful, and I don't know the best way to shorten and verbify it. Perhaps \"covaries\" is an improvement?</p>\r\n\r\n<blockquote><p>Are the gene-anatomy relationships not backwards? … Same goes for gene-pertubation relationships.</p></blockquote>\r\n\r\n<p>Great point. We should present these edges in subject-verb-object order. I have switched the default orientation of the confusing metaedges (<a href=\"https://github.com/dhimmel/integrate/commit/3354a4cbb36d184f46e78831fa0f605ff92e7637)\" title=\"GitHub · dhimmel/integrate @ 3354a4cbb36d184f46e78831fa0f605ff92e7637\">commit</a>). In practice the object-verb-subject order may still arise, for example when representing paths.</p>\r\n\r\n<blockquote><p>I am not entirely sure how useful the \"knockdown downregulates\" etc. types are. Usually \"knockdown downregulates\" would be interpreted to mean \"upregulates\" etc.</p></blockquote>\r\n\r\n<p>I will look into collapsing:</p>\r\n\r\n<ul><li><em>knockdown downregulates</em> with <em>overexpression upregulates</em> to create an <em>upregulates</em> edge</li><li><em>knockdown upregulates</em> with <em>overexpression downregulates</em> to create a <em>downregulates</em> edge</li></ul>",
      "body_md": "> I assume that when, for example, a compound downregulates a gene, it is supposed to mean that the compound inhibits the protein product encoded by the gene. However, if read at face value, it would mean that the compound binds to something else that through some signaling results in down-regulation of the gene (i.e. less transcription).\r\n\r\nYour face value interpretation is correct. Compound--downregulates--Gene means the compound decreases the transcriptional expression of the gene. We [extracted these relationships](http://thinklab.com/discussion/computing-consensus-transcriptional-profiles-for-compounds-using-lincs/43#6) from LINCS L1000.\r\n\r\n> The gene-gene association \"evolves\" is bit of a misnomer\r\n\r\nI agree, \"evolves\" is not good. This edge signifies [evolutionary rate covariation](http://thinklab.com/discussion/selecting-informative-erc-evolutionary-rate-covariation-values-between-genes/57) [@10.1371/journal.pgen.1004967]. It's a mouthful, and I don't know the best way to shorten and verbify it. Perhaps \"covaries\" is an improvement?\r\n\r\n> Are the gene-anatomy relationships not backwards? … Same goes for gene-pertubation relationships.\r\n\r\nGreat point. We should present these edges in subject-verb-object order. I have switched the default orientation of the confusing metaedges ([commit](https://github.com/dhimmel/integrate/commit/3354a4cbb36d184f46e78831fa0f605ff92e7637) \"GitHub · dhimmel/integrate @ 3354a4cbb36d184f46e78831fa0f605ff92e7637\")). In practice the object-verb-subject order may still arise, for example when representing paths.\r\n\r\n> I am not entirely sure how useful the \"knockdown downregulates\" etc. types are. Usually \"knockdown downregulates\" would be interpreted to mean \"upregulates\" etc.\r\n\r\nI will look into collapsing:\r\n\r\n+ _knockdown downregulates_ with _overexpression upregulates_ to create an _upregulates_ edge\r\n+ _knockdown upregulates_ with _overexpression downregulates_ to create a _downregulates_ edge",
      "comment_id": 815,
      "profile_id": 17,
      "published": "2016-02-18T19:59:49.447133Z",
      "thread_id": 162,
      "url": "/discussion/data-nomenclature-naming-and-abbreviating-our-network-types/162#4"
    },
    {
      "body_html": "<h1>Initial results from the third curator</h1>\r\n\r\n<p>I was initially recruited to break the 444 disagreements between the other curators. After an initial pilot review of the first 80 or so disagreements, I noted some ambiguity in definition of the three classes that appeared to be giving rise to some of the disagreements. I discussed these with Daniel and we reached a more precise amended set of definitions.</p>\r\n\r\n<h3>Definitions:</h3>\r\n\r\n<ul><li><strong>disease modifying (DM) </strong> — a drug that therapeutically changes the underlying or downstream biology of the disease</li><li><strong>symptomatic (SYM) </strong> — a drug that treats a significant symptom of the disease</li><li><strong>non-indication (NOT) </strong> — a drug that neither therapeutically changes the underlying or downstream biology nor treats a significant symptom of the disease</li></ul>\r\n\r\n<h3>Guidelines:</h3>\r\n\r\n<ul><li><strong>reasonable evidence</strong> of efficacy is required to be classified as disease modifying or symptomatic. This includes off-label use.</li><li>if no classification accurately describes an indication, the <strong>most appropriate</strong> (although imperfect) classification should be chosen</li></ul>\r\n\r\n<h3>Amendments: (created 1/27/16, not seen by AJG and CSH)</h3>\r\n\r\n<ul><li><strong>Amendment 1: </strong> if a drug was <strong>previously indicated, but is no longer used</strong> due to side effects, or because there are better drugs, it is still considered <strong>DM</strong></li><li><strong>Amendment 2: </strong> it <strong>doesn't matter whether it is first line or fifth line</strong>, it's still considered <strong>DM</strong></li></ul>\r\n\r\n<h3>Assumptions: (by PK)</h3>\r\n\r\n<ul><li><strong>Assumption 1: DM trumps SYM. </strong> If a drug is clearly both disease modifying and also treats symptoms, then I will call it disease modifying. This is because most disease modifying drugs also treat symptoms.</li><li><strong>Assumption 2: SYM trumps NOT.</strong> If a drug is clearly symptomatic treatment, but can actually exacerbate the downstream biology of disease, then I chose SYM. I made this choice because this was the choice I saw most often made by AJG and CSH</li></ul>\r\n\r\n<p>With the revised definitions above, I reviewed the 444 disagreements as well as the 944 agreements (and suggested a change on 124 of these). I was not blinded to the other curators' decisions. I was able to see both of their decisions and also any comments they had left regarding their reasoning. In general, my strategy was to look three sources for each drug (unless I clearly already knew that a drug was DM or SYM): uptodate.com, drugbank.ca (link provided by Daniel in the spreadsheet), and a basic google search (which also served as a proxy for a pubmed search). When I noted that one of the two curators was calling an indication which I was not aware of (either DM or SYM), I would do a much more detailed search including a more detailed google search and a direct pubmed search. </p>\r\n\r\n<p>Below is the breakdown of classifications</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>class</th><th>AJG</th><th>CSH</th><th>PK</th><th></th><th>class</th><th>AJG</th><th>CSH</th><th>PK</th></tr></thead><tbody><tr><td>DM</td><td>599</td><td>593</td><td>755</td><td></td><td>DM</td><td>43.2%</td><td>42.7%</td><td>54.4%</td></tr><tr><td>SYM</td><td>514</td><td>517</td><td>390</td><td></td><td>SYM</td><td>37.0%</td><td>37.2%</td><td>28.1%</td></tr><tr><td>NOT</td><td>275</td><td>278</td><td>243</td><td></td><td>NOT</td><td>19.8%</td><td>20.0%</td><td>17.5%</td></tr><tr><td>total</td><td>1388</td><td>1388</td><td>1388</td><td></td><td>total</td><td>100.0%</td><td>100.0%</td><td>100.0%</td></tr></tbody></table>\r\n\r\n<p>The most notable difference was that I called DM more often than the other curators. There are at least two reasons for this. First, I was making use of amendment 1 and amendment 2 to make calls for DM, whereas the other curators were not using these amendments (in fact, when the other curators called NOT, they left comments such as \"no longer recommended due to side effects\", \"not used anymore\", or \"rarely used\"). Second, when I found a disagreement between two curators, I was more likely to agree with the curator who called DM. Specifically, of the 444 disagreements, there were 298 where one curator chose DM; of these 298 instances, I chose DM 204 times. I think this is because I did a more detailed search when I knew that one other curator thought that there was a DM indication. Of note, of the 146 times that the other curators were in disagreement between SYM and NOT, I chose SYM 76 times, I chose NOT 52 times, and I chose DM 18 times, likely for the same reasons described above.</p>\r\n\r\n<p>The <a href=\"https://github.com/dhimmel/indications/blob/d3d57b07abcf8d7af55f8e42ef7c4c99acd87ca8/curation/pk/template-pk%20final.xlsx\">excel spreadsheet</a> includes a detailed discussion of every decision that I made. I will not re-iterate here the instances where I used one of the amendments above to change a call or to resolve a disagreement. I will also not detail instances where I changed a call because I thought another curator made a human error (for example, not classifying two proton-pump inhibitors in the same way for the same disease). I will also not re-iterate cases where I felt that one of the two other curators knew about an indication (either DM or SYM) and I was able to confirm evidence of this indication.</p>\r\n\r\n<p>I would like to enter into the discussion the cases where there was a tough decision to be made, and would like to welcome an open discussion to come to a consensus. In general, when there was a tough decision, I did look at the other curators' calls to see what the consensus would be. Below is a summary of this discussion (with greater detail given in the spreadsheet), organized by disease and drug class.</p>\r\n\r\n<ul><li><p><strong>hypertension, general </strong>— Hypertension (the disease entity) is a heterogenous group of diseases. The most likely subtype of hypertension was likely Essential Hypertension (ET). The disease of Hypertension (including ET) progresses to have complications such as strokes and heart attacks. Hypertension (i.e. high blood pressure) is also a symptom (of many diseases, including diseases that are not called \"hypertension\"). Within the disease of ET, hypertension is not just a symptom but also a marker of disease progression, i.e. controlling blood pressure (treating this symptom) will slow the advancement of the disease hypertension and prevent downstream biology (proven by evidence, guideline 1). Therefore, by assumption 1, a total of 29 drugs were called <strong>DM</strong> rather than SYM.</p></li><li><p><strong>hypertension, diuretics </strong>—all called <strong>DM</strong> due to amendment 1 and amendment 2</p></li><li><p><strong>hypertension, drugs used to treat ocular hypertension or pulmonary hypertension </strong>— \"hypertension\" as defined in Daniel's link as \"chronic elevated blood pressure in the arteries\" It is therefore not the same as \"ocular hypertension\" or \"pulmonary hypertension\" (I think the spirit of the definition is systemic arteries, not pulmonary arteries. Also, pulmonary hypertension is quite a different disease with different pharmacology).Therefore, I chose to put <strong>NOT</strong> for all of these.</p></li><li><p><strong>type 2 diabetes, drugs that lower blood sugar </strong>—Diabetes is similar to hypertension. The disease is a tendency to have high blood sugar (hyperglycemia). Hyperglycemia is a symptom (of both diabetes and other diseases). Within the disease of diabetes, hyperglycemia is both a symptom and a marker of disease progression. Therefore anything that lowers hyperglycemia will be <strong>DM</strong>.</p></li><li><p><strong>type 1 and type 2 diabetes, ACE inhibitors and ARBs </strong>— The downstream biology of DM2 includes proteinuria and eventual renal failure. ACE inhibitors and ARBs prevent this downstream biology in DM2 patients. Therefore they are <strong>DM</strong>.</p></li><li><p><strong>epilepsy, anti-epileptic drugs </strong>—I think that for consistency, all anti-epileptics should be either DM or SYM, as there is only very limited evidence that any of these drugs are different from each other. My thoughts would be to label them all as <strong>DM</strong>. Here is why: epilepsy syndrome (disease) is defined as a propensity to have seizures (symptom). However, the natural downstream biology of the disease is that each seizure that you actually have makes you more likely to have worse epilepsy in the future (i.e. seizures beget more seizures). One mechanism is that when you have a lot of seizures, you develop mesial temporal sclerosis, and mesial temporal sclerosis is a risk factor for further seizures. Therefore, I would argue that any drug which treats the symptom of seizure is actually affecting downstream biology, and is therefore disease modifying. And by assumption 1, DM trumps SYM.</p></li><li><p><strong>osteoarthritis, NSAIDs and steroids </strong>— I put everything as <strong>SYM</strong>. From <a href=\"http://emedicine.medscape.com/article/330487-medication\">MedScape</a>: \"To date, no disease-modifying or structure-modifying intervention has been proved effective in osteoarthritis.\" CSH agreed with this interpretation, while it was clear that AJG was conflicted. To play devil's advocate, you could potentially say that the biology of osteoarthritis (OA) that it starts with inflammation, and the \"down-stream\" biology is the pain (the primary symptom as well), and therefore NSAIDs prevent \"down-stream\" biology. However, if we want to make that decision, I think we should change all the NSAIDs and steroids to DM.</p></li><li><p><strong>cancers, pain medications </strong>— I think pain is a symptom of cancer and therefore I put all of these as <strong>SYM</strong>. CSH agreed, while AJG was conflicted and sometimes called NOT. </p></li><li><p><strong>hematologic cancers, steroids </strong>—steroids actually \"treat\" hematologic cancers, even though these days there are much better meds and steroids are not considered \"treatment\", in the past they were the first line. By amendment 1, I put all of these as <strong>DM</strong>.</p></li><li><p><strong>non-hematologic cancers, steroids </strong>— steroids treat the nausea symptoms associated with cancers. While many cancers can potentially cause nausea, most nausea in cancer patients is due to side effect of chemo. However, I still put <strong>SYM</strong> for these because they can treat nausea and nausea is potentially a side effect of any cancer. CSH agreed with me on most of these, AJG was conflicted.</p></li><li><p><strong>cancers, hydroxyurea and other chemotherapies </strong>— AJG called this DM for all cancers. CSH called it DM only for the cancers for which it is indicated. The truth is, any chemotherapy has theoretical benefit against any cancer (any quickly-reproducing cell type). One possibility would be to label all chemotherapies as DM for all cancers. I thought it would be better to be selective and only label DM for chemo that is used (or has been used) in a particular cancer. That way, the results of the drug-repurposing search would yield different results for different cancers (rather than giving the exact same result for all cancers because the input was exactly the same for all cancers).Thus, I labeled some <strong>DM</strong> and some as <strong>NOT</strong>.</p></li><li><p><strong>cancers, bisphosphonates </strong>— I don't think of bone loss as a \"side effect\" of cancers (at least not any of the cancers listed). Some people are malnourished and/or have drug-induced bone loss, or may have bone metastases, but I don't think this captures the essence of cancer. I chose to put <strong>NOT</strong> for all of these (CSH agreed, AJG generally chose SYM).</p></li><li><p><strong>coronary artery disease, drug to treat hypertension or diabetes </strong>— I treated this as pure coronary artery disease (CAD) in the absence of other causes. I did not interpret this as \"CAD as a consequence of hypertension (HTN)\" or \"CAD as a consequence of diabetes (DM2)\". It is true that many of these medications would help prevent CAD if CAD is considered as the \"downstream biology\" of HTN or DM2. However, the medications to not treat any biology downstream of CAD in the absence of HTN or DM2. I therefore labeled these as <strong>NOT</strong>.</p></li><li><p><strong>coronary artery disease, diuretics and other drugs used for congestive heart failure (CHF) </strong>— I consider these to be <strong>DM</strong>. Consider CHF as a common dowstream biology of coronary artery disease (CAD), specifically let's consider HFrEF. The biology of HFrEF is that the heart has poor cardiac output, thus there is fluid retention, thus there is further strain on the heart, creating a vicious cycle. Thus, diuretics should help avoid the vicious cycle and slow the downstream progression of disease. While no trial may have ever showed mortality benefit, I think there is reasonable evidence that this would be true.</p></li><li><p><strong>migraine, general </strong>— While AJG called everything SYM, CSH called one drug (amitryptilene) DM and everything else SYM, citing that this medications \"may decrease frequency of migraines\". I agreed with CSH's interpretation and actually chose to include many other medications as DM based on the same reasoning. Migraine disease is a propensity to get migraine headaches. Therefore, anything that decreased migraine frequency was considered by me to be <strong>DM</strong> (decreases the downstream biology that leads to headache). Anything that treated the pain of the headache I considered <strong>SYM</strong>.</p></li><li><p><strong>autoimmune diseases, steroids and NSAIDs </strong>— I labeled the steroids as <strong>DM</strong> and the NSAIDs as <strong>SYM</strong>. It is true that steroids are rarely if ever actually used for chronic disease (though often used to treat the symptoms of flares), mostly because of their terrible side-effect profile long-term. However, they do actually affect disease biology and do not specifically treat any specific symptom (for example, steroids do not cure \"weakness\", but do change the biology of the multiple sclerosis flare to help the patient recover from \"weakness\"). It was a close call for me for NSAIDs (as they do have anti-inflammatory properties, especially useful in the auto-immune arthritidies), but I went with consensus and chose SYM. The other curators tended not to call steroids DM (probably because they were thinking about side-effect profile), and they were inconsistent on their calls on NSAIDs.</p></li><li><p><strong>asthma, steroids and beta-agonists and anticholinergics </strong>— I put <strong>DM</strong> for all of these. I felt steroids are DM (since they are given to prevent attacks), long-acting beta-agonists are also DM in my opinion since they prevent attacks (in conjunction with steroids, despite the small increased risk of asthma-related death in people who don't use steroids). I put short acting beta-agonists as DM because they too can prevent downstream biology (since they are sometimes used, for example before exercise, to prevent downstream biology from happening).</p></li><li><p><strong>allergic rhinitis, steroids and anti-histamines and decongestants </strong>— CSH admittedly had a problem with this, she even noted \"im having a hard time with allergic rhinitis. Maybe all of these meds are SYM.\".  AJG was conflicted as well.  I chose to mark all of the steroids and anti-histamines as <strong>DM</strong> because they alter the immune response (the allergy). I chose to mark the decongestants (i.e. pseudoephedrine) as <strong>SYM</strong> because they treat a symptom (congestion) but not the underyling biology (the immune reaction)</p></li><li><p><strong>chronic obstructive pulmonary disease (COPD), general </strong>— I put steroids and beta-agonists as <strong>DM</strong> for similar reasons to asthma, though admittedly there is less evidence for this. I put all the antibiotics as <strong>SYM</strong> (they don't eradicate infection, they don't delay progression, they treat attacks) and did not differentiate between the antibiotics</p></li><li><p><strong>glaucoma, general </strong>— I agreed with CSH that almost every drug is DM, AJG was conflicted. I think it's more <strong>DM</strong>, based on similar discussion as hypertension.</p></li><li><p><strong>alcohol dependence, general </strong>— First, I included symptoms of alcohol withdrawal along with alcohol dependence, presumably because withdrawal symptoms are probably felt at some point in any person with alcohol dependence. Thus, I chose to mark chlordiazepoxide and zofran (used to treat withdrawal) as <strong>SYM</strong> (CSH agreed with both, AJG agreed with one of these). Next, there was the question of drugs designed to curb drinking (Citalopram, Disulfiram, Naltrexone, Acamprosate); I chose to mark these as <strong>DM</strong> because they are different from the drugs above in that they treat the urge to drink (modifying the disease) rather than the symptoms of not drinking (AJG agreed with all 5, CSH agreed with 1)</p></li><li><p><strong>psychiatric diseases other than alcohol/drug dependence, general </strong>— I agreed with both CSH and AJG that in general, the medications used are all <strong>SYM</strong> rather than DM (other than alcohol and nicotine dependence as described).</p></li><li><p><strong>alzheimer's disease, general </strong>— donepezil was marked as <strong>DM</strong> (agreed with AJG) because it is supposed to slow disease, not treat any specific symptom. Other cholinesterase inhibitors were changed to DM to match donepezil. I chose to group all antipsychotics as <strong>SYM</strong> in order to be consistent (AJG and CSH agreed most of the time)</p></li><li><p><strong>anemia </strong>— there is no good way to do this. Anemia is not a single disease, it is a very heterogeneous set of diseases (with very little overlap between sub-types in terms of incidence or pathophysiology). Though the most common cause of anemia is likely iron deficiency anemia, iron deficiency anemia accounts for probably a minority of all anemias. Specific types of anemia will of course respond to specific drugs  (autoimmune anemia to steroids, folate deficiency responds to folate, etc...). I was faced with two choices: (1) choose DM for anything which could treat any type of anemia or (2) choose DM for anything which could treat most types of anemia. Choice (2) means nothing will link to anemia (no DM or SYM) and anemia will essentially be removed from analysis. Choice (1) means we are choosing a variety of drugs to treat a variety of illnesses. I chose choice (2) because I think it's best to ignore anemia, given that it is such a heterogeneous set of diseases. AJG and CSH were rather inconsistent in their answers, it is clear that they too had difficulty with anemia. In summary, everything was marked as <strong>NOT</strong>.</p></li></ul>",
      "body_md": "# Initial results from the third curator\r\nI was initially recruited to break the 444 disagreements between the other curators. After an initial pilot review of the first 80 or so disagreements, I noted some ambiguity in definition of the three classes that appeared to be giving rise to some of the disagreements. I discussed these with Daniel and we reached a more precise amended set of definitions.\r\n### Definitions:\r\n- **disease modifying (DM) ** — a drug that therapeutically changes the underlying or downstream biology of the disease\r\n- **symptomatic (SYM) ** — a drug that treats a significant symptom of the disease\r\n-  **non-indication (NOT) ** — a drug that neither therapeutically changes the underlying or downstream biology nor treats a significant symptom of the disease\r\n### Guidelines:\r\n- **reasonable evidence** of efficacy is required to be classified as disease modifying or symptomatic. This includes off-label use.\r\n- if no classification accurately describes an indication, the **most appropriate** (although imperfect) classification should be chosen\r\n### Amendments: (created 1/27/16, not seen by AJG and CSH)\r\n- **Amendment 1: ** if a drug was **previously indicated, but is no longer used** due to side effects, or because there are better drugs, it is still considered **DM**\r\n- **Amendment 2: ** it **doesn't matter whether it is first line or fifth line**, it's still considered **DM**\r\n### Assumptions: (by PK)\r\n- **Assumption 1: DM trumps SYM. ** If a drug is clearly both disease modifying and also treats symptoms, then I will call it disease modifying. This is because most disease modifying drugs also treat symptoms.\r\n- **Assumption 2: SYM trumps NOT.** If a drug is clearly symptomatic treatment, but can actually exacerbate the downstream biology of disease, then I chose SYM. I made this choice because this was the choice I saw most often made by AJG and CSH\r\n\r\nWith the revised definitions above, I reviewed the 444 disagreements as well as the 944 agreements (and suggested a change on 124 of these). I was not blinded to the other curators' decisions. I was able to see both of their decisions and also any comments they had left regarding their reasoning. In general, my strategy was to look three sources for each drug (unless I clearly already knew that a drug was DM or SYM): uptodate.com, drugbank.ca (link provided by Daniel in the spreadsheet), and a basic google search (which also served as a proxy for a pubmed search). When I noted that one of the two curators was calling an indication which I was not aware of (either DM or SYM), I would do a much more detailed search including a more detailed google search and a direct pubmed search. \r\n\r\nBelow is the breakdown of classifications\r\n\r\n|class | AJG | CSH | PK |  | class | AJG | CSH | PK\r\n|---|---|---|---|---|---|---|---|---|\r\n|DM | 599 | 593 | 755 |  | DM | 43.2% | 42.7% | 54.4%|\r\n|SYM | 514 | 517 | 390 |  | SYM | 37.0% | 37.2% | 28.1%|\r\n|NOT | 275 | 278 | 243 |  | NOT | 19.8% | 20.0% | 17.5%|\r\n|total | 1388 | 1388 | 1388 |  | total | 100.0% | 100.0% | 100.0%|\r\n\r\nThe most notable difference was that I called DM more often than the other curators. There are at least two reasons for this. First, I was making use of amendment 1 and amendment 2 to make calls for DM, whereas the other curators were not using these amendments (in fact, when the other curators called NOT, they left comments such as \"no longer recommended due to side effects\", \"not used anymore\", or \"rarely used\"). Second, when I found a disagreement between two curators, I was more likely to agree with the curator who called DM. Specifically, of the 444 disagreements, there were 298 where one curator chose DM; of these 298 instances, I chose DM 204 times. I think this is because I did a more detailed search when I knew that one other curator thought that there was a DM indication. Of note, of the 146 times that the other curators were in disagreement between SYM and NOT, I chose SYM 76 times, I chose NOT 52 times, and I chose DM 18 times, likely for the same reasons described above.\r\n\r\nThe [excel spreadsheet](https://github.com/dhimmel/indications/blob/d3d57b07abcf8d7af55f8e42ef7c4c99acd87ca8/curation/pk/template-pk%20final.xlsx) includes a detailed discussion of every decision that I made. I will not re-iterate here the instances where I used one of the amendments above to change a call or to resolve a disagreement. I will also not detail instances where I changed a call because I thought another curator made a human error (for example, not classifying two proton-pump inhibitors in the same way for the same disease). I will also not re-iterate cases where I felt that one of the two other curators knew about an indication (either DM or SYM) and I was able to confirm evidence of this indication.\r\n\r\nI would like to enter into the discussion the cases where there was a tough decision to be made, and would like to welcome an open discussion to come to a consensus. In general, when there was a tough decision, I did look at the other curators' calls to see what the consensus would be. Below is a summary of this discussion (with greater detail given in the spreadsheet), organized by disease and drug class.\r\n\r\n- **hypertension, general **— Hypertension (the disease entity) is a heterogenous group of diseases. The most likely subtype of hypertension was likely Essential Hypertension (ET). The disease of Hypertension (including ET) progresses to have complications such as strokes and heart attacks. Hypertension (i.e. high blood pressure) is also a symptom (of many diseases, including diseases that are not called \"hypertension\"). Within the disease of ET, hypertension is not just a symptom but also a marker of disease progression, i.e. controlling blood pressure (treating this symptom) will slow the advancement of the disease hypertension and prevent downstream biology (proven by evidence, guideline 1). Therefore, by assumption 1, a total of 29 drugs were called **DM** rather than SYM.\r\n\r\n- **hypertension, diuretics **—all called **DM** due to amendment 1 and amendment 2\r\n\r\n- **hypertension, drugs used to treat ocular hypertension or pulmonary hypertension **— \"hypertension\" as defined in Daniel's link as \"chronic elevated blood pressure in the arteries\" It is therefore not the same as \"ocular hypertension\" or \"pulmonary hypertension\" (I think the spirit of the definition is systemic arteries, not pulmonary arteries. Also, pulmonary hypertension is quite a different disease with different pharmacology).Therefore, I chose to put **NOT** for all of these.\r\n\r\n- **type 2 diabetes, drugs that lower blood sugar **—Diabetes is similar to hypertension. The disease is a tendency to have high blood sugar (hyperglycemia). Hyperglycemia is a symptom (of both diabetes and other diseases). Within the disease of diabetes, hyperglycemia is both a symptom and a marker of disease progression. Therefore anything that lowers hyperglycemia will be **DM**.\r\n\r\n- **type 1 and type 2 diabetes, ACE inhibitors and ARBs **— The downstream biology of DM2 includes proteinuria and eventual renal failure. ACE inhibitors and ARBs prevent this downstream biology in DM2 patients. Therefore they are **DM**.\r\n\r\n- **epilepsy, anti-epileptic drugs **—I think that for consistency, all anti-epileptics should be either DM or SYM, as there is only very limited evidence that any of these drugs are different from each other. My thoughts would be to label them all as **DM**. Here is why: epilepsy syndrome (disease) is defined as a propensity to have seizures (symptom). However, the natural downstream biology of the disease is that each seizure that you actually have makes you more likely to have worse epilepsy in the future (i.e. seizures beget more seizures). One mechanism is that when you have a lot of seizures, you develop mesial temporal sclerosis, and mesial temporal sclerosis is a risk factor for further seizures. Therefore, I would argue that any drug which treats the symptom of seizure is actually affecting downstream biology, and is therefore disease modifying. And by assumption 1, DM trumps SYM.\r\n\r\n- **osteoarthritis, NSAIDs and steroids **— I put everything as **SYM**. From [MedScape](http://emedicine.medscape.com/article/330487-medication): \"To date, no disease-modifying or structure-modifying intervention has been proved effective in osteoarthritis.\" CSH agreed with this interpretation, while it was clear that AJG was conflicted. To play devil's advocate, you could potentially say that the biology of osteoarthritis (OA) that it starts with inflammation, and the \"down-stream\" biology is the pain (the primary symptom as well), and therefore NSAIDs prevent \"down-stream\" biology. However, if we want to make that decision, I think we should change all the NSAIDs and steroids to DM.\r\n\r\n- **cancers, pain medications **— I think pain is a symptom of cancer and therefore I put all of these as **SYM**. CSH agreed, while AJG was conflicted and sometimes called NOT. \r\n\r\n- **hematologic cancers, steroids **—steroids actually \"treat\" hematologic cancers, even though these days there are much better meds and steroids are not considered \"treatment\", in the past they were the first line. By amendment 1, I put all of these as **DM**.\r\n\r\n- **non-hematologic cancers, steroids **— steroids treat the nausea symptoms associated with cancers. While many cancers can potentially cause nausea, most nausea in cancer patients is due to side effect of chemo. However, I still put **SYM** for these because they can treat nausea and nausea is potentially a side effect of any cancer. CSH agreed with me on most of these, AJG was conflicted.\r\n\r\n- **cancers, hydroxyurea and other chemotherapies **— AJG called this DM for all cancers. CSH called it DM only for the cancers for which it is indicated. The truth is, any chemotherapy has theoretical benefit against any cancer (any quickly-reproducing cell type). One possibility would be to label all chemotherapies as DM for all cancers. I thought it would be better to be selective and only label DM for chemo that is used (or has been used) in a particular cancer. That way, the results of the drug-repurposing search would yield different results for different cancers (rather than giving the exact same result for all cancers because the input was exactly the same for all cancers).Thus, I labeled some **DM** and some as **NOT**.\r\n\r\n- **cancers, bisphosphonates **— I don't think of bone loss as a \"side effect\" of cancers (at least not any of the cancers listed). Some people are malnourished and/or have drug-induced bone loss, or may have bone metastases, but I don't think this captures the essence of cancer. I chose to put **NOT** for all of these (CSH agreed, AJG generally chose SYM).\r\n\r\n- **coronary artery disease, drug to treat hypertension or diabetes **— I treated this as pure coronary artery disease (CAD) in the absence of other causes. I did not interpret this as \"CAD as a consequence of hypertension (HTN)\" or \"CAD as a consequence of diabetes (DM2)\". It is true that many of these medications would help prevent CAD if CAD is considered as the \"downstream biology\" of HTN or DM2. However, the medications to not treat any biology downstream of CAD in the absence of HTN or DM2. I therefore labeled these as **NOT**.\r\n\r\n- **coronary artery disease, diuretics and other drugs used for congestive heart failure (CHF) **— I consider these to be **DM**. Consider CHF as a common dowstream biology of coronary artery disease (CAD), specifically let's consider HFrEF. The biology of HFrEF is that the heart has poor cardiac output, thus there is fluid retention, thus there is further strain on the heart, creating a vicious cycle. Thus, diuretics should help avoid the vicious cycle and slow the downstream progression of disease. While no trial may have ever showed mortality benefit, I think there is reasonable evidence that this would be true.\r\n\r\n- **migraine, general **— While AJG called everything SYM, CSH called one drug (amitryptilene) DM and everything else SYM, citing that this medications \"may decrease frequency of migraines\". I agreed with CSH's interpretation and actually chose to include many other medications as DM based on the same reasoning. Migraine disease is a propensity to get migraine headaches. Therefore, anything that decreased migraine frequency was considered by me to be **DM** (decreases the downstream biology that leads to headache). Anything that treated the pain of the headache I considered **SYM**.\r\n\r\n- **autoimmune diseases, steroids and NSAIDs **— I labeled the steroids as **DM** and the NSAIDs as **SYM**. It is true that steroids are rarely if ever actually used for chronic disease (though often used to treat the symptoms of flares), mostly because of their terrible side-effect profile long-term. However, they do actually affect disease biology and do not specifically treat any specific symptom (for example, steroids do not cure \"weakness\", but do change the biology of the multiple sclerosis flare to help the patient recover from \"weakness\"). It was a close call for me for NSAIDs (as they do have anti-inflammatory properties, especially useful in the auto-immune arthritidies), but I went with consensus and chose SYM. The other curators tended not to call steroids DM (probably because they were thinking about side-effect profile), and they were inconsistent on their calls on NSAIDs.\r\n\r\n- **asthma, steroids and beta-agonists and anticholinergics **— I put **DM** for all of these. I felt steroids are DM (since they are given to prevent attacks), long-acting beta-agonists are also DM in my opinion since they prevent attacks (in conjunction with steroids, despite the small increased risk of asthma-related death in people who don't use steroids). I put short acting beta-agonists as DM because they too can prevent downstream biology (since they are sometimes used, for example before exercise, to prevent downstream biology from happening).\r\n\r\n- **allergic rhinitis, steroids and anti-histamines and decongestants **— CSH admittedly had a problem with this, she even noted \"im having a hard time with allergic rhinitis. Maybe all of these meds are SYM.\".  AJG was conflicted as well.  I chose to mark all of the steroids and anti-histamines as **DM** because they alter the immune response (the allergy). I chose to mark the decongestants (i.e. pseudoephedrine) as **SYM** because they treat a symptom (congestion) but not the underyling biology (the immune reaction)\r\n\r\n- **chronic obstructive pulmonary disease (COPD), general **— I put steroids and beta-agonists as **DM** for similar reasons to asthma, though admittedly there is less evidence for this. I put all the antibiotics as **SYM** (they don't eradicate infection, they don't delay progression, they treat attacks) and did not differentiate between the antibiotics\r\n\r\n- **glaucoma, general **— I agreed with CSH that almost every drug is DM, AJG was conflicted. I think it's more **DM**, based on similar discussion as hypertension.\r\n\r\n- **alcohol dependence, general **— First, I included symptoms of alcohol withdrawal along with alcohol dependence, presumably because withdrawal symptoms are probably felt at some point in any person with alcohol dependence. Thus, I chose to mark chlordiazepoxide and zofran (used to treat withdrawal) as **SYM** (CSH agreed with both, AJG agreed with one of these). Next, there was the question of drugs designed to curb drinking (Citalopram, Disulfiram, Naltrexone, Acamprosate); I chose to mark these as **DM** because they are different from the drugs above in that they treat the urge to drink (modifying the disease) rather than the symptoms of not drinking (AJG agreed with all 5, CSH agreed with 1)\r\n\r\n- **psychiatric diseases other than alcohol/drug dependence, general **— I agreed with both CSH and AJG that in general, the medications used are all **SYM** rather than DM (other than alcohol and nicotine dependence as described).\r\n\r\n- **alzheimer's disease, general **— donepezil was marked as **DM** (agreed with AJG) because it is supposed to slow disease, not treat any specific symptom. Other cholinesterase inhibitors were changed to DM to match donepezil. I chose to group all antipsychotics as **SYM** in order to be consistent (AJG and CSH agreed most of the time)\r\n\r\n- **anemia **— there is no good way to do this. Anemia is not a single disease, it is a very heterogeneous set of diseases (with very little overlap between sub-types in terms of incidence or pathophysiology). Though the most common cause of anemia is likely iron deficiency anemia, iron deficiency anemia accounts for probably a minority of all anemias. Specific types of anemia will of course respond to specific drugs  (autoimmune anemia to steroids, folate deficiency responds to folate, etc...). I was faced with two choices: (1) choose DM for anything which could treat any type of anemia or (2) choose DM for anything which could treat most types of anemia. Choice (2) means nothing will link to anemia (no DM or SYM) and anemia will essentially be removed from analysis. Choice (1) means we are choosing a variety of drugs to treat a variety of illnesses. I chose choice (2) because I think it's best to ignore anemia, given that it is such a heterogeneous set of diseases. AJG and CSH were rather inconsistent in their answers, it is clear that they too had difficulty with anemia. In summary, everything was marked as **NOT**.",
      "comment_id": 900,
      "profile_id": 188,
      "published": "2016-02-20T03:13:15.931940Z",
      "thread_id": 95,
      "url": "/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95#7"
    },
    {
      "body_html": "<h1>Overly broad and thus uninformative diseases</h1>\r\n\r\n<p><a href=\"/u/pouyakhankhanian\" class=\"username\">@pouyakhankhanian</a>, fantastic curation!</p>\r\n\r\n<p>From your comments, it appears that some of our diseases are too general from a pharmacological perspective. For example, you mention anemia and hypertension as particularly troublesome. To recap how we arrived at our 137 diseases, I <a href=\"http://thinklab.com/discussion/unifying-disease-vocabularies/44#6\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d44\">selected the subset</a> of Disease Ontology terms that have been analyzed using GWAS or were a 'body system' cancer. When diseases were redundant, a single disease was chosen (for example, coronary artery disease was chosen over myocardial infarction). In retrospect, input from physicians would have been prudent during this stage.</p>\r\n\r\n<p>When we created our <a href=\"http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#21\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d21\">indication catalog</a> (which we're curating here), I propagated indications from specific to more general terms. For example, an indication for non-small cell lung carcinoma (<code>DOID:3908</code>) would be considered an indication for lung cancer (<code>DOID:1324</code>).</p>\r\n\r\n<p>In the cases of hypertension and anemia, <a href=\"/u/pouyakhankhanian\" class=\"username\">@pouyakhankhanian</a> found this practice problematic. Specifically, he considered pulmonary hypertension (<code>DOID:6432</code>) to be \"quite a different disease with different pharmacology\" than the definition of hypertension (<code>DOID:10763</code>). However the Disease Ontology defines pulmonary hypertension as a subtype of hypertension. Ocular hypertension (<code>DOID:9282</code>) is not a subtype — instead it's part of the glaucoma lineage. He also mentioned anemia as having heterogeneous subtypes.</p>\r\n\r\n<p>While my original guidance would have been to chose DM or SYM if the drug is DM or SYM for any subtype, I see the point that some diseases may be too broad and therefore uninformative for our prediction approach.</p>",
      "body_md": "# Overly broad and thus uninformative diseases\r\n\r\n@pouyakhankhanian, fantastic curation!\r\n\r\nFrom your comments, it appears that some of our diseases are too general from a pharmacological perspective. For example, you mention anemia and hypertension as particularly troublesome. To recap how we arrived at our 137 diseases, I [selected the subset](http://thinklab.com/discussion/unifying-disease-vocabularies/44#6) of Disease Ontology terms that have been analyzed using GWAS or were a 'body system' cancer. When diseases were redundant, a single disease was chosen (for example, coronary artery disease was chosen over myocardial infarction). In retrospect, input from physicians would have been prudent during this stage.\r\n\r\nWhen we created our [indication catalog](http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#21) (which we're curating here), I propagated indications from specific to more general terms. For example, an indication for non-small cell lung carcinoma (`DOID:3908`) would be considered an indication for lung cancer (`DOID:1324`).\r\n\r\nIn the cases of hypertension and anemia, @pouyakhankhanian found this practice problematic. Specifically, he considered pulmonary hypertension (`DOID:6432`) to be \"quite a different disease with different pharmacology\" than the definition of hypertension (`DOID:10763`). However the Disease Ontology defines pulmonary hypertension as a subtype of hypertension. Ocular hypertension (`DOID:9282`) is not a subtype -- instead it's part of the glaucoma lineage. He also mentioned anemia as having heterogeneous subtypes.\r\n\r\nWhile my original guidance would have been to chose DM or SYM if the drug is DM or SYM for any subtype, I see the point that some diseases may be too broad and therefore uninformative for our prediction approach.",
      "comment_id": 905,
      "profile_id": 17,
      "published": "2016-02-23T00:20:34.010990Z",
      "thread_id": 95,
      "url": "/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95#8"
    },
    {
      "body_html": "<h1>Redundant terms removed from the slim DO</h1>\r\n\r\n<p>My <a href=\"#6\">above post</a> on creating the slim DO didn't specify which diseases were removed to \"resolve overlapping nodes\". The table below shows which diseases we removed and why (rules above). The exclusions counts by rule are: 7 for rule 1, 22 for rule 2, and 5 for rule 3.</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>ID</th><th>Name</th><th>Source</th><th>Removed by</th></tr></thead><tbody><tr><td>DOID:201</td><td>Connective tissue cancer</td><td>DOcancerslim</td><td>rule 1</td></tr><tr><td>DOID:10155</td><td>Intestinal cancer</td><td>DOcancerslim</td><td>rule 1</td></tr><tr><td>DOID:5672</td><td>Large intestine cancer</td><td>DOcancerslim</td><td>rule 1</td></tr><tr><td>DOID:3119</td><td>Gastrointestinal system cancer</td><td>DOcancerslim</td><td>rule 1</td></tr><tr><td>DOID:8618</td><td>Oral cavity cancer</td><td>DOcancerslim</td><td>rule 1</td></tr><tr><td>DOID:170</td><td>Endocrine gland cancer</td><td>DOcancerslim</td><td>rule 1</td></tr><tr><td>DOID:3996</td><td>Urinary system cancer</td><td>DOcancerslim</td><td>rule 1</td></tr><tr><td>DOID:3459</td><td>breast carcinoma</td><td>hetio</td><td>rule 2</td></tr><tr><td>DOID:10286</td><td>prostate carcinoma</td><td>hetio</td><td>rule 2</td></tr><tr><td>DOID:1040</td><td>chronic lymphocytic leukemia</td><td>hetio</td><td>rule 2</td></tr><tr><td>DOID:3905</td><td>lung carcinoma</td><td>hetio</td><td>rule 2</td></tr><tr><td>DOID:1909</td><td>melanoma</td><td>hetio</td><td>rule 2</td></tr><tr><td>DOID:4001</td><td>ovarian carcinoma</td><td>hetio</td><td>rule 2</td></tr><tr><td>DOID:1107</td><td>esophageal carcinoma</td><td>hetio</td><td>rule 2</td></tr><tr><td>DOID:4007</td><td>bladder carcinoma</td><td>hetio</td><td>rule 2</td></tr><tr><td>DOID:289</td><td>endometriosis</td><td>hetio</td><td>rule 2</td></tr><tr><td>DOID:4450</td><td>renal cell carcinoma</td><td>hetio</td><td>rule 2</td></tr><tr><td>DOID:769</td><td>neuroblastoma</td><td>hetio</td><td>rule 2</td></tr><tr><td>DOID:8567</td><td>Hodgkin's lymphoma</td><td>hetio</td><td>rule 2</td></tr><tr><td>DOID:3963</td><td>thyroid carcinoma</td><td>hetio</td><td>rule 2</td></tr><tr><td>DOID:9538</td><td>multiple myeloma</td><td>hetio</td><td>rule 2</td></tr><tr><td>DOID:9952</td><td>acute lymphocytic leukemia</td><td>hetio</td><td>rule 2</td></tr><tr><td>DOID:5517</td><td>stomach carcinoma</td><td>hetio</td><td>rule 2</td></tr><tr><td>DOID:684</td><td>hepatocellular carcinoma</td><td>hetio</td><td>rule 2</td></tr><tr><td>DOID:1380</td><td>endometrial cancer</td><td>hetio</td><td>rule 2</td></tr><tr><td>DOID:4905</td><td>pancreatic carcinoma</td><td>hetio</td><td>rule 2</td></tr><tr><td>DOID:4960</td><td>bone marrow cancer</td><td>hetio</td><td>rule 2</td></tr><tr><td>DOID:706</td><td>mature B-cell neoplasm</td><td>hetio</td><td>rule 2</td></tr><tr><td>DOID:8552</td><td>chronic myeloid leukemia</td><td>hetio</td><td>rule 2</td></tr><tr><td>DOID:5844</td><td>myocardial infarction</td><td>hetio</td><td>rule 3</td></tr><tr><td>DOID:6713</td><td>cerebrovascular disease</td><td>hetio</td><td>rule 3</td></tr><tr><td>DOID:11829</td><td>degenerative myopia</td><td>hetio</td><td>rule 3</td></tr><tr><td>DOID:13641</td><td>exfoliation syndrome</td><td>hetio</td><td>rule 3</td></tr><tr><td>DOID:3324</td><td>mood disorder</td><td>hetio</td><td>rule 3</td></tr></tbody></table>\r\n\r\n<p>See the <a href=\"https://github.com/dhimmel/disease-ontology/blob/5cb93c38568536222b0a14fbcb7fb644a348931d/data/slim-terms.tsv\">remaining 137 diseases here</a>.</p>",
      "body_md": "# Redundant terms removed from the slim DO\r\n\r\nMy [above post](#6) on creating the slim DO didn't specify which diseases were removed to \"resolve overlapping nodes\". The table below shows which diseases we removed and why (rules above). The exclusions counts by rule are: 7 for rule 1, 22 for rule 2, and 5 for rule 3.\r\n\r\n| ID | Name | Source | Removed by |\r\n|------------|--------------------------------|--------------|------------|\r\n| DOID:201 | Connective tissue cancer | DOcancerslim | rule 1 |\r\n| DOID:10155 | Intestinal cancer | DOcancerslim | rule 1 |\r\n| DOID:5672 | Large intestine cancer | DOcancerslim | rule 1 |\r\n| DOID:3119 | Gastrointestinal system cancer | DOcancerslim | rule 1 |\r\n| DOID:8618 | Oral cavity cancer | DOcancerslim | rule 1 |\r\n| DOID:170 | Endocrine gland cancer | DOcancerslim | rule 1 |\r\n| DOID:3996 | Urinary system cancer | DOcancerslim | rule 1 |\r\n| DOID:3459 | breast carcinoma | hetio | rule 2 |\r\n| DOID:10286 | prostate carcinoma | hetio | rule 2 |\r\n| DOID:1040 | chronic lymphocytic leukemia | hetio | rule 2 |\r\n| DOID:3905 | lung carcinoma | hetio | rule 2 |\r\n| DOID:1909 | melanoma | hetio | rule 2 |\r\n| DOID:4001 | ovarian carcinoma | hetio | rule 2 |\r\n| DOID:1107 | esophageal carcinoma | hetio | rule 2 |\r\n| DOID:4007 | bladder carcinoma | hetio | rule 2 |\r\n| DOID:289 | endometriosis | hetio | rule 2 |\r\n| DOID:4450 | renal cell carcinoma | hetio | rule 2 |\r\n| DOID:769 | neuroblastoma | hetio | rule 2 |\r\n| DOID:8567 | Hodgkin's lymphoma | hetio | rule 2 |\r\n| DOID:3963 | thyroid carcinoma | hetio | rule 2 |\r\n| DOID:9538 | multiple myeloma | hetio | rule 2 |\r\n| DOID:9952 | acute lymphocytic leukemia | hetio | rule 2 |\r\n| DOID:5517 | stomach carcinoma | hetio | rule 2 |\r\n| DOID:684 | hepatocellular carcinoma | hetio | rule 2 |\r\n| DOID:1380 | endometrial cancer | hetio | rule 2 |\r\n| DOID:4905 | pancreatic carcinoma | hetio | rule 2 |\r\n| DOID:4960 | bone marrow cancer | hetio | rule 2 |\r\n| DOID:706 | mature B-cell neoplasm | hetio | rule 2 |\r\n| DOID:8552 | chronic myeloid leukemia | hetio | rule 2 |\r\n| DOID:5844 | myocardial infarction | hetio | rule 3 |\r\n| DOID:6713 | cerebrovascular disease | hetio | rule 3 |\r\n| DOID:11829 | degenerative myopia | hetio | rule 3 |\r\n| DOID:13641 | exfoliation syndrome | hetio | rule 3 |\r\n| DOID:3324 | mood disorder | hetio | rule 3 |\r\n\r\nSee the [remaining 137 diseases here](https://github.com/dhimmel/disease-ontology/blob/5cb93c38568536222b0a14fbcb7fb644a348931d/data/slim-terms.tsv).",
      "comment_id": 906,
      "profile_id": 17,
      "published": "2016-02-20T23:36:08.170080Z",
      "thread_id": 44,
      "url": "/discussion/unifying-disease-vocabularies/44#7"
    },
    {
      "body_html": "<h1>Indication terminology</h1>\r\n\r\n<p>We've been referred to when a drug treats a disease as an \"<a href=\"https://en.wikipedia.org/w/index.php?title=Indication_(medicine)&amp;oldid=703054912\" title=\"Wikipedia · Indication (medicine)\">indication</a>\". While readers with a medical background understand the term, others find \"indication\" confusing. </p>\r\n\r\n<p>Now <a href=\"http://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d95\">we've split our indications</a> into two categories: disease-modifying and symptomatic. Additionally, we've switched to <a href=\"#2\">using verbs</a> to describe relationships. </p>\r\n\r\n<p>Given these factors, I chose \"treats\" for disease-modifying indications and \"palliates\" for symptomatic indications. This terminology aligns with a recent repurposing study <span class=\"citation\">[<a href=\"https://doi.org/10.1038/ncomms10331\" class=\"citation\" data-key=\"10.1038/ncomms10331\">1</a>]</span>, which refers to</p>\r\n\r\n<blockquote><p>distinguishing non-causative and palliative from causative and effective treatments</p></blockquote>\r\n\r\n<p>While readers may not be familiar with the term palliates, it has an applicable and precise <a href=\"http://www.oxforddictionaries.com/us/definition/american_english/palliate\">definition</a> (making lookup easier):</p>\r\n\r\n<blockquote><p>Make (a disease or its symptoms) less severe or unpleasant without removing the cause</p></blockquote>\r\n\r\n<p><a href=\"/u/pouyakhankhanian\" class=\"username\">@pouyakhankhanian</a>, do you think the treats/palliates terminology makes sense?</p>",
      "body_md": "# Indication terminology\r\n\r\nWe've been referred to when a drug treats a disease as an \"[indication](https://en.wikipedia.org/w/index.php?title=Indication_(medicine)&oldid=703054912 \"Wikipedia · Indication (medicine)\")\". While readers with a medical background understand the term, others find \"indication\" confusing. \r\n\r\nNow [we've split our indications](http://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95) into two categories: disease-modifying and symptomatic. Additionally, we've switched to [using verbs](#2) to describe relationships. \r\n\r\nGiven these factors, I chose \"treats\" for disease-modifying indications and \"palliates\" for symptomatic indications. This terminology aligns with a recent repurposing study [@10.1038/ncomms10331], which refers to\r\n\r\n> distinguishing non-causative and palliative from causative and effective treatments\r\n\r\nWhile readers may not be familiar with the term palliates, it has an applicable and precise [definition](http://www.oxforddictionaries.com/us/definition/american_english/palliate) (making lookup easier):\r\n\r\n> Make (a disease or its symptoms) less severe or unpleasant without removing the cause\r\n\r\n@pouyakhankhanian, do you think the treats/palliates terminology makes sense?",
      "comment_id": 1004,
      "profile_id": 17,
      "published": "2016-02-22T23:47:56.149928Z",
      "thread_id": 162,
      "url": "/discussion/data-nomenclature-naming-and-abbreviating-our-network-types/162#5"
    },
    {
      "body_html": "<p><a href=\"/u/alessandrodidonna\" class=\"username\">@alessandrodidonna</a> suggested adding RNA interference data, so we <a href=\"http://thinklab.com/discussion/suggestions-for-additional-information-types/22#6\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d22\">incorporated genetic perturbation relationships</a> from LINCS L1000. The L1000 project measures how the expression of 978 genes (called landmark genes) changes in response to perturbation. Here we are focusing on gene knockdown (shRNA) and gene overexpression perturbations.</p>\r\n\r\n<p>We <a href=\"http://thinklab.com/discussion/computing-consensus-transcriptional-profiles-for-compounds-using-lincs/43#6\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d43\">computed consensus transcriptional profiles</a> for knockdown (<a href=\"http://support.lincscloud.org/hc/en-us/articles/202216073-Perturbation-Types\" title=\"lincscloud Perturbation Types\"><code>pert_type = trt_sh</code></a>) and overexpression (<code>pert_type = trt_oe</code>) perturbations. For each gene perturbation, we end up with a vector of 978 z-scores representing the change in expression of each landmark gene. Using a Bonferroni cutoff to correct for the 978 comparisons, we identify the significantly upregulated and downregulated genes for each perturbation. Using this approach, we generate four relationship types for our network:</p>\r\n\r\n<ol><li>Gene → knockdown downregulates → Gene</li><li>Gene → knockdown upregulates → Gene</li><li>Gene → overexpression downregulates → Gene</li><li>Gene → overexpression upregulates → Gene</li></ol>\r\n\r\n<p>In a <a href=\"http://thinklab.com/discussion/data-nomenclature-naming-and-abbreviating-our-network-types/162#3\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d162\">separate discussion</a>, <a href=\"/u/larsjuhljensen\" class=\"username\">@larsjuhljensen</a> commented:</p>\r\n\r\n<blockquote><p>I am not entirely sure how useful the \"knockdown downregulates\" etc. types are. Usually \"knockdown downregulates\" would be interpreted to mean \"upregulates\" etc.</p></blockquote>\r\n\r\n<p>In other words, shouldn't we combine relationship types 1 &amp; 4 above into \"Gene → upregulates → Gene\" and 2 &amp; 3 into \"Gene → downregulates → Gene\"? To investigate whether this makes sense, I looked into whether knockdown and overexpression profiles for the same gene were anticorrelated. Does knocking down a gene have the opposite trascriptional effect as overexpressing it?</p>\r\n\r\n<p>The results were surprising (<a href=\"https://github.com/dhimmel/lincs/blob/00c55f95ead78bec72b9c7255f38b512c4a3da30/binarize-consensi.ipynb\">notebook</a>). Knockdown and overexpression of the same gene resulted in positively correlated transcriptional profiles 65.0% of the time. And if we correlate the knockdown of a random gene with the overexpression of a different random gene, we see a positive correlation 65.3% of the time. In summary, the transcriptional profiles of knocking down and overexpressing genes are more often than not positively correlated. And profiles for the same gene show no more correlation or anticorrelation than profiles for two different genes. Hmm.</p>\r\n\r\n<p><img src=\"https://github.com/dhimmel/lincs/raw/00c55f95ead78bec72b9c7255f38b512c4a3da30/viz/knockdown-overexpression-corr.png\" alt=\"Violinplots of correlation distributions\"></p>\r\n\r\n<p>What could cause this counterintuitive finding?</p>\r\n\r\n<ul><li>We could have a mistake in our code. Does anyone know of a gold standard for genetic perturbations that we could compare to?</li><li>By looking only at the 978 landmark genes, we are overlooking the crucial genes and instead picking up on a general perturbation response.</li><li>Gene regulation is a non-linear process.</li><li>Our method of analysis or the LINCS L1000 data may be limitated.</li></ul>\r\n\r\n<p>Does anyone, specifically those with gene expression experience (<a href=\"/u/caseygreene\" class=\"username\">@caseygreene</a>, <a href=\"/u/larsjuhljensen\" class=\"username\">@larsjuhljensen</a>, <a href=\"/u/fbastian\" class=\"username\">@fbastian</a>), have any insight on what might be happening? I'll also reach out to the L1000 team.</p>",
      "body_md": "@alessandrodidonna suggested adding RNA interference data, so we [incorporated genetic perturbation relationships](http://thinklab.com/discussion/suggestions-for-additional-information-types/22#6) from LINCS L1000. The L1000 project measures how the expression of 978 genes (called landmark genes) changes in response to perturbation. Here we are focusing on gene knockdown (shRNA) and gene overexpression perturbations.\r\n\r\nWe [computed consensus transcriptional profiles](http://thinklab.com/discussion/computing-consensus-transcriptional-profiles-for-compounds-using-lincs/43#6) for knockdown ([`pert_type = trt_sh`](http://support.lincscloud.org/hc/en-us/articles/202216073-Perturbation-Types \"lincscloud Perturbation Types\")) and overexpression (`pert_type = trt_oe`) perturbations. For each gene perturbation, we end up with a vector of 978 z-scores representing the change in expression of each landmark gene. Using a Bonferroni cutoff to correct for the 978 comparisons, we identify the significantly upregulated and downregulated genes for each perturbation. Using this approach, we generate four relationship types for our network:\r\n\r\n1. Gene → knockdown downregulates → Gene\r\n2. Gene → knockdown upregulates → Gene\r\n3. Gene → overexpression downregulates → Gene\r\n4. Gene → overexpression upregulates → Gene\r\n\r\nIn a [separate discussion](http://thinklab.com/discussion/data-nomenclature-naming-and-abbreviating-our-network-types/162#3), @larsjuhljensen commented:\r\n\r\n> I am not entirely sure how useful the \"knockdown downregulates\" etc. types are. Usually \"knockdown downregulates\" would be interpreted to mean \"upregulates\" etc.\r\n\r\nIn other words, shouldn't we combine relationship types 1 & 4 above into \"Gene → upregulates → Gene\" and 2 & 3 into \"Gene → downregulates → Gene\"? To investigate whether this makes sense, I looked into whether knockdown and overexpression profiles for the same gene were anticorrelated. Does knocking down a gene have the opposite trascriptional effect as overexpressing it?\r\n\r\nThe results were surprising ([notebook](https://github.com/dhimmel/lincs/blob/00c55f95ead78bec72b9c7255f38b512c4a3da30/binarize-consensi.ipynb)). Knockdown and overexpression of the same gene resulted in positively correlated transcriptional profiles 65.0% of the time. And if we correlate the knockdown of a random gene with the overexpression of a different random gene, we see a positive correlation 65.3% of the time. In summary, the transcriptional profiles of knocking down and overexpressing genes are more often than not positively correlated. And profiles for the same gene show no more correlation or anticorrelation than profiles for two different genes. Hmm.\r\n\r\n![Violinplots of correlation distributions](https://github.com/dhimmel/lincs/raw/00c55f95ead78bec72b9c7255f38b512c4a3da30/viz/knockdown-overexpression-corr.png)\r\n\r\nWhat could cause this counterintuitive finding?\r\n\r\n+ We could have a mistake in our code. Does anyone know of a gold standard for genetic perturbations that we could compare to?\r\n+ By looking only at the 978 landmark genes, we are overlooking the crucial genes and instead picking up on a general perturbation response.\r\n+ Gene regulation is a non-linear process.\r\n+ Our method of analysis or the LINCS L1000 data may be limitated.\r\n\r\nDoes anyone, specifically those with gene expression experience (@caseygreene, @larsjuhljensen, @fbastian), have any insight on what might be happening? I'll also reach out to the L1000 team.",
      "comment_id": 1051,
      "profile_id": 17,
      "published": "2016-02-26T17:17:30.858537Z",
      "thread_id": 171,
      "url": "/discussion/positive-correlations-between-knockdown-and-overexpression-profiles-from-lincs-l1000/171"
    },
    {
      "body_html": "<p>Re: \"While my original guidance would have been to chose DM or SYM if the drug is DM or SYM for any subtype, I see the point that some diseases may be too broad and therefore uninformative for our prediction approach.\"</p>\r\n\r\n<p>I actually think either approach is reasonable. The key would be to maintain consistency throughout the curation process. After making a final decision on how to proceed, we can go back and ensure that we are being consistent.</p>\r\n\r\n<p>I also think we may want to consider the relative frequency of subtypes of disease. For example, \"lung cancer\" has probably three very common subtypes which each account for 25-30% of the total entity of \"lung cancer\". Similarly, 90-95% of \"Hypertension\" is accounted for by \"essential hypertension\", even if you include \"pulmonary hypertension\". in contrast, most of the subtypes of \"anemia\" included in this curation each account for probably less than 1-2% of all \"anemia\".</p>",
      "body_md": "Re: \"While my original guidance would have been to chose DM or SYM if the drug is DM or SYM for any subtype, I see the point that some diseases may be too broad and therefore uninformative for our prediction approach.\"\r\n\r\nI actually think either approach is reasonable. The key would be to maintain consistency throughout the curation process. After making a final decision on how to proceed, we can go back and ensure that we are being consistent.\r\n\r\nI also think we may want to consider the relative frequency of subtypes of disease. For example, \"lung cancer\" has probably three very common subtypes which each account for 25-30% of the total entity of \"lung cancer\". Similarly, 90-95% of \"Hypertension\" is accounted for by \"essential hypertension\", even if you include \"pulmonary hypertension\". in contrast, most of the subtypes of \"anemia\" included in this curation each account for probably less than 1-2% of all \"anemia\".",
      "comment_id": 1059,
      "profile_id": 188,
      "published": "2016-02-23T12:59:08.531425Z",
      "thread_id": 95,
      "url": "/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95#9"
    },
    {
      "body_html": "<p>I certainly agree with maintaining the terminology consistent with prior studies. I think the terms \"indication and \"palliates\" are well defined as you describe. My only concern is the use of the word \"treat\" to mean \"disease-modifying\" as opposed to symptom management, especially since it is very common to use the phrase \"treat symptoms\". </p>\r\n\r\n<p>If there are other prior studies that use alternate terminology, it might be best to align with those. Otherwise, I would think the two goals are (1) maintain previous terminology and (2) make sure to define our terminology very clearly.</p>",
      "body_md": "I certainly agree with maintaining the terminology consistent with prior studies. I think the terms \"indication and \"palliates\" are well defined as you describe. My only concern is the use of the word \"treat\" to mean \"disease-modifying\" as opposed to symptom management, especially since it is very common to use the phrase \"treat symptoms\". \r\n\r\nIf there are other prior studies that use alternate terminology, it might be best to align with those. Otherwise, I would think the two goals are (1) maintain previous terminology and (2) make sure to define our terminology very clearly.",
      "comment_id": 1061,
      "profile_id": 188,
      "published": "2016-02-23T14:43:26.748895Z",
      "thread_id": 162,
      "url": "/discussion/data-nomenclature-naming-and-abbreviating-our-network-types/162#6"
    },
    {
      "body_html": "<h1>Results from all three curators</h1>\r\n\r\n<p>To recap our curation effort thus far, we first had AJG and CSH (<a href=\"/u/chrissyhessler\" class=\"username\">@chrissyhessler</a>) independently classify the 1388 indications. Then a third curator, PK (<a href=\"/u/pouyakhankhanian\" class=\"username\">@pouyakhankhanian</a>), classified each indication with access to the picks and notes from the first two curators.</p>\r\n\r\n<p>PK provided <a href=\"#7\">detailed documentation</a> of his methodology, with a focus on instances of disagreement. I now report of the results from all three curators (<a href=\"https://github.com/dhimmel/indications/blob/49cf8e3858f124e552051fc1e8c1c229a43dadf6/curation/results-three-curators.ipynb\">notebook</a>, <a href=\"https://github.com/dhimmel/indications/blob/49cf8e3858f124e552051fc1e8c1c229a43dadf6/curation/results-three-curators.tsv\">dataset</a>).</p>\r\n\r\n<p>PK's kappa coefficient was 51.5% with AJG and 65.1% with CSH. PK classified many indications as disease-modifying that the other curators considered symptomatic. Overall, there were <a href=\"https://github.com/dhimmel/indications/blob/49cf8e3858f124e552051fc1e8c1c229a43dadf6/curation/results-threeway-disagreements.tsv\">34 threeway disagreements</a> and <a href=\"https://github.com/dhimmel/indications/blob/49cf8e3858f124e552051fc1e8c1c229a43dadf6/curation/results-PK-changes.tsv\">124 instances</a> where PK disagreed with the consensus of the first two curators.</p>\r\n\r\n<h1>Reaching a consensus</h1>\r\n\r\n<p>The next step is to agree upon a consensus classification for each indication. These indications will go into our network and will be used to train our model for predicting drug repurposing.</p>\r\n\r\n<p>We would like the first two curators to review <a href=\"#7\">PK's methodology</a> and voice their opinions. In particular, do AJG and CSH agree with PK's reasoning that led him to reverse <a href=\"https://github.com/dhimmel/indications/blob/49cf8e3858f124e552051fc1e8c1c229a43dadf6/curation/results-PK-changes.tsv\">124 instances where they agreed</a>? Given this feedback, we will determine how to proceed.</p>",
      "body_md": "# Results from all three curators\r\n\r\nTo recap our curation effort thus far, we first had AJG and CSH (@chrissyhessler) independently classify the 1388 indications. Then a third curator, PK (@pouyakhankhanian), classified each indication with access to the picks and notes from the first two curators.\r\n\r\nPK provided [detailed documentation](#7) of his methodology, with a focus on instances of disagreement. I now report of the results from all three curators ([notebook](https://github.com/dhimmel/indications/blob/49cf8e3858f124e552051fc1e8c1c229a43dadf6/curation/results-three-curators.ipynb), [dataset](https://github.com/dhimmel/indications/blob/49cf8e3858f124e552051fc1e8c1c229a43dadf6/curation/results-three-curators.tsv)).\r\n\r\nPK's kappa coefficient was 51.5% with AJG and 65.1% with CSH. PK classified many indications as disease-modifying that the other curators considered symptomatic. Overall, there were [34 threeway disagreements](https://github.com/dhimmel/indications/blob/49cf8e3858f124e552051fc1e8c1c229a43dadf6/curation/results-threeway-disagreements.tsv) and [124 instances](https://github.com/dhimmel/indications/blob/49cf8e3858f124e552051fc1e8c1c229a43dadf6/curation/results-PK-changes.tsv) where PK disagreed with the consensus of the first two curators.\r\n\r\n# Reaching a consensus\r\n\r\nThe next step is to agree upon a consensus classification for each indication. These indications will go into our network and will be used to train our model for predicting drug repurposing.\r\n\r\nWe would like the first two curators to review [PK's methodology](#7) and voice their opinions. In particular, do AJG and CSH agree with PK's reasoning that led him to reverse [124 instances where they agreed](https://github.com/dhimmel/indications/blob/49cf8e3858f124e552051fc1e8c1c229a43dadf6/curation/results-PK-changes.tsv)? Given this feedback, we will determine how to proceed.",
      "comment_id": 1063,
      "profile_id": 17,
      "published": "2016-02-24T00:15:33.603406Z",
      "thread_id": 95,
      "url": "/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95#10"
    },
    {
      "body_html": "<p>I'm not sure the phrase \"drug X treats symptom Y\" is that problematic, since symptom Y is the sentence's subject rather than a disease. I agree that we should maintain existing terminology, but I'm not finding much guidance in the literature.</p>\r\n\r\n<p>Potential alternatives to \"treats\" for representing disease-modifying indications are: modifies, medicates, indicates, remedies, ameliorates, betters, improves, corrects, affects, alleviates, repairs, and cures. <a href=\"/u/pouyakhankhanian\" class=\"username\">@pouyakhankhanian</a>, do you prefer any of these verbs to \"treats\"?</p>\r\n\r\n<p>And regardless of which term we pick, we'll make sure to define each relationship type.</p>",
      "body_md": "I'm not sure the phrase \"drug X treats symptom Y\" is that problematic, since symptom Y is the sentence's subject rather than a disease. I agree that we should maintain existing terminology, but I'm not finding much guidance in the literature.\r\n\r\nPotential alternatives to \"treats\" for representing disease-modifying indications are: modifies, medicates, indicates, remedies, ameliorates, betters, improves, corrects, affects, alleviates, repairs, and cures. @pouyakhankhanian, do you prefer any of these verbs to \"treats\"?\r\n\r\nAnd regardless of which term we pick, we'll make sure to define each relationship type.",
      "comment_id": 1093,
      "profile_id": 17,
      "published": "2016-02-24T01:31:28.304553Z",
      "thread_id": 162,
      "url": "/discussion/data-nomenclature-naming-and-abbreviating-our-network-types/162#7"
    },
    {
      "body_html": "<p>We've previously discussed <a href=\"http://thinklab.com/discussion/permuting-hetnets-and-implementing-randomized-edge-swaps-in-cypher/136#1\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d136\">what hetnet permutation is and why we do it</a>. To permute a hetnet, we go through each relationship type (metaedge) and repeatedly swap the target nodes of two random relationships (edges). This strategy is called <code>XSwap</code> <span class=\"citation\">[<a href=\"https://doi.org/10.1137/1.9781611972795.67\" class=\"citation\" data-key=\"10.1137/1.9781611972795.67\">1</a>]</span>.</p>\r\n\r\n<p>We looked into performing the <a href=\"http://thinklab.com/discussion/permuting-hetnets-and-implementing-randomized-edge-swaps-in-cypher/136#2\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d136\">permutation in neo4j using cypher</a>, but decided to stick with our <a href=\"https://github.com/dhimmel/hetio/blob/a6c8a286ec0c7367673970c6ddda06cd47733034/hetio/permute.py#L7\" title=\"hetio.permute.permute_graph · dhimmel/hetio on GitHub\">python implementation</a> since cypher's cost planner currently lacks the needed abilities.</p>\r\n\r\n<h2>Implementation specifics</h2>\r\n\r\n<p>We closely followed the parameters from our previous study <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1004259\">2</a>]</span> and did the following:</p>\r\n\r\n<ul><li>We created 5 permuted hetnets. The first permutated hetnet was created from the unpermuted hetnet; the second permutated hetnet was created from the first permutated hetnet; and so on until the fifth permutated hetnet was created from the fourth permutated hetnet. This iterative strategy is referred to as a Markov chain.</li><li>To create each permuted hetnet, we separately permuted each metaedge. For a given metaedge, we attempted <em>n</em> XSwaps where <em>n</em> equals four times the number of edges (<code>multipler = 4</code>).</li><li>Xswaps can be unsuccessful for several reasons. The same edge could have been randomly selected twice (referred to as <code>same_edge</code>). One or both of the potential new edges may already exist (<code>duplicate</code> or <code>undirected_duplicate</code> for select cases where a biderectional edge connects two nodes of the same type). One or both of the potential new edges may connect a node to itself (<code>self_loop</code>). In these instances, no swap is performed. In the future, we may switch to stopping a completing permutation after a certain number of successes rather than attempts.</li></ul>\r\n\r\n<h2>Assessing permutation effectiveness</h2>\r\n\r\n<p>For each permutation and each metaedge, we measure the progress of the randomization at 10 points (<a href=\"https://github.com/dhimmel/integrate/blob/ebd71cd2157d26e52646b5b483f5c70293a84f71/data/permuted/stats.tsv\">dataset</a>). The measure we're primarily interested in is the percent of edges that are unchanged after a permutation (<code>unchanged</code>).</p>\r\n\r\n<p>We find that the percent of unchanged edges varies by metaedge (<a href=\"http://nbviewer.jupyter.org/github/dhimmel/integrate/blob/ebd71cd2157d26e52646b5b483f5c70293a84f71/data/permuted/evaluate-permutations.ipynb#How-many-permutations-are-needed-to-randomize-an-edge\">notebook cell 4</a>). It appears that we could safely reduce our multiplier from 4 to 2.5 and still generate permuted networks that are maximally diversified from their predecessor.</p>\r\n\r\n<p>Of concern are metaedges where a high percentage of the edges do not change. This occurred when a high percentage of swaps resulted in already existing edges (<a href=\"https://github.com/dhimmel/integrate/blob/ebd71cd2157d26e52646b5b483f5c70293a84f71/data/permuted/evaluate-permutations.ipynb\">notebook cell 6</a>). Particularly troublesome was the <em>Anatomy–expresses–Gene</em> edge where almost all attempts yielded duplicated edges and only ~10% of edges changed from a permutation. I'm now inclined to revisit our <a href=\"http://thinklab.com/discussion/processing-bgee-for-tissue-specific-gene-presence-and-overunder-expression/124#2\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d124\">previous observation</a> that we're being too permissive regarding expression edge inclusion.</p>\r\n\r\n<p>Metaedges whose edges do not change from permutation are limited in informativeness. Such edges hold little information besides their degree contribution to the nodes they connect. In the context of our expression edge, the problem is visible in the node degree distribution: most anatomies express 0 genes while a minority of anatomies express an extremely high number of genes (<a href=\"http://nbviewer.jupyter.org/github/dhimmel/integrate/blob/ebd71cd2157d26e52646b5b483f5c70293a84f71/viz/degrees.pdf#page=10\">see the <code>anatomy - expresses - gene</code> panel on page 10</a>).</p>",
      "body_md": "We've previously discussed [what hetnet permutation is and why we do it](http://thinklab.com/discussion/permuting-hetnets-and-implementing-randomized-edge-swaps-in-cypher/136#1). To permute a hetnet, we go through each relationship type (metaedge) and repeatedly swap the target nodes of two random relationships (edges). This strategy is called `XSwap` [@10.1137/1.9781611972795.67].\r\n\r\nWe looked into performing the [permutation in neo4j using cypher](http://thinklab.com/discussion/permuting-hetnets-and-implementing-randomized-edge-swaps-in-cypher/136#2), but decided to stick with our [python implementation](https://github.com/dhimmel/hetio/blob/a6c8a286ec0c7367673970c6ddda06cd47733034/hetio/permute.py#L7 \"hetio.permute.permute_graph · dhimmel/hetio on GitHub\") since cypher's cost planner currently lacks the needed abilities.\r\n\r\n## Implementation specifics\r\n\r\nWe closely followed the parameters from our previous study [@10.1371/journal.pcbi.1004259] and did the following:\r\n\r\n+ We created 5 permuted hetnets. The first permutated hetnet was created from the unpermuted hetnet; the second permutated hetnet was created from the first permutated hetnet; and so on until the fifth permutated hetnet was created from the fourth permutated hetnet. This iterative strategy is referred to as a Markov chain.\r\n+ To create each permuted hetnet, we separately permuted each metaedge. For a given metaedge, we attempted _n_ XSwaps where _n_ equals four times the number of edges (`multipler = 4`).\r\n+ Xswaps can be unsuccessful for several reasons. The same edge could have been randomly selected twice (referred to as `same_edge`). One or both of the potential new edges may already exist (`duplicate` or `undirected_duplicate` for select cases where a biderectional edge connects two nodes of the same type). One or both of the potential new edges may connect a node to itself (`self_loop`). In these instances, no swap is performed. In the future, we may switch to stopping a completing permutation after a certain number of successes rather than attempts.\r\n\r\n## Assessing permutation effectiveness\r\n\r\nFor each permutation and each metaedge, we measure the progress of the randomization at 10 points ([dataset](https://github.com/dhimmel/integrate/blob/ebd71cd2157d26e52646b5b483f5c70293a84f71/data/permuted/stats.tsv)). The measure we're primarily interested in is the percent of edges that are unchanged after a permutation (`unchanged`).\r\n\r\nWe find that the percent of unchanged edges varies by metaedge ([notebook cell 4](http://nbviewer.jupyter.org/github/dhimmel/integrate/blob/ebd71cd2157d26e52646b5b483f5c70293a84f71/data/permuted/evaluate-permutations.ipynb#How-many-permutations-are-needed-to-randomize-an-edge)). It appears that we could safely reduce our multiplier from 4 to 2.5 and still generate permuted networks that are maximally diversified from their predecessor.\r\n\r\nOf concern are metaedges where a high percentage of the edges do not change. This occurred when a high percentage of swaps resulted in already existing edges ([notebook cell 6](https://github.com/dhimmel/integrate/blob/ebd71cd2157d26e52646b5b483f5c70293a84f71/data/permuted/evaluate-permutations.ipynb)). Particularly troublesome was the _Anatomy--expresses--Gene_ edge where almost all attempts yielded duplicated edges and only ~10% of edges changed from a permutation. I'm now inclined to revisit our [previous observation](http://thinklab.com/discussion/processing-bgee-for-tissue-specific-gene-presence-and-overunder-expression/124#2) that we're being too permissive regarding expression edge inclusion.\r\n\r\nMetaedges whose edges do not change from permutation are limited in informativeness. Such edges hold little information besides their degree contribution to the nodes they connect. In the context of our expression edge, the problem is visible in the node degree distribution: most anatomies express 0 genes while a minority of anatomies express an extremely high number of genes ([see the `anatomy - expresses - gene` panel on page 10](http://nbviewer.jupyter.org/github/dhimmel/integrate/blob/ebd71cd2157d26e52646b5b483f5c70293a84f71/viz/degrees.pdf#page=10)).",
      "comment_id": 1135,
      "profile_id": 17,
      "published": "2016-02-25T22:56:18.333496Z",
      "thread_id": 178,
      "url": "/discussion/assessing-the-effectiveness-of-our-hetnet-permutations/178"
    },
    {
      "body_html": "<p>Quick thoughts: Is there a specific set of genes driving the positive correlation? Maybe perturbations in general lead to some change in, for example, growth rate? What, specifically, is your high correlation measuring? Is it possible that highly expressed genes tend to remain highly expressed, or did you transform the data in some way to normalize gene expression across conditions per gene.</p>",
      "body_md": "Quick thoughts: Is there a specific set of genes driving the positive correlation? Maybe perturbations in general lead to some change in, for example, growth rate? What, specifically, is your high correlation measuring? Is it possible that highly expressed genes tend to remain highly expressed, or did you transform the data in some way to normalize gene expression across conditions per gene.",
      "comment_id": 1137,
      "profile_id": 22,
      "published": "2016-02-26T17:26:44.322718Z",
      "thread_id": 171,
      "url": "/discussion/positive-correlations-between-knockdown-and-overexpression-profiles-from-lincs-l1000/171#2"
    },
    {
      "body_html": "<p>Messing about with cells always tends to induce some degree of stress-induced global expression changes. This is the case pretty much no matter which perturbation you do to the cells, including overexpression of some gene, knockdown of some gene, cell-cycle synchronization, centrifugation, increasing temperature, decreasing temperature, etc.</p>\r\n\r\n<p>My guess is that the small positive correlation you see is caused by small changes in expression of a large number of genes, which you could summarize as \"not a happy cell\".</p>",
      "body_md": "Messing about with cells always tends to induce some degree of stress-induced global expression changes. This is the case pretty much no matter which perturbation you do to the cells, including overexpression of some gene, knockdown of some gene, cell-cycle synchronization, centrifugation, increasing temperature, decreasing temperature, etc.\r\n\r\nMy guess is that the small positive correlation you see is caused by small changes in expression of a large number of genes, which you could summarize as \"not a happy cell\".",
      "comment_id": 1139,
      "profile_id": 125,
      "published": "2016-02-26T17:28:07.784153Z",
      "thread_id": 171,
      "url": "/discussion/positive-correlations-between-knockdown-and-overexpression-profiles-from-lincs-l1000/171#3"
    },
    {
      "body_html": "<blockquote><p>Did you transform the data in some way to normalize gene expression across conditions per gene.</p></blockquote>\r\n\r\n<p><a href=\"/u/caseygreene\" class=\"username\">@caseygreene</a>, our profiles contain <em>z</em>-scores measuring the differential expression for 978 genes. The profiles (called consensus signatures in <a href=\"http://support.lincscloud.org/hc/en-us/articles/202099616-Signature-Generation-and-Analysis-L1000-\">L1000 terminology</a>) are at the CONSENSUS stage in the following pipeline:</p>\r\n\r\n<p><img src=\"http://support.lincscloud.org/hc/en-us/article_attachments/200733106/data_flow.png\" alt=\"Processing of Broad LINCS data\"></p>\r\n\r\n<p>The <em>z</em>-scores compare a gene's expression level in cells given the perturbation to cells without the perturbation (controls). I believe the controls account for the non-specific disturbances caused by delivering the molecular payload, but will confirm.</p>\r\n\r\n<p>Now I will look into the following questions:</p>\r\n\r\n<ul><li><a href=\"/u/larsjuhljensen\" class=\"username\">@larsjuhljensen</a>: My guess is that the small positive correlation you see is caused by small changes in expression of a large number of genes.</li><li><a href=\"/u/caseygreene\" class=\"username\">@caseygreene</a>: Is there a specific set of genes driving the positive correlation?</li></ul>",
      "body_md": "> Did you transform the data in some way to normalize gene expression across conditions per gene.\r\n\r\n@caseygreene, our profiles contain _z_-scores measuring the differential expression for 978 genes. The profiles (called consensus signatures in [L1000 terminology](http://support.lincscloud.org/hc/en-us/articles/202099616-Signature-Generation-and-Analysis-L1000-)) are at the CONSENSUS stage in the following pipeline:\r\n\r\n![Processing of Broad LINCS data](http://support.lincscloud.org/hc/en-us/article_attachments/200733106/data_flow.png)\r\n\r\nThe _z_-scores compare a gene's expression level in cells given the perturbation to cells without the perturbation (controls). I believe the controls account for the non-specific disturbances caused by delivering the molecular payload, but will confirm.\r\n\r\nNow I will look into the following questions:\r\n\r\n+ @larsjuhljensen: My guess is that the small positive correlation you see is caused by small changes in expression of a large number of genes.\r\n+ @caseygreene: Is there a specific set of genes driving the positive correlation?",
      "comment_id": 1140,
      "profile_id": 17,
      "published": "2016-02-26T19:53:18.806257Z",
      "thread_id": 171,
      "url": "/discussion/positive-correlations-between-knockdown-and-overexpression-profiles-from-lincs-l1000/171#4"
    },
    {
      "body_html": "<h1>Methods for reducing the number of Bgee expression relationships</h1>\r\n\r\n<p><a href=\"/u/fbastian\" class=\"username\">@fbastian</a>, we're looking to reduce the number of expression relationships extracted from Bgee. Our motivation is twofold:</p>\r\n\r\n<ol><li>Our hetnet <a href=\"https://github.com/dhimmel/integrate/blob/dff453c020bbea953adc6cc3225235e445ba94f9/data/summary/metaedges.tsv#L3\" title=\"hetio-ind metaedge summaries\">currently contains</a> over 1 million <em>Anatomy–expresses–Gene</em> relationships. This high number of relationships is causing computational bottlenecks.</li><li>Our network permutations <a href=\"http://thinklab.com/discussion/assessing-the-effectiveness-of-our-hetnet-permutations/178#1\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d178\">do little to randomize the expression relationships</a>. In other words, too many expression relationships connect super anatomies — anatomies which express most genes — limiting the information content of the edge.</li></ol>\r\n\r\n<p>From our previous conversations, it appears that there are three ways to proceed:</p>\r\n\r\n<ol><li>Exclude relationships for general anatomies, as <a href=\"#3\">suggested above</a>.</li><li>Use only RNA-Seq experiments. <a href=\"/u/fbastian\" class=\"username\">@fbastian</a> <a href=\"http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#5\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d81\">mentions</a> that using only RNA-Seq data avoids the ambiguity states. So what happens when a gene is present in one experiment but not the other for the same data type and conditions? With RNA-seq we should be able to adjust the RPKM inclusion threshold.</li><li>Use unpropagated relationships, so for example genes expressed in for brain gray matter would not automatically be transmitted to brain.</li></ol>\r\n\r\n<p>These options are not mutually exclusive. We can choose any combination of the three.</p>\r\n\r\n<p>I am leaning towards option 3, because I think studies will often be performed on clinically relevant anatomies. In other words, we may accomplish the goal of 1 (removing overly broad anatomies) by including only relationships to their directly annotated anatomies. Additionally, since our hetnet contains <a href=\"http://thinklab.com/discussion/tissue-node/41#16\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d41\">many nested levels Uberon terms</a>,  we would not be throwing out too many experiments entirely. In the future, we can even write queries that perform the propagation in realtime.</p>\r\n\r\n<p><strong>Data complications:</strong> In <code>Homo_sapiens_expr-complete.tsv</code> version 13.1, all the values for <code>In situ call quality</code> and <code>In situ call quality</code> equal <code>no data</code>. Additionally, all values for <code>Including in situ observed data</code> are <code>no</code>. <a href=\"/u/fbastian\" class=\"username\">@fbastian</a>, I assume this is a bug? Is there a workaround? Advice on the specific filters to apply on which files to achieve options 2 or 3 would be appreciated.</p>",
      "body_md": "# Methods for reducing the number of Bgee expression relationships\r\n\r\n@fbastian, we're looking to reduce the number of expression relationships extracted from Bgee. Our motivation is twofold:\r\n\r\n1. Our hetnet [currently contains](https://github.com/dhimmel/integrate/blob/dff453c020bbea953adc6cc3225235e445ba94f9/data/summary/metaedges.tsv#L3 \"hetio-ind metaedge summaries\") over 1 million _Anatomy--expresses--Gene_ relationships. This high number of relationships is causing computational bottlenecks.\r\n2. Our network permutations [do little to randomize the expression relationships](http://thinklab.com/discussion/assessing-the-effectiveness-of-our-hetnet-permutations/178#1). In other words, too many expression relationships connect super anatomies -- anatomies which express most genes -- limiting the information content of the edge.\r\n\r\nFrom our previous conversations, it appears that there are three ways to proceed:\r\n\r\n1. Exclude relationships for general anatomies, as [suggested above](#3).\r\n2. Use only RNA-Seq experiments. @fbastian [mentions](http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#5) that using only RNA-Seq data avoids the ambiguity states. So what happens when a gene is present in one experiment but not the other for the same data type and conditions? With RNA-seq we should be able to adjust the RPKM inclusion threshold.\r\n3. Use unpropagated relationships, so for example genes expressed in for brain gray matter would not automatically be transmitted to brain.\r\n\r\nThese options are not mutually exclusive. We can choose any combination of the three.\r\n\r\nI am leaning towards option 3, because I think studies will often be performed on clinically relevant anatomies. In other words, we may accomplish the goal of 1 (removing overly broad anatomies) by including only relationships to their directly annotated anatomies. Additionally, since our hetnet contains [many nested levels Uberon terms](http://thinklab.com/discussion/tissue-node/41#16),  we would not be throwing out too many experiments entirely. In the future, we can even write queries that perform the propagation in realtime.\r\n\r\n**Data complications:** In `Homo_sapiens_expr-complete.tsv` version 13.1, all the values for `In situ call quality` and `In situ call quality` equal `no data`. Additionally, all values for `Including in situ observed data` are `no`. @fbastian, I assume this is a bug? Is there a workaround? Advice on the specific filters to apply on which files to achieve options 2 or 3 would be appreciated.",
      "comment_id": 1143,
      "profile_id": 17,
      "published": "2016-03-01T19:30:53.637385Z",
      "thread_id": 124,
      "url": "/discussion/processing-bgee-for-tissue-specific-gene-presence-and-overunder-expression/124#4"
    },
    {
      "body_html": "<p>Very thorough analysis by Pouya. I agree with the slight change in the definitions of categories. One clarification: is a drug still considered disease modifying if there are significant and dangerous side effects? amendment 1 seems to indicate that the answer is yes.</p>\r\n\r\n<p>For the most part, I agree with how you classified the following. I have made some comments for the particularly challenging disease categories:</p>\r\n\r\n<ul><li><strong>hypertension, general</strong></li><li><strong>hypertension, diuretics</strong></li><li><strong>hypertension, ocular and pulmonary htn</strong></li><li><strong>diabetes, drugs that lower blood sugar</strong></li><li><strong>diabetes, ACEi and ARBs</strong></li><li><strong>epilepsy</strong>: I think I agree with categorizing all AEDs as DM instead of SYM. I thought the pathophysiology behind MTS was not clearcut and treating someone with AEDs does not necessarily prevent MTS, although I think it may prevent morbidity and mortality.</li><li><strong>OA, NSAIDs and steroids</strong></li><li><strong>cancers, pain meds</strong></li><li><strong>hematologic cancers, steroids</strong></li><li><strong>non-heme cancers, steroids</strong></li><li><strong>cancers, hydroxyura and other chemotx</strong></li><li><strong>cancers, bisphos</strong></li><li><strong>CAD, drugs for htn or dm</strong></li><li><strong>CAD, diuretics</strong></li><li><strong>migraine</strong>: I think prophylactic medications should be DM; abortives may be better classified as SYM</li><li><strong>asthma, steroids, beta gonists, antichol</strong></li><li><strong>allergic rhinitis</strong>: this categorization makes sense to me.</li><li><strong>COPD, general</strong></li><li><strong>etoh dependence</strong></li><li><strong>psych disease</strong></li><li><strong>AD</strong></li><li><strong>anemia</strong>: I agree. It is like trying to categorize \"leukocytosis\" or some other lab abnormality, without getting at the etiology.</li></ul>\r\n\r\n<p>I am still stuck on one disease entity:</p>\r\n\r\n<ul><li><strong>Autoimmune diseases, steroids</strong>: do steroids actually change the long-term disease of autoimmune diseases? Do they reduce morbidity and mortality?</li></ul>",
      "body_md": "Very thorough analysis by Pouya. I agree with the slight change in the definitions of categories. One clarification: is a drug still considered disease modifying if there are significant and dangerous side effects? amendment 1 seems to indicate that the answer is yes.\r\n \r\nFor the most part, I agree with how you classified the following. I have made some comments for the particularly challenging disease categories:\r\n\r\n+ **hypertension, general**\r\n+ **hypertension, diuretics**\r\n+ **hypertension, ocular and pulmonary htn**\r\n+ **diabetes, drugs that lower blood sugar**\r\n+ **diabetes, ACEi and ARBs**\r\n+ **epilepsy**: I think I agree with categorizing all AEDs as DM instead of SYM. I thought the pathophysiology behind MTS was not clearcut and treating someone with AEDs does not necessarily prevent MTS, although I think it may prevent morbidity and mortality.\r\n+ **OA, NSAIDs and steroids**\r\n+ **cancers, pain meds**\r\n+ **hematologic cancers, steroids**\r\n+ **non-heme cancers, steroids**\r\n+ **cancers, hydroxyura and other chemotx**\r\n+ **cancers, bisphos**\r\n+ **CAD, drugs for htn or dm**\r\n+ **CAD, diuretics**\r\n+ **migraine**: I think prophylactic medications should be DM; abortives may be better classified as SYM\r\n+ **asthma, steroids, beta gonists, antichol**\r\n+ **allergic rhinitis**: this categorization makes sense to me.\r\n+ **COPD, general**\r\n+ **etoh dependence**\r\n+ **psych disease**\r\n+ **AD**\r\n+ **anemia**: I agree. It is like trying to categorize \"leukocytosis\" or some other lab abnormality, without getting at the etiology.\r\n\r\nI am still stuck on one disease entity:\r\n\r\n+ **Autoimmune diseases, steroids**: do steroids actually change the long-term disease of autoimmune diseases? Do they reduce morbidity and mortality?",
      "comment_id": 1144,
      "profile_id": 172,
      "published": "2016-03-02T16:49:17.802833Z",
      "thread_id": 95,
      "url": "/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95#11"
    },
    {
      "body_html": "<h1>Initial release of STARGEO analyses</h1>\r\n\r\n<p>We've released the first complete version of our STARGEO analysis (<a href=\"https://github.com/dhimmel/stargeo\">repository</a> <span class=\"citation\">[<a href=\"https://doi.org/10.5281/zenodo.46866\" class=\"citation\" data-key=\"10.5281/zenodo.46866\">1</a>]</span>). Thanks <a href=\"/u/idrdex\" class=\"username\">@idrdex</a> for helping us get all of the queries <a href=\"https://github.com/idrdex/star_api/issues/13#issuecomment-191414422\">running smoothly</a>.</p>\r\n\r\n<p>In summary, we defined case-control queries for <a href=\"https://github.com/dhimmel/stargeo/blob/1a11633b5e0095454453335be82012a9f0f482e4/data/queries.tsv\">66 diseases</a>. Of these diseases, 49 contained sufficient data (multiple studies with at least 3 samples per class). We used STARGEO's random effects meta-analysis and applied an FDR <em>p</em>-value threshold of 0.05 to identify deferentially expressed genes for each disease. </p>\r\n\r\n<p>48,688 <em>Disease–downregulates–Gene</em> and 50,287 <em>Disease–upregulates–Gene</em> relationships were identified (<a href=\"https://github.com/dhimmel/stargeo/blob/1a11633b5e0095454453335be82012a9f0f482e4/data/diffex.tsv\">dataset</a>). The number of dysregulated genes <a href=\"https://github.com/dhimmel/stargeo/blob/1a11633b5e0095454453335be82012a9f0f482e4/data/summary.tsv\">varied widely</a> by disease. No deferentially expressed genes were identified for endogenous depression, which had a combined sample size of <a href=\"https://github.com/dhimmel/stargeo/blob/1a11633b5e0095454453335be82012a9f0f482e4/data/doslim/DOID_1595/samples.tsv\">533 cases and controls</a>.</p>\r\n\r\n<p>Now we will integrate these relationships into our hetnet. We may choose to limit each disease to the 500 most significantly up and 500 most significantly down-regulated genes.</p>",
      "body_md": "# Initial release of STARGEO analyses\r\n\r\nWe've released the first complete version of our STARGEO analysis ([repository](https://github.com/dhimmel/stargeo) [@10.5281/zenodo.46866]). Thanks @idrdex for helping us get all of the queries [running smoothly](https://github.com/idrdex/star_api/issues/13#issuecomment-191414422).\r\n\r\nIn summary, we defined case-control queries for [66 diseases](https://github.com/dhimmel/stargeo/blob/1a11633b5e0095454453335be82012a9f0f482e4/data/queries.tsv). Of these diseases, 49 contained sufficient data (multiple studies with at least 3 samples per class). We used STARGEO's random effects meta-analysis and applied an FDR _p_-value threshold of 0.05 to identify deferentially expressed genes for each disease. \r\n\r\n48,688 _Disease--downregulates--Gene_ and 50,287 _Disease--upregulates--Gene_ relationships were identified ([dataset](https://github.com/dhimmel/stargeo/blob/1a11633b5e0095454453335be82012a9f0f482e4/data/diffex.tsv)). The number of dysregulated genes [varied widely](https://github.com/dhimmel/stargeo/blob/1a11633b5e0095454453335be82012a9f0f482e4/data/summary.tsv) by disease. No deferentially expressed genes were identified for endogenous depression, which had a combined sample size of [533 cases and controls](https://github.com/dhimmel/stargeo/blob/1a11633b5e0095454453335be82012a9f0f482e4/data/doslim/DOID_1595/samples.tsv).\r\n\r\nNow we will integrate these relationships into our hetnet. We may choose to limit each disease to the 500 most significantly up and 500 most significantly down-regulated genes.",
      "comment_id": 1145,
      "profile_id": 17,
      "published": "2016-03-03T00:50:58.434610Z",
      "thread_id": 96,
      "url": "/discussion/stargeo-expression-signatures-for-disease-using-crowdsourced-geo-annotation/96#10"
    },
    {
      "body_html": "<ul><li><p><strong>Re: Autoimmune diseases and steroids</strong>. I do believe that steroids are DM in a variety of auto-immune diseases. The easiest examples are Lupus and RA where the occasional difficult-to-control patient is given low-dose maintenance steroids to prevent disease flares (i.e. reduce morbidity). Tougher examples include MS but there is some evidence that it may help decrease disease activity and relapse rate <span class=\"citation\">[<a href=\"https://doi.org/10.1212/wnl.57.7.1239\" class=\"citation\" data-key=\"10.1212/wnl.57.7.1239\">1</a>]</span>, which puts it is a similar category to say Copaxone which we would probably mark as DM (even though copaxone also does not delay progression of disease). Given that, I felt it was reasonable to assume the same for other auto-immune diseases, although I must admit I'm probably under-qualified to comment on the subtleties of this (perhaps we can curb-side a rheumatologist). I fully agree that there is a high side-effect burden and chronic steroids are probably not clinically indicated for treatment, but perhaps they should still DM for the purposes of this study. I think of it like this, if Daniel's analysis could suggest a drug because it acted on some of the same molecular targets as do steroids, but that drug had zero side effects, then would that drug be of interest in treating auto-immune diseases? If yes, then I think we should classify steroids as DM.</p></li><li><p><strong>Re: epilepsy</strong>. Good point that AEDs prevent morbidity and mortality, it's clearly better than my hand-waving and highly disputed MTS argument. Additionally, I think we should consider the same argument as above, if Daniel's network were to find a drug that acts on the same molecular targets as our AEDs, then would we consider that drug when treating epilepsy? I would think yes.</p></li><li><p><strong>Re: migraine</strong>. I wholly agree with what you wrote. I think I just didn't state it as clearly as you did.</p></li></ul>",
      "body_md": "- **Re: Autoimmune diseases and steroids**. I do believe that steroids are DM in a variety of auto-immune diseases. The easiest examples are Lupus and RA where the occasional difficult-to-control patient is given low-dose maintenance steroids to prevent disease flares (i.e. reduce morbidity). Tougher examples include MS but there is some evidence that it may help decrease disease activity and relapse rate [@10.1212/wnl.57.7.1239], which puts it is a similar category to say Copaxone which we would probably mark as DM (even though copaxone also does not delay progression of disease). Given that, I felt it was reasonable to assume the same for other auto-immune diseases, although I must admit I'm probably under-qualified to comment on the subtleties of this (perhaps we can curb-side a rheumatologist). I fully agree that there is a high side-effect burden and chronic steroids are probably not clinically indicated for treatment, but perhaps they should still DM for the purposes of this study. I think of it like this, if Daniel's analysis could suggest a drug because it acted on some of the same molecular targets as do steroids, but that drug had zero side effects, then would that drug be of interest in treating auto-immune diseases? If yes, then I think we should classify steroids as DM.\r\n\r\n- **Re: epilepsy**. Good point that AEDs prevent morbidity and mortality, it's clearly better than my hand-waving and highly disputed MTS argument. Additionally, I think we should consider the same argument as above, if Daniel's network were to find a drug that acts on the same molecular targets as our AEDs, then would we consider that drug when treating epilepsy? I would think yes.\r\n\r\n- **Re: migraine**. I wholly agree with what you wrote. I think I just didn't state it as clearly as you did.",
      "comment_id": 1146,
      "profile_id": 188,
      "published": "2016-03-03T01:18:31.088155Z",
      "thread_id": 95,
      "url": "/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95#12"
    },
    {
      "body_html": "<p>For me, the two working solutions would either be:  </p>\r\n\r\n<ul><li>\"3. Use unpropagated relationships\": actually, you would still use the propagated data, but you would consider only the anatomical structures described in the experiments. This is what our \"simple\" expression file contains.</li><li>or manually select a list of 50-100 anatomical structures you are interested in, and use the propagated data in them. Maybe you can also include all cell types. This is very similar to the previous solution, except that you'd have more freedom about the choice of the organs. Although you should already have lots of organs experimentally described once we include the GTEx data (see bottom of this message), so the previous solution might be good enough.</li></ul>\r\n\r\n<p>\"2. Use only RNA-Seq experiments\" is incorrect: you'll still get the ambiguity states if two libraries provide contradicting information. And, it would be sad not to use other data types – lots of good information come from Affymetrix data.<br>And adjusting the RPKM threshold will not solve your problem: your problem comes from the propagation of data to upper level terms.</p>\r\n\r\n<p>To implement solution \"3\", you can either use our \"simple\" expression file, or use the \"complete\" file, but filter thanks to the column \"Observed data\": <a href=\"http://bgee.org/?page=doc&amp;action=call_files#single_expr_complete_col9\">http://bgee.org/?page=doc&amp;action=call_files#single_expr_complete_col9</a></p>\r\n\r\n<p>Otherwise, we can think of alternative solutions: </p>\r\n\r\n<ul><li>Using only over-/under-expression data. We should have a lot of them thanks to the GTEx data in the near future</li><li>Using only the best-ranked anatomical structures for each gene, rather than all data, and do the propagation based on that (e.g., in TISSUES the anatomical structures are ranked – we are going to release a gene page next week also providing ranked anatomical structures). </li><li>Using a completely different approach, based on gene lists rather than individual genes: see our new GO-like expression enrichment test: <a href=\"http://bgee.org/?page=top_anat\">http://bgee.org/?page=top_anat</a>. I don't know if it can be applied to your network, though, but maybe you can link groups of genes to anatomical structures, rather than individual genes.</li></ul>\r\n\r\n<p><strong>About in situ data:</strong> we don't have in situ data for human. I don't know of any resource providing systematic gene expression analyses in human using in situ hybridization. This data type is not well suited for human (e.g., I think you're not supposed to use frozen tissues). </p>\r\n\r\n<p><strong>Additional information:</strong> we have started the pipeline for Bgee 14, that will include the GTEx data. The full pipeline run should take a few months, but you'll get the data ultimately. Also, I'll let you know about the status of our work of re-annotation in the other thread, as we have completed it.</p>",
      "body_md": "For me, the two working solutions would either be:  \r\n\r\n* \"3. Use unpropagated relationships\": actually, you would still use the propagated data, but you would consider only the anatomical structures described in the experiments. This is what our \"simple\" expression file contains.\r\n* or manually select a list of 50-100 anatomical structures you are interested in, and use the propagated data in them. Maybe you can also include all cell types. This is very similar to the previous solution, except that you'd have more freedom about the choice of the organs. Although you should already have lots of organs experimentally described once we include the GTEx data (see bottom of this message), so the previous solution might be good enough.\r\n\r\n\"2. Use only RNA-Seq experiments\" is incorrect: you'll still get the ambiguity states if two libraries provide contradicting information. And, it would be sad not to use other data types – lots of good information come from Affymetrix data.\r\nAnd adjusting the RPKM threshold will not solve your problem: your problem comes from the propagation of data to upper level terms.\r\n\r\nTo implement solution \"3\", you can either use our \"simple\" expression file, or use the \"complete\" file, but filter thanks to the column \"Observed data\": http://bgee.org/?page=doc&action=call_files#single_expr_complete_col9\r\n\r\nOtherwise, we can think of alternative solutions: \r\n\r\n* Using only over-/under-expression data. We should have a lot of them thanks to the GTEx data in the near future\r\n* Using only the best-ranked anatomical structures for each gene, rather than all data, and do the propagation based on that (e.g., in TISSUES the anatomical structures are ranked – we are going to release a gene page next week also providing ranked anatomical structures). \r\n* Using a completely different approach, based on gene lists rather than individual genes: see our new GO-like expression enrichment test: http://bgee.org/?page=top_anat. I don't know if it can be applied to your network, though, but maybe you can link groups of genes to anatomical structures, rather than individual genes.\r\n\r\n\r\n**About in situ data:** we don't have in situ data for human. I don't know of any resource providing systematic gene expression analyses in human using in situ hybridization. This data type is not well suited for human (e.g., I think you're not supposed to use frozen tissues). \r\n\r\n**Additional information:** we have started the pipeline for Bgee 14, that will include the GTEx data. The full pipeline run should take a few months, but you'll get the data ultimately. Also, I'll let you know about the status of our work of re-annotation in the other thread, as we have completed it.",
      "comment_id": 1147,
      "profile_id": 111,
      "published": "2016-03-03T17:50:32.818528Z",
      "thread_id": 124,
      "url": "/discussion/processing-bgee-for-tissue-specific-gene-presence-and-overunder-expression/124#5"
    },
    {
      "body_html": "<h2>Clarification</h2>\r\n\r\n<p>Let's see if I understand: It is not possible to tell whether gene presence for a specific condition (anatomy–developmental stage) was from an experiment on that exact condition or was propagated. However, the simple file (or complete file filtered for <code>Observed data</code>) contains only conditions with directly annotated experiments, but any given gene presence call may be from propagation.</p>\r\n\r\n<h2>Proposed gene presence method</h2>\r\n\r\n<p>I think the ideal setup for our network would be <em>propagation by developmental stage but not by anatomical structure</em>. Using just the simple or complete datasets, this doesn't currently seem to be possible. However, I've what about the following workaround: using all adult stages on the simple dataset.</p>\r\n\r\n<p>Using the simple dataset, I found all gene–anatomy pairs where <code>Expression</code> is <code>present</code> and <code>Call quality</code> is <code>high quality</code> for any adult developmental stage. To identify adult developmental stages, I filtered for <code>HsapDv:0000087</code> and its descendants (<a href=\"https://github.com/dhimmel/bgee/blob/5cfed945305d7ec118fe79a1486c28d6a97ee8ee/developmental-stages.ipynb\">notebook</a>, <a href=\"https://github.com/dhimmel/bgee/blob/5cfed945305d7ec118fe79a1486c28d6a97ee8ee/data/stages.tsv#L76\">dataset</a>).</p>\r\n\r\n<p>The resulting presence/absence matrix of gene expression is 16,257 genes × 188 anatomies  (<a href=\"https://github.com/dhimmel/bgee/blob/5cfed945305d7ec118fe79a1486c28d6a97ee8ee/bgee.ipynb\">notebook</a>, <a href=\"https://github.com/dhimmel/bgee/blob/5cfed945305d7ec118fe79a1486c28d6a97ee8ee/data/present-in-adult.tsv.gz\">dataset</a>) compared to the <a href=\"http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#8\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d81\">previous dimensions</a> of 16,278 genes × 666 anatomies. We hope that this pruning of anatomies will help address the network problems we <a href=\"#4\">were facing</a>.</p>\r\n\r\n<h2>Miscellaneous</h2>\r\n\r\n<p>Thanks <a href=\"/u/fbastian\" class=\"username\">@fbastian</a> for suggesting other possible approaches. For future networks, we will revisit these options. For now we're looking for the most straightforward and immediately actionable option.</p>\r\n\r\n<blockquote><p>We don't have in situ data for human. I don't know of any resource providing systematic gene expression analyses in human using in situ hybridization.</p></blockquote>\r\n\r\n<p>I had misinterpreted <code>Including in situ observed data</code> to mean <code>Observed data</code></p>",
      "body_md": "## Clarification\r\n\r\nLet's see if I understand: It is not possible to tell whether gene presence for a specific condition (anatomy--developmental stage) was from an experiment on that exact condition or was propagated. However, the simple file (or complete file filtered for `Observed data`) contains only conditions with directly annotated experiments, but any given gene presence call may be from propagation.\r\n\r\n## Proposed gene presence method\r\n\r\nI think the ideal setup for our network would be *propagation by developmental stage but not by anatomical structure*. Using just the simple or complete datasets, this doesn't currently seem to be possible. However, I've what about the following workaround: using all adult stages on the simple dataset.\r\n\r\nUsing the simple dataset, I found all gene--anatomy pairs where `Expression` is `present` and `Call quality` is `high quality` for any adult developmental stage. To identify adult developmental stages, I filtered for `HsapDv:0000087` and its descendants ([notebook](https://github.com/dhimmel/bgee/blob/5cfed945305d7ec118fe79a1486c28d6a97ee8ee/developmental-stages.ipynb), [dataset](https://github.com/dhimmel/bgee/blob/5cfed945305d7ec118fe79a1486c28d6a97ee8ee/data/stages.tsv#L76)).\r\n\r\nThe resulting presence/absence matrix of gene expression is 16,257 genes × 188 anatomies  ([notebook](https://github.com/dhimmel/bgee/blob/5cfed945305d7ec118fe79a1486c28d6a97ee8ee/bgee.ipynb), [dataset](https://github.com/dhimmel/bgee/blob/5cfed945305d7ec118fe79a1486c28d6a97ee8ee/data/present-in-adult.tsv.gz)) compared to the [previous dimensions](http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#8) of 16,278 genes × 666 anatomies. We hope that this pruning of anatomies will help address the network problems we [were facing](#4).\r\n\r\n## Miscellaneous\r\n\r\nThanks @fbastian for suggesting other possible approaches. For future networks, we will revisit these options. For now we're looking for the most straightforward and immediately actionable option.\r\n\r\n> We don't have in situ data for human. I don't know of any resource providing systematic gene expression analyses in human using in situ hybridization.\r\n\r\nI had misinterpreted `Including in situ observed data` to mean `Observed data`",
      "comment_id": 1148,
      "profile_id": 17,
      "published": "2016-03-04T01:41:27.690045Z",
      "thread_id": 124,
      "url": "/discussion/processing-bgee-for-tissue-specific-gene-presence-and-overunder-expression/124#6"
    },
    {
      "body_html": "<blockquote><p> the simple file (or complete file filtered for Observed data) contains only conditions with directly annotated experiments, but any given gene presence call may be from propagation.</p></blockquote>\r\n\r\n<p>No, you have the guarantee that there exists an unpropagated call for that very gene. What you can't know for sure from these files, is where the quality level comes from. For instance: </p>\r\n\r\n<pre><code>gene A expressed in brain with low quality from experiment A\r\ngene A expressed in brain substructure with high quality from experiment B\r\n=&gt; gene A expressed in brain with high quality in Bgee files</code></pre>\r\n\r\n<p>Or </p>\r\n\r\n<pre><code>gene A NOT expressed in brain from RNA-Seq experiment A\r\ngene A expressed in brain substructure from Affymetrix experiment B\r\n=&gt; gene A with lowly conflicting status in brain substructure, in Bgee files </code></pre>\r\n\r\n<p>Data in adult for human must represent 90% of the data, so you shouldn't add much by considering all developmental stages. </p>\r\n\r\n<p>If you want, I can provide you with a completely unpropagated dataset. But I think it's good to benefit from propagation (e.g., to determine that 2 genes are both expressed in brain, which you might miss if they were expressed in different brain substructures). </p>\r\n\r\n<blockquote><p>I had misinterpreted <code>Including in situ observed data</code> to mean <code>Observed data</code></p></blockquote>\r\n\r\n<p>I see, we should rename these fields with <code>in situ hybridization</code> then.</p>",
      "body_md": ">  the simple file (or complete file filtered for Observed data) contains only conditions with directly annotated experiments, but any given gene presence call may be from propagation.\r\n\r\nNo, you have the guarantee that there exists an unpropagated call for that very gene. What you can't know for sure from these files, is where the quality level comes from. For instance: \r\n\r\n    gene A expressed in brain with low quality from experiment A\r\n    gene A expressed in brain substructure with high quality from experiment B\r\n    => gene A expressed in brain with high quality in Bgee files\r\n\r\nOr \r\n\r\n    gene A NOT expressed in brain from RNA-Seq experiment A\r\n    gene A expressed in brain substructure from Affymetrix experiment B\r\n    => gene A with lowly conflicting status in brain substructure, in Bgee files \r\n\r\n\r\nData in adult for human must represent 90% of the data, so you shouldn't add much by considering all developmental stages. \r\n\r\nIf you want, I can provide you with a completely unpropagated dataset. But I think it's good to benefit from propagation (e.g., to determine that 2 genes are both expressed in brain, which you might miss if they were expressed in different brain substructures). \r\n\r\n> I had misinterpreted `Including in situ observed data` to mean `Observed data`\r\n\r\nI see, we should rename these fields with `in situ hybridization` then.",
      "comment_id": 1149,
      "profile_id": 111,
      "published": "2016-03-04T13:08:49.847183Z",
      "thread_id": 124,
      "url": "/discussion/processing-bgee-for-tissue-specific-gene-presence-and-overunder-expression/124#7"
    },
    {
      "body_html": "<h1>Concensus signatures version 2.0</h1>\r\n\r\n<p>We've released <code>v2.0</code> of our analysis of LINCS L1000. This release brings major updates including:</p>\r\n\r\n<ul><li><strong>Inferred genes</strong>. <a href=\"#6\">Previously</a>, dysregulation scores were only reported for the 978 landmark (directly measured) genes. Now we've expanded our analysis to include 6,489 imputed genes from the best inferred gene set (<code>is_bing</code>), which covers genes imputed with high accuracy. However, we've maintained backwards compatibility by only using landmark probes for signature weighting.</li><li><strong>Significantly dysregulated genes</strong>. We now report significantly down or upregulated perturbagen–gene pairs.</li><li><strong>Improved knockdown and overexpression pipeline</strong>. We now convert gene symbols to entrez genes at the earliest stage. Now two genetic perturbations with different symbols that map to the same entrez gene will benefit from <a href=\"#5\"><em>z</em>-score meta-analysis</a>.</li></ul>\r\n\r\n<h2>Consensus signature datasets</h2>\r\n\r\n<p>Our consensus signatures are available on <a href=\"https://github.com/dhimmel/lincs/tree/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi\">GitHub</a> <span class=\"citation\">[<a href=\"https://doi.org/10.5281/zenodo.47223\" class=\"citation\" data-key=\"10.5281/zenodo.47223\">1</a>]</span> and <a href=\"https://doi.org/10.6084/m9.figshare.3085426\" title=\"Consensus signatures for LINCS L1000 perturbations · figshare data deposition\">figshare</a> <span class=\"citation\">[<a href=\"https://doi.org/10.6084/m9.figshare.3085426\" class=\"citation\" data-key=\"10.6084/m9.figshare.3085426\">2</a>]</span>. Each consensus signature measures the transcriptional response to a perturbation at <a href=\"https://github.com/dhimmel/lincs/blob/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/genes.tsv\">7,467 genes</a>. Genes are identified by their Entrez GeneID. Consensi are produced for:</p>\r\n\r\n<ul><li><strong>DrugBank compounds</strong> — 1,170 small molecule compounds identified by their DrugBank ID. L1000 compounds were mapped to DrugBank <a href=\"http://thinklab.com/discussion/unichem-mapping-to-lincs-small-molecules/51#8\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d51\">using atomic connectivity</a>.</li><li><strong>Gene knockdowns</strong> — 4,326 knocked-down genes identified by their Entrez GeneID.</li><li><strong>Gene overexpressions</strong> — 2,413 overexpressed genes identified by their Entrez GeneID</li><li><strong>All L1000 pertubations</strong> — 38,327 perturbagens identified by their L1000 <code>pert_id</code>.</li></ul>\r\n\r\n<h2>Methodology</h2>\r\n\r\n<p>To recap our methodology, our objective is to compute a consensus signature from multiple input signatures. Each input signature measures the dysregulation caused by a specific perturbation and condition. The purpose of computing consensi is to combine signatures for the same perturbation under different conditions (for examples different dosages, cell types, or time points). </p>\r\n\r\n<p>Our method, developed in consultation with the L1000 team, arrives at a consensus signature from a set of input signatures by:</p>\r\n\r\n<p>A) Starting with a probe × signature matrix of dysregulation <em>z</em>-scores with the following filters:</p>\r\n\r\n<ul><li><strong>Initial probe filter</strong>: include all landmark or <code>is_bing</code> probes with the following exclusions: a) inferred probes for genes with a landmark probe. b) probes with non-existent Entrez GeneIDs.</li><li><strong>Initial signature filter</strong>: use only <a href=\"#3\">gold signatures</a> to remove non-replicating or indistinct signatures</li></ul>\r\n\r\n<p>B) Then a gene-level consensus signature is computed by:</p>\r\n\r\n<ol><li>Calculating an input signature weight. Each input signature gets a weight equal to its average Spearman's correlation with other input signatures. We set a minimum correlation value of 0.05 to ensure all signatures make at least a small contribution and to prevent negative weights. Weights are computed using only landmark probes.</li><li><a href=\"#5\">Meta-analyzing <em>z</em>-scores</a> with Stouffer's method to compute a probe-level consensus signature.</li><li>Condensing to a gene-level consensus by averaging probe <em>z</em>-scores for the same entrez gene.</li></ol>\r\n\r\n<p>C) Finally, significant <em>Perturbagen–regulates–Gene</em> relationships are extracted for a given perturbation by:</p>\r\n\r\n<ol><li>Converting gene <em>z</em>-scores to <em>p</em>-values by via a normal distribution</li><li>Correcting p-values for multiple testing using a Bonferroni adjustment. The correction is applied separately to measured genes and inferred genes. Hence, inferred genes are more heavily penalized for multiple testing.</li><li>Filter genes for corrected <em>p</em>-value ≤ 0.05.</li><li>Allowing at most 1000 significant inferred genes. In cases with more than 1000 significant inferred genes, filter to the 1000 smallest <em>p</em>-values.</li></ol>\r\n\r\n<p>The methods described above are executed in the <a href=\"https://github.com/dhimmel/lincs/blob/abcb12f942f93e3ee839e5e3593f930df2c56845/consensi.ipynb\"><code>consensi.ipynb</code></a> and <a href=\"https://github.com/dhimmel/lincs/blob/abcb12f942f93e3ee839e5e3593f930df2c56845/significance.ipynb\"><code>significance.ipynb</code></a> notebooks.</p>",
      "body_md": "# Concensus signatures version 2.0\r\n\r\nWe've released `v2.0` of our analysis of LINCS L1000. This release brings major updates including:\r\n\r\n+ **Inferred genes**. [Previously](#6), dysregulation scores were only reported for the 978 landmark (directly measured) genes. Now we've expanded our analysis to include 6,489 imputed genes from the best inferred gene set (`is_bing`), which covers genes imputed with high accuracy. However, we've maintained backwards compatibility by only using landmark probes for signature weighting.\r\n+ **Significantly dysregulated genes**. We now report significantly down or upregulated perturbagen--gene pairs.\r\n+ **Improved knockdown and overexpression pipeline**. We now convert gene symbols to entrez genes at the earliest stage. Now two genetic perturbations with different symbols that map to the same entrez gene will benefit from [_z_-score meta-analysis](#5).\r\n\r\n## Consensus signature datasets\r\n\r\nOur consensus signatures are available on [GitHub](https://github.com/dhimmel/lincs/tree/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi) [@10.5281/zenodo.47223] and [figshare](https://doi.org/10.6084/m9.figshare.3085426 \"Consensus signatures for LINCS L1000 perturbations · figshare data deposition\") [@10.6084/m9.figshare.3085426]. Each consensus signature measures the transcriptional response to a perturbation at [7,467 genes](https://github.com/dhimmel/lincs/blob/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/genes.tsv). Genes are identified by their Entrez GeneID. Consensi are produced for:\r\n\r\n+ **DrugBank compounds** -- 1,170 small molecule compounds identified by their DrugBank ID. L1000 compounds were mapped to DrugBank [using atomic connectivity](http://thinklab.com/discussion/unichem-mapping-to-lincs-small-molecules/51#8).\r\n+ **Gene knockdowns** -- 4,326 knocked-down genes identified by their Entrez GeneID.\r\n+ **Gene overexpressions** -- 2,413 overexpressed genes identified by their Entrez GeneID\r\n+ **All L1000 pertubations** -- 38,327 perturbagens identified by their L1000 `pert_id`.\r\n\r\n## Methodology\r\n\r\nTo recap our methodology, our objective is to compute a consensus signature from multiple input signatures. Each input signature measures the dysregulation caused by a specific perturbation and condition. The purpose of computing consensi is to combine signatures for the same perturbation under different conditions (for examples different dosages, cell types, or time points). \r\n\r\nOur method, developed in consultation with the L1000 team, arrives at a consensus signature from a set of input signatures by:\r\n\r\nA) Starting with a probe × signature matrix of dysregulation _z_-scores with the following filters:\r\n\r\n+ **Initial probe filter**: include all landmark or `is_bing` probes with the following exclusions: a) inferred probes for genes with a landmark probe. b) probes with non-existent Entrez GeneIDs.\r\n+ **Initial signature filter**: use only [gold signatures](#3) to remove non-replicating or indistinct signatures\r\n\r\nB) Then a gene-level consensus signature is computed by:\r\n\r\n1. Calculating an input signature weight. Each input signature gets a weight equal to its average Spearman's correlation with other input signatures. We set a minimum correlation value of 0.05 to ensure all signatures make at least a small contribution and to prevent negative weights. Weights are computed using only landmark probes.\r\n2. [Meta-analyzing _z_-scores](#5) with Stouffer's method to compute a probe-level consensus signature.\r\n3. Condensing to a gene-level consensus by averaging probe _z_-scores for the same entrez gene.\r\n\r\nC) Finally, significant _Perturbagen--regulates--Gene_ relationships are extracted for a given perturbation by:\r\n\r\n1. Converting gene _z_-scores to _p_-values by via a normal distribution\r\n2. Correcting p-values for multiple testing using a Bonferroni adjustment. The correction is applied separately to measured genes and inferred genes. Hence, inferred genes are more heavily penalized for multiple testing.\r\n3. Filter genes for corrected _p_-value ≤ 0.05.\r\n4. Allowing at most 1000 significant inferred genes. In cases with more than 1000 significant inferred genes, filter to the 1000 smallest _p_-values.\r\n\r\nThe methods described above are executed in the [`consensi.ipynb`](https://github.com/dhimmel/lincs/blob/abcb12f942f93e3ee839e5e3593f930df2c56845/consensi.ipynb) and [`significance.ipynb`](https://github.com/dhimmel/lincs/blob/abcb12f942f93e3ee839e5e3593f930df2c56845/significance.ipynb) notebooks.",
      "comment_id": 1150,
      "profile_id": 17,
      "published": "2016-03-07T23:55:51.378082Z",
      "thread_id": 43,
      "url": "/discussion/computing-consensus-transcriptional-profiles-for-lincs-l1000-perturbations/43#7"
    },
    {
      "body_html": "<h1>Method for mapping L1000 compounds to external vocabularies</h1>\r\n\r\n<p>We chose to map LINCS L1000 compounds to external vocabularies by querying UniChem with the InChIKey of each L1000 compound (strategy 2 <a href=\"#2\">above</a>). This approach enabled us to map L1000 compounds not only to DrugBank, but also to the other vocabularies covered by UniChem.</p>\r\n\r\n<p>The InChIKey for each L1000 compound was retrieved from the <a href=\"http://api.lincscloud.org/a2/docs/pertinfo\" title=\"L1000 pertinfo API\">L1000 API</a> (<a href=\"https://github.com/dhimmel/lincs/blob/093dc3a0497028ad2b9549a3f9fa12f8ce38461f/api.ipynb\" title=\"api.ipynb in the dhimmel/lincs GitHub repository\">notebook</a>). Only perturbations with <code>pert_type == 'trt_cp'</code> and a non-null <code>inchi_key</code> were mapped. We queried the <a href=\"https://www.ebi.ac.uk/unichem/info/widesearchInfo\" title=\"Connectivity Search Documentation\">UniChem API</a> for each L1000 InChIKey to retrieve matches (<a href=\"https://github.com/dhimmel/lincs/blob/093dc3a0497028ad2b9549a3f9fa12f8ce38461f/unichem.ipynb\" title=\"unichem.ipynb in the dhimmel/lincs GitHub repository\">notebook</a>).</p>\r\n\r\n<p>We used the same UniChem Connectivity Search parameters that we <a href=\"http://thinklab.com/discussion/unifying-drug-vocabularies/40#5\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d40\">used for mapping DrugBank</a>. Our search permissively matches compounds by atomic structure, ignoring small molecular details <span class=\"citation\">[<a href=\"https://doi.org/10.1186/s13321-014-0043-5\" class=\"citation\" data-key=\"10.1186/s13321-014-0043-5\">1</a>]</span>. We store all the UniChem output in our SQLite database (<code>l1000.db</code> <span class=\"citation\">[<a href=\"https://doi.org/10.6084/m9.figshare.3085837.v1\" class=\"citation\" data-key=\"10.6084/m9.figshare.3085837.v1\">2</a>]</span>, <code>unichem</code> table), so users could later choose more restrictive parameters without having to requery UniChem.</p>",
      "body_md": "# Method for mapping L1000 compounds to external vocabularies\r\n\r\nWe chose to map LINCS L1000 compounds to external vocabularies by querying UniChem with the InChIKey of each L1000 compound (strategy 2 [above](#2)). This approach enabled us to map L1000 compounds not only to DrugBank, but also to the other vocabularies covered by UniChem.\r\n\r\nThe InChIKey for each L1000 compound was retrieved from the [L1000 API](http://api.lincscloud.org/a2/docs/pertinfo \"L1000 pertinfo API\") ([notebook](https://github.com/dhimmel/lincs/blob/093dc3a0497028ad2b9549a3f9fa12f8ce38461f/api.ipynb \"api.ipynb in the dhimmel/lincs GitHub repository\")). Only perturbations with `pert_type == 'trt_cp'` and a non-null `inchi_key` were mapped. We queried the [UniChem API](https://www.ebi.ac.uk/unichem/info/widesearchInfo \"Connectivity Search Documentation\") for each L1000 InChIKey to retrieve matches ([notebook](https://github.com/dhimmel/lincs/blob/093dc3a0497028ad2b9549a3f9fa12f8ce38461f/unichem.ipynb \"unichem.ipynb in the dhimmel/lincs GitHub repository\")).\r\n\r\nWe used the same UniChem Connectivity Search parameters that we [used for mapping DrugBank](http://thinklab.com/discussion/unifying-drug-vocabularies/40#5). Our search permissively matches compounds by atomic structure, ignoring small molecular details [@10.1186/s13321-014-0043-5]. We store all the UniChem output in our SQLite database (`l1000.db` [@10.6084/m9.figshare.3085837.v1], `unichem` table), so users could later choose more restrictive parameters without having to requery UniChem.",
      "comment_id": 1151,
      "profile_id": 17,
      "published": "2016-03-07T23:26:38.528312Z",
      "thread_id": 51,
      "url": "/discussion/unichem-mapping-to-lincs-small-molecules/51#8"
    },
    {
      "body_html": "<h1>Releasing <code>dhimmel/bgee v1.0</code></h1>\r\n\r\n<p>We've released <a href=\"https://github.com/dhimmel/bgee/tree/08ba54e83ee8e28dec22b4351d29e23f1d034d30\" title=\"GitHub repository\">version 1.0</a> of our Bgee processing <span class=\"citation\">[<a href=\"https://doi.org/10.5281/zenodo.47157\" class=\"citation\" data-key=\"10.5281/zenodo.47157\">1</a>]</span>.</p>\r\n\r\n<h2>Datasets</h2>\r\n\r\n<p>Genes are identified with Entrez GeneIDs and anatomical structures (anatomies) are identified by Cell Ontology or Uberon terms.</p>\r\n\r\n<ul><li><a href=\"https://github.com/dhimmel/bgee/blob/08ba54e83ee8e28dec22b4351d29e23f1d034d30/data/present-in-adult.tsv.gz\"><code>present-in-adult.tsv.gz</code></a> indicates whether a gene is present (<code>1</code>) or absent (<code>0</code>) for a given anatomy in human adults. The dataset is a matrix of 16,257 genes × 188 anatomies.</li><li><a href=\"https://github.com/dhimmel/bgee/blob/08ba54e83ee8e28dec22b4351d29e23f1d034d30/data/diffex.tsv.gz\"><code>diffex.tsv.gz</code></a> indicates whether a gene is over-expressed (<code>1</code>), under-expressed (<code>-1</code>), or non-deferentially expressed (<code>0</code>) for a given anatomy. The dataset is a matrix of 18,620 genes × 98 anatomies.</li></ul>\r\n\r\n<h2>Changelog</h2>\r\n\r\n<p>Compared to <a href=\"http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#8\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d81\">version 0</a> — the Bgee data in the <a href=\"http://thinklab.com/discussion/one-network-to-rule-them-all/102\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d102\">initial version</a> of our hetnet — the following change was made:</p>\r\n\r\n<ul><li>We adopted the modification <a href=\"#6\">proposed above</a>: gene presence was extracted from the simple Bgee dataset, which <a href=\"#6\">guarantees</a> that each <em>Anatomy–expresses–Gene</em> relationship contains direct (unpropagated) experimental data.</li></ul>",
      "body_md": "# Releasing `dhimmel/bgee v1.0`\r\n\r\nWe've released [version 1.0](https://github.com/dhimmel/bgee/tree/08ba54e83ee8e28dec22b4351d29e23f1d034d30 \"GitHub repository\") of our Bgee processing [@10.5281/zenodo.47157].\r\n\r\n## Datasets\r\n\r\nGenes are identified with Entrez GeneIDs and anatomical structures (anatomies) are identified by Cell Ontology or Uberon terms.\r\n\r\n+ [`present-in-adult.tsv.gz`](https://github.com/dhimmel/bgee/blob/08ba54e83ee8e28dec22b4351d29e23f1d034d30/data/present-in-adult.tsv.gz) indicates whether a gene is present (`1`) or absent (`0`) for a given anatomy in human adults. The dataset is a matrix of 16,257 genes × 188 anatomies.\r\n+ [`diffex.tsv.gz`](https://github.com/dhimmel/bgee/blob/08ba54e83ee8e28dec22b4351d29e23f1d034d30/data/diffex.tsv.gz) indicates whether a gene is over-expressed (`1`), under-expressed (`-1`), or non-deferentially expressed (`0`) for a given anatomy. The dataset is a matrix of 18,620 genes × 98 anatomies.\r\n\r\n## Changelog\r\n\r\nCompared to [version 0](http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#8) -- the Bgee data in the [initial version](http://thinklab.com/discussion/one-network-to-rule-them-all/102) of our hetnet -- the following change was made:\r\n\r\n+ We adopted the modification [proposed above](#6): gene presence was extracted from the simple Bgee dataset, which [guarantees](#6) that each _Anatomy--expresses--Gene_ relationship contains direct (unpropagated) experimental data.",
      "comment_id": 1152,
      "profile_id": 17,
      "published": "2016-03-08T02:21:02.188057Z",
      "thread_id": 124,
      "url": "/discussion/processing-bgee-for-tissue-specific-gene-presence-and-overunder-expression/124#8"
    },
    {
      "body_html": "<p>Today, I'm teaching a workshop for the <a href=\"http://coursecatalog.ucsf.edu/course/1266\" title=\"Pharmacogenomics 245B · UCSF Registrar\">Systems Pharmacology</a> course at UCSF. The course primarily consists of first year students in the <a href=\"http://pspg.ucsf.edu/\" title=\"PSPG PhD Program at UCSF\">Pharmaceutical Sciences and Pharmacogenomics</a> graduate program.</p>\r\n\r\n<p>The topic of my workshop is \"Big data\". Therefore, I thought a perfect activity would be to analyze the transcriptional perturbation data from <a href=\"http://www.lincscloud.org/l1000/\" title=\"Gene Expression Data · L1000 · Broad Institute\">LINCS L1000</a>. And stars have aligned: first, we've <a href=\"http://thinklab.com/discussion/computing-consensus-transcriptional-profiles-for-lincs-l1000-perturbations/43#7\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d43\">just released</a> version 2 of our consensus signatures; second, we recently noticed some <a href=\"http://thinklab.com/discussion/positive-correlations-between-knockdown-and-overexpression-profiles-from-lincs-l1000/171\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d171\">counterintuitive occurrences</a> in the genetic perturbation data. </p>\r\n\r\n<p>Hence, I've designed a set of questions. Each pupil will be assigned a question. The pupils will then use R to attempt to answer the question. At the end of the three hour workshop, we will encourage pupils to post their findings as a comment on this discussion.</p>\r\n\r\n<p>I'm hoping to teach my <a href=\"http://thinklab.com/discussion/r-best-practices/83\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d83\">R best practices</a> as well as introduce several packages for modern data science. We will strive for the following workflow in R (not every step is needed for each question):</p>\r\n\r\n<ol><li>Read the appropriate file into a dataframe using <a href=\"https://github.com/hadley/readr\"><code>readr</code></a>. The <code>readr::read_tsv()</code> function should come in handy. Datasets are <a href=\"https://github.com/dhimmel/lincs/tree/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi\">available on GitHub</a> (<code>readr</code> should be able to read from the raw dataset URL).</li><li>Tidy the dataframe using <a href=\"https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html\"><code>tidyr</code></a>. The <code>tidyr::spread()</code> function will help convert the wide (matrix) format to a long format.</li><li>Manipulate the dataframe using <a href=\"https://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html\"><code>dplyr</code></a>. Common operations here will be <code>dplyr::filter</code> and <code>dplyr::mutate</code>.</li><li>Join dataframes using <code>dplyr::inner_join()</code> or <code>dplyr::left_join()</code>. </li><li>Answer the question, either by using <code>dplyr::group_by()</code> followed by <code>dplyr::summarize()</code> or by using <a href=\"http://docs.ggplot2.org/\"><code>ggplot2</code></a> to visualize the results.</li></ol>\r\n\r\n<p>Questions will follow!</p>",
      "body_md": "Today, I'm teaching a workshop for the [Systems Pharmacology](http://coursecatalog.ucsf.edu/course/1266 \"Pharmacogenomics 245B · UCSF Registrar\") course at UCSF. The course primarily consists of first year students in the [Pharmaceutical Sciences and Pharmacogenomics](http://pspg.ucsf.edu/ \"PSPG PhD Program at UCSF\") graduate program.\r\n\r\nThe topic of my workshop is \"Big data\". Therefore, I thought a perfect activity would be to analyze the transcriptional perturbation data from [LINCS L1000](http://www.lincscloud.org/l1000/ \"Gene Expression Data · L1000 · Broad Institute\"). And stars have aligned: first, we've [just released](http://thinklab.com/discussion/computing-consensus-transcriptional-profiles-for-lincs-l1000-perturbations/43#7) version 2 of our consensus signatures; second, we recently noticed some [counterintuitive occurrences](http://thinklab.com/discussion/positive-correlations-between-knockdown-and-overexpression-profiles-from-lincs-l1000/171) in the genetic perturbation data. \r\n\r\nHence, I've designed a set of questions. Each pupil will be assigned a question. The pupils will then use R to attempt to answer the question. At the end of the three hour workshop, we will encourage pupils to post their findings as a comment on this discussion.\r\n\r\nI'm hoping to teach my [R best practices](http://thinklab.com/discussion/r-best-practices/83) as well as introduce several packages for modern data science. We will strive for the following workflow in R (not every step is needed for each question):\r\n\r\n1. Read the appropriate file into a dataframe using [`readr`](https://github.com/hadley/readr). The `readr::read_tsv()` function should come in handy. Datasets are [available on GitHub](https://github.com/dhimmel/lincs/tree/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi) (`readr` should be able to read from the raw dataset URL).\r\n2. Tidy the dataframe using [`tidyr`](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html). The `tidyr::spread()` function will help convert the wide (matrix) format to a long format.\r\n3. Manipulate the dataframe using [`dplyr`](https://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html). Common operations here will be `dplyr::filter` and `dplyr::mutate`.\r\n4. Join dataframes using `dplyr::inner_join()` or `dplyr::left_join()`. \r\n5. Answer the question, either by using `dplyr::group_by()` followed by `dplyr::summarize()` or by using [`ggplot2`](http://docs.ggplot2.org/) to visualize the results.\r\n\r\nQuestions will follow!",
      "comment_id": 1153,
      "profile_id": 17,
      "published": "2016-03-08T20:48:53.558018Z",
      "thread_id": 181,
      "url": "/discussion/workshop-to-analyze-lincs-data-for-the-systems-pharmacology-course-at-ucsf/181"
    },
    {
      "body_html": "<h1>Datasets</h1>\r\n\r\n<p>The <a href=\"#2\">above questions</a> can all be answered using the following three datasets.</p>\r\n\r\n<h3>Gene information <a href=\"https://github.com/dhimmel/lincs/blob/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/genes.tsv\"><code>genes.tsv</code></a></h3>\r\n\r\n<p>This dataset contains which genes have regulation scores. It also contains whether the gene's expression was directly measured or imputed. The raw dataset is available at:</p>\r\n\r\n<pre><code class=\"no-highlight hljs\">https://github.com/dhimmel/lincs/raw/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/genes.tsv</code></pre>\r\n\r\n<p>Below is a preview:</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>entrez_gene_id</th><th>status</th><th>symbol</th><th>type_of_gene</th><th>description</th></tr></thead><tbody><tr><td>100</td><td>imputed</td><td>ADA</td><td>protein-coding</td><td>adenosine deaminase</td></tr><tr><td>1000</td><td>imputed</td><td>CDH2</td><td>protein-coding</td><td>cadherin 2, type 1, N-cadherin (neuronal)</td></tr><tr><td>10000</td><td>imputed</td><td>AKT3</td><td>protein-coding</td><td>v-akt murine thymoma viral oncogene homolog 3</td></tr></tbody></table>\r\n\r\n<h3>Genes dysregulated by knockdowns <a href=\"https://github.com/dhimmel/lincs/blob/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/signif/dysreg-knockdown.tsv\"><code>dysreg-knockdown.tsv</code></a></h3>\r\n\r\n<p>This dataset contains significantly dysregulated genes due to knockdown perturbations. The raw dataset is available at:</p>\r\n\r\n<pre><code class=\"no-highlight hljs\">https://github.com/dhimmel/lincs/raw/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/signif/dysreg-knockdown.tsv</code></pre>\r\n\r\n<p>Below is a preview:</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>perturbagen</th><th>entrez_gene_id</th><th>z_score</th><th>symbol</th><th>status</th><th>direction</th><th>nlog10_bonferroni_pval</th></tr></thead><tbody><tr><td>2</td><td>133</td><td>-5.495</td><td>ADM</td><td>imputed</td><td>down</td><td>3.596</td></tr><tr><td>2</td><td>501</td><td>-4.317</td><td>ALDH7A1</td><td>measured</td><td>down</td><td>1.811</td></tr><tr><td>2</td><td>9915</td><td>-5.579</td><td>ARNT2</td><td>measured</td><td>down</td><td>4.626</td></tr></tbody></table>\r\n\r\n<h3>Genes dysregulated by overexpressions <a href=\"https://github.com/dhimmel/lincs/blob/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/signif/dysreg-overexpression.tsv\"><code>dysreg-overexpression.tsv</code></a></h3>\r\n\r\n<p>This dataset contains significantly dysregulated genes due to overexpression perturbations. The raw dataset is available at:</p>\r\n\r\n<pre><code class=\"no-highlight hljs\">https://github.com/dhimmel/lincs/raw/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/signif/dysreg-overexpression.tsv</code></pre>\r\n\r\n<p>Below is a preview:</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>perturbagen</th><th>entrez_gene_id</th><th>z_score</th><th>symbol</th><th>status</th><th>direction</th><th>nlog10_bonferroni_pval</th></tr></thead><tbody><tr><td>2</td><td>991</td><td>-4.687</td><td>CDC20</td><td>measured</td><td>down</td><td>2.567</td></tr><tr><td>2</td><td>54438</td><td>4.551</td><td>GFOD1</td><td>measured</td><td>up</td><td>2.282</td></tr><tr><td>2</td><td>5950</td><td>4.590</td><td>RBP4</td><td>imputed</td><td>up</td><td>1.541</td></tr></tbody></table>",
      "body_md": "# Datasets\r\n\r\nThe [above questions](#2) can all be answered using the following three datasets.\r\n\r\n### Gene information [`genes.tsv`](https://github.com/dhimmel/lincs/blob/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/genes.tsv)\r\n\r\nThis dataset contains which genes have regulation scores. It also contains whether the gene's expression was directly measured or imputed. The raw dataset is available at:\r\n\r\n```\r\nhttps://github.com/dhimmel/lincs/raw/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/genes.tsv\r\n```\r\n\r\nBelow is a preview:\r\n\r\n| entrez_gene_id | status | symbol | type_of_gene | description |\r\n|----------------|---------|--------|----------------|----------------------|\r\n| 100 | imputed | ADA | protein-coding | adenosine deaminase |\r\n| 1000 | imputed | CDH2 | protein-coding | cadherin 2, type 1, N-cadherin (neuronal) |\r\n| 10000 | imputed | AKT3 | protein-coding | v-akt murine thymoma viral oncogene homolog 3 |\r\n\r\n### Genes dysregulated by knockdowns [`dysreg-knockdown.tsv`](https://github.com/dhimmel/lincs/blob/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/signif/dysreg-knockdown.tsv)\r\n\r\nThis dataset contains significantly dysregulated genes due to knockdown perturbations. The raw dataset is available at:\r\n\r\n```\r\nhttps://github.com/dhimmel/lincs/raw/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/signif/dysreg-knockdown.tsv\r\n```\r\n\r\nBelow is a preview:\r\n\r\n| perturbagen | entrez_gene_id | z_score | symbol | status | direction | nlog10_bonferroni_pval |\r\n|-------------|----------------|---------|---------|----------|-----------|------------------------|\r\n| 2 | 133 | -5.495 | ADM | imputed | down | 3.596 |\r\n| 2 | 501 | -4.317 | ALDH7A1 | measured | down | 1.811 |\r\n| 2 | 9915 | -5.579 | ARNT2 | measured | down | 4.626 |\r\n\r\n### Genes dysregulated by overexpressions [`dysreg-overexpression.tsv`](https://github.com/dhimmel/lincs/blob/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/signif/dysreg-overexpression.tsv)\r\n\r\nThis dataset contains significantly dysregulated genes due to overexpression perturbations. The raw dataset is available at:\r\n\r\n```\r\nhttps://github.com/dhimmel/lincs/raw/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/signif/dysreg-overexpression.tsv\r\n```\r\n\r\nBelow is a preview:\r\n\r\n| perturbagen | entrez_gene_id | z_score | symbol | status | direction | nlog10_bonferroni_pval |\r\n|-------------|----------------|---------|--------|----------|-----------|------------------------|\r\n| 2 | 991 | -4.687 | CDC20 | measured | down | 2.567 |\r\n| 2 | 54438 | 4.551 | GFOD1 | measured | up | 2.282 |\r\n| 2 | 5950 | 4.590 | RBP4 | imputed | up | 1.541 |",
      "comment_id": 1154,
      "profile_id": 17,
      "published": "2016-03-08T21:50:14.240676Z",
      "thread_id": 181,
      "url": "/discussion/workshop-to-analyze-lincs-data-for-the-systems-pharmacology-course-at-ucsf/181#3"
    },
    {
      "body_html": "<h1>Questions</h1>\r\n\r\n<p>Here are the 13 questions for the workshop. They all focus on understanding the transcriptional response to genetic perturbation.</p>\r\n\r\n<ol><li><p>How many knockdowns significantly downregulated their target gene (expected)? How many knockdowns significantly upregulated their target gene (unexpected)?</p></li><li><p>How many overexpressions significantly upregulated their target gene (expected)? How many overexpressions significantly downregulated their target gene (unexpected)?</p></li><li><p>How many genes were never significantly dysregulated by any knockdown perturbation? Report this number for both the measured and inferred gene sets.</p></li><li><p>How many genes were never significantly dysregulated by any knockdown perturbation? Report this number for both the measured and inferred gene sets. (<strong>same as 3 by accident</strong>)</p></li><li><p>Which ten genes were most frequently significantly downregulated by gene knockdowns? How many knockdowns significantly downregulated these genes? How many knockdowns significantly upregulated these genes?</p></li><li><p>Which ten genes were most frequently significantly upregulated by gene knockdowns? How many knockdowns significantly upregulated these genes? How many knockdowns significantly downregulated these genes?</p></li><li><p>Which ten genes were most frequently significantly downregulated by gene overexpression? How many overexpressions significantly downregulated these genes? How many overexpressions significantly upregulated these genes?</p></li><li><p>Which ten genes were most frequently significantly upregulated by gene overexpression? How many overexpressions significantly upregulated these genes? How many overexpressions significantly downregulated these genes?</p></li><li><p>For knockdown perturbations, what is the correlation between number of significantly down and upregulated measured genes.</p></li></ol>\r\n\r\n<p>Dataset documentation will follow.</p>",
      "body_md": "# Questions\r\n\r\nHere are the 13 questions for the workshop. They all focus on understanding the transcriptional response to genetic perturbation.\r\n\r\n1. How many knockdowns significantly downregulated their target gene (expected)? How many knockdowns significantly upregulated their target gene (unexpected)?\r\n\r\n2. How many overexpressions significantly upregulated their target gene (expected)? How many overexpressions significantly downregulated their target gene (unexpected)?\r\n\r\n3. How many genes were never significantly dysregulated by any knockdown perturbation? Report this number for both the measured and inferred gene sets.\r\n\r\n4. How many genes were never significantly dysregulated by any knockdown perturbation? Report this number for both the measured and inferred gene sets. (**same as 3 by accident**)\r\n\r\n5. Which ten genes were most frequently significantly downregulated by gene knockdowns? How many knockdowns significantly downregulated these genes? How many knockdowns significantly upregulated these genes?\r\n\r\n6. Which ten genes were most frequently significantly upregulated by gene knockdowns? How many knockdowns significantly upregulated these genes? How many knockdowns significantly downregulated these genes?\r\n\r\n7. Which ten genes were most frequently significantly downregulated by gene overexpression? How many overexpressions significantly downregulated these genes? How many overexpressions significantly upregulated these genes?\r\n\r\n8. Which ten genes were most frequently significantly upregulated by gene overexpression? How many overexpressions significantly upregulated these genes? How many overexpressions significantly downregulated these genes?\r\n\r\n9. For knockdown perturbations, what is the correlation between number of significantly down and upregulated measured genes.\r\n\r\nDataset documentation will follow.",
      "comment_id": 1155,
      "profile_id": 17,
      "published": "2016-03-08T21:30:42.249146Z",
      "thread_id": 181,
      "url": "/discussion/workshop-to-analyze-lincs-data-for-the-systems-pharmacology-course-at-ucsf/181#2"
    },
    {
      "body_html": "<h1>Question 2</h1>\r\n\r\n<p>I answered:</p>\r\n\r\n<blockquote><p>How many overexpressions significantly upregulated their target gene (expected)? How many overexpressions significantly downregulated their target gene (unexpected)?</p></blockquote>\r\n\r\n<p>R code: <br></p>\r\n\r\n<pre><code class=\"no-highlight hljs\"># workshop with dan himmelstein\r\n\r\n# which genes have regulation scores. It also contains whether the gene's expression was directly measured or imputed\r\n\r\npath &lt;- 'https://github.com/dhimmel/lincs/raw/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/genes.tsv'\r\ngene_df &lt;- readr::read_tsv(path)\r\n\r\n# significantly dysregulated genes due to knockdown perturbations\r\n\r\npath2 &lt;- 'https://github.com/dhimmel/lincs/raw/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/signif/dysreg-knockdown.tsv'\r\nkd_df &lt;- readr::read_tsv(path2)\r\n\r\n# significantly dysregulated genes due to overexpression perturbations\r\n\r\npath3 &lt;- 'https://github.com/dhimmel/lincs/raw/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/signif/dysreg-overexpression.tsv'\r\noe_df &lt;- readr::read_tsv(path3)\r\n\r\ndat &lt;- filter(oe_df, perturbagen == entrez_gene_id)\r\n\r\ndat %&gt;%\r\n  dplyr::group_by(direction) %&gt;%\r\n  dplyr::summarize(\r\n    count = n()\r\n  )</code></pre>\r\n\r\n<p>R output: <br></p>\r\n\r\n<pre><code class=\"no-highlight hljs\">Source: local data frame [2 x 2]\r\n\r\n  direction count\r\n      (chr) (int)\r\n1      down     4\r\n2        up   124\r\n/</code></pre>\r\n\r\n<p>So, 4 genes were significantly downregulated after being overexpressed (unexpected) and 124 genes were significantly upregulated after being overexpressed (expected). </p>\r\n\r\n<p>Thanks Dan!</p>",
      "body_md": "# Question 2\r\n\r\nI answered:\r\n\r\n> How many overexpressions significantly upregulated their target gene (expected)? How many overexpressions significantly downregulated their target gene (unexpected)?\r\n\r\nR code: \r\n```R\r\n# workshop with dan himmelstein\r\n\r\n# which genes have regulation scores. It also contains whether the gene's expression was directly measured or imputed\r\n\r\npath <- 'https://github.com/dhimmel/lincs/raw/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/genes.tsv'\r\ngene_df <- readr::read_tsv(path)\r\n\r\n# significantly dysregulated genes due to knockdown perturbations\r\n\r\npath2 <- 'https://github.com/dhimmel/lincs/raw/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/signif/dysreg-knockdown.tsv'\r\nkd_df <- readr::read_tsv(path2)\r\n\r\n# significantly dysregulated genes due to overexpression perturbations\r\n\r\npath3 <- 'https://github.com/dhimmel/lincs/raw/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/signif/dysreg-overexpression.tsv'\r\noe_df <- readr::read_tsv(path3)\r\n\r\ndat <- filter(oe_df, perturbagen == entrez_gene_id)\r\n\r\ndat %>%\r\n  dplyr::group_by(direction) %>%\r\n  dplyr::summarize(\r\n    count = n()\r\n  )\r\n```\r\n\r\nR output: \r\n```R\r\nSource: local data frame [2 x 2]\r\n\r\n  direction count\r\n      (chr) (int)\r\n1      down     4\r\n2        up   124\r\n/\r\n```\r\n\r\nSo, 4 genes were significantly downregulated after being overexpressed (unexpected) and 124 genes were significantly upregulated after being overexpressed (expected). \r\n\r\nThanks Dan!",
      "comment_id": 1156,
      "profile_id": 203,
      "published": "2016-03-08T22:59:21.544674Z",
      "thread_id": 181,
      "url": "/discussion/workshop-to-analyze-lincs-data-for-the-systems-pharmacology-course-at-ucsf/181#4"
    },
    {
      "body_html": "<p>For question 3,</p>\r\n\r\n<blockquote><p>How many genes were never significantly dysregulated by any knockdown perturbation? Report this number for both the measured and inferred gene sets.</p></blockquote>\r\n\r\n<p>The elegant dplyr solution (thanks Daniel) looks like:</p>\r\n\r\n<pre><code class=\"r\">#how many times are genes disregulated in all?\r\ncount_df = knockdown_df %&gt;%\r\n  dplyr::group_by(entrez_gene_id) %&gt;%\r\n  dplyr::summarise(count=n())\r\n\r\n#join the table of counts with the full table of genes. the genes that were not present\r\n#are automatically converted to missing data\r\nfull=gene_df %&gt;% \r\n  dplyr::left_join(count_df)\r\n\r\n#divide the missing data by imputed vs. measured\r\nresult = full %&gt;% dplyr::filter(is.na(count)) %&gt;% \r\n  dplyr::group_by(status) %&gt;% \r\n  dplyr::summarise(count=n())</code></pre>\r\n\r\n<p>The solution: of all the genes, very few avoid disregulation!</p>\r\n\r\n<pre><code class=\"no-highlight hljs\">    status count\r\n     (chr) (int)\r\n1  imputed    55\r\n2 measured     1</code></pre>",
      "body_md": "For question 3,\r\n\r\n> How many genes were never significantly dysregulated by any knockdown perturbation? Report this number for both the measured and inferred gene sets.\r\n\r\nThe elegant dplyr solution (thanks Daniel) looks like:\r\n\r\n```r\r\n#how many times are genes disregulated in all?\r\ncount_df = knockdown_df %>%\r\n  dplyr::group_by(entrez_gene_id) %>%\r\n  dplyr::summarise(count=n())\r\n\r\n#join the table of counts with the full table of genes. the genes that were not present\r\n#are automatically converted to missing data\r\nfull=gene_df %>% \r\n  dplyr::left_join(count_df)\r\n\r\n#divide the missing data by imputed vs. measured\r\nresult = full %>% dplyr::filter(is.na(count)) %>% \r\n  dplyr::group_by(status) %>% \r\n  dplyr::summarise(count=n())\r\n```\r\n\r\nThe solution: of all the genes, very few avoid disregulation!\r\n\r\n```\r\n    status count\r\n     (chr) (int)\r\n1  imputed    55\r\n2 measured     1\r\n```",
      "comment_id": 1157,
      "profile_id": 205,
      "published": "2016-03-08T23:45:28.542693Z",
      "thread_id": 181,
      "url": "/discussion/workshop-to-analyze-lincs-data-for-the-systems-pharmacology-course-at-ucsf/181#5"
    },
    {
      "body_html": "<h1>Question 1</h1>\r\n\r\n<blockquote><p>How many knockdowns significantly downregulated their target gene (expected)? How many knockdowns significantly upregulated their target gene (unexpected)?</p></blockquote>\r\n\r\n<p>Here is the Code :)</p>\r\n\r\n<pre><code class=\"r\">path = 'https://github.com/dhimmel/lincs/raw/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/signif/dysreg-knockdown.tsv'\r\ngene_kd = readr::read_tsv(path)\r\n\r\ngene_kd %&gt;%\r\n  dplyr::filter(perturbagen == entrez_gene_id) %&gt;%\r\n  dplyr::group_by(direction) %&gt;%\r\n  dplyr::summarize(\r\n    count = n()\r\n  )\r\n\r\n</code></pre>\r\n\r\n<p>Output:</p>\r\n\r\n<pre><code class=\"no-highlight hljs\">  direction count\r\n      (chr) (int)\r\n1      down   806\r\n2        up     9</code></pre>\r\n\r\n<p><strong>Conclusion:</strong> Of the knockdown genes, 806 significantly downregulated their gene (expected) while 9 upregulated their gene (unexpected)</p>",
      "body_md": "# Question 1\r\n\r\n>How many knockdowns significantly downregulated their target gene (expected)? How many knockdowns significantly upregulated their target gene (unexpected)?\r\n\r\nHere is the Code :)\r\n\r\n```r\r\npath = 'https://github.com/dhimmel/lincs/raw/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/signif/dysreg-knockdown.tsv'\r\ngene_kd = readr::read_tsv(path)\r\n\r\ngene_kd %>%\r\n  dplyr::filter(perturbagen == entrez_gene_id) %>%\r\n  dplyr::group_by(direction) %>%\r\n  dplyr::summarize(\r\n    count = n()\r\n  )\r\n\r\n```\r\n\r\nOutput:\r\n\r\n```\r\n  direction count\r\n      (chr) (int)\r\n1      down   806\r\n2        up     9\r\n```\r\n\r\n**Conclusion:** Of the knockdown genes, 806 significantly downregulated their gene (expected) while 9 upregulated their gene (unexpected)",
      "comment_id": 1158,
      "profile_id": 206,
      "published": "2016-03-08T23:56:35.270382Z",
      "thread_id": 181,
      "url": "/discussion/workshop-to-analyze-lincs-data-for-the-systems-pharmacology-course-at-ucsf/181#6"
    },
    {
      "body_html": "<h2>Question 6</h2>\r\n\r\n<pre><code>knock_down_path =    \"https://github.com/dhimmel/lincs/raw/abcb12f942f93e3ee839e5e3593f930df2c56845/data/con    sensi/signif/dysreg-knockdown.tsv\"\r\nkd_genes = readr::read_tsv(knock_down_path)\r\nkd_genes$direction = as.factor(kd_genes$direction)\r\n\r\nkd_genes %&gt;%\r\n  group_by(symbol, direction) %&gt;%\r\n  dplyr::summarise(count=n()) %&gt;%\r\n  tidyr::spread(key = direction, value = count, fill = 0) %&gt;%\r\n  arrange(desc(up)) %&gt;% top_n(n = 10, wt = desc(up))</code></pre>\r\n\r\n<h2>Resulting Table</h2>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>symbol</th><th>down</th><th>up</th></tr></thead><tbody><tr><td>MCOLN1</td><td>2</td><td>1128</td></tr><tr><td>MAL</td><td>0</td><td>985</td></tr><tr><td>WIF1</td><td>0</td><td>884</td></tr><tr><td>SERPINA3</td><td>0</td><td>873</td></tr><tr><td>SATB1</td><td>0</td><td>862</td></tr><tr><td>CES1</td><td>0</td><td>849</td></tr><tr><td>XIST</td><td>30</td><td>764</td></tr><tr><td>CRIP1</td><td>0</td><td>713</td></tr><tr><td>KLHL21</td><td>2</td><td>602</td></tr><tr><td>COL11A1</td><td>0</td><td>562</td></tr><tr><td>TF</td><td>0</td><td>527</td></tr><tr><td>ERAP2</td><td>0</td><td>512</td></tr><tr><td>ABCC5</td><td>3</td><td>501</td></tr><tr><td>AGR2</td><td>2</td><td>478</td></tr><tr><td>CPVL</td><td>1</td><td>476</td></tr></tbody></table>\r\n\r\n<h2>Notes</h2>\r\n\r\n<p>These are the top 10 most unregulated genes. These up-regulated genes do not appear to be down-regulated with any significant frequency</p>",
      "body_md": "## Question 6\r\n    knock_down_path =    \"https://github.com/dhimmel/lincs/raw/abcb12f942f93e3ee839e5e3593f930df2c56845/data/con    sensi/signif/dysreg-knockdown.tsv\"\r\n    kd_genes = readr::read_tsv(knock_down_path)\r\n    kd_genes$direction = as.factor(kd_genes$direction)\r\n\r\n    kd_genes %>%\r\n      group_by(symbol, direction) %>%\r\n      dplyr::summarise(count=n()) %>%\r\n      tidyr::spread(key = direction, value = count, fill = 0) %>%\r\n      arrange(desc(up)) %>% top_n(n = 10, wt = desc(up))\r\n\r\n## Resulting Table\r\n| symbol   | down | up   |\r\n|----------|------|------|\r\n| MCOLN1   | 2    | 1128 |\r\n| MAL      | 0    | 985  |\r\n| WIF1     | 0    | 884  |\r\n| SERPINA3 | 0    | 873  |\r\n| SATB1    | 0    | 862  |\r\n| CES1     | 0    | 849  |\r\n| XIST     | 30   | 764  |\r\n| CRIP1    | 0    | 713  |\r\n| KLHL21   | 2    | 602  |\r\n| COL11A1  | 0    | 562  |\r\n| TF       | 0    | 527  |\r\n| ERAP2    | 0    | 512  |\r\n| ABCC5    | 3    | 501  |\r\n| AGR2     | 2    | 478  |\r\n| CPVL     | 1    | 476  |\r\n\r\n## Notes\r\nThese are the top 10 most unregulated genes. These up-regulated genes do not appear to be down-regulated with any significant frequency",
      "comment_id": 1159,
      "profile_id": 204,
      "published": "2016-03-09T00:01:36.493127Z",
      "thread_id": 181,
      "url": "/discussion/workshop-to-analyze-lincs-data-for-the-systems-pharmacology-course-at-ucsf/181#7"
    },
    {
      "body_html": "<h1>Question 5</h1>\r\n\r\n<blockquote><p>Which ten genes were most frequently significantly downregulated by gene knockdowns? How many knockdowns significantly downregulated these genes? How many knockdowns significantly upregulated these genes?</p></blockquote>\r\n\r\n<p>Here's my code:</p>\r\n\r\n<pre><code class=\"r\">path=\"https://raw.githubusercontent.com/dhimmel/lincs/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/genes.tsv\"\r\npath2=\"https://raw.githubusercontent.com/dhimmel/lincs/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/signif/dysreg-knockdown.tsv\"\r\npath3=\"https://raw.githubusercontent.com/dhimmel/lincs/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/signif/dysreg-overexpression.tsv\"\r\ngene_df = readr::read_tsv(path)\r\nkd_gene = readr::read_tsv(path2)\r\noexp_gene= readr::read_tsv(path3)\r\nhead(gene_df)\r\nhead(kd_gene)\r\nView(kd_gene)\r\nlibrary(dplyr)\r\nlibrary(tidyr)\r\n\r\ngene_df %&gt;%\r\n  dplyr::group_by(status) %&gt;%\r\n  dplyr::summarize(\r\n    count=n()\r\n  )\r\n\r\ngene_df %&gt;% \r\n  dplyr::mutate(kind='gene')\r\n\r\n#which 10 genes were most frequently dowregulated by KDs\r\n\r\n#first, find number of distinct genes downregulated by KDs (7411)\r\nkd_gene$entrez_gene_id %&gt;% \r\n  n_distinct()\r\n#next, find number of pertubagens (4312)\r\nkd_gene$perturbagen %&gt;% \r\n  n_distinct()\r\n\r\n#from the top 10 genes, how many times were they downregulated? \r\n#genes most frequently DOWNREGULATED by the KNOCKDOWNS\r\n\r\n\r\n#filter to only downregulated KDs\r\ndownregulated_kds &lt;- kd_gene %&gt;% \r\n  filter(direction==\"down\")\r\n#sort by count to downregulated KDs\r\ndownreg_kd_sorted &lt;- downregulated_kds %&gt;%\r\n  dplyr::group_by(symbol) %&gt;%\r\n  dplyr::summarise(\r\n    count=n()\r\n  ) %&gt;%\r\n  dplyr::arrange(desc(count))\r\nhead(downreg_kd_sorted, 10)\r\nView(downreg_kd_sorted)\r\n\r\n#from the top 10 genes, how many times were they UPREGULATED? \r\n#genes most frequently UPREGULATED by the KNOCKDOWNS\r\n\r\n#filter to only upregulated KDs\r\nupregulated_kds &lt;- kd_gene %&gt;% \r\n  filter(direction==\"up\")\r\n#sort by count to upregulated KDs\r\nupreg_kd_sorted &lt;- upregulated_kds %&gt;%\r\n  dplyr::group_by(symbol) %&gt;%\r\n  dplyr::summarise(\r\n    count=n()\r\n  ) %&gt;%\r\n  dplyr::arrange(desc(count))\r\nhead(upreg_kd_sorted, 10)\r\nView(upreg_kd_sorted)\r\n\r\n\r\n#How many knockdowns downregulated these genes? 195,786\r\n#How many knockdowns upregulated these genes? 132,282\r\nnrow(kd_gene)\r\nkd_gene %&gt;%\r\n  dplyr::group_by(direction) %&gt;%\r\n  dplyr::summarize(\r\n    count=n()\r\n  )\r\n\r\nupreg_kd_sorted&lt;- upreg_kd_sorted %&gt;% \r\n  dplyr::rename(up_count=count)\r\ndim(upreg_kd_sorted)\r\nView(upreg_kd_sorted)\r\n\r\ndownreg_kd_sorted &lt;-downreg_kd_sorted %&gt;%\r\n  dplyr::rename(down_count=count)\r\ndim(downreg_kd_sorted)\r\n\r\nMYANSWER&lt;- dplyr::full_join(downreg_kd_sorted, upreg_kd_sorted)\r\n\r\nMYANSWER[is.na(MYANSWER)] = 0\r\nMYANSWER</code></pre>\r\n\r\n<p>Here's my answer:</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>symbol</th><th>down_count</th><th>up_count</th></tr></thead><tbody><tr><td>RPS4Y1</td><td>1637</td><td>0</td></tr><tr><td>CDC20</td><td>1456</td><td>1</td></tr><tr><td>PCNA</td><td>1360</td><td>0</td></tr><tr><td>NME1</td><td>1182</td><td>0</td></tr><tr><td>MIF</td><td>1052</td><td>0</td></tr><tr><td>CSRP1</td><td>1031</td><td>1</td></tr><tr><td>STUB1</td><td>996</td><td>10</td></tr><tr><td>TIMM9</td><td>989</td><td>4</td></tr><tr><td>TYMS</td><td>881</td><td>0</td></tr><tr><td>GDF15</td><td>866</td><td>0</td></tr></tbody></table>",
      "body_md": "# Question 5\r\n\r\n> Which ten genes were most frequently significantly downregulated by gene knockdowns? How many knockdowns significantly downregulated these genes? How many knockdowns significantly upregulated these genes?\r\n\r\nHere's my code:\r\n\r\n```r\r\npath=\"https://raw.githubusercontent.com/dhimmel/lincs/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/genes.tsv\"\r\npath2=\"https://raw.githubusercontent.com/dhimmel/lincs/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/signif/dysreg-knockdown.tsv\"\r\npath3=\"https://raw.githubusercontent.com/dhimmel/lincs/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/signif/dysreg-overexpression.tsv\"\r\ngene_df = readr::read_tsv(path)\r\nkd_gene = readr::read_tsv(path2)\r\noexp_gene= readr::read_tsv(path3)\r\nhead(gene_df)\r\nhead(kd_gene)\r\nView(kd_gene)\r\nlibrary(dplyr)\r\nlibrary(tidyr)\r\n\r\ngene_df %>%\r\n  dplyr::group_by(status) %>%\r\n  dplyr::summarize(\r\n    count=n()\r\n  )\r\n\r\ngene_df %>% \r\n  dplyr::mutate(kind='gene')\r\n\r\n#which 10 genes were most frequently dowregulated by KDs\r\n\r\n#first, find number of distinct genes downregulated by KDs (7411)\r\nkd_gene$entrez_gene_id %>% \r\n  n_distinct()\r\n#next, find number of pertubagens (4312)\r\nkd_gene$perturbagen %>% \r\n  n_distinct()\r\n\r\n#from the top 10 genes, how many times were they downregulated? \r\n#genes most frequently DOWNREGULATED by the KNOCKDOWNS\r\n\r\n\r\n#filter to only downregulated KDs\r\ndownregulated_kds <- kd_gene %>% \r\n  filter(direction==\"down\")\r\n#sort by count to downregulated KDs\r\ndownreg_kd_sorted <- downregulated_kds %>%\r\n  dplyr::group_by(symbol) %>%\r\n  dplyr::summarise(\r\n    count=n()\r\n  ) %>%\r\n  dplyr::arrange(desc(count))\r\nhead(downreg_kd_sorted, 10)\r\nView(downreg_kd_sorted)\r\n\r\n#from the top 10 genes, how many times were they UPREGULATED? \r\n#genes most frequently UPREGULATED by the KNOCKDOWNS\r\n\r\n#filter to only upregulated KDs\r\nupregulated_kds <- kd_gene %>% \r\n  filter(direction==\"up\")\r\n#sort by count to upregulated KDs\r\nupreg_kd_sorted <- upregulated_kds %>%\r\n  dplyr::group_by(symbol) %>%\r\n  dplyr::summarise(\r\n    count=n()\r\n  ) %>%\r\n  dplyr::arrange(desc(count))\r\nhead(upreg_kd_sorted, 10)\r\nView(upreg_kd_sorted)\r\n\r\n\r\n#How many knockdowns downregulated these genes? 195,786\r\n#How many knockdowns upregulated these genes? 132,282\r\nnrow(kd_gene)\r\nkd_gene %>%\r\n  dplyr::group_by(direction) %>%\r\n  dplyr::summarize(\r\n    count=n()\r\n  )\r\n\r\nupreg_kd_sorted<- upreg_kd_sorted %>% \r\n  dplyr::rename(up_count=count)\r\ndim(upreg_kd_sorted)\r\nView(upreg_kd_sorted)\r\n\r\ndownreg_kd_sorted <-downreg_kd_sorted %>%\r\n  dplyr::rename(down_count=count)\r\ndim(downreg_kd_sorted)\r\n\r\nMYANSWER<- dplyr::full_join(downreg_kd_sorted, upreg_kd_sorted)\r\n\r\nMYANSWER[is.na(MYANSWER)] = 0\r\nMYANSWER\r\n```\r\n\r\nHere's my answer:\r\n\r\n| symbol | down_count | up_count |\r\n|--------|------------|----------|\r\n| RPS4Y1 | 1637       | 0        |\r\n| CDC20  | 1456       | 1        |\r\n| PCNA   | 1360       | 0        |\r\n| NME1   | 1182       | 0        |\r\n| MIF    | 1052       | 0        |\r\n| CSRP1  | 1031       | 1        |\r\n| STUB1  | 996        | 10       |\r\n| TIMM9  | 989        | 4        |\r\n| TYMS   | 881        | 0        |\r\n| GDF15  | 866        | 0        |",
      "comment_id": 1160,
      "profile_id": 208,
      "published": "2016-03-09T00:09:28.230131Z",
      "thread_id": 181,
      "url": "/discussion/workshop-to-analyze-lincs-data-for-the-systems-pharmacology-course-at-ucsf/181#8"
    },
    {
      "body_html": "<h1>Question 7, 8, and 9</h1>\r\n\r\n<pre><code class=\"r\">#read in data \r\npath_genes = 'https://github.com/dhimmel/lincs/raw/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/genes.tsv'\r\ngene_df = readr::read_tsv(path_genes)\r\n\r\npath_down = 'https://github.com/dhimmel/lincs/raw/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/signif/dysreg-knockdown.tsv'\r\ndown_df = readr::read_tsv(path_down)\r\n\r\npath_over = 'https://github.com/dhimmel/lincs/raw/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/signif/dysreg-overexpression.tsv'\r\nover_df = readr::read_tsv(path_over)</code></pre>\r\n\r\n<h2>Question 7- Emmalyn Chen</h2>\r\n\r\n<pre><code class=\"r\">q.7 = over_df %&gt;% subset(z_score &lt; 0) %&gt;% group_by(entrez_gene_id) %&gt;% summarize(count=n()) %&gt;% arrange(-count)\r\nq.7 = q.7[1:10,]</code></pre>\r\n\r\n<p>a. Which ten genes were most frequently significantly downregulated by gene overexpression? <br></p>\r\n\r\n<pre><code class=\"no-highlight hljs\">entrez_gene_id count\r\n            (int) (int)\r\n1            6192   166\r\n2             991   165\r\n3            5111   165\r\n4            5018   122\r\n5             994   105\r\n6           26520   102\r\n7            1738    91\r\n8            9133    86\r\n9            7298    84\r\n10          22827    83\r\n</code></pre>\r\n\r\n<p>b. How many overexpressions significantly downregulated these genes?</p>\r\n\r\n<pre><code class=\"r\">q.7.2 = over_df %&gt;% subset(z_score &lt; 0) %&gt;% filter(entrez_gene_id %in% q.7$entrez_gene_id) %&gt;% \r\n  group_by(perturbagen) %&gt;% summarize(count = n())</code></pre>\r\n\r\n<p>612 overexpressed genes </p>\r\n\r\n<p>c. How many overexpressions significantly upregulated these genes?</p>\r\n\r\n<pre><code class=\"r\">q.7.3 = over_df %&gt;% subset(z_score &gt; 0) %&gt;% filter(entrez_gene_id %in% q.7$entrez_gene_id) %&gt;% \r\n  group_by(perturbagen) %&gt;% summarize(count = n())</code></pre>\r\n\r\n<p>4 overexpressed genes</p>\r\n\r\n<h2>Question 8 - Liz Levy</h2>\r\n\r\n<pre><code class=\"r\">q.8 = over_df %&gt;% subset(z_score &gt; 0) %&gt;% group_by(entrez_gene_id) %&gt;% summarize(count=n()) %&gt;% arrange(-count)\r\nq.8 = q.8[1:10,]</code></pre>\r\n\r\n<p>a. Which ten genes were most frequently significantly upregulated by gene overexpression? <br></p>\r\n\r\n<pre><code class=\"no-highlight hljs\">entrez_gene_id count\r\n            (int) (int)\r\n1           57192   180\r\n2            5331   152\r\n3           25966   140\r\n4           23378   113\r\n5            4118   104\r\n6            9903    99\r\n7           55008    98\r\n8            1066    96\r\n9            5971    94\r\n10           7503    94</code></pre>\r\n\r\n<p>b. How many overexpressions significantly upregulated these genes?<br></p>\r\n\r\n<pre><code class=\"r\">q.8.2 = over_df %&gt;% subset(z_score &gt; 0) %&gt;% filter(entrez_gene_id %in% q.8$entrez_gene_id) %&gt;% \r\n  group_by(perturbagen) %&gt;% summarize(count = n())</code></pre>\r\n\r\n<p>792 overexpressed genes  </p>\r\n\r\n<p>c. How many overexpressions significantly downregulated these genes?<br></p>\r\n\r\n<pre><code class=\"r\">q.8.3 = over_df %&gt;% subset(z_score &lt; 0) %&gt;% filter(entrez_gene_id %in% q.8$entrez_gene_id) %&gt;% \r\n  group_by(perturbagen) %&gt;% summarize(count = n())</code></pre>\r\n\r\n<p>14 overexpressed genes </p>\r\n\r\n<h2>Question 9 - Marjorie Imperial</h2>\r\n\r\n<p>For knockdown perturbations, what is the correlation between number of significantly down and upregulated measured genes.<br></p>\r\n\r\n<pre><code class=\"r\">q.9.down.reg = down_df %&gt;% subset(z_score &lt; 0) %&gt;% group_by(perturbagen) %&gt;% summarize(count.down.reg = n())\r\nq.9.up.reg = down_df %&gt;% subset(z_score &gt; 0) %&gt;% group_by(perturbagen) %&gt;% summarize(count.up.reg = n())\r\n\r\njoined_df = dplyr::full_join(q.9.down.reg, q.9.up.reg)\r\njoined_df[is.na(joined_df)] = 0</code></pre>\r\n\r\n<p>Pearson correlation, R =0.9371317<br></p>\r\n\r\n<pre><code class=\"r\">cor(joined_df$count.down.reg, joined_df$count.up.reg)</code></pre>\r\n\r\n<p>Kendall correlation R = 0.732456 <br></p>\r\n\r\n<pre><code class=\"no-highlight hljs\">cor(joined_df$count.down.reg, joined_df$count.up.reg, method = 'kendall')</code></pre>",
      "body_md": "# Question 7, 8, and 9\r\n\r\n```r\r\n#read in data \r\npath_genes = 'https://github.com/dhimmel/lincs/raw/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/genes.tsv'\r\ngene_df = readr::read_tsv(path_genes)\r\n\r\npath_down = 'https://github.com/dhimmel/lincs/raw/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/signif/dysreg-knockdown.tsv'\r\ndown_df = readr::read_tsv(path_down)\r\n\r\npath_over = 'https://github.com/dhimmel/lincs/raw/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/signif/dysreg-overexpression.tsv'\r\nover_df = readr::read_tsv(path_over)\r\n```\r\n\r\n## Question 7- Emmalyn Chen \r\n\r\n```r\r\nq.7 = over_df %>% subset(z_score < 0) %>% group_by(entrez_gene_id) %>% summarize(count=n()) %>% arrange(-count)\r\nq.7 = q.7[1:10,]\r\n```\r\na. Which ten genes were most frequently significantly downregulated by gene overexpression? \r\n```\r\nentrez_gene_id count\r\n            (int) (int)\r\n1            6192   166\r\n2             991   165\r\n3            5111   165\r\n4            5018   122\r\n5             994   105\r\n6           26520   102\r\n7            1738    91\r\n8            9133    86\r\n9            7298    84\r\n10          22827    83\r\n\r\n```\r\nb. How many overexpressions significantly downregulated these genes?\r\n\r\n```r\r\nq.7.2 = over_df %>% subset(z_score < 0) %>% filter(entrez_gene_id %in% q.7$entrez_gene_id) %>% \r\n  group_by(perturbagen) %>% summarize(count = n())\r\n```\r\n612 overexpressed genes \r\n\r\nc. How many overexpressions significantly upregulated these genes?\r\n\r\n```r\r\nq.7.3 = over_df %>% subset(z_score > 0) %>% filter(entrez_gene_id %in% q.7$entrez_gene_id) %>% \r\n  group_by(perturbagen) %>% summarize(count = n())\r\n```\r\n4 overexpressed genes\r\n\r\n## Question 8 - Liz Levy \r\n\r\n```r\r\nq.8 = over_df %>% subset(z_score > 0) %>% group_by(entrez_gene_id) %>% summarize(count=n()) %>% arrange(-count)\r\nq.8 = q.8[1:10,]\r\n``` \r\na. Which ten genes were most frequently significantly upregulated by gene overexpression? \r\n``` \r\nentrez_gene_id count\r\n            (int) (int)\r\n1           57192   180\r\n2            5331   152\r\n3           25966   140\r\n4           23378   113\r\n5            4118   104\r\n6            9903    99\r\n7           55008    98\r\n8            1066    96\r\n9            5971    94\r\n10           7503    94\r\n```\r\nb. How many overexpressions significantly upregulated these genes?\r\n```r\r\nq.8.2 = over_df %>% subset(z_score > 0) %>% filter(entrez_gene_id %in% q.8$entrez_gene_id) %>% \r\n  group_by(perturbagen) %>% summarize(count = n())\r\n```\r\n792 overexpressed genes  \r\n\r\nc. How many overexpressions significantly downregulated these genes?\r\n```r\r\nq.8.3 = over_df %>% subset(z_score < 0) %>% filter(entrez_gene_id %in% q.8$entrez_gene_id) %>% \r\n  group_by(perturbagen) %>% summarize(count = n())\r\n```\r\n14 overexpressed genes \r\n\r\n## Question 9 - Marjorie Imperial \r\n\r\nFor knockdown perturbations, what is the correlation between number of significantly down and upregulated measured genes.\r\n```r\r\nq.9.down.reg = down_df %>% subset(z_score < 0) %>% group_by(perturbagen) %>% summarize(count.down.reg = n())\r\nq.9.up.reg = down_df %>% subset(z_score > 0) %>% group_by(perturbagen) %>% summarize(count.up.reg = n())\r\n\r\njoined_df = dplyr::full_join(q.9.down.reg, q.9.up.reg)\r\njoined_df[is.na(joined_df)] = 0\r\n```\r\nPearson correlation, R =0.9371317\r\n```r\r\ncor(joined_df$count.down.reg, joined_df$count.up.reg)\r\n```\r\nKendall correlation R = 0.732456 \r\n``` r\r\ncor(joined_df$count.down.reg, joined_df$count.up.reg, method = 'kendall')\r\n```",
      "comment_id": 1161,
      "profile_id": 209,
      "published": "2016-03-09T00:35:44.397866Z",
      "thread_id": 181,
      "url": "/discussion/workshop-to-analyze-lincs-data-for-the-systems-pharmacology-course-at-ucsf/181#9"
    },
    {
      "body_html": "<p>See Question 7 above. </p>",
      "body_md": "See Question 7 above.",
      "comment_id": 1162,
      "profile_id": 210,
      "published": "2016-03-09T00:36:44.588057Z",
      "thread_id": 181,
      "url": "/discussion/workshop-to-analyze-lincs-data-for-the-systems-pharmacology-course-at-ucsf/181#10"
    },
    {
      "body_html": "<h1>Question 4</h1>\r\n\r\n<blockquote><p>How many genes were never significantly dysregulated by any knockdown perturbation? </p></blockquote>\r\n\r\n<pre><code class=\"r\">library(dplyr)\r\ninstall.packages(\"tidyr\")\r\nlibrary(readr)\r\nlibrary(ggplot2)\r\n\r\npath = 'https://github.com/dhimmel/lincs/raw/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/genes.tsv'\r\npath_ko = 'https://github.com/dhimmel/lincs/raw/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/signif/dysreg-knockdown.tsv'\r\ngene_df = readr::read_tsv(path)\r\ngene_ko_df = readr::read_tsv(path_ko)\r\n\r\nghost_df = gene_df[! (gene_df$entrez_gene_id %in% gene_ko_df$entrez_gene_id), ]\r\nnrow(ghost_df)\r\n\r\n#for a list of these genes\r\nghost_df$symbol</code></pre>\r\n\r\n<p>The number of genes that were not sig dysregulated by knockdown perturbation (on main list of genes, but not on knockdown list of genes) = 56!</p>",
      "body_md": "# Question 4\r\n\r\n> How many genes were never significantly dysregulated by any knockdown perturbation? \r\n\r\n```r\r\nlibrary(dplyr)\r\ninstall.packages(\"tidyr\")\r\nlibrary(readr)\r\nlibrary(ggplot2)\r\n\r\npath = 'https://github.com/dhimmel/lincs/raw/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/genes.tsv'\r\npath_ko = 'https://github.com/dhimmel/lincs/raw/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/signif/dysreg-knockdown.tsv'\r\ngene_df = readr::read_tsv(path)\r\ngene_ko_df = readr::read_tsv(path_ko)\r\n\r\nghost_df = gene_df[! (gene_df$entrez_gene_id %in% gene_ko_df$entrez_gene_id), ]\r\nnrow(ghost_df)\r\n\r\n#for a list of these genes\r\nghost_df$symbol\r\n```\r\n\r\nThe number of genes that were not sig dysregulated by knockdown perturbation (on main list of genes, but not on knockdown list of genes) = 56!",
      "comment_id": 1163,
      "profile_id": 211,
      "published": "2016-03-09T00:38:17.837026Z",
      "thread_id": 181,
      "url": "/discussion/workshop-to-analyze-lincs-data-for-the-systems-pharmacology-course-at-ucsf/181#11"
    },
    {
      "body_html": "<p>See question 8 above.</p>",
      "body_md": "See question 8 above.",
      "comment_id": 1164,
      "profile_id": 213,
      "published": "2016-03-09T01:40:45.660945Z",
      "thread_id": 181,
      "url": "/discussion/workshop-to-analyze-lincs-data-for-the-systems-pharmacology-course-at-ucsf/181#12"
    },
    {
      "body_html": "<h1>Closing remarks</h1>\r\n\r\n<p>Impressive work!</p>\r\n\r\n<p>Each of the nine pupils in attendance answered their question. Most finished within two hours — despite several having little R experience — after an initial 30 minute tutorial. The workshop succeeded at introducing a broad range of topics: R, the hadleyverse, transcriptomics, LINCS L1000, markdown, <em>Thinklab</em>, and open science.</p>\r\n\r\n<p>I enjoyed helping the pupils learn while they performed original and noteworthy analyses. And meanwhile, through the power of realtime open science on <em>Thinklab</em>, we're now coauthors on a citeable work <span class=\"citation\">[<a href=\"/discussion/workshop-to-analyze-lincs-data-for-the-systems-pharmacology-course-at-ucsf/181\" class=\"citation\" data-key=\"10.15363/thinklab.d181\">1</a>]</span>.</p>\r\n\r\n<p>The workshop built off of many developments in scientific education: specifically, solving problems <span class=\"citation\">[<a href=\"https://doi.org/10.1038/523272a\" class=\"citation\" data-key=\"10.1038/523272a\">2</a>]</span> in contemporary research <span class=\"citation\">[<a href=\"https://doi.org/10.1126/science.1216570\" class=\"citation\" data-key=\"10.1126/science.1216570\">3</a>]</span> while contributing to the scientific record <span class=\"citation\">[<a href=\"https://doi.org/10.1038/521263f\" class=\"citation\" data-key=\"10.1038/521263f\">4</a>]</span>.</p>\r\n\r\n<p>Next, I'll review the answers to see what we have learned.</p>",
      "body_md": "# Closing remarks\r\n\r\nImpressive work!\r\n\r\nEach of the nine pupils in attendance answered their question. Most finished within two hours -- despite several having little R experience -- after an initial 30 minute tutorial. The workshop succeeded at introducing a broad range of topics: R, the hadleyverse, transcriptomics, LINCS L1000, markdown, _Thinklab_, and open science.\r\n\r\nI enjoyed helping the pupils learn while they performed original and noteworthy analyses. And meanwhile, through the power of realtime open science on _Thinklab_, we're now coauthors on a citeable work [@10.15363/thinklab.d181].\r\n\r\nThe workshop built off of many developments in scientific education: specifically, solving problems [@10.1038/523272a] in contemporary research [@10.1126/science.1216570] while contributing to the scientific record [@10.1038/521263f].\r\n\r\nNext, I'll review the answers to see what we have learned.",
      "comment_id": 1165,
      "profile_id": 17,
      "published": "2016-03-09T03:23:31.969515Z",
      "thread_id": 181,
      "url": "/discussion/workshop-to-analyze-lincs-data-for-the-systems-pharmacology-course-at-ucsf/181#13"
    },
    {
      "body_html": "<h1>Workshop conclusions</h1>\r\n\r\n<p>Here's my analysis of the answers from today's workshop. Thanks again to the pupils for their hard work.</p>\r\n\r\n<h3>Do target genes of genetic perturbation respond in the expected direction?</h3>\r\n\r\n<p>Yes, we established this important control. Knockdown overwhelming downregulated (806 instances) rather than upregulated (9 instances) its target gene (<a href=\"#6\">Q1</a> by <a href=\"/u/jeffreykim\" class=\"username\">@jeffreykim</a>). Overexpression overwhelming upregulated (124 instances) rather than downregulated (4 instances) its target gene (<a href=\"#4\">Q2</a> by <a href=\"/u/kathleenk\" class=\"username\">@kathleenk</a>).</p>\r\n\r\n<h3>Are the many genes that never respond to genetic perturbation?</h3>\r\n\r\n<p>No, we saw that almost all genes were dysregulated by at least one genetic perturbation. Only 0.7% of genes (56 out of 7,467) were never dysregulated by a knockdown (<a href=\"#11\">Q4</a> by <a href=\"/u/jasleensodhi\" class=\"username\">@jasleensodhi</a>). Only 1 of these genes was measured, while the remaining 55 were imputed (<a href=\"#5\">Q3</a> by <a href=\"/u/mishavysotskiy\" class=\"username\">@mishavysotskiy</a>). This imbalance makes sense since imputed genes were <a href=\"http://thinklab.com/discussion/computing-consensus-transcriptional-profiles-for-lincs-l1000-perturbations/43#70\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d43\">subject to</a> a more stringent significance threshold. The low number of never-dysregulated genes is a welcome result from a network perspective, where pervasive connectivity is important.</p>\r\n\r\n<h3>Which genes are most frequently dysregulated?</h3>\r\n\r\n<p>Next, we identified which genes were most frequently dysregulated due to a knockdown. <em>RPS4Y1</em> was downregulated by 37.8% (1,637 out of 4,326) of knockdowns (<a href=\"#8\">Q5</a> by <a href=\"/u/juliacluceru\" class=\"username\">@juliacluceru</a>). <em>MCOLN1</em> was upregulated by 26.1% (1,128 out of 4,326) of knockdowns (<a href=\"#7\">Q6</a> by <a href=\"/u/beaunorgeot\" class=\"username\">@beaunorgeot</a>). The top-ten-most-frequently-downregulated-by-knockdown genes were rarely upregulated by knockdown. The same consistency in direction of dysregulation applied to the top-ten-most-frequently-upregulated genes as well.</p>\r\n\r\n<p>Next, we identified which genes were most frequently dysregulated due to overexpression. <em>RPS4Y1</em> was downregulated by 6.9% (166 out of 2,413) of overepressions (<a href=\"#12\">Q7</a> by <a href=\"/u/emmalynchen\" class=\"username\">@emmalynchen</a>). <em>MCOLN1</em> was upregulated by 7.5% (180 out of 2,413) of overepressions (<a href=\"#12\">Q8</a> by <a href=\"/u/elizabethlevy1\" class=\"username\">@elizabethlevy1</a>). Interestingly, <em>RPS4Y1</em> was the most downregulated gene by both knockdown and overexpression. Conversely, <em>MCOLN1</em> was the most upregulated gene for both perturbation types.</p>\r\n\r\n<p>The findings from Q5–8 fit with <a href=\"/u/larsjuhljensen\" class=\"username\">@larsjuhljensen</a>'s <a href=\"http://thinklab.com/discussion/positive-correlations-between-knockdown-and-overexpression-profiles-from-lincs-l1000/171#3\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d171\">hypothesis</a> that a general stress response may cause many genes to respond to any genetic perturbation in a consistent direction. Q5–8 also help address <a href=\"/u/caseygreene\" class=\"username\">@caseygreene</a>'s question on <a href=\"http://thinklab.com/discussion/positive-correlations-between-knockdown-and-overexpression-profiles-from-lincs-l1000/171#2\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d171\">which genes</a> are driving the signals.</p>\r\n\r\n<h3>Does broad downregulation occur in tandem with broad upregulation?</h3>\r\n\r\n<p>Finally, there was a strong correlation between the number of downregulated and upregulated genes per knockdown (<a href=\"#12\">Q9</a> by <a href=\"/u/marjorieimperial\" class=\"username\">@marjorieimperial</a>). In other words, a perturbation which downregulates many genes will also likely upregulate many genes.</p>",
      "body_md": "# Workshop conclusions\r\n\r\nHere's my analysis of the answers from today's workshop. Thanks again to the pupils for their hard work.\r\n\r\n### Do target genes of genetic perturbation respond in the expected direction?\r\n\r\nYes, we established this important control. Knockdown overwhelming downregulated (806 instances) rather than upregulated (9 instances) its target gene ([Q1](#6) by @jeffreykim). Overexpression overwhelming upregulated (124 instances) rather than downregulated (4 instances) its target gene ([Q2](#4) by @kathleenk).\r\n\r\n### Are the many genes that never respond to genetic perturbation?\r\n\r\nNo, we saw that almost all genes were dysregulated by at least one genetic perturbation. Only 0.7% of genes (56 out of 7,467) were never dysregulated by a knockdown ([Q4](#11) by @jasleensodhi). Only 1 of these genes was measured, while the remaining 55 were imputed ([Q3](#5) by @mishavysotskiy). This imbalance makes sense since imputed genes were [subject to](http://thinklab.com/discussion/computing-consensus-transcriptional-profiles-for-lincs-l1000-perturbations/43#70) a more stringent significance threshold. The low number of never-dysregulated genes is a welcome result from a network perspective, where pervasive connectivity is important.\r\n\r\n### Which genes are most frequently dysregulated?\r\n\r\nNext, we identified which genes were most frequently dysregulated due to a knockdown. _RPS4Y1_ was downregulated by 37.8% (1,637 out of 4,326) of knockdowns ([Q5](#8) by @juliacluceru). _MCOLN1_ was upregulated by 26.1% (1,128 out of 4,326) of knockdowns ([Q6](#7) by @beaunorgeot). The top-ten-most-frequently-downregulated-by-knockdown genes were rarely upregulated by knockdown. The same consistency in direction of dysregulation applied to the top-ten-most-frequently-upregulated genes as well.\r\n\r\nNext, we identified which genes were most frequently dysregulated due to overexpression. _RPS4Y1_ was downregulated by 6.9% (166 out of 2,413) of overepressions ([Q7](#12) by @emmalynchen). _MCOLN1_ was upregulated by 7.5% (180 out of 2,413) of overepressions ([Q8](#12) by @elizabethlevy1). Interestingly, _RPS4Y1_ was the most downregulated gene by both knockdown and overexpression. Conversely, _MCOLN1_ was the most upregulated gene for both perturbation types.\r\n\r\nThe findings from Q5--8 fit with @larsjuhljensen's [hypothesis](http://thinklab.com/discussion/positive-correlations-between-knockdown-and-overexpression-profiles-from-lincs-l1000/171#3) that a general stress response may cause many genes to respond to any genetic perturbation in a consistent direction. Q5--8 also help address @caseygreene's question on [which genes](http://thinklab.com/discussion/positive-correlations-between-knockdown-and-overexpression-profiles-from-lincs-l1000/171#2) are driving the signals.\r\n\r\n### Does broad downregulation occur in tandem with broad upregulation?\r\n\r\nFinally, there was a strong correlation between the number of downregulated and upregulated genes per knockdown ([Q9](#12) by @marjorieimperial). In other words, a perturbation which downregulates many genes will also likely upregulate many genes.",
      "comment_id": 1166,
      "profile_id": 17,
      "published": "2016-03-09T04:48:50.298369Z",
      "thread_id": 181,
      "url": "/discussion/workshop-to-analyze-lincs-data-for-the-systems-pharmacology-course-at-ucsf/181#14"
    },
    {
      "body_html": "<h1>Update with workshop findings</h1>\r\n\r\n<p>I recently led a Systems Pharmacology workshop for first-year graduate students. <a href=\"http://thinklab.com/discussion/workshop-to-analyze-lincs-data-for-the-systems-pharmacology-course-at-ucsf/181\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d181\">We analyzed</a> the L1000 genetic perturbation data with the goal of shedding light on the issues in this discussion. The workshop was based on significant dysregulation due to knockdown or overexpression from <a href=\"http://thinklab.com/discussion/computing-consensus-transcriptional-profiles-for-lincs-l1000-perturbations/43#7\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d43\"><code>dhimmel/lincs v2.0</code></a> <span class=\"citation\">[<a href=\"https://doi.org/10.5281/zenodo.47223\" class=\"citation\" data-key=\"10.5281/zenodo.47223\">1</a>, <a href=\"https://doi.org/10.6084/m9.figshare.3085426\" class=\"citation\" data-key=\"10.6084/m9.figshare.3085426\">2</a>]</span>. Compared to <code>v1.0</code> (what the <a href=\"#1\">leadoff post</a> was based on), <code>v2.0</code> adds dysregulation scores for imputed genes.</p>\r\n\r\n<p>See the <a href=\"http://thinklab.com/discussion/workshop-to-analyze-lincs-data-for-the-systems-pharmacology-course-at-ucsf/181#14\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d181\">summary of our findings</a>. In short, certain genes responded in the same direction to a large number of perturbations. For example, <em>RPS4Y1</em> was frequently downregulated and <em>MCOLN1</em> was frequently upregulated, regardless of which gene was perturbed in which direction.</p>\r\n\r\n<p><a href=\"/u/larsjuhljensen\" class=\"username\">@larsjuhljensen</a> noted:</p>\r\n\r\n<blockquote><p>Reassuring to see that things behave the way I would expect. This should make it fairly easy to derive a scoring scheme that extracts only associations that are specifically associated with a small number of perturbations, as opposed to associated with any perturbation.</p></blockquote>\r\n\r\n<p>I think Lars makes a great suggestion, worthy of investigation. However, due to time constraints, we will have to postpone this analysis for a future undertaking.</p>\r\n\r\n<h1>Proposed quick fix</h1>\r\n\r\n<p>Currently, I'm leaning towards collapsing all four types of regulation into a single relationship type (<em>Gene → regulates → Gene</em>), which means perturbation of the source gene significantly dysregulated the target gene. In other words, we'll take the union of the four <a href=\"#1\">aforementioned</a> regulation relationships.</p>\r\n\r\n<p>Our <em>DWPC</em> method for quantifying the connectivity between two nodes downweights paths through high degree nodes <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1004259\">3</a>]</span>. Thus the pervasively dysregulated genes should not be too problematic.</p>",
      "body_md": "# Update with workshop findings\r\n\r\nI recently led a Systems Pharmacology workshop for first-year graduate students. [We analyzed](http://thinklab.com/discussion/workshop-to-analyze-lincs-data-for-the-systems-pharmacology-course-at-ucsf/181) the L1000 genetic perturbation data with the goal of shedding light on the issues in this discussion. The workshop was based on significant dysregulation due to knockdown or overexpression from [`dhimmel/lincs v2.0`](http://thinklab.com/discussion/computing-consensus-transcriptional-profiles-for-lincs-l1000-perturbations/43#7) [@10.5281/zenodo.47223 @10.6084/m9.figshare.3085426]. Compared to `v1.0` (what the [leadoff post](#1) was based on), `v2.0` adds dysregulation scores for imputed genes.\r\n\r\nSee the [summary of our findings](http://thinklab.com/discussion/workshop-to-analyze-lincs-data-for-the-systems-pharmacology-course-at-ucsf/181#14). In short, certain genes responded in the same direction to a large number of perturbations. For example, _RPS4Y1_ was frequently downregulated and _MCOLN1_ was frequently upregulated, regardless of which gene was perturbed in which direction.\r\n\r\n@larsjuhljensen noted:\r\n\r\n> Reassuring to see that things behave the way I would expect. This should make it fairly easy to derive a scoring scheme that extracts only associations that are specifically associated with a small number of perturbations, as opposed to associated with any perturbation.\r\n\r\nI think Lars makes a great suggestion, worthy of investigation. However, due to time constraints, we will have to postpone this analysis for a future undertaking.\r\n\r\n# Proposed quick fix \r\n\r\nCurrently, I'm leaning towards collapsing all four types of regulation into a single relationship type (_Gene → regulates → Gene_), which means perturbation of the source gene significantly dysregulated the target gene. In other words, we'll take the union of the four [aforementioned](#1) regulation relationships.\r\n\r\nOur _DWPC_ method for quantifying the connectivity between two nodes downweights paths through high degree nodes [@10.1371/journal.pcbi.1004259]. Thus the pervasively dysregulated genes should not be too problematic.",
      "comment_id": 1167,
      "profile_id": 17,
      "published": "2016-03-09T18:23:08.023532Z",
      "thread_id": 171,
      "url": "/discussion/positive-correlations-between-knockdown-and-overexpression-profiles-from-lincs-l1000/171#5"
    },
    {
      "body_html": "<p>Time is short to finalize our indication catalog by consensus.</p>\r\n\r\n<p><a href=\"/u/pouyakhankhanian\" class=\"username\">@pouyakhankhanian</a>, are any changes needed to your original classifications to reach a consensus with <a href=\"/u/chrissyhessler\" class=\"username\">@chrissyhessler</a> regarding epilepsy and migraine indications?</p>\r\n\r\n<p><a href=\"/u/pouyakhankhanian\" class=\"username\">@pouyakhankhanian</a>, how many indications are subject to what we decide for autoimmune diseases and steroids? I agree this is a tough call. In practice, steroids are <a href=\"http://www.nationalmssociety.org/For-Professionals/Clinical-Care/Managing-MS/Disease-Modification\" title=\"Disease Modification · National MS Society\">not referred to</a> as disease modifying for multiple sclerosis. However, I'm not convinced there is a logic to this omission that could be consistently applied to other diseases. Thoughts?</p>\r\n\r\n<p>We do want our catalog to be broadly applicable to projects beyond our specific study. In other words, we want the catalog to be generally useful to train and test computational approaches without too many disputable calls. </p>\r\n\r\n<blockquote><p>One clarification: is a drug still considered disease modifying if there are significant and dangerous side effects?</p></blockquote>\r\n\r\n<p>My take here is yes as long as the drug has been indicated in a disease-modifying capacity in some context. The context may be the time before the dangerous side effects were fully appreciated or the time before better tolerated therapies came to market.</p>",
      "body_md": "Time is short to finalize our indication catalog by consensus.\r\n\r\n@pouyakhankhanian, are any changes needed to your original classifications to reach a consensus with @chrissyhessler regarding epilepsy and migraine indications?\r\n\r\n@pouyakhankhanian, how many indications are subject to what we decide for autoimmune diseases and steroids? I agree this is a tough call. In practice, steroids are [not referred to](http://www.nationalmssociety.org/For-Professionals/Clinical-Care/Managing-MS/Disease-Modification \"Disease Modification · National MS Society\") as disease modifying for multiple sclerosis. However, I'm not convinced there is a logic to this omission that could be consistently applied to other diseases. Thoughts?\r\n\r\nWe do want our catalog to be broadly applicable to projects beyond our specific study. In other words, we want the catalog to be generally useful to train and test computational approaches without too many disputable calls. \r\n\r\n> One clarification: is a drug still considered disease modifying if there are significant and dangerous side effects?\r\n\r\nMy take here is yes as long as the drug has been indicated in a disease-modifying capacity in some context. The context may be the time before the dangerous side effects were fully appreciated or the time before better tolerated therapies came to market.",
      "comment_id": 1168,
      "profile_id": 17,
      "published": "2016-03-09T20:45:38.038438Z",
      "thread_id": 95,
      "url": "/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95#13"
    },
    {
      "body_html": "<ul><li><p><strong>Re: migraines and epilepsy.</strong>  No changes need to be made to the spreadsheet, the proposed classification presented by CSH matches what I chose.</p></li><li><p><strong>Re: steroids and auto-immune diseases.</strong> There are about 70 steroid-autoimmune connections that would need to be subject to this decision. I think there are about 20 which are Rheumatoid Arthritis and Lupus, which I think are safely DM. That leaves another 50 which would have to be re-evaluated based on the decision. For the case of multiple sclerosis, I still tend to favor calling steroids DM for a few reasons. First, let's consider an easy (but  rare) example. Suppose a patient comes in with painful trigeminal neuralgia due to an active demyelinating lesion. One would give this patient steroids. The steroids would decrease active inflammation and demyelination, thereby decreasing the duration of time of the symptom of pain. The steroid does not actually treat the pain directly (like a \"pain-killer\"), but it treats the biology behind the pain. While it is true that the steroid does not slow the progression from RRMS to SPMS, nor does it prevent future attacks (hence it is not called \"DM\" in the clinic), it does affect the biology of the current attack. Next, let's consdier a more complex (but more common) example. Suppose a patient comes in with leg weakness making her unable to walk, due to an active demyelinating lesion. One would give this patient steroids. The steroids would decrease active inflammation and demyelination, thereby decreasing the duration of time of the symptom of weakness. The steroid does not directly treat weakness (like a drug like Ampyra might do). Again, while it is true that the steroid does not slow the progression from RRMS to SPMS, nor does it prevent future attacks (hence it is not called \"DM\" in the clinic), it does affect the biology of the current attack. Finally, let's consider <a href=\"http://journals.lww.com/neurotodayonline/Fulltext/2009/07020/Monthly_Steroid_Pulses_Cut_MS_Relapses_38_Percent.12.aspx\" title=\"Neurology Green journal\">this article</a>. In that article, they give monthly steroids and in order to prevent future attacks. They find that the number of future attacks is decreased (though it is likely not a large enough effect to justify the use of chronic steroids long-term given all the side effects that go along with chronic steroid use). Decreasing the number of attacks is exactly what defines nearly all of the drugs typically which are <a href=\"http://www.nationalmssociety.org/For-Professionals/Clinical-Care/Managing-MS/Disease-Modification\" title=\"National MS Society definition of DM\">\"in practice... referred to as disease modifying\"</a> (most of these drugs to not prevent progression from RRMS to SPMS). For the three reasons above, I would still tend to favor calling steroids DM in MS. If we choose otherwise, then I think we should use MS as an example to set up a precise definition of what qualifies as disease modifying in auto-immune diseases, and then re-evaluate the other 50 steroid-autoimmune indications based on that definition.</p></li></ul>",
      "body_md": "- **Re: migraines and epilepsy.**  No changes need to be made to the spreadsheet, the proposed classification presented by CSH matches what I chose.\r\n\r\n- **Re: steroids and auto-immune diseases.** There are about 70 steroid-autoimmune connections that would need to be subject to this decision. I think there are about 20 which are Rheumatoid Arthritis and Lupus, which I think are safely DM. That leaves another 50 which would have to be re-evaluated based on the decision. For the case of multiple sclerosis, I still tend to favor calling steroids DM for a few reasons. First, let's consider an easy (but  rare) example. Suppose a patient comes in with painful trigeminal neuralgia due to an active demyelinating lesion. One would give this patient steroids. The steroids would decrease active inflammation and demyelination, thereby decreasing the duration of time of the symptom of pain. The steroid does not actually treat the pain directly (like a \"pain-killer\"), but it treats the biology behind the pain. While it is true that the steroid does not slow the progression from RRMS to SPMS, nor does it prevent future attacks (hence it is not called \"DM\" in the clinic), it does affect the biology of the current attack. Next, let's consdier a more complex (but more common) example. Suppose a patient comes in with leg weakness making her unable to walk, due to an active demyelinating lesion. One would give this patient steroids. The steroids would decrease active inflammation and demyelination, thereby decreasing the duration of time of the symptom of weakness. The steroid does not directly treat weakness (like a drug like Ampyra might do). Again, while it is true that the steroid does not slow the progression from RRMS to SPMS, nor does it prevent future attacks (hence it is not called \"DM\" in the clinic), it does affect the biology of the current attack. Finally, let's consider [this article] (http://journals.lww.com/neurotodayonline/Fulltext/2009/07020/Monthly_Steroid_Pulses_Cut_MS_Relapses_38_Percent.12.aspx \"Neurology Green journal\"). In that article, they give monthly steroids and in order to prevent future attacks. They find that the number of future attacks is decreased (though it is likely not a large enough effect to justify the use of chronic steroids long-term given all the side effects that go along with chronic steroid use). Decreasing the number of attacks is exactly what defines nearly all of the drugs typically which are [\"in practice... referred to as disease modifying\"] (http://www.nationalmssociety.org/For-Professionals/Clinical-Care/Managing-MS/Disease-Modification  \"National MS Society definition of DM\") (most of these drugs to not prevent progression from RRMS to SPMS). For the three reasons above, I would still tend to favor calling steroids DM in MS. If we choose otherwise, then I think we should use MS as an example to set up a precise definition of what qualifies as disease modifying in auto-immune diseases, and then re-evaluate the other 50 steroid-autoimmune indications based on that definition.",
      "comment_id": 1169,
      "profile_id": 188,
      "published": "2016-03-10T08:15:17.165414Z",
      "thread_id": 95,
      "url": "/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95#14"
    },
    {
      "body_html": "<h2>Introducing PharmacotherapyDB</h2>\r\n\r\n<p>I'm excited to announce the initial release of our catalog of drug therapies for disease. The catalog  contains physician curated medical indications. It's available on <a href=\"https://doi.org/10.6084/m9.figshare.3103054\">figshare</a> <span class=\"citation\">[<a href=\"https://doi.org/10.6084/m9.figshare.3103054\" class=\"citation\" data-key=\"10.6084/m9.figshare.3103054\">1</a>]</span> and <a href=\"https://github.com/dhimmel/indications/tree/11d535ba0884ee56c3cd5756fdfb4985f313bd80\" title=\"dhimmel/indications at v1.0\">GitHub</a> <span class=\"citation\">[<a href=\"https://doi.org/10.5281/zenodo.47664\" class=\"citation\" data-key=\"10.5281/zenodo.47664\">2</a>]</span> and licensed to be maximally reusable.</p>\r\n\r\n<p>This initial release contains 97 diseases and 601 drugs. Between these drug–disease pairs, there are 755 disease-modifying therapies, 390 symptomatic therapies, and 243 non-indications. To enable integrative analyses, drugs and diseases are coded using <a href=\"http://www.drugbank.ca/\">DrugBank</a> and <a href=\"http://disease-ontology.org/\">Disease Ontology</a> identifiers.</p>\r\n\r\n<p>The catalog adheres to pathophysiological principals first. Therefore, the catalog includes indications with a poor risk–benefit ratio that are rarely used in the modern clinic. Contributions are welcome as we hope to expand and refine the catalog over time.</p>\r\n\r\n<h2>History &amp; Methods</h2>\r\n\r\n<p>One of our priorities from the beginning of this project was to construct a catalog of efficacious pharmacotherapies. Since our approach learns how to repurpose drugs based on the indications we feed it, a high quality indication catalog was a crucial. </p>\r\n\r\n<h3>Compilation and data integration</h3>\r\n\r\n<p>We began by looking for existing indication resources. In a <a href=\"http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d21\">discussion</a> which generated 23 comments — the most of any Thinklab discussion to date — we received helpful suggestions from the community. Based on these suggestions and our research, we proceeded by integrating four resources:</p>\r\n\r\n<ul><li><strong>MEDI-HPS</strong> <span class=\"citation\">[<a href=\"https://doi.org/10.1136/amiajnl-2012-001431\" class=\"citation\" data-key=\"10.1136/amiajnl-2012-001431\">3</a>]</span> — indications from RxNorm, SIDER 2, MedlinePlus, and Wikipedia (<a href=\"http://thinklab.com/discussion/medi-indications-data-discrepancy-in-resource-specific-counts/31\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d31\">discussed</a>).</li><li><strong>LabeledIn</strong> — indications extracted from drug labels by experts <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.jbi.2014.08.004\" class=\"citation\" data-key=\"10.1016/j.jbi.2014.08.004\">4</a>]</span> and crowdsourced non-experts <span class=\"citation\">[<a href=\"https://doi.org/10.1093/database/bav016\" class=\"citation\" data-key=\"10.1093/database/bav016\">5</a>]</span> (<a href=\"http://thinklab.com/discussion/processing-labeledin-to-extract-indications/46\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d46\">discussed</a>).</li><li><strong>ehrlink</strong> <span class=\"citation\">[<a href=\"https://doi.org/10.1136/amiajnl-2012-000852\" class=\"citation\" data-key=\"10.1136/amiajnl-2012-000852\">6</a>]</span> — indications from electronic health records where physicians linked medications to problems (<a href=\"http://thinklab.com/discussion/extracting-indications-from-the-ehrlink-resource/62\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d62\">discussed</a>).</li><li><strong>PREDICT</strong> <span class=\"citation\">[<a href=\"https://doi.org/10.1038/msb.2011.26\" class=\"citation\" data-key=\"10.1038/msb.2011.26\">7</a>]</span> — indications from UMLS relationships, drugs.com, and drug labels (<a href=\"http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#17\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d21\">discussed</a>).</li></ul>\r\n\r\n<p>We mapped these resources onto our slim sets of <a href=\"http://thinklab.com/discussion/unifying-disease-vocabularies/44#6\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d44\">137 diseases</a> and <a href=\"http://thinklab.com/discussion/unifying-drug-vocabularies/40#5\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d40\">1,552 small molecule compounds</a>. Taking the union of the four resources, <a href=\"http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#21\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d21\">we extracted</a> 1,388 high-confidence indications.</p>\r\n\r\n<h3>Curation and categorization</h3>\r\n\r\n<p>Next, <a href=\"http://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d95\">we decided</a> physician curation was needed to separate disease-modifying from symptomatic indications. We recruited two physician curators (<a href=\"/u/chrissyhessler\" class=\"username\">@chrissyhessler</a> &amp; Ari J. Green) to perform a pilot on 50 random indications. Then together, we defined disease modifying as \"a drug that therapeutically changes the underlying or downstream biology of the disease\" and symptomatic as \"a drug that treats a significant symptom of the disease.\"</p>\r\n\r\n<p>The two curators then each reviewed all 1,388 indications and classified them as disease modifying (<code>DM</code>), symptomatic (<code>SYM</code>), or a non-indication (<code>NOT</code>). The initial two curators <a href=\"http://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95#5\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d95\">disagreed</a> 444 times. We recruited a third curator (<a href=\"/u/pouyakhankhanian\" class=\"username\">@pouyakhankhanian</a>) who had access to the prior curations. The third curator developed a <a href=\"http://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95#7\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d95\">detailed methodology</a> that helped us <a href=\"http://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95#15\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d95\">reach consensus</a> for the time being.</p>\r\n\r\n<h3>Future plans</h3>\r\n\r\n<p>We're receptive to feedback on how to improve PharmacotherapyDB. For future releases, we hope to curate the unpropagated indications, include additional sources, and expand our disease and drug vocabularies.</p>",
      "body_md": "## Introducing PharmacotherapyDB\r\n\r\nI'm excited to announce the initial release of our catalog of drug therapies for disease. The catalog  contains physician curated medical indications. It's available on [figshare](https://doi.org/10.6084/m9.figshare.3103054) [@10.6084/m9.figshare.3103054] and [GitHub](https://github.com/dhimmel/indications/tree/11d535ba0884ee56c3cd5756fdfb4985f313bd80 \"dhimmel/indications at v1.0\") [@10.5281/zenodo.47664] and licensed to be maximally reusable.\r\n\r\nThis initial release contains 97 diseases and 601 drugs. Between these drug–disease pairs, there are 755 disease-modifying therapies, 390 symptomatic therapies, and 243 non-indications. To enable integrative analyses, drugs and diseases are coded using [DrugBank](http://www.drugbank.ca/) and [Disease Ontology](http://disease-ontology.org/) identifiers.\r\n\r\nThe catalog adheres to pathophysiological principals first. Therefore, the catalog includes indications with a poor risk–benefit ratio that are rarely used in the modern clinic. Contributions are welcome as we hope to expand and refine the catalog over time.\r\n\r\n## History & Methods\r\n\r\nOne of our priorities from the beginning of this project was to construct a catalog of efficacious pharmacotherapies. Since our approach learns how to repurpose drugs based on the indications we feed it, a high quality indication catalog was a crucial. \r\n\r\n### Compilation and data integration\r\n\r\nWe began by looking for existing indication resources. In a [discussion](http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21) which generated 23 comments -- the most of any Thinklab discussion to date -- we received helpful suggestions from the community. Based on these suggestions and our research, we proceeded by integrating four resources:\r\n\r\n+ **MEDI-HPS** [@10.1136/amiajnl-2012-001431] -- indications from RxNorm, SIDER 2, MedlinePlus, and Wikipedia ([discussed](http://thinklab.com/discussion/medi-indications-data-discrepancy-in-resource-specific-counts/31)).\r\n+ **LabeledIn** -- indications extracted from drug labels by experts [@10.1016/j.jbi.2014.08.004] and crowdsourced non-experts [@10.1093/database/bav016] ([discussed](http://thinklab.com/discussion/processing-labeledin-to-extract-indications/46)).\r\n+ **ehrlink** [@10.1136/amiajnl-2012-000852] -- indications from electronic health records where physicians linked medications to problems ([discussed](http://thinklab.com/discussion/extracting-indications-from-the-ehrlink-resource/62)).\r\n+ **PREDICT** [@10.1038/msb.2011.26] -- indications from UMLS relationships, drugs.com, and drug labels ([discussed](http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#17)).\r\n\r\nWe mapped these resources onto our slim sets of [137 diseases](http://thinklab.com/discussion/unifying-disease-vocabularies/44#6) and [1,552 small molecule compounds](http://thinklab.com/discussion/unifying-drug-vocabularies/40#5). Taking the union of the four resources, [we extracted](http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#21) 1,388 high-confidence indications.\r\n\r\n### Curation and categorization\r\n\r\nNext, [we decided](http://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95) physician curation was needed to separate disease-modifying from symptomatic indications. We recruited two physician curators (@chrissyhessler & Ari J. Green) to perform a pilot on 50 random indications. Then together, we defined disease modifying as \"a drug that therapeutically changes the underlying or downstream biology of the disease\" and symptomatic as \"a drug that treats a significant symptom of the disease.\"\r\n\r\nThe two curators then each reviewed all 1,388 indications and classified them as disease modifying (`DM`), symptomatic (`SYM`), or a non-indication (`NOT`). The initial two curators [disagreed](http://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95#5) 444 times. We recruited a third curator (@pouyakhankhanian) who had access to the prior curations. The third curator developed a [detailed methodology](http://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95#7) that helped us [reach consensus](http://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95#15) for the time being.\r\n\r\n### Future plans\r\n\r\nWe're receptive to feedback on how to improve PharmacotherapyDB. For future releases, we hope to curate the unpropagated indications, include additional sources, and expand our disease and drug vocabularies.",
      "comment_id": 1170,
      "profile_id": 17,
      "published": "2016-03-15T05:24:35.132602Z",
      "thread_id": 182,
      "url": "/discussion/announcing-pharmacotherapydb-the-open-catalog-of-drug-therapies-for-disease/182"
    },
    {
      "body_html": "<h1>Announcing the consensus curation</h1>\r\n\r\n<p>In the interest of time, we are finalizing the consensus curation now. We have chosen the <a href=\"#7\">PK curation</a> as the consensus. Discussion is still welcome and will be helpful for future incarnations of our catalog.</p>\r\n\r\n<h2>Resolving steroids for autoimmune disease</h2>\r\n\r\n<p>Both original curators were given a change to respond to the PK curation and methodology. In CSH's <a href=\"#11\">response</a> and offline discussion with AJG, questions were raised regarding calling steroids DM for autoimmune diseases. Further discussion with PK, both above and offline, helped clarify the issue and convinced <a href=\"/u/sergiobaranzini\" class=\"username\">@sergiobaranzini</a> and I that the DM classification was appropriate.</p>\r\n\r\n<p>According to PK, steroids are not considered DM in the clinic because their poor risk–benefit ratios generally preclude longterm use. Clinicians interpret \"disease modifying\" to mean a therapy for changing the longterm disease course and therefore do not consider steroids, which are usually given for only a short period of time, disease modifying. However, our definition of DM does not require longterm modification. Nevertheless, PK points to some evidence <span class=\"citation\">[<a href=\"https://doi.org/10.1097/01.NT.0000357562.58878.0a\" class=\"citation\" data-key=\"10.1097/01.NT.0000357562.58878.0a\">1</a>, <a href=\"https://doi.org/10.1212/wnl.57.7.1239\" class=\"citation\" data-key=\"10.1212/wnl.57.7.1239\">2</a>]</span> that steroids do modify the longterm disease course when administered over a prolonged period.</p>\r\n\r\n<p>While a clinician's decision to prescribe a steroid for an autoimmune disease is motivated by reducing symptoms, PK believes the steroid reduces symptoms by modifying the underlying disease biology. In his opinion, steroids lead to a short-term suppression of the underlying biology — in the case of autoimmune disease, the overactive immune response — leading to a short-term improvement in symptoms. One litmus test is that while a steroid may be prescribed to treat a specific symptom of a multiple sclerosis relapse, the steroid would not treat the symptom in the absence of MS.</p>\r\n\r\n<p>In conclusion, we are conformable with the decision that steroids modify autoimmune disease rather than treat their symptoms according to our <a href=\"#7\">definition</a>. However, it's important to clarify that our indication catalog is designed primarily from a perspective of pathophysiology rather than clinical best practice.</p>",
      "body_md": "# Announcing the consensus curation\r\n\r\nIn the interest of time, we are finalizing the consensus curation now. We have chosen the [PK curation](#7) as the consensus. Discussion is still welcome and will be helpful for future incarnations of our catalog.\r\n\r\n## Resolving steroids for autoimmune disease\r\n\r\nBoth original curators were given a change to respond to the PK curation and methodology. In CSH's [response](#11) and offline discussion with AJG, questions were raised regarding calling steroids DM for autoimmune diseases. Further discussion with PK, both above and offline, helped clarify the issue and convinced @sergiobaranzini and I that the DM classification was appropriate.\r\n\r\nAccording to PK, steroids are not considered DM in the clinic because their poor risk–benefit ratios generally preclude longterm use. Clinicians interpret \"disease modifying\" to mean a therapy for changing the longterm disease course and therefore do not consider steroids, which are usually given for only a short period of time, disease modifying. However, our definition of DM does not require longterm modification. Nevertheless, PK points to some evidence [@10.1097/01.NT.0000357562.58878.0a @10.1212/wnl.57.7.1239] that steroids do modify the longterm disease course when administered over a prolonged period.\r\n\r\nWhile a clinician's decision to prescribe a steroid for an autoimmune disease is motivated by reducing symptoms, PK believes the steroid reduces symptoms by modifying the underlying disease biology. In his opinion, steroids lead to a short-term suppression of the underlying biology -- in the case of autoimmune disease, the overactive immune response -- leading to a short-term improvement in symptoms. One litmus test is that while a steroid may be prescribed to treat a specific symptom of a multiple sclerosis relapse, the steroid would not treat the symptom in the absence of MS.\r\n\r\nIn conclusion, we are conformable with the decision that steroids modify autoimmune disease rather than treat their symptoms according to our [definition](#7). However, it's important to clarify that our indication catalog is designed primarily from a perspective of pathophysiology rather than clinical best practice.",
      "comment_id": 1171,
      "profile_id": 17,
      "published": "2016-03-12T20:24:37.834807Z",
      "thread_id": 95,
      "url": "/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95#15"
    },
    {
      "body_html": "<h1>Improved randomization of expression edges</h1>\r\n\r\n<p>We <a href=\"http://thinklab.com/discussion/processing-bgee-for-tissue-specific-gene-presence-and-overunder-expression/124#6\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d124\">updated our method</a> for extracting <em>Anatomy–expresses–Gene</em> relationships from Bgee. This update <a href=\"https://github.com/dhimmel/integrate/commit/d68b823bf2167e7ab7f0e784d1280200c33fb3bf#diff-c849eed0ccfe917ca2fceb4f57045444R3\">reduced the number</a> of expression edges in our hetnet from 1,006,278 to 526,407. The number of genes with an expression edge went from 18,147 to 18,094. The number of anatomies with an expression edge went from 256 to 241.</p>\r\n\r\n<p>The permutation of expression edges increased in effectiveness. Now ~25% of expression edges (as opposed to ~10% <a href=\"#1\">previously</a>) <a href=\"http://nbviewer.jupyter.org/github/dhimmel/integrate/blob/d68b823bf2167e7ab7f0e784d1280200c33fb3bf/data/permuted/evaluate-permutations.ipynb#How-many-permutations-are-needed-to-randomize-an-edge\">change in</a> a permuted hetnet. And this is in spite of fewer attempted swaps per permutation: I decreased the multiplier from 4 to 3 to reduce runtime.</p>",
      "body_md": "# Improved randomization of expression edges\r\n\r\nWe [updated our method](http://thinklab.com/discussion/processing-bgee-for-tissue-specific-gene-presence-and-overunder-expression/124#6) for extracting _Anatomy–expresses–Gene_ relationships from Bgee. This update [reduced the number](https://github.com/dhimmel/integrate/commit/d68b823bf2167e7ab7f0e784d1280200c33fb3bf#diff-c849eed0ccfe917ca2fceb4f57045444R3) of expression edges in our hetnet from 1,006,278 to 526,407. The number of genes with an expression edge went from 18,147 to 18,094. The number of anatomies with an expression edge went from 256 to 241.\r\n\r\nThe permutation of expression edges increased in effectiveness. Now ~25% of expression edges (as opposed to ~10% [previously](#1)) [change in](http://nbviewer.jupyter.org/github/dhimmel/integrate/blob/d68b823bf2167e7ab7f0e784d1280200c33fb3bf/data/permuted/evaluate-permutations.ipynb#How-many-permutations-are-needed-to-randomize-an-edge) a permuted hetnet. And this is in spite of fewer attempted swaps per permutation: I decreased the multiplier from 4 to 3 to reduce runtime.",
      "comment_id": 1172,
      "profile_id": 17,
      "published": "2016-03-11T17:13:45.157056Z",
      "thread_id": 178,
      "url": "/discussion/assessing-the-effectiveness-of-our-hetnet-permutations/178#2"
    },
    {
      "body_html": "<p>We <a href=\"http://thinklab.com/discussion/computing-consensus-transcriptional-profiles-for-lincs-l1000-perturbations/43#7\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d43\">recently released</a> version 2.0 of our LINCS L1000 analysis <span class=\"citation\">[<a href=\"https://doi.org/10.6084/m9.figshare.3085426\" class=\"citation\" data-key=\"10.6084/m9.figshare.3085426\">1</a>, <a href=\"https://doi.org/10.5281/zenodo.47223\" class=\"citation\" data-key=\"10.5281/zenodo.47223\">2</a>]</span>. This release added dysregulation <em>z</em>-scores for 6,489 imputed genes, in addition to the 978 directly measured genes on the L1000 <a href=\"http://support.lincscloud.org/hc/en-us/articles/202264116-What-are-L1000-probe-pools-\" title=\"What Are L1000 Probe Pools? · LINCS Cloud Support\">epsilon</a> platform. We only added imputed genes that were part of the best inferred gene set (BING, genes <a href=\"http://thinklab.com/discussion/computing-consensus-transcriptional-profiles-for-lincs-l1000-perturbations/43#3\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d43\">supposedly</a> imputed with high quality).</p>\r\n\r\n<p>We've also been <a href=\"http://thinklab.com/discussion/positive-correlations-between-knockdown-and-overexpression-profiles-from-lincs-l1000/171\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d171\">looking into</a> the genetic perturbation data in L1000. Here, we will assess the quality of the Broad's gene imputation using genetic perturbation consensus signatures. Specifically, we'll use whether a genetic perturbation dysregulates its target gene in the correct direction as a quality metric.</p>\r\n\r\n<p>Below we show the distribution of dysregulation <em>z</em>-scores by imputation status and perturbation type (<a href=\"https://github.com/dhimmel/lincs/blob/7f0f937cc3f3346f88a5d18eae8b07c6822ce653/imputation-assess.ipynb\" title=\"imputation-assess.ipynb · dhimmel/lincs · GitHub\">notebook</a>):</p>\r\n\r\n<p><img src=\"https://github.com/dhimmel/lincs/raw/7f0f937cc3f3346f88a5d18eae8b07c6822ce653/viz/self-targeting-perts.png\" alt=\"Violin plots of perturbagen-self z-scores\" title=\"Violin plots of perturbagen-self z-scores\"></p>\r\n\r\n<p>In general, the measured genes responded in the expected direction. For genetic perturbations whose targets were measured, 97% of knockdowns downregulated their targets (negative <em>z</em>-score), and 64% of overexpressions upregulated their targets (positive <em>z</em>-score). Instances where a measured gene responded in the reverse direction could be due to problems with perturbation delivery or <a href=\"http://arxiv.org/abs/1602.06316\" title=\"Model-based clustering with data correction for removing artifacts in gene expression data · Young et al. · arXiv\">expression quantification</a>.</p>\r\n\r\n<p>For genetic perturbations whose targets were imputed, 54% of knockdowns downregulated their targets, and 51% of overexpressions upregulated their targets. Using the success rates of measured genes as a baseline, we're led to conclude that the imputation quality of BING genes is poor.</p>\r\n\r\n<p>If we instead judge the imputation based only significantly dysregulated genes, the results improve. For significant, imputed perturbagen–target pairs, 67% of knockdowns (18 of 24) downregulated their target, while 80% of overexpressions (4 of 5) upregulated their target. Since these sample sizes are small, I'm hesitant to declare that filtering for significant genes is sufficient to overcome the imputation problems.</p>\r\n\r\n<p>For reader reference, recent research <span class=\"citation\">[<a href=\"https://doi.org/10.1093/bioinformatics/btw074\" class=\"citation\" data-key=\"10.1093/bioinformatics/btw074\">3</a>]</span> looked at improved imputation techniques that presumably could be applied to reimpute LINCS L1000 gene expression.</p>",
      "body_md": "We [recently released](http://thinklab.com/discussion/computing-consensus-transcriptional-profiles-for-lincs-l1000-perturbations/43#7) version 2.0 of our LINCS L1000 analysis [@10.6084/m9.figshare.3085426 @10.5281/zenodo.47223]. This release added dysregulation _z_-scores for 6,489 imputed genes, in addition to the 978 directly measured genes on the L1000 [epsilon](http://support.lincscloud.org/hc/en-us/articles/202264116-What-are-L1000-probe-pools- \"What Are L1000 Probe Pools? · LINCS Cloud Support\") platform. We only added imputed genes that were part of the best inferred gene set (BING, genes [supposedly](http://thinklab.com/discussion/computing-consensus-transcriptional-profiles-for-lincs-l1000-perturbations/43#3) imputed with high quality).\r\n\r\nWe've also been [looking into](http://thinklab.com/discussion/positive-correlations-between-knockdown-and-overexpression-profiles-from-lincs-l1000/171) the genetic perturbation data in L1000. Here, we will assess the quality of the Broad's gene imputation using genetic perturbation consensus signatures. Specifically, we'll use whether a genetic perturbation dysregulates its target gene in the correct direction as a quality metric.\r\n\r\nBelow we show the distribution of dysregulation _z_-scores by imputation status and perturbation type ([notebook](https://github.com/dhimmel/lincs/blob/7f0f937cc3f3346f88a5d18eae8b07c6822ce653/imputation-assess.ipynb \"imputation-assess.ipynb · dhimmel/lincs · GitHub\")):\r\n\r\n![Violin plots of perturbagen-self z-scores](https://github.com/dhimmel/lincs/raw/7f0f937cc3f3346f88a5d18eae8b07c6822ce653/viz/self-targeting-perts.png \"Violin plots of perturbagen-self z-scores\")\r\n\r\nIn general, the measured genes responded in the expected direction. For genetic perturbations whose targets were measured, 97% of knockdowns downregulated their targets (negative _z_-score), and 64% of overexpressions upregulated their targets (positive _z_-score). Instances where a measured gene responded in the reverse direction could be due to problems with perturbation delivery or [expression quantification](http://arxiv.org/abs/1602.06316 \"Model-based clustering with data correction for removing artifacts in gene expression data · Young et al. · arXiv\").\r\n\r\nFor genetic perturbations whose targets were imputed, 54% of knockdowns downregulated their targets, and 51% of overexpressions upregulated their targets. Using the success rates of measured genes as a baseline, we're led to conclude that the imputation quality of BING genes is poor.\r\n\r\nIf we instead judge the imputation based only significantly dysregulated genes, the results improve. For significant, imputed perturbagen--target pairs, 67% of knockdowns (18 of 24) downregulated their target, while 80% of overexpressions (4 of 5) upregulated their target. Since these sample sizes are small, I'm hesitant to declare that filtering for significant genes is sufficient to overcome the imputation problems.\r\n\r\nFor reader reference, recent research [@10.1093/bioinformatics/btw074] looked at improved imputation techniques that presumably could be applied to reimpute LINCS L1000 gene expression.",
      "comment_id": 1173,
      "profile_id": 17,
      "published": "2016-03-11T22:41:36.326470Z",
      "thread_id": 185,
      "url": "/discussion/assessing-the-imputation-quality-of-gene-expression-in-lincs-l1000/185"
    },
    {
      "body_html": "<h1>Mention in <em>Storybench</em> piece on BLAZE</h1>\r\n\r\n<p>Margaux Phares wrote an article <a href=\"http://www.storybench.org/science-search-engine-visualizing-discovery-process/\" title=\"How a Science Search Engine Is Visualizing the Discovery Process\">published today on <em>Storybench</em></a> exploring BLAZE. <a href=\"http://openknowledgemaps.org/search/\">BLAZE</a> is a new type of scholarly search engine that returns search results as bubble maps rather than lists. The article quotes me:</p>\r\n\r\n<blockquote><p>“I’ll often work on problems for years before encountering seminal works that would have been helpful from day one,” Himmelstein said. “The [scientific literature search problem] is worst at the cross-section of fields as each field has its own specialized terminology.” He thinks Blaze may help solve this problem.</p></blockquote>\r\n\r\n<p>This quote was motivated by this project: specifically, the difficultly we faced when finding literature on hetnets. As I wrote to Margaux:</p>\r\n\r\n<blockquote><p>I work on networks with multiple types of relationships. I call these networks \"hetnets\". It wasn't until the fifth year of my PhD, that I <a href=\"http://thinklab.com/discussion/renaming-heterogeneous-networks-to-a-more-concise-and-catchy-term/104#6\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d104\">learned of a plethora</a> of other terms referring to the same concept. And had I not been highly proactive at reaching out to diverse players, my ignorance would persist to this day.</p></blockquote>",
      "body_md": "# Mention in _Storybench_ piece on BLAZE\r\n\r\nMargaux Phares wrote an article [published today on _Storybench_](http://www.storybench.org/science-search-engine-visualizing-discovery-process/ \"How a Science Search Engine Is Visualizing the Discovery Process\") exploring BLAZE. [BLAZE](http://openknowledgemaps.org/search/) is a new type of scholarly search engine that returns search results as bubble maps rather than lists. The article quotes me:\r\n\r\n> “I’ll often work on problems for years before encountering seminal works that would have been helpful from day one,” Himmelstein said. “The [scientific literature search problem] is worst at the cross-section of fields as each field has its own specialized terminology.” He thinks Blaze may help solve this problem.\r\n\r\nThis quote was motivated by this project: specifically, the difficultly we faced when finding literature on hetnets. As I wrote to Margaux:\r\n\r\n> I work on networks with multiple types of relationships. I call these networks \"hetnets\". It wasn't until the fifth year of my PhD, that I [learned of a plethora](http://thinklab.com/discussion/renaming-heterogeneous-networks-to-a-more-concise-and-catchy-term/104#6) of other terms referring to the same concept. And had I not been highly proactive at reaching out to diverse players, my ignorance would persist to this day.",
      "comment_id": 1174,
      "profile_id": 17,
      "published": "2016-03-14T18:17:15.121105Z",
      "thread_id": 113,
      "url": "/discussion/tracking-project-reuse-citation-and-publicity/113#5"
    },
    {
      "body_html": "<ul><li><strong>I think this is a valuable data source to maintain.</strong> I understand the need to freeze it at the moment for your analysis. Going forward, I'd love to see a couple additional data sources. One would be uptodate, which would add to the total number of indications (including those where side effects outweight potential benefit) and would give you precise disease-indications for drugs (no need for curation by experts). When thinking about a second data source which may help add to your total number of indications, I might suggest a more clinically relevant source (like medscape). I think your current data-sources are heavy on government approval and, per our discussion earlier, for often politico-economic reasons, drugs may be very commonly used but not had any pharma funding for official approval, and these drugs may not all be caught when surveying pharmacy or doctor's \"indication notes\" as those may lack sensitivity (due to under-reporting of key \"disease\" designations).</li><li><strong>I would keep an eye out for the steroids in auto-immune diseases</strong> Steroid represent a relatively large fraction of the drugs, and auto-immune diseases a reasonable fraction of the total diseases (approximately 5%). I would interpret any results that your algorithm suggests in light of this. For example, I expect this will drive your algorithm into picking things that \"look\" like steroids (in terms of molecular structure, and known targets of possible action). As you know, steroids are molecularly quite similar to each other, and are often associated with the same limited number of key molecular targets. The other immunosuppressive agents (i.e. all the other drugs on your typical clinical list of choices) represent a variety of shapes (molecular structure) and known targets, and may provider richer (but more subtle, and probably lower powered to get a trustworthy result) information, and hopefully provide a more nuanced drug suggestion rather than picking things that \"look\" like steroids (e.g. suggesting a drug that nobody would ever have considered) .</li><li><strong>Consider assigning mechanisms to drugs</strong>. If you note that something richer is to be gained by \"decreasing the gain\" in large drug classes (i.e. the class \"steroids\" includes about 10 drugs in the list), consider using drug classes as an attribute. This will also aid any person who will have to curate the disease-drug connections.</li><li><strong>The few remaining discrepancies, if using my calls as final calls</strong>. After the discussion of the major discrepancies (where multiple discrepant drug-disease connections hinged on a single discussion), there are still minor discrepancies. There appear to be 55 other discrepancies to eventually be evaluated, totaling less than 5 percent of the total number of connections. Given the small number of total calls (less than 5% of total calls) and the large amount of discussion that would be required to solve each one, it makes sense to go forward with a data freeze for your downstream analysis. But I think it would be great to have you at least aware of these, and we can decide what to do on future versions. <br>Of the 55 cases of discrepant calls, there are include 31 cases where my curation changed a previous agreement between the prior 2 curators, and those 24 cases where my curation resulted in a three way tie. <br>— 7 are explained directly by ammendment 1<br>— 14 where I made a call which was explained by a prior call regarding the same disease being connected to another drug within the same drug class<br>— 11 can be encapsulated in a discussion regarding hormone therapy in breast cancer. This is a more complex discussion than that of steroids, because the hormone therapies include \"partial agonists\". <br>— 3 which treated symptom of chemo rather than symptom of disease (therefore changed to NOT)<br>— 3 regarding SSRIs in parkinson's<br>— 17 discrepancies would each require a long discussion (similar to our discussions of diseases earlier). These are briefly denoted below.</li></ul>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>drug</th><th>disease</th><th>CSH</th><th>AJG</th><th>PK</th><th>PK_notes</th></tr></thead><tbody><tr><td>Memantine</td><td>Alzheimer's disease</td><td>SYM</td><td>SYM</td><td>DM</td><td>\"neuroprotective\", doesn't treat any symptom</td></tr><tr><td>Colchicine</td><td>primary biliary cirrhosis</td><td>NOT</td><td>NOT</td><td>DM</td><td>admittedly less evidence, but see <a href=\"http://www.uptodate.com/contents/overview-of-the-treatment-of-primary-biliary-cholangitis-primary-biliary-cirrhosis\">\"uptodate 'Overview of the treatment of primary biliary cholangitis (primary biliary cirrhosis)' \"</a></td></tr><tr><td>Pentoxifylline</td><td>systemic scleroderma</td><td>SYM</td><td>SYM</td><td>DM</td><td>affects the biology of the disease, thereby easing symptoms</td></tr><tr><td>Tretinoin</td><td>peripheral nervous system neoplasm</td><td>NOT</td><td>NOT</td><td>DM</td><td>can treat sarcomas <span class=\"citation\">[<a href=\"https://doi.org/10.1002/14651858.CD003256.pub2\" class=\"citation\" data-key=\"10.1002/14651858.CD003256.pub2\">1</a>]</span> and per amendment 1</td></tr><tr><td>Ursodeoxycholic acid</td><td>primary biliary cirrhosis</td><td>SYM</td><td>SYM</td><td>DM</td><td>doesn't treat any symptom, only modifies disease, see <a href=\"http://www.uptodate.com/contents/overview-of-the-treatment-of-primary-biliary-cholangitis-primary-biliary-cirrhosis\">\"uptodate 'Overview of the treatment of primary biliary cholangitis (primary biliary cirrhosis)' \"</a></td></tr><tr><td>Colchicine</td><td>systemic scleroderma</td><td>NOT</td><td>DM</td><td>SYM</td><td>for arthralgia, not aware of disease modification</td></tr><tr><td>Chenodeoxycholic acid</td><td>primary biliary cirrhosis</td><td>SYM</td><td>NOT</td><td>DM</td><td>in trials, see <a href=\"http://www.uptodate.com/contents/overview-of-the-treatment-of-primary-biliary-cholangitis-primary-biliary-cirrhosis\">\"uptodate 'Overview of the treatment of primary biliary cholangitis (primary biliary cirrhosis)' \"</a></td></tr><tr><td>Dimenhydrinate</td><td>allergic rhinitis</td><td>SYM</td><td>NOT</td><td>DM</td><td>it blocks histamine-H1 just like benadryl. Granted, one would never actually use this in clinic (you would just use benadryl given better efficacy and less side effects), but given the mechanism of action there is reasonable evidence of efficacy</td></tr><tr><td>Dimenhydrinate</td><td>atopic dermatitis</td><td>SYM</td><td>NOT</td><td>DM</td><td>it blocks histamine-H1 just like benadryl. Granted, one would never actually use this in clinic (you would just use benadryl given better efficacy and less side effects), but given the mechanism of action there is reasonable evidence of efficacy</td></tr><tr><td>Sildenafil</td><td>type 1 diabetes mellitus</td><td>NOT</td><td>DM</td><td>SYM</td><td>may be DM for DM2 but not for DM1 <span class=\"citation\">[<a href=\"https://doi.org/10.2337/diacare.26.2.279\" class=\"citation\" data-key=\"10.2337/diacare.26.2.279\">2</a>]</span></td></tr><tr><td>Temozolomide</td><td>skin cancer</td><td>NOT</td><td>NOT</td><td>DM</td><td>melanoma</td></tr><tr><td>Acetylcysteine</td><td>chronic obstructive pulmonary disease</td><td>DM</td><td>DM</td><td>SYM</td><td>mucolytic, does not affect disease biology</td></tr><tr><td>Epoprostenol</td><td>systemic scleroderma</td><td>NOT</td><td>DM</td><td>SYM</td><td>not aware of disease modification, agree with CSH comment re: symptom</td></tr><tr><td>Timolol</td><td>coronary artery disease</td><td>NOT</td><td>SYM</td><td>DM</td><td>per <a href=\"http://www.uptodate.com/contents/timolol-systemic-drug-information?source=search_result&amp;search=timolol&amp;selectedTitle=1~36\">\"uptodate - Timolol Drug info\"</a></td></tr><tr><td></td></tr><tr><td>Finasteride</td><td>prostate cancer</td><td>SYM</td><td>DM</td><td>NOT</td><td>prevents but doesn't treat it. Not sure what the symptomatic thing CSH refers to, does she mean symptoms of BPH? (and if so isn't that a different disease?)</td></tr><tr><td>Digoxin</td><td>dilated cardiomyopathy</td><td>DM</td><td>NOT</td><td>SYM</td><td>see <a href=\"http://www.uptodate.com/contents/overview-of-the-therapy-of-heart-failure-with-reduced-ejection-fraction\">\"uptodate: Overview of the therapy of heart failure with reduced ejection fraction\"</a></td></tr><tr><td>Ergocalciferol</td><td>metabolic syndrome X</td><td>SYM</td><td>DM</td><td>NOT</td><td>would you give this med to anyone who has metabolic syndrome X but does not also have vitamin D deficiency?</td></tr></tbody></table>",
      "body_md": "- **I think this is a valuable data source to maintain.** I understand the need to freeze it at the moment for your analysis. Going forward, I'd love to see a couple additional data sources. One would be uptodate, which would add to the total number of indications (including those where side effects outweight potential benefit) and would give you precise disease-indications for drugs (no need for curation by experts). When thinking about a second data source which may help add to your total number of indications, I might suggest a more clinically relevant source (like medscape). I think your current data-sources are heavy on government approval and, per our discussion earlier, for often politico-economic reasons, drugs may be very commonly used but not had any pharma funding for official approval, and these drugs may not all be caught when surveying pharmacy or doctor's \"indication notes\" as those may lack sensitivity (due to under-reporting of key \"disease\" designations).\r\n- **I would keep an eye out for the steroids in auto-immune diseases** Steroid represent a relatively large fraction of the drugs, and auto-immune diseases a reasonable fraction of the total diseases (approximately 5%). I would interpret any results that your algorithm suggests in light of this. For example, I expect this will drive your algorithm into picking things that \"look\" like steroids (in terms of molecular structure, and known targets of possible action). As you know, steroids are molecularly quite similar to each other, and are often associated with the same limited number of key molecular targets. The other immunosuppressive agents (i.e. all the other drugs on your typical clinical list of choices) represent a variety of shapes (molecular structure) and known targets, and may provider richer (but more subtle, and probably lower powered to get a trustworthy result) information, and hopefully provide a more nuanced drug suggestion rather than picking things that \"look\" like steroids (e.g. suggesting a drug that nobody would ever have considered) .\r\n- **Consider assigning mechanisms to drugs**. If you note that something richer is to be gained by \"decreasing the gain\" in large drug classes (i.e. the class \"steroids\" includes about 10 drugs in the list), consider using drug classes as an attribute. This will also aid any person who will have to curate the disease-drug connections.\r\n- **The few remaining discrepancies, if using my calls as final calls**. After the discussion of the major discrepancies (where multiple discrepant drug-disease connections hinged on a single discussion), there are still minor discrepancies. There appear to be 55 other discrepancies to eventually be evaluated, totaling less than 5 percent of the total number of connections. Given the small number of total calls (less than 5% of total calls) and the large amount of discussion that would be required to solve each one, it makes sense to go forward with a data freeze for your downstream analysis. But I think it would be great to have you at least aware of these, and we can decide what to do on future versions. \r\nOf the 55 cases of discrepant calls, there are include 31 cases where my curation changed a previous agreement between the prior 2 curators, and those 24 cases where my curation resulted in a three way tie. \r\n--- 7 are explained directly by ammendment 1\r\n--- 14 where I made a call which was explained by a prior call regarding the same disease being connected to another drug within the same drug class\r\n--- 11 can be encapsulated in a discussion regarding hormone therapy in breast cancer. This is a more complex discussion than that of steroids, because the hormone therapies include \"partial agonists\". \r\n--- 3 which treated symptom of chemo rather than symptom of disease (therefore changed to NOT)\r\n--- 3 regarding SSRIs in parkinson's\r\n--- 17 discrepancies would each require a long discussion (similar to our discussions of diseases earlier). These are briefly denoted below.\r\n\r\n|drug|disease|CSH|AJG|PK|PK_notes|\r\n|----|-------|---|---|--|--------|\r\n|Memantine|Alzheimer's disease|SYM|SYM|DM|\"neuroprotective\", doesn't treat any symptom|\r\n|Colchicine|primary biliary cirrhosis|NOT|NOT|DM|admittedly less evidence, but see [\"uptodate 'Overview of the treatment of primary biliary cholangitis (primary biliary cirrhosis)' \"](http://www.uptodate.com/contents/overview-of-the-treatment-of-primary-biliary-cholangitis-primary-biliary-cirrhosis)|\r\n|Pentoxifylline|systemic scleroderma|SYM|SYM|DM|affects the biology of the disease, thereby easing symptoms|\r\n|Tretinoin|peripheral nervous system neoplasm|NOT|NOT|DM|can treat sarcomas [@10.1002/14651858.CD003256.pub2] and per amendment 1|\r\n|Ursodeoxycholic acid|primary biliary cirrhosis|SYM|SYM|DM|doesn't treat any symptom, only modifies disease, see [\"uptodate 'Overview of the treatment of primary biliary cholangitis (primary biliary cirrhosis)' \"](http://www.uptodate.com/contents/overview-of-the-treatment-of-primary-biliary-cholangitis-primary-biliary-cirrhosis)|\r\n|Colchicine|systemic scleroderma|NOT|DM|SYM|for arthralgia, not aware of disease modification|\r\n|Chenodeoxycholic acid|primary biliary cirrhosis|SYM|NOT|DM|in trials, see [\"uptodate 'Overview of the treatment of primary biliary cholangitis (primary biliary cirrhosis)' \"](http://www.uptodate.com/contents/overview-of-the-treatment-of-primary-biliary-cholangitis-primary-biliary-cirrhosis)|\r\n|Dimenhydrinate|allergic rhinitis|SYM|NOT|DM|it blocks histamine-H1 just like benadryl. Granted, one would never actually use this in clinic (you would just use benadryl given better efficacy and less side effects), but given the mechanism of action there is reasonable evidence of efficacy|\r\n|Dimenhydrinate|atopic dermatitis|SYM|NOT|DM|it blocks histamine-H1 just like benadryl. Granted, one would never actually use this in clinic (you would just use benadryl given better efficacy and less side effects), but given the mechanism of action there is reasonable evidence of efficacy|\r\n|Sildenafil|type 1 diabetes mellitus|NOT|DM|SYM|may be DM for DM2 but not for DM1 [@10.2337/diacare.26.2.279]|\r\n|Temozolomide|skin cancer|NOT|NOT|DM|melanoma|\r\n|Acetylcysteine|chronic obstructive pulmonary disease|DM|DM|SYM|mucolytic, does not affect disease biology|\r\n|Epoprostenol|systemic scleroderma|NOT|DM|SYM|not aware of disease modification, agree with CSH comment re: symptom|\r\n|Timolol|coronary artery disease|NOT|SYM|DM|per [\"uptodate - Timolol Drug info\"](http://www.uptodate.com/contents/timolol-systemic-drug-information?source=search_result&search=timolol&selectedTitle=1~36)\r\n|\r\n|Finasteride|prostate cancer|SYM|DM|NOT|prevents but doesn't treat it. Not sure what the symptomatic thing CSH refers to, does she mean symptoms of BPH? (and if so isn't that a different disease?)|\r\n|Digoxin|dilated cardiomyopathy|DM|NOT|SYM|see [\"uptodate: Overview of the therapy of heart failure with reduced ejection fraction\"](http://www.uptodate.com/contents/overview-of-the-therapy-of-heart-failure-with-reduced-ejection-fraction)|\r\n|Ergocalciferol|metabolic syndrome X|SYM|DM|NOT|would you give this med to anyone who has metabolic syndrome X but does not also have vitamin D deficiency?|",
      "comment_id": 1175,
      "profile_id": 188,
      "published": "2016-03-14T18:26:05.738184Z",
      "thread_id": 95,
      "url": "/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95#16"
    },
    {
      "body_html": "<h1>Data licensing and compliance report</h1>\r\n\r\n<p>As a refresher, we released an initial version of our network built from publicly-availabe resources. I had assumed that as long as a resource was public, we could use it for our research. In addition, we're committed to open science — releasing our network and intermediate data, both for reproducibility and to allow others to build off of our research. However, as <a href=\"/u/larsjuhljensen\" class=\"username\">@larsjuhljensen</a> <a href=\"http://thinklab.com/discussion/one-network-to-rule-them-all/102#2\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d102\">pointed out</a>, legal issues arise when using public data that isn't specifically licensed to permit reuse.</p>\r\n\r\n<p>It has now been 212 days since Lar's alert and 199 days since I started this discussion seeking expert advice. Here I'll report on the strategy we chose. Our goals were: to bring us into compliance with copyright law and license agreements; to respect the intent of resource creators; to preserve our sunk time investment; and to retain the scientific value of our network. Unfortunately, no one solution satisfied every objective. We were left to choose between several imperfect ways forward.</p>\r\n\r\n<h2>Compliance efforts</h2>\r\n\r\n<p>First, I compiled the <a href=\"https://github.com/dhimmel/integrate/blob/145810796f0729d1ed5255bcb83c658490a198f9/licenses/README.md\">licenses for all of the resources</a> we included in our network. Of the 28 resources we integrated, only 12 had licenses that <a href=\"http://opendefinition.org/licenses/0\">met</a> the <a href=\"http://opendefinition.org/od/2.1/en/\" title=\"Open Definition 2.1\">criteria for open knowledge</a>. As a result, our project would not be a possibility under a paradigm of absolute compliance.</p>\r\n\r\n<p>Resources fell into four categories regarding their licensing:</p>\r\n\r\n<ol><li>Resources that are in the <strong>public domain</strong>.</li><li>Resources with a license that <strong>allows</strong> use, redistribution, and modification.</li><li>Resources with a license that <strong>forbids</strong> use, redistribution, or modification.</li><li>Resources that <strong>do not have</strong> a license.</li></ol>\r\n\r\n<p>While I retrospectively assigned these categories while writing this post, the approach we pursued for a given resource aligned with its category. We approached category 1 &amp; 2 resources by specifying their license wherever we use, redistribute, or modify them. We approached category 3 &amp; 4 resources by requesting permission from their creators or owners. I attempted attribution for all resources, regardless of category, to maintain data provenance.</p>\r\n\r\n<h3>Category 1 &amp; 2 resources</h3>\r\n\r\n<p>There were 4 <strong>category 1</strong> resources — Entrez Gene, MEDLINE, LabeledIn, and MeSH — all due to US federal Government creations <a href=\"https://en.wikipedia.org/w/index.php?title=Copyright_status_of_work_by_the_U.S._government&amp;oldid=708981516\">not being entitled</a> to copyright protection. These resources were easy to integrate: I could proceed without restriction and released derivative works under CC0.</p>\r\n\r\n<p>There were 14 <strong>category 2</strong> resources. If the resource uses a standard license, such as a license by <a href=\"https://creativecommons.org/licenses/\">Creative Commons</a> or <a href=\"http://opendatacommons.org/licenses/\">Open Data Commons</a>, I used the same license including version for redistribution and derivative works. Examples include Disease Ontology, DISEASES, Gene Ontology, TISSUES, Uberon, WikiPathways, BindingDB, DisGeNET. If the resource used a custom license, then I applied a Creative Commons license that abided by the custom stipulations. For example, <a href=\"https://creativecommons.org/licenses/by/4.0/\">CC BY 4.0</a> for custom licenses that require attribution — GWAS Catalog &amp; LINCS L1000 — and <a href=\"https://creativecommons.org/licenses/by-nc/4.0/\">CC BY-NC 4.0</a> for custom licenses that forbid commercial use or specify academic use only — DrugBank.</p>\r\n\r\n<p>I embedded licensing into the network as node/relationship properties. Therefore, users can filter to retain only specific licenses when querying or parsing our network. Prior to the network stage when data for each resource still resides in separate repositories, I specified licensing via a <code>LICENSE.md</code> file or a section in the <code>README.md</code> file.</p>\r\n\r\n<h3>Category 3 &amp; 4 resources</h3>\r\n\r\n<p>Originally I identified 3 <strong>category 3</strong> resources — MSigDB, Incomplete Interactome, LINCS L1000. I chronicled these permission requests on <em>Thinklab</em>. Through our permission requests, we learned that the <a href=\"https://doi.org/10.15363/thinklab.d111\">Incomplete Interactome was</a> actually category 4 and <a href=\"https://doi.org/10.15363/thinklab.d110\">LINCS L1000 was</a> actually category 2. Our permission request to MSigDB <a href=\"http://doi.org/10.15363/thinklab.d108\">is ongoing</a>.</p>\r\n\r\n<p>There were 9 <strong>category 4</strong> resources — ADEPTUS, Bgee, DOAF, ehrlink, ERC, hetio-dag, Incomplete Interactome, Human Interactome Database, STARGEO. Since I am the creator of hetio-dag and our STARGEO analysis, these resources did not require any action. For the remaining resources, I sent permission requests.</p>\r\n\r\n<p>For category 3 &amp; 4 resources, I opted to continue including the resource in our network regardless of whether we affirmatively received permission. I deemed these resources too critical from a scientific perspective to justify their removal. Several factors shaped my decision: many scientists who post their data assume it will automatically be reusable; the resources were publicly funded with the intent to be used for science; copyright may not apply if our network is fair use or the underlying data is factual; and reuse of scientific data despite all rights reserved is prevalent throughout academia.</p>\r\n\r\n<p>There are several unpleasant consequences to my decision to include category 3 &amp; 4 works. First, I risk the legal consequences of infringement. Second, we could have to purge content from our network if a data creator/owner requests that we discontinue use of their resource. Third, anyone who wants to use or build off of our network will have to revisit the same issues we're facing here.</p>\r\n\r\n<h4>Permission requests by outcome</h4>\r\n\r\n<p>For category 3 &amp; 4 resources, I requested permission to use the resource for our project. I've organized my requests into four outcomes:</p>\r\n\r\n<ul><li>EXST — We received a response referring us to an existing license. In the four instances, we had overlooked the license because it was difficult to find or unclear whether it applied.</li><li>PERM — We received a response granting us permission to use the resource. In both cases, the authors granted their permission but acknowledged that they may not be the rights holder.</li><li>INC — We received an inconclusive response. In all three cases, the authors indicated they would take licensing actions which have yet to happen.</li><li>NORESP — No response.</li></ul>\r\n\r\n<p>Each resource for which we requested permissions is below. Days indicates the time till first response. When present, public documentation of our request is linked to in Contact Method. The table is sorted by outcome and then by days.</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>Resource</th><th>Outcome</th><th>Days</th><th>Contact Method</th></tr></thead><tbody><tr><td><a href=\"http://uberon.org\">Uberon</a></td><td>EXST</td><td>0</td><td><a href=\"https://github.com/obophenotype/uberon/issues/1139\">GitHub Issue</a></td></tr><tr><td><a href=\"http://www.ncbi.nlm.nih.gov/gene\">Entrez Gene</a></td><td>EXST</td><td>2</td><td>helpdesk</td></tr><tr><td><a href=\"http://www.lincscloud.org/l1000/\">LINCS L1000</a></td><td>EXST</td><td>16</td><td><a href=\"https://doi.org/10.15363/thinklab.d110\">email</a></td></tr><tr><td><a href=\"https://www.ebi.ac.uk/gwas/\">GWAS Catalog</a></td><td>EXST</td><td>19</td><td>email</td></tr><tr><td><a href=\"http://science.sciencemag.org/content/suppl/2015/02/18/347.6224.1257601.DC1\">Incomplete Interactome</a></td><td>PERM</td><td>0</td><td><a href=\"https://doi.org/10.15363/thinklab.d111\">email</a></td></tr><tr><td><a href=\"http://csb.pitt.edu/erc_analysis/Methods.php\">Evolutionary Rate Covariation</a></td><td>PERM</td><td>16</td><td>email</td></tr><tr><td><a href=\"http://doa.nubic.northwestern.edu/pages/search.php\">DOAF</a></td><td>INC</td><td>2</td><td>email</td></tr><tr><td><a href=\"http://bgee.org\">Bgee</a></td><td>INC</td><td>9</td><td>email/<a href=\"https://doi.org/10.15363/thinklab.d82#15\">note</a></td></tr><tr><td><a href=\"http://software.broadinstitute.org/gsea/msigdb\">MSigDB</a></td><td>INC</td><td>129</td><td><a href=\"https://doi.org/10.15363/thinklab.d108\">email</a></td></tr><tr><td><a href=\"http://interactome.dfci.harvard.edu/H_sapiens/index.php?page=download\">Human Interactome Database</a></td><td>NORESP</td><td>189+</td><td>email</td></tr><tr><td><a href=\"http://acgt.cs.tau.ac.il/adeptus/\">ADEPTUS</a></td><td>NORESP</td><td>198+</td><td>email</td></tr></tbody></table>\r\n\r\n<h2>Conclusion</h2>\r\n\r\n<p>We've gone to great lengths and invested substantial time in complying with data copyright and licensing. However, under a strict interpretation, our project may infringe upon the rights of publicly-funded scholarly resources.</p>",
      "body_md": "# Data licensing and compliance report\r\n\r\nAs a refresher, we released an initial version of our network built from publicly-availabe resources. I had assumed that as long as a resource was public, we could use it for our research. In addition, we're committed to open science — releasing our network and intermediate data, both for reproducibility and to allow others to build off of our research. However, as @larsjuhljensen [pointed out](http://thinklab.com/discussion/one-network-to-rule-them-all/102#2), legal issues arise when using public data that isn't specifically licensed to permit reuse.\r\n\r\nIt has now been 212 days since Lar's alert and 199 days since I started this discussion seeking expert advice. Here I'll report on the strategy we chose. Our goals were: to bring us into compliance with copyright law and license agreements; to respect the intent of resource creators; to preserve our sunk time investment; and to retain the scientific value of our network. Unfortunately, no one solution satisfied every objective. We were left to choose between several imperfect ways forward.\r\n\r\n## Compliance efforts\r\n\r\nFirst, I compiled the [licenses for all of the resources](https://github.com/dhimmel/integrate/blob/145810796f0729d1ed5255bcb83c658490a198f9/licenses/README.md) we included in our network. Of the 28 resources we integrated, only 12 had licenses that [met](http://opendefinition.org/licenses/0) the [criteria for open knowledge](http://opendefinition.org/od/2.1/en/ \"Open Definition 2.1\"). As a result, our project would not be a possibility under a paradigm of absolute compliance.\r\n\r\nResources fell into four categories regarding their licensing:\r\n\r\n1. Resources that are in the **public domain**.\r\n2. Resources with a license that **allows** use, redistribution, and modification.\r\n3. Resources with a license that **forbids** use, redistribution, or modification.\r\n4. Resources that **do not have** a license.\r\n\r\nWhile I retrospectively assigned these categories while writing this post, the approach we pursued for a given resource aligned with its category. We approached category 1 & 2 resources by specifying their license wherever we use, redistribute, or modify them. We approached category 3 & 4 resources by requesting permission from their creators or owners. I attempted attribution for all resources, regardless of category, to maintain data provenance.\r\n\r\n### Category 1 & 2 resources\r\n\r\nThere were 4 **category 1** resources — Entrez Gene, MEDLINE, LabeledIn, and MeSH — all due to US federal Government creations [not being entitled](https://en.wikipedia.org/w/index.php?title=Copyright_status_of_work_by_the_U.S._government&oldid=708981516) to copyright protection. These resources were easy to integrate: I could proceed without restriction and released derivative works under CC0.\r\n\r\nThere were 14 **category 2** resources. If the resource uses a standard license, such as a license by [Creative Commons](https://creativecommons.org/licenses/) or [Open Data Commons](http://opendatacommons.org/licenses/), I used the same license including version for redistribution and derivative works. Examples include Disease Ontology, DISEASES, Gene Ontology, TISSUES, Uberon, WikiPathways, BindingDB, DisGeNET. If the resource used a custom license, then I applied a Creative Commons license that abided by the custom stipulations. For example, [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/) for custom licenses that require attribution — GWAS Catalog & LINCS L1000 — and [CC BY-NC 4.0](https://creativecommons.org/licenses/by-nc/4.0/) for custom licenses that forbid commercial use or specify academic use only — DrugBank.\r\n\r\nI embedded licensing into the network as node/relationship properties. Therefore, users can filter to retain only specific licenses when querying or parsing our network. Prior to the network stage when data for each resource still resides in separate repositories, I specified licensing via a `LICENSE.md` file or a section in the `README.md` file.\r\n\r\n### Category 3 & 4 resources\r\n\r\nOriginally I identified 3 **category 3** resources — MSigDB, Incomplete Interactome, LINCS L1000. I chronicled these permission requests on _Thinklab_. Through our permission requests, we learned that the [Incomplete Interactome was](https://doi.org/10.15363/thinklab.d111) actually category 4 and [LINCS L1000 was](https://doi.org/10.15363/thinklab.d110) actually category 2. Our permission request to MSigDB [is ongoing](http://doi.org/10.15363/thinklab.d108).\r\n\r\nThere were 9 **category 4** resources — ADEPTUS, Bgee, DOAF, ehrlink, ERC, hetio-dag, Incomplete Interactome, Human Interactome Database, STARGEO. Since I am the creator of hetio-dag and our STARGEO analysis, these resources did not require any action. For the remaining resources, I sent permission requests.\r\n\r\nFor category 3 & 4 resources, I opted to continue including the resource in our network regardless of whether we affirmatively received permission. I deemed these resources too critical from a scientific perspective to justify their removal. Several factors shaped my decision: many scientists who post their data assume it will automatically be reusable; the resources were publicly funded with the intent to be used for science; copyright may not apply if our network is fair use or the underlying data is factual; and reuse of scientific data despite all rights reserved is prevalent throughout academia.\r\n\r\nThere are several unpleasant consequences to my decision to include category 3 & 4 works. First, I risk the legal consequences of infringement. Second, we could have to purge content from our network if a data creator/owner requests that we discontinue use of their resource. Third, anyone who wants to use or build off of our network will have to revisit the same issues we're facing here.\r\n\r\n#### Permission requests by outcome\r\n\r\nFor category 3 & 4 resources, I requested permission to use the resource for our project. I've organized my requests into four outcomes:\r\n\r\n+ EXST — We received a response referring us to an existing license. In the four instances, we had overlooked the license because it was difficult to find or unclear whether it applied.\r\n+ PERM — We received a response granting us permission to use the resource. In both cases, the authors granted their permission but acknowledged that they may not be the rights holder.\r\n+ INC — We received an inconclusive response. In all three cases, the authors indicated they would take licensing actions which have yet to happen.\r\n+ NORESP — No response.\r\n\r\nEach resource for which we requested permissions is below. Days indicates the time till first response. When present, public documentation of our request is linked to in Contact Method. The table is sorted by outcome and then by days.\r\n\r\n| Resource | Outcome | Days | Contact Method |\r\n|----------|----------|------|----------------|\r\n| [Uberon](http://uberon.org) | EXST | 0 | [GitHub Issue](https://github.com/obophenotype/uberon/issues/1139) |\r\n| [Entrez Gene](http://www.ncbi.nlm.nih.gov/gene) | EXST | 2 | helpdesk |\r\n| [LINCS L1000](http://www.lincscloud.org/l1000/) | EXST | 16 | [email](https://doi.org/10.15363/thinklab.d110) |\r\n| [GWAS Catalog](https://www.ebi.ac.uk/gwas/) | EXST | 19 | email |\r\n| [Incomplete Interactome](http://science.sciencemag.org/content/suppl/2015/02/18/347.6224.1257601.DC1) | PERM | 0 | [email](https://doi.org/10.15363/thinklab.d111) |\r\n| [Evolutionary Rate Covariation](http://csb.pitt.edu/erc_analysis/Methods.php) | PERM | 16 | email |\r\n| [DOAF](http://doa.nubic.northwestern.edu/pages/search.php) | INC | 2 | email |\r\n| [Bgee](http://bgee.org) | INC | 9 | email/[note](https://doi.org/10.15363/thinklab.d82#15) |\r\n| [MSigDB](http://software.broadinstitute.org/gsea/msigdb) | INC | 129 | [email](https://doi.org/10.15363/thinklab.d108) |\r\n| [Human Interactome Database](http://interactome.dfci.harvard.edu/H_sapiens/index.php?page=download) | NORESP | 189+ | email |\r\n| [ADEPTUS](http://acgt.cs.tau.ac.il/adeptus/) | NORESP | 198+ | email |\r\n\r\n## Conclusion\r\n\r\nWe've gone to great lengths and invested substantial time in complying with data copyright and licensing. However, under a strict interpretation, our project may infringe upon the rights of publicly-funded scholarly resources.",
      "comment_id": 1176,
      "profile_id": 17,
      "published": "2016-03-15T03:01:43.148728Z",
      "thread_id": 107,
      "url": "/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#14"
    },
    {
      "body_html": "<h2>Category breakdown by resource</h2>\r\n\r\n<p>Using the consensus curation, we have gone back and calculated the composition of indication category by resource (<a href=\"https://github.com/dhimmel/indications/blob/11d535ba0884ee56c3cd5756fdfb4985f313bd80/curation/catalog.ipynb\">notebook</a>).</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>Resource</th><th>DM</th><th>SYM</th><th>NOT</th><th>Total</th></tr></thead><tbody><tr><td>MEDI-HPS</td><td>532 (67.1%)</td><td>168 (21.2%)</td><td>93 (11.7%)</td><td>793 (100%)</td></tr><tr><td>PREDICT</td><td>346 (59.7%)</td><td>158 (27.2%)</td><td>76 (13.1%)</td><td>580 (100%)</td></tr><tr><td>EHRLink</td><td>205 (44.3%)</td><td>163 (35.2%)</td><td>95 (20.5%)</td><td>463 (100%)</td></tr><tr><td>LabeledIn</td><td>183 (66.1%)</td><td>72 (26.0%)</td><td>22 (7.9%)</td><td>277 (100%)</td></tr></tbody></table>\r\n\r\n<p>The table indicates that of the 793 indications we extracted from MEDI-HPS, 532 (67.1%) were disease modifying. In short, we found that MEDI-HPS and LabeledIn contained the highest percentage of disease-modifying indications. EHRLink, which is based on electronic health records, contained the highest percentage of symptomatic (35.2%) and non (20.5%) indications.</p>\r\n\r\n<h2>Category breakdown by number of resources</h2>\r\n\r\n<p>Next, we looked at the category composition based on the number of resources reporting each indication.</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th># of Resources</th><th>DM</th><th>SYM</th><th>NOT</th><th>Total</th></tr></thead><tbody><tr><td>1</td><td>433 (47.4%)</td><td>271 (29.6%)</td><td>210 (23.0%)</td><td>914 (100%)</td></tr><tr><td>2</td><td>190 (66.2%)</td><td>74 (25.8%)</td><td>23 (8.0%)</td><td>287 (100%)</td></tr><tr><td>3</td><td>75 (61.0%)</td><td>38 (30.9%)</td><td>10 (8.1%)</td><td>123 (100%)</td></tr><tr><td>4</td><td>57 (89.1%)</td><td>7 (10.9%)</td><td>0 (0.0%)</td><td>64 (100%)</td></tr></tbody></table>\r\n\r\n<p>The more resources that reported an indication the more likely it was to be disease modifying: indications in only a single resource were disease modifying 47.4% of the time whereas indications in all four resources were disease modifying 89.1% of the time.</p>",
      "body_md": "## Category breakdown by resource\r\n\r\nUsing the consensus curation, we have gone back and calculated the composition of indication category by resource ([notebook](https://github.com/dhimmel/indications/blob/11d535ba0884ee56c3cd5756fdfb4985f313bd80/curation/catalog.ipynb)).\r\n\r\n| Resource | DM | SYM | NOT | Total |\r\n|-----------|-------------|-------------|------------|------------|\r\n| MEDI-HPS | 532 (67.1%) | 168 (21.2%) | 93 (11.7%) | 793 (100%) |\r\n| PREDICT | 346 (59.7%) | 158 (27.2%) | 76 (13.1%) | 580 (100%) |\r\n| EHRLink | 205 (44.3%) | 163 (35.2%) | 95 (20.5%) | 463 (100%) |\r\n| LabeledIn | 183 (66.1%) | 72 (26.0%) | 22 (7.9%) | 277 (100%) |\r\n\r\nThe table indicates that of the 793 indications we extracted from MEDI-HPS, 532 (67.1%) were disease modifying. In short, we found that MEDI-HPS and LabeledIn contained the highest percentage of disease-modifying indications. EHRLink, which is based on electronic health records, contained the highest percentage of symptomatic (35.2%) and non (20.5%) indications.\r\n\r\n## Category breakdown by number of resources\r\n\r\nNext, we looked at the category composition based on the number of resources reporting each indication.\r\n\r\n| # of Resources | DM | SYM | NOT | Total |\r\n|----------------|-------------|-------------|-------------|------------|\r\n| 1 | 433 (47.4%) | 271 (29.6%) | 210 (23.0%) | 914 (100%) |\r\n| 2 | 190 (66.2%) | 74 (25.8%) | 23 (8.0%) | 287 (100%) |\r\n| 3 | 75 (61.0%) | 38 (30.9%) | 10 (8.1%) | 123 (100%) |\r\n| 4 | 57 (89.1%) | 7 (10.9%) | 0 (0.0%) | 64 (100%) |\r\n\r\nThe more resources that reported an indication the more likely it was to be disease modifying: indications in only a single resource were disease modifying 47.4% of the time whereas indications in all four resources were disease modifying 89.1% of the time.",
      "comment_id": 1177,
      "profile_id": 17,
      "published": "2016-03-15T05:25:20.118976Z",
      "thread_id": 182,
      "url": "/discussion/announcing-pharmacotherapydb-the-open-catalog-of-drug-therapies-for-disease/182#2"
    },
    {
      "body_html": "<h1>2016 Neo4j GraphGist Challenge</h1>\r\n\r\n<p>We <a href=\"http://thinklab.com/discussion/using-the-neo4j-graph-database-for-hetnets/112#8\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d112\">created</a> a Star Wars themed entry to the 2016 Neo4j GraphGist challenge. The competition aimed to showcase exciting uses of Neo4j — a graph database designed for hetnets. The winners were <a href=\"http://neo4j.com/blog/graphgist-challenge-winners/\" title=\"The Graph Is Strong with This One: GraphGist Challenge Winners!\">announced today</a> and <a href=\"http://neo4j.com/graphgist/c4eab62c-7f5e-4e17-8f75-811d65d83127\" title=\"Drug repurposing by hetnet relationship prediction: a hew hope\">our GraphGist</a> won the \"Open/Government Data and Politics\" category.</p>",
      "body_md": "# 2016 Neo4j GraphGist Challenge\r\n\r\nWe [created](http://thinklab.com/discussion/using-the-neo4j-graph-database-for-hetnets/112#8) a Star Wars themed entry to the 2016 Neo4j GraphGist challenge. The competition aimed to showcase exciting uses of Neo4j -- a graph database designed for hetnets. The winners were [announced today](http://neo4j.com/blog/graphgist-challenge-winners/ \"The Graph Is Strong with This One: GraphGist Challenge Winners!\") and [our GraphGist](http://neo4j.com/graphgist/c4eab62c-7f5e-4e17-8f75-811d65d83127 \"Drug repurposing by hetnet relationship prediction: a hew hope\") won the \"Open/Government Data and Politics\" category.",
      "comment_id": 1178,
      "profile_id": 17,
      "published": "2016-03-15T23:58:06.449545Z",
      "thread_id": 113,
      "url": "/discussion/tracking-project-reuse-citation-and-publicity/113#6"
    },
    {
      "body_html": "<h1>PharmacotherapyDB Version 1.0</h1>\r\n\r\n<p>We <a href=\"http://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95#15\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d95\">completed physician curation</a> for the time being and <a href=\"http://thinklab.com/discussion/announcing-pharmacotherapydb-the-open-catalog-of-drug-therapies-for-disease/182\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d182\">released the first version</a> of our indications catalog called PharmacotherapyDB.</p>\r\n\r\n<p>Thanks <a href=\"/u/b_good\" class=\"username\">@b_good</a>, <a href=\"/u/TIOprea\" class=\"username\">@TIOprea</a>, <a href=\"/u/allisonmccoy\" class=\"username\">@allisonmccoy</a>, <a href=\"/u/ritukhare\" class=\"username\">@ritukhare</a>, and <a href=\"/u/alizee\" class=\"username\">@alizee</a> — your suggestions and feedback were immensely helpful!</p>\r\n\r\n<p>We'll keep this discussion alive for any suggestions of new resources or methods to improve future versions of PharmacotherapyDB.</p>",
      "body_md": "# PharmacotherapyDB Version 1.0\r\n\r\nWe [completed physician curation](http://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95#15) for the time being and [released the first version](http://thinklab.com/discussion/announcing-pharmacotherapydb-the-open-catalog-of-drug-therapies-for-disease/182) of our indications catalog called PharmacotherapyDB.\r\n\r\nThanks @b_good, @TIOprea, @allisonmccoy, @ritukhare, and @alizee -- your suggestions and feedback were immensely helpful!\r\n\r\nWe'll keep this discussion alive for any suggestions of new resources or methods to improve future versions of PharmacotherapyDB.",
      "comment_id": 1179,
      "profile_id": 17,
      "published": "2016-03-16T21:56:38.375668Z",
      "thread_id": 21,
      "url": "/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#24"
    },
    {
      "body_html": "<h1>Therapeutic Target Database</h1>\r\n\r\n<p>The Therapeutic Target Database (<a href=\"http://bidd.nus.edu.sg/group/cjttd/\" title=\"Therapeutic Target Database Homepage\">TTD</a>) is a target focused resource with pharmacological relationships. <a href=\"/u/janispi\" class=\"username\">@janispi</a> <a href=\"https://twitter.com/Janis3_14159/status/709844572600475648\" title=\"Twitter\">suggested</a> we check out TTD as a source of drug–disease therapies.</p>\r\n\r\n<p>Specifically, TTD has a dataset of indications, which range from approved to investigational, available online (<a href=\"http://database.idrb.cqu.edu.cn/TTD/download/drug-disease_TTD2016.txt\"><code>drug-disease_TTD2016.txt</code></a>). I couldn't find how these indications were constructed from their publications <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/30.1.412\" class=\"citation\" data-key=\"10.1093/nar/30.1.412\">1</a>, <a href=\"https://doi.org/10.1093/nar/gkp1014\" class=\"citation\" data-key=\"10.1093/nar/gkp1014\">2</a>, <a href=\"https://doi.org/10.1093/nar/gkr797\" class=\"citation\" data-key=\"10.1093/nar/gkr797\">3</a>, <a href=\"https://doi.org/10.1093/nar/gkt1129\" class=\"citation\" data-key=\"10.1093/nar/gkt1129\">4</a>, <a href=\"https://doi.org/10.1093/nar/gkv1230\" class=\"citation\" data-key=\"10.1093/nar/gkv1230\">5</a>]</span>, although I may have missed it. I emailed Professor Yu Zong (<code>csccyz@nus.edu.sg</code>), who indicated their drug-disease relationships were human curated.</p>\r\n\r\n<p>Just wanted to note this information, so we remember to keep TTD in mind.</p>\r\n\r\n<p><strong>Update July 16, 2016</strong>: Qin Chu provided me the following additional information via email: </p>\r\n\r\n<blockquote><p>The mapping between diseases and drugs were done manually. We searched different sources of literature such as pharmacology textbooks, review articles and research papers. The methods to extract the related drug target and disease information from literature were described in the 2012 version of TTD update paper <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkr797\" class=\"citation\" data-key=\"10.1093/nar/gkr797\">3</a>]</span>. We mapped the disease information to ICD code in the 2014 update of TTD <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkt1129\" class=\"citation\" data-key=\"10.1093/nar/gkt1129\">4</a>]</span>.</p></blockquote>",
      "body_md": "# Therapeutic Target Database\r\n\r\nThe Therapeutic Target Database ([TTD](http://bidd.nus.edu.sg/group/cjttd/ \"Therapeutic Target Database Homepage\")) is a target focused resource with pharmacological relationships. @janispi [suggested](https://twitter.com/Janis3_14159/status/709844572600475648 \"Twitter\") we check out TTD as a source of drug--disease therapies.\r\n\r\nSpecifically, TTD has a dataset of indications, which range from approved to investigational, available online ([`drug-disease_TTD2016.txt`](http://database.idrb.cqu.edu.cn/TTD/download/drug-disease_TTD2016.txt)). I couldn't find how these indications were constructed from their publications [@10.1093/nar/30.1.412 @10.1093/nar/gkp1014 @10.1093/nar/gkr797 @10.1093/nar/gkt1129 @10.1093/nar/gkv1230], although I may have missed it. I emailed Professor Yu Zong (`csccyz@nus.edu.sg`), who indicated their drug-disease relationships were human curated.\r\n\r\nJust wanted to note this information, so we remember to keep TTD in mind.\r\n\r\n**Update July 16, 2016**: Qin Chu provided me the following additional information via email: \r\n\r\n> The mapping between diseases and drugs were done manually. We searched different sources of literature such as pharmacology textbooks, review articles and research papers. The methods to extract the related drug target and disease information from literature were described in the 2012 version of TTD update paper [@10.1093/nar/gkr797]. We mapped the disease information to ICD code in the 2014 update of TTD [@10.1093/nar/gkt1129].",
      "comment_id": 1180,
      "profile_id": 17,
      "published": "2016-03-16T22:14:15.042713Z",
      "thread_id": 21,
      "url": "/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#25"
    },
    {
      "body_html": "<p>I spoke with <a href=\"/u/TIOprea\" class=\"username\">@TIOprea</a> and Oleg Ursu from the University of New Mexico. They are constructing a highly curated yet highly integrative database of pharmacology named <a href=\"http://datascience.unm.edu/drugdb/\">DrugCentral</a>. They have not yet published a journal article detailing their database. However, they have posted an alpha <a href=\"http://pasilla.health.unm.edu/tomcat/drugcentral/drugcentral\" title=\"DrugCentral Browser\">webapp</a> and <a href=\"https://github.com/olegursu/drugtarget\" title=\"olegursu/drugtarget on GitHub\">data repository</a>, which provide access to select components of the database.</p>\r\n\r\n<p>My impression was that the database is similar in concept to <a href=\"http://www.drugbank.ca/\">DrugBank</a> but has key advantages in certain areas. First, it has integrated types of data which are not currently part of DrugBank. Second, it takes a more clinical approach to curation compared to DrugBank. For example, drug–target relationships in DrugCentral adhere more to the \"three pillars <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.drudis.2011.12.020\" class=\"citation\" data-key=\"10.1016/j.drudis.2011.12.020\">1</a>]</span>\" of pharmacological activity.</p>\r\n\r\n<p>I created a repository (<a href=\"https://github.com/dhimmel/drugcentral\" title=\"dhimmel/drugcentral on GitHub\"><code>dhimmel/drugcentral</code></a>) to process parts of DrugCentral for inclusion in our network. Details of the integration will follow.</p>",
      "body_md": "I spoke with @TIOprea and Oleg Ursu from the University of New Mexico. They are constructing a highly curated yet highly integrative database of pharmacology named [DrugCentral](http://datascience.unm.edu/drugdb/). They have not yet published a journal article detailing their database. However, they have posted an alpha [webapp](http://pasilla.health.unm.edu/tomcat/drugcentral/drugcentral \"DrugCentral Browser\") and [data repository](https://github.com/olegursu/drugtarget \"olegursu/drugtarget on GitHub\"), which provide access to select components of the database.\r\n\r\nMy impression was that the database is similar in concept to [DrugBank](http://www.drugbank.ca/) but has key advantages in certain areas. First, it has integrated types of data which are not currently part of DrugBank. Second, it takes a more clinical approach to curation compared to DrugBank. For example, drug--target relationships in DrugCentral adhere more to the \"three pillars [@10.1016/j.drudis.2011.12.020]\" of pharmacological activity.\r\n\r\nI created a repository ([`dhimmel/drugcentral`](https://github.com/dhimmel/drugcentral \"dhimmel/drugcentral on GitHub\")) to process parts of DrugCentral for inclusion in our network. Details of the integration will follow.",
      "comment_id": 1182,
      "profile_id": 17,
      "published": "2016-03-20T16:41:10.716611Z",
      "thread_id": 186,
      "url": "/discussion/incorporating-drugcentral-data-in-our-network/186"
    },
    {
      "body_html": "<h1>Contributions to our hetnet</h1>\r\n\r\n<p>I processed DrugCentral data and converted it into the identifier systems used by our network (<a href=\"https://github.com/dhimmel/drugcentral/blob/e80a0c966a53ce48650d98069b126801c2793517/drugcentral-to-rephetio.ipynb\">notebook</a>). I have initially added two relationship types from DrugCentral into the hetnet (<a href=\"https://github.com/dhimmel/integrate/commit/0f2ef740197dd2767cb0de80f57d9f47e2e91c7a\">commit</a>). </p>\r\n\r\n<h2>Drug targets</h2>\r\n\r\n<p>I extracted drug–target relationships from DrugCentral and converted them into the DrugBank and Entrez Gene identifiers in our network (<a href=\"https://github.com/dhimmel/drugcentral/blob/e80a0c966a53ce48650d98069b126801c2793517/rephetio/targets.tsv\">dataset</a>). The table below shows the sources from which DrugCentral compiled drug targets and how many relationships each source contributed. </p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>Resource</th><th>Count</th></tr></thead><tbody><tr><td>DrugCentral (ChEMBL)</td><td>2,922</td></tr><tr><td>DrugCentral (literature)</td><td>182</td></tr><tr><td>DrugCentral (label)</td><td>89</td></tr><tr><td>DrugCentral (IUPHAR)</td><td>56</td></tr><tr><td>DrugCentral (KEGG DRUG)</td><td>25</td></tr></tbody></table>\r\n\r\n<p>Prior to including DrugCentral, our network contained 10,747 <em>Compound–binds–Gene</em> relationships from <a href=\"http://thinklab.com/discussion/protein-target-carrier-transporter-and-enzyme-interactions-in-drugbank/65#1\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d65\">DrugBank</a> and <a href=\"http://thinklab.com/discussion/integrating-drug-target-information-from-bindingdb/53#6\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d53\">BindingDB</a>. Drug targets from DrugCentral added 824 additional binding relationships.</p>\r\n\r\n<h2>Pharmacologic classes</h2>\r\n\r\n<p>DrugCentral has compiled the membership of compounds in pharmacologic classes from several <a href=\"https://github.com/olegursu/drugtarget/blob/9a6d84bed8650c6c507a2d3d786814c774568610/README.md#pharmacologic-class-table\">sources</a>, which contain the following types of classes:</p>\r\n\r\n<ul><li>FDA — Mechanism of Action</li><li>FDA — Physiologic Effect</li><li>FDA — Chemical/Ingredient</li><li>FDA — Established Pharmacologic Class</li><li>MeSH — Pharmacological Action</li><li>CHEBI — Application</li></ul>\r\n\r\n<p>I decided to assign all of these classes to a single node type (<em>Pharmacologic Class</em>). I added a new relationship type for <em>Pharmacologic Class–includes–Compound</em>. DrugCentral contributed 10,959 relationships for 1,262 <a href=\"https://github.com/dhimmel/drugcentral/blob/e80a0c966a53ce48650d98069b126801c2793517/rephetio/classes.tsv\" title=\"Table of Pharmacologic Classes extracted from DrugCentral\">pharmacologic classes</a>.</p>",
      "body_md": "# Contributions to our hetnet\r\n\r\nI processed DrugCentral data and converted it into the identifier systems used by our network ([notebook](https://github.com/dhimmel/drugcentral/blob/e80a0c966a53ce48650d98069b126801c2793517/drugcentral-to-rephetio.ipynb)). I have initially added two relationship types from DrugCentral into the hetnet ([commit](https://github.com/dhimmel/integrate/commit/0f2ef740197dd2767cb0de80f57d9f47e2e91c7a)). \r\n\r\n\r\n## Drug targets\r\n\r\nI extracted drug--target relationships from DrugCentral and converted them into the DrugBank and Entrez Gene identifiers in our network ([dataset](https://github.com/dhimmel/drugcentral/blob/e80a0c966a53ce48650d98069b126801c2793517/rephetio/targets.tsv)). The table below shows the sources from which DrugCentral compiled drug targets and how many relationships each source contributed. \r\n\r\n| Resource | Count |\r\n| ------------- | -------- |\r\n| DrugCentral (ChEMBL) | 2,922 |\r\n| DrugCentral (literature) | 182 |\r\n| DrugCentral (label) | 89|\r\n| DrugCentral (IUPHAR) | 56 |\r\n| DrugCentral (KEGG DRUG) | 25 |\r\n\r\nPrior to including DrugCentral, our network contained 10,747 _Compound--binds--Gene_ relationships from [DrugBank](http://thinklab.com/discussion/protein-target-carrier-transporter-and-enzyme-interactions-in-drugbank/65#1) and [BindingDB](http://thinklab.com/discussion/integrating-drug-target-information-from-bindingdb/53#6). Drug targets from DrugCentral added 824 additional binding relationships.\r\n\r\n## Pharmacologic classes\r\n\r\nDrugCentral has compiled the membership of compounds in pharmacologic classes from several [sources](https://github.com/olegursu/drugtarget/blob/9a6d84bed8650c6c507a2d3d786814c774568610/README.md#pharmacologic-class-table), which contain the following types of classes:\r\n\r\n+ FDA -- Mechanism of Action\r\n+ FDA -- Physiologic Effect\r\n+ FDA -- Chemical/Ingredient\r\n+ FDA -- Established Pharmacologic Class\r\n+ MeSH -- Pharmacological Action\r\n+ CHEBI -- Application\r\n\r\nI decided to assign all of these classes to a single node type (_Pharmacologic Class_). I added a new relationship type for _Pharmacologic Class--includes--Compound_. DrugCentral contributed 10,959 relationships for 1,262 [pharmacologic classes](https://github.com/dhimmel/drugcentral/blob/e80a0c966a53ce48650d98069b126801c2793517/rephetio/classes.tsv \"Table of Pharmacologic Classes extracted from DrugCentral\").",
      "comment_id": 1183,
      "profile_id": 17,
      "published": "2016-03-20T17:21:28.930112Z",
      "thread_id": 186,
      "url": "/discussion/incorporating-drugcentral-data-in-our-network/186#2"
    },
    {
      "body_html": "<h1>Medical indications</h1>\r\n\r\n<p>In my conversation with DrugCentral team members, we first discussed PharmacotherapyDB, our <a href=\"http://thinklab.com/discussion/announcing-pharmacotherapydb-the-open-catalog-of-drug-therapies-for-disease/182\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d182\">recently-released</a> physician-curated catalog of indications. One major takeaway was that we needed to more clearly explain that our definition of disease modifying differs from the clinical definition. Also, we need to more clearly state that <code>NOT</code> refers to non-indications.</p>\r\n\r\n<p>As part of DrugCentral, they've constructed their own indications catalog. Their seeded their catalog from <a href=\"http://omop.org/\" title=\"Observational Medical Outcomes Partnership\">OMOP</a> in 2012 and have since then manually added additional indications. OMOP has now become <a href=\"http://www.ohdsi.org/\" title=\"Observational Health Data Sciences and Informatics\">OHDSI</a> and hosts their vocabular on GitHub at <a href=\"https://github.com/OHDSI/Vocabulary-v5.0\"><code>OHDSI/Vocabulary-v5.0</code></a>. As a side note, we were not aware of OMOP <span class=\"citation\">[<a href=\"https://doi.org/10.7326/0003-4819-153-9-201011020-00010\" class=\"citation\" data-key=\"10.7326/0003-4819-153-9-201011020-00010\">1</a>]</span> or OHDSI <span class=\"citation\">[<a href=\"https://doi.org/10.3233/978-1-61499-564-7-574\" class=\"citation\" data-key=\"10.3233/978-1-61499-564-7-574\">2</a>]</span> when we <a href=\"http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#21\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d21\">assembled</a> our indications for version 1.0 of PharmacotherapyDB.</p>\r\n\r\n<h2>Aligning indications with PharmacotherapyDB</h2>\r\n\r\n<p>I converted the DrugCentral indications to the slim sets of DrugBank drugs and Disease Ontology diseases in PharmacotherapyDB 1.0 (<a href=\"https://github.com/dhimmel/drugcentral/blob/e80a0c966a53ce48650d98069b126801c2793517/drugcentral-to-rephetio.ipynb\">notebook</a>, <a href=\"https://github.com/dhimmel/drugcentral/blob/e80a0c966a53ce48650d98069b126801c2793517/rephetio/indications.tsv\">dataset</a>). For each disease, I aggregated direct indications as well as indications for subtypes (referred to as propagation). </p>\r\n\r\n<p>In the <a href=\"https://github.com/dhimmel/drugcentral/blob/e80a0c966a53ce48650d98069b126801c2793517/rephetio/indications.tsv\">converted dataset</a>, I included a <code>category</code> column giving the indication's PharmacotherapyDB 1.0 status. Of a total of 671 indications extracted from DrugCentral, 210 were not in PharmacotherapyDB 1.0. Of the 461 indications in PharmacotherapyDB, 359 were classified as disease modifying (78%), 77 were classified as symptomatic (17%), and 25 were classified as non-indications (5%). </p>\r\n\r\n<p>6 of the non-indications were <a href=\"https://github.com/dhimmel/drugcentral/blob/e80a0c966a53ce48650d98069b126801c2793517/rephetio/indications.tsv#L38\">for anemia</a> and 8 were <a href=\"https://github.com/dhimmel/drugcentral/blob/e80a0c966a53ce48650d98069b126801c2793517/rephetio/indications.tsv#L296\">for hypertension</a>, two diseases for which we have a <a href=\"http://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95#8\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d95\">known problem</a> with their generality. <a href=\"http://thinklab.com/discussion/announcing-pharmacotherapydb-the-open-catalog-of-drug-therapies-for-disease/182#2\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d182\">Compared to the four sources</a> of PharmacotherapyDB indications, DrugCentral appears to have a higher percentage of disease modifying indications. However, we're basing this assessment on indications that appeared in DrugCentral and at least one other resource, so it's potentially biased.</p>\r\n\r\n<p><a href=\"/u/pouyakhankhanian\" class=\"username\">@pouyakhankhanian</a>, if you are up for curating the 210 new indications as <code>DM</code>, <code>SYM</code>, or <code>NOT</code>, we could potentially:</p>\r\n\r\n<ol><li>add these indications to a future release of PharmacotherapyDB</li><li>use these indications to test our predictions</li></ol>",
      "body_md": "# Medical indications\r\n\r\nIn my conversation with DrugCentral team members, we first discussed PharmacotherapyDB, our [recently-released](http://thinklab.com/discussion/announcing-pharmacotherapydb-the-open-catalog-of-drug-therapies-for-disease/182) physician-curated catalog of indications. One major takeaway was that we needed to more clearly explain that our definition of disease modifying differs from the clinical definition. Also, we need to more clearly state that `NOT` refers to non-indications.\r\n\r\nAs part of DrugCentral, they've constructed their own indications catalog. Their seeded their catalog from [OMOP](http://omop.org/ \"Observational Medical Outcomes Partnership\") in 2012 and have since then manually added additional indications. OMOP has now become [OHDSI](http://www.ohdsi.org/ \"Observational Health Data Sciences and Informatics\") and hosts their vocabular on GitHub at [`OHDSI/Vocabulary-v5.0`](https://github.com/OHDSI/Vocabulary-v5.0). As a side note, we were not aware of OMOP [@10.7326/0003-4819-153-9-201011020-00010] or OHDSI [@10.3233/978-1-61499-564-7-574] when we [assembled](http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#21) our indications for version 1.0 of PharmacotherapyDB.\r\n\r\n## Aligning indications with PharmacotherapyDB\r\n\r\nI converted the DrugCentral indications to the slim sets of DrugBank drugs and Disease Ontology diseases in PharmacotherapyDB 1.0 ([notebook](https://github.com/dhimmel/drugcentral/blob/e80a0c966a53ce48650d98069b126801c2793517/drugcentral-to-rephetio.ipynb), [dataset](https://github.com/dhimmel/drugcentral/blob/e80a0c966a53ce48650d98069b126801c2793517/rephetio/indications.tsv)). For each disease, I aggregated direct indications as well as indications for subtypes (referred to as propagation). \r\n\r\nIn the [converted dataset](https://github.com/dhimmel/drugcentral/blob/e80a0c966a53ce48650d98069b126801c2793517/rephetio/indications.tsv), I included a `category` column giving the indication's PharmacotherapyDB 1.0 status. Of a total of 671 indications extracted from DrugCentral, 210 were not in PharmacotherapyDB 1.0. Of the 461 indications in PharmacotherapyDB, 359 were classified as disease modifying (78%), 77 were classified as symptomatic (17%), and 25 were classified as non-indications (5%). \r\n\r\n6 of the non-indications were [for anemia](https://github.com/dhimmel/drugcentral/blob/e80a0c966a53ce48650d98069b126801c2793517/rephetio/indications.tsv#L38) and 8 were [for hypertension](https://github.com/dhimmel/drugcentral/blob/e80a0c966a53ce48650d98069b126801c2793517/rephetio/indications.tsv#L296), two diseases for which we have a [known problem](http://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95#8) with their generality. [Compared to the four sources](http://thinklab.com/discussion/announcing-pharmacotherapydb-the-open-catalog-of-drug-therapies-for-disease/182#2) of PharmacotherapyDB indications, DrugCentral appears to have a higher percentage of disease modifying indications. However, we're basing this assessment on indications that appeared in DrugCentral and at least one other resource, so it's potentially biased.\r\n\r\n@pouyakhankhanian, if you are up for curating the 210 new indications as `DM`, `SYM`, or `NOT`, we could potentially:\r\n\r\n1. add these indications to a future release of PharmacotherapyDB\r\n2. use these indications to test our predictions",
      "comment_id": 1184,
      "profile_id": 17,
      "published": "2016-03-20T19:18:45.927561Z",
      "thread_id": 186,
      "url": "/discussion/incorporating-drugcentral-data-in-our-network/186#3"
    },
    {
      "body_html": "<h1>Pharmacologic Classes that are indications</h1>\r\n\r\n<p>We've noticed that many of the <a href=\"https://github.com/dhimmel/drugcentral/blob/e80a0c966a53ce48650d98069b126801c2793517/rephetio/classes.tsv\">pharmacologic classes</a> are essentially indications. This could be problematic since it could confound our classification approach. Specifically, it could lead to the appearance that our method predicts indications when in reality it just regurgitates indications which were encoded by a pharmacologic class.</p>\r\n\r\n<p>Some examples of classes that resemble indications are:</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>class_id</th><th>class_name</th><th>class_source</th><th>class_type</th></tr></thead><tbody><tr><td><a href=\"http://identifiers.org/chebi/CHEBI%3A35469\">CHEBI:35469</a></td><td>antidepressant</td><td>CHEBI</td><td>Application</td></tr><tr><td><a href=\"http://purl.bioontology.org/ontology/NDFRT/N0000175482\">N0000175482</a></td><td>Antimalarial</td><td>FDA</td><td>FDA Established Pharmacologic Class</td></tr><tr><td><a href=\"http://identifiers.org/mesh/D018501\">D018501</a></td><td>Antirheumatic Agents</td><td>MeSH</td><td>Pharmacological Action</td></tr></tbody></table>\r\n\r\n<p><a href=\"/u/sergiobaranzini\" class=\"username\">@sergiobaranzini</a> and I looked through the 6 sources and found that 3 were <strong>less problematic</strong>:</p>\r\n\r\n<ul><li>FDA — Chemical/Ingredient</li><li>FDA — Mechanism of Action</li><li>FDA — Physiologic Effect</li></ul>\r\n\r\n<p>The other 3 were <strong>more problematic</strong>:</p>\r\n\r\n<ul><li>FDA — Established Pharmacologic Class</li><li>MeSH — Pharmacological Action</li><li>CHEBI — Application</li></ul>\r\n\r\n<p>Therefore, I excluded classes from the 3 more problematic sources. This reduced the number of classes from 1,262 to 345, the number of edges from 10,959 to 1,029, and the number of compounds in a class from 1,423 to 724 (<a href=\"https://github.com/dhimmel/integrate/commit/1229536c6d2146c4cae97f045cf8cbdd272420f6\">commit</a>).</p>\r\n\r\n<p>One step would be to salvage many of the filtered classes by manual curation. The majority of the removed classes did not overlap with <a href=\"http://thinklab.com/discussion/unifying-disease-vocabularies/44#6\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d44\">DO Slim</a> diseases and thus shouldn't confound our analysis. If we decide to curate, we'll have to decide whether to exclude all indications or just indications in DO Slim.</p>",
      "body_md": "# Pharmacologic Classes that are indications\r\n\r\nWe've noticed that many of the [pharmacologic classes](https://github.com/dhimmel/drugcentral/blob/e80a0c966a53ce48650d98069b126801c2793517/rephetio/classes.tsv) are essentially indications. This could be problematic since it could confound our classification approach. Specifically, it could lead to the appearance that our method predicts indications when in reality it just regurgitates indications which were encoded by a pharmacologic class.\r\n\r\nSome examples of classes that resemble indications are:\r\n\r\n| class_id | class_name | class_source | class_type |\r\n|------------------|------------|--------------|---------------------|\r\n| [CHEBI:35469](http://identifiers.org/chebi/CHEBI%3A35469) | antidepressant | CHEBI | Application |\r\n| [N0000175482](http://purl.bioontology.org/ontology/NDFRT/N0000175482) | Antimalarial | FDA | FDA Established Pharmacologic Class |\r\n| [D018501](http://identifiers.org/mesh/D018501) | Antirheumatic Agents | MeSH | Pharmacological Action |\r\n\r\n@sergiobaranzini and I looked through the 6 sources and found that 3 were **less problematic**:\r\n\r\n+ FDA — Chemical/Ingredient\r\n+ FDA — Mechanism of Action\r\n+ FDA — Physiologic Effect\r\n\r\nThe other 3 were **more problematic**:\r\n\r\n+ FDA — Established Pharmacologic Class\r\n+ MeSH — Pharmacological Action\r\n+ CHEBI — Application\r\n\r\nTherefore, I excluded classes from the 3 more problematic sources. This reduced the number of classes from 1,262 to 345, the number of edges from 10,959 to 1,029, and the number of compounds in a class from 1,423 to 724 ([commit](https://github.com/dhimmel/integrate/commit/1229536c6d2146c4cae97f045cf8cbdd272420f6)).\r\n\r\nOne step would be to salvage many of the filtered classes by manual curation. The majority of the removed classes did not overlap with [DO Slim](http://thinklab.com/discussion/unifying-disease-vocabularies/44#6) diseases and thus shouldn't confound our analysis. If we decide to curate, we'll have to decide whether to exclude all indications or just indications in DO Slim.",
      "comment_id": 1185,
      "profile_id": 17,
      "published": "2016-03-24T00:57:39.774095Z",
      "thread_id": 186,
      "url": "/discussion/incorporating-drugcentral-data-in-our-network/186#4"
    },
    {
      "body_html": "<p>Our approach quantifies the hetnet topology between compound–disease pairs by calculating the prevalence of different path types (metapaths) <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1004259\">1</a>]</span>. We would like to be able to estimate the complexity of a metapath, given the graph. We'll define complexity as the number of Neo4j database hits (<code>dbhits</code>) needed to execute a query. Specifically, we're interested in  assessing the runtime of queries for a given metapath, without having to run the queries. </p>\r\n\r\n<p>If we can accurately predict runtime using estimated complexity, we can selectively avoid computing features for overly complex metapaths. Since the number of potential metapaths (as well as paths per metapath) scales combinatorially with increasing path length, our method will be always run into computational limits. We're hoping to use complexity estimates to help choose a tractable set of metpaths.</p>\r\n\r\n<h2>Metapath runtime on a trial feature extraction</h2>\r\n\r\n<p>In the past, we've used a length cutoff for metapaths. In a trial run of our feature extraction, I computed features for all metapaths with lengths 2–4. However, I terminated the process midway because progress was too slow. What we saw was that a few metapaths took a disproportionate amount of time to query.</p>\r\n\r\n<p>See <a href=\"http://nbviewer.jupyter.org/github/dhimmel/learn/blob/5c94a0b53d71f2ac0a2f48133a8e1d4e4e0ee26c/all-features-pyviz.ipynb#Time-per-query\">cells 11–12 in this notebook</a>, noting that ~half of metapaths with lengths 2–4 are missing and that paths with duplicate nodes were not excluded as they <a href=\"http://thinklab.com/discussion/path-exclusion-conditions/134#4\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d134\">should have been</a>. Nonetheless, the results are clear: the metapaths with long runtimes were only mildly predictive (<code>auroc</code>), did not decline in predictiveness due to <a href=\"http://thinklab.com/discussion/assessing-the-effectiveness-of-our-hetnet-permutations/178\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d178\">network permutation</a> (<code>delta_auroc</code>).</p>\r\n\r\n<p>The worst metapath was <em>CdGeAeGuD</em>, taking on average 37 seconds per query (compound–disease pair).  This metapath combines four gene-expression-based edges, which can be terribly high degree on their non-gene terminus.</p>\r\n\r\n<p>Hence, we will look into estimating metapath complexity to exclude such runtime outliers.</p>",
      "body_md": "Our approach quantifies the hetnet topology between compound--disease pairs by calculating the prevalence of different path types (metapaths) [@10.1371/journal.pcbi.1004259]. We would like to be able to estimate the complexity of a metapath, given the graph. We'll define complexity as the number of Neo4j database hits (`dbhits`) needed to execute a query. Specifically, we're interested in  assessing the runtime of queries for a given metapath, without having to run the queries. \r\n\r\nIf we can accurately predict runtime using estimated complexity, we can selectively avoid computing features for overly complex metapaths. Since the number of potential metapaths (as well as paths per metapath) scales combinatorially with increasing path length, our method will be always run into computational limits. We're hoping to use complexity estimates to help choose a tractable set of metpaths.\r\n\r\n## Metapath runtime on a trial feature extraction\r\n\r\nIn the past, we've used a length cutoff for metapaths. In a trial run of our feature extraction, I computed features for all metapaths with lengths 2--4. However, I terminated the process midway because progress was too slow. What we saw was that a few metapaths took a disproportionate amount of time to query.\r\n\r\nSee [cells 11--12 in this notebook](http://nbviewer.jupyter.org/github/dhimmel/learn/blob/5c94a0b53d71f2ac0a2f48133a8e1d4e4e0ee26c/all-features-pyviz.ipynb#Time-per-query), noting that ~half of metapaths with lengths 2--4 are missing and that paths with duplicate nodes were not excluded as they [should have been](http://thinklab.com/discussion/path-exclusion-conditions/134#4). Nonetheless, the results are clear: the metapaths with long runtimes were only mildly predictive (`auroc`), did not decline in predictiveness due to [network permutation](http://thinklab.com/discussion/assessing-the-effectiveness-of-our-hetnet-permutations/178) (`delta_auroc`).\r\n\r\nThe worst metapath was _CdGeAeGuD_, taking on average 37 seconds per query (compound--disease pair).  This metapath combines four gene-expression-based edges, which can be terribly high degree on their non-gene terminus.\r\n\r\nHence, we will look into estimating metapath complexity to exclude such runtime outliers.",
      "comment_id": 1186,
      "profile_id": 17,
      "published": "2016-03-22T17:03:53.425951Z",
      "thread_id": 187,
      "url": "/discussion/estimating-the-complexity-of-hetnet-traversal/187"
    },
    {
      "body_html": "<h1>Estimating the complexity of a sequential traversal</h1>\r\n\r\n<p>In sequential traversal, the query begins on a single node and expands to create a tree of paths conforming to the specified metapath. Once the tree has been fully expanded, only paths whose leaves match the desired ending node are retained.</p>\r\n\r\n<p>To estimate the sequential complexity of a metapath on a given graph, I first calculated the average degree of each metaedge based on our specific hetnet. Then, I took the log10 of the product of the average degrees along the path. Each metaedge contributes one degree: the average degree of whichever metanode is traversed first by the path. Since you can start a sequential traversal from either end of a path, we'll refer to forward versus backward sequential traversal.</p>\r\n\r\n<p><a href=\"/u/alizee\" class=\"username\">@alizee</a> proved to me in whiteboard discussion, that there is always a constant difference between the complexity of a forward and reverse sequential traversal, which is based only on the number of nodes of the source and target metanodes. The estimated complexity of a sequential traversal is less when starting on the node whose type is more abundant. I'll let <a href=\"/u/alizee\" class=\"username\">@alizee</a> explain the details.</p>\r\n\r\n<p>On the trial feature extraction, forward sequential complexity was a good estimator of runtime (<a href=\"http://nbviewer.jupyter.org/github/dhimmel/learn/blob/5c94a0b53d71f2ac0a2f48133a8e1d4e4e0ee26c/time.ipynb#sequential_complexity\" title=\"Disregard cells 14--15, which use a flawed method for computing join complexity\">notebook cell 13</a>). However, it's important to note that our Neo4j queries were not performed sequentially. Instead, traversal began from both termini and met in the middle where the results were joined. Even so, estimated sequential complexity may be a good metric to use for metapath selection.</p>",
      "body_md": "# Estimating the complexity of a sequential traversal\r\n\r\nIn sequential traversal, the query begins on a single node and expands to create a tree of paths conforming to the specified metapath. Once the tree has been fully expanded, only paths whose leaves match the desired ending node are retained.\r\n\r\nTo estimate the sequential complexity of a metapath on a given graph, I first calculated the average degree of each metaedge based on our specific hetnet. Then, I took the log10 of the product of the average degrees along the path. Each metaedge contributes one degree: the average degree of whichever metanode is traversed first by the path. Since you can start a sequential traversal from either end of a path, we'll refer to forward versus backward sequential traversal.\r\n\r\n@alizee proved to me in whiteboard discussion, that there is always a constant difference between the complexity of a forward and reverse sequential traversal, which is based only on the number of nodes of the source and target metanodes. The estimated complexity of a sequential traversal is less when starting on the node whose type is more abundant. I'll let @alizee explain the details.\r\n\r\nOn the trial feature extraction, forward sequential complexity was a good estimator of runtime ([notebook cell 13](http://nbviewer.jupyter.org/github/dhimmel/learn/blob/5c94a0b53d71f2ac0a2f48133a8e1d4e4e0ee26c/time.ipynb#sequential_complexity \"Disregard cells 14--15, which use a flawed method for computing join complexity\")). However, it's important to note that our Neo4j queries were not performed sequentially. Instead, traversal began from both termini and met in the middle where the results were joined. Even so, estimated sequential complexity may be a good metric to use for metapath selection.",
      "comment_id": 1187,
      "profile_id": 17,
      "published": "2016-03-22T17:31:44.934453Z",
      "thread_id": 187,
      "url": "/discussion/estimating-the-complexity-of-hetnet-traversal/187#2"
    },
    {
      "body_html": "<h1>A note on traversal complexity</h1>\r\n\r\n<h2>Intro</h2>\r\n\r\n<p>The question here is to estimate the complexity of graph traversal when following a 'metapath': a specification for which kind of nodes we need to traverse, in which order. This complexity will be useful to get a proxy for computation time when create the features we currently use in <em>rephetio</em> for prediction problems, the DWPC. We mainly look at sequential complexity, which is estimating complexity of traversal from one point to another, in only one direction, without joining two partial traversals in the middle. (even though the latter is almost always a better option)</p>\r\n\r\n<p>We can reasonably make the hypothesis that sequential complexity is equal to the number of possible paths that must be traversed. You propose above, and I would agree, that we use something along the <a href=\"https://en.wikipedia.org/wiki/Mean_field_theory\">mean-field approximation</a> and consider that the average number of paths to be traversed when following a Metapath is equal to the multiplication of the average degrees (outward connections) of all node types along the metapath. Doing so, we intrinsically base our analysis on the number of edges in the networks, which gives us some simple, neat properties.</p>\r\n\r\n<h2>Formal definition</h2>\r\n\r\n<p>We consider as an example 4 types of Nodes in our Network, <span class=\"math\">$$A, B, C, D$$</span>, linked with symmetrical edges, and the Metapath joining them <span class=\"math\">$$A-B-C-D$$</span>. We consider these nodes in order, since the difference between 'forward' (starting from <span class=\"math\">$$A$$</span>) and 'backward' (starting from <span class=\"math\">$$D$$</span>) traversal matters - as defined by <a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a> above. Each node type has respectively <span class=\"math\">$$N_A, N_B, N_C, N_D$$</span> nodes, noted  <span class=\"math\">$$A_i, B_j,$$</span>... Each of these single nodes has a forward degree, noted <span class=\"math\">$$a_i$$</span> for instance, and a backward degree, noted with a prime, eg <span class=\"math\">$$b_i'$$</span>. These degrees represent the number of edges that connect the node at stake (<span class=\"math\">$$A_i$$</span> and <span class=\"math\">$$B_i$$</span> in our examples) to the nodes of the next (<span class=\"math\">$$B$$</span>) or previous (<span class=\"math\">$$A$$</span>) types respectively.</p>\r\n\r\n<p>[remark: we use the actual types instead of a notation \"<span class=\"math\">$$K$$</span>\" for simplicity. The results that are written below for nodes of type <span class=\"math\">$$A$$</span> or <span class=\"math\">$$B$$</span> stand general]</p>\r\n\r\n<h2>Proof of the equivalence between forward and backward complexities</h2>\r\n\r\n<p>The average of node degree is written <span class=\"math\">$$E[a_i]$$</span> such as:</p>\r\n\r\n<div class=\"math\">$$$\r\n\\begin{align}\r\nE_{i\\in1,...,N_A}[a_i]=\\frac{1}{N_A}\\sum_{i\\in1,...,N_A}{a_i}\r\n\\end{align}\r\n$$$</div>\r\n\r\n<p>Then, we have</p>\r\n\r\n<div class=\"math\">$$$\r\n\\begin{align}\r\nE_{i\\in1,...,N_A}[a_i] \\cdot N_A = N_{A-B} = E_{i\\in1,...,N_B}[b_i'] \\cdot N_B \r\n\\end{align}\r\n$$$</div>\r\n\r\n<p>where <span class=\"math\">$$N_{A-B}$$</span> is the number of edges from the nodes <span class=\"math\">$$A$$</span> to <span class=\"math\">$$B$$</span>. Follows, in short notation: </p>\r\n\r\n<div class=\"math\">$$$\r\n\\begin{align}\r\nE[a_i] = E[b_i'] \\cdot \\frac{N_B} {N_A} \r\n\\quad or \\quad\r\nE[b_i'] = E[a_i] \\cdot \\frac{N_A} {N_B} \r\n\\end{align}\r\n$$$</div>\r\n\r\n<p>The estimation of 'forward complexity' outlined above, for discovering the paths that correspond to the metapath <span class=\"math\">$$A-B-C-D$$</span> is written as:</p>\r\n\r\n<div class=\"math\">$$$\r\n\\begin{equation}\r\nFC_{A-B-C-D} = E[a_i] \\cdot E[b_i] \\cdot E[c_i]\r\n\\end{equation}\r\n$$$</div>\r\n\r\n<p>The estimated backward complexity can be written as:</p>\r\n\r\n<div class=\"math\">$$$\r\n\\begin{align}\r\nBC_{A-B-C-D} = FC_{D-C-B-A} = E[b_i'] \\cdot E[c_i'] \\cdot E[d_i']\r\n\\end{align}\r\n$$$</div>\r\n\r\n<p>Follows:</p>\r\n\r\n<div class=\"math\">$$$\r\n\\begin{align}\r\nBC_{A-B-C-D} &amp;= E[b_i'] \\cdot E[c_i'] \\cdot E[d_i']\\\\\r\n &amp;= E[a_i]\\frac{N_A}{N_B} \\cdot E[b_i]\\frac{N_B}{N_C} \\cdot E[c_i]\\frac{N_C}{N_D}\\\\\r\n &amp;= E[a_i] \\cdot E[b_i]\\ \\cdot E[c_i] \\cdot \\frac{N_A}{N_D}\\\\\r\nBC_{A-B-C-D} &amp;= FC_{A-B-C-D} \\cdot \\frac{N_A}{N_D}\r\n\\end{align}\r\n$$$</div>\r\n\r\n<p>More generally:</p>\r\n\r\n<div class=\"math\">$$$\r\n\\begin{equation}\r\n\\boxed{BC = FC \\cdot \\frac{N_{START}}{N_{END}}}\r\n\\end{equation}\r\n$$$</div>\r\n\r\n<h2>All sequential complexities are made equal</h2>\r\n\r\n<p>Thus, forward and backward complexities are trivially related by the formula above. </p>\r\n\r\n<p><em>Nevertheless</em>, we need to keep in mind that the forward and backward complexity estimates above stand only for a single traversal, starting either from one Node <span class=\"math\">$$A_i$$</span> or <span class=\"math\">$$D_i$$</span> respectively. Thus, if you plan to do these traversals for all the <span class=\"math\">$$N_A \\cdot N_D $$</span> possible pairs (or a randomly selected subset of those) you need to multiply these complexities by the number of starting nodes, <span class=\"math\">$$N_A$$</span> or <span class=\"math\">$$N_D$$</span> in order to get a relevant time estimate. As a result of this computation and under these hypotheses, there is no difference between forward and backward traversal - which is reassuring.</p>\r\n\r\n<h2>Conclusion</h2>\r\n\r\n<ul><li>Forward and Backward Complexity estimates are trivially related through the formula above.</li><li>Time estimates should take into account the number of starting nodes, resulting in no difference between both directions of traversal.</li><li>About join complexity: I believe that the sequential complexity estimates discussed here are good proxies for the process of \"joint\" traversal, when two semi-traversals are joined in the middle in order to reduce computation time.</li></ul>",
      "body_md": "# A note on traversal complexity\r\n\r\n## Intro\r\n\r\nThe question here is to estimate the complexity of graph traversal when following a 'metapath': a specification for which kind of nodes we need to traverse, in which order. This complexity will be useful to get a proxy for computation time when create the features we currently use in _rephetio_ for prediction problems, the DWPC. We mainly look at sequential complexity, which is estimating complexity of traversal from one point to another, in only one direction, without joining two partial traversals in the middle. (even though the latter is almost always a better option)\r\n\r\nWe can reasonably make the hypothesis that sequential complexity is equal to the number of possible paths that must be traversed. You propose above, and I would agree, that we use something along the [mean-field approximation](https://en.wikipedia.org/wiki/Mean_field_theory) and consider that the average number of paths to be traversed when following a Metapath is equal to the multiplication of the average degrees (outward connections) of all node types along the metapath. Doing so, we intrinsically base our analysis on the number of edges in the networks, which gives us some simple, neat properties.\r\n\r\n## Formal definition\r\n\r\nWe consider as an example 4 types of Nodes in our Network, $$A, B, C, D$$, linked with symmetrical edges, and the Metapath joining them $$A-B-C-D$$. We consider these nodes in order, since the difference between 'forward' (starting from $$A$$) and 'backward' (starting from $$D$$) traversal matters - as defined by @dhimmel above. Each node type has respectively $$N_A, N_B, N_C, N_D$$ nodes, noted  $$A_i, B_j,$$... Each of these single nodes has a forward degree, noted $$a_i$$ for instance, and a backward degree, noted with a prime, eg $$b_i'$$. These degrees represent the number of edges that connect the node at stake ($$A_i$$ and $$B_i$$ in our examples) to the nodes of the next ($$B$$) or previous ($$A$$) types respectively.\r\n\r\n[remark: we use the actual types instead of a notation \"$$K$$\" for simplicity. The results that are written below for nodes of type $$A$$ or $$B$$ stand general]\r\n\r\n## Proof of the equivalence between forward and backward complexities\r\n\r\nThe average of node degree is written $$E[a_i]$$ such as:\r\n\r\n$$$\r\n\\begin{align}\r\nE_{i\\in1,...,N_A}[a_i]=\\frac{1}{N_A}\\sum_{i\\in1,...,N_A}{a_i}\r\n\\end{align}\r\n$$$\r\n\r\nThen, we have\r\n\r\n$$$\r\n\\begin{align}\r\nE_{i\\in1,...,N_A}[a_i] \\cdot N_A = N_{A-B} = E_{i\\in1,...,N_B}[b_i'] \\cdot N_B \r\n\\end{align}\r\n$$$\r\n\r\nwhere $$N_{A-B}$$ is the number of edges from the nodes $$A$$ to $$B$$. Follows, in short notation: \r\n\r\n$$$\r\n\\begin{align}\r\nE[a_i] = E[b_i'] \\cdot \\frac{N_B} {N_A} \r\n\\quad or \\quad\r\nE[b_i'] = E[a_i] \\cdot \\frac{N_A} {N_B} \r\n\\end{align}\r\n$$$\r\n\r\nThe estimation of 'forward complexity' outlined above, for discovering the paths that correspond to the metapath $$A-B-C-D$$ is written as:\r\n\r\n$$$\r\n\\begin{equation}\r\nFC_{A-B-C-D} = E[a_i] \\cdot E[b_i] \\cdot E[c_i]\r\n\\end{equation}\r\n$$$\r\n\r\nThe estimated backward complexity can be written as:\r\n\r\n$$$\r\n\\begin{align}\r\nBC_{A-B-C-D} = FC_{D-C-B-A} = E[b_i'] \\cdot E[c_i'] \\cdot E[d_i']\r\n\\end{align}\r\n$$$\r\n\r\nFollows:\r\n\r\n$$$\r\n\\begin{align}\r\nBC_{A-B-C-D} &= E[b_i'] \\cdot E[c_i'] \\cdot E[d_i']\\\\\r\n &= E[a_i]\\frac{N_A}{N_B} \\cdot E[b_i]\\frac{N_B}{N_C} \\cdot E[c_i]\\frac{N_C}{N_D}\\\\\r\n &= E[a_i] \\cdot E[b_i]\\ \\cdot E[c_i] \\cdot \\frac{N_A}{N_D}\\\\\r\nBC_{A-B-C-D} &= FC_{A-B-C-D} \\cdot \\frac{N_A}{N_D}\r\n\\end{align}\r\n$$$\r\n\r\nMore generally:\r\n\r\n$$$\r\n\\begin{equation}\r\n\\boxed{BC = FC \\cdot \\frac{N_{START}}{N_{END}}}\r\n\\end{equation}\r\n$$$\r\n\r\n## All sequential complexities are made equal\r\n\r\nThus, forward and backward complexities are trivially related by the formula above. \r\n\r\n*Nevertheless*, we need to keep in mind that the forward and backward complexity estimates above stand only for a single traversal, starting either from one Node $$A_i$$ or $$D_i$$ respectively. Thus, if you plan to do these traversals for all the $$N_A \\cdot N_D $$ possible pairs (or a randomly selected subset of those) you need to multiply these complexities by the number of starting nodes, $$N_A$$ or $$N_D$$ in order to get a relevant time estimate. As a result of this computation and under these hypotheses, there is no difference between forward and backward traversal - which is reassuring.\r\n\r\n## Conclusion\r\n\r\n+ Forward and Backward Complexity estimates are trivially related through the formula above.\r\n+ Time estimates should take into account the number of starting nodes, resulting in no difference between both directions of traversal.\r\n+ About join complexity: I believe that the sequential complexity estimates discussed here are good proxies for the process of \"joint\" traversal, when two semi-traversals are joined in the middle in order to reduce computation time.",
      "comment_id": 1191,
      "profile_id": 23,
      "published": "2016-03-23T17:19:48.764749Z",
      "thread_id": 187,
      "url": "/discussion/estimating-the-complexity-of-hetnet-traversal/187#3"
    },
    {
      "body_html": "<h1>The <a href=\"/u/alizee\" class=\"username\">@alizee</a> theorem of sequential complexity</h1>\r\n\r\n<p><a href=\"/u/alizee\" class=\"username\">@alizee</a>, fantastic proof! The takeaway for me is that if you're doing a sequential traversal from one source to one target, start from the end where there are a greater number of nodes. In situations where we are using sequential complexity to estimate runtime, we only have be consistent on reporting either forward or backward complexity.</p>",
      "body_md": "# The @alizee theorem of sequential complexity\r\n\r\n@alizee, fantastic proof! The takeaway for me is that if you're doing a sequential traversal from one source to one target, start from the end where there are a greater number of nodes. In situations where we are using sequential complexity to estimate runtime, we only have be consistent on reporting either forward or backward complexity.",
      "comment_id": 1203,
      "profile_id": 17,
      "published": "2016-03-31T00:13:13.028884Z",
      "thread_id": 187,
      "url": "/discussion/estimating-the-complexity-of-hetnet-traversal/187#4"
    },
    {
      "body_html": "<h1>A formula for estimating joint traversal complexity</h1>\r\n\r\n<p>Rather than perform traversals sequentially, both <a href=\"http://neo4j.com/docs/2.3.3/execution-plans-combining.html#query-plan-node-hash-join\" title=\"Node Hash Join in Neo4j\">Neo4j</a> and <a href=\"https://github.com/dhimmel/hetio/blob/2c135fcd32616d6979972105ba60b003d65c98bd/hetio/pathtools.py#L96\" title=\"hetio.pathtools.paths_between()\">hetio</a> support joint traversal. In joint traversal, paths are expanded upon from both endpoints until meeting at an interior node, where they are joined.</p>\r\n\r\n<p>Using <a href=\"/u/alizee\" class=\"username\">@alizee</a>'s notation <a href=\"#3\">above</a>, we'll consider metapath <span class=\"math\">$$A-B-C-D$$</span>. If we adopt a join index of 2 (joining on <em>C</em>), we compute joint complexity (<em>JC</em>) as:</p>\r\n\r\n<div class=\"math\">$$$\r\nJC_{A-B-C_{join}-D} = \\log _{10} (E[a_i] \\cdot E[b_i] + E[d_i'])\r\n$$$</div>\r\n\r\n<p>Note that <a href=\"/u/alizee\" class=\"username\">@alizee</a> didn't include the log, but for consistency with our reported complexity values, I'm including it. This proposed formula for complexity assumes that joining the traversals is a free operation. In Neo4j a <a href=\"(http://neo4j.com/docs/2.3.3/execution-plans-combining.html#query-plan-node-hash-join\" title=\"Node Hash Join in Neo4j\"><code>NodeHashJoin</code></a> doesn't require any dbhits, but could still add to runtime.</p>\r\n\r\n<p>When the join index is 0, the joint traversal becomes equivalent to backward traversal. When the join index is the target node, the joint traversal becomes equivalent to forward traversal.</p>",
      "body_md": "# A formula for estimating joint traversal complexity\r\n\r\nRather than perform traversals sequentially, both [Neo4j](http://neo4j.com/docs/2.3.3/execution-plans-combining.html#query-plan-node-hash-join \"Node Hash Join in Neo4j\") and [hetio](https://github.com/dhimmel/hetio/blob/2c135fcd32616d6979972105ba60b003d65c98bd/hetio/pathtools.py#L96 \"hetio.pathtools.paths_between()\") support joint traversal. In joint traversal, paths are expanded upon from both endpoints until meeting at an interior node, where they are joined.\r\n\r\nUsing @alizee's notation [above](#3), we'll consider metapath $$A-B-C-D$$. If we adopt a join index of 2 (joining on _C_), we compute joint complexity (_JC_) as:\r\n\r\n$$$\r\nJC_{A-B-C_{join}-D} = \\log _{10} (E[a_i] \\cdot E[b_i] + E[d_i'])\r\n$$$\r\n\r\nNote that @alizee didn't include the log, but for consistency with our reported complexity values, I'm including it. This proposed formula for complexity assumes that joining the traversals is a free operation. In Neo4j a [`NodeHashJoin`]((http://neo4j.com/docs/2.3.3/execution-plans-combining.html#query-plan-node-hash-join \"Node Hash Join in Neo4j\") doesn't require any dbhits, but could still add to runtime.\r\n\r\nWhen the join index is 0, the joint traversal becomes equivalent to backward traversal. When the join index is the target node, the joint traversal becomes equivalent to forward traversal.",
      "comment_id": 1204,
      "profile_id": 17,
      "published": "2016-03-31T00:37:47.170455Z",
      "thread_id": 187,
      "url": "/discussion/estimating-the-complexity-of-hetnet-traversal/187#5"
    },
    {
      "body_html": "<h1>Choosing the best join index for Neo4j queries</h1>\r\n\r\n<p>If you don't give Neo4j 2.3.2 any hints where to join, the planner decides for itself. The planner is capable of sequential or join traversal. However, which query plan to use is determined prior to query execution (see <a href=\"https://github.com/neo4j/neo4j/issues/6030\" title=\"GitHub Issue on whether the join index could be adaptively determined during Neo4j query execution\">my issue</a>). You can tell Neo4j which node to join on using a join hint (<code>USING JOIN ON</code> in Cypher). If you specify a terminal node to join on in 2.3.2, a sequential query will be executed, but Neo4j will decide for itself whether to do a forward or backward sequential join.</p>\r\n\r\n<p>Therefore, we wanted to see whether we could use our <a href=\"#5\">estimated join complexities</a> to optimize our Neo4j queries. Therefore we did a parameter sweep where we evaluated all possible join indexes when computing features (<em>DWPCs</em>) for 75 metapaths × 150 compound–disease pairs (<a href=\"https://github.com/dhimmel/learn/blob/92d89c9eaf54704968f7397fac38d3e7a2074ca5/optimize/join-index/sweep.ipynb\">notebook</a>). In total, we performed 66,600 queries.</p>\r\n\r\n<p>We consider three options for specifying the join index:</p>\r\n\r\n<ul><li><strong>midpoint index</strong> — the floor of the metapath length divided by two. Note if there were more diseases than compounds, then <a href=\"#3\">we expect</a> the ceiling would outperform the floor.</li><li><strong>optimal index</strong> — the least complex join index based on <a href=\"#5\">our formula</a> for estimating join complexity.</li><li><strong>no hint</strong> — where we let Neo4j choose the join index. The query planner will choose a join index, although we do not know which index was used.</li></ul>\r\n\r\n<p>For each metapath, we identified the average runtime of the three options (<a href=\"https://github.com/dhimmel/learn/blob/92d89c9eaf54704968f7397fac38d3e7a2074ca5/optimize/join-index/data/index-choice-by-metapath.tsv\">table</a>). While no option was universally fastest for all metapaths, on average the midpoint index was best (0.229 seconds), followed by the optimal index (0.339), and last no hint (0.656). In other words, specifying the midpoint as the join index cut runtime in third compared to not providing any join hint. Interestingly, our optimal complexity estimate performed ~50% worse than the midpoint overall.</p>\r\n\r\n<p>On an individual query level, the midpoint index was the fastest index for 40% of queries, while the optimal index was the fastest index for 29% of the queries. The average rank of the fastest join index according to our complexity estimate was 2.5.</p>\r\n\r\n<p>In conclusion, the optimal join index for a specific query is highly variable. For a given metapath, different compound–disease pairs will prefer different join indexes. However, since we plan to select a join index at the metapath level, the midpoint is the best option thus far.</p>",
      "body_md": "# Choosing the best join index for Neo4j queries\r\n\r\nIf you don't give Neo4j 2.3.2 any hints where to join, the planner decides for itself. The planner is capable of sequential or join traversal. However, which query plan to use is determined prior to query execution (see [my issue](https://github.com/neo4j/neo4j/issues/6030 \"GitHub Issue on whether the join index could be adaptively determined during Neo4j query execution\")). You can tell Neo4j which node to join on using a join hint (`USING JOIN ON` in Cypher). If you specify a terminal node to join on in 2.3.2, a sequential query will be executed, but Neo4j will decide for itself whether to do a forward or backward sequential join.\r\n\r\nTherefore, we wanted to see whether we could use our [estimated join complexities](#5) to optimize our Neo4j queries. Therefore we did a parameter sweep where we evaluated all possible join indexes when computing features (_DWPCs_) for 75 metapaths × 150 compound–disease pairs ([notebook](https://github.com/dhimmel/learn/blob/92d89c9eaf54704968f7397fac38d3e7a2074ca5/optimize/join-index/sweep.ipynb)). In total, we performed 66,600 queries.\r\n\r\nWe consider three options for specifying the join index:\r\n\r\n+ **midpoint index** -- the floor of the metapath length divided by two. Note if there were more diseases than compounds, then [we expect](#3) the ceiling would outperform the floor.\r\n+ **optimal index** -- the least complex join index based on [our formula](#5) for estimating join complexity.\r\n+ **no hint** -- where we let Neo4j choose the join index. The query planner will choose a join index, although we do not know which index was used.\r\n\r\nFor each metapath, we identified the average runtime of the three options ([table](https://github.com/dhimmel/learn/blob/92d89c9eaf54704968f7397fac38d3e7a2074ca5/optimize/join-index/data/index-choice-by-metapath.tsv)). While no option was universally fastest for all metapaths, on average the midpoint index was best (0.229 seconds), followed by the optimal index (0.339), and last no hint (0.656). In other words, specifying the midpoint as the join index cut runtime in third compared to not providing any join hint. Interestingly, our optimal complexity estimate performed ~50% worse than the midpoint overall.\r\n\r\nOn an individual query level, the midpoint index was the fastest index for 40% of queries, while the optimal index was the fastest index for 29% of the queries. The average rank of the fastest join index according to our complexity estimate was 2.5.\r\n\r\nIn conclusion, the optimal join index for a specific query is highly variable. For a given metapath, different compound–disease pairs will prefer different join indexes. However, since we plan to select a join index at the metapath level, the midpoint is the best option thus far.",
      "comment_id": 1205,
      "profile_id": 17,
      "published": "2016-03-31T02:09:04.916809Z",
      "thread_id": 187,
      "url": "/discussion/estimating-the-complexity-of-hetnet-traversal/187#6"
    },
    {
      "body_html": "<h1>Complexity poorly estimates runtime</h1>\r\n\r\n<p>We recently performed 22,933,125 <em>DWPC</em> queries (3,775 compound–disease pairs × 1,215 metapaths × 5 hetnets). For these queries, I specified the optimal join index according to our <a href=\"#5\">formula for join complexity</a>. In the future, we will switch to the midpoint join index.</p>\r\n\r\n<p>Both sequential complexity and optimal index join complexity poorly predicted runtime (<a href=\"http://nbviewer.jupyter.org/github/dhimmel/learn/blob/edb3cb68cb62e37ac426e39dc9196cfb279db2e7/optimize/time.ipynb\">notebook</a>). Many of the outlier metapaths appear to contain a <em>Gene→regulates→Gene</em> edge. Since, the target genes for these edges will largely <a href=\"http://thinklab.com/discussion/computing-consensus-transcriptional-profiles-for-lincs-l1000-perturbations/43#7\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d43\">be restricted</a> to the 978 landmark L1000 genes, I suspect mean degree is a underestimating complexity. One idea I've had is to weight the average degree calculation by degree to address this issue. In other words, should we account for the fact that queries are more likely to traverse high degree nodes when estimating complexity?</p>",
      "body_md": "# Complexity poorly estimates runtime\r\n\r\nWe recently performed 22,933,125 _DWPC_ queries (3,775 compound--disease pairs × 1,215 metapaths × 5 hetnets). For these queries, I specified the optimal join index according to our [formula for join complexity](#5). In the future, we will switch to the midpoint join index.\r\n\r\nBoth sequential complexity and optimal index join complexity poorly predicted runtime ([notebook](http://nbviewer.jupyter.org/github/dhimmel/learn/blob/edb3cb68cb62e37ac426e39dc9196cfb279db2e7/optimize/time.ipynb)). Many of the outlier metapaths appear to contain a _Gene→regulates→Gene_ edge. Since, the target genes for these edges will largely [be restricted](http://thinklab.com/discussion/computing-consensus-transcriptional-profiles-for-lincs-l1000-perturbations/43#7) to the 978 landmark L1000 genes, I suspect mean degree is a underestimating complexity. One idea I've had is to weight the average degree calculation by degree to address this issue. In other words, should we account for the fact that queries are more likely to traverse high degree nodes when estimating complexity?",
      "comment_id": 1206,
      "profile_id": 17,
      "published": "2016-03-31T02:42:11.987669Z",
      "thread_id": 187,
      "url": "/discussion/estimating-the-complexity-of-hetnet-traversal/187#7"
    },
    {
      "body_html": "<h1>Permission to reuse ADEPTUS</h1>\r\n\r\n<p>Now that our STARGEO <a href=\"http://thinklab.com/discussion/stargeo-expression-signatures-for-disease-using-crowdsourced-geo-annotation/96#10\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d96\">analysis is ready</a>, we're no longer including ADEPTUS in our hetnet. From STARGEO, we extracted differential expression signatures for 49 diseases, so integrating the signatures for the 3 diseases from ADEPTUS no longer made sense.</p>\r\n\r\n<p>However, on August 29, 2015 I emailed the authors requesting permission to reuse the ADEPTUS data as I did not see a license on their <a href=\"http://acgt.cs.tau.ac.il/adeptus/download.html\">website</a>. This was part of a <a href=\"http://thinklab.com/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#14\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d107\">broader effort</a> to try to comply with the copyrights and licenses of our sources.</p>\r\n\r\n<p>Today, David Amar responded stating that we have permission to use the datasets in question. Specifically, he noted that the publication itself <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkv810\" class=\"citation\" data-key=\"10.1093/nar/gkv810\">1</a>]</span> grants permission to use any of their results.</p>",
      "body_md": "# Permission to reuse ADEPTUS\r\n\r\nNow that our STARGEO [analysis is ready](http://thinklab.com/discussion/stargeo-expression-signatures-for-disease-using-crowdsourced-geo-annotation/96#10), we're no longer including ADEPTUS in our hetnet. From STARGEO, we extracted differential expression signatures for 49 diseases, so integrating the signatures for the 3 diseases from ADEPTUS no longer made sense.\r\n\r\nHowever, on August 29, 2015 I emailed the authors requesting permission to reuse the ADEPTUS data as I did not see a license on their [website](http://acgt.cs.tau.ac.il/adeptus/download.html). This was part of a [broader effort](http://thinklab.com/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#14) to try to comply with the copyrights and licenses of our sources.\r\n\r\nToday, David Amar responded stating that we have permission to use the datasets in question. Specifically, he noted that the publication itself [@10.1093/nar/gkv810] grants permission to use any of their results.",
      "comment_id": 1207,
      "profile_id": 17,
      "published": "2016-03-31T04:55:38.403207Z",
      "thread_id": 101,
      "url": "/discussion/the-adeptus-resource-for-expression-signatures-of-disease/101#2"
    },
    {
      "body_html": "<p>Our approach for hetnet edge prediction models the relationship between two nodes by extracting degree-weighted path counts (<em>DWPCs</em>) <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1004259\">1</a>]</span>. We use <em>DWPCs</em>, each corresponding to a different metapath, as the main features for a logistic regression classifier. Here we will investigate whether <em>DWPCs</em> should be transformed prior to being used as predictors.</p>\r\n\r\n<p>Below, we show the distribution of <em>DWPCs</em> for randomly selected metapaths, stratified by percent of non-zero values (<a href=\"https://github.com/dhimmel/learn/blob/becacbb47bed3346478a4c05beade44c165a22bd/all-features/transform.ipynb\">notebook</a>). We look at three metapaths for each non-zero quintile. These distributions are calculated from all positives (<em>Compound–treats–Disease</em> pairs) but only a small subset of negatives (4 times the # of positives). Since positives tend to be more connected than negatives, we expect the distribution for all compound–disease pairs to be even sparser. </p>\r\n\r\n<p><img src=\"https://github.com/dhimmel/learn/raw/becacbb47bed3346478a4c05beade44c165a22bd/all-features/media/DWPC-distribution.png\" alt=\"Raw DWPC distributions\" title=\"Facet strips note the non-zero quintile, metapath abbreviation, and non-zero percentage\"></p>\r\n\r\n<p>Note that the y-axis (histograms counts) is heavily transformed. The <em>DWPC</em> distribution is zero-inflated. The non-zero portion of the distribution has a long right tail, looking potentially lognormal.</p>\r\n\r\n<p>My concern is that these long-tailed distributions are suboptimal for linear modeling. For example, they lead to very few extremely high predictions at the expense of all other predictions. We <a href=\"http://het.io/disease-genes/browse/disease/?disease=DOID_12236\" title=\"Predictions for primary biliary cirrhosis\">observed this trend</a> when we used a <em>DWPC</em> approach for predictng gene–disease associations.</p>\r\n\r\n<p>This discussion will look into whether transforming <em>DWPCs</em> makes sense.</p>",
      "body_md": "Our approach for hetnet edge prediction models the relationship between two nodes by extracting degree-weighted path counts (_DWPCs_) [@10.1371/journal.pcbi.1004259]. We use _DWPCs_, each corresponding to a different metapath, as the main features for a logistic regression classifier. Here we will investigate whether _DWPCs_ should be transformed prior to being used as predictors.\r\n\r\nBelow, we show the distribution of _DWPCs_ for randomly selected metapaths, stratified by percent of non-zero values ([notebook](https://github.com/dhimmel/learn/blob/becacbb47bed3346478a4c05beade44c165a22bd/all-features/transform.ipynb)). We look at three metapaths for each non-zero quintile. These distributions are calculated from all positives (_Compound--treats--Disease_ pairs) but only a small subset of negatives (4 times the # of positives). Since positives tend to be more connected than negatives, we expect the distribution for all compound--disease pairs to be even sparser. \r\n\r\n![Raw DWPC distributions](https://github.com/dhimmel/learn/raw/becacbb47bed3346478a4c05beade44c165a22bd/all-features/media/DWPC-distribution.png \"Facet strips note the non-zero quintile, metapath abbreviation, and non-zero percentage\")\r\n\r\nNote that the y-axis (histograms counts) is heavily transformed. The _DWPC_ distribution is zero-inflated. The non-zero portion of the distribution has a long right tail, looking potentially lognormal.\r\n\r\nMy concern is that these long-tailed distributions are suboptimal for linear modeling. For example, they lead to very few extremely high predictions at the expense of all other predictions. We [observed this trend](http://het.io/disease-genes/browse/disease/?disease=DOID_12236 \"Predictions for primary biliary cirrhosis\") when we used a _DWPC_ approach for predictng gene--disease associations.\r\n\r\nThis discussion will look into whether transforming _DWPCs_ makes sense.",
      "comment_id": 1208,
      "profile_id": 17,
      "published": "2016-04-01T21:13:21.147431Z",
      "thread_id": 193,
      "url": "/discussion/transforming-dwpcs-for-hetnet-edge-prediction/193"
    },
    {
      "body_html": "<h1>Inverse hyperbolic sine transformation</h1>\r\n\r\n<p>One option is to use the inverse hyperbolic sine (IHS) transformation <span class=\"citation\">[<a href=\"https://doi.org/10.2307/2288929\" class=\"citation\" data-key=\"10.2307/2288929\">1</a>, <a href=\"https://doi.org/10.2307/2332539\" class=\"citation\" data-key=\"10.2307/2332539\">2</a>]</span>. The IHS transformation has <a href=\"http://worthwhile.typepad.com/worthwhile_canadian_initi/2011/07/a-rant-on-inverse-hyperbolic-sine-transformations.html\" title=\"A rant on inverse hyperbolic sine transformations\">nice properties</a>. Foremost, it's zero preserving and easy to implement. It has a single parameter, <em>θ</em> that controls to what extent values are pulled towards 0. Here's an R implementation:</p>\r\n\r\n<pre><code class=\"r\">ihs_transform &lt;- function(x, theta = 1) {\r\n  # Inverse Hyperbolic Sine transformation\r\n  return(asinh(theta * x) / theta)\r\n}</code></pre>\r\n\r\n<p>This implementation can be easily ported to Python by replacing <a href=\"https://stat.ethz.ch/R-manual/R-devel/library/base/html/Hyperbolic.html\"><code>asinh</code></a> with <a href=\"http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.arcsinh.html\"><code>numpy.arcsinh</code></a>.</p>\r\n\r\n<p>Now many applications, where the values extend into the natural number range, will do fine with the default <em>θ</em> = 1. However, since <em>DWPCs</em> tend to be very small numbers, the IHS transformation will have a negligible effect unless we increase <em>θ</em>.</p>\r\n\r\n<p>Others have discussed choosing <em>θ</em> to <a href=\"http://stats.stackexchange.com/a/79109/74908\">achieve normality</a> using <a href=\"http://stats.stackexchange.com/a/26373/74908\">maximum likelihood</a>. There is also a recent R package <a href=\"https://cran.r-project.org/web/packages/ihs/index.html\"><code>ihs</code></a> that could be useful.</p>\r\n\r\n<p>So the question becomes, what exactly do we want our transformation to do? Should we base the fitting of <em>θ</em> only on the non-zero <em>DWPCs</em> or on all <em>DWPCs</em>. Should we use an efficient and simple heuristic to fit <em>θ</em> or should we go with a more intense likelihood method?</p>",
      "body_md": "# Inverse hyperbolic sine transformation\r\n\r\nOne option is to use the inverse hyperbolic sine (IHS) transformation [@10.2307/2288929 @10.2307/2332539]. The IHS transformation has [nice properties](http://worthwhile.typepad.com/worthwhile_canadian_initi/2011/07/a-rant-on-inverse-hyperbolic-sine-transformations.html \"A rant on inverse hyperbolic sine transformations\"). Foremost, it's zero preserving and easy to implement. It has a single parameter, _θ_ that controls to what extent values are pulled towards 0. Here's an R implementation:\r\n\r\n```r\r\nihs_transform <- function(x, theta = 1) {\r\n  # Inverse Hyperbolic Sine transformation\r\n  return(asinh(theta * x) / theta)\r\n}\r\n```\r\n\r\nThis implementation can be easily ported to Python by replacing [`asinh`](https://stat.ethz.ch/R-manual/R-devel/library/base/html/Hyperbolic.html) with [`numpy.arcsinh`](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.arcsinh.html).\r\n\r\nNow many applications, where the values extend into the natural number range, will do fine with the default _θ_ = 1. However, since _DWPCs_ tend to be very small numbers, the IHS transformation will have a negligible effect unless we increase _θ_.\r\n\r\nOthers have discussed choosing _θ_ to [achieve normality](http://stats.stackexchange.com/a/79109/74908) using [maximum likelihood](http://stats.stackexchange.com/a/26373/74908). There is also a recent R package [`ihs`](https://cran.r-project.org/web/packages/ihs/index.html) that could be useful.\r\n\r\nSo the question becomes, what exactly do we want our transformation to do? Should we base the fitting of _θ_ only on the non-zero _DWPCs_ or on all _DWPCs_. Should we use an efficient and simple heuristic to fit _θ_ or should we go with a more intense likelihood method?",
      "comment_id": 1209,
      "profile_id": 17,
      "published": "2016-04-01T21:35:20.632708Z",
      "thread_id": 193,
      "url": "/discussion/transforming-dwpcs-for-hetnet-edge-prediction/193#2"
    },
    {
      "body_html": "<p>Overall I'd say arcsin is a fine function. But to achieve your stated goals, I wonder why you didn't just use a log transformation? </p>\r\n\r\n<p>To achieve goal<br>1.zero preserving<br>2. easy to implement</p>\r\n\r\n<p>x -&gt; log(x+1)</p>\r\n\r\n<p>To acheive a third goal<br>3. has a \"theta\" value that could be use to \"pull\" values toward zero</p>\r\n\r\n<p>x-&gt; log(ax+1) / a</p>\r\n\r\n<p>The arsinh, as you know, is a linear derivative of the exponential function. And thus the inverse of this is a derivative of the log. So I guess it's unclear why you chose a derivative rather than the actual.</p>",
      "body_md": "Overall I'd say arcsin is a fine function. But to achieve your stated goals, I wonder why you didn't just use a log transformation? \r\n\r\nTo achieve goal\r\n1.zero preserving\r\n2. easy to implement\r\n\r\nx -> log(x+1)\r\n\r\nTo acheive a third goal\r\n3. has a \"theta\" value that could be use to \"pull\" values toward zero\r\n\r\nx-> log(ax+1) / a\r\n\r\nThe arsinh, as you know, is a linear derivative of the exponential function. And thus the inverse of this is a derivative of the log. So I guess it's unclear why you chose a derivative rather than the actual.",
      "comment_id": 1211,
      "profile_id": 188,
      "published": "2016-04-02T15:31:03.700466Z",
      "thread_id": 193,
      "url": "/discussion/transforming-dwpcs-for-hetnet-edge-prediction/193#3"
    },
    {
      "body_html": "<h1>Log versus IHS transformation</h1>\r\n\r\n<p><a href=\"/u/pouyakhankhanian\" class=\"username\">@pouyakhankhanian</a>, originally I stayed away from <code>log1p</code> because because it's <a href=\"https://www.wolframalpha.com/input/?i=log(x+%2B+1)+between+0+and+1\" title=\"log(x + 1) between 0 and 1 · WolframAlpha\">practically linear</a> across the range of our <em>DWPCs</em>. You bring up a good point regarding scaling <em>DWPCs</em> prior to transformation.</p>\r\n\r\n<p>Yesterday, <a href=\"/u/alizee\" class=\"username\">@alizee</a> and I looked into scaling <em>DWPCs</em> before transformation. This would eliminate the need to fit <em>θ</em>: we could use <em>θ</em> = 1 for both the log and IHS transforms. For example, if <code>x</code> is the vector of <em>DWPCs</em> for a single feature, we could transform using:</p>\r\n\r\n<pre><code class=\"r\"># Standard deviation scaling\r\nx_scale = sd(x)\r\n\r\n# Mean absolute deviation scaling\r\nx_scale = mad(x, center = mean(x))\r\n\r\n# Mean scaling\r\nx_scale = mean(x)\r\n\r\n# Scale\r\nx_scaled = x / x_scale\r\n\r\n# Inverse hyperbolic sine transform\r\nasinh(x_scaled)\r\n\r\n# Log transform\r\nlog1p(x_scaled)</code></pre>\r\n\r\n<p>I think we should choose between the log and IHS methods based on which gives better performance. Regarding choosing a derivative rather than the actual, I don't view one as inherently superior, especially since the IHS has better transformation properties than the log, such as handling negatives (although this isn't an issue here).</p>\r\n\r\n<p>I think we should also use performance to choose the scaling method, but with a preference for standard deviation scaling since <a href=\"/u/alizee\" class=\"username\">@alizee</a> thinks it the most versatile method.</p>",
      "body_md": "# Log versus IHS transformation\r\n\r\n@pouyakhankhanian, originally I stayed away from `log1p` because because it's [practically linear](https://www.wolframalpha.com/input/?i=log(x+%2B+1)+between+0+and+1 \"log(x + 1) between 0 and 1 · WolframAlpha\") across the range of our _DWPCs_. You bring up a good point regarding scaling _DWPCs_ prior to transformation.\r\n\r\nYesterday, @alizee and I looked into scaling _DWPCs_ before transformation. This would eliminate the need to fit _θ_: we could use _θ_ = 1 for both the log and IHS transforms. For example, if `x` is the vector of _DWPCs_ for a single feature, we could transform using:\r\n\r\n```r\r\n# Standard deviation scaling\r\nx_scale = sd(x)\r\n\r\n# Mean absolute deviation scaling\r\nx_scale = mad(x, center = mean(x))\r\n\r\n# Mean scaling\r\nx_scale = mean(x)\r\n\r\n# Scale\r\nx_scaled = x / x_scale\r\n\r\n# Inverse hyperbolic sine transform\r\nasinh(x_scaled)\r\n\r\n# Log transform\r\nlog1p(x_scaled)\r\n```\r\n\r\nI think we should choose between the log and IHS methods based on which gives better performance. Regarding choosing a derivative rather than the actual, I don't view one as inherently superior, especially since the IHS has better transformation properties than the log, such as handling negatives (although this isn't an issue here).\r\n\r\nI think we should also use performance to choose the scaling method, but with a preference for standard deviation scaling since @alizee thinks it the most versatile method.",
      "comment_id": 1212,
      "profile_id": 17,
      "published": "2016-04-02T19:05:58.165957Z",
      "thread_id": 193,
      "url": "/discussion/transforming-dwpcs-for-hetnet-edge-prediction/193#4"
    },
    {
      "body_html": "<h1>Replacing MSigDB with Pathway Commons</h1>\r\n\r\n<p>Due to <a href=\"http://thinklab.com/discussion/msigdb-licensing/108\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d108\">licensing issues with MSigDB</a>, we've removed MSigDB pathways and switched to Pathway Commons as <a href=\"/u/alexanderpico\" class=\"username\">@alexanderpico</a> <a href=\"#1\">initially suggested</a>. <a href=\"http://www.pathwaycommons.org/pc2/\" title=\"Pathway Commons 2\">Pathway Commons</a> aggregates pathway and binary interaction data from <a href=\"http://www.pathwaycommons.org/pc2/datasources\">many providers</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkq1039\" class=\"citation\" data-key=\"10.1093/nar/gkq1039\">1</a>]</span>.</p>\r\n\r\n<p>Pathway Commons data is <a href=\"https://github.com/dhimmel/integrate/blob/e0d90e389c017dddacd98189d80ec1ffe3223c9b/licenses/custom/PathwayCommons.md\">freely available</a>, but the data is licensed under the terms of each contributing database. For example, Pathway Commons includes KEGG pathways, which have a <a href=\"https://github.com/dhimmel/integrate/blob/e0d90e389c017dddacd98189d80ec1ffe3223c9b/licenses/custom/KEGG.md\">problematic license</a>. Accordingly, we only include pathways from Pathway Commons resources that are openly licensed.</p>\r\n\r\n<p>Specifically, I identified only two appropriate resources from the 8 Pathway Commons resources that contribute pathways (see <a href=\"https://github.com/dhimmel/pathways/blob/1bd2c68853e38297d20f8f885419ff81fc0608a8/merge-resources.ipynb\">notebook</a> cell 7). These resources were <a href=\"http://www.reactome.org/\">Reactome</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkv1351\" class=\"citation\" data-key=\"10.1093/nar/gkv1351\">2</a>]</span> and the <a href=\"http://pid.nci.nih.gov/\">Pathway Interaction Database</a> (PID) <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkn653\" class=\"citation\" data-key=\"10.1093/nar/gkn653\">3</a>]</span>. Reactome is licensed as CC BY, while I believe PID data is in the public domain since it was created by US Government employees. At least the PID publication states, \"All data in PID is freely available, without restriction on use. <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkn653\" class=\"citation\" data-key=\"10.1093/nar/gkn653\">3</a>]</span>\" Since Reactome and PID contributed the <a href=\"#6\">majority of MSigDB pathways</a>, I suspect that we didn't lose much information by abandoning MSigDB.</p>\r\n\r\n<p>Ultimately, our updated compilation of human gene sets (<code>dhimmel/pathways v2.0</code> <span class=\"citation\">[<a href=\"https://doi.org/10.5281/zenodo.48810\" class=\"citation\" data-key=\"10.5281/zenodo.48810\">4</a>]</span>) contains 1,862 human pathways of which 1,341 are from Reactome, 298 are from WikiPathways, and 223 are from the PID.</p>",
      "body_md": "# Replacing MSigDB with Pathway Commons\r\n\r\nDue to [licensing issues with MSigDB](http://thinklab.com/discussion/msigdb-licensing/108), we've removed MSigDB pathways and switched to Pathway Commons as @alexanderpico [initially suggested](#1). [Pathway Commons](http://www.pathwaycommons.org/pc2/ \"Pathway Commons 2\") aggregates pathway and binary interaction data from [many providers](http://www.pathwaycommons.org/pc2/datasources) [@10.1093/nar/gkq1039].\r\n\r\nPathway Commons data is [freely available](https://github.com/dhimmel/integrate/blob/e0d90e389c017dddacd98189d80ec1ffe3223c9b/licenses/custom/PathwayCommons.md), but the data is licensed under the terms of each contributing database. For example, Pathway Commons includes KEGG pathways, which have a [problematic license](https://github.com/dhimmel/integrate/blob/e0d90e389c017dddacd98189d80ec1ffe3223c9b/licenses/custom/KEGG.md). Accordingly, we only include pathways from Pathway Commons resources that are openly licensed.\r\n\r\nSpecifically, I identified only two appropriate resources from the 8 Pathway Commons resources that contribute pathways (see [notebook](https://github.com/dhimmel/pathways/blob/1bd2c68853e38297d20f8f885419ff81fc0608a8/merge-resources.ipynb) cell 7). These resources were [Reactome](http://www.reactome.org/) [@10.1093/nar/gkv1351] and the [Pathway Interaction Database](http://pid.nci.nih.gov/) (PID) [@10.1093/nar/gkn653]. Reactome is licensed as CC BY, while I believe PID data is in the public domain since it was created by US Government employees. At least the PID publication states, \"All data in PID is freely available, without restriction on use. [@10.1093/nar/gkn653]\" Since Reactome and PID contributed the [majority of MSigDB pathways](#6), I suspect that we didn't lose much information by abandoning MSigDB.\r\n\r\nUltimately, our updated compilation of human gene sets (`dhimmel/pathways v2.0` [@10.5281/zenodo.48810]) contains 1,862 human pathways of which 1,341 are from Reactome, 298 are from WikiPathways, and 223 are from the PID.",
      "comment_id": 1213,
      "profile_id": 17,
      "published": "2016-04-02T22:16:02.980687Z",
      "thread_id": 72,
      "url": "/discussion/adding-pathway-resources-to-your-network/72#11"
    },
    {
      "body_html": "<h1>Removing MSigDB from the Rephetio project</h1>\r\n\r\n<p>I removed MSigDB from our project, since we haven't been able to resolve the licensing issues. It's been 186 days since we initially contacted the MSigDB team and 53 days since we were told that the IP/Licensing team had been notified and a meeting scheduled. Unfortunately, we can't wait any longer.</p>\r\n\r\n<p>There are a few distinctions that make MSigDB distinct from <a href=\"http://thinklab.com/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#14\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d107\">other resources</a> where permission is pending but we continue to include. MSigDB is the <a href=\"https://github.com/dhimmel/integrate/blob/daefe6e3e9a44b9fdc85cb79cee597927f119559/licenses/README.md\" title=\"Table of licenses for all sources\">only resource</a> with a license that explicitly forbids distribution. Additionally, the MSigDB website requires <a href=\"http://software.broadinstitute.org/gsea/register.jsp\">registration</a>, although accessing the database by URL bypasses registration.</p>\r\n\r\n<p>Registration makes the license into a legally binding agreement. Essentially, the registration acts as a contract, which can place additional restrictions beyond copyright. As an aside, I therefore find it misleading that the <a href=\"http://software.broadinstitute.org/gsea/msigdb\">website</a> states:</p>\r\n\r\n<blockquote><p>Registration is free. Its only purpose is to help us track usage for reports to our funding agencies.</p></blockquote>\r\n\r\n<p>Specifically, <a href=\"https://github.com/dhimmel/integrate/blob/daefe6e3e9a44b9fdc85cb79cee597927f119559/licenses/custom/MSigDB.asciidoc\" title=\"MSigDB License\">the license</a> contains several troubling components. First is a reporting requirement for modifications and bug fixes:</p>\r\n\r\n<blockquote><p>modifications and BUG FIXES shall be provided to MIT promptly upon their creation.</p></blockquote>\r\n\r\n<p>While this reporting requirement only applies to the program, which we don't use, a different reporting requirement applies to database:</p>\r\n\r\n<blockquote><p>As consideration for the licenses granted in this Agreement, LICENSEE agrees to provide … a written evaluation of the PROGRAM and the DATABASE, including a description of its functionality or problems and areas for further improvement in the PROGRAM or the DATABASE.</p></blockquote>\r\n\r\n<p>The license is very clear that distribution is prohibited. In fact, uploading the database to a private cloud service appears to violate the license:</p>\r\n\r\n<blockquote><p>2.2 No Sublicensing or Additional Rights. In no event shall LICENSEE sublicense or distribute, in whole or in part, the PROGRAM, modifications, BUG FIXES, or the DATABASE, without prior permission from MIT. LICENSEE agrees not to allow any non-employee of LICENSEE to access, view, or use the PROGRAM or the DATABASE, unless such person is an independent contractor performing services on behalf of LICENSEE. LICENSEE agrees not to put the PROGRAM or the DATABASE on a network, server, or other similar technology that may be accessed by any individual other than the LICENSEE.</p></blockquote>\r\n\r\n<p>As a result, using MSigDB as part of extensible open science project is not possible.</p>\r\n\r\n<h2>Remedial action</h2>\r\n\r\n<p>I removed MSigDB from our hetnet (<a href=\"https://github.com/dhimmel/integrate/commit/daefe6e3e9a44b9fdc85cb79cee597927f119559\">commit</a>). Our hetnet no longer contains perturbation gene sets, which were from the <code>C2:CGP</code> collection. I <a href=\"http://thinklab.com/discussion/adding-pathway-resources-to-your-network/72#11\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d72\">replaced</a> the MSigDB pathways (<code>C2:CP</code> collection) using <a href=\"http://www.pathwaycommons.org/\">Pathway Commons</a>. Both Pathway Commons and MSigDB include data from Reactome and the PID, but by going through Pathway Commons we were able to release those resources as CC BY and CC0.</p>\r\n\r\n<p>I deleted my GitHub repository, formerly <a href=\"https://github.com/dhimmel/msigdb\"><code>dhimmel/msigdb</code></a>, for converting the database into a single user-friendly TSV. Our <a href=\"http://het.io/disease-genes/downloads/\">website</a> for a previous project contains a hetnet including MSigDB 3.0, which I posted before being aware of the licensing issue. Since this hetnet is the foundation of our prior study <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1004259\">1</a>]</span>, taking it offline would be problematic for reproducibility and destructive to science. Therefore, I am not taking down this dataset unless specifically requested.</p>\r\n\r\n<p>Finally, I removed the following two paragraphs from our project report draft. I'll let them serve as a eulogy:</p>\r\n\r\n<blockquote><p>Pathways were extracted by combining human pathways from <a href=\"http://www.wikipathways.org/\">WikiPathways</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkv1024\" class=\"citation\" data-key=\"10.1093/nar/gkv1024\">2</a>, <a href=\"https://doi.org/10.1371/journal.pbio.0060184\" class=\"citation\" data-key=\"10.1371/journal.pbio.0060184\">3</a>]</span> and MSigDB version 5.1 <span class=\"citation\">[<a href=\"https://doi.org/10.1073/pnas.0506580102\" class=\"citation\" data-key=\"10.1073/pnas.0506580102\">4</a>, <a href=\"https://doi.org/10.1093/bioinformatics/btr260\" class=\"citation\" data-key=\"10.1093/bioinformatics/btr260\">5</a>]</span>. Perturbations were extracted from MSigDB. Each perturbation corresponds to a differential expression experiment of a chemical or genetic perturbation.</p><p><em>Perturbation–regulates–Gene</em> edges are from MSigDB <span class=\"citation\">[<a href=\"https://doi.org/10.1073/pnas.0506580102\" class=\"citation\" data-key=\"10.1073/pnas.0506580102\">4</a>, <a href=\"https://doi.org/10.1093/bioinformatics/btr260\" class=\"citation\" data-key=\"10.1093/bioinformatics/btr260\">5</a>]</span>. These edges represent groups of genes that responded in the same direction to a chemical or genetic perturbation. Our previous project found this indiscriminate, automated, and high-throughput method produced gene sets that together were highly informative for predicting disease–gene associations <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004743\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1004743\">6</a>]</span>.</p></blockquote>\r\n\r\n<h2>Reflections</h2>\r\n\r\n<p>One issue at play is the restrictive licensing of resources that MSigDB integrates. For example, KEGG <a href=\"https://github.com/dhimmel/integrate/blob/daefe6e3e9a44b9fdc85cb79cee597927f119559/licenses/custom/KEGG.md\">requires</a> academic services to obtain a <a href=\"http://www.bioinformatics.jp/docs/subscription_organizational.pdf\">subscription</a>, which stipulates that:</p>\r\n\r\n<blockquote><p>Your Product or Service must not allow Your users to obtain KEGG FTP Data, except in small quantities.</p></blockquote>\r\n\r\n<p>Hence, portions of the MSigDB dataset do have to be licensed to forbid redistribution. Nevertheless, MIT went beyond these upstream restrictions when writing the MSigDB license. First, much of the database could likely be released openly. Second, I find the reporting requirements extreme. It's possible that MIT had a financial motivation when writing the license, as it states:</p>\r\n\r\n<blockquote><p>LICENSEE agrees that neither the PROGRAM nor the DATABASE shall be used as the basis of a commercial software or hardware product</p></blockquote>\r\n\r\n<p>I think the MSigDB team deserves credit for making their comprehensive compilation of gene sets public. However, given the <a href=\"http://grantome.com/grant/NIH/R01-CA121941-10\" title=\"See Related projects on Grantome\">extent of public funding</a> this project has received, I question whether it's ethical for MIT to apply such a problematic license.</p>\r\n\r\n<p>Finally I'm not deflecting responsibility: I'm the one who included a resource whose license forbids redistribution. While scientists are often poorly informed on the legality of data reuse, I think it's important to take responsibility for educating yourself. Going forward I will address licensing issues before using a new dataset to avoid similar problems.</p>",
      "body_md": "# Removing MSigDB from the Rephetio project\r\n\r\nI removed MSigDB from our project, since we haven't been able to resolve the licensing issues. It's been 186 days since we initially contacted the MSigDB team and 53 days since we were told that the IP/Licensing team had been notified and a meeting scheduled. Unfortunately, we can't wait any longer.\r\n\r\nThere are a few distinctions that make MSigDB distinct from [other resources](http://thinklab.com/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#14) where permission is pending but we continue to include. MSigDB is the [only resource](https://github.com/dhimmel/integrate/blob/daefe6e3e9a44b9fdc85cb79cee597927f119559/licenses/README.md \"Table of licenses for all sources\") with a license that explicitly forbids distribution. Additionally, the MSigDB website requires [registration](http://software.broadinstitute.org/gsea/register.jsp), although accessing the database by URL bypasses registration.\r\n\r\nRegistration makes the license into a legally binding agreement. Essentially, the registration acts as a contract, which can place additional restrictions beyond copyright. As an aside, I therefore find it misleading that the [website](http://software.broadinstitute.org/gsea/msigdb) states:\r\n\r\n> Registration is free. Its only purpose is to help us track usage for reports to our funding agencies.\r\n\r\nSpecifically, [the license](https://github.com/dhimmel/integrate/blob/daefe6e3e9a44b9fdc85cb79cee597927f119559/licenses/custom/MSigDB.asciidoc \"MSigDB License\") contains several troubling components. First is a reporting requirement for modifications and bug fixes:\r\n\r\n> modifications and BUG FIXES shall be provided to MIT promptly upon their creation.\r\n\r\nWhile this reporting requirement only applies to the program, which we don't use, a different reporting requirement applies to database:\r\n\r\n> As consideration for the licenses granted in this Agreement, LICENSEE agrees to provide … a written evaluation of the PROGRAM and the DATABASE, including a description of its functionality or problems and areas for further improvement in the PROGRAM or the DATABASE.\r\n\r\nThe license is very clear that distribution is prohibited. In fact, uploading the database to a private cloud service appears to violate the license:\r\n\r\n> 2.2 No Sublicensing or Additional Rights. In no event shall LICENSEE sublicense or distribute, in whole or in part, the PROGRAM, modifications, BUG FIXES, or the DATABASE, without prior permission from MIT. LICENSEE agrees not to allow any non-employee of LICENSEE to access, view, or use the PROGRAM or the DATABASE, unless such person is an independent contractor performing services on behalf of LICENSEE. LICENSEE agrees not to put the PROGRAM or the DATABASE on a network, server, or other similar technology that may be accessed by any individual other than the LICENSEE.\r\n\r\nAs a result, using MSigDB as part of extensible open science project is not possible.\r\n\r\n## Remedial action\r\n\r\nI removed MSigDB from our hetnet ([commit](https://github.com/dhimmel/integrate/commit/daefe6e3e9a44b9fdc85cb79cee597927f119559)). Our hetnet no longer contains perturbation gene sets, which were from the `C2:CGP` collection. I [replaced](http://thinklab.com/discussion/adding-pathway-resources-to-your-network/72#11) the MSigDB pathways (`C2:CP` collection) using [Pathway Commons](http://www.pathwaycommons.org/). Both Pathway Commons and MSigDB include data from Reactome and the PID, but by going through Pathway Commons we were able to release those resources as CC BY and CC0.\r\n\r\nI deleted my GitHub repository, formerly [`dhimmel/msigdb`](https://github.com/dhimmel/msigdb), for converting the database into a single user-friendly TSV. Our [website](http://het.io/disease-genes/downloads/) for a previous project contains a hetnet including MSigDB 3.0, which I posted before being aware of the licensing issue. Since this hetnet is the foundation of our prior study [@10.1371/journal.pcbi.1004259], taking it offline would be problematic for reproducibility and destructive to science. Therefore, I am not taking down this dataset unless specifically requested.\r\n\r\nFinally, I removed the following two paragraphs from our project report draft. I'll let them serve as a eulogy:\r\n\r\n> Pathways were extracted by combining human pathways from [WikiPathways](http://www.wikipathways.org/) [@10.1093/nar/gkv1024 @10.1371/journal.pbio.0060184] and MSigDB version 5.1 [@10.1073/pnas.0506580102 @10.1093/bioinformatics/btr260]. Perturbations were extracted from MSigDB. Each perturbation corresponds to a differential expression experiment of a chemical or genetic perturbation.\r\n\r\n> _Perturbation–regulates–Gene_ edges are from MSigDB [@10.1073/pnas.0506580102 @10.1093/bioinformatics/btr260]. These edges represent groups of genes that responded in the same direction to a chemical or genetic perturbation. Our previous project found this indiscriminate, automated, and high-throughput method produced gene sets that together were highly informative for predicting disease–gene associations [@10.1371/journal.pcbi.1004743].\r\n\r\n## Reflections\r\n\r\nOne issue at play is the restrictive licensing of resources that MSigDB integrates. For example, KEGG [requires](https://github.com/dhimmel/integrate/blob/daefe6e3e9a44b9fdc85cb79cee597927f119559/licenses/custom/KEGG.md) academic services to obtain a [subscription](http://www.bioinformatics.jp/docs/subscription_organizational.pdf), which stipulates that:\r\n\r\n> Your Product or Service must not allow Your users to obtain KEGG FTP Data, except in small quantities.\r\n\r\nHence, portions of the MSigDB dataset do have to be licensed to forbid redistribution. Nevertheless, MIT went beyond these upstream restrictions when writing the MSigDB license. First, much of the database could likely be released openly. Second, I find the reporting requirements extreme. It's possible that MIT had a financial motivation when writing the license, as it states:\r\n\r\n> LICENSEE agrees that neither the PROGRAM nor the DATABASE shall be used as the basis of a commercial software or hardware product\r\n\r\nI think the MSigDB team deserves credit for making their comprehensive compilation of gene sets public. However, given the [extent of public funding](http://grantome.com/grant/NIH/R01-CA121941-10 \"See Related projects on Grantome\") this project has received, I question whether it's ethical for MIT to apply such a problematic license.\r\n\r\nFinally I'm not deflecting responsibility: I'm the one who included a resource whose license forbids redistribution. While scientists are often poorly informed on the legality of data reuse, I think it's important to take responsibility for educating yourself. Going forward I will address licensing issues before using a new dataset to avoid similar problems.",
      "comment_id": 1214,
      "profile_id": 17,
      "published": "2016-04-03T04:08:21.092646Z",
      "thread_id": 108,
      "url": "/discussion/msigdb-licensing/108#3"
    },
    {
      "body_html": "<h2>A remark on asinh, log1p and derivatives</h2>\r\n\r\n<p>[The aim of this post is mainly to respond to <a href=\"/u/pouyakhankhanian\" class=\"username\">@pouyakhankhanian</a> regarding his post above] </p>\r\n\r\n<p><a href=\"/u/pouyakhankhanian\" class=\"username\">@pouyakhankhanian</a>: I find your last remark interesting, but unfortunately not quite accurate as currently stated. </p>\r\n\r\n<p>(i) <span class=\"math\">$$\\sinh$$</span> is not a linear derivative of the exponential function, but a simple linear combination of it: <span class=\"math\">$$ \\sinh = \\frac{1}{2}(e^x - e^{-x}) $$</span>.</p>\r\n\r\n<p>(ii) Further, your second sentence has no grounding: the inverse of a derivative of a function <span class=\"math\">$$f$$</span> is definitely not the derivative of the inverse of the same <span class=\"math\">$$f$$</span>... So even if (i) was right, the result wouldn't hold. </p>\r\n\r\n<p>To see more clearly that <span class=\"math\">$$log1p$$</span> and <span class=\"math\">$$asinh$$</span> are not derivatives of each other, we can look at their analytical formulae:</p>\r\n\r\n<div class=\"math\">$$$\r\n\\begin{align}\r\n\\text{log1p}(x) &amp;= \\log(1 + x)\\\\\r\n\\sinh^{-1}(x) &amp;= \\log(x + \\sqrt{1 + x^2})\r\n\\end{align}\r\n$$$</div>\r\n\r\n<p>On a related note, we see here that both functions are very similar. This similarity is even clearer when looking at their derivatives:</p>\r\n\r\n<div class=\"math\">$$$\r\n\\begin{align}\r\n\\text{log1p}'(x) &amp;= \\frac{1}{1 + x}\\\\\r\n(\\sinh^{-1})'(x) &amp;= \\frac{1}{\\sqrt{1 + x^2}}\r\n\\end{align}\r\n$$$</div>\r\n\r\n<p>When <a href=\"https://www.wolframalpha.com/input/?i=Plot%5B%7B1%2FSqrt%5B1+%2B+x%5E2%5D,+(1+%2B+x)%5E(-1)%7D,+%7Bx,+0,+10%7D%5D\">plotted</a>, the trend is clear. The derivative of <span class=\"math\">$$\\text{asinh}$$</span> takes some time to get into the form of <span class=\"math\">$$ \\frac{1}{x} $$</span>, thus expanding the beginning of the range (for <span class=\"math\">$$x \\in 0..2$$</span>) more than its counterpart.</p>",
      "body_md": "## A remark on asinh, log1p and derivatives\r\n\r\n[The aim of this post is mainly to respond to @pouyakhankhanian regarding his post above] \r\n\r\n@pouyakhankhanian: I find your last remark interesting, but unfortunately not quite accurate as currently stated. \r\n\r\n(i) $$\\sinh$$ is not a linear derivative of the exponential function, but a simple linear combination of it: $$ \\sinh = \\frac{1}{2}(e^x - e^{-x}) $$.\r\n\r\n(ii) Further, your second sentence has no grounding: the inverse of a derivative of a function $$f$$ is definitely not the derivative of the inverse of the same $$f$$... So even if (i) was right, the result wouldn't hold. \r\n\r\nTo see more clearly that $$log1p$$ and $$asinh$$ are not derivatives of each other, we can look at their analytical formulae:\r\n\r\n$$$\r\n\\begin{align}\r\n\\text{log1p}(x) &= \\log(1 + x)\\\\\r\n\\sinh^{-1}(x) &= \\log(x + \\sqrt{1 + x^2})\r\n\\end{align}\r\n$$$\r\n\r\nOn a related note, we see here that both functions are very similar. This similarity is even clearer when looking at their derivatives:\r\n\r\n$$$\r\n\\begin{align}\r\n\\text{log1p}'(x) &= \\frac{1}{1 + x}\\\\\r\n(\\sinh^{-1})'(x) &= \\frac{1}{\\sqrt{1 + x^2}}\r\n\\end{align}\r\n$$$\r\n\r\nWhen [plotted](https://www.wolframalpha.com/input/?i=Plot%5B%7B1%2FSqrt%5B1+%2B+x%5E2%5D,+(1+%2B+x)%5E(-1)%7D,+%7Bx,+0,+10%7D%5D), the trend is clear. The derivative of $$\\text{asinh}$$ takes some time to get into the form of $$ \\frac{1}{x} $$, thus expanding the beginning of the range (for $$x \\in 0..2$$) more than its counterpart.",
      "comment_id": 1215,
      "profile_id": 23,
      "published": "2016-04-04T17:41:01.777748Z",
      "thread_id": 193,
      "url": "/discussion/transforming-dwpcs-for-hetnet-edge-prediction/193#5"
    },
    {
      "body_html": "<h1>The Prior Problem</h1>\r\n\r\n<p>The last step of our project <em>rephetio</em> is to use our heterogeneous Network <em>hetionet</em> † to create features that can predict missing edges in the Network. As the goal is to repurpose existing drugs to existing diseases, the outcome metaedge we are predicting is <em>treatments</em> (read 'treats' as a verb in our nomenclature). We tackle here a major issue that we call 'self-testing', which makes our Machine Learning approach non-conventional.</p>\r\n\r\n<h2>Self-testing</h2>\r\n\r\n<p>For computational and semantical reasons, we currently fit our machine-learned models and report evaluated performance based on the <strong>training</strong> error. Indeed, our Network architecture, implementation and data currently prevents us from creating separate training and testing sets, e.g. by selectively hiding predictor and predicted edges based on time of apparition. As a result (i) predictive models are trained with features that have intrinsic knowledge of the outcome, exposing us to overfitting of these features (ii) classical performance evaluation measures (like AUROC) lose relevance and applicability.</p>\r\n\r\n<h2>Source-Target Degrees as Features</h2>\r\n\r\n<p>We included source-target degrees as features of our edge prediction problem. The goal of this addition, as explained elsewhere, is to avoid misleading selection of DWPC features that are proxies for this basic topological information. </p>\r\n\r\n<p>In this discussion, we want to focus on treatment degrees. They can be noted <span class=\"math\">$$n_{DtC}(Ci)$$</span> and <span class=\"math\">$$n_{CtD}(D_j)$$</span>, and represent, respectively, the number of diseases treated by a Compound <span class=\"math\">$$C_i$$</span> (source Node) and the number of compounds that treat a Disease <span class=\"math\">$$D_j$$</span> (target Node). We believe that these degrees, as features, crystallizes the problem of self-testing in our edge-prediction problem.</p>\r\n\r\n<h2>Direct contamination</h2>\r\n\r\n<p>These degrees characterize with precision the (bipartite) subnetwork <span class=\"math\">$$\\mathcal{N}_O$$</span> that have only edges from the 'treatment' metaedge and source and target nodes (from the Compound and Disease metanodes). <span class=\"math\">$$\\mathcal{N}_O$$</span> contains no information apart from the actual outcomes we want to predict, and yet it is sufficient to compute all the treatment degrees <span class=\"math\">$$n_{DtC}$$</span> and <span class=\"math\">$$n_{CtD}$$</span>. As a result, outcome observations directly 'contaminates' our features on which the models are trained and evaluated. Because these degrees are so unequally distributed (they follow a <a href=\"https://en.wikipedia.org/wiki/Power_law\">power law</a>), and since these degree features are directly linked to the probability of existence of a treatment, fitting a model with only these two degree features gives misleeading high performance numbers.</p>\r\n\r\n<p>A first pass gave a AUROC above 0.97.</p>\r\n\r\n<h2>Prior knowledge</h2>\r\n\r\n<p>The information encapsulated in these two degree features are solely characterizing the treatment edges, <em>as we use them for fitting and evaluation</em>. We are not tackling here the more general problem of knowledge bias, but the specific issue arising as a result of self-testing: actual outcome observations directly contaminates our features, inducing prior knowledge about their value (positive or negative) before any additional information being integrated in our network.</p>\r\n\r\n<hr>\r\n\r\n<p>† This is the first public use of the name '<em>hetionet</em>' for our heterogeneous network that powers — in particular — the project <em>rephetio</em>. We call it a 'soft disclosure' ;-)</p>",
      "body_md": "# The Prior Problem\r\n\r\nThe last step of our project _rephetio_ is to use our heterogeneous Network _hetionet_ † to create features that can predict missing edges in the Network. As the goal is to repurpose existing drugs to existing diseases, the outcome metaedge we are predicting is *treatments* (read 'treats' as a verb in our nomenclature). We tackle here a major issue that we call 'self-testing', which makes our Machine Learning approach non-conventional.\r\n\r\n## Self-testing\r\n\r\nFor computational and semantical reasons, we currently fit our machine-learned models and report evaluated performance based on the **training** error. Indeed, our Network architecture, implementation and data currently prevents us from creating separate training and testing sets, e.g. by selectively hiding predictor and predicted edges based on time of apparition. As a result (i) predictive models are trained with features that have intrinsic knowledge of the outcome, exposing us to overfitting of these features (ii) classical performance evaluation measures (like AUROC) lose relevance and applicability.\r\n\r\n## Source-Target Degrees as Features\r\n\r\nWe included source-target degrees as features of our edge prediction problem. The goal of this addition, as explained elsewhere, is to avoid misleading selection of DWPC features that are proxies for this basic topological information. \r\n\r\nIn this discussion, we want to focus on treatment degrees. They can be noted $$n_{DtC}(Ci)$$ and $$n_{CtD}(D_j)$$, and represent, respectively, the number of diseases treated by a Compound $$C_i$$ (source Node) and the number of compounds that treat a Disease $$D_j$$ (target Node). We believe that these degrees, as features, crystallizes the problem of self-testing in our edge-prediction problem.\r\n\r\n## Direct contamination\r\n\r\nThese degrees characterize with precision the (bipartite) subnetwork $$\\mathcal{N}_O$$ that have only edges from the 'treatment' metaedge and source and target nodes (from the Compound and Disease metanodes). $$\\mathcal{N}_O$$ contains no information apart from the actual outcomes we want to predict, and yet it is sufficient to compute all the treatment degrees $$n_{DtC}$$ and $$n_{CtD}$$. As a result, outcome observations directly 'contaminates' our features on which the models are trained and evaluated. Because these degrees are so unequally distributed (they follow a [power law](https://en.wikipedia.org/wiki/Power_law)), and since these degree features are directly linked to the probability of existence of a treatment, fitting a model with only these two degree features gives misleeading high performance numbers.\r\n\r\nA first pass gave a AUROC above 0.97.\r\n\r\n## Prior knowledge\r\n\r\nThe information encapsulated in these two degree features are solely characterizing the treatment edges, _as we use them for fitting and evaluation_. We are not tackling here the more general problem of knowledge bias, but the specific issue arising as a result of self-testing: actual outcome observations directly contaminates our features, inducing prior knowledge about their value (positive or negative) before any additional information being integrated in our network.\r\n\r\n---\r\n† This is the first public use of the name '_hetionet_' for our heterogeneous network that powers -- in particular -- the project _rephetio_. We call it a 'soft disclosure' ;-)",
      "comment_id": 1216,
      "profile_id": 23,
      "published": "2016-04-05T22:49:42.917862Z",
      "thread_id": 194,
      "url": "/discussion/network-edge-prediction-how-to-deal-with-self-testing/194"
    },
    {
      "body_html": "<h1>Characterizing the Prior</h1>\r\n\r\n<p>Removal of degree features would only obfuscate the problem at hand, since this trivial information about outcomes could be picked up in subtler ways by DWPC features. On the contrary, we found that embracing the concept of prior knowledge presented above could solve both problems of fitting and evaluating our models. We will strive here for more accurate characterization of this prior knowledge.</p>\r\n\r\n<h2>Computing prior probabilities</h2>\r\n\r\n<p>Solely from the two treatment degree features, we can directly compute a probability of a given Compound-Disease couple to be linked by a treatment edge. </p>\r\n\r\n<p>Let us consider a couple <span class=\"math\">$$C_i\\text{-}D_j$$</span> where the treatment degree from the compound <span class=\"math\">$$C_i$$</span> is known, and the Disease <span class=\"math\">$$D_j$$</span> is drawn at random. The probability of this couple to be a treatment is equal to the number of disease <span class=\"math\">$$C_i$$</span> is connected to divided by the total number of diseases it could connect to. This can be written as:</p>\r\n\r\n<div class=\"math\">$$$\r\n\\begin{align}\r\np_t(C_i\\text{-}D) &amp; = \\frac{n_{CtD}(C_i)}{N_{C_i\\text{-}D}} \\\\\r\np_t(C_i\\text{-}D)  &amp; = \\frac{n_{CtD}(C_i)}{N_D}\r\n\\end{align}\r\n$$$</div>\r\n\r\n<p>... where <span class=\"math\">$$N_{C_i\\text{-}D}$$</span> is the total number of possible edges starting from <span class=\"math\">$$C_i$$</span>, equal to <span class=\"math\">$$N_D$$</span> the number of Diseases in the network.</p>\r\n\r\n<p>A similar formula can be derived for the Disease degrees:</p>\r\n\r\n<div class=\"math\">$$$\r\n\\begin{align}\r\np_t(D_j\\text{-}C)  &amp; = \\frac{n_{DtC}(D_j)}{N_C}\r\n\\end{align}\r\n$$$</div>\r\n\r\n<p>And both of these prior probabilities can be combined to get the prior probability of a given treatment edge knowing both degrees:</p>\r\n\r\n<div class=\"math\">$$$\r\n\\begin{equation}\r\n\\boxed{p_{ij} = p_t(C_i\\text{-}D_j) = \\frac{n_{DtC}(C_i) \\cdot n_{DtC}(D_j)}{N_D \\cdot N_C}}\r\n\\end{equation}\r\n$$$</div>\r\n\r\n<p>This probability fully describes the prior knowledge about the outcome that the treatment degrees hold.</p>\r\n\r\n<h2>A Null model</h2>\r\n\r\n<p>A null model can be specified, where the outcome for any source-target couple when predicting presence of a treatment edge is equal to the prior probability <span class=\"math\">$$p_{ij}$$</span> above. This model is denoted <span class=\"math\">$$\\mathcal{M}_{prior}$$</span>.</p>\r\n\r\n<p><span class=\"math\">$$\\mathcal{M}_{prior}$$</span>, when tested on all observations, is expected to have a very high AUROC, because it successfully stratifies the population of potential edges into tiers that have increasing and radically different probabilities of being a true link. For instance, it successfully discriminates the huge majority (85%) of couples that have no chances of being a treatment edge because either the Compound and/or the Disease has a treatment degree equal to zero. </p>\r\n\r\n<hr>\r\n\r\n<h2>AUROC of the null model</h2>\r\n\r\n<p>Just considering this point in the ROC curve, with <span class=\"math\">$$P_0 = P\\left(p_{ij} = 0\\right)$$</span> the proportion of edges that have a priori probability of zero, we can compute (for the fun) a lower bound for the AUROC that will illustrate why the expected performance is high. Every couple with prior probability of zero is ranked lower than any other couple, and each of these couples is actually a True Negative (TN) by design. Since we know that the model will be better than random for the remaining of the range of specificity, the lower bound for the AUROC of this null model is given by a simple linear interpolation based on one point we know in ROC space. </p>\r\n\r\n<p>This point corresponds to classifying only these \"absolute negatives\" that have <span class=\"math\">$$p_{ij} = 0$$</span>, as negatives. We get a sensitivity <span class=\"math\">$$sens = 1$$</span>, since all the real positives are predicted to be positives; and a specificity of </p>\r\n\r\n<div class=\"math\">$$$\r\n\\begin{align}\r\nspe &amp;= \\frac{P_0}{P_0 + (1 - P_0) \\cdot (1 - pre)}\\\\\r\n&amp;= \\frac{P_0}{1 - pre \\cdot (1 - P_0)}\\\\\r\nspe &amp;\\simeq  P_0\r\n\\end{align}\r\n$$$</div>\r\n\r\n<p>with the prevalence <span class=\"math\">$$pre$$</span> being negligible (of the order of <span class=\"math\">$$10^{-4}$$</span>).</p>\r\n\r\n<p>The linear interpolation gives us:</p>\r\n\r\n<div class=\"math\">$$$ \r\n\\begin{align}\r\nauroc_{min}\\left(\\mathcal{M}_{prior}\\right) &amp;= 1 - \\frac{1 - P_0}{2}\r\n\\end{align}\r\n$$$</div>\r\n\r\n<p>With <span class=\"math\">$$P_0 = 0.85 $$</span>, we get <span class=\"math\">$$ \\boxed{auroc_{min}\\left(\\mathcal{M}_{prior}\\right) = 92.5 \\%} $$</span> as a lower bound for the null model performance.</p>\r\n\r\n<hr>\r\n\r\n<p>The measured AUROC of the this null model, on all observations is equal to:</p>\r\n\r\n<div class=\"math\">$$$ auroc\\left(\\mathcal{M}_{prior}\\right)  = 97.9 \\%$$$</div>",
      "body_md": "# Characterizing the Prior\r\n\r\nRemoval of degree features would only obfuscate the problem at hand, since this trivial information about outcomes could be picked up in subtler ways by DWPC features. On the contrary, we found that embracing the concept of prior knowledge presented above could solve both problems of fitting and evaluating our models. We will strive here for more accurate characterization of this prior knowledge.\r\n\r\n## Computing prior probabilities\r\n\r\nSolely from the two treatment degree features, we can directly compute a probability of a given Compound-Disease couple to be linked by a treatment edge. \r\n\r\nLet us consider a couple $$C_i\\text{-}D_j$$ where the treatment degree from the compound $$C_i$$ is known, and the Disease $$D_j$$ is drawn at random. The probability of this couple to be a treatment is equal to the number of disease $$C_i$$ is connected to divided by the total number of diseases it could connect to. This can be written as:\r\n$$$\r\n\\begin{align}\r\np_t(C_i\\text{-}D) & = \\frac{n_{CtD}(C_i)}{N_{C_i\\text{-}D}} \\\\\r\np_t(C_i\\text{-}D)  & = \\frac{n_{CtD}(C_i)}{N_D}\r\n\\end{align}\r\n$$$\r\n... where $$N_{C_i\\text{-}D}$$ is the total number of possible edges starting from $$C_i$$, equal to $$N_D$$ the number of Diseases in the network.\r\n\r\nA similar formula can be derived for the Disease degrees:\r\n$$$\r\n\\begin{align}\r\np_t(D_j\\text{-}C)  & = \\frac{n_{DtC}(D_j)}{N_C}\r\n\\end{align}\r\n$$$\r\n\r\nAnd both of these prior probabilities can be combined to get the prior probability of a given treatment edge knowing both degrees:\r\n$$$\r\n\\begin{equation}\r\n\\boxed{p_{ij} = p_t(C_i\\text{-}D_j) = \\frac{n_{DtC}(C_i) \\cdot n_{DtC}(D_j)}{N_D \\cdot N_C}}\r\n\\end{equation}\r\n$$$\r\n\r\nThis probability fully describes the prior knowledge about the outcome that the treatment degrees hold.\r\n\r\n## A Null model\r\n\r\nA null model can be specified, where the outcome for any source-target couple when predicting presence of a treatment edge is equal to the prior probability $$p_{ij}$$ above. This model is denoted $$\\mathcal{M}_{prior}$$.\r\n\r\n$$\\mathcal{M}_{prior}$$, when tested on all observations, is expected to have a very high AUROC, because it successfully stratifies the population of potential edges into tiers that have increasing and radically different probabilities of being a true link. For instance, it successfully discriminates the huge majority (85%) of couples that have no chances of being a treatment edge because either the Compound and/or the Disease has a treatment degree equal to zero. \r\n\r\n---\r\n\r\n## AUROC of the null model\r\n\r\nJust considering this point in the ROC curve, with $$P_0 = P\\left(p_{ij} = 0\\right)$$ the proportion of edges that have a priori probability of zero, we can compute (for the fun) a lower bound for the AUROC that will illustrate why the expected performance is high. Every couple with prior probability of zero is ranked lower than any other couple, and each of these couples is actually a True Negative (TN) by design. Since we know that the model will be better than random for the remaining of the range of specificity, the lower bound for the AUROC of this null model is given by a simple linear interpolation based on one point we know in ROC space. \r\n\r\nThis point corresponds to classifying only these \"absolute negatives\" that have $$p_{ij} = 0$$, as negatives. We get a sensitivity $$sens = 1$$, since all the real positives are predicted to be positives; and a specificity of \r\n$$$\r\n\\begin{align}\r\nspe &= \\frac{P_0}{P_0 + (1 - P_0) \\cdot (1 - pre)}\\\\\r\n&= \\frac{P_0}{1 - pre \\cdot (1 - P_0)}\\\\\r\nspe &\\simeq  P_0\r\n\\end{align}\r\n$$$\r\nwith the prevalence $$pre$$ being negligible (of the order of $$10^{-4}$$).\r\n\r\nThe linear interpolation gives us:\r\n$$$ \r\n\\begin{align}\r\nauroc_{min}\\left(\\mathcal{M}_{prior}\\right) &= 1 - \\frac{1 - P_0}{2}\r\n\\end{align}\r\n$$$\r\nWith $$P_0 = 0.85 $$, we get $$ \\boxed{auroc_{min}\\left(\\mathcal{M}_{prior}\\right) = 92.5 \\%} $$ as a lower bound for the null model performance.\r\n\r\n---\r\n\r\nThe measured AUROC of the this null model, on all observations is equal to:\r\n$$$ auroc\\left(\\mathcal{M}_{prior}\\right)  = 97.9 \\%$$$",
      "comment_id": 1220,
      "profile_id": 23,
      "published": "2016-04-07T22:14:58.448547Z",
      "thread_id": 194,
      "url": "/discussion/network-edge-prediction-how-to-deal-with-self-testing/194#2"
    },
    {
      "body_html": "<h1>Why we self-test</h1>\r\n\r\n<p><a href=\"/u/alizee\" class=\"username\">@alizee</a> mentions that we plan to use self-testing. Here I'll describe what that means, and why we chose this unconventional approach. Self-testing refers to our plan to not withhold any treatments (positives) and non-treatments (negatives) from our hetnet and subsequent model training. In a conventional testing/validation approach, a subset of compound–disease pairs would be entirely removed from the training process. Here are reasons we don't want to withhold compound–disease pairs for testing.</p>\r\n\r\n<p>We only have 755 treatments. Many of the best performing features rely on these edges. For example, we'll look for compounds that bind to similar genes to compounds that treat the target disease. The informativeness of this feature is proportional to how many compounds treat the target disease. Therefore, withholding too many treatments for testing will hurt performance. Conversely, withholding too few treatments will lead to unreliable performance estimates. One solution to this dilemma is cross-validation. However, each fold would require a distinct feature extraction on a distinct hetnet. With our current infrastructure, this would create a major runtime and implementation time bottleneck that would negatively influence our agility.</p>\r\n\r\n<p>So the question becomes whether this investment is warranted by the benefits of a true testing set. The main benefit is accurate assessment of performance. However, in our particular situation, I don't think this a major concern and is probably not even possible. We're focused on making good predictions, not comparing the performance of many different methods. Ultimately the predictions will be unaffected by whether we adopt a formal testing scheme.</p>\r\n\r\n<p>Next, I expect the extent of model-based overfitting to be low. When training our logistic regression model, we use cross-validation to find an optimal level of regularization (a penalty to prevent overfitting). Specifically, we adopt the \"one-standard-error\" rule to choose the optimal λ from deviance <span class=\"citation\">[<a href=\"https://doi.org/10.18637/jss.v033.i01\" class=\"citation\" data-key=\"10.18637/jss.v033.i01\">1</a>]</span>. This is a stringent choice that takes a more conservative regularization strength than the deviance-minimizing value as an extra precaution against overfitting. In our previous project, where we did mask edges from the hetnet for testing, we comment <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1004259\">2</a>]</span>:</p>\r\n\r\n<blockquote><p>Importantly, we did not observe any significant degradation of performance from training to testing (<a href=\"https://doi.org/10.1371/journal.pcbi.1004259.g003\">Fig 3A</a>), indicating that our disciplined regularization approach avoided overfitting and that predictions for associations included in the network were not biased by their presence in the network.</p></blockquote>\r\n\r\n<p>And finally, there are two much bigger biases than overfitting. The first is the bias of existing knowledge (study bias), which we realistically cannot control for. The second is the prior probability of treatment based on degrees, as <a href=\"/u/alizee\" class=\"username\">@alizee</a> has discussed. I don't think cross-validation can easily address the prior probability issue. The PREDICT study — which also incorporated treatment information in features used to predict treatments — attempted to address the issue with the following approach <span class=\"citation\">[<a href=\"https://doi.org/10.1038/msb.2011.26\" class=\"citation\" data-key=\"10.1038/msb.2011.26\">3</a>]</span>:</p>\r\n\r\n<blockquote><p>To evaluate our classification scheme, we applied it in a 10‐fold cross‐validation setting. To avoid easy prediction cases, we hid all the associations involved with 10% of the drugs in each iteration, rather than hiding 10% of the associations.</p></blockquote>\r\n\r\n<p>However, if you hide all treatments for a set of drugs, a non-uniform prior based on the treatment-degree of the diseases still exists. Therefore, I think the best way forward will be explicitly model the prior probability of treatment based on degree and proceed intelligently.</p>",
      "body_md": "# Why we self-test\r\n\r\n@alizee mentions that we plan to use self-testing. Here I'll describe what that means, and why we chose this unconventional approach. Self-testing refers to our plan to not withhold any treatments (positives) and non-treatments (negatives) from our hetnet and subsequent model training. In a conventional testing/validation approach, a subset of compound--disease pairs would be entirely removed from the training process. Here are reasons we don't want to withhold compound--disease pairs for testing.\r\n\r\nWe only have 755 treatments. Many of the best performing features rely on these edges. For example, we'll look for compounds that bind to similar genes to compounds that treat the target disease. The informativeness of this feature is proportional to how many compounds treat the target disease. Therefore, withholding too many treatments for testing will hurt performance. Conversely, withholding too few treatments will lead to unreliable performance estimates. One solution to this dilemma is cross-validation. However, each fold would require a distinct feature extraction on a distinct hetnet. With our current infrastructure, this would create a major runtime and implementation time bottleneck that would negatively influence our agility.\r\n\r\nSo the question becomes whether this investment is warranted by the benefits of a true testing set. The main benefit is accurate assessment of performance. However, in our particular situation, I don't think this a major concern and is probably not even possible. We're focused on making good predictions, not comparing the performance of many different methods. Ultimately the predictions will be unaffected by whether we adopt a formal testing scheme.\r\n\r\nNext, I expect the extent of model-based overfitting to be low. When training our logistic regression model, we use cross-validation to find an optimal level of regularization (a penalty to prevent overfitting). Specifically, we adopt the \"one-standard-error\" rule to choose the optimal λ from deviance [@10.18637/jss.v033.i01]. This is a stringent choice that takes a more conservative regularization strength than the deviance-minimizing value as an extra precaution against overfitting. In our previous project, where we did mask edges from the hetnet for testing, we comment [@10.1371/journal.pcbi.1004259]:\r\n\r\n> Importantly, we did not observe any significant degradation of performance from training to testing ([Fig 3A](https://doi.org/10.1371/journal.pcbi.1004259.g003)), indicating that our disciplined regularization approach avoided overfitting and that predictions for associations included in the network were not biased by their presence in the network.\r\n\r\nAnd finally, there are two much bigger biases than overfitting. The first is the bias of existing knowledge (study bias), which we realistically cannot control for. The second is the prior probability of treatment based on degrees, as @alizee has discussed. I don't think cross-validation can easily address the prior probability issue. The PREDICT study -- which also incorporated treatment information in features used to predict treatments -- attempted to address the issue with the following approach [@10.1038/msb.2011.26]:\r\n\r\n> To evaluate our classification scheme, we applied it in a 10‐fold cross‐validation setting. To avoid easy prediction cases, we hid all the associations involved with 10% of the drugs in each iteration, rather than hiding 10% of the associations.\r\n\r\nHowever, if you hide all treatments for a set of drugs, a non-uniform prior based on the treatment-degree of the diseases still exists. Therefore, I think the best way forward will be explicitly model the prior probability of treatment based on degree and proceed intelligently.",
      "comment_id": 1221,
      "profile_id": 17,
      "published": "2016-04-14T06:31:03.552549Z",
      "thread_id": 194,
      "url": "/discussion/network-edge-prediction-how-to-deal-with-self-testing/194#4"
    },
    {
      "body_html": "<h1>Incorporating the prior in fitting and testing</h1>\r\n\r\n<h2>Using <span class=\"math\">$$\\mathcal{M}_{prior}$$</span> as baseline</h2>\r\n\r\n<p>The performance achieved by the null model <span class=\"math\">$$\\mathcal{M}_{prior}$$</span> should serve as a baseline, thus mitigating the lack of meaning of the AUROC: we'll use <span class=\"math\">$$auroc(\\mathcal{M}_{prior})$$</span> as a minimum value to improve on (instead of the usual <span class=\"math\">$$auroc(\\mathcal{M}_{random})= 0.5$$</span>).</p>\r\n\r\n<h2>Using <span class=\"math\">$$p_{ij}$$</span> as covariate</h2>\r\n\r\n<p>Nevertheless, we also want to include as a covariate in our models this prior probability, in order to isolate the prior knowledge about the outcome it describes, and avoid selection of DWPC features that 'tag' it. </p>\r\n\r\n<p>In the framework of generalized linear regressions I propose to directly take the linear predictor that corresponds to the computed prior probability. In the case of logistic regression, the feature to use as covariate in the model would be equal to:</p>\r\n\r\n<div class=\"math\">$$$\r\n\\begin{align}\r\n\\boxed{f_{prior}\\left(C_i\\text{-}D_j\\right) = \\text{logit}\\left(p_{ij}\\right)\\strut}\r\n\\end{align}\r\n$$$</div>\r\n\r\n<h2>Proposed procedure</h2>\r\n\r\n<p>We propose an incremental approach to the fitting and evaluation of the models, going through different iteration:</p>\r\n\r\n<div class=\"math\">$$$\r\n\\begin{align}\r\n\\text{1.} &amp;&amp; \\mathcal{M}_{prior}: \\; &amp;\\text{the null model described above} \\\\\r\n\\text{2.} &amp;&amp; \\mathcal{M}_{deg}: \\; &amp;\\delta_{CtD}  \\sim f_{prior} + degrees \\\\\r\n\\text{3.} &amp;&amp; \\mathcal{M}_{perm}: \\; &amp;\\delta_{CtD}  \\sim f_{prior} + degrees + DWPC_{permuted} \\\\\r\n\\text{4.} &amp;&amp; \\mathcal{M}_{real}: \\; &amp;\\delta_{CtD}  \\sim f_{prior} + degrees + DWPC_{real} \\\\\r\n\\end{align}\r\n$$$</div>\r\n\r\n<p>where we use the R formula notation to specify outcomes and features of the model;<br>where <span class=\"math\">$$\\delta_{CtD} = \\delta_{DtC}$$</span> is the outcome variable that denotes the presence of a treatment edge between a given couple of Compound and Disease; <br>where '<span class=\"math\">$$degrees$$</span>' are all the source/target degree features; and<br>where the <span class=\"math\">$$DWPC_{permuted}$$</span> and <span class=\"math\">$$DWPC_{real}$$</span> are the all DWPC features computed respectively from the degree-preserving permuted network <span class=\"math\">$$ \\mathcal{N}_{permuted} $$</span> (see ***) and the full network <span class=\"math\">$$\\mathcal{N}$$</span>.</p>\r\n\r\n<p>We expect <span class=\"math\">$$ \\mathcal{M}_{deg} $$</span> to bring no additional predictive value than the null model <span class=\"math\">$$ \\mathcal{M}_{prior} $$</span>, since the latter withholds already the best information possible at the atomicity of the source/target degrees level. For <span class=\"math\">$$\\mathcal{M}_{perm}$$</span> and <span class=\"math\">$$\\mathcal{M}_{real}$$</span>, the degrees might be useful in conjunction with the DWPC features.</p>\r\n\r\n<p>Testing of new or fitted data will be carried out using an arbitrary value for the prior in the models, e.g. an estimation of the prevalence.</p>\r\n\r\n<h2>Redefining the training &amp; testing sets</h2>\r\n\r\n<p>Finally, we propose to fit the models above only on couples that have a non-null prior probability of being a treatment edge, i.e. couples that verify both:</p>\r\n\r\n<div class=\"math\">$$$\r\n\\left\\{ \r\n\\begin{array}{c}\r\nn_{CtD}(C_i) &gt; 0 \\\\\r\nn_{DtC}(D_j) &gt; 0\r\n\\end{array}\r\n\\right. \r\n$$$</div>\r\n\r\n<p>Indeed, when the prior probability <span class=\"math\">$$p_{ij}$$</span> is equal to zero, the points do not theoretically contribute to the fitting, whereas they practically induce complications (lack of convergence, problem with the numerical encoding of <span class=\"math\">$$-\\infty$$</span> ... ). Moreover, it gives us the opportunity to report results for the couples from the complementary set (of the couples that have a null prior), which seems quite independent from the set used for training.</p>\r\n\r\n<p>On this smaller training set, the performance of the prior alone as measured by the ROC decreases since we removed obvious negatives:</p>\r\n\r\n<div class=\"math\">$$$ auroc\\left(\\mathcal{M}_{prior}\\right)  = 85.1 \\%$$$</div>\r\n\r\n<p>... while the area under the precision recall curve is exactly the same: <span class=\"math\">$$auprc\\left(\\mathcal{M}_{prior}\\right) = 0.16$$</span>.</p>",
      "body_md": "# Incorporating the prior in fitting and testing\r\n\r\n## Using $$\\mathcal{M}_{prior}$$ as baseline\r\n\r\nThe performance achieved by the null model $$\\mathcal{M}_{prior}$$ should serve as a baseline, thus mitigating the lack of meaning of the AUROC: we'll use $$auroc(\\mathcal{M}_{prior})$$ as a minimum value to improve on (instead of the usual $$auroc(\\mathcal{M}_{random})= 0.5$$).\r\n\r\n## Using $$p_{ij}$$ as covariate\r\n\r\nNevertheless, we also want to include as a covariate in our models this prior probability, in order to isolate the prior knowledge about the outcome it describes, and avoid selection of DWPC features that 'tag' it. \r\n\r\nIn the framework of generalized linear regressions I propose to directly take the linear predictor that corresponds to the computed prior probability. In the case of logistic regression, the feature to use as covariate in the model would be equal to:\r\n$$$\r\n\\begin{align}\r\n\\boxed{f_{prior}\\left(C_i\\text{-}D_j\\right) = \\text{logit}\\left(p_{ij}\\right)\\strut}\r\n\\end{align}\r\n$$$\r\n\r\n## Proposed procedure\r\n\r\nWe propose an incremental approach to the fitting and evaluation of the models, going through different iteration:\r\n\r\n$$$\r\n\\begin{align}\r\n\\text{1.} && \\mathcal{M}_{prior}: \\; &\\text{the null model described above} \\\\\r\n\\text{2.} && \\mathcal{M}_{deg}: \\; &\\delta_{CtD}  \\sim f_{prior} + degrees \\\\\r\n\\text{3.} && \\mathcal{M}_{perm}: \\; &\\delta_{CtD}  \\sim f_{prior} + degrees + DWPC_{permuted} \\\\\r\n\\text{4.} && \\mathcal{M}_{real}: \\; &\\delta_{CtD}  \\sim f_{prior} + degrees + DWPC_{real} \\\\\r\n\\end{align}\r\n$$$\r\n\r\nwhere we use the R formula notation to specify outcomes and features of the model;\r\nwhere $$\\delta_{CtD} = \\delta_{DtC}$$ is the outcome variable that denotes the presence of a treatment edge between a given couple of Compound and Disease; \r\nwhere '$$degrees$$' are all the source/target degree features; and\r\nwhere the $$DWPC_{permuted}$$ and $$DWPC_{real}$$ are the all DWPC features computed respectively from the degree-preserving permuted network $$ \\mathcal{N}_{permuted} $$ (see ***) and the full network $$\\mathcal{N}$$.\r\n\r\nWe expect $$ \\mathcal{M}_{deg} $$ to bring no additional predictive value than the null model $$ \\mathcal{M}_{prior} $$, since the latter withholds already the best information possible at the atomicity of the source/target degrees level. For $$\\mathcal{M}_{perm}$$ and $$\\mathcal{M}_{real}$$, the degrees might be useful in conjunction with the DWPC features.\r\n\r\nTesting of new or fitted data will be carried out using an arbitrary value for the prior in the models, e.g. an estimation of the prevalence.\r\n\r\n## Redefining the training & testing sets\r\n\r\nFinally, we propose to fit the models above only on couples that have a non-null prior probability of being a treatment edge, i.e. couples that verify both:\r\n$$$\r\n\\left\\{ \r\n\\begin{array}{c}\r\nn_{CtD}(C_i) > 0 \\\\\r\nn_{DtC}(D_j) > 0\r\n\\end{array}\r\n\\right. \r\n$$$\r\n\r\nIndeed, when the prior probability $$p_{ij}$$ is equal to zero, the points do not theoretically contribute to the fitting, whereas they practically induce complications (lack of convergence, problem with the numerical encoding of $$-\\infty$$ ... ). Moreover, it gives us the opportunity to report results for the couples from the complementary set (of the couples that have a null prior), which seems quite independent from the set used for training.\r\n\r\nOn this smaller training set, the performance of the prior alone as measured by the ROC decreases since we removed obvious negatives:\r\n$$$ auroc\\left(\\mathcal{M}_{prior}\\right)  = 85.1 \\%$$$\r\n\r\n... while the area under the precision recall curve is exactly the same: $$auprc\\left(\\mathcal{M}_{prior}\\right) = 0.16$$.",
      "comment_id": 1224,
      "profile_id": 23,
      "published": "2016-04-07T23:43:24.684141Z",
      "thread_id": 194,
      "url": "/discussion/network-edge-prediction-how-to-deal-with-self-testing/194#3"
    },
    {
      "body_html": "<p>Extracting LD from 1000 genomes data is not straightforward. Here is a rough outline of the solution I came up with. I used Plink1.9 <a href=\"https://www.cog-genomics.org/plink2/\">https://www.cog-genomics.org/plink2/</a> and VCFTools. It will require some tweaking for specific applications.</p>\r\n\r\n<h1>Step 0: Download 1000 genomes data and remove duplicate SNP IDs</h1>\r\n\r\n<h1></h1>\r\n\r\n<h1>Step 1: use vcftools to generate a population specific tped file</h1>\r\n\r\n<pre><code class=\"no-highlight hljs\">vcftools --gzvcf &lt;vcf_file&gt; --plink-tped --keep &lt;samples.txt&gt; --out &lt;tped_fh&gt;</code></pre>\r\n\r\n<p>where &lt;samples.txt&gt; is the location of a text file with a single column of sample IDs</p>\r\n\r\n<h1>Step 2: transpose the tped file (more efficient than creating a ped file originally)</h1>\r\n\r\n<pre><code class=\"no-highlight hljs\">plink --tfile &lt;tped_fh&gt; --recode --threads &lt;num_threads&gt; --no-sex --no-pheno --out &lt;ped_fh&gt;</code></pre>\r\n\r\n<h1>Step 3: use Plink1.9 to pull out an LD matrix</h1>\r\n\r\n<pre><code class=\"no-highlight hljs\">plink --file &lt;vcf_file&gt; --allow-no-sex --r2 --threads &lt;num_threads&gt; --ld-window-r2 &lt;window&gt; --chr &lt;chromosome&gt; --ld-snps &lt;snp_string&gt; --out &lt;out_name&gt;</code></pre>\r\n\r\n<p>where &lt;snp_string&gt; is a comma separated list of RS IDs</p>",
      "body_md": "Extracting LD from 1000 genomes data is not straightforward. Here is a rough outline of the solution I came up with. I used Plink1.9 <https://www.cog-genomics.org/plink2/> and VCFTools. It will require some tweaking for specific applications.\r\n#\r\nStep 0: Download 1000 genomes data and remove duplicate SNP IDs\r\n#\r\n#\r\nStep 1: use vcftools to generate a population specific tped file\r\n\r\n```\r\nvcftools --gzvcf <vcf_file> --plink-tped --keep <samples.txt> --out <tped_fh>\r\n```\r\nwhere <samples.txt> is the location of a text file with a single column of sample IDs\r\n#\r\nStep 2: transpose the tped file (more efficient than creating a ped file originally)\r\n\r\n```\r\nplink --tfile <tped_fh> --recode --threads <num_threads> --no-sex --no-pheno --out <ped_fh>\r\n```\r\n#\r\nStep 3: use Plink1.9 to pull out an LD matrix\r\n\r\n```\r\nplink --file <vcf_file> --allow-no-sex --r2 --threads <num_threads> --ld-window-r2 <window> --chr <chromosome> --ld-snps <snp_string> --out <out_name>\r\n```\r\nwhere <snp_string> is a comma separated list of RS IDs",
      "comment_id": 1231,
      "profile_id": 224,
      "published": "2016-04-08T13:55:13.834889Z",
      "thread_id": 71,
      "url": "/discussion/calculating-genomic-windows-for-gwas-lead-snps/71#8"
    },
    {
      "body_html": "<h1>Cheng et al 2014</h1>\r\n\r\n<p>A 2014 study titled \"Systematic evaluation of connectivity map for disease indications\" compiled 890 indications between 152 drugs and 145 diseases <span class=\"citation\">[<a href=\"https://doi.org/10.1186/s13073-014-0095-1\" class=\"citation\" data-key=\"10.1186/s13073-014-0095-1\">1</a>]</span>. They compiled the indications from FAERS and <a href=\"http://citeline.com/products/pharmaprojects/\">Pharmaprojects</a>. The indications are available as free text in Table S2 of the supplementary word document. I copied Table S2 into a TSV <a href=\"https://gist.github.com/dhimmel/4977c3f538fb215d9c49c9ccd66a41d4\" title=\"GitHub Gist: Catalog of treatments from Table S2 of Cheng et al 2014\">available here</a>.</p>",
      "body_md": "# Cheng et al 2014\r\n\r\nA 2014 study titled \"Systematic evaluation of connectivity map for disease indications\" compiled 890 indications between 152 drugs and 145 diseases [@10.1186/s13073-014-0095-1]. They compiled the indications from FAERS and [Pharmaprojects](http://citeline.com/products/pharmaprojects/). The indications are available as free text in Table S2 of the supplementary word document. I copied Table S2 into a TSV [available here](https://gist.github.com/dhimmel/4977c3f538fb215d9c49c9ccd66a41d4 \"GitHub Gist: Catalog of treatments from Table S2 of Cheng et al 2014\").",
      "comment_id": 1238,
      "profile_id": 17,
      "published": "2016-04-10T03:18:34.097548Z",
      "thread_id": 21,
      "url": "/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#26"
    },
    {
      "body_html": "<p>Have you considered the <a href=\"http://mentha.uniroma2.it/about.php\">Mentha PPI database</a>? </p>\r\n\r\n<ul><li>It combines protein-protein interaction data from most databases.</li><li>It assigns a reliability score to each interaction (like iRefIndex). </li><li>It uses the psicquic protocol and MITAB 2.5 format, so it compatible with all <a href=\"http://www.ebi.ac.uk/Tools/webservices/psicquic/registry/registry?action=STATUS\">other protein interaction databases</a>.</li><li>Over the last few years, it has been <a href=\"http://mentha.uniroma2.it/download.php\">regularly updated</a>. </li><li>It uses HGNC Gene IDs and UniProt accessions.</li></ul>",
      "body_md": "Have you considered the [Mentha PPI database](http://mentha.uniroma2.it/about.php)? \r\n\r\n  - It combines protein-protein interaction data from most databases.\r\n  - It assigns a reliability score to each interaction (like iRefIndex). \r\n  - It uses the psicquic protocol and MITAB 2.5 format, so it compatible with all [other protein interaction databases](http://www.ebi.ac.uk/Tools/webservices/psicquic/registry/registry?action=STATUS).\r\n  - Over the last few years, it has been [regularly updated](http://mentha.uniroma2.it/download.php). \r\n  - It uses HGNC Gene IDs and UniProt accessions.",
      "comment_id": 1241,
      "profile_id": 226,
      "published": "2016-04-11T03:03:22.135132Z",
      "thread_id": 85,
      "url": "/discussion/creating-a-catalog-of-protein-interactions/85#10"
    },
    {
      "body_html": "<p><a href=\"/u/ostrokach\" class=\"username\">@ostrokach</a>, thanks for letting us know about <a href=\"http://mentha.uniroma2.it/\">Mentha</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nmeth.2561\" class=\"citation\" data-key=\"10.1038/nmeth.2561\">1</a>]</span>. We've moved past the network construction stage on this project but will keep Mentha in mind for the future.</p>\r\n\r\n<p>I downloaded the latest release (<code>2016-04-11.zip</code>). Here are a few select rows from the top:</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>Protein A</th><th>Gene A</th><th>Taxon A</th><th>Protein B</th><th>Gene B</th><th>Taxon B</th><th>Score</th><th>PMID</th></tr></thead><tbody><tr><td>Q86UX7</td><td>FERMT3</td><td>9606</td><td>Q06830</td><td>PRDX1</td><td>9606</td><td>0.126</td><td>26496610</td></tr><tr><td>Q9LK77</td><td>Q9LK77</td><td>3702</td><td>A0A088QD33</td><td>OEC103 {ECO:0000313|EMBL:AIN81148.1}</td><td>62715</td><td>0.236</td><td>25211078</td></tr><tr><td>Q96QD9</td><td>FYTTD1</td><td>9606</td><td>Q86UX7</td><td>FERMT3</td><td>9606</td><td>0.126</td><td>26496610</td></tr><tr><td>F4J5N9</td><td>BZIP24 {ECO:0000313|EMBL:AEE78868.1}</td><td>3702</td><td>A0A088QD42</td><td>OEC112 {ECO:0000313|EMBL:AIN81158.1}</td><td>62715</td><td>0.236</td><td>25211078</td></tr><tr><td>Q9Y5Q8</td><td>GTF3C5</td><td>9606</td><td>Q86U86</td><td>PBRM1</td><td>9606</td><td>0.155</td><td>22939629 26344197</td></tr></tbody></table>\r\n\r\n<p>Two features that caught my eye are the reliability scores and the PubMed IDs of the original source(s). It looks like the file format could be a little bit cleaner (see for example <code>{ECO:0000313|EMBL:AEE78868.1}</code>). Also I didn't see a license on the Mentha website. Going forward I plan to avoid resources without an <a href=\"http://opendefinition.org/licenses/\" title=\"Conformant Licenses: Open Definition\">open license</a> — something we <a href=\"http://thinklab.com/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#14\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d107\">learned the importance</a> of during this project.</p>",
      "body_md": "@ostrokach, thanks for letting us know about [Mentha](http://mentha.uniroma2.it/) [@10.1038/nmeth.2561]. We've moved past the network construction stage on this project but will keep Mentha in mind for the future.\r\n\r\nI downloaded the latest release (`2016-04-11.zip`). Here are a few select rows from the top:\r\n\r\n| Protein A | Gene A | Taxon A | Protein B | Gene B | Taxon B | Score | PMID |\r\n|-----------|--------------|---------|------------|---------------|---------|-------|-------------------|\r\n| Q86UX7 | FERMT3 | 9606 | Q06830 | PRDX1 | 9606 | 0.126 | 26496610 |\r\n| Q9LK77 | Q9LK77 | 3702 | A0A088QD33 | OEC103 {ECO:0000313\\|EMBL:AIN81148.1} | 62715 | 0.236 | 25211078 |\r\n| Q96QD9 | FYTTD1 | 9606 | Q86UX7 | FERMT3 | 9606 | 0.126 | 26496610 |\r\n| F4J5N9 | BZIP24 {ECO:0000313\\|EMBL:AEE78868.1} | 3702 | A0A088QD42 | OEC112 {ECO:0000313\\|EMBL:AIN81158.1} | 62715 | 0.236 | 25211078 |\r\n| Q9Y5Q8 | GTF3C5 | 9606 | Q86U86 | PBRM1 | 9606 | 0.155 | 22939629 26344197 |\r\n\r\nTwo features that caught my eye are the reliability scores and the PubMed IDs of the original source(s). It looks like the file format could be a little bit cleaner (see for example `{ECO:0000313|EMBL:AEE78868.1}`). Also I didn't see a license on the Mentha website. Going forward I plan to avoid resources without an [open license](http://opendefinition.org/licenses/ \"Conformant Licenses: Open Definition\") -- something we [learned the importance](http://thinklab.com/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#14) of during this project.",
      "comment_id": 1242,
      "profile_id": 17,
      "published": "2016-04-11T05:56:08.147984Z",
      "thread_id": 85,
      "url": "/discussion/creating-a-catalog-of-protein-interactions/85#11"
    },
    {
      "body_html": "<p>We're planning to release our first project report soon, which will cover the completed hetnet. We'd like to assess the amount of user contribution and content creation the <em>Thinklab</em> venue has facilitated thus far. With the new <a href=\"http://thinklab.com/discussion/discussion-summary-statistics-for-illustrating-project-impact/191\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d191\">project export feature</a>, we can now perform custom analytics.</p>\r\n\r\n<p>Using today's export, I calculated some basic stats (<a href=\"https://github.com/dhimmel/thinklytics/blob/a3403caa68e37102d53722de38dfba7e98adf2d7/rephetio-stats.ipynb\">notebook</a>). The <a href=\"http://thinklab.com/p/rephetio/discussion\">67 discussions</a> in our project (comments + notes) contain:</p>\r\n\r\n<ul><li>403 comments and 133 notes containing 662,501 characters</li><li>contributions from 40 users who have written a comment or note</li><li>248 unique DOI references to 39 different DOI registrants</li></ul>\r\n\r\n<p><a href=\"/u/alizee\" class=\"username\">@alizee</a> is creating a visualization of user contribution over time, so stay tuned.</p>",
      "body_md": "We're planning to release our first project report soon, which will cover the completed hetnet. We'd like to assess the amount of user contribution and content creation the _Thinklab_ venue has facilitated thus far. With the new [project export feature](http://thinklab.com/discussion/discussion-summary-statistics-for-illustrating-project-impact/191), we can now perform custom analytics.\r\n\r\nUsing today's export, I calculated some basic stats ([notebook](https://github.com/dhimmel/thinklytics/blob/a3403caa68e37102d53722de38dfba7e98adf2d7/rephetio-stats.ipynb)). The [67 discussions](http://thinklab.com/p/rephetio/discussion) in our project (comments + notes) contain:\r\n\r\n+ 403 comments and 133 notes containing 662,501 characters\r\n+ contributions from 40 users who have written a comment or note\r\n+ 248 unique DOI references to 39 different DOI registrants\r\n\r\n@alizee is creating a visualization of user contribution over time, so stay tuned.",
      "comment_id": 1243,
      "profile_id": 17,
      "published": "2016-04-11T22:43:07.368630Z",
      "thread_id": 200,
      "url": "/discussion/measuring-user-contribution-and-content-creation/200"
    },
    {
      "body_html": "<p>We adapted one of the graph shown in the <a href=\"http://thinklab.com/discussion/discussion-summary-statistics-for-illustrating-project-impact/191#10\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d191\">thinklytics dicussion</a> for the scope of the <em>rephetio</em> project (R-<a href=\"https://github.com/antoine-lizee/thinklytics/blob/master/R-Code/03-singleProject.R\">script</a>), as well as the few numbers that <a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a> shared above(R-<a href=\"https://github.com/antoine-lizee/thinklytics/blob/master/R-Code/02-description.R\">script</a>).</p>\r\n\r\n<p>We include in the graph only the 33 users that have written more than 500 characters, highlighting the 8 top contributors with more than 5 thousands.</p>\r\n\r\n<p><img src=\"https://github.com/antoine-lizee/thinklytics/raw/master/Output/03-evoCumProfiles.png\" alt=\"Evolution of individual contributions\" title=\"Evolution of individual contributions\"></p>",
      "body_md": "We adapted one of the graph shown in the [thinklytics dicussion](http://thinklab.com/discussion/discussion-summary-statistics-for-illustrating-project-impact/191#10) for the scope of the _rephetio_ project (R-[script](https://github.com/antoine-lizee/thinklytics/blob/master/R-Code/03-singleProject.R)), as well as the few numbers that @dhimmel shared above(R-[script](https://github.com/antoine-lizee/thinklytics/blob/master/R-Code/02-description.R)).\r\n\r\nWe include in the graph only the 33 users that have written more than 500 characters, highlighting the 8 top contributors with more than 5 thousands.\r\n\r\n![Evolution of individual contributions](https://github.com/antoine-lizee/thinklytics/raw/master/Output/03-evoCumProfiles.png \"Evolution of individual contributions\")",
      "comment_id": 1248,
      "profile_id": 23,
      "published": "2016-04-12T05:44:20.935980Z",
      "thread_id": 200,
      "url": "/discussion/measuring-user-contribution-and-content-creation/200#2"
    },
    {
      "body_html": "<p>We also created the stream chart that shows instantaneous instead of cumulative contribution over time. I removed the main project owner, <a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a>, to highlight the patterns outside of his massive contribution. These counts are not transformed.</p>\r\n\r\n<p><img src=\"https://raw.githubusercontent.com/antoine-lizee/thinklytics/master/Output/03-evoStreamProfiles.png\" alt=\"User contribution stream chart\"></p>",
      "body_md": "We also created the stream chart that shows instantaneous instead of cumulative contribution over time. I removed the main project owner, @dhimmel, to highlight the patterns outside of his massive contribution. These counts are not transformed.\r\n\r\n![User contribution stream chart](https://raw.githubusercontent.com/antoine-lizee/thinklytics/master/Output/03-evoStreamProfiles.png)",
      "comment_id": 1264,
      "profile_id": 23,
      "published": "2016-04-15T00:46:13.213603Z",
      "thread_id": 200,
      "url": "/discussion/measuring-user-contribution-and-content-creation/200#3"
    },
    {
      "body_html": "<p>We discussed in a different <a href=\"http://thinklab.com/discussion/network-edge-prediction-how-to-deal-with-self-testing/194\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d194\">thread</a> why we believe that including the prior is a correct way of mitigating the problems posed by self-testing. In one of the <a href=\"http://thinklab.com/discussion/network-edge-prediction-how-to-deal-with-self-testing/194#2\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d194\">comments</a>, I derived a formula for the prior probability <span class=\"math\">$$p_{ij}$$</span> of a certain couple <span class=\"math\">$$C_i\\text{-}D_j$$</span> to have a treatment edge, only based on the source/target degrees <span class=\"math\">$$n_{CtD}(C_i)$$</span> and <span class=\"math\">$$n_{DtC}(D_j)$$</span>. Unfortunately, this formula is wrong. </p>\r\n\r\n<p>Here, we want to discuss why the formula is wrong, find a more accurate analytical formula, and explore ways to estimate programmatically this prior probability.</p>\r\n\r\n<h2>The previous formula</h2>\r\n\r\n<p>The reasoning was flawed at the point where we combined the two correct \"asymmetrical\"  probabilities into our final prior probability <span class=\"math\">$$p_{ij}$$</span>. Indeed, the \"asymmetrical\" probability of a source node <span class=\"math\">$$C_i$$</span> connecting a target node drawn at random can be accurately expressed as the ratio of the degree <span class=\"math\">$$n_{CtD}(C_i)$$</span> of this node over the total number of target nodes <span class=\"math\">$$N_D$$</span>. Nevertheless, multiplying the two probabilities  <span class=\"math\">$$p_t(C_i\\text{-}D)  = \\frac{n_{CtD}(C_i)}{N_D}$$</span> and  <span class=\"math\">$$p_t(D_j\\text{-}C)  = \\frac{n_{DtC}(D_j)}{N_D}$$</span> is <em>not</em> equal to the prior probability <span class=\"math\">$$p_{ij}$$</span>, but merely the joint probability of <span class=\"math\">$$C_i$$</span> to treat a disease drawn at random, and <span class=\"math\">$$D_j$$</span> to be treated by a Compound drawn at random.</p>\r\n\r\n<p>This formula appeared obviously wrong since the sum of the prior probabilities over all potential is not equal to anything meaningful, and certainly not the expected number of treatments <span class=\"math\">$$N_T$$</span>:</p>\r\n\r\n<div class=\"math\">$$$\r\n\\begin{align}\r\n\\sum_{i,j \\in 1..N_C \\times 1..N_D} p_{ij} &amp;= \\sum_{i,j \\in 1..N_C \\times 1..N_D} \\frac{n_{CtD}(C_i) \\cdot n_{DtC}(D_j)}{N_D \\cdot N_C}\\\\\r\n&amp;= \\frac{\\left( \\sum_{i \\in 1..N_C}n_{CtD}(C_i) \\right) \\cdot \\left( \\sum_{j \\in 1..N_D}n_{DtC}(D_j) \\right)}{N_D \\cdot N_C}\\\\\r\n&amp;= \\frac{N_T^2}{N_D \\cdot N_C} \\ne N_T\r\n\\end{align}\r\n$$$</div>\r\n\r\n<h2>Prior probability estimation is a hard problem</h2>\r\n\r\n<p>Deriving the prior probability <span class=\"math\">$$p_{ij}$$</span> from the individual source/target degrees is harder than we first thought. To grasp the complexity of the problem, we can see that the prior probability for one particular couple <span class=\"math\">$$C_i\\text-D_j$$</span> is not only dependant on the degrees of the two nodes <span class=\"math\">$$C_i$$</span> and <span class=\"math\">$$D_j$$</span>, but on the degrees of all the Compound and Disease nodes. As a result, it is complicated (maybe impossible) to derive an exact analytical solution, and it might be desirable to strive for a 'mean-field approximation' solution.</p>\r\n\r\n<p>In the meantime, we can brute-force the estimation of the prior probability, based on many random source/target subnetworks that have the same degrees than ours.</p>",
      "body_md": "We discussed in a different [thread](http://thinklab.com/discussion/network-edge-prediction-how-to-deal-with-self-testing/194) why we believe that including the prior is a correct way of mitigating the problems posed by self-testing. In one of the [comments](http://thinklab.com/discussion/network-edge-prediction-how-to-deal-with-self-testing/194#2), I derived a formula for the prior probability $$p_{ij}$$ of a certain couple $$C_i\\text{-}D_j$$ to have a treatment edge, only based on the source/target degrees $$n_{CtD}(C_i)$$ and $$n_{DtC}(D_j)$$. Unfortunately, this formula is wrong. \r\n\r\nHere, we want to discuss why the formula is wrong, find a more accurate analytical formula, and explore ways to estimate programmatically this prior probability.\r\n\r\n## The previous formula\r\n\r\nThe reasoning was flawed at the point where we combined the two correct \"asymmetrical\"  probabilities into our final prior probability $$p_{ij}$$. Indeed, the \"asymmetrical\" probability of a source node $$C_i$$ connecting a target node drawn at random can be accurately expressed as the ratio of the degree $$n_{CtD}(C_i)$$ of this node over the total number of target nodes $$N_D$$. Nevertheless, multiplying the two probabilities  $$p_t(C_i\\text{-}D)  = \\frac{n_{CtD}(C_i)}{N_D}$$ and  $$p_t(D_j\\text{-}C)  = \\frac{n_{DtC}(D_j)}{N_D}$$ is *not* equal to the prior probability $$p_{ij}$$, but merely the joint probability of $$C_i$$ to treat a disease drawn at random, and $$D_j$$ to be treated by a Compound drawn at random.\r\n\r\nThis formula appeared obviously wrong since the sum of the prior probabilities over all potential is not equal to anything meaningful, and certainly not the expected number of treatments $$N_T$$:\r\n$$$\r\n\\begin{align}\r\n\\sum_{i,j \\in 1..N_C \\times 1..N_D} p_{ij} &= \\sum_{i,j \\in 1..N_C \\times 1..N_D} \\frac{n_{CtD}(C_i) \\cdot n_{DtC}(D_j)}{N_D \\cdot N_C}\\\\\r\n&= \\frac{\\left( \\sum_{i \\in 1..N_C}n_{CtD}(C_i) \\right) \\cdot \\left( \\sum_{j \\in 1..N_D}n_{DtC}(D_j) \\right)}{N_D \\cdot N_C}\\\\\r\n&= \\frac{N_T^2}{N_D \\cdot N_C} \\ne N_T\r\n\\end{align}\r\n$$$\r\n\r\n\r\n## Prior probability estimation is a hard problem\r\n\r\nDeriving the prior probability $$p_{ij}$$ from the individual source/target degrees is harder than we first thought. To grasp the complexity of the problem, we can see that the prior probability for one particular couple $$C_i\\text-D_j$$ is not only dependant on the degrees of the two nodes $$C_i$$ and $$D_j$$, but on the degrees of all the Compound and Disease nodes. As a result, it is complicated (maybe impossible) to derive an exact analytical solution, and it might be desirable to strive for a 'mean-field approximation' solution.\r\n\r\nIn the meantime, we can brute-force the estimation of the prior probability, based on many random source/target subnetworks that have the same degrees than ours.",
      "comment_id": 1265,
      "profile_id": 23,
      "published": "2016-04-15T01:44:45.425274Z",
      "thread_id": 201,
      "url": "/discussion/network-edge-prediction-estimating-the-prior/201"
    },
    {
      "body_html": "<p>What about disease-disease co-occurrence data mined from electronic health records (EHR)? I know of two studies in particular, but there are probably more: </p>\r\n\r\n<p>Human Disease Network (HuDiNe) <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1000353\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1000353\">1</a>]</span></p>\r\n\r\n<ul><li>Data compiled from Medicare claims of mostly elderly Americans. </li><li>Diseases are mapped to ICD9.</li><li>Data can be downloaded from the <a href=\"http://barabasilab.neu.edu/projects/hudine/resource/data/data.html\">HuDiNe website</a>.</li><li>License: Free for academic use only.</li></ul>\r\n\r\n<p>Stanford Translational Research Integrated Database Environment (STRIDE) <span class=\"citation\">[<a href=\"https://doi.org/10.1038/sdata.2014.32\" class=\"citation\" data-key=\"10.1038/sdata.2014.32\">2</a>]</span></p>\r\n\r\n<ul><li>Data was mined from EHR at Stanford hospitals.</li><li>Diseases are mapped to UMLS CUI.</li><li>Data can be downloaded from <a href=\"http://datadryad.org/pages/policies\">dryad</a>.</li><li>License: Looks like something liberal.</li></ul>",
      "body_md": "What about disease-disease co-occurrence data mined from electronic health records (EHR)? I know of two studies in particular, but there are probably more: \r\n\r\nHuman Disease Network (HuDiNe) [@10.1371/journal.pcbi.1000353]\r\n\r\n- Data compiled from Medicare claims of mostly elderly Americans. \r\n- Diseases are mapped to ICD9.\r\n- Data can be downloaded from the [HuDiNe website](http://barabasilab.neu.edu/projects/hudine/resource/data/data.html).\r\n- License: Free for academic use only.\r\n\r\nStanford Translational Research Integrated Database Environment (STRIDE) [@10.1038/sdata.2014.32]\r\n\r\n- Data was mined from EHR at Stanford hospitals.\r\n- Diseases are mapped to UMLS CUI.\r\n- Data can be downloaded from [dryad](http://datadryad.org/pages/policies).\r\n- License: Looks like something liberal.",
      "comment_id": 1266,
      "profile_id": 226,
      "published": "2016-04-15T20:54:32.937525Z",
      "thread_id": 22,
      "url": "/discussion/suggestions-for-additional-information-types/22#7"
    },
    {
      "body_html": "<h1>Estimating the prior probability of treatment via permutation</h1>\r\n\r\n<p><strong>Problem:</strong> We have a bipartite graph of compounds and diseases connected by treatment edges. Using only node degrees, what is the probability that a given compound treats a given disease.</p>\r\n\r\n<p>Since compounds with the same degree are equivalent and diseases with the same degree are equivalent, we can focus on estimating the probability of a degree pair (<span class=\"math\">$$n_{CtD}(C_i)-n_{DtC}(D_i)$$</span>) rather than a specific compound–disease pair.</p>\r\n\r\n<p>Since we struggled to solve this problem analytically, we applied a brute-force permutation approach. Specifically, we took our empiric bipartite treatment network (<a href=\"https://thinklab.com/discussion/announcing-pharmacotherapydb-the-open-catalog-of-drug-therapies-for-disease/182#1\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d182\"><em>PharmacotherapyDB</em></a>) with 755 treatments and derived 744,975 permuted networks.</p>\r\n\r\n<p>We applied the <code>XSwap</code> method of permutation <span class=\"citation\">[<a href=\"https://doi.org/10.1137/1.9781611972795.67\" class=\"citation\" data-key=\"10.1137/1.9781611972795.67\">1</a>, <a href=\"/discussion/permuting-hetnets-and-implementing-randomized-edge-swaps-in-cypher/136\" class=\"citation\" data-key=\"10.15363/thinklab.d136\">2</a>, <a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1004259\">3</a>]</span> and found 2,265 (755 × 3) attempted swaps provided sufficient randomization <span class=\"citation\">[<a href=\"/discussion/assessing-the-effectiveness-of-our-hetnet-permutations/178\" class=\"citation\" data-key=\"10.15363/thinklab.d178\">4</a>]</span> (<a href=\"https://github.com/dhimmel/learn/blob/0aae784e83cfaa00d1269f17a3bd3a6c6fdc3a0a/prior/1-prior.ipynb\">notebook</a>). After every permutation, we recorded the percent of possible edges that were present for each degree pair. The final result is the prior probability that each degree pair exists (<a href=\"https://github.com/dhimmel/learn/blob/0aae784e83cfaa00d1269f17a3bd3a6c6fdc3a0a/prior/data/degree-prior.tsv\">table</a>).</p>\r\n\r\n<p><strong>Challenge:</strong> Can <a href=\"/u/alizee\" class=\"username\">@alizee</a> or others derive a general formula from these probabilities? For context here are the <a href=\"https://github.com/dhimmel/learn/blob/0aae784e83cfaa00d1269f17a3bd3a6c6fdc3a0a/summary/compounds.tsv\">compounds</a> and <a href=\"https://github.com/dhimmel/learn/blob/0aae784e83cfaa00d1269f17a3bd3a6c6fdc3a0a/summary/diseases.tsv\">diseases</a> — note that nodes with zero treatments (zero-prior nodes) can be ignored. The pseudo-linear relationship we see between our permuted prior probabilities and our faulty theoretic prior probabilities (scaled <span class=\"math\">$$n_{CtD}(C_i) \\cdot n_{DtC}(D_j)$$</span>) after logit transformation suggests an analytic solution may exist:</p>\r\n\r\n<p><img src=\"https://github.com/dhimmel/learn/blob/0aae784e83cfaa00d1269f17a3bd3a6c6fdc3a0a/prior/viz/scatter-theoretic-v-perm.png?raw=true\" alt=\"permuted versus theoretic prior probabilities\"></p>\r\n\r\n<p>Another interesting visualization shows the log-transformed probability of an edge existing for all compound–disease degree pairs (<a href=\"https://github.com/dhimmel/learn/blob/0aae784e83cfaa00d1269f17a3bd3a6c6fdc3a0a/prior/2-prior-viz.ipynb\">notebook</a>). The top facet shows the prevalence in the unpermuted treatment network:</p>\r\n\r\n<p><img src=\"https://github.com/dhimmel/learn/blob/0aae784e83cfaa00d1269f17a3bd3a6c6fdc3a0a/prior/viz/log-prob-tiled-empiric-v-perm.png?raw=true\" alt=\"compound versus disease degree permuted log priors\"></p>\r\n\r\n<p>Now here is the same plot without transforming the probabilities. Notice the high probabilities for the existence of treatment between high degree compounds and diseases.</p>\r\n\r\n<p><img src=\"https://github.com/dhimmel/learn/blob/0aae784e83cfaa00d1269f17a3bd3a6c6fdc3a0a/prior/viz/prob-tiled-empiric-v-perm.png?raw=true\" alt=\"compound versus disease degree permuted priors\"></p>\r\n\r\n<p>The incredible disparity in prior probabilities based on treatment degree reinforces the need to explicitly model the phenomenon.</p>",
      "body_md": "# Estimating the prior probability of treatment via permutation\r\n\r\n**Problem:** We have a bipartite graph of compounds and diseases connected by treatment edges. Using only node degrees, what is the probability that a given compound treats a given disease.\r\n\r\nSince compounds with the same degree are equivalent and diseases with the same degree are equivalent, we can focus on estimating the probability of a degree pair ($$n_{CtD}(C_i)-n_{DtC}(D_i)$$) rather than a specific compound--disease pair.\r\n\r\nSince we struggled to solve this problem analytically, we applied a brute-force permutation approach. Specifically, we took our empiric bipartite treatment network ([_PharmacotherapyDB_](https://thinklab.com/discussion/announcing-pharmacotherapydb-the-open-catalog-of-drug-therapies-for-disease/182#1)) with 755 treatments and derived 744,975 permuted networks.\r\n\r\nWe applied the `XSwap` method of permutation [@10.1137/1.9781611972795.67 @10.15363/thinklab.d136 @10.1371/journal.pcbi.1004259] and found 2,265 (755 × 3) attempted swaps provided sufficient randomization [@10.15363/thinklab.d178] ([notebook](https://github.com/dhimmel/learn/blob/0aae784e83cfaa00d1269f17a3bd3a6c6fdc3a0a/prior/1-prior.ipynb)). After every permutation, we recorded the percent of possible edges that were present for each degree pair. The final result is the prior probability that each degree pair exists ([table](https://github.com/dhimmel/learn/blob/0aae784e83cfaa00d1269f17a3bd3a6c6fdc3a0a/prior/data/degree-prior.tsv)).\r\n\r\n**Challenge:** Can @alizee or others derive a general formula from these probabilities? For context here are the [compounds](https://github.com/dhimmel/learn/blob/0aae784e83cfaa00d1269f17a3bd3a6c6fdc3a0a/summary/compounds.tsv) and [diseases](https://github.com/dhimmel/learn/blob/0aae784e83cfaa00d1269f17a3bd3a6c6fdc3a0a/summary/diseases.tsv) -- note that nodes with zero treatments (zero-prior nodes) can be ignored. The pseudo-linear relationship we see between our permuted prior probabilities and our faulty theoretic prior probabilities (scaled $$n_{CtD}(C_i) \\cdot n_{DtC}(D_j)$$) after logit transformation suggests an analytic solution may exist:\r\n\r\n![permuted versus theoretic prior probabilities](https://github.com/dhimmel/learn/blob/0aae784e83cfaa00d1269f17a3bd3a6c6fdc3a0a/prior/viz/scatter-theoretic-v-perm.png?raw=true)\r\n\r\nAnother interesting visualization shows the log-transformed probability of an edge existing for all compound--disease degree pairs ([notebook](https://github.com/dhimmel/learn/blob/0aae784e83cfaa00d1269f17a3bd3a6c6fdc3a0a/prior/2-prior-viz.ipynb)). The top facet shows the prevalence in the unpermuted treatment network:\r\n\r\n![compound versus disease degree permuted log priors](https://github.com/dhimmel/learn/blob/0aae784e83cfaa00d1269f17a3bd3a6c6fdc3a0a/prior/viz/log-prob-tiled-empiric-v-perm.png?raw=true)\r\n\r\nNow here is the same plot without transforming the probabilities. Notice the high probabilities for the existence of treatment between high degree compounds and diseases.\r\n\r\n![compound versus disease degree permuted priors](https://github.com/dhimmel/learn/blob/0aae784e83cfaa00d1269f17a3bd3a6c6fdc3a0a/prior/viz/prob-tiled-empiric-v-perm.png?raw=true)\r\n\r\nThe incredible disparity in prior probabilities based on treatment degree reinforces the need to explicitly model the phenomenon.",
      "comment_id": 1267,
      "profile_id": 17,
      "published": "2016-04-15T21:31:50.795312Z",
      "thread_id": 201,
      "url": "/discussion/network-edge-prediction-estimating-the-prior/201#2"
    },
    {
      "body_html": "<p>Thanks <a href=\"/u/ostrokach\" class=\"username\">@ostrokach</a>. While <a href=\"#7\">these resources</a> won't make it into the current project (corresponding to Hetionet v1.0), your suggestions will help us in the future.</p>\r\n\r\n<h2>HuDiNe</h2>\r\n\r\n<p>Regarding HuDiNe, I know I looked into the resource in the past. Specifically, I mention it in my Qualifying Exam proposal in 2013 <span class=\"citation\">[<a href=\"https://doi.org/10.6084/m9.figshare.3180142.v1\" class=\"citation\" data-key=\"10.6084/m9.figshare.3180142.v1\">1</a>]</span>:</p>\r\n\r\n<blockquote><p>Disease comorbidity will be extracted from <a href=\"http://hudine.neu.edu/\">HuDiNe</a>, a resource of co-occurring diseases constructed from Medicare claims spanning three years and 13 million patients <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1000353\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1000353\">2</a>]</span>. FDR adjusted p-values from the φ comorbidity statistic — a conservative metric optimized for prevalent diseases — will determine disease-disease edges.</p></blockquote>\r\n\r\n<p>If I remember correctly, I didn't end up including comorbidity relationships from HuDiNe because I had trouble picking an inclusion threshold: prevalent diseases were always comorbid with each other, while rare diseases never had comorbidities. However, as the HuDiNe paper explains they include two measures of comorbidity <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1000353\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1000353\">2</a>]</span>:</p>\r\n\r\n<blockquote><p>We will use two comorbidity measures to quantify the distance between two diseases: The Relative Risk (RR) and φ-correlation (φ). … For example, <em>RR</em> overestimates relationships involving rare diseases and underestimates the comorbidity between highly prevalent illnesses, whereas φ accurately discriminates comorbidities between pairs of diseases of similar prevalence but underestimates the comorbidity between rare and common diseases (see <a href=\"https://doi.org/10.1371/journal.pcbi.1000353.s001\">SM Box 1</a>).</p></blockquote>\r\n\r\n<p>Hence, I think it may make sense for us to revisit this dataset and attempt to pick a threshold that combines information from several <a href=\"http://barabasilab.neu.edu/projects/hudine/resource/data/data.html\" title=\"HuDiNe Data Download Page\">available columns</a> including:</p>\r\n\r\n<ul><li>Relative Risk 99% Conf. Interval</li><li>Phi-correlation</li><li>t-test value</li></ul>\r\n\r\n<p>Intuitively, comorbidity is an ideal relationship for our approach because it's high throughput and could potentially offer orthogonal information to existing relationships.</p>\r\n\r\n<h2>STRIDE</h2>\r\n\r\n<p>STRIDE is definitely be of interest <span class=\"citation\">[<a href=\"https://doi.org/10.1038/sdata.2014.32\" class=\"citation\" data-key=\"10.1038/sdata.2014.32\">3</a>]</span>. The data is licensed as CC0 <span class=\"citation\">[<a href=\"https://doi.org/10.5061/dryad.jp917\" class=\"citation\" data-key=\"10.5061/dryad.jp917\">4</a>]</span>, which is ideal. However, a good deal of exploratory analysis would be needed to determine a processing pipeline and see what types of cooccurring concepts have meaning.</p>",
      "body_md": "Thanks @ostrokach. While [these resources](#7) won't make it into the current project (corresponding to Hetionet v1.0), your suggestions will help us in the future.\r\n\r\n## HuDiNe\r\n\r\nRegarding HuDiNe, I know I looked into the resource in the past. Specifically, I mention it in my Qualifying Exam proposal in 2013 [@10.6084/m9.figshare.3180142.v1]:\r\n\r\n> Disease comorbidity will be extracted from [HuDiNe](http://hudine.neu.edu/), a resource of co-occurring diseases constructed from Medicare claims spanning three years and 13 million patients [@10.1371/journal.pcbi.1000353]. FDR adjusted p-values from the φ comorbidity statistic -- a conservative metric optimized for prevalent diseases -- will determine disease-disease edges.\r\n\r\nIf I remember correctly, I didn't end up including comorbidity relationships from HuDiNe because I had trouble picking an inclusion threshold: prevalent diseases were always comorbid with each other, while rare diseases never had comorbidities. However, as the HuDiNe paper explains they include two measures of comorbidity [@10.1371/journal.pcbi.1000353]:\r\n\r\n> We will use two comorbidity measures to quantify the distance between two diseases: The Relative Risk (RR) and φ-correlation (φ). … For example, _RR_ overestimates relationships involving rare diseases and underestimates the comorbidity between highly prevalent illnesses, whereas φ accurately discriminates comorbidities between pairs of diseases of similar prevalence but underestimates the comorbidity between rare and common diseases (see [SM Box 1](https://doi.org/10.1371/journal.pcbi.1000353.s001)).\r\n\r\nHence, I think it may make sense for us to revisit this dataset and attempt to pick a threshold that combines information from several [available columns](http://barabasilab.neu.edu/projects/hudine/resource/data/data.html \"HuDiNe Data Download Page\") including:\r\n\r\n+ Relative Risk 99% Conf. Interval\r\n+ Phi-correlation\r\n+ t-test value\r\n\r\nIntuitively, comorbidity is an ideal relationship for our approach because it's high throughput and could potentially offer orthogonal information to existing relationships.\r\n\r\n## STRIDE\r\n\r\nSTRIDE is definitely be of interest [@10.1038/sdata.2014.32]. The data is licensed as CC0 [@10.5061/dryad.jp917], which is ideal. However, a good deal of exploratory analysis would be needed to determine a processing pipeline and see what types of cooccurring concepts have meaning.",
      "comment_id": 1268,
      "profile_id": 17,
      "published": "2016-04-16T19:39:04.496320Z",
      "thread_id": 22,
      "url": "/discussion/suggestions-for-additional-information-types/22#8"
    },
    {
      "body_html": "<h1>The relationship between midpoint-join runtime and complexity</h1>\r\n\r\n<p>We performed a similar <em>DWPC</em> computation to <a href=\"#7\">before</a> but switched to specifying midpoint join indexes rather than our \"optimal\" join indexes. This time we computed 27,308,958 <em>DWPCs</em> for 3,775 compound–disease pairs × 1,206 metapaths × 6 hetnets. However, a <a href=\"https://github.com/dhimmel/learn/issues/1\" title=\"Failing feature extraction queries due to py2neo's socket timeout\">bug was introduced</a> which made queries taking over 30 seconds fail silently. Therefore, the following features are incomplete and will be prone to runtime underestimation: <em>CbGeAeGaD</em>, <em>CdG&lt;rGeAlD</em>, <em>CdGeAeGaD</em>, <em>CdGeAeGdD</em>, <em>CdGeAeGuD</em>, <em>CuG&lt;rGeAlD</em>, <em>CuGeAeGaD</em>, <em>CuGeAeGdD</em>, <em>CuGeAeGuD</em>, <em>CuGeAuGaD</em>.</p>\r\n\r\n<p><a href=\"/u/alizee\" class=\"username\">@alizee</a>: the switch to midpoint join led to a stronger association between sequential complexity and runtime (<a href=\"http://nbviewer.jupyter.org/github/dhimmel/learn/blob/6775c34768b5d4aaa0f386351a3ffec115548b2f/optimize/time.ipynb\">notebook</a>). Interestingly, switch also improved the fit between optimal complexity and runtime.</p>",
      "body_md": "# The relationship between midpoint-join runtime and complexity\r\n\r\nWe performed a similar _DWPC_ computation to [before](#7) but switched to specifying midpoint join indexes rather than our \"optimal\" join indexes. This time we computed 27,308,958 _DWPCs_ for 3,775 compound–disease pairs × 1,206 metapaths × 6 hetnets. However, a [bug was introduced](https://github.com/dhimmel/learn/issues/1 \"Failing feature extraction queries due to py2neo's socket timeout\") which made queries taking over 30 seconds fail silently. Therefore, the following features are incomplete and will be prone to runtime underestimation: _CbGeAeGaD_, _CdG<rGeAlD_, _CdGeAeGaD_, _CdGeAeGdD_, _CdGeAeGuD_, _CuG<rGeAlD_, _CuGeAeGaD_, _CuGeAeGdD_, _CuGeAeGuD_, _CuGeAuGaD_.\r\n\r\n@alizee: the switch to midpoint join led to a stronger association between sequential complexity and runtime ([notebook](http://nbviewer.jupyter.org/github/dhimmel/learn/blob/6775c34768b5d4aaa0f386351a3ffec115548b2f/optimize/time.ipynb)). Interestingly, switch also improved the fit between optimal complexity and runtime.",
      "comment_id": 1269,
      "profile_id": 17,
      "published": "2016-04-16T04:40:09.487281Z",
      "thread_id": 187,
      "url": "/discussion/estimating-the-complexity-of-hetnet-traversal/187#8"
    },
    {
      "body_html": "<h1>Transformation sweep</h1>\r\n\r\n<p>I ran a parameter sweep of transformation options on the all-features dataset (<a href=\"https://github.com/dhimmel/learn/blob/dd860cd19951886f3f82b04487d2faf6fa297e1b/all-features/7-transform.ipynb\">notebook</a>). The sweep used 10-fold cross-validation to select the regularization strength and summarized results over 10 cross-validation random seeds. \"All features\" refers to the dataset that includes all metapaths as features but covers only a portion of compound–disease pairs. These findings are not guaranteed to hold for the all-observations dataset, which we use for predictions.</p>\r\n\r\n<p>The performance results (<a href=\"https://github.com/dhimmel/learn/blob/dd860cd19951886f3f82b04487d2faf6fa297e1b/all-features/data/transformation-sweep.tsv\">table</a>) show that it's important to transform degrees and <em>DWPCs</em>. As <a href=\"/u/alizee\" class=\"username\">@alizee</a> hypothesized, transforming with log1p versus asinh didn't make a big difference. If for simplicity we choose the same transformation for degrees and <em>DWPCs</em>, then asinh ranked higher than log1p. Regarding <em>DWPC</em> scaling, the mean appears to perform better than the standard deviation although the difference is small. I know <a href=\"/u/alizee\" class=\"username\">@alizee</a> thinks the mean is less standard for this purpose, but it seems intuitive for <em>DWPCs</em> which start at zero.</p>\r\n\r\n<p>Hence, I plan to proceed by asinh transforming degrees and mean scaling and asinh transforming <em>DWPCs</em>.</p>",
      "body_md": "# Transformation sweep\r\n\r\nI ran a parameter sweep of transformation options on the all-features dataset ([notebook](https://github.com/dhimmel/learn/blob/dd860cd19951886f3f82b04487d2faf6fa297e1b/all-features/7-transform.ipynb)). The sweep used 10-fold cross-validation to select the regularization strength and summarized results over 10 cross-validation random seeds. \"All features\" refers to the dataset that includes all metapaths as features but covers only a portion of compound--disease pairs. These findings are not guaranteed to hold for the all-observations dataset, which we use for predictions.\r\n\r\nThe performance results ([table](https://github.com/dhimmel/learn/blob/dd860cd19951886f3f82b04487d2faf6fa297e1b/all-features/data/transformation-sweep.tsv)) show that it's important to transform degrees and _DWPCs_. As @alizee hypothesized, transforming with log1p versus asinh didn't make a big difference. If for simplicity we choose the same transformation for degrees and _DWPCs_, then asinh ranked higher than log1p. Regarding _DWPC_ scaling, the mean appears to perform better than the standard deviation although the difference is small. I know @alizee thinks the mean is less standard for this purpose, but it seems intuitive for _DWPCs_ which start at zero.\r\n\r\nHence, I plan to proceed by asinh transforming degrees and mean scaling and asinh transforming _DWPCs_.",
      "comment_id": 1270,
      "profile_id": 17,
      "published": "2016-04-16T17:46:03.774230Z",
      "thread_id": 193,
      "url": "/discussion/transforming-dwpcs-for-hetnet-edge-prediction/193#6"
    },
    {
      "body_html": "<p>We have finished building the hetnet for Project Rephetio, which we've named <a href=\"https://github.com/dhimmel/hetionet\">Hetionet</a>. As we gear up for the version 1.0 release, we'd like to provide statistics and visualizations to help users appreciate the network. Here we'll discuss ways to communicate hetnet topology and showcase our current visualizations.</p>\r\n\r\n<p>Here are some points to keep in mind:</p>\r\n\r\n<ul><li>the hetnet, which consists of 47,031 nodes of 11 types and 2,250,197 edges of 24 types, will break most existing visualization software</li><li>we prefer approaches that are automatable: we're looking for sustainable and versatile solutions</li></ul>",
      "body_md": "We have finished building the hetnet for Project Rephetio, which we've named [Hetionet](https://github.com/dhimmel/hetionet). As we gear up for the version 1.0 release, we'd like to provide statistics and visualizations to help users appreciate the network. Here we'll discuss ways to communicate hetnet topology and showcase our current visualizations.\r\n\r\nHere are some points to keep in mind:\r\n\r\n+ the hetnet, which consists of 47,031 nodes of 11 types and 2,250,197 edges of 24 types, will break most existing visualization software\r\n+ we prefer approaches that are automatable: we're looking for sustainable and versatile solutions",
      "comment_id": 1271,
      "profile_id": 17,
      "published": "2016-04-16T21:39:16.725202Z",
      "thread_id": 202,
      "url": "/discussion/describing-hetionet-v10-through-visualization-and-statistics/202"
    },
    {
      "body_html": "<h1>Metagraph</h1>\r\n\r\n<p>A metagaph is the graph of types in a hetnet. In Neo4j speak, metagraphs are often referred to as \"data models\". Another synonymous term is \"network schema\". Here is the metagraph for Hetionet v1.0:</p>\r\n\r\n<p><img src=\"https://github.com/dhimmel/rephetio/blob/103054a2bc3f86998fed6cb3753d1ecdb5cbe1e7/figure/metagraph.png?raw=true\" alt=\"Hetionet v1.0 Metagraph\" title=\"Hetionet v1.0 Metagraph\"></p>\r\n\r\n<p>Metagraphs show what types of entities and relationships are included in the network. However by design, they don't provide any information on the actual nodes or edges.</p>",
      "body_md": "# Metagraph\r\n\r\nA metagaph is the graph of types in a hetnet. In Neo4j speak, metagraphs are often referred to as \"data models\". Another synonymous term is \"network schema\". Here is the metagraph for Hetionet v1.0:\r\n\r\n![Hetionet v1.0 Metagraph](https://github.com/dhimmel/rephetio/blob/103054a2bc3f86998fed6cb3753d1ecdb5cbe1e7/figure/metagraph.png?raw=true \"Hetionet v1.0 Metagraph\")\r\n\r\nMetagraphs show what types of entities and relationships are included in the network. However by design, they don't provide any information on the actual nodes or edges.",
      "comment_id": 1272,
      "profile_id": 17,
      "published": "2016-04-18T13:24:16.554453Z",
      "thread_id": 202,
      "url": "/discussion/describing-hetionet-v10-through-visualization-and-statistics/202#2"
    },
    {
      "body_html": "<p>Project Rephetio has finally reached its prediction stage. A brief recap, we created <a href=\"https://github.com/dhimmel/hetionet\" title=\"Hetionet on GitHub\">Hetionet v1.0</a> — an integrative network with 2,250,197 relationships of 24 types. Then we extracted features from the network to quantify the prevalence of specific path types between each compound and disease. Finally, we <a href=\"https://thinklab.com/discussion/our-hetnet-edge-prediction-methodology-the-modeling-framework-for-project-rephetio/210#4\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d210\">fit a model</a> to translate from network-based features to a probability of treatment for a given compound–disease pair.</p>\r\n\r\n<p>In total, we make predictions for 209,168 compound–disease pairs between 1,538 approved small molecule compounds and 136 complex diseases. Our model was trained on 755 disease-modifying indications (treatments) from <a href=\"https://thinklab.com/discussion/announcing-pharmacotherapydb-the-open-catalog-of-drug-therapies-for-disease/182\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d182\">PharmacotherapyDB v1.0</a>. Hence, our predicted probabilities assume a true prevalence of treatment of 0.36%. Note that in reality the prevalence of treatment is higher and thus are predicted probabilities are on the low side.</p>\r\n\r\n<p>Our top predictions (probability &gt; 1%) are available in this <a href=\"https://docs.zoho.com/sheet/published.do?rid=e69hz753221749d71463d874d3cb7eeed03c6\" title=\"Project Rephetio Top Predictions\">online spreadsheet</a>. The full set of predictions is available as <a href=\"https://github.com/dhimmel/learn/blob/a7766ea00da67f5cf03bd77e6e613a262918f1b8/prediction/predictions/probabilities.tsv\" title=\"probabilities.tsv on GitHub\">TSV file</a>.</p>\r\n\r\n<p>Our model relied heavily on the following features which positively influence the prediction. Each feature corresponds to a type of path:</p>\r\n\r\n<ul><li><strong>CbGbCtD</strong>: whether the compound binds to the same genes as compounds which treat the disease</li><li><strong>CbGaD</strong>: whether the compound binds to genes that are associated with the disease</li><li><strong>CiPCiCtD</strong>: whether the compound belongs to the same pharmacologic classes as compounds that treat the disease</li><li><strong>CrCtD</strong>: whether the compound chemically resembles compounds that treat the disease</li><li><strong>CtDrD</strong>: whether the compound treats diseases which resemble the disease</li><li><strong>CrCrCtD</strong>: whether the compound resembles compounds that resemble compounds that treat the disease.</li><li><strong>CcSEcCtD</strong>: whether the compound causes the same side effects as compounds that treat the disease</li><li><strong>CpDpCtD</strong>: whether the compound palliates the same diseases as compounds that treat the disease</li><li><strong>CbGpPWpGaD</strong>: whether the compound binds to genes that participate in the same pathways as genes associated with the disease</li><li><strong>CbGeAlD</strong>: whether the compound binds to genes that are expressed in the anatomies affected by the disease</li></ul>\r\n\r\n<p>We are working on a method for investigating the specific network paths supporting each prediction. Stay tuned and let us know what you think of the predictions.</p>",
      "body_md": "Project Rephetio has finally reached its prediction stage. A brief recap, we created [Hetionet v1.0](https://github.com/dhimmel/hetionet \"Hetionet on GitHub\") -- an integrative network with 2,250,197 relationships of 24 types. Then we extracted features from the network to quantify the prevalence of specific path types between each compound and disease. Finally, we [fit a model](https://thinklab.com/discussion/our-hetnet-edge-prediction-methodology-the-modeling-framework-for-project-rephetio/210#4) to translate from network-based features to a probability of treatment for a given compound--disease pair.\r\n\r\nIn total, we make predictions for 209,168 compound--disease pairs between 1,538 approved small molecule compounds and 136 complex diseases. Our model was trained on 755 disease-modifying indications (treatments) from [PharmacotherapyDB v1.0](https://thinklab.com/discussion/announcing-pharmacotherapydb-the-open-catalog-of-drug-therapies-for-disease/182). Hence, our predicted probabilities assume a true prevalence of treatment of 0.36%. Note that in reality the prevalence of treatment is higher and thus are predicted probabilities are on the low side.\r\n\r\nOur top predictions (probability > 1%) are available in this [online spreadsheet](https://docs.zoho.com/sheet/published.do?rid=e69hz753221749d71463d874d3cb7eeed03c6 \"Project Rephetio Top Predictions\"). The full set of predictions is available as [TSV file](https://github.com/dhimmel/learn/blob/a7766ea00da67f5cf03bd77e6e613a262918f1b8/prediction/predictions/probabilities.tsv \"probabilities.tsv on GitHub\").\r\n\r\nOur model relied heavily on the following features which positively influence the prediction. Each feature corresponds to a type of path:\r\n\r\n+ **CbGbCtD**: whether the compound binds to the same genes as compounds which treat the disease\r\n+ **CbGaD**: whether the compound binds to genes that are associated with the disease\r\n+ **CiPCiCtD**: whether the compound belongs to the same pharmacologic classes as compounds that treat the disease\r\n+ **CrCtD**: whether the compound chemically resembles compounds that treat the disease\r\n+ **CtDrD**: whether the compound treats diseases which resemble the disease\r\n+ **CrCrCtD**: whether the compound resembles compounds that resemble compounds that treat the disease.\r\n+ **CcSEcCtD**: whether the compound causes the same side effects as compounds that treat the disease\r\n+ **CpDpCtD**: whether the compound palliates the same diseases as compounds that treat the disease\r\n+ **CbGpPWpGaD**: whether the compound binds to genes that participate in the same pathways as genes associated with the disease\r\n+ **CbGeAlD**: whether the compound binds to genes that are expressed in the anatomies affected by the disease\r\n\r\nWe are working on a method for investigating the specific network paths supporting each prediction. Stay tuned and let us know what you think of the predictions.",
      "comment_id": 1273,
      "profile_id": 17,
      "published": "2016-05-17T18:29:23.509801Z",
      "thread_id": 203,
      "url": "/discussion/predictions-of-whether-a-compound-treats-a-disease/203"
    },
    {
      "body_html": "<h1>Circular metanode layout</h1>\r\n\r\n<p>One of our primary methods for showing the actual hetnet has been a layout which groups nodes by their type. For each metanode, nodes are laid out in circles. Edges are colored by their type. Here is the circular metanode layout for Hetionet:</p>\r\n\r\n<p><img src=\"https://github.com/dhimmel/rephetio/blob/103054a2bc3f86998fed6cb3753d1ecdb5cbe1e7/figure/hetionet-v1.0-labeled.png?raw=true\" alt=\"Hetionet v1.0 Circular Metanode Layout\" title=\"Hetionet v1.0\"></p>\r\n\r\n<p>This method of visualization gives users a bird's eye view of the hetnet. It begins to show certain summary statistics, such as the number of nodes per metanode. It also weakly illustrates whether a metaedge is concentrated to a few high degree nodes or is well dispersed. However, this visualization is primarily meant to be aesthetic and generally accessible.</p>\r\n\r\n<p>In the past, we've received positive feedback on the circular metanode layout. This <a href=\"https://doi.org/10.1371/journal.pcbi.1004259.g001\" title=\"Fig 1. Heterogeneous network integrates diverse information domains\">visualization for our previous project</a> took 2nd place for the most aesthetically pleasing network visualization in the <a href=\"http://www.cytoscape.org/cy32_launch_challenge.html\">Cytoscape 3.2 Launch Challenge</a>.</p>\r\n\r\n<h2>Methods</h2>\r\n\r\n<p>We create this visualization in <a href=\"http://www.cytoscape.org/\">Cytoscape</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1101/gr.1239303\" class=\"citation\" data-key=\"10.1101/gr.1239303\">1</a>, <a href=\"https://doi.org/10.1093/bioinformatics/btq675\" class=\"citation\" data-key=\"10.1093/bioinformatics/btq675\">2</a>]</span> — a Java-based desktop application for network visualization with strong adoption in biology (current version 3.3.0). Creating this visualization is labor intensive and frustrating, since our hetnets push Cytoscape to its limits.</p>\r\n\r\n<p>To make the visualization possible, we limit the number of edges per type to 5,000 (by setting <a href=\"https://github.com/dhimmel/hetio/blob/2c135fcd32616d6979972105ba60b003d65c98bd/hetio/readwrite.py#L260\" title=\"hetio.readwrite.write_sif\"><code>max_edges = 5000</code></a>). One side effect is that Cytoscape only shows the subset of nodes connected by the selected edge subset. Hence, the visualization moderately reflects the number of nodes per metanode and poorly reflects the number of edges per metaedge.</p>",
      "body_md": "# Circular metanode layout\r\n\r\nOne of our primary methods for showing the actual hetnet has been a layout which groups nodes by their type. For each metanode, nodes are laid out in circles. Edges are colored by their type. Here is the circular metanode layout for Hetionet:\r\n\r\n![Hetionet v1.0 Circular Metanode Layout](https://github.com/dhimmel/rephetio/blob/103054a2bc3f86998fed6cb3753d1ecdb5cbe1e7/figure/hetionet-v1.0-labeled.png?raw=true \"Hetionet v1.0\")\r\n\r\nThis method of visualization gives users a bird's eye view of the hetnet. It begins to show certain summary statistics, such as the number of nodes per metanode. It also weakly illustrates whether a metaedge is concentrated to a few high degree nodes or is well dispersed. However, this visualization is primarily meant to be aesthetic and generally accessible.\r\n\r\nIn the past, we've received positive feedback on the circular metanode layout. This [visualization for our previous project](https://doi.org/10.1371/journal.pcbi.1004259.g001 \"Fig 1. Heterogeneous network integrates diverse information domains\") took 2nd place for the most aesthetically pleasing network visualization in the [Cytoscape 3.2 Launch Challenge](http://www.cytoscape.org/cy32_launch_challenge.html).\r\n\r\n## Methods\r\n\r\nWe create this visualization in [Cytoscape](http://www.cytoscape.org/) [@10.1101/gr.1239303 @10.1093/bioinformatics/btq675] -- a Java-based desktop application for network visualization with strong adoption in biology (current version 3.3.0). Creating this visualization is labor intensive and frustrating, since our hetnets push Cytoscape to its limits.\r\n\r\nTo make the visualization possible, we limit the number of edges per type to 5,000 (by setting [`max_edges = 5000`](https://github.com/dhimmel/hetio/blob/2c135fcd32616d6979972105ba60b003d65c98bd/hetio/readwrite.py#L260 \"hetio.readwrite.write_sif\")). One side effect is that Cytoscape only shows the subset of nodes connected by the selected edge subset. Hence, the visualization moderately reflects the number of nodes per metanode and poorly reflects the number of edges per metaedge.",
      "comment_id": 1275,
      "profile_id": 17,
      "published": "2016-04-18T14:00:26.867435Z",
      "thread_id": 202,
      "url": "/discussion/describing-hetionet-v10-through-visualization-and-statistics/202#3"
    },
    {
      "body_html": "<h1>Metapath counts by metanode pairs</h1>\r\n\r\n<p>This is a new visualization we're trying out that is based solely on the <a href=\"#2\">metagraph</a>. The plot shows the number of metapaths (types of paths) that connect a source and target metanode for a given length. The Length 1 condition shows the number of metaedges connecting two nodes. The longer lengths help show the combinatoric explosion in types of connectivity on the hetnet. Here's the graph for Hetionet v1.0 (<a href=\"https://github.com/dhimmel/integrate/blob/b53b835dbac09101c2036328b3fc72644fcb71bc/viz/auto/2-netviz.ipynb\">notebook</a>):</p>\r\n\r\n<p><img src=\"https://github.com/dhimmel/integrate/blob/095747de9efe42a9ed1e23ab18db282e14705cd9/viz/auto/figure/metapath-counts.png?raw=true\" alt=\"Hetionet Metapath Counts\" title=\"Hetionet v1.0 Metapath Counts by Metanode Pairs\"></p>",
      "body_md": "# Metapath counts by metanode pairs\r\n\r\nThis is a new visualization we're trying out that is based solely on the [metagraph](#2). The plot shows the number of metapaths (types of paths) that connect a source and target metanode for a given length. The Length 1 condition shows the number of metaedges connecting two nodes. The longer lengths help show the combinatoric explosion in types of connectivity on the hetnet. Here's the graph for Hetionet v1.0 ([notebook](https://github.com/dhimmel/integrate/blob/b53b835dbac09101c2036328b3fc72644fcb71bc/viz/auto/2-netviz.ipynb)):\r\n\r\n![Hetionet Metapath Counts](https://github.com/dhimmel/integrate/blob/095747de9efe42a9ed1e23ab18db282e14705cd9/viz/auto/figure/metapath-counts.png?raw=true \"Hetionet v1.0 Metapath Counts by Metanode Pairs\")",
      "comment_id": 1276,
      "profile_id": 17,
      "published": "2016-04-18T14:09:45.060264Z",
      "thread_id": 202,
      "url": "/discussion/describing-hetionet-v10-through-visualization-and-statistics/202#4"
    },
    {
      "body_html": "<h1>Chord diagram of edges per type</h1>\r\n\r\n<p><a href=\"https://en.wikipedia.org/wiki/Chord_diagram\">Chord diagrams</a>, also called radial network diagrams, consist of nodes laid out as segments in a circle and edges as chords connecting the segments. In our example, metanodes are laid out on along the perimeter with chords corresponding to metaedges:</p>\r\n\r\n<p><img src=\"https://github.com/dhimmel/integrate/blob/095747de9efe42a9ed1e23ab18db282e14705cd9/viz/auto/figure/edge-chord-diagram.png?raw=true\" alt=\"Hetionet Chord Diagram\" title=\"Hetionet v1.0 Chord Diagram\"></p>\r\n\r\n<p>Note that we transform sqaure root transformed the edge count for each metaedge, represented with chord width. The segment width for metanodes does not correspond to the proportion of total nodes which may be slightly confusing.</p>\r\n\r\n<p>Chord diagrams were popularized by the <a href=\"http://circos.ca/\">Circos</a> app <span class=\"citation\">[<a href=\"https://doi.org/10.1101/gr.092759.109\" class=\"citation\" data-key=\"10.1101/gr.092759.109\">1</a>]</span>. We created our visualization the the R <a href=\"https://github.com/jokergoo/circlize\"><code>circlize</code></a> package <span class=\"citation\">[<a href=\"https://doi.org/10.1093/bioinformatics/btu393\" class=\"citation\" data-key=\"10.1093/bioinformatics/btu393\">2</a>]</span> (<a href=\"https://github.com/dhimmel/integrate/blob/b53b835dbac09101c2036328b3fc72644fcb71bc/viz/auto/2-netviz.ipynb\">notebook</a>).</p>\r\n\r\n<h2>Chord diagram of edges?</h2>\r\n\r\n<p>Another option is to explore a chord diagram showing actual edges (see Fig. 13B in <span class=\"citation\">[<a href=\"https://doi.org/10.1109/tvcg.2006.147\" class=\"citation\" data-key=\"10.1109/tvcg.2006.147\">3</a>]</span>). I'm hesitant to invest time here, but let us know if you think a chord diagram of edges is promising.</p>",
      "body_md": "# Chord diagram of edges per type\r\n\r\n[Chord diagrams](https://en.wikipedia.org/wiki/Chord_diagram), also called radial network diagrams, consist of nodes laid out as segments in a circle and edges as chords connecting the segments. In our example, metanodes are laid out on along the perimeter with chords corresponding to metaedges:\r\n\r\n![Hetionet Chord Diagram](https://github.com/dhimmel/integrate/blob/095747de9efe42a9ed1e23ab18db282e14705cd9/viz/auto/figure/edge-chord-diagram.png?raw=true \"Hetionet v1.0 Chord Diagram\")\r\n\r\nNote that we transform sqaure root transformed the edge count for each metaedge, represented with chord width. The segment width for metanodes does not correspond to the proportion of total nodes which may be slightly confusing.\r\n\r\nChord diagrams were popularized by the [Circos](http://circos.ca/) app [@10.1101/gr.092759.109]. We created our visualization the the R [`circlize`](https://github.com/jokergoo/circlize) package [@10.1093/bioinformatics/btu393] ([notebook](https://github.com/dhimmel/integrate/blob/b53b835dbac09101c2036328b3fc72644fcb71bc/viz/auto/2-netviz.ipynb)).\r\n\r\n## Chord diagram of edges?\r\n\r\nAnother option is to explore a chord diagram showing actual edges (see Fig. 13B in [@10.1109/tvcg.2006.147]). I'm hesitant to invest time here, but let us know if you think a chord diagram of edges is promising.",
      "comment_id": 1277,
      "profile_id": 17,
      "published": "2016-04-18T14:30:25.332207Z",
      "thread_id": 202,
      "url": "/discussion/describing-hetionet-v10-through-visualization-and-statistics/202#5"
    },
    {
      "body_html": "<h1>Hive plots</h1>\r\n\r\n<p>Martin Krzywinski — creator of Circos which led to the technology for making our <a href=\"#5\">chord diagram</a> — also created a type of visualization called a <a href=\"http://www.hiveplot.net/\">hive plot</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/bib/bbr069\" class=\"citation\" data-key=\"10.1093/bib/bbr069\">1</a>]</span>. Hive plots lay nodes out along lines which extend radially from a center point. Edges are drawn as curved lines between nodes. The most mature method for generating hive plots looks to be the <a href=\"https://www.bcgsc.ca/wiki/display/jhive/home\" title=\"jhive - A Java GUI for Hive Plots\"><code>jhive</code></a> Java application.</p>",
      "body_md": "# Hive plots\r\n\r\nMartin Krzywinski -- creator of Circos which led to the technology for making our [chord diagram](#5) -- also created a type of visualization called a [hive plot](http://www.hiveplot.net/) [@10.1093/bib/bbr069]. Hive plots lay nodes out along lines which extend radially from a center point. Edges are drawn as curved lines between nodes. The most mature method for generating hive plots looks to be the [`jhive`](https://www.bcgsc.ca/wiki/display/jhive/home \"jhive - A Java GUI for Hive Plots\") Java application.",
      "comment_id": 1278,
      "profile_id": 17,
      "published": "2016-04-18T14:43:43.077703Z",
      "thread_id": 202,
      "url": "/discussion/describing-hetionet-v10-through-visualization-and-statistics/202#6"
    },
    {
      "body_html": "<h1>Visualizing metaedge informativeness</h1>\r\n\r\n<p>The following figure shows the Δ AUROC for each of the 1,206 metapaths (<a href=\"https://github.com/dhimmel/learn/blob/master/all-features/6-rvisualize.ipynb\">notebook</a>). Metapaths are assigned to their composing metaedges, so the <em>CbGaD</em> metapath will show up under <em>Compound–binds–Gene</em> and <em>Disease–associates–Gene</em>. Metaedges are ordered by their max Δ AUROC metapath, under the assumption that a metapath's performance is limited by its least informative metaedge.</p>\r\n\r\n<p><img src=\"https://github.com/dhimmel/learn/blob/a7766ea00da67f5cf03bd77e6e613a262918f1b8/all-features/data/feature-performance/delta-auroc.png?raw=true\" alt=\"Performance by metaedge\"></p>\r\n\r\n<p>While informativeness varies by metaedge, it appears that almost all data types we integrated are informative of whether a compound treats a disease.</p>",
      "body_md": "# Visualizing metaedge informativeness\r\n\r\nThe following figure shows the Δ AUROC for each of the 1,206 metapaths ([notebook](https://github.com/dhimmel/learn/blob/master/all-features/6-rvisualize.ipynb)). Metapaths are assigned to their composing metaedges, so the _CbGaD_ metapath will show up under _Compound--binds--Gene_ and _Disease--associates--Gene_. Metaedges are ordered by their max Δ AUROC metapath, under the assumption that a metapath's performance is limited by its least informative metaedge.\r\n\r\n![Performance by metaedge](https://github.com/dhimmel/learn/blob/a7766ea00da67f5cf03bd77e6e613a262918f1b8/all-features/data/feature-performance/delta-auroc.png?raw=true)\r\n\r\nWhile informativeness varies by metaedge, it appears that almost all data types we integrated are informative of whether a compound treats a disease.",
      "comment_id": 1279,
      "profile_id": 17,
      "published": "2016-05-17T02:22:19.104756Z",
      "thread_id": 115,
      "url": "/discussion/assessing-the-informativeness-of-features/115#4"
    },
    {
      "body_html": "<h1>Hetionet v1.0 type nomenclature</h1>\r\n\r\n<p>We've settled on a final type nomenclature for Hetionet v1.0 (our hetnet for this project). See the following tables:</p>\r\n\r\n<ul><li><a href=\"https://github.com/dhimmel/hetionet/blob/31e6cb3162dee8a06085709e730380b52278e32a/hetnet/neo4j/labels.tsv\" title=\"Hetionet v1.0 metanode table\"><strong>Metanodes</strong></a> where <code>metanode</code> is the primary name, <code>abbreviation</code> is the 1–2 letter abbreviation, and <code>label</code> is the Neo4j node label.</li><li><a href=\"https://github.com/dhimmel/hetionet/blob/31e6cb3162dee8a06085709e730380b52278e32a/describe/edges/metaedge-styles.tsv\" title=\"Hetionet v1.0 styled metaedge table\"><strong>Metaedges</strong></a> where <code>metaedge</code> is the primary name, <code>unicode_metaedge</code> is a styled version of the primary name, <code>standard_metaedge</code> is the primary edge orientation, and <code>inverted</code> indicates the non-primary edge orientation. The remaining columns are <code>abbreviation</code>, <code>standard_abbreviation</code>, <code>source</code>, and <code>target</code>. </li><li><a href=\"https://github.com/dhimmel/hetionet/blob/31e6cb3162dee8a06085709e730380b52278e32a/hetnet/neo4j/types.tsv\" title=\"Hetionet v1.0 Neo4j relationship type mapping\"><strong>Neo4j relationship types</strong></a> where <code>metaedge</code> is the primary name, <code>rel_type</code> is Neo4j relationship type, and <code>direction</code> notes whether edges are bidirectional (<code>both</code>) or directed (<code>forward</code> or <code>backward</code>).</li></ul>\r\n\r\n<h2>Neo4j type nomenclature</h2>\r\n\r\n<p>We conform to the Neo4j style of CamelCase labels and ALL_CAPS relationship types. In addition, Neo4j relationship types are appended with metaedge standard abbreviations. This adds source/target-metanode awareness to relationship types and <a href=\"https://thinklab.com/discussion/using-the-neo4j-graph-database-for-hetnets/112#6\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d112\">enables optimized queries</a>.</p>",
      "body_md": "# Hetionet v1.0 type nomenclature\r\n\r\nWe've settled on a final type nomenclature for Hetionet v1.0 (our hetnet for this project). See the following tables:\r\n\r\n+ [**Metanodes**](https://github.com/dhimmel/hetionet/blob/31e6cb3162dee8a06085709e730380b52278e32a/hetnet/neo4j/labels.tsv \"Hetionet v1.0 metanode table\") where `metanode` is the primary name, `abbreviation` is the 1--2 letter abbreviation, and `label` is the Neo4j node label.\r\n+ [**Metaedges**](https://github.com/dhimmel/hetionet/blob/31e6cb3162dee8a06085709e730380b52278e32a/describe/edges/metaedge-styles.tsv \"Hetionet v1.0 styled metaedge table\") where `metaedge` is the primary name, `unicode_metaedge` is a styled version of the primary name, `standard_metaedge` is the primary edge orientation, and `inverted` indicates the non-primary edge orientation. The remaining columns are `abbreviation`, `standard_abbreviation`, `source`, and `target`. \r\n+ [**Neo4j relationship types**](https://github.com/dhimmel/hetionet/blob/31e6cb3162dee8a06085709e730380b52278e32a/hetnet/neo4j/types.tsv \"Hetionet v1.0 Neo4j relationship type mapping\") where `metaedge` is the primary name, `rel_type` is Neo4j relationship type, and `direction` notes whether edges are bidirectional (`both`) or directed (`forward` or `backward`).\r\n\r\n## Neo4j type nomenclature\r\n\r\nWe conform to the Neo4j style of CamelCase labels and ALL_CAPS relationship types. In addition, Neo4j relationship types are appended with metaedge standard abbreviations. This adds source/target-metanode awareness to relationship types and [enables optimized queries](https://thinklab.com/discussion/using-the-neo4j-graph-database-for-hetnets/112#6).",
      "comment_id": 1280,
      "profile_id": 17,
      "published": "2016-04-18T17:02:02.916266Z",
      "thread_id": 162,
      "url": "/discussion/data-nomenclature-naming-and-abbreviating-our-network-types/162#8"
    },
    {
      "body_html": "<h1>Genes with more SNPs tend to have higher hetnet degrees</h1>\r\n\r\n<p>A review I worked on with <a href=\"/u/caseygreene\" class=\"username\">@caseygreene</a> was published today <span class=\"citation\">[<a href=\"https://doi.org/10.1161/CIRCGENETICS.115.001181\" class=\"citation\" data-key=\"10.1161/CIRCGENETICS.115.001181\">1</a>]</span>:</p>\r\n\r\n<blockquote><p>Greene CS, Himmelstein DS (2016) <a href=\"https://doi.org/bffr\">Genetic Association–Guided Analysis of Gene Networks for the Study of Complex Traits</a>. <em>Circulation: Cardiovascular Genetics</em></p></blockquote>\r\n\r\n<p>The review explains the <a href=\"http://giant.princeton.edu/gwas/create_new\" title=\"GIANT Webapp\">NetWAS</a> method for prioritizing disease-associated genes <span class=\"citation\">[<a href=\"https://doi.org/10.1038/ng.3259\" class=\"citation\" data-key=\"10.1038/ng.3259\">2</a>]</span>. Additionally, it investigates the relationship between SNP abundance and network degree for human genes <span class=\"citation\">[<a href=\"https://doi.org/10.5281/zenodo.30105\" class=\"citation\" data-key=\"10.5281/zenodo.30105\">3</a>]</span>. I based this analysis on the <a href=\"https://thinklab.com/discussion/one-network-to-rule-them-all/102\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d102\">prerelease of Hetionet</a> — the hetnet constructed for this study. We observed that more connected genes tended to contain more SNPs across several genotyping platforms:</p>\r\n\r\n<p><img src=\"https://github.com/dhimmel/snplentiful/blob/f159bc1007811d26f3b3121209049f6b2899baeb/figure/degree-v-snps.png?raw=true\" alt=\"Hetnet degree versus SNPs in Gene\"></p>\r\n\r\n<p>This finding is important because it shows why network methods that convert from SNP to gene space are prone to bias. Without the integration provided by our hetnet, this analysis would have been time consuming. However, once the different network edges were integrated, the analysis became trivial.</p>",
      "body_md": "# Genes with more SNPs tend to have higher hetnet degrees\r\n\r\nA review I worked on with @caseygreene was published today [@10.1161/CIRCGENETICS.115.001181]:\r\n\r\n> Greene CS, Himmelstein DS (2016) [Genetic Association–Guided Analysis of Gene Networks for the Study of Complex Traits](https://doi.org/bffr). _Circulation: Cardiovascular Genetics_\r\n\r\nThe review explains the [NetWAS](http://giant.princeton.edu/gwas/create_new \"GIANT Webapp\") method for prioritizing disease-associated genes [@10.1038/ng.3259]. Additionally, it investigates the relationship between SNP abundance and network degree for human genes [@10.5281/zenodo.30105]. I based this analysis on the [prerelease of Hetionet](https://thinklab.com/discussion/one-network-to-rule-them-all/102) -- the hetnet constructed for this study. We observed that more connected genes tended to contain more SNPs across several genotyping platforms:\r\n\r\n![Hetnet degree versus SNPs in Gene](https://github.com/dhimmel/snplentiful/blob/f159bc1007811d26f3b3121209049f6b2899baeb/figure/degree-v-snps.png?raw=true)\r\n\r\nThis finding is important because it shows why network methods that convert from SNP to gene space are prone to bias. Without the integration provided by our hetnet, this analysis would have been time consuming. However, once the different network edges were integrated, the analysis became trivial.",
      "comment_id": 1281,
      "profile_id": 17,
      "published": "2016-04-20T15:03:59.767935Z",
      "thread_id": 113,
      "url": "/discussion/tracking-project-reuse-citation-and-publicity/113#7"
    },
    {
      "body_html": "<p>How about this?<br>Just tweaking settings in Cytoscape <br><img src=\"https://raw.githubusercontent.com/dhimmel/integrate/f11d7ce796c5805457fd7b729c91326d93881eee/viz/network-lines.png\" alt=\"daniel_net\"></p>",
      "body_md": "How about this?\r\nJust tweaking settings in Cytoscape \r\n![daniel_net](https://raw.githubusercontent.com/dhimmel/integrate/f11d7ce796c5805457fd7b729c91326d93881eee/viz/network-lines.png)",
      "comment_id": 1282,
      "profile_id": 20,
      "published": "2016-04-20T18:56:49.207861Z",
      "thread_id": 202,
      "url": "/discussion/describing-hetionet-v10-through-visualization-and-statistics/202#7"
    },
    {
      "body_html": "<p>It appears that there are multiple ways to compute <a href=\"https://en.wikipedia.org/wiki/Standardized_coefficient\">standardized coefficients</a> for logistic regression <span class=\"citation\">[<a href=\"https://doi.org/10.1093/sf/89.4.1409\" class=\"citation\" data-key=\"10.1093/sf/89.4.1409\">1</a>, <a href=\"https://doi.org/10.1007/978-981-287-077-3_63\" class=\"citation\" data-key=\"10.1007/978-981-287-077-3_63\">2</a>, <a href=\"https://doi.org/10.1198/000313004x946\" class=\"citation\" data-key=\"10.1198/000313004x946\">3</a>]</span>. We'd like a way to make coefficients comparable across features. <a href=\"/u/alizee\" class=\"username\">@alizee</a>, can you look over this debate and decide on a method? In addition, we should be aware of <a href=\"http://www.mwsug.org/proceedings/2009/stats/MWSUG-2009-D10.pdf\" title=\"Thompson (2009) Ranking Predictors in Logistic Regression\">other approaches</a> for comparing feature importance in logistic regression.</p>",
      "body_md": "It appears that there are multiple ways to compute [standardized coefficients](https://en.wikipedia.org/wiki/Standardized_coefficient) for logistic regression [@10.1093/sf/89.4.1409 @10.1007/978-981-287-077-3_63 @10.1198/000313004x946]. We'd like a way to make coefficients comparable across features. @alizee, can you look over this debate and decide on a method? In addition, we should be aware of [other approaches](http://www.mwsug.org/proceedings/2009/stats/MWSUG-2009-D10.pdf \"Thompson (2009) Ranking Predictors in Logistic Regression\") for comparing feature importance in logistic regression.",
      "comment_id": 1283,
      "profile_id": 17,
      "published": "2016-04-21T19:42:43.253121Z",
      "thread_id": 205,
      "url": "/discussion/computing-standardized-logistic-regression-coefficients/205"
    },
    {
      "body_html": "<h1>Agresti method</h1>\r\n\r\n<p><a href=\"/u/alizee\" class=\"username\">@alizee</a> and I were talking this morning, prior to this discussion, and he arrived at the Agresti method <span class=\"citation\">[<a href=\"https://doi.org/10.1002/0470114754\" class=\"citation\" data-key=\"10.1002/0470114754\">1</a>]</span>. Agresti describes the method as follows (§ 4.5.2 Standardized Interpretations <span class=\"citation\">[<a href=\"https://doi.org/10.1002/9780470114759.ch4\" class=\"citation\" data-key=\"10.1002/9780470114759.ch4\">2</a>]</span>):</p>\r\n\r\n<blockquote><p>With multiple predictors, it is tempting to compare magnitudes of <span class=\"math\">$$\\{\\hat{\\beta}_j\\}$$</span> to compare effects of predictors. For binary predictors, this gives a comparison of conditional log odds ratios, given the other predictors in the model. For quantitative predictors, this is relevant if the predictors have the same units, so a 1-unit change means the same thing for each. Otherwise, it is not meaningful.</p><p>An alternative comparison of effects of quantitative predictors having different units uses <em>standardized coefficients</em>. The model is fitted to standardized predictors, replacing each <span class=\"math\">$$x_j$$</span> by <span class=\"math\">$$(x_j - \\bar{x}_j) \\mathbin{/} s_{x_j}$$</span>. A 1-unit change in the standardized predictor is a standard deviation change in the original predictor. Then, each regression coefficient represents the effect of a standard deviation change in a predictor, controlling for the other variables. The standardized estimate for predictor <span class=\"math\">$$x_j$$</span> is the unstandardized estimate <span class=\"math\">$$\\hat{\\beta}_j$$</span> multiplied by <span class=\"math\">$$s_{x_j}$$</span>.</p></blockquote>\r\n\r\n<p>This method is simple and intuitive. I believe it corresponds to coefficients from converting each predictor to <em>z</em>-scores and then fitting the logistic regression model. I <a href=\"https://github.com/dhimmel/hetior/commit/0e2691810ed7132c2431020c6882b180c1329c76\" title=\"Commit on GitHub\">updated</a> our <code>hetior</code> package — which was previously using a flawed approach — to use the Agresti method.</p>",
      "body_md": "# Agresti method\r\n\r\n@alizee and I were talking this morning, prior to this discussion, and he arrived at the Agresti method [@10.1002/0470114754]. Agresti describes the method as follows (§ 4.5.2 Standardized Interpretations [@10.1002/9780470114759.ch4]):\r\n\r\n> With multiple predictors, it is tempting to compare magnitudes of $$\\{\\hat{\\beta}_j\\}$$ to compare effects of predictors. For binary predictors, this gives a comparison of conditional log odds ratios, given the other predictors in the model. For quantitative predictors, this is relevant if the predictors have the same units, so a 1-unit change means the same thing for each. Otherwise, it is not meaningful.\r\n\r\n> An alternative comparison of effects of quantitative predictors having different units uses _standardized coefficients_. The model is fitted to standardized predictors, replacing each $$x_j$$ by $$(x_j - \\bar{x}_j) \\mathbin{/} s_{x_j}$$. A 1-unit change in the standardized predictor is a standard deviation change in the original predictor. Then, each regression coefficient represents the effect of a standard deviation change in a predictor, controlling for the other variables. The standardized estimate for predictor $$x_j$$ is the unstandardized estimate $$\\hat{\\beta}_j$$ multiplied by $$s_{x_j}$$.\r\n\r\nThis method is simple and intuitive. I believe it corresponds to coefficients from converting each predictor to _z_-scores and then fitting the logistic regression model. I [updated](https://github.com/dhimmel/hetior/commit/0e2691810ed7132c2431020c6882b180c1329c76 \"Commit on GitHub\") our `hetior` package -- which was previously using a flawed approach -- to use the Agresti method.",
      "comment_id": 1284,
      "profile_id": 17,
      "published": "2016-04-21T20:16:45.695287Z",
      "thread_id": 205,
      "url": "/discussion/computing-standardized-logistic-regression-coefficients/205#2"
    },
    {
      "body_html": "<h1>A note on standardized coefficients for logistic regression</h1>\r\n\r\n<p>This note aims at (i) understanding what standardized coefficients are, (ii) sketching the landscape of standardization approaches for logistic regression, (iii) drawing conclusions and guidelines to follow in general, and for our study in particular. I apologize for the length of the piece, but I find the exhaustivity of the result desirable — don't hesitate to jump to the conclusion if short in time.</p>\r\n\r\n<p>This note draws mainly from the most recent review of Menart (2011) <span class=\"citation\">[<a href=\"https://doi.org/10.1093/sf/89.4.1409\" class=\"citation\" data-key=\"10.1093/sf/89.4.1409\">1</a>]</span>, as well as a few other papers <span class=\"citation\">[<a href=\"https://doi.org/10.1007/978-981-287-077-3_63\" class=\"citation\" data-key=\"10.1007/978-981-287-077-3_63\">2</a>, <a href=\"https://doi.org/10.1198/000313004x946\" class=\"citation\" data-key=\"10.1198/000313004x946\">3</a>]</span> for exhaustivity and clarification purposes.</p>\r\n\r\n<h2>Standardization is a transformation of the coefficients (not the model)</h2>\r\n\r\n<p>The goal of standardized coefficients is to specify a same model with different nominal values of its parameters. These transformed values present the main advantage of relying on an objectively defined scale rather than depending on the original metric of the corresponding predictor.</p>\r\n\r\n<p>Standardizing the coefficients is a matter of presentation and interpretation of a given model; it does not modify the model, its hypotheses, or its output. It <em>happens</em> that the approaches presented here sometimes results in parameters that coincide with the <em>expected</em> values for a different model, eg fitted with transformed input data. These are properties of some methods, not the goal of standardization.</p>\r\n\r\n<p>Standardization enables three things that are not possible with unstandardized coefficients. First, it offers an objective scale to coefficients corresponding to variables that have no natural metric. Second, and most importantly, it lets the user compare the effect of different predictor variables within the same model, by simply comparing the values of the corresponding standardized coefficients. Third, standardized coefficients provide an alternative interpretation of the model parameters, based on 'standard deviation' units of the predicted variables (and optionally of the predictor). </p>\r\n\r\n<p>Nevertheless, a few strong cases remain in favor of using unstandardized coefficients. The first one is the practical meaning of unstandardized coefficients when the predictor variable has a meaningful natural metric (like time, in years), or if the predictor is a boolean category (gender). In these cases, the interpretative power associated with unstandardized coefficients and their related parameters (e.g. odd ratios) promotes intuitive understanding and easy communication of the results. The second important problem that comes with (over)using standardized coefficients is their <em>sample specificity</em>. Even when studying the same phenomena, the standardized coefficients will have a different practical unit depending on the sample variance. This can pose significant challenges in interpreting the data, particularly when comparing models.</p>\r\n\r\n<h2>Standardization approaches</h2>\r\n\r\n<p>While standardized coefficients in classic linear regression are well-defined, logistic regression, like other generalized linear models, present additional complexity as a result of the non-linear link function (logit), and non-normal error function (binomial).</p>\r\n\r\n<p>The — historically — first <em>Goodman</em>'s standardization method standardizes each coefficient by its standard-error, effectively performing the equivalent of a Wald-Test. Beyond this first method, irrelevant here, two approaches have been taken. We call the first <em>partial standardization</em>; it leaves the predicted boolean variable untouched when standardizing the coefficients, and solely relies on the dispersion of each corresponding predictor. The second approach, <em>full standardization</em>, incorporates the dispersion of the predicted variable in an attempt to improve the general relevance of the resulting standardized coefficients.</p>\r\n\r\n<p>All these approaches result in sets of coefficients that are proportional to each other for a given model.</p>\r\n\r\n<h3>Partial standardization</h3>\r\n\r\n<p>We list here three variants of partial standardization. In all cases, each standardized coefficient <span class=\"math\">$$b^*$$</span> is a scaling of the corresponding unstandardized coefficient <span class=\"math\">$$b$$</span> by the sample standard deviation of the corresponding predictor <span class=\"math\">$$\\sigma_x$$</span>:</p>\r\n\r\n<div class=\"math\">$$$ b_{PS}^* = b \\cdot \\sigma_x \\big/ C$$$</div>\r\n\r\n<p>...where <span class=\"math\">$$C$$</span> is a constant that depends on the variation.</p>\r\n\r\n<p><strong>Agresti: <span class=\"math\">$$ C = 1 $$</span></strong>. This is the most straightforward and clear approach, where the coefficient is specified in 'per standard deviation' unit of the predictor. The <em>Agresti</em> coefficients are equal to the expected values for the coefficients of the same model fitted on the standardized predictors, if the Maximum Likelihood Estimator is the fitting algorithm.</p>\r\n\r\n<p><strong>SAS: <span class=\"math\">$$ C = \\text{sd}(logis) = \\frac{\\pi}{\\sqrt3} $$</span></strong>. This method scales by the standard deviation of the logistic distribution of unit scale. The resulting coefficients are equal to the expected values for the coefficients of the logistic regression on the standardized predictors, if fitted with Ordinary Least Square. This approach is used in the software SAS. </p>\r\n\r\n<p><strong>Long: <span class=\"math\">$$ C = \\text{sd}(logis) + \\text{sd}(norm) = \\frac{\\pi}{\\sqrt3} + 1 $$</span></strong>, where the standard deviation of the normal distribution is added to the normalization.</p>\r\n\r\n<h3>Full standardization</h3>\r\n\r\n<p>Here, we use the variance of the predicted variable to further scale the coefficients. This provides a closer equivalent to standardized coefficients of classic linear regression.</p>\r\n\r\n<p>The main difficulty resides in the non-meaningful variance of the class outcome, which points to using the variance of the linear predictor <span class=\"math\">$$\\mathrm{logit}(Y)$$</span>. Nevertheless, because <span class=\"math\">$$\\mathrm{logit}(Y)$$</span> takes only values of <span class=\"math\">$$\\pm\\infty$$</span>, its variance is not defined and we need proxies for it, based on <span class=\"math\">$$\\hat{Y}$$</span>, the <em>predicted</em> outcome. <em>Menard</em><span class=\"citation\">[<a href=\"https://doi.org/10.4135/9781412983433\" class=\"citation\" data-key=\"10.4135/9781412983433\">4</a>]</span> proposes the variance estimate <span class=\"math\">$$ \\sigma_{\\mathrm{logit}(\\hat{Y})}^2 / R^2 $$</span>, while <em>Long</em> proposes to use the variance of the underlying latent variable <span class=\"math\">$$ \\sigma_{\\mathrm{logit}(\\hat{Y})}^2 + \\pi^2 / 3 $$</span>. The results can be expressed with the same formalism as above:</p>\r\n\r\n<p><strong>Menard: <span class=\"math\">$$ C = \\sigma_{\\mathrm{logit}(\\hat{Y})} \\big/ R $$</span></strong> This method, presented as superior than the others by its author <span class=\"citation\">[<a href=\"https://doi.org/10.1093/sf/89.4.1409\" class=\"citation\" data-key=\"10.1093/sf/89.4.1409\">1</a>]</span>, has the downside of relying on the R-square of the model, whose computation is ambiguous (Cox &amp; Snell, Nagelkerke, and others have proposed <a href=\"http://www.ats.ucla.edu/stat/mult_pkg/faq/general/Psuedo_RSquareds.htm\"><em>pseudo</em>-R-squared</a> measures for logistic regression).</p>\r\n\r\n<p><strong>Long (full): <span class=\"math\">$$ C = \\sqrt{\\sigma_{\\mathrm{logit}(\\hat{Y})} ^2 + \\pi^2/3} $$</span></strong></p>\r\n\r\n<h2>Conclusion</h2>\r\n\r\n<p>Standardized coefficients are extremely valuable, mainly to (i) give a meaning to the coefficient affecting a predictor that has no natural metric and (ii) compare effects of predictors reported in different units.</p>\r\n\r\n<p>To achieve these two goals, I advise using the most straightforward, simple <em>Agresti</em> method of standardization:</p>\r\n\r\n<div class=\"math\">$$$ b^*_A = b \\cdot \\sigma_X $$$</div>\r\n\r\n<p>Further, to improve the general relevance of the standardized coefficients, one can account for the sample dispersion of the outcome variable, and use <em>fully standardized</em> coefficients as first introduced by <em>Menard</em> (1995). When using <em>Menard</em>'s standardization, one must choose and report the measure of pseudo-R-squared used:</p>\r\n\r\n<div class=\"math\">$$$ b^*_M = b \\cdot \\sigma_X \\cdot \\frac{R}{\\sigma_{\\mathrm{logit}(\\hat{Y})}}$$$</div>\r\n\r\n<p>Standardized coefficients don't change the model. If they are used as the main specification of the model, the variables need to be scaled accordingly, and the intercept should be transformed as the result. </p>\r\n\r\n<h3>For ML models on hetionet</h3>\r\n\r\n<p>For <em>hetionet</em>'s edge prediction problems,  we use DWPCs features, whose unit is highly non-intuitive and of variable range across metapaths. Therefore, we settled on using exclusively standardized coefficients of the <em>Agresti</em> method.</p>",
      "body_md": "# A note on standardized coefficients for logistic regression\r\n\r\nThis note aims at (i) understanding what standardized coefficients are, (ii) sketching the landscape of standardization approaches for logistic regression, (iii) drawing conclusions and guidelines to follow in general, and for our study in particular. I apologize for the length of the piece, but I find the exhaustivity of the result desirable -- don't hesitate to jump to the conclusion if short in time.\r\n\r\nThis note draws mainly from the most recent review of Menart (2011) [@10.1093/sf/89.4.1409], as well as a few other papers [@10.1007/978-981-287-077-3_63 @10.1198/000313004x946] for exhaustivity and clarification purposes.\r\n\r\n## Standardization is a transformation of the coefficients (not the model)\r\n\r\nThe goal of standardized coefficients is to specify a same model with different nominal values of its parameters. These transformed values present the main advantage of relying on an objectively defined scale rather than depending on the original metric of the corresponding predictor.\r\n\r\nStandardizing the coefficients is a matter of presentation and interpretation of a given model; it does not modify the model, its hypotheses, or its output. It _happens_ that the approaches presented here sometimes results in parameters that coincide with the _expected_ values for a different model, eg fitted with transformed input data. These are properties of some methods, not the goal of standardization.\r\n\r\nStandardization enables three things that are not possible with unstandardized coefficients. First, it offers an objective scale to coefficients corresponding to variables that have no natural metric. Second, and most importantly, it lets the user compare the effect of different predictor variables within the same model, by simply comparing the values of the corresponding standardized coefficients. Third, standardized coefficients provide an alternative interpretation of the model parameters, based on 'standard deviation' units of the predicted variables (and optionally of the predictor). \r\n\r\nNevertheless, a few strong cases remain in favor of using unstandardized coefficients. The first one is the practical meaning of unstandardized coefficients when the predictor variable has a meaningful natural metric (like time, in years), or if the predictor is a boolean category (gender). In these cases, the interpretative power associated with unstandardized coefficients and their related parameters (e.g. odd ratios) promotes intuitive understanding and easy communication of the results. The second important problem that comes with (over)using standardized coefficients is their *sample specificity*. Even when studying the same phenomena, the standardized coefficients will have a different practical unit depending on the sample variance. This can pose significant challenges in interpreting the data, particularly when comparing models.\r\n\r\n## Standardization approaches\r\n\r\nWhile standardized coefficients in classic linear regression are well-defined, logistic regression, like other generalized linear models, present additional complexity as a result of the non-linear link function (logit), and non-normal error function (binomial).\r\n\r\nThe -- historically -- first _Goodman_'s standardization method standardizes each coefficient by its standard-error, effectively performing the equivalent of a Wald-Test. Beyond this first method, irrelevant here, two approaches have been taken. We call the first _partial standardization_; it leaves the predicted boolean variable untouched when standardizing the coefficients, and solely relies on the dispersion of each corresponding predictor. The second approach, _full standardization_, incorporates the dispersion of the predicted variable in an attempt to improve the general relevance of the resulting standardized coefficients.\r\n\r\nAll these approaches result in sets of coefficients that are proportional to each other for a given model.\r\n\r\n### Partial standardization\r\n\r\nWe list here three variants of partial standardization. In all cases, each standardized coefficient $$b^*$$ is a scaling of the corresponding unstandardized coefficient $$b$$ by the sample standard deviation of the corresponding predictor $$\\sigma_x$$:\r\n\r\n$$$ b_{PS}^* = b \\cdot \\sigma_x \\big/ C$$$\r\n\r\n...where $$C$$ is a constant that depends on the variation.\r\n \r\n**Agresti: $$ C = 1 $$**. This is the most straightforward and clear approach, where the coefficient is specified in 'per standard deviation' unit of the predictor. The _Agresti_ coefficients are equal to the expected values for the coefficients of the same model fitted on the standardized predictors, if the Maximum Likelihood Estimator is the fitting algorithm.\r\n\r\n**SAS: $$ C = \\text{sd}(logis) = \\frac{\\pi}{\\sqrt3} $$**. This method scales by the standard deviation of the logistic distribution of unit scale. The resulting coefficients are equal to the expected values for the coefficients of the logistic regression on the standardized predictors, if fitted with Ordinary Least Square. This approach is used in the software SAS. \r\n\r\n**Long: $$ C = \\text{sd}(logis) + \\text{sd}(norm) = \\frac{\\pi}{\\sqrt3} + 1 $$**, where the standard deviation of the normal distribution is added to the normalization.\r\n\r\n### Full standardization\r\n\r\nHere, we use the variance of the predicted variable to further scale the coefficients. This provides a closer equivalent to standardized coefficients of classic linear regression.\r\n\r\nThe main difficulty resides in the non-meaningful variance of the class outcome, which points to using the variance of the linear predictor $$\\mathrm{logit}(Y)$$. Nevertheless, because $$\\mathrm{logit}(Y)$$ takes only values of $$\\pm\\infty$$, its variance is not defined and we need proxies for it, based on $$\\hat{Y}$$, the _predicted_ outcome. _Menard_[@10.4135/9781412983433] proposes the variance estimate $$ \\sigma_{\\mathrm{logit}(\\hat{Y})}^2 / R^2 $$, while _Long_ proposes to use the variance of the underlying latent variable $$ \\sigma_{\\mathrm{logit}(\\hat{Y})}^2 + \\pi^2 / 3 $$. The results can be expressed with the same formalism as above:\r\n\r\n**Menard: $$ C = \\sigma_{\\mathrm{logit}(\\hat{Y})} \\big/ R $$** This method, presented as superior than the others by its author [@10.1093/sf/89.4.1409], has the downside of relying on the R-square of the model, whose computation is ambiguous (Cox & Snell, Nagelkerke, and others have proposed [_pseudo_-R-squared](http://www.ats.ucla.edu/stat/mult_pkg/faq/general/Psuedo_RSquareds.htm) measures for logistic regression).\r\n\r\n**Long (full): $$ C = \\sqrt{\\sigma_{\\mathrm{logit}(\\hat{Y})} ^2 + \\pi^2/3} $$**\r\n\r\n## Conclusion\r\n\r\nStandardized coefficients are extremely valuable, mainly to (i) give a meaning to the coefficient affecting a predictor that has no natural metric and (ii) compare effects of predictors reported in different units.\r\n\r\nTo achieve these two goals, I advise using the most straightforward, simple _Agresti_ method of standardization:\r\n\r\n$$$ b^*_A = b \\cdot \\sigma_X $$$\r\n\r\nFurther, to improve the general relevance of the standardized coefficients, one can account for the sample dispersion of the outcome variable, and use _fully standardized_ coefficients as first introduced by _Menard_ (1995). When using _Menard_'s standardization, one must choose and report the measure of pseudo-R-squared used:\r\n\r\n$$$ b^*_M = b \\cdot \\sigma_X \\cdot \\frac{R}{\\sigma_{\\mathrm{logit}(\\hat{Y})}}$$$\r\n\r\nStandardized coefficients don't change the model. If they are used as the main specification of the model, the variables need to be scaled accordingly, and the intercept should be transformed as the result. \r\n\r\n### For ML models on hetionet\r\n\r\nFor _hetionet_'s edge prediction problems,  we use DWPCs features, whose unit is highly non-intuitive and of variable range across metapaths. Therefore, we settled on using exclusively standardized coefficients of the _Agresti_ method.",
      "comment_id": 1286,
      "profile_id": 23,
      "published": "2016-05-01T23:34:02.781816Z",
      "thread_id": 205,
      "url": "/discussion/computing-standardized-logistic-regression-coefficients/205#3"
    },
    {
      "body_html": "<h2>Standardized coefficients &amp; glmnet</h2>\r\n\r\n<p>In the edge prediction problem for <em>rephetio</em>, we use the R-package <code>glmnet</code> to perform lasso and ridge regression, in order to perform feature selection while fitting the model.</p>\r\n\r\n<p>In the light of the note above, we wanted to adapt the <em>Artesi</em> standardization to the tools we are using.</p>\r\n\r\n<h2>Summary</h2>\r\n\r\n<p><code>glmnet</code>, by default, standardizes the predictor variables <strong>before</strong> fitting the model. After checking in the source code and testing (see below) we came to the conclusion that the computed coefficients were then <em>reverse</em> standardized, with the inverse of the Artesi transformation, in order to report the coefficients in their natural metric †.</p>\r\n\r\n<p>Hence, there are three way to use standardization with the <code>glmnet</code> package:</p>\r\n\r\n<ol><li><p><strong>Untransformed variables, specifying <code>standardize = FALSE</code></strong>: this corresponds to taking into account the units of the variables when fitting the regularisation. Because of the nature of regularization, this setting is usually undesirable and should be reserved to specific, well understood use-cases where keeping the variables in their natural metrics is justified. This is the only method where standardization of the coefficients after fitting of the model, as described in the note above, is appropriate.</p></li><li><p><strong>Untransformed variables, keeping the default <code>standardize = TRUE</code></strong>: This is the easiest option and advised for quick analysis. In order to get the standardized coefficients that actually were the result of the fitting process, apply the Agresti transformation.</p></li><li><p><strong>Standardized variables, with <code>standardize = FALSE</code></strong>: This last method has three key features: (i) it lets the user diagnose the regularisation in the correct units for the coefficients (using, e.g. <code>glmnet:::plot.glmnet()</code>); (ii) it lets the user deal differently with boolean or categorical variables if necessary; (iii) it makes obvious that the regularization has been done on transformed variables. The main disadvantage is that one must separately keep record of the scaling coefficients for future use of the model. If the variables are each standardized with the standard deviation (eg with <code>scale()</code>), this approach lead to the same <em>model</em> as the previous one.</p></li></ol>\r\n\r\n<h2>Proof</h2>\r\n\r\n<p>We needed to understand how were the variables standardized when using the <code>glmnet</code> package, and more importantly how were the coefficients transformed back in their natural metric after fitting the model with those standardized variables.</p>\r\n\r\n<p>Unfortunately for our digging purposes (i) the code is written in FORTRAN, which made us nostalgic but required some getting used to; (ii) the code does not live on a source sharing platform, but fortunately has <a href=\"https://github.com/cran/glmnet\">a mirror on github</a>, like all packages published on CRAN.</p>\r\n\r\n<p>Everything we are interested in is in the <a href=\"https://github.com/cran/glmnet/blob/d80f1b1351ff68c03492aa654d437a99b4de5b49/src/glmnet5.f90\">fortran source code file</a>, whose <a href=\"https://github.com/cran/glmnet/blob/d80f1b1351ff68c03492aa654d437a99b4de5b49/src/glmnet5.f90#L280\">detailed comments</a> on the top alieviated the need to reverse-enginner the variable names.</p>\r\n\r\n<ol><li><p>Definition of the <code>lognet</code> function (<code>routine</code>) starts at line <a href=\"https://github.com/cran/glmnet/blob/d80f1b1351ff68c03492aa654d437a99b4de5b49/src/glmnet5.f90#L2032\">2032</a>. We will follow the track of the standardization flag <code>isd</code>.</p></li><li><p>Line <a href=\"https://github.com/cran/glmnet/blob/d80f1b1351ff68c03492aa654d437a99b4de5b49/src/glmnet5.f90#L2154\">2154-2159</a>, we withness the centering and standardization of the variable array <code>x</code> by the vector of means <code>xms</code> and the vector of standard deviations <code>xs</code>, within the subfunction <code>lstandard1</code>:<br></p><pre><code class=\"no-highlight hljs\">  if(ju(j).eq.0)goto 12561                                             1519\r\n  xm(j)=dot_product(w,x(:,j))                                          1519\r\n  x(:,j)=x(:,j)-xm(j)                                                  1520\r\n  if(isd .le. 0)goto 12581                                             1520\r\n  xs(j)=sqrt(dot_product(w,x(:,j)**2))                                 1520\r\n  x(:,j)=x(:,j)/xs(j)                                                  1520</code></pre></li><li><p>Line <a href=\"https://github.com/cran/glmnet/blob/d80f1b1351ff68c03492aa654d437a99b4de5b49/src/glmnet5.f90#L2117\">2117</a>:<br></p><pre><code class=\"no-highlight hljs\">  ca(l,ic,k)=ca(l,ic,k)/xs(ia(l))                                      1499</code></pre></li><li><p>And finally, line <a href=\"https://github.com/cran/glmnet/blob/d80f1b1351ff68c03492aa654d437a99b4de5b49/src/glmnet5.f90#L2125\">2125</a>, the intercept is computed (if the flag <code>intr</code> is 1):<br></p><pre><code class=\"no-highlight hljs\">  a0(ic,k)=a0(ic,k)-dot_product(ca(1:nk,ic,k),xm(ia(1:nk)))            1501</code></pre></li></ol>\r\n\r\n<h2>Test</h2>\r\n\r\n<p>I wrote a quick <a href=\"https://htmlpreview.github.io/?https://github.com/antoine-lizee/R-Miscs/blob/adc01ea6d49514efb047c58376126b4480929eeb/Stat-glm_coeffs.html\">R report</a> to test our conclusions on the famous <code>diamonds</code> dataset. </p>\r\n\r\n<hr>\r\n\r\n<p>† It also must be noted that <code>glmnet</code>, being written in fortran, does not make any difference between types of variables. As a result, the categorical and boolean predictor are treated as numeric vectors and standardized accordingly.</p>",
      "body_md": "## Standardized coefficients & glmnet\r\n\r\nIn the edge prediction problem for _rephetio_, we use the R-package `glmnet` to perform lasso and ridge regression, in order to perform feature selection while fitting the model.\r\n\r\nIn the light of the note above, we wanted to adapt the _Artesi_ standardization to the tools we are using.\r\n\r\n## Summary\r\n\r\n`glmnet`, by default, standardizes the predictor variables **before** fitting the model. After checking in the source code and testing (see below) we came to the conclusion that the computed coefficients were then _reverse_ standardized, with the inverse of the Artesi transformation, in order to report the coefficients in their natural metric †.\r\n\r\nHence, there are three way to use standardization with the `glmnet` package:\r\n\r\n1. **Untransformed variables, specifying `standardize = FALSE`**: this corresponds to taking into account the units of the variables when fitting the regularisation. Because of the nature of regularization, this setting is usually undesirable and should be reserved to specific, well understood use-cases where keeping the variables in their natural metrics is justified. This is the only method where standardization of the coefficients after fitting of the model, as described in the note above, is appropriate.\r\n\r\n2. **Untransformed variables, keeping the default `standardize = TRUE`**: This is the easiest option and advised for quick analysis. In order to get the standardized coefficients that actually were the result of the fitting process, apply the Agresti transformation.\r\n\r\n3. **Standardized variables, with `standardize = FALSE`**: This last method has three key features: (i) it lets the user diagnose the regularisation in the correct units for the coefficients (using, e.g. `glmnet:::plot.glmnet()`); (ii) it lets the user deal differently with boolean or categorical variables if necessary; (iii) it makes obvious that the regularization has been done on transformed variables. The main disadvantage is that one must separately keep record of the scaling coefficients for future use of the model. If the variables are each standardized with the standard deviation (eg with `scale()`), this approach lead to the same _model_ as the previous one.\r\n\r\n## Proof\r\n\r\nWe needed to understand how were the variables standardized when using the `glmnet` package, and more importantly how were the coefficients transformed back in their natural metric after fitting the model with those standardized variables.\r\n\r\nUnfortunately for our digging purposes (i) the code is written in FORTRAN, which made us nostalgic but required some getting used to; (ii) the code does not live on a source sharing platform, but fortunately has [a mirror on github](https://github.com/cran/glmnet), like all packages published on CRAN.\r\n\r\nEverything we are interested in is in the [fortran source code file](https://github.com/cran/glmnet/blob/d80f1b1351ff68c03492aa654d437a99b4de5b49/src/glmnet5.f90), whose [detailed comments](https://github.com/cran/glmnet/blob/d80f1b1351ff68c03492aa654d437a99b4de5b49/src/glmnet5.f90#L280) on the top alieviated the need to reverse-enginner the variable names.\r\n\r\n0. Definition of the `lognet` function (`routine`) starts at line [2032](https://github.com/cran/glmnet/blob/d80f1b1351ff68c03492aa654d437a99b4de5b49/src/glmnet5.f90#L2032). We will follow the track of the standardization flag `isd`.\r\n\r\n1. Line [2154-2159](https://github.com/cran/glmnet/blob/d80f1b1351ff68c03492aa654d437a99b4de5b49/src/glmnet5.f90#L2154), we withness the centering and standardization of the variable array `x` by the vector of means `xms` and the vector of standard deviations `xs`, within the subfunction `lstandard1`:\r\n```\r\n      if(ju(j).eq.0)goto 12561                                             1519\r\n      xm(j)=dot_product(w,x(:,j))                                          1519\r\n      x(:,j)=x(:,j)-xm(j)                                                  1520\r\n      if(isd .le. 0)goto 12581                                             1520\r\n      xs(j)=sqrt(dot_product(w,x(:,j)**2))                                 1520\r\n      x(:,j)=x(:,j)/xs(j)                                                  1520\r\n```\r\n\r\n2. Line [2117](https://github.com/cran/glmnet/blob/d80f1b1351ff68c03492aa654d437a99b4de5b49/src/glmnet5.f90#L2117):\r\n```\r\n      ca(l,ic,k)=ca(l,ic,k)/xs(ia(l))                                      1499\r\n```\r\n\r\n3. And finally, line [2125](https://github.com/cran/glmnet/blob/d80f1b1351ff68c03492aa654d437a99b4de5b49/src/glmnet5.f90#L2125), the intercept is computed (if the flag `intr` is 1):\r\n```\r\n      a0(ic,k)=a0(ic,k)-dot_product(ca(1:nk,ic,k),xm(ia(1:nk)))            1501\r\n```\r\ntaking into account the centering of variables. This could be written: $$a_0^* = a_0 + \\sum ca_i \\cdot xm_i$$\r\n\r\n\r\n## Test\r\n\r\nI wrote a quick [R report](https://htmlpreview.github.io/?https://github.com/antoine-lizee/R-Miscs/blob/adc01ea6d49514efb047c58376126b4480929eeb/Stat-glm_coeffs.html) to test our conclusions on the famous `diamonds` dataset. \r\n\r\n---\r\n\r\n† It also must be noted that `glmnet`, being written in fortran, does not make any difference between types of variables. As a result, the categorical and boolean predictor are treated as numeric vectors and standardized accordingly.",
      "comment_id": 1287,
      "profile_id": 23,
      "published": "2016-05-02T20:45:01.106725Z",
      "thread_id": 205,
      "url": "/discussion/computing-standardized-logistic-regression-coefficients/205#5"
    },
    {
      "body_html": "<p>I agree that using the <em>Agresti</em> makes the most sense. Since we're not interested in comparing our logistic models to models created using different regression techniques, I don't think the complexity of meddling with <em>C</em> is justified. Also most modern implementations will be using maximum likelihood estimatation, right <a href=\"/u/alizee\" class=\"username\">@alizee</a>? So of the partial methods, <em>Agresti</em> will create coefficients equivalent to the a logistic model fit on <em>z</em>-score features.</p>\r\n\r\n<p>Regarding the full standardization and the choice of a pseudo R-squared: Would you advise against using the Tjur coefficient of discrimination <span class=\"citation\">[<a href=\"https://doi.org/10.1198/tast.2009.08210\" class=\"citation\" data-key=\"10.1198/tast.2009.08210\">1</a>]</span>? Or would Tjur's statistic also work?</p>\r\n\r\n<blockquote><p>the corresponding intercept should be computed ad hoc</p></blockquote>\r\n\r\n<p>What formula should be used for computing the intercept?</p>",
      "body_md": "I agree that using the _Agresti_ makes the most sense. Since we're not interested in comparing our logistic models to models created using different regression techniques, I don't think the complexity of meddling with _C_ is justified. Also most modern implementations will be using maximum likelihood estimatation, right @alizee? So of the partial methods, _Agresti_ will create coefficients equivalent to the a logistic model fit on _z_-score features.\r\n\r\nRegarding the full standardization and the choice of a pseudo R-squared: Would you advise against using the Tjur coefficient of discrimination [@10.1198/tast.2009.08210]? Or would Tjur's statistic also work?\r\n\r\n> the corresponding intercept should be computed ad hoc\r\n\r\nWhat formula should be used for computing the intercept?",
      "comment_id": 1289,
      "profile_id": 17,
      "published": "2016-05-02T02:54:32.970448Z",
      "thread_id": 205,
      "url": "/discussion/computing-standardized-logistic-regression-coefficients/205#4"
    },
    {
      "body_html": "<h1>Background</h1>\r\n\r\n<p>This discussion will describe the machine learning pipeline used by Project Rephetio to predict the probability that a compound treats a disease. Our method derives from a 2011 study to predict coauthorship <span class=\"citation\">[<a href=\"https://doi.org/10.1109/ASONAM.2011.112\" class=\"citation\" data-key=\"10.1109/ASONAM.2011.112\">1</a>]</span> and our 2015 study to predict disease–gene associations <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1004259\">2</a>]</span>. Several months of investigation by <a href=\"/u/alizee\" class=\"username\">@alizee</a>, <a href=\"/u/sergiobaranzini\" class=\"username\">@sergiobaranzini</a>, and I have led to several advances in our algorithm, which we call <em>metapath-based hetnet edge prediction</em> or HNEP for short.</p>\r\n\r\n<p>The founding principal behind HNEP is to identify types of paths (metapaths) that can predict whether two nodes are connected. For Project Rephetio, we are modeling whether a compound (source node) treats (prediction edge) a disease (target node). For each compound–disease pair (observation), we extract the prevalence of specific metapaths from the hetnet using a metric called <em>degree-weighted path count</em> (DWPC). The DWPC quantifies the number of paths between a source and target node, while adjusting for network degree along the path <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1004259\">2</a>]</span>. The degree-weighting downweights paths through high-degree nodes, which by their nature tend to be less informative.</p>\r\n\r\n<p>From the hetnet, we extract a feature matrix whose rows represent compound–disease pairs and whose columns represent features (the vast majority of which are DWPCs corresponding to specific metapaths). Some observations are positives (treatments in our case) and some observations are negatives (non-treatments in our case). We fit a logistic regression model that takes features as input and predicts the probability of treatment as output. </p>\r\n\r\n<p>Since we have many features, we use regularization when fitting our regression models, which penalizes complexity to prevent overfitting and accommodate correlations between features. We use two specific cases of elastic net regularization <span class=\"citation\">[<a href=\"https://doi.org/10.1111/j.1467-9868.2005.00503.x\" class=\"citation\" data-key=\"10.1111/j.1467-9868.2005.00503.x\">3</a>]</span>: the ridge and the lasso. Both perform coefficient shrinkage but lasso also performs variable selection. We use the glmnet package in R to fit our models, which implements cross-validation to choose an optimal regularization strength <span class=\"citation\">[<a href=\"https://doi.org/10.18637/jss.v033.i01\" class=\"citation\" data-key=\"10.18637/jss.v033.i01\">4</a>]</span>. The logistic regression model is responsible for learning <em>how</em> to predict treatments from the network-based features. </p>\r\n\r\n<p>Next, we'll describe the detailed machine learning pipeline used in Project Rephetio.</p>",
      "body_md": "# Background\r\n\r\nThis discussion will describe the machine learning pipeline used by Project Rephetio to predict the probability that a compound treats a disease. Our method derives from a 2011 study to predict coauthorship [@10.1109/ASONAM.2011.112] and our 2015 study to predict disease--gene associations [@10.1371/journal.pcbi.1004259]. Several months of investigation by @alizee, @sergiobaranzini, and I have led to several advances in our algorithm, which we call _metapath-based hetnet edge prediction_ or HNEP for short.\r\n\r\nThe founding principal behind HNEP is to identify types of paths (metapaths) that can predict whether two nodes are connected. For Project Rephetio, we are modeling whether a compound (source node) treats (prediction edge) a disease (target node). For each compound--disease pair (observation), we extract the prevalence of specific metapaths from the hetnet using a metric called _degree-weighted path count_ (DWPC). The DWPC quantifies the number of paths between a source and target node, while adjusting for network degree along the path [@10.1371/journal.pcbi.1004259]. The degree-weighting downweights paths through high-degree nodes, which by their nature tend to be less informative.\r\n\r\nFrom the hetnet, we extract a feature matrix whose rows represent compound--disease pairs and whose columns represent features (the vast majority of which are DWPCs corresponding to specific metapaths). Some observations are positives (treatments in our case) and some observations are negatives (non-treatments in our case). We fit a logistic regression model that takes features as input and predicts the probability of treatment as output. \r\n\r\nSince we have many features, we use regularization when fitting our regression models, which penalizes complexity to prevent overfitting and accommodate correlations between features. We use two specific cases of elastic net regularization [@10.1111/j.1467-9868.2005.00503.x]: the ridge and the lasso. Both perform coefficient shrinkage but lasso also performs variable selection. We use the glmnet package in R to fit our models, which implements cross-validation to choose an optimal regularization strength [@10.18637/jss.v033.i01]. The logistic regression model is responsible for learning _how_ to predict treatments from the network-based features. \r\n\r\nNext, we'll describe the detailed machine learning pipeline used in Project Rephetio.",
      "comment_id": 1293,
      "profile_id": 17,
      "published": "2016-05-04T05:28:16.489552Z",
      "thread_id": 210,
      "url": "/discussion/our-hetnet-edge-prediction-methodology-the-modeling-framework-for-project-rephetio/210"
    },
    {
      "body_html": "<h1>Machine learning pipeline</h1>\r\n\r\n<p><strong>Observations.</strong> We identified all compounds and diseases that are connected by at least one edge resulting in <a href=\"https://github.com/dhimmel/learn/blob/5e61aed9789913d5b3525bb83eba80e0fcc060a4/summary/compounds.tsv\">1,538 compounds</a> and <a href=\"https://github.com/dhimmel/learn/blob/5e61aed9789913d5b3525bb83eba80e0fcc060a4/summary/diseases.tsv\">136 diseases</a>. Hence, we have 209,168 possible compound–disease pairs. 755 or 0.36% of these pairs are treatments and 390 or 0.19% are palliative (see <a href=\"https://github.com/dhimmel/learn/blob/5e61aed9789913d5b3525bb83eba80e0fcc060a4/summary/indications.tsv\">indications</a>).</p>\r\n\r\n<p><strong>Features.</strong> We have three types of features:</p>\r\n\r\n<ol><li><strong>The prior</strong> is a single feature equal to the logit-transformed <a href=\"https://thinklab.com/discussion/network-edge-prediction-estimating-the-prior/201#2\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d201\">prior probability of treatment</a>. The prior incorporates the probability that a compound treats a disease based only on their treatment degrees.</li><li><strong>Degree features</strong> correspond to each metaedge that connects either a compound or disease. In total we have 16 degree features, 8 for compound degrees and 8 for disease degrees. Degree features count either the compound or disease degree for a given metaedge and thus only depend on either the source or target node. Degree features are <a href=\"https://thinklab.com/discussion/transforming-dwpcs-for-hetnet-edge-prediction/193#6\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d193\">IHS transformed</a>.</li><li><strong>DWPCs</strong> make up the vast majority of features. Each DWPC corresponds to a metapath. We consider the 1,206 metapaths that traverse from compound to disease and have lengths 2–4. We use <em>w</em> = 0.4 as the damping exponent when computing DWPCs. DWPCs are <a href=\"https://thinklab.com/discussion/transforming-dwpcs-for-hetnet-edge-prediction/193#6\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d193\">mean scaled and IHS transformed</a>.</li></ol>\r\n\r\n<p><strong>Stages.</strong> The DWPC features are computed by querying the Neo4j graph database. The queries are computationally intensive. Thus far, our runtime bottleneck has been <a href=\"https://thinklab.com/discussion/estimating-the-complexity-of-hetnet-traversal/187\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d187\">network traversal</a>. Computing all 252,256,608 DWPC queries (209,168 observations × 1,206 DWPCs) is impractical. Accordingly, we adopted a shortcut by splitting the machine learning process into two stages: the all-features stage and the all-observations stage.</p>\r\n\r\n<h2>Stage 1: all features</h2>\r\n\r\n<p>The purpose of the all-features stage is to assess feature performance and perform feature selection. For this stage, we include all 755 positives but randomly select 3,020 negatives (4 × the # of positives).</p>\r\n\r\n<p>In addition to the unpermuted hetnet, we compute DWPCs on 5 permuted hetnets. For each permuted hetnet, we compute features for the 755 positives and 3,020 random negatives corresponding to that permutation (referred to as primary observations). We also compute DWPCs for any observations that were assessed on the unpermuted network but were not primary observations for a given permuted hetnet.</p>\r\n\r\n<p>In total, we computed 46,867,572 DWPCs for the all-features stage. Computing these DWPCs took 4 days and 11 hours using a multithreading approach to perform up to 12 queries in parallel (<a href=\"https://github.com/dhimmel/learn/blob/6ffd61f209a182d89c5becd96203850f3c5e13e3/all-features/3-extract.ipynb\">notebook</a>).</p>\r\n\r\n<p>On the all features dataset, we identified <a href=\"https://thinklab.com/discussion/transforming-dwpcs-for-hetnet-edge-prediction/193\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d193\">how to transform DWPCs</a> to address their highly skewed distribution. We also <a href=\"https://thinklab.com/discussion/network-edge-prediction-how-to-deal-with-self-testing/194\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d194\">learned how</a> the prior probability of treatment affects model performance. This investigation led us to include the <code>prior_logit</code> feature mentioned above.</p>\r\n\r\n<p>For each feature, we computed <a href=\"https://thinklab.com/discussion/assessing-the-informativeness-of-features/115#3\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d115\">several measures of performance</a>. These feature-specific performance measures indicate whether the DWPCs for a given metapath reliably discriminate whether a drug treats a disease. We use this information to filter the majority of DWPC features, which are not predictive or suffer from an <a href=\"https://thinklab.com/discussion/edge-dropout-contamination-in-hetnet-edge-prediction/215\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d215\">edge-dropout contamination issue</a>. The DWPCs from permuted hetnets are used here as baseline measures to assess the contribution of edge specificity.</p>\r\n\r\n<h2>Stage 2: all observations</h2>\r\n\r\n<p>Proceeding with the metapaths selected in Stage 1 (see <a href=\"#3\">next comment</a>), we compute DWPCs for all 209,168 observations on the unpermuted hetnet. After transforming the degree and DWPC features, we <a href=\"https://thinklab.com/discussion/computing-standardized-logistic-regression-coefficients/205\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d205\">standardize</a> all variables besides the prior. Standardization allows us to decompose the linear predictor to assess each feature's contribution to a prediction compared to its mean.</p>\r\n\r\n<p>We fit a logistic regression model with the prior, the degree features, and the selected DWPC features. However, this model is fit only on the 29,799 observations with a non-zero prior. From this model, we predict the probability of treatment for all observations. We enable predictions for zero priors by setting the prior for every observation equal to the mean prevalence of positives. Hence, it's important that the model assigns a coefficient near 1.0 to the <code>prior_logit</code> feature. In essence, we're erasing the effect of how many treatments each compound and disease have, since this knowledge is otherwise overpowering. The end result is a treatment-degree-naive prediction of whether each compound treats each disease.</p>",
      "body_md": "# Machine learning pipeline\r\n\r\n**Observations.** We identified all compounds and diseases that are connected by at least one edge resulting in [1,538 compounds](https://github.com/dhimmel/learn/blob/5e61aed9789913d5b3525bb83eba80e0fcc060a4/summary/compounds.tsv) and [136 diseases](https://github.com/dhimmel/learn/blob/5e61aed9789913d5b3525bb83eba80e0fcc060a4/summary/diseases.tsv). Hence, we have 209,168 possible compound--disease pairs. 755 or 0.36% of these pairs are treatments and 390 or 0.19% are palliative (see [indications](https://github.com/dhimmel/learn/blob/5e61aed9789913d5b3525bb83eba80e0fcc060a4/summary/indications.tsv)).\r\n\r\n**Features.** We have three types of features:\r\n\r\n1. **The prior** is a single feature equal to the logit-transformed [prior probability of treatment](https://thinklab.com/discussion/network-edge-prediction-estimating-the-prior/201#2). The prior incorporates the probability that a compound treats a disease based only on their treatment degrees.\r\n2. **Degree features** correspond to each metaedge that connects either a compound or disease. In total we have 16 degree features, 8 for compound degrees and 8 for disease degrees. Degree features count either the compound or disease degree for a given metaedge and thus only depend on either the source or target node. Degree features are [IHS transformed](https://thinklab.com/discussion/transforming-dwpcs-for-hetnet-edge-prediction/193#6).\r\n3. **DWPCs** make up the vast majority of features. Each DWPC corresponds to a metapath. We consider the 1,206 metapaths that traverse from compound to disease and have lengths 2--4. We use _w_ = 0.4 as the damping exponent when computing DWPCs. DWPCs are [mean scaled and IHS transformed](https://thinklab.com/discussion/transforming-dwpcs-for-hetnet-edge-prediction/193#6).\r\n\r\n**Stages.** The DWPC features are computed by querying the Neo4j graph database. The queries are computationally intensive. Thus far, our runtime bottleneck has been [network traversal](https://thinklab.com/discussion/estimating-the-complexity-of-hetnet-traversal/187). Computing all 252,256,608 DWPC queries (209,168 observations × 1,206 DWPCs) is impractical. Accordingly, we adopted a shortcut by splitting the machine learning process into two stages: the all-features stage and the all-observations stage.\r\n\r\n## Stage 1: all features\r\n\r\nThe purpose of the all-features stage is to assess feature performance and perform feature selection. For this stage, we include all 755 positives but randomly select 3,020 negatives (4 × the # of positives).\r\n\r\nIn addition to the unpermuted hetnet, we compute DWPCs on 5 permuted hetnets. For each permuted hetnet, we compute features for the 755 positives and 3,020 random negatives corresponding to that permutation (referred to as primary observations). We also compute DWPCs for any observations that were assessed on the unpermuted network but were not primary observations for a given permuted hetnet.\r\n\r\nIn total, we computed 46,867,572 DWPCs for the all-features stage. Computing these DWPCs took 4 days and 11 hours using a multithreading approach to perform up to 12 queries in parallel ([notebook](https://github.com/dhimmel/learn/blob/6ffd61f209a182d89c5becd96203850f3c5e13e3/all-features/3-extract.ipynb)).\r\n\r\nOn the all features dataset, we identified [how to transform DWPCs](https://thinklab.com/discussion/transforming-dwpcs-for-hetnet-edge-prediction/193) to address their highly skewed distribution. We also [learned how](https://thinklab.com/discussion/network-edge-prediction-how-to-deal-with-self-testing/194) the prior probability of treatment affects model performance. This investigation led us to include the `prior_logit` feature mentioned above.\r\n\r\nFor each feature, we computed [several measures of performance](https://thinklab.com/discussion/assessing-the-informativeness-of-features/115#3). These feature-specific performance measures indicate whether the DWPCs for a given metapath reliably discriminate whether a drug treats a disease. We use this information to filter the majority of DWPC features, which are not predictive or suffer from an [edge-dropout contamination issue](https://thinklab.com/discussion/edge-dropout-contamination-in-hetnet-edge-prediction/215). The DWPCs from permuted hetnets are used here as baseline measures to assess the contribution of edge specificity.\r\n\r\n## Stage 2: all observations\r\n\r\nProceeding with the metapaths selected in Stage 1 (see [next comment](#3)), we compute DWPCs for all 209,168 observations on the unpermuted hetnet. After transforming the degree and DWPC features, we [standardize](https://thinklab.com/discussion/computing-standardized-logistic-regression-coefficients/205) all variables besides the prior. Standardization allows us to decompose the linear predictor to assess each feature's contribution to a prediction compared to its mean.\r\n\r\nWe fit a logistic regression model with the prior, the degree features, and the selected DWPC features. However, this model is fit only on the 29,799 observations with a non-zero prior. From this model, we predict the probability of treatment for all observations. We enable predictions for zero priors by setting the prior for every observation equal to the mean prevalence of positives. Hence, it's important that the model assigns a coefficient near 1.0 to the `prior_logit` feature. In essence, we're erasing the effect of how many treatments each compound and disease have, since this knowledge is otherwise overpowering. The end result is a treatment-degree-naive prediction of whether each compound treats each disease.",
      "comment_id": 1294,
      "profile_id": 17,
      "published": "2016-05-12T02:23:47.232670Z",
      "thread_id": 210,
      "url": "/discussion/our-hetnet-edge-prediction-methodology-the-modeling-framework-for-project-rephetio/210#2"
    },
    {
      "body_html": "<h1>Greene &amp; Voight Review</h1>\r\n\r\n<p><a href=\"/u/caseygreene\" class=\"username\">@caseygreene</a>'s has preprinted his new review titled \"Pathway and network-based strategies to translate genetic discoveries into effective therapies\" <span class=\"citation\">[<a href=\"https://doi.org/10.1101/051524\" class=\"citation\" data-key=\"10.1101/051524\">1</a>]</span>. The review mentions our project:</p>\r\n\r\n<blockquote><p>They use heterogeneous networks that connect genes, diseases, tissues, and other<br>factors <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1004259\">2</a>]</span>. They then apply machine learning methods to predict effective drug-disease pairs. The entire process has been visible on an open science platform called Thinklab. The open platform reveals the extensive sets of analyses that lay the groundwork for machine learning applications. Though work is ongoing the initial results are highly promising.</p></blockquote>\r\n\r\n<p>as well as the legal barriers to data reuse that we've encountered:</p>\r\n\r\n<blockquote><p>An often-overlooked aspect of studies that incorporate multiple data types and sources for drug repurposing is licensing and resource accessibility. The manner in which restrictive database licenses have hampered progress by the Himmelstein et al. team <span class=\"citation\">[<a href=\"/p/rephetio\" class=\"citation\" data-key=\"10.15363/thinklab.4\">3</a>]</span> has been instructive <span class=\"citation\">[<a href=\"/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107\" class=\"citation\" data-key=\"10.15363/thinklab.d107\">4</a>]</span>.</p></blockquote>\r\n\r\n<p>The review mentions the difficulties faced by genetic-association-driven drug development:</p>\r\n\r\n<blockquote><p>There have been a limited number of cases where each required elements falls cleanly into place.</p></blockquote>\r\n\r\n<p>I'm exciting to see if our metapath-based approach can help decode the contexts in which genetic association data is most informative for drug efficacy.</p>",
      "body_md": "# Greene & Voight Review\r\n\r\n@caseygreene's has preprinted his new review titled \"Pathway and network-based strategies to translate genetic discoveries into effective therapies\" [@10.1101/051524]. The review mentions our project:\r\n\r\n> They use heterogeneous networks that connect genes, diseases, tissues, and other\r\nfactors [@10.1371/journal.pcbi.1004259]. They then apply machine learning methods to predict effective drug-disease pairs. The entire process has been visible on an open science platform called Thinklab. The open platform reveals the extensive sets of analyses that lay the groundwork for machine learning applications. Though work is ongoing the initial results are highly promising.\r\n\r\nas well as the legal barriers to data reuse that we've encountered:\r\n\r\n> An often-overlooked aspect of studies that incorporate multiple data types and sources for drug repurposing is licensing and resource accessibility. The manner in which restrictive database licenses have hampered progress by the Himmelstein et al. team [@10.15363/thinklab.4] has been instructive [@10.15363/thinklab.d107].\r\n\r\nThe review mentions the difficulties faced by genetic-association-driven drug development:\r\n\r\n> There have been a limited number of cases where each required elements falls cleanly into place.\r\n\r\nI'm exciting to see if our metapath-based approach can help decode the contexts in which genetic association data is most informative for drug efficacy.",
      "comment_id": 1295,
      "profile_id": 17,
      "published": "2016-05-04T22:31:58.818987Z",
      "thread_id": 113,
      "url": "/discussion/tracking-project-reuse-citation-and-publicity/113#8"
    },
    {
      "body_html": "<p>We would <a href=\"https://thinklab.com/discussion/evaluation-framework/47\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d47\">like to validate</a> our predictions by assessing whether we highly rank treatments that are under investigation in clinical trial. Clinical trials are generally supporting by a large body of preclinical evidence including animal studies <span class=\"citation\">[<a href=\"https://doi.org/10.1111/bph.12771\" class=\"citation\" data-key=\"10.1111/bph.12771\">1</a>]</span>, which makes them a rich resource of drug efficacy.</p>\r\n\r\n<p>The <a href=\"https://clinicaltrials.gov/\">ClinicalTrials.gov</a> database is a \"registry and results database of publicly and privately supported clinical studies of human participants conducted around the world.\" Previous studies that have computationally predicted pharmacotherapies have used ClinicalTrials.gov to evaluate their performance <span class=\"citation\">[<a href=\"https://doi.org/10.1038/msb.2011.26\" class=\"citation\" data-key=\"10.1038/msb.2011.26\">2</a>, <a href=\"https://doi.org/10.1038/ncomms10331\" class=\"citation\" data-key=\"10.1038/ncomms10331\">3</a>]</span>.</p>\r\n\r\n<p>Several existing studies have investigated the utility of ClinicalTrials.gov data from various angles <span class=\"citation\">[<a href=\"https://doi.org/10.1056/NEJMsa1012065\" class=\"citation\" data-key=\"10.1056/NEJMsa1012065\">4</a>, <a href=\"https://doi.org/10.1371/journal.pone.0101826\" class=\"citation\" data-key=\"10.1371/journal.pone.0101826\">5</a>, <a href=\"https://doi.org/10.1371/journal.pmed.1000144\" class=\"citation\" data-key=\"10.1371/journal.pmed.1000144\">6</a>, <a href=\"https://doi.org/10.1056/NEJMsa053234\" class=\"citation\" data-key=\"10.1056/NEJMsa053234\">7</a>, <a href=\"https://doi.org/10.1136/bmj.d7292\" class=\"citation\" data-key=\"10.1136/bmj.d7292\">8</a>, <a href=\"https://doi.org/10.1001/jama.2012.3424\" class=\"citation\" data-key=\"10.1001/jama.2012.3424\">9</a>, <a href=\"https://doi.org/10.7326/0003-4819-153-3-201008030-00006\" class=\"citation\" data-key=\"10.7326/0003-4819-153-3-201008030-00006\">10</a>, <a href=\"https://doi.org/10.1093/jamia/ocv062\" class=\"citation\" data-key=\"10.1093/jamia/ocv062\">11</a>]</span>. In this discussion, we will focus on constructing a catalog of potential indications under investigation by clinical trial. Any advice on using analyzing ClinicalTrials.gov data will be appreciated.</p>",
      "body_md": "We would [like to validate](https://thinklab.com/discussion/evaluation-framework/47) our predictions by assessing whether we highly rank treatments that are under investigation in clinical trial. Clinical trials are generally supporting by a large body of preclinical evidence including animal studies [@10.1111/bph.12771], which makes them a rich resource of drug efficacy.\r\n\r\nThe [ClinicalTrials.gov](https://clinicaltrials.gov/) database is a \"registry and results database of publicly and privately supported clinical studies of human participants conducted around the world.\" Previous studies that have computationally predicted pharmacotherapies have used ClinicalTrials.gov to evaluate their performance [@10.1038/msb.2011.26 @10.1038/ncomms10331].\r\n\r\nSeveral existing studies have investigated the utility of ClinicalTrials.gov data from various angles [@10.1056/NEJMsa1012065 @10.1371/journal.pone.0101826 @10.1371/journal.pmed.1000144 @10.1056/NEJMsa053234 @10.1136/bmj.d7292 @10.1001/jama.2012.3424 @10.7326/0003-4819-153-3-201008030-00006 @10.1093/jamia/ocv062]. In this discussion, we will focus on constructing a catalog of potential indications under investigation by clinical trial. Any advice on using analyzing ClinicalTrials.gov data will be appreciated.",
      "comment_id": 1297,
      "profile_id": 17,
      "published": "2016-05-08T05:00:24.012824Z",
      "thread_id": 212,
      "url": "/discussion/cataloging-drugdisease-therapies-in-the-clinicaltrialsgov-database/212"
    },
    {
      "body_html": "<h1>Initial catalog of drug–disease therapies</h1>\r\n\r\n<p>I created an initial catalog of drug–disease therapies from ClinicalTrials.gov. The process consisted of downloading all study records and extracting the MeSH-coded interventions and conditions (<a href=\"https://github.com/dhimmel/clintrials/blob/7c65dec7b69322ca2f8ba2b170c1b3dbd92ebff8/1.clinical-trials.ipynb\">notebook</a>). Next, I mapped the MeSH diseases to Disease Ontology terms and mapped MeSH compounds to DrugBank via <a href=\"https://thinklab.com/discussion/incorporating-drugcentral-data-in-our-network/186\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d186\">DrugCentral</a> (<a href=\"https://github.com/dhimmel/clintrials/blob/7c65dec7b69322ca2f8ba2b170c1b3dbd92ebff8/2.map.ipynb\">notebook</a>).</p>\r\n\r\n<p>The <a href=\"https://github.com/dhimmel/clintrials/blob/7c65dec7b69322ca2f8ba2b170c1b3dbd92ebff8/data/DrugBank-DO.tsv\">resulting catalog</a> consists of 158,767 trial–drug–disease relationships between 1,181 drugs and 1,617 diseases from 42,826 trials. Note that trials will often assess multiple drug interventions and even conditions, resulting in multiple drug–disease pairs for a single trial. The total number of distinct drug–disease therapies extracted was 33,095.</p>\r\n\r\n<p>Project Rephetio uses a subset of 137 diseases called <a href=\"https://thinklab.com/discussion/unifying-disease-vocabularies/44#6\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d44\">DO Slim</a> and a subset of all drugs called <a href=\"https://thinklab.com/discussion/unifying-drug-vocabularies/40#5\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d40\">DrugBank Slim</a>. Thus, I created a slim trial–drug–disease catalog for use with our project (<a href=\"https://github.com/dhimmel/clintrials/blob/7c65dec7b69322ca2f8ba2b170c1b3dbd92ebff8/data/DrugBank-DO-slim.tsv\">dataset</a>). Transitive closure was used to propagate therapies to DO Slim diseases from their subtypes. The slim clinical trial catalog contains 6,382 drug–disease pairs for 794 compounds and 130 diseases that incorporate 27,240 trials.</p>",
      "body_md": "# Initial catalog of drug–disease therapies\r\n\r\nI created an initial catalog of drug–disease therapies from ClinicalTrials.gov. The process consisted of downloading all study records and extracting the MeSH-coded interventions and conditions ([notebook](https://github.com/dhimmel/clintrials/blob/7c65dec7b69322ca2f8ba2b170c1b3dbd92ebff8/1.clinical-trials.ipynb)). Next, I mapped the MeSH diseases to Disease Ontology terms and mapped MeSH compounds to DrugBank via [DrugCentral](https://thinklab.com/discussion/incorporating-drugcentral-data-in-our-network/186) ([notebook](https://github.com/dhimmel/clintrials/blob/7c65dec7b69322ca2f8ba2b170c1b3dbd92ebff8/2.map.ipynb)).\r\n\r\nThe [resulting catalog](https://github.com/dhimmel/clintrials/blob/7c65dec7b69322ca2f8ba2b170c1b3dbd92ebff8/data/DrugBank-DO.tsv) consists of 158,767 trial--drug--disease relationships between 1,181 drugs and 1,617 diseases from 42,826 trials. Note that trials will often assess multiple drug interventions and even conditions, resulting in multiple drug--disease pairs for a single trial. The total number of distinct drug--disease therapies extracted was 33,095.\r\n\r\nProject Rephetio uses a subset of 137 diseases called [DO Slim](https://thinklab.com/discussion/unifying-disease-vocabularies/44#6) and a subset of all drugs called [DrugBank Slim](https://thinklab.com/discussion/unifying-drug-vocabularies/40#5). Thus, I created a slim trial--drug--disease catalog for use with our project ([dataset](https://github.com/dhimmel/clintrials/blob/7c65dec7b69322ca2f8ba2b170c1b3dbd92ebff8/data/DrugBank-DO-slim.tsv)). Transitive closure was used to propagate therapies to DO Slim diseases from their subtypes. The slim clinical trial catalog contains 6,382 drug--disease pairs for 794 compounds and 130 diseases that incorporate 27,240 trials.",
      "comment_id": 1298,
      "profile_id": 17,
      "published": "2016-05-08T17:37:10.718986Z",
      "thread_id": 212,
      "url": "/discussion/cataloging-drugdisease-therapies-in-the-clinicaltrialsgov-database/212#2"
    },
    {
      "body_html": "<p><strong>Update on 2016-06-21:</strong> The OMx team in charge of DrugBank's licensing was highly responsive and thoroughly addressed the issues I raised. See <a href=\"/u/cknoxrun\" class=\"username\">@cknoxrun</a>'s <a href=\"#10\">description below</a> of the revised DrugBank licensing.</p>\r\n\r\n<hr>\r\n\r\n<p><a href=\"http://www.drugbank.ca/\">DrugBank</a> is a database of drugs which includes information on drug biochemistry and pharmacology <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkj067\" class=\"citation\" data-key=\"10.1093/nar/gkj067\">1</a>, <a href=\"https://doi.org/10.1093/nar/gkm958\" class=\"citation\" data-key=\"10.1093/nar/gkm958\">2</a>, <a href=\"https://doi.org/10.1093/nar/gkq1126\" class=\"citation\" data-key=\"10.1093/nar/gkq1126\">3</a>, <a href=\"https://doi.org/10.1093/nar/gkt1068\" class=\"citation\" data-key=\"10.1093/nar/gkt1068\">4</a>]</span>. DrugBank is a publicly-funded resource that is frequently used for biomedical research. Google Scholar <a href=\"https://scholar.google.com/scholar?q=drugbank&amp;hl=en&amp;as_sdt=0%2C5&amp;as_ylo=2006&amp;as_yhi=2015\" title=\"Google Scholar Search for articles mentioning DrugBank from 2006–2015\">returns</a> 8,940 studies which mention \"DrugBank\" during its first decade of existence (2006–2015).</p>\r\n\r\n<p>When we began using DrugBank for Project Rephetio and Hetionet in 2015, DrugBank <a href=\"https://github.com/dhimmel/integrate/blob/7b95bf337d6e43e54457621f39a7341e620138f7/licenses/custom/DrugBank.md\" title=\"Archive of DrugBank's legal statement from 2015-08-20\">had</a> a brief legal statement:</p>\r\n\r\n<blockquote><p>DrugBank is offered to the public as a freely available resource. Use and re-distribution of the data, in whole or in part, for commercial purposes requires explicit permission of the authors and explicit acknowledgment of the source material (DrugBank) and the original publication.</p></blockquote>\r\n\r\n<p>Therefore, in accordance with our <a href=\"https://thinklab.com/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#14\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d107\">data-licensing compliance strategy</a>, we applied a <a href=\"https://creativecommons.org/licenses/by-nc/4.0/\" title=\"Creative Commons Attribution-NonCommercial 4.0 International\">CC BY-NC</a> license to DrugBank data. The non-commercial stipulation was regrettable because it discriminates against a class of user and precludes the data from being <a href=\"http://opendefinition.org/od/2.1/en/\" title=\"Open Definition 2.1\">open knowledge</a>. Additionally, what qualifies as commercial reuse is unclear and potentially broad making NC stipulations especially toxic <span class=\"citation\">[<a href=\"https://doi.org/10.3897/zookeys.150.2189\" class=\"citation\" data-key=\"10.3897/zookeys.150.2189\">5</a>]</span>.</p>\r\n\r\n<p>Nonetheless, many publicly-funded resources will specify \"academic use only\" by habit, without appreciating the full ramifications of their discrimination. Hence, I assumed that DrugBank was effectively an open resource with a poorly-devised license statement.</p>\r\n\r\n<p>The <a href=\"http://www.drugbank.ca/releases/4-5-0/release_notes\">release</a> of DrugBank 4.5 on April 20, 2016 dispelled my naiveté. DrugBank has been hijacked by the commercial interests of the University of Alberta and OMx. <a href=\"http://omx.io/\" title=\"OMx Personal Health Analytics\">OMx</a> is a company <a href=\"http://entrepreneurship.ualberta.ca/ehub/ehub-startups/omx\" title=\"Entrepreneurship @ UAlberta eHUB Startups Interview\">started</a> in 2012 at the University of Alberta, which currently lists DrugBank as their only product. While the University of Alberta asserts to own DrugBank, OMx is responsible for commercial DrugBank licensing.</p>\r\n\r\n<p>Downloading DrugBank now requires registration. To <a href=\"http://www.drugbank.ca/public_users/sign_up\" title=\"Sign up for DrugBank account\">register</a>, users must provide their name, contact information, university/institutional affiliation, and intended use of DrugBank. Additionally, registration is contingent upon entering into the following agreement:</p>\r\n\r\n<blockquote><p>I accept DrugBank's Privacy Policy, Terms of Use, and the above End User License Agreement (required)</p><p>By checking the above box, you are confirming that your use of DrugBank shall not be for commercial purposes. If you wish to use DrugBank for commercial purposes, contact <a href=\"mailto:info@omx.io\">info@omx.io</a> to inquire about a separate agreement with OMx.</p></blockquote>\r\n\r\n<p>My next post will examine how the new <a href=\"https://github.com/dhimmel/drugbank/blob/27ca084815803dff5d8c2ee3a7e85b7ef5cf23a1/legal/privacy.md\" title=\"Archive of the Privacy Policy from 2016-05-08\">Privacy Policy</a>, <a href=\"https://github.com/dhimmel/drugbank/blob/27ca084815803dff5d8c2ee3a7e85b7ef5cf23a1/legal/terms.md\" title=\"Archive of the Terms of Use from 2016-05-08\">Terms of Use</a>, and <a href=\"https://github.com/dhimmel/drugbank/blob/27ca084815803dff5d8c2ee3a7e85b7ef5cf23a1/legal/EULA.md\" title=\"Archive of the End User License Agreement from 2016-05-08\">License Agreement</a> inhibit reuse of DrugBank. In essence, DrugBank has chosen a path that prioritizes licensing revenue over public reuse. Its heavy-handed legal infrastructure presents a grave barrier to reuse. The academic community must now consider parting ways with what has been a foundational resource.</p>",
      "body_md": "**Update on 2016-06-21:** The OMx team in charge of DrugBank's licensing was highly responsive and thoroughly addressed the issues I raised. See @cknoxrun's [description below](#10) of the revised DrugBank licensing.\r\n\r\n***\r\n\r\n[DrugBank](http://www.drugbank.ca/) is a database of drugs which includes information on drug biochemistry and pharmacology [@10.1093/nar/gkj067 @10.1093/nar/gkm958 @10.1093/nar/gkq1126 @10.1093/nar/gkt1068]. DrugBank is a publicly-funded resource that is frequently used for biomedical research. Google Scholar [returns](https://scholar.google.com/scholar?q=drugbank&hl=en&as_sdt=0%2C5&as_ylo=2006&as_yhi=2015 \"Google Scholar Search for articles mentioning DrugBank from 2006–2015\") 8,940 studies which mention \"DrugBank\" during its first decade of existence (2006–2015).\r\n\r\nWhen we began using DrugBank for Project Rephetio and Hetionet in 2015, DrugBank [had](https://github.com/dhimmel/integrate/blob/7b95bf337d6e43e54457621f39a7341e620138f7/licenses/custom/DrugBank.md \"Archive of DrugBank's legal statement from 2015-08-20\") a brief legal statement:\r\n\r\n> DrugBank is offered to the public as a freely available resource. Use and re-distribution of the data, in whole or in part, for commercial purposes requires explicit permission of the authors and explicit acknowledgment of the source material (DrugBank) and the original publication.\r\n\r\nTherefore, in accordance with our [data-licensing compliance strategy](https://thinklab.com/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#14), we applied a [CC BY-NC](https://creativecommons.org/licenses/by-nc/4.0/ \"Creative Commons Attribution-NonCommercial 4.0 International\") license to DrugBank data. The non-commercial stipulation was regrettable because it discriminates against a class of user and precludes the data from being [open knowledge](http://opendefinition.org/od/2.1/en/ \"Open Definition 2.1\"). Additionally, what qualifies as commercial reuse is unclear and potentially broad making NC stipulations especially toxic [@10.3897/zookeys.150.2189].\r\n\r\nNonetheless, many publicly-funded resources will specify \"academic use only\" by habit, without appreciating the full ramifications of their discrimination. Hence, I assumed that DrugBank was effectively an open resource with a poorly-devised license statement.\r\n\r\nThe [release](http://www.drugbank.ca/releases/4-5-0/release_notes) of DrugBank 4.5 on April 20, 2016 dispelled my naiveté. DrugBank has been hijacked by the commercial interests of the University of Alberta and OMx. [OMx](http://omx.io/ \"OMx Personal Health Analytics\") is a company [started](http://entrepreneurship.ualberta.ca/ehub/ehub-startups/omx \"Entrepreneurship @ UAlberta eHUB Startups Interview\") in 2012 at the University of Alberta, which currently lists DrugBank as their only product. While the University of Alberta asserts to own DrugBank, OMx is responsible for commercial DrugBank licensing.\r\n\r\nDownloading DrugBank now requires registration. To [register](http://www.drugbank.ca/public_users/sign_up \"Sign up for DrugBank account\"), users must provide their name, contact information, university/institutional affiliation, and intended use of DrugBank. Additionally, registration is contingent upon entering into the following agreement:\r\n\r\n> I accept DrugBank's Privacy Policy, Terms of Use, and the above End User License Agreement (required)\r\n\r\n> By checking the above box, you are confirming that your use of DrugBank shall not be for commercial purposes. If you wish to use DrugBank for commercial purposes, contact info@omx.io to inquire about a separate agreement with OMx.\r\n\r\nMy next post will examine how the new [Privacy Policy](https://github.com/dhimmel/drugbank/blob/27ca084815803dff5d8c2ee3a7e85b7ef5cf23a1/legal/privacy.md \"Archive of the Privacy Policy from 2016-05-08\"), [Terms of Use](https://github.com/dhimmel/drugbank/blob/27ca084815803dff5d8c2ee3a7e85b7ef5cf23a1/legal/terms.md \"Archive of the Terms of Use from 2016-05-08\"), and [License Agreement](https://github.com/dhimmel/drugbank/blob/27ca084815803dff5d8c2ee3a7e85b7ef5cf23a1/legal/EULA.md \"Archive of the End User License Agreement from 2016-05-08\") inhibit reuse of DrugBank. In essence, DrugBank has chosen a path that prioritizes licensing revenue over public reuse. Its heavy-handed legal infrastructure presents a grave barrier to reuse. The academic community must now consider parting ways with what has been a foundational resource.",
      "comment_id": 1300,
      "profile_id": 17,
      "published": "2016-05-08T21:35:21.495978Z",
      "thread_id": 213,
      "url": "/discussion/sounding-the-alarm-on-drugbanks-new-license-and-terms-of-use/213"
    },
    {
      "body_html": "<h1>Funding</h1>\r\n\r\n<p>Ultimately science funders have the most leverage regarding data licensing issues. Public funding agencies and philanthropists are generally interested in making sure the research they fund is shared openly. DrugBank appears to have received both public and private funding. DrugBank has pursued commercial partnerships <a href=\"http://www.bio-itworld.com/issues/2008/feb/drugbank-database.html\" title=\"DrugBank Database in Commercial Partnership\">since at least 2008</a>.</p>\r\n\r\n<h2>Specific grants</h2>\r\n\r\n<p>The database has received at least $1,069,848 CAD from the Canadian Institutes of Health Research (CIHR) from the following two grants:</p>\r\n\r\n<ul><li><a href=\"http://agingportfolio.org/projects/project/CIHR-944397\">$374,128 CAD from 2007–2010</a></li><li>$695,720 CAD from 2011–2016</li></ul>\r\n\r\n<p>Please leave a note if you find specifics on other DrugBank grants.</p>\r\n\r\n<h2>Funding Statements</h2>\r\n\r\n<p>As of May 8, 2016, the <a href=\"http://www.drugbank.ca/\">DrugBank homepage</a> includes the following funding statement:</p>\r\n\r\n<blockquote><p>This project is supported by the <a href=\"http://www.cihr-irsc.gc.ca\">Canadian Institutes of Health Research</a> (award #111062), <a href=\"http://www.aihealthsolutions.ca\">Alberta Innovates - Health Solutions</a>, and by <a href=\"http://www.metabolomicscentre.ca/\">The Metabolomics Innovation Centre (TMIC)</a>, a nationally-funded research and core facility that supports a wide range of cutting-edge metabolomic studies. TMIC is funded by <a href=\"http://www.genomealberta.ca\">Genome Alberta</a>, <a href=\"http://www.genomebc.ca/\">Genome British Columbia</a>, and <a href=\"http://www.genomecanada.ca\">Genome Canada</a>, a not-for-profit organization that is leading Canada's national genomics strategy with $900 million in funding from the federal government. Maintenance, support, and commercial licensing is provided by <a href=\"http://omx.io\">OMx Personal Health Analytics, Inc.</a></p></blockquote>\r\n\r\n<p>The DrugBank publications include the following funding statements:</p>\r\n\r\n<p>From 2006 <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkj067\" class=\"citation\" data-key=\"10.1093/nar/gkj067\">1</a>]</span>:</p>\r\n\r\n<blockquote><p>The authors wish to thank Genome Prairie, a division of Genome Canada for financial support. Funding to pay the Open Access publication charges for this article was provided by Genome Canada.</p></blockquote>\r\n\r\n<p>From 2007 <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkm958\" class=\"citation\" data-key=\"10.1093/nar/gkm958\">2</a>]</span>:</p>\r\n\r\n<blockquote><p>The authors wish to thank the Canadian Institutes for Health Research (CIHR), as well as Genome Alberta and Genome Canada for financial support. We are also indebted to the many users of DrugBank who have provided valuable feedback and suggestions. Funding to pay the Open Access publication charges was provided by Genome Alberta.</p></blockquote>\r\n\r\n<p>From 2010 <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkq1126\" class=\"citation\" data-key=\"10.1093/nar/gkq1126\">3</a>]</span>:</p>\r\n\r\n<blockquote><p>Canadian Institutes of Health Research (CIHR); Genome Alberta; Genome Canada; GenomeQuest Inc. Funding for open access charge: CIHR.</p></blockquote>\r\n\r\n<p>From 2013 <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkt1068\" class=\"citation\" data-key=\"10.1093/nar/gkt1068\">4</a>]</span>:</p>\r\n\r\n<blockquote><p>The authors wish to thank Genome Alberta (a division of Genome Canada), The Canadian Institutes of Health Research (CIHR), and Alberta Innovates Health Solutions (AIHS) for financial support. Funding for open access charge: CIHR.</p></blockquote>",
      "body_md": "# Funding\r\n\r\nUltimately science funders have the most leverage regarding data licensing issues. Public funding agencies and philanthropists are generally interested in making sure the research they fund is shared openly. DrugBank appears to have received both public and private funding. DrugBank has pursued commercial partnerships [since at least 2008](http://www.bio-itworld.com/issues/2008/feb/drugbank-database.html \"DrugBank Database in Commercial Partnership\").\r\n\r\n## Specific grants\r\n\r\nThe database has received at least $1,069,848 CAD from the Canadian Institutes of Health Research (CIHR) from the following two grants:\r\n\r\n+ [$374,128 CAD from 2007--2010](http://agingportfolio.org/projects/project/CIHR-944397)\r\n+ $695,720 CAD from 2011--2016\r\n\r\nPlease leave a note if you find specifics on other DrugBank grants.\r\n\r\n## Funding Statements\r\n\r\nAs of May 8, 2016, the [DrugBank homepage](http://www.drugbank.ca/) includes the following funding statement:\r\n\r\n> This project is supported by the [Canadian Institutes of Health Research](http://www.cihr-irsc.gc.ca) (award #111062), [Alberta Innovates - Health Solutions](http://www.aihealthsolutions.ca), and by [The Metabolomics Innovation Centre (TMIC)](http://www.metabolomicscentre.ca/), a nationally-funded research and core facility that supports a wide range of cutting-edge metabolomic studies. TMIC is funded by [Genome Alberta](http://www.genomealberta.ca), [Genome British Columbia](http://www.genomebc.ca/), and [Genome Canada](http://www.genomecanada.ca), a not-for-profit organization that is leading Canada's national genomics strategy with $900 million in funding from the federal government. Maintenance, support, and commercial licensing is provided by [OMx Personal Health Analytics, Inc.](http://omx.io)\r\n\r\nThe DrugBank publications include the following funding statements:\r\n\r\nFrom 2006 [@10.1093/nar/gkj067]:\r\n\r\n> The authors wish to thank Genome Prairie, a division of Genome Canada for financial support. Funding to pay the Open Access publication charges for this article was provided by Genome Canada.\r\n\r\nFrom 2007 [@10.1093/nar/gkm958]:\r\n\r\n> The authors wish to thank the Canadian Institutes for Health Research (CIHR), as well as Genome Alberta and Genome Canada for financial support. We are also indebted to the many users of DrugBank who have provided valuable feedback and suggestions. Funding to pay the Open Access publication charges was provided by Genome Alberta.\r\n\r\nFrom 2010 [@10.1093/nar/gkq1126]:\r\n\r\n> Canadian Institutes of Health Research (CIHR); Genome Alberta; Genome Canada; GenomeQuest Inc. Funding for open access charge: CIHR.\r\n\r\nFrom 2013 [@10.1093/nar/gkt1068]:\r\n\r\n> The authors wish to thank Genome Alberta (a division of Genome Canada), The Canadian Institutes of Health Research (CIHR), and Alberta Innovates Health Solutions (AIHS) for financial support. Funding for open access charge: CIHR.",
      "comment_id": 1301,
      "profile_id": 17,
      "published": "2016-05-09T02:11:11.872236Z",
      "thread_id": 213,
      "url": "/discussion/sounding-the-alarm-on-drugbanks-new-license-and-terms-of-use/213#3"
    },
    {
      "body_html": "<h1>Decoding the legal texts</h1>\r\n\r\n<p>Researchers looking to use DrugBank now have quite a bit of reading to do. As described in the 1,424-word <a href=\"https://github.com/dhimmel/drugbank/blob/27ca084815803dff5d8c2ee3a7e85b7ef5cf23a1/legal/privacy.md\">Privacy Policy</a>:</p>\r\n\r\n<blockquote><p>You are prohibited from using the Platform unless you fully understand and agree to the Terms of Use and the [Privacy] Policy.</p></blockquote>\r\n\r\n<h2>Terms of Use</h2>\r\n\r\n<p>Let's start with the 3,529-word <a href=\"https://github.com/dhimmel/drugbank/blob/27ca084815803dff5d8c2ee3a7e85b7ef5cf23a1/legal/terms.md\">Terms of Use</a>. Remember that these terms of use claim to govern any use of the Platform, which encompasses the drugbank.ca website. First make sure you understand the terms before using DrugBank:</p>\r\n\r\n<blockquote><p>If you do not agree to or understand all the provisions, terms and conditions set out below, then you may not access the Platform or use any of our services.</p></blockquote>\r\n\r\n<p>Second, it appears that using information from DrugBank in a publication is prohibited:</p>\r\n\r\n<blockquote><p>Users are not permitted to take any information from the site and share it with others ... unless they have obtained OMx’s consent.</p></blockquote>\r\n\r\n<p>In fact, you're not allowed to even copy information:</p>\r\n\r\n<blockquote><p>Users are prohibited from copying, reproducing, downloading, sharing, or storing the Platform, the data contained within DrugBank or any components thereof, to any device or server unless previously authorized to do so by OMx.</p></blockquote>\r\n\r\n<p>Third, it appears that showing a DrugBank page in your presentation is prohibited:</p>\r\n\r\n<blockquote><p>Users are prohibited from providing any display or demonstration of the Platform to others, either publicly or in private, for any purpose whatsoever without the prior express written consent of OMx.</p></blockquote>\r\n\r\n<p>Fourth, users under 18 are denied access:</p>\r\n\r\n<blockquote><p>We do not permit any User under the age of 18 to use our Service or Platform.</p></blockquote>\r\n\r\n<p>Finally, any past permissions you've received are no longer any good:</p>\r\n\r\n<blockquote><p>The Agreement, in combination with all policies and guidelines related thereto (including but not limited to the Privacy Policy), incorporated by reference, constitute the entire agreement between you and OMx and supersede all prior communications, agreements and understandings, written or oral, with respect to the subject matter of the Agreement.</p></blockquote>\r\n\r\n<h2>License Agreement</h2>\r\n\r\n<p>To register with DrugBank, which is necessary for downloading the database, users must agree to a 877-word <a href=\"https://github.com/dhimmel/drugbank/blob/27ca084815803dff5d8c2ee3a7e85b7ef5cf23a1/legal/EULA.md\">Non-Commercial End User License Agreement</a> (EULA). Specifically, the agreement states:</p>\r\n\r\n<blockquote><p>Your use of DrugBank Database is governed by a legal agreement between you and OMx consisting of this Non-Commercial End User License Agreement, the Terms of Use (the \"Terms\") and the Privacy Policy, which you must accept by checking the box indicating your acceptance of this License, the Terms and the Privacy Policy.</p></blockquote>\r\n\r\n<p>Next, the EULA states:</p>\r\n\r\n<blockquote><p>1.2 Access to DrugBank Database is subject to this standard Non-Commercial End User License Agreement, which is <a href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/legalcode\">Creative Common's Attribution-NonCommercial-ShareAlike 4.0 International License</a>. You must accept the license as an integrated part of this Agreement by checking the box indicating your acceptance.</p></blockquote>\r\n\r\n<p>I am confused because Section 1.2 claims that the EULA is a CC BY-NC-SA 4.0 license. However, the EULA also requires agreeing to the Terms of Use and other conditions that impose additional restrictions on top of CC BY-NC-SA 4.0. Is this a <a href=\"https://wiki.creativecommons.org/wiki/Modifying_the_CC_licenses\">modified Creative Commons license</a>? Or does CC BY-NC-SA 4.0 become the only relevant license and terms once the EULA is accepted? <a href=\"/u/katiefortney\" class=\"username\">@katiefortney</a>, what's your take here?</p>\r\n\r\n<p>The EULA reiterates the age discrimination:</p>\r\n\r\n<blockquote><p>In order to use DrugBank Database you must be 18 years of age or older.</p></blockquote>\r\n\r\n<p>Additionally, it's not clear that you can access the DrugBank Database though other channels even though it's supposedly CC BY-NC-SA 4.0:</p>\r\n\r\n<blockquote><p>You agree not to access (or attempt to access) DrugBank Database by any means other than through the interface that is provided by the Platform (as defined in the Terms and Privacy Policy), unless you have been specifically allowed to do so in a separate agreement with OMx.</p></blockquote>\r\n\r\n<p>Posting a disclaimer is required (which is a condition of the CC license):</p>\r\n\r\n<blockquote><p>You warrant that you shall publish the following disclaimer to third parties</p></blockquote>\r\n\r\n<p>Additionally, users are bound by whatever the current License is at the time of use rather than just the one they agreed to:</p>\r\n\r\n<blockquote><p>You understand and agree that if you use DrugBank Database after the date on which this License, the Terms or the Privacy Policy have changed, we will treat your use as acceptance of the updated License, Terms or Privacy Policy</p></blockquote>\r\n\r\n<p>Finally, the EULA includes the CC definition of commercial use:</p>\r\n\r\n<blockquote><p>Commercial use is one primarily intended for commercial advantage or monetary compensation.</p></blockquote>\r\n\r\n<h2>Conclusion</h2>\r\n\r\n<p>The Terms of Use and License Agreement are deeply troubling. Imposing non-commercial share-alike stipulations is already severely limiting and disqualifies reuse in an open resource. However, the Terms of Use and License exceed CC BY-NC-SA. For example, they add age discrimination and the prohibition on displaying the Platform. Finally, the burden to \"fully understand\" 8,000+ words of legalese is placed on the academic user, before they are supposed to even access the Platform.</p>",
      "body_md": "# Decoding the legal texts\r\n\r\nResearchers looking to use DrugBank now have quite a bit of reading to do. As described in the 1,424-word [Privacy Policy](https://github.com/dhimmel/drugbank/blob/27ca084815803dff5d8c2ee3a7e85b7ef5cf23a1/legal/privacy.md):\r\n\r\n> You are prohibited from using the Platform unless you fully understand and agree to the Terms of Use and the [Privacy] Policy.\r\n\r\n## Terms of Use\r\n\r\nLet's start with the 3,529-word [Terms of Use](https://github.com/dhimmel/drugbank/blob/27ca084815803dff5d8c2ee3a7e85b7ef5cf23a1/legal/terms.md). Remember that these terms of use claim to govern any use of the Platform, which encompasses the drugbank.ca website. First make sure you understand the terms before using DrugBank:\r\n\r\n> If you do not agree to or understand all the provisions, terms and conditions set out below, then you may not access the Platform or use any of our services.\r\n\r\nSecond, it appears that using information from DrugBank in a publication is prohibited:\r\n\r\n> Users are not permitted to take any information from the site and share it with others ... unless they have obtained OMx’s consent.\r\n\r\nIn fact, you're not allowed to even copy information:\r\n\r\n> Users are prohibited from copying, reproducing, downloading, sharing, or storing the Platform, the data contained within DrugBank or any components thereof, to any device or server unless previously authorized to do so by OMx.\r\n\r\nThird, it appears that showing a DrugBank page in your presentation is prohibited:\r\n\r\n> Users are prohibited from providing any display or demonstration of the Platform to others, either publicly or in private, for any purpose whatsoever without the prior express written consent of OMx.\r\n\r\nFourth, users under 18 are denied access:\r\n\r\n> We do not permit any User under the age of 18 to use our Service or Platform.\r\n\r\nFinally, any past permissions you've received are no longer any good:\r\n\r\n> The Agreement, in combination with all policies and guidelines related thereto (including but not limited to the Privacy Policy), incorporated by reference, constitute the entire agreement between you and OMx and supersede all prior communications, agreements and understandings, written or oral, with respect to the subject matter of the Agreement.\r\n\r\n## License Agreement\r\n\r\nTo register with DrugBank, which is necessary for downloading the database, users must agree to a 877-word [Non-Commercial End User License Agreement](https://github.com/dhimmel/drugbank/blob/27ca084815803dff5d8c2ee3a7e85b7ef5cf23a1/legal/EULA.md) (EULA). Specifically, the agreement states:\r\n\r\n> Your use of DrugBank Database is governed by a legal agreement between you and OMx consisting of this Non-Commercial End User License Agreement, the Terms of Use (the \"Terms\") and the Privacy Policy, which you must accept by checking the box indicating your acceptance of this License, the Terms and the Privacy Policy.\r\n\r\nNext, the EULA states:\r\n\r\n> 1.2 Access to DrugBank Database is subject to this standard Non-Commercial End User License Agreement, which is [Creative Common's Attribution-NonCommercial-ShareAlike 4.0 International License](http://creativecommons.org/licenses/by-nc-sa/4.0/legalcode). You must accept the license as an integrated part of this Agreement by checking the box indicating your acceptance.\r\n\r\nI am confused because Section 1.2 claims that the EULA is a CC BY-NC-SA 4.0 license. However, the EULA also requires agreeing to the Terms of Use and other conditions that impose additional restrictions on top of CC BY-NC-SA 4.0. Is this a [modified Creative Commons license](https://wiki.creativecommons.org/wiki/Modifying_the_CC_licenses)? Or does CC BY-NC-SA 4.0 become the only relevant license and terms once the EULA is accepted? @katiefortney, what's your take here?\r\n\r\nThe EULA reiterates the age discrimination:\r\n\r\n> In order to use DrugBank Database you must be 18 years of age or older.\r\n\r\nAdditionally, it's not clear that you can access the DrugBank Database though other channels even though it's supposedly CC BY-NC-SA 4.0:\r\n\r\n> You agree not to access (or attempt to access) DrugBank Database by any means other than through the interface that is provided by the Platform (as defined in the Terms and Privacy Policy), unless you have been specifically allowed to do so in a separate agreement with OMx.\r\n\r\nPosting a disclaimer is required (which is a condition of the CC license):\r\n\r\n> You warrant that you shall publish the following disclaimer to third parties\r\n\r\nAdditionally, users are bound by whatever the current License is at the time of use rather than just the one they agreed to:\r\n\r\n> You understand and agree that if you use DrugBank Database after the date on which this License, the Terms or the Privacy Policy have changed, we will treat your use as acceptance of the updated License, Terms or Privacy Policy\r\n\r\nFinally, the EULA includes the CC definition of commercial use:\r\n\r\n> Commercial use is one primarily intended for commercial advantage or monetary compensation.\r\n\r\n## Conclusion\r\n\r\nThe Terms of Use and License Agreement are deeply troubling. Imposing non-commercial share-alike stipulations is already severely limiting and disqualifies reuse in an open resource. However, the Terms of Use and License exceed CC BY-NC-SA. For example, they add age discrimination and the prohibition on displaying the Platform. Finally, the burden to \"fully understand\" 8,000+ words of legalese is placed on the academic user, before they are supposed to even access the Platform.",
      "comment_id": 1302,
      "profile_id": 17,
      "published": "2016-05-09T01:21:16.368177Z",
      "thread_id": 213,
      "url": "/discussion/sounding-the-alarm-on-drugbanks-new-license-and-terms-of-use/213#2"
    },
    {
      "body_html": "<h1><em>NAR</em> Database Issue Compliance</h1>\r\n\r\n<p>The last three DrugBank papers have been published in <em>Nucleic Acids Research</em> Database Issue <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkm958\" class=\"citation\" data-key=\"10.1093/nar/gkm958\">1</a>, <a href=\"https://doi.org/10.1093/nar/gkq1126\" class=\"citation\" data-key=\"10.1093/nar/gkq1126\">2</a>, <a href=\"https://doi.org/10.1093/nar/gkt1068\" class=\"citation\" data-key=\"10.1093/nar/gkt1068\">3</a>]</span>. The <em>NAR</em> <a href=\"http://www.oxfordjournals.org/our_journals/nar/for_authors/msprep_database.html\">guidelines for the Database Issue</a> state that:</p>\r\n\r\n<blockquote><p>Databases must be freely available to all via the web without the need to register or login. If any part of the database (e.g. the one that deals with the user-submitted data) needs to be password-protected, only the freely available part will be considered by the reviewers. Authors are encouraged, but not required, to make the contents of their databases freely available as flat or relational files upon request.</p></blockquote>\r\n\r\n<p>Additionally,</p>\r\n\r\n<blockquote><p>All databases published in the NAR Database Issue are expected to be maintained under the same URL for at least 5 years after the publication data. Graduation or retirement of the database developers is not a valid reason for termination of the database.</p></blockquote>\r\n\r\n<p>I interpret the five year window to mean that DrugBank must be \"must be freely available to all via the web without the need to register or login\" through 2018. The age restrictions and registration requirements would therefore violate <em>NAR</em>'s policy.</p>\r\n\r\n<p>Since reviewers are directed to consider \"only the freely available part\", any future submission of DrugBank to the <em>NAR</em> Database Issue should be treated as lacking a bulk database download. Much of the value contributed by of DrugBank depends on high-throughput applications that use the bulk download. Hence, it would be interesting to see how reviewers respond to this feature being effectively removed.</p>",
      "body_md": "# _NAR_ Database Issue Compliance\r\n\r\nThe last three DrugBank papers have been published in _Nucleic Acids Research_ Database Issue [@10.1093/nar/gkm958 @10.1093/nar/gkq1126 @10.1093/nar/gkt1068]. The _NAR_ [guidelines for the Database Issue](http://www.oxfordjournals.org/our_journals/nar/for_authors/msprep_database.html) state that:\r\n\r\n> Databases must be freely available to all via the web without the need to register or login. If any part of the database (e.g. the one that deals with the user-submitted data) needs to be password-protected, only the freely available part will be considered by the reviewers. Authors are encouraged, but not required, to make the contents of their databases freely available as flat or relational files upon request.\r\n\r\nAdditionally,\r\n\r\n> All databases published in the NAR Database Issue are expected to be maintained under the same URL for at least 5 years after the publication data. Graduation or retirement of the database developers is not a valid reason for termination of the database.\r\n\r\nI interpret the five year window to mean that DrugBank must be \"must be freely available to all via the web without the need to register or login\" through 2018. The age restrictions and registration requirements would therefore violate _NAR_'s policy.\r\n\r\nSince reviewers are directed to consider \"only the freely available part\", any future submission of DrugBank to the _NAR_ Database Issue should be treated as lacking a bulk database download. Much of the value contributed by of DrugBank depends on high-throughput applications that use the bulk download. Hence, it would be interesting to see how reviewers respond to this feature being effectively removed.",
      "comment_id": 1303,
      "profile_id": 17,
      "published": "2016-05-09T02:33:16.706465Z",
      "thread_id": 213,
      "url": "/discussion/sounding-the-alarm-on-drugbanks-new-license-and-terms-of-use/213#4"
    },
    {
      "body_html": "<p>I would say it sounds like they don't understand CC licenses. The statement \"Access to DrugBank Database is subject to this standard Non-Commercial End User License Agreement, <strong>which is</strong> Creative Common's Attribution-NonCommercial-ShareAlike 4.0 International License\" is false. It's bad drafting. In a hypothetical universe where someone relied upon the CC BY-NC-SA terms because OMx said their use was subject to the CC license, and then OMx sued them for sharing the database, in such a way that complied with the terms of the CC license but violated OMx's other terms... I don't know. It'd be messy. I think it's most likely the <a href=\"https://en.wikipedia.org/wiki/Contra_proferentem\">bad drafting is construed against the drafter</a>, but it's possible a court could find that OMx's restrictions were valid since <a href=\"http://www.lexology.com/library/detail.aspx?g=3e97d26c-bf45-4358-8106-c8f75840f91c\">they're more specific</a>. And spread among multiple documents.</p>",
      "body_md": "I would say it sounds like they don't understand CC licenses. The statement \"Access to DrugBank Database is subject to this standard Non-Commercial End User License Agreement, **which is** Creative Common's Attribution-NonCommercial-ShareAlike 4.0 International License\" is false. It's bad drafting. In a hypothetical universe where someone relied upon the CC BY-NC-SA terms because OMx said their use was subject to the CC license, and then OMx sued them for sharing the database, in such a way that complied with the terms of the CC license but violated OMx's other terms... I don't know. It'd be messy. I think it's most likely the [bad drafting is construed against the drafter](https://en.wikipedia.org/wiki/Contra_proferentem), but it's possible a court could find that OMx's restrictions were valid since [they're more specific](http://www.lexology.com/library/detail.aspx?g=3e97d26c-bf45-4358-8106-c8f75840f91c). And spread among multiple documents.",
      "comment_id": 1304,
      "profile_id": 137,
      "published": "2016-05-09T17:50:09.483286Z",
      "thread_id": 213,
      "url": "/discussion/sounding-the-alarm-on-drugbanks-new-license-and-terms-of-use/213#5"
    },
    {
      "body_html": "<p>Daniel,</p>\r\n\r\n<p>Thanks for your post detailed post detailing your criticisms of the new terms/privacy policy and license for DrugBank. I wanted to reply and clear a couple things up here, and explain some of our thinking:</p>\r\n\r\n<p>1) You have some good points and I believe we have made some mistakes in our current documents. I apologize and hope that we can work to improve this to make our users happier. It would be great to have a discussion about ways to improve.</p>\r\n\r\n<p>2) Half of the founding members of OMx have been working on DrugBank since it’s inception in 2005. One of the things that has attracted and kept us working on DrugBank over the years is the passionate research community that has used the data to produce interesting and insightful work.</p>\r\n\r\n<p>3) The funding situation is not good. Over the past decade we have received significant funding from various levels of the Canadian government. This has allowed us to hire several annotators and programmers, and we have managed to produce several highly cited papers. However, over the past year we have seen several of our colleagues lose their positions (as well as our own) as the funding has disappeared. It seems no funding agency is interested in maintaining highly used databases, regardless of how useful they are. </p>\r\n\r\n<p>4) Our goal with DrugBank is to continue to improve and expand the database. The DrugBank database will always be free for non-commercial use, free to use in research, and by the public. At the same time we intend on funding further development by providing companies with affordable licensing, including small startups and enterprise customers. We are also working on some new things that we plan on releasing with fully open licensing.</p>\r\n\r\n<p>5) We are trying to give as much away for free as we can. Unlike some of the other databases mentioned on twitter and here (KEGG, etc.), we are not charging non-commercial users. Non-commercial can include corporations, depending on use. I think we need to do more work to explain what entails commercial use.</p>\r\n\r\n<p>6) As you pointed out, in the past there was a brief description that included: “Use and re-distribution of the data, in whole or in part, for commercial purposes requires explicit permission of the authors”, some commercial users requested permission, some were granted permission and some were required to get a commercial license, but the majority did not ask for permission. This is one of the things that pushed us to make a signup page for the downloads. Previously it was vague and inconsistently applied, and some groups did not use DrugBank because the licensing was unclear.</p>\r\n\r\n<p>7) We attempted to make our license simple and fair and easy for non-commercial researchers to access. I think we have more work to do here. We also agree that we need to address the requirement that our users are 18 or older, this is far too restrictive.</p>\r\n\r\n<p>We are new to this, and we are learning as we go, so it is good to get your feedback. <br>You have brought up some valid criticism that needs to be addressed. We propose that instead of “sounding the alarm”, we start the discussion on how to solve the issues you have brought up. We will be looking more closely at our terms of use in the next week to see how we can move forward in a way that allows us to secure a future for DrugBank as well as alleviate any fears people in the research community may have. We will be setting up a blog as a medium for this discussion, and look forward to working with you and other members of the research and data community.</p>\r\n\r\n<p>Thanks,<br>Mike and Craig<br>OMx/DrugBank</p>",
      "body_md": "Daniel,\r\n\r\nThanks for your post detailed post detailing your criticisms of the new terms/privacy policy and license for DrugBank. I wanted to reply and clear a couple things up here, and explain some of our thinking:\r\n\r\n1) You have some good points and I believe we have made some mistakes in our current documents. I apologize and hope that we can work to improve this to make our users happier. It would be great to have a discussion about ways to improve.\r\n\r\n2) Half of the founding members of OMx have been working on DrugBank since it’s inception in 2005. One of the things that has attracted and kept us working on DrugBank over the years is the passionate research community that has used the data to produce interesting and insightful work.\r\n\r\n3) The funding situation is not good. Over the past decade we have received significant funding from various levels of the Canadian government. This has allowed us to hire several annotators and programmers, and we have managed to produce several highly cited papers. However, over the past year we have seen several of our colleagues lose their positions (as well as our own) as the funding has disappeared. It seems no funding agency is interested in maintaining highly used databases, regardless of how useful they are. \r\n\r\n4) Our goal with DrugBank is to continue to improve and expand the database. The DrugBank database will always be free for non-commercial use, free to use in research, and by the public. At the same time we intend on funding further development by providing companies with affordable licensing, including small startups and enterprise customers. We are also working on some new things that we plan on releasing with fully open licensing.\r\n\r\n5) We are trying to give as much away for free as we can. Unlike some of the other databases mentioned on twitter and here (KEGG, etc.), we are not charging non-commercial users. Non-commercial can include corporations, depending on use. I think we need to do more work to explain what entails commercial use.\r\n\r\n6) As you pointed out, in the past there was a brief description that included: “Use and re-distribution of the data, in whole or in part, for commercial purposes requires explicit permission of the authors”, some commercial users requested permission, some were granted permission and some were required to get a commercial license, but the majority did not ask for permission. This is one of the things that pushed us to make a signup page for the downloads. Previously it was vague and inconsistently applied, and some groups did not use DrugBank because the licensing was unclear.\r\n\r\n7) We attempted to make our license simple and fair and easy for non-commercial researchers to access. I think we have more work to do here. We also agree that we need to address the requirement that our users are 18 or older, this is far too restrictive.\r\n\r\n\r\nWe are new to this, and we are learning as we go, so it is good to get your feedback. \r\nYou have brought up some valid criticism that needs to be addressed. We propose that instead of “sounding the alarm”, we start the discussion on how to solve the issues you have brought up. We will be looking more closely at our terms of use in the next week to see how we can move forward in a way that allows us to secure a future for DrugBank as well as alleviate any fears people in the research community may have. We will be setting up a blog as a medium for this discussion, and look forward to working with you and other members of the research and data community.\r\n\r\nThanks,\r\nMike and Craig\r\nOMx/DrugBank",
      "comment_id": 1305,
      "profile_id": 241,
      "published": "2016-05-09T18:29:50.285961Z",
      "thread_id": 213,
      "url": "/discussion/sounding-the-alarm-on-drugbanks-new-license-and-terms-of-use/213#6"
    },
    {
      "body_html": "<p>Thanks <a href=\"/u/cknoxrun\" class=\"username\">@cknoxrun</a> for your <a href=\"#6\">helpful comment</a>. I'm happy that you are open to discussion regarding these issues and I'd love to contribute. I really appreciate your quick response and willingness to address the issues we've raised.</p>\r\n\r\n<p>Sorry if I made too many assumptions based on our past experiences. Specifically, I assumed DrugBank's licensing was a done deal and in the hands of an intellectual property department that didn't prioritize data reuse. My experience with MIT's technology licensing (<a href=\"https://thinklab.com/discussion/msigdb-licensing/108\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d108\">primarily regarding MSigDB</a> and less so <a href=\"https://github.com/fraenkel-lab/OmicsIntegrator/issues/11\" title=\"GitHub Issue · Switch OmicsIntegrator from CC BY-NC to an open source license\">OmicsIntegrator</a>) led me to \"sound the alarm\" and reference \"the hijacking\". I think the close ties between DrugBank and OMx will help resolve any disconnect between the legal and community considerations DrugBank faces.</p>\r\n\r\n<p>I understand the difficult realities your team faces when seeking biocuration funding — a point that's been <a href=\"https://listserv.it.northwestern.edu/scripts/wa.exe?A2=ind1605&amp;L=ISB&amp;D=0&amp;P=10771\" title=\"International Society for Biocuration Mailing List\">echoed elsewhere</a>. DrugBank is a fantastic resource. Were I to have to choose between no DrugBank and a highly-restrictive DrugBank, I'd choose the later. Additionally, your team has done a great job of responding to demand and providing a clean user experience. Given the hard compromises imposed by the funding environment, I completely understand that releasing DrugBank <a href=\"http://opendefinition.org/\" title=\"The Open Definition\">openly</a> may not be most healthy long-term option for DrugBank's continued upkeep.</p>\r\n\r\n<p>That being said I do have a few suggestions, which I'll post next. Once the blog is up and running, we can copy any relevant discussion over.</p>",
      "body_md": "Thanks @cknoxrun for your [helpful comment](#6). I'm happy that you are open to discussion regarding these issues and I'd love to contribute. I really appreciate your quick response and willingness to address the issues we've raised.\r\n\r\nSorry if I made too many assumptions based on our past experiences. Specifically, I assumed DrugBank's licensing was a done deal and in the hands of an intellectual property department that didn't prioritize data reuse. My experience with MIT's technology licensing ([primarily regarding MSigDB](https://thinklab.com/discussion/msigdb-licensing/108) and less so [OmicsIntegrator](https://github.com/fraenkel-lab/OmicsIntegrator/issues/11 \"GitHub Issue · Switch OmicsIntegrator from CC BY-NC to an open source license\")) led me to \"sound the alarm\" and reference \"the hijacking\". I think the close ties between DrugBank and OMx will help resolve any disconnect between the legal and community considerations DrugBank faces.\r\n\r\nI understand the difficult realities your team faces when seeking biocuration funding -- a point that's been [echoed elsewhere](https://listserv.it.northwestern.edu/scripts/wa.exe?A2=ind1605&L=ISB&D=0&P=10771 \"International Society for Biocuration Mailing List\"). DrugBank is a fantastic resource. Were I to have to choose between no DrugBank and a highly-restrictive DrugBank, I'd choose the later. Additionally, your team has done a great job of responding to demand and providing a clean user experience. Given the hard compromises imposed by the funding environment, I completely understand that releasing DrugBank [openly](http://opendefinition.org/ \"The Open Definition\") may not be most healthy long-term option for DrugBank's continued upkeep.\r\n\r\nThat being said I do have a few suggestions, which I'll post next. Once the blog is up and running, we can copy any relevant discussion over.",
      "comment_id": 1306,
      "profile_id": 17,
      "published": "2016-05-09T20:12:21.078487Z",
      "thread_id": 213,
      "url": "/discussion/sounding-the-alarm-on-drugbanks-new-license-and-terms-of-use/213#7"
    },
    {
      "body_html": "<p><a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a> does bosentan indication for hypertension originate from DrugCentral? if so, there might be an error in your pipeline, the files uploaded to Github have pulmonary hypertension as an indication.</p>",
      "body_md": "@dhimmel does bosentan indication for hypertension originate from DrugCentral? if so, there might be an error in your pipeline, the files uploaded to Github have pulmonary hypertension as an indication.",
      "comment_id": 1307,
      "profile_id": 242,
      "published": "2016-05-09T19:32:53.684977Z",
      "thread_id": 186,
      "url": "/discussion/incorporating-drugcentral-data-in-our-network/186#5"
    },
    {
      "body_html": "<p>Greetings <a href=\"/u/olegursu\" class=\"username\">@olegursu</a>! I used transitive closure <span class=\"citation\">[<a href=\"https://doi.org/10.1093/bioinformatics/btr164\" class=\"citation\" data-key=\"10.1093/bioinformatics/btr164\">1</a>]</span> on to convert diseases to the level of specificity in Hetionet. This is what I meant by <a href=\"#3\">saying</a>:</p>\r\n\r\n<blockquote><p>For each disease, I aggregated direct indications as well as indications for subtypes (referred to as propagation).</p></blockquote>\r\n\r\n<p>I think you've picked up on an issue that <a href=\"https://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95#8\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d95\">came up</a> during our curation. Specifically the Disease Ontology defines pulmonary hypertension (<code>DOID:6432</code>) as a subtype of hypertension (<code>DOID:10763</code>). However, our curator considered the definition of hypertension to be distinct from pulmonary hypertension.</p>\r\n\r\n<p>So in conclusion, DrugCentral included a bosentan indication for pulmonary hypertension, which was translated to an indication for hypertension in Hetionet. In the future, I'd like to make  transitive closure a query-time decision rather than a builtin, but for now that's not the case.</p>",
      "body_md": "Greetings @olegursu! I used transitive closure [@10.1093/bioinformatics/btr164] on to convert diseases to the level of specificity in Hetionet. This is what I meant by [saying](#3):\r\n\r\n> For each disease, I aggregated direct indications as well as indications for subtypes (referred to as propagation).\r\n\r\nI think you've picked up on an issue that [came up](https://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95#8) during our curation. Specifically the Disease Ontology defines pulmonary hypertension (`DOID:6432`) as a subtype of hypertension (`DOID:10763`). However, our curator considered the definition of hypertension to be distinct from pulmonary hypertension.\r\n\r\nSo in conclusion, DrugCentral included a bosentan indication for pulmonary hypertension, which was translated to an indication for hypertension in Hetionet. In the future, I'd like to make  transitive closure a query-time decision rather than a builtin, but for now that's not the case.",
      "comment_id": 1308,
      "profile_id": 17,
      "published": "2016-05-09T20:43:38.200217Z",
      "thread_id": 186,
      "url": "/discussion/incorporating-drugcentral-data-in-our-network/186#6"
    },
    {
      "body_html": "<h1>How to improve the reusability of DrugBank</h1>\r\n\r\n<p>Here, I'll provide my thoughts on steps DrugBank can take to foster its use in academic research.</p>\r\n\r\n<h2>A standard license</h2>\r\n\r\n<p>From a research perspective, having a license that allows for use, redistribution, and modification are of utmost importance. The CC BY-NC-SA 4.0 License mentioned in the EULA would allow for these uses. As <a href=\"#5\">pointed out above</a>, some changes will be needed before DrugBank can be clearly considered as having a Creative Commons license. </p>\r\n\r\n<p>Redistribution rights are especially important for reproducible science (as some <a href=\"https://gu.com/p/4dcx2/sbl\">weird situations</a> have shown) <span class=\"citation\">[<a href=\"https://doi.org/10.5334/jors.ay\" class=\"citation\" data-key=\"10.5334/jors.ay\">1</a>]</span>. One aspect of redistribution is that users could access DrugBank data from a third party and avoid having to sign up.</p>\r\n\r\n<p>I also think it's important to use a standard license, such as a Creative Commons license, rather than a custom one. Especially since most researchers have minimal legal expertise, a standard license helps reduce the burden academic users must endure to use the resource. Given OMx's commercial licensing goals, a <a href=\"https://creativecommons.org/licenses/by-nc/4.0/\">CC BY-NC</a> license for the public seems to make sense. I'm not sure what OMx gains by adding the share alike (SA) restriction.</p>\r\n\r\n<h2>An open vocabulary</h2>\r\n\r\n<p>A standard non-commercial license like CC BY-NC would enable many academic research uses. For resources such as Hetionet (the network we're creating in Project Rephetio) that aim to integrate knowledge into an open database, the non-commercial stipulation is a disqualifying factor. Here there's no easy solution: one of our main long term goals is to integrate only <a href=\"http://opendefinition.org/licenses/\" title=\"Open Definition Conformant Licenses\">openly licensed</a> content, which would preclude DrugBank.</p>\r\n\r\n<p>In the short term, I have a more pressing concern. Since we use DrugBank to identify compounds in our networks, many of our datasets rely on DrugBank identifiers and drug names. For example, our catalog of medical indications named <a href=\"https://thinklab.com/discussion/announcing-pharmacotherapydb-the-open-catalog-of-drug-therapies-for-disease/182\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d182\">PharmacotherapyDB</a> <span class=\"citation\">[<a href=\"https://doi.org/10.6084/m9.figshare.3103054\" class=\"citation\" data-key=\"10.6084/m9.figshare.3103054\">2</a>]</span> and our forthcoming drug repurposing predictions both identify compounds with their DrugBank IDs. We're committed to releasing the results of our research under the <a href=\"https://creativecommons.org/publicdomain/zero/1.0/\">CC0</a> Public Domain Dedication. As it turns out, our results will often include DrugBank identifiers. While I believe that using a portion of the DrugBank vocabulary is likely fair use, reducing uncertainty in arena would be helpful.</p>\r\n\r\n<p>Hence, I think it would make sense to release the DrugBank vocabulary under an open license (preferably CC0). By vocabulary, I'm referring the identifying information for each compound such as ID, name, and chemical structure. This would allow researchers to use DrugBank-coded compounds in their integrative research without having to worry about any legality issues.</p>\r\n\r\n<p>One final point, I don't want users to feel uncomfortable using our predictions because they include DrugBank identifiers. I hope many of our users will be commercial, and I don't want to scare them away.</p>\r\n\r\n<h2>Website Terms of Use</h2>\r\n\r\n<p>Finally, I think the website Terms of Use should be made less draconian. Many of the forbidden uses seem legitimate and even desirable from a business perspective. The current Terms of Service make the website an intimidating platform to use.</p>",
      "body_md": "# How to improve the reusability of DrugBank\r\n\r\nHere, I'll provide my thoughts on steps DrugBank can take to foster its use in academic research.\r\n\r\n## A standard license\r\n\r\nFrom a research perspective, having a license that allows for use, redistribution, and modification are of utmost importance. The CC BY-NC-SA 4.0 License mentioned in the EULA would allow for these uses. As [pointed out above](#5), some changes will be needed before DrugBank can be clearly considered as having a Creative Commons license. \r\n\r\nRedistribution rights are especially important for reproducible science (as some [weird situations](https://gu.com/p/4dcx2/sbl) have shown) [@10.5334/jors.ay]. One aspect of redistribution is that users could access DrugBank data from a third party and avoid having to sign up.\r\n\r\nI also think it's important to use a standard license, such as a Creative Commons license, rather than a custom one. Especially since most researchers have minimal legal expertise, a standard license helps reduce the burden academic users must endure to use the resource. Given OMx's commercial licensing goals, a [CC BY-NC](https://creativecommons.org/licenses/by-nc/4.0/) license for the public seems to make sense. I'm not sure what OMx gains by adding the share alike (SA) restriction.\r\n\r\n## An open vocabulary\r\n\r\nA standard non-commercial license like CC BY-NC would enable many academic research uses. For resources such as Hetionet (the network we're creating in Project Rephetio) that aim to integrate knowledge into an open database, the non-commercial stipulation is a disqualifying factor. Here there's no easy solution: one of our main long term goals is to integrate only [openly licensed](http://opendefinition.org/licenses/ \"Open Definition Conformant Licenses\") content, which would preclude DrugBank.\r\n\r\nIn the short term, I have a more pressing concern. Since we use DrugBank to identify compounds in our networks, many of our datasets rely on DrugBank identifiers and drug names. For example, our catalog of medical indications named [PharmacotherapyDB](https://thinklab.com/discussion/announcing-pharmacotherapydb-the-open-catalog-of-drug-therapies-for-disease/182) [@10.6084/m9.figshare.3103054] and our forthcoming drug repurposing predictions both identify compounds with their DrugBank IDs. We're committed to releasing the results of our research under the [CC0](https://creativecommons.org/publicdomain/zero/1.0/) Public Domain Dedication. As it turns out, our results will often include DrugBank identifiers. While I believe that using a portion of the DrugBank vocabulary is likely fair use, reducing uncertainty in arena would be helpful.\r\n\r\nHence, I think it would make sense to release the DrugBank vocabulary under an open license (preferably CC0). By vocabulary, I'm referring the identifying information for each compound such as ID, name, and chemical structure. This would allow researchers to use DrugBank-coded compounds in their integrative research without having to worry about any legality issues.\r\n\r\nOne final point, I don't want users to feel uncomfortable using our predictions because they include DrugBank identifiers. I hope many of our users will be commercial, and I don't want to scare them away.\r\n\r\n## Website Terms of Use\r\n\r\nFinally, I think the website Terms of Use should be made less draconian. Many of the forbidden uses seem legitimate and even desirable from a business perspective. The current Terms of Service make the website an intimidating platform to use.",
      "comment_id": 1309,
      "profile_id": 17,
      "published": "2016-05-09T22:18:07.810525Z",
      "thread_id": 213,
      "url": "/discussion/sounding-the-alarm-on-drugbanks-new-license-and-terms-of-use/213#8"
    },
    {
      "body_html": "<p>I'm assuming Mike and Craig  at least contemplated the option of an open/Pro version split.  So what precludes this?  Wouldn't it make things sooooo much simpler?   Cheers</p>",
      "body_md": "I'm assuming Mike and Craig  at least contemplated the option of an open/Pro version split.  So what precludes this?  Wouldn't it make things sooooo much simpler?   Cheers",
      "comment_id": 1310,
      "profile_id": 248,
      "published": "2016-05-11T07:08:13.439456Z",
      "thread_id": 213,
      "url": "/discussion/sounding-the-alarm-on-drugbanks-new-license-and-terms-of-use/213#9"
    },
    {
      "body_html": "<h2>Feature improvements</h2>\r\n\r\n<p>We've made several improvements that affect our features. Compared to the <a href=\"#3\">previous post</a> the following updates were made:</p>\r\n\r\n<ol><li>We completed the first production version of our hetnet named Hetionet v1.0. See <a href=\"https://thinklab.com/discussion/data-nomenclature-naming-and-abbreviating-our-network-types/162#8\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d162\">this post</a> for the updated metagraph and type abbreviations.</li><li>We <a href=\"https://thinklab.com/discussion/announcing-pharmacotherapydb-the-open-catalog-of-drug-therapies-for-disease/182\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d182\">created PharamacotherapyDB</a> which refined our indication catalog to differentiate between disease modifying and symptomatic indications. Now disease modifying indications (called treatments or <code>DM</code>) are positives and all other compound–disease pairs (observations) are negatives.</li><li>We <a href=\"https://thinklab.com/discussion/using-the-neo4j-graph-database-for-hetnets/112#4\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d112\">switched</a> from using our pure python toolset (<a href=\"https://github.com/dhimmel/hetio/blob/2c135fcd32616d6979972105ba60b003d65c98bd/hetio/pathtools.py\"><code>hetio.pathtools</code></a>) to Neo4j for computing network-based features. While we maintained the <a href=\"https://thinklab.com/discussion/path-exclusion-conditions/134\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d134\">duplicate node exclusion</a> for path traversal, there are some minor differences in the Cypher and <code>hetio.pathtools</code> DWPC algorithms.</li><li>We <a href=\"https://thinklab.com/discussion/transforming-dwpcs-for-hetnet-edge-prediction/193#6\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d193\">identified a transformation</a> to make DWPCs distributions more appropriate for modeling.</li><li>We computed DWPCs for all 1,206 metapaths with lengths 2–4. <a href=\"https://github.com/dhimmel/integrate/blob/095747de9efe42a9ed1e23ab18db282e14705cd9/viz/auto/data/metapath-counts.tsv#L129\" title=\"Metapath counts for each length-source-target combination\">1,072</a> of the methapaths are length 4.</li><li>We computed DWPCs on five <a href=\"https://thinklab.com/discussion/assessing-the-effectiveness-of-our-hetnet-permutations/178\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d178\">permuted networks</a>.</li><li>We invented a DWPC derivative called <em>residual DWPC</em> (R-DWPC), which is the difference between DWPC and average permuted DWPC for an observation.</li></ol>\r\n\r\n<h2>AUROC-based metrics for assessing DWPC features</h2>\r\n\r\n<p>The performance for each of 1,206 DWPC features is now available (<a href=\"https://github.com/dhimmel/learn/blob/e1c46ddc7e04a3d3eac6b907298c58db1d32a95b/all-features/data/feature-performance/auroc.tsv\">dataset</a>). The dataset consists of the following AUROC-based performance metrics:</p>\r\n\r\n<ul><li><code>dwpc_auroc</code>: the AUROC of a DWPC</li><li><code>pdwpc_auroc</code>: the average AUROC of a DWPC across permuted networks but computed on the positives and negatives corresponding to the unpermuted network</li><li><code>rdwpc_auroc</code>: the AUROC of a residual DWPC</li><li><code>pdwpc_primary_auroc</code>: the average AUROC of a DWPC across permuted networks. This AUROC uses reassigned positives and negatives based on the specific treatment edges in each permuted network</li><li><code>delta_auroc</code>: the <code>dwpc_auroc</code> minus the <code>pdwpc_primary_auroc</code> for a metapath</li><li><code>pval_delta_auroc</code>: the p-value from a t-test of the difference between the <code>dwpc_auroc</code> and the five corresponding primary permuted AUROCs.</li></ul>\r\n\r\n<p>We're adopting the Δ AUROC (<code>delta_auroc</code>) as our main assessment of feature informativeness. The Δ AUROC is preferable to the plain DWPC AUROC because it assesses whether the specific edges of a metapath are predictive. Otherwise predictiveness may be dominated by node degree effects — an often overlooked shortcoming of many network analyses <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pone.0017258\" class=\"citation\" data-key=\"10.1371/journal.pone.0017258\">1</a>, <a href=\"https://doi.org/10.1161/CIRCGENETICS.115.001181\" class=\"citation\" data-key=\"10.1161/CIRCGENETICS.115.001181\">2</a>]</span>. The R-DWPC AUROC (<code>rdwpc_auroc</code>) is a promising metric for the future but currently suffers from an <a href=\"https://thinklab.com/discussion/edge-dropout-contamination-in-hetnet-edge-prediction/215\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d215\">edge-dropout contamination issue</a>.</p>",
      "body_md": "## Feature improvements\r\n\r\nWe've made several improvements that affect our features. Compared to the [previous post](#3) the following updates were made:\r\n\r\n1. We completed the first production version of our hetnet named Hetionet v1.0. See [this post](https://thinklab.com/discussion/data-nomenclature-naming-and-abbreviating-our-network-types/162#8) for the updated metagraph and type abbreviations.\r\n+ We [created PharamacotherapyDB](https://thinklab.com/discussion/announcing-pharmacotherapydb-the-open-catalog-of-drug-therapies-for-disease/182) which refined our indication catalog to differentiate between disease modifying and symptomatic indications. Now disease modifying indications (called treatments or `DM`) are positives and all other compound--disease pairs (observations) are negatives.\r\n+ We [switched](https://thinklab.com/discussion/using-the-neo4j-graph-database-for-hetnets/112#4) from using our pure python toolset ([`hetio.pathtools`](https://github.com/dhimmel/hetio/blob/2c135fcd32616d6979972105ba60b003d65c98bd/hetio/pathtools.py)) to Neo4j for computing network-based features. While we maintained the [duplicate node exclusion](https://thinklab.com/discussion/path-exclusion-conditions/134) for path traversal, there are some minor differences in the Cypher and `hetio.pathtools` DWPC algorithms.\r\n+ We [identified a transformation](https://thinklab.com/discussion/transforming-dwpcs-for-hetnet-edge-prediction/193#6) to make DWPCs distributions more appropriate for modeling.\r\n+ We computed DWPCs for all 1,206 metapaths with lengths 2--4. [1,072](https://github.com/dhimmel/integrate/blob/095747de9efe42a9ed1e23ab18db282e14705cd9/viz/auto/data/metapath-counts.tsv#L129 \"Metapath counts for each length-source-target combination\") of the methapaths are length 4.\r\n+ We computed DWPCs on five [permuted networks](https://thinklab.com/discussion/assessing-the-effectiveness-of-our-hetnet-permutations/178).\r\n+ We invented a DWPC derivative called _residual DWPC_ (R-DWPC), which is the difference between DWPC and average permuted DWPC for an observation.\r\n\r\n## AUROC-based metrics for assessing DWPC features\r\n\r\nThe performance for each of 1,206 DWPC features is now available ([dataset](https://github.com/dhimmel/learn/blob/e1c46ddc7e04a3d3eac6b907298c58db1d32a95b/all-features/data/feature-performance/auroc.tsv)). The dataset consists of the following AUROC-based performance metrics:\r\n\r\n+ `dwpc_auroc`: the AUROC of a DWPC\r\n+ `pdwpc_auroc`: the average AUROC of a DWPC across permuted networks but computed on the positives and negatives corresponding to the unpermuted network\r\n+ `rdwpc_auroc`: the AUROC of a residual DWPC\r\n+ `pdwpc_primary_auroc`: the average AUROC of a DWPC across permuted networks. This AUROC uses reassigned positives and negatives based on the specific treatment edges in each permuted network\r\n+ `delta_auroc`: the `dwpc_auroc` minus the `pdwpc_primary_auroc` for a metapath\r\n+ `pval_delta_auroc`: the p-value from a t-test of the difference between the `dwpc_auroc` and the five corresponding primary permuted AUROCs.\r\n\r\nWe're adopting the Δ AUROC (`delta_auroc`) as our main assessment of feature informativeness. The Δ AUROC is preferable to the plain DWPC AUROC because it assesses whether the specific edges of a metapath are predictive. Otherwise predictiveness may be dominated by node degree effects -- an often overlooked shortcoming of many network analyses [@10.1371/journal.pone.0017258 @10.1161/CIRCGENETICS.115.001181]. The R-DWPC AUROC (`rdwpc_auroc`) is a promising metric for the future but currently suffers from an [edge-dropout contamination issue](https://thinklab.com/discussion/edge-dropout-contamination-in-hetnet-edge-prediction/215).",
      "comment_id": 1311,
      "profile_id": 17,
      "published": "2016-05-15T06:08:00.181046Z",
      "thread_id": 115,
      "url": "/discussion/assessing-the-informativeness-of-features/115#3"
    },
    {
      "body_html": "<p>The degree-weighted path count (DWPC) is the metric we use to assess the prevalence of a specific type of path between two nodes <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1004259\">1</a>]</span>. The DWPC assesses the number of paths between a source and target node for a given metapath while weighting the connectivity (node degrees) along the path.</p>\r\n\r\n<p>Despite the degree weighting, DWPCs are highly dependent on the source and target node degrees. For a given observation (compound–disease pair in our application) and metapath, the majority of a DWPC often reflects the source and target node degrees rather than the specific relationship between the source and target.</p>\r\n\r\n<p>The residual DWPC or R-DWPC is a metric invented by <a href=\"/u/alizee\" class=\"username\">@alizee</a> and I to measure the specific connectivity between two nodes after adjusting for general effects of node degree. The definition is, for a given observation and metapath, the R-DWPC equals the DWPC minus the P-DWPC. The P-DWPC is the average DWPC for an observation across <a href=\"https://thinklab.com/discussion/assessing-the-effectiveness-of-our-hetnet-permutations/178\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d178\">permuted hetnets</a>. Hence, the P-DWPC captures general effects of node degree but does not capture specific edge effects.</p>\r\n\r\n<p>In summary, we've developed a method for splitting a DWPC into permuted (degree specific) and residual (edge specific) components. I see the R-DWPC as part of a larger movement to disentangle degree and edge effects in network analysis. As past research has shown <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1004259\">1</a>, <a href=\"https://doi.org/10.1371/journal.pone.0017258\" class=\"citation\" data-key=\"10.1371/journal.pone.0017258\">2</a>, <a href=\"https://doi.org/10.1161/CIRCGENETICS.115.001181\" class=\"citation\" data-key=\"10.1161/CIRCGENETICS.115.001181\">3</a>, <a href=\"/discussion/network-edge-prediction-estimating-the-prior/201\" class=\"citation\" data-key=\"10.15363/thinklab.d201\">4</a>]</span>, network degree can be highly predictive without drawing any insight from the relationship between entities. While a good modeling approach should incorporate degree effects, it could aid interpretation to separately model degree and edge effects.</p>\r\n\r\n<h2>Transformation and the R-DWPC</h2>\r\n\r\n<p>We <a href=\"https://thinklab.com/discussion/transforming-dwpcs-for-hetnet-edge-prediction/193#6\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d193\">identified a transformation</a> for DWPCs to make their distribution more suitable for modeling. The transformation scales DWPCs by their mean and then applies the IHS function. When computing P-DWPCs and R-DWPCs <a href=\"/u/alizee\" class=\"username\">@alizee</a> and I decided on the following pipeline:</p>\r\n\r\n<ol><li>Compute DWPCs for the selected observations on the unpermuted and permuted hetnets.</li><li>Identify the mean DWPCs for each metapath on the unpermuted network.</li><li>Transform DWPCs for the unpermuted and permuted networsk using the scaling factor identified in 2.</li><li>Average the DWPCs on the permuted networks to get the P-DWPC.</li><li>Subtract the P-DWPC from the unpermuted-hetnet DWPC to get the R-DWPC.</li></ol>\r\n\r\n<p>We chose to base the R-DWPC on a difference rather than a quotient. Additionally, we chose one of many ways to incorporate transformation. Future research that makes use of R-DWPCs may want to reevaluate these decisions under a performance-driven approach.</p>",
      "body_md": "The degree-weighted path count (DWPC) is the metric we use to assess the prevalence of a specific type of path between two nodes [@10.1371/journal.pcbi.1004259]. The DWPC assesses the number of paths between a source and target node for a given metapath while weighting the connectivity (node degrees) along the path.\r\n\r\nDespite the degree weighting, DWPCs are highly dependent on the source and target node degrees. For a given observation (compound--disease pair in our application) and metapath, the majority of a DWPC often reflects the source and target node degrees rather than the specific relationship between the source and target.\r\n\r\nThe residual DWPC or R-DWPC is a metric invented by @alizee and I to measure the specific connectivity between two nodes after adjusting for general effects of node degree. The definition is, for a given observation and metapath, the R-DWPC equals the DWPC minus the P-DWPC. The P-DWPC is the average DWPC for an observation across [permuted hetnets](https://thinklab.com/discussion/assessing-the-effectiveness-of-our-hetnet-permutations/178). Hence, the P-DWPC captures general effects of node degree but does not capture specific edge effects.\r\n\r\nIn summary, we've developed a method for splitting a DWPC into permuted (degree specific) and residual (edge specific) components. I see the R-DWPC as part of a larger movement to disentangle degree and edge effects in network analysis. As past research has shown [@10.1371/journal.pcbi.1004259 @10.1371/journal.pone.0017258 @10.1161/CIRCGENETICS.115.001181 @10.15363/thinklab.d201], network degree can be highly predictive without drawing any insight from the relationship between entities. While a good modeling approach should incorporate degree effects, it could aid interpretation to separately model degree and edge effects.\r\n\r\n## Transformation and the R-DWPC\r\n\r\nWe [identified a transformation](https://thinklab.com/discussion/transforming-dwpcs-for-hetnet-edge-prediction/193#6) for DWPCs to make their distribution more suitable for modeling. The transformation scales DWPCs by their mean and then applies the IHS function. When computing P-DWPCs and R-DWPCs @alizee and I decided on the following pipeline:\r\n\r\n1. Compute DWPCs for the selected observations on the unpermuted and permuted hetnets.\r\n2. Identify the mean DWPCs for each metapath on the unpermuted network.\r\n3. Transform DWPCs for the unpermuted and permuted networsk using the scaling factor identified in 2.\r\n4. Average the DWPCs on the permuted networks to get the P-DWPC.\r\n5. Subtract the P-DWPC from the unpermuted-hetnet DWPC to get the R-DWPC.\r\n\r\nWe chose to base the R-DWPC on a difference rather than a quotient. Additionally, we chose one of many ways to incorporate transformation. Future research that makes use of R-DWPCs may want to reevaluate these decisions under a performance-driven approach.",
      "comment_id": 1312,
      "profile_id": 17,
      "published": "2016-05-16T18:32:57.242798Z",
      "thread_id": 214,
      "url": "/discussion/introducing-the-residual-degree-weighted-path-count-r-dwpc/214"
    },
    {
      "body_html": "<h1>Assessing the performance of R-DWPCs</h1>\r\n\r\n<p>We assessed the performance of several DWPC-derived measures in predicting when a compound treats a disease. The analysis was based on <a href=\"https://thinklab.com/discussion/assessing-the-informativeness-of-features/115#3\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d115\">our features</a> extracted from Hetionet v1.0. Metapaths with a <em>treats</em> or <em>palliates</em> metaedge were excluded to remove any <a href=\"https://thinklab.com/discussion/edge-dropout-contamination-in-hetnet-edge-prediction/215\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d215\">prediction-edge-dropout contamination</a>. Models included <a href=\"https://thinklab.com/discussion/our-hetnet-edge-prediction-methodology-the-modeling-framework-for-project-rephetio/210#2\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d210\">prior, degree, and DWPC features</a>. However, different models were fit for each of five DWPC feature sets (<a href=\"http://nbviewer.jupyter.org/github/dhimmel/learn/blob/e1c46ddc7e04a3d3eac6b907298c58db1d32a95b/all-features/5.6-model.ipynb\">notebook</a>):</p>\r\n\r\n<ol><li>DPWCs</li><li>P-DWPCs</li><li>R-DWPCs</li><li>P-DWPCs &amp; R-DWPCs</li><li>DPWCs, P-DWPCs &amp; R-DWPCs</li></ol>\r\n\r\n<p>Model 2 (P-DWPCs) was the worst performer, with only the <code>prior_logit</code> feature being selected by a cross-validated lasso. Model 1 performed the best (AUROC = 91.2%). Model 4, for which we had the highest hopes, had (AUROC = 91.0%). I was surprised that splitting the DWPC into permuted and residual components did not improve performance. The split didn't seem to majorly change predictions, with the predicted probabilities from Models 1 and 4 having a correlation of 87.0%.</p>\r\n\r\n<p>Given that the P/R-DWPC separation adds complexity without improving performance, we plan to continue primarily with DWPCs for Project Rephetio. However, I do hope to explore per-observation permutation adjustment again in the future.</p>",
      "body_md": "# Assessing the performance of R-DWPCs\r\n\r\nWe assessed the performance of several DWPC-derived measures in predicting when a compound treats a disease. The analysis was based on [our features](https://thinklab.com/discussion/assessing-the-informativeness-of-features/115#3) extracted from Hetionet v1.0. Metapaths with a _treats_ or _palliates_ metaedge were excluded to remove any [prediction-edge-dropout contamination](https://thinklab.com/discussion/edge-dropout-contamination-in-hetnet-edge-prediction/215). Models included [prior, degree, and DWPC features](https://thinklab.com/discussion/our-hetnet-edge-prediction-methodology-the-modeling-framework-for-project-rephetio/210#2). However, different models were fit for each of five DWPC feature sets ([notebook](http://nbviewer.jupyter.org/github/dhimmel/learn/blob/e1c46ddc7e04a3d3eac6b907298c58db1d32a95b/all-features/5.6-model.ipynb)):\r\n\r\n1. DPWCs\r\n2. P-DWPCs\r\n3. R-DWPCs\r\n4. P-DWPCs & R-DWPCs\r\n5. DPWCs, P-DWPCs & R-DWPCs\r\n\r\nModel 2 (P-DWPCs) was the worst performer, with only the `prior_logit` feature being selected by a cross-validated lasso. Model 1 performed the best (AUROC = 91.2%). Model 4, for which we had the highest hopes, had (AUROC = 91.0%). I was surprised that splitting the DWPC into permuted and residual components did not improve performance. The split didn't seem to majorly change predictions, with the predicted probabilities from Models 1 and 4 having a correlation of 87.0%.\r\n\r\nGiven that the P/R-DWPC separation adds complexity without improving performance, we plan to continue primarily with DWPCs for Project Rephetio. However, I do hope to explore per-observation permutation adjustment again in the future.",
      "comment_id": 1313,
      "profile_id": 17,
      "published": "2016-05-16T19:54:45.696710Z",
      "thread_id": 214,
      "url": "/discussion/introducing-the-residual-degree-weighted-path-count-r-dwpc/214#2"
    },
    {
      "body_html": "<p>Our current approach revolves around modeling treatments that are included in the hetnet as <em>treats</em> edges. We've previously discussed and dealt with some implications of this <a href=\"https://thinklab.com/discussion/network-edge-prediction-how-to-deal-with-self-testing/194\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d194\">self-testing methodology</a>. This post will introduce another issue related to modeling edges that are part of the hetnet used to extract features.</p>\r\n\r\n<p>Previously, we looked into whether paths with duplicate nodes should be excluded. Without the duplicate node exclusion, we were allowing paths that directly contained the prediction edge (the prediction edge refers to the compound–disease pair that a feature describes). We <a href=\"https://thinklab.com/discussion/path-exclusion-conditions/134#4\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d134\">found that</a>:</p>\r\n\r\n<blockquote><p>paths including the prediction edge cause overfitting by incorporating the outcome (indication status) into the predictor (DWPC)</p></blockquote>\r\n\r\n<p>Now we have identified another contamination vector by which the presence of the prediction edge can seep into DWPCs. In the previous example of contamination, the DWPC of positives is <em>inflated </em> relative to negatives. With edge dropout contamination, the DWPC of positives is <em>deflated </em> relative to negatives. Here's why: if the prediction edge is an actual treatment, a treatment edge is effectively masked from the hetnet. However, if the prediction edge is not a treatment, no treatment edges are masked from the hetnet.</p>\r\n\r\n<p>Let's imagine that Compound <code>C1</code> treats only Disease <code>D1</code>. We'll consider the <em>CtDlAlD</em> metapath (<em>Compound–treats–Disease–localizes–Anatomy–localizes–Disease</em>). First note that Disease–localizes–Anatomy edges are common. Therefore, two random diseases likely colocalize to several anatomies. In other words, there will almost always be paths for the <em>DlAlD</em> portion of the metapath. When the prediction edge is <code>C1</code>–<code>D1</code>, the DWPC will be zero because <code>C1</code>–treats–<code>D1</code> is masked due to the duplicate node exclusion. However, for other diseases (<code>D2</code>, <code>D3</code>, …), the <code>C1</code>–treats–<code>D1</code> edge is available for traversal. Thus the path count (and hence the DWPC) will generally be nonzero between <code>C1</code> and all other diseases besides <code>D1</code>. In this hypothetical example, edge dropout contamination could lead to spurious negative association between the DWPC for the <em>CtDlAlD</em> metapath and the presence of treatment edges.</p>\r\n\r\n<p>The specific issue we describe here could more precisely be called \"prediction-edge dropout contamination\". It's possible that edge dropout raises problems for a broad spectrum of network approaches.</p>",
      "body_md": "Our current approach revolves around modeling treatments that are included in the hetnet as _treats_ edges. We've previously discussed and dealt with some implications of this [self-testing methodology](https://thinklab.com/discussion/network-edge-prediction-how-to-deal-with-self-testing/194). This post will introduce another issue related to modeling edges that are part of the hetnet used to extract features.\r\n\r\nPreviously, we looked into whether paths with duplicate nodes should be excluded. Without the duplicate node exclusion, we were allowing paths that directly contained the prediction edge (the prediction edge refers to the compound--disease pair that a feature describes). We [found that](https://thinklab.com/discussion/path-exclusion-conditions/134#4):\r\n\r\n> paths including the prediction edge cause overfitting by incorporating the outcome (indication status) into the predictor (DWPC)\r\n\r\nNow we have identified another contamination vector by which the presence of the prediction edge can seep into DWPCs. In the previous example of contamination, the DWPC of positives is _inflated _ relative to negatives. With edge dropout contamination, the DWPC of positives is _deflated _ relative to negatives. Here's why: if the prediction edge is an actual treatment, a treatment edge is effectively masked from the hetnet. However, if the prediction edge is not a treatment, no treatment edges are masked from the hetnet.\r\n\r\nLet's imagine that Compound `C1` treats only Disease `D1`. We'll consider the _CtDlAlD_ metapath (_Compound--treats--Disease--localizes--Anatomy--localizes--Disease_). First note that Disease--localizes--Anatomy edges are common. Therefore, two random diseases likely colocalize to several anatomies. In other words, there will almost always be paths for the _DlAlD_ portion of the metapath. When the prediction edge is `C1`--`D1`, the DWPC will be zero because `C1`--treats--`D1` is masked due to the duplicate node exclusion. However, for other diseases (`D2`, `D3`, …), the `C1`--treats--`D1` edge is available for traversal. Thus the path count (and hence the DWPC) will generally be nonzero between `C1` and all other diseases besides `D1`. In this hypothetical example, edge dropout contamination could lead to spurious negative association between the DWPC for the _CtDlAlD_ metapath and the presence of treatment edges.\r\n\r\nThe specific issue we describe here could more precisely be called \"prediction-edge dropout contamination\". It's possible that edge dropout raises problems for a broad spectrum of network approaches.",
      "comment_id": 1314,
      "profile_id": 17,
      "published": "2016-05-16T20:03:59.583717Z",
      "thread_id": 215,
      "url": "/discussion/edge-dropout-contamination-in-hetnet-edge-prediction/215"
    },
    {
      "body_html": "<h1>Selecting features for Stage 2</h1>\r\n\r\n<p>One major goal of <a href=\"#2\">Stage 1</a> is to select a subset of DWPC features to calculate on all observations. We've considered three methods for this selection.</p>\r\n\r\n<h2>Method 1</h2>\r\n\r\n<p>The first method is to use <a href=\"https://thinklab.com/discussion/assessing-the-informativeness-of-features/115#3\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d115\">feature-specific performance measures</a> as selection criteria. This method allows the user to define the characteristics of a promising feature. For example, the user could select only features that will lend themselves to interpretation.</p>\r\n\r\n<h2>Method 2</h2>\r\n\r\n<p>The second method is to use the lasso to select features <span class=\"citation\">[<a href=\"https://doi.org/10.1111/j.1467-9868.2011.00771.x\" class=\"citation\" data-key=\"10.1111/j.1467-9868.2011.00771.x\">1</a>]</span>. Since we find the optimal regularization strength using cross-validation, each modeling fit will be slightly different. Therefore, we fit many models, each time varying the random seed, and identify features which were selected by at least a given percentage of the models. The advantages of this method are that it considers how features perform in a model rather than alone. Hence, it is adept at identifying features with a unique contribution and can avoid selecting collinear (redundant) features <span class=\"citation\">[<a href=\"https://doi.org/10.1111/j.1600-0587.2012.07348.x\" class=\"citation\" data-key=\"10.1111/j.1600-0587.2012.07348.x\">2</a>]</span>. The downside of this method is that it can select features that are not marginally informative but are helpful covariates. While this improves model goodness of fit, it can lead to difficultly in interpreting the model and understanding why a given prediction was made.</p>\r\n\r\n<h2>Method 3</h2>\r\n\r\n<p>Method three involves performing Method 1 and then Method 2. This combined approach makes sense if the user-guided selection of Method 1 results in a large number of features. If extra feature selection is warranted by computational constraints, then Method 2 can be applied on top of Method 1.</p>\r\n\r\n<h2>Our choice</h2>\r\n\r\n<p>We went with Method 1 and defined the following inclusion criteria for a DWPC feature (<a href=\"https://github.com/dhimmel/learn/blob/a7766ea00da67f5cf03bd77e6e613a262918f1b8/prediction/1-prepare.ipynb\">notebook</a>):</p>\r\n\r\n<ul><li><code>delta_auroc &gt; 0</code> and <code>fdr_delta_auroc &lt; 0.05</code> to select informative features</li><li><code>pdwpc_primary_auroc &gt; 0.5</code> to guard against <a href=\"https://thinklab.com/discussion/edge-dropout-contamination-in-hetnet-edge-prediction/215\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d215\">edge dropout contamination</a></li><li><code>rdwpc_auroc &gt; 0.55</code> to select informative features and guard against edge dropout contamination</li></ul>\r\n\r\n<p>These filters reduced our number of DWPC features from 1,206 to 142. Since we could compute 142 features on all observations, we skipped Method 2. The choice to rely on Method 1 was driven by desire to address edge dropout contamination and select features that are insightful.</p>",
      "body_md": "# Selecting features for Stage 2\r\n\r\nOne major goal of [Stage 1](#2) is to select a subset of DWPC features to calculate on all observations. We've considered three methods for this selection.\r\n\r\n## Method 1\r\n\r\nThe first method is to use [feature-specific performance measures](https://thinklab.com/discussion/assessing-the-informativeness-of-features/115#3) as selection criteria. This method allows the user to define the characteristics of a promising feature. For example, the user could select only features that will lend themselves to interpretation.\r\n\r\n## Method 2\r\n\r\nThe second method is to use the lasso to select features [@10.1111/j.1467-9868.2011.00771.x]. Since we find the optimal regularization strength using cross-validation, each modeling fit will be slightly different. Therefore, we fit many models, each time varying the random seed, and identify features which were selected by at least a given percentage of the models. The advantages of this method are that it considers how features perform in a model rather than alone. Hence, it is adept at identifying features with a unique contribution and can avoid selecting collinear (redundant) features [@10.1111/j.1600-0587.2012.07348.x]. The downside of this method is that it can select features that are not marginally informative but are helpful covariates. While this improves model goodness of fit, it can lead to difficultly in interpreting the model and understanding why a given prediction was made.\r\n\r\n## Method 3\r\n\r\nMethod three involves performing Method 1 and then Method 2. This combined approach makes sense if the user-guided selection of Method 1 results in a large number of features. If extra feature selection is warranted by computational constraints, then Method 2 can be applied on top of Method 1.\r\n\r\n## Our choice\r\n\r\nWe went with Method 1 and defined the following inclusion criteria for a DWPC feature ([notebook](https://github.com/dhimmel/learn/blob/a7766ea00da67f5cf03bd77e6e613a262918f1b8/prediction/1-prepare.ipynb)):\r\n\r\n+ `delta_auroc > 0` and `fdr_delta_auroc < 0.05` to select informative features\r\n+ `pdwpc_primary_auroc > 0.5` to guard against [edge dropout contamination](https://thinklab.com/discussion/edge-dropout-contamination-in-hetnet-edge-prediction/215)\r\n+ `rdwpc_auroc > 0.55` to select informative features and guard against edge dropout contamination\r\n\r\nThese filters reduced our number of DWPC features from 1,206 to 142. Since we could compute 142 features on all observations, we skipped Method 2. The choice to rely on Method 1 was driven by desire to address edge dropout contamination and select features that are insightful.",
      "comment_id": 1317,
      "profile_id": 17,
      "published": "2016-05-17T16:22:15.920779Z",
      "thread_id": 210,
      "url": "/discussion/our-hetnet-edge-prediction-methodology-the-modeling-framework-for-project-rephetio/210#3"
    },
    {
      "body_html": "<h1>Refining our Stage 2 modeling approach</h1>\r\n\r\n<p>Here we'll describe how we fit the model on the all observations dataset for Stage 2. Remember that the model is fit only the 29,799 observations with a non-zero prior. We fit an elastic net with α = 0.2 <span class=\"citation\">[<a href=\"https://doi.org/10.1111/j.1467-9868.2005.00503.x\" class=\"citation\" data-key=\"10.1111/j.1467-9868.2005.00503.x\">1</a>]</span>. We chose the elastic net mixing parameter (α) to balance model parsimony (which aids interpretation) and retaining pharmacologically-meaningful features.</p>\r\n\r\n<p>Despite our efforts to remove features susceptible to edge dropout contamination during <a href=\"#3\">Stage 1 feature selection</a>, several features were getting incorporated into the Stage 2 model that showed evidence of contamination: features with <em>treats</em> relationships receiving negative coefficients when their marginal association with treatment is positive. Hence, I manually assembled a <a href=\"https://github.com/dhimmel/learn/blob/a7766ea00da67f5cf03bd77e6e613a262918f1b8/prediction/features/blacklist.tsv\">feature blacklist</a>, which I iteratively added features to that were showing evidence of contamination. In total, 22 features were blacklisted.</p>\r\n\r\n<p>Ultimately, the model was fit on 138 features and assigned 18 negative and 13 positive feature coefficients (<a href=\"https://github.com/dhimmel/learn/blob/a7766ea00da67f5cf03bd77e6e613a262918f1b8/prediction/4-predictr.ipynb\">notebook</a>, <a href=\"https://github.com/dhimmel/learn/blob/a7766ea00da67f5cf03bd77e6e613a262918f1b8/prediction/model/coefficient.tsv\">coefficient table</a>). The negative coefficients seem to serve as covariates by adjusting for unspecific node degree effects. While we included separate degree features for this purpose, the DWPCs seem to have been preferred by the model.</p>\r\n\r\n<p>Such a small number of positive coefficients is a bit disappointing. Our feature assessment (<a href=\"https://thinklab.com/discussion/assessing-the-informativeness-of-features/115#4\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d115\">here</a> and in Panel A below) shows that a broad range of metapaths are informative. The origin of our model's selectivity appears to lie with the “one-standard-error” rule <span class=\"citation\">[<a href=\"https://doi.org/10.18637/jss.v033.i01\" class=\"citation\" data-key=\"10.18637/jss.v033.i01\">2</a>]</span> we use to identify the optimal regularization strength (λ). Our model had high cross-validated standard error leading to substantial regularization on top of the deviance minimizing model. While it's tempting to relax our λ selection, I'd rather be more confident in a minimalist model than risk a less coherent but more complex model.</p>\r\n\r\n<h2>Visualizing feature contribution</h2>\r\n\r\n<p>Panel A below shows the performance of each of the 142 selected DWPC features. Metapaths are organized by their constituent metaedges. Here we see that our <a href=\"#3\">feature selection approach</a> retained features that cover diverse types of information. In fact, the only metaedge that lost all of its features was <em>Gene–participates–Cellular Component</em>.</p>\r\n\r\n<p><img src=\"https://github.com/dhimmel/learn/blob/a7766ea00da67f5cf03bd77e6e613a262918f1b8/prediction/figure/features.png?raw=true\" alt=\"Feature performance and modeling\"></p>\r\n\r\n<p>Panel B shows the non-zero model coefficients from the Stage 2 model. Note that the invariant term coefficients are not shows (the intercept and the prior).</p>",
      "body_md": "# Refining our Stage 2 modeling approach\r\n\r\nHere we'll describe how we fit the model on the all observations dataset for Stage 2. Remember that the model is fit only the 29,799 observations with a non-zero prior. We fit an elastic net with α = 0.2 [@10.1111/j.1467-9868.2005.00503.x]. We chose the elastic net mixing parameter (α) to balance model parsimony (which aids interpretation) and retaining pharmacologically-meaningful features.\r\n\r\nDespite our efforts to remove features susceptible to edge dropout contamination during [Stage 1 feature selection](#3), several features were getting incorporated into the Stage 2 model that showed evidence of contamination: features with _treats_ relationships receiving negative coefficients when their marginal association with treatment is positive. Hence, I manually assembled a [feature blacklist](https://github.com/dhimmel/learn/blob/a7766ea00da67f5cf03bd77e6e613a262918f1b8/prediction/features/blacklist.tsv), which I iteratively added features to that were showing evidence of contamination. In total, 22 features were blacklisted.\r\n\r\nUltimately, the model was fit on 138 features and assigned 18 negative and 13 positive feature coefficients ([notebook](https://github.com/dhimmel/learn/blob/a7766ea00da67f5cf03bd77e6e613a262918f1b8/prediction/4-predictr.ipynb), [coefficient table](https://github.com/dhimmel/learn/blob/a7766ea00da67f5cf03bd77e6e613a262918f1b8/prediction/model/coefficient.tsv)). The negative coefficients seem to serve as covariates by adjusting for unspecific node degree effects. While we included separate degree features for this purpose, the DWPCs seem to have been preferred by the model.\r\n\r\nSuch a small number of positive coefficients is a bit disappointing. Our feature assessment ([here](https://thinklab.com/discussion/assessing-the-informativeness-of-features/115#4) and in Panel A below) shows that a broad range of metapaths are informative. The origin of our model's selectivity appears to lie with the “one-standard-error” rule [@10.18637/jss.v033.i01] we use to identify the optimal regularization strength (λ). Our model had high cross-validated standard error leading to substantial regularization on top of the deviance minimizing model. While it's tempting to relax our λ selection, I'd rather be more confident in a minimalist model than risk a less coherent but more complex model.\r\n\r\n## Visualizing feature contribution\r\n\r\nPanel A below shows the performance of each of the 142 selected DWPC features. Metapaths are organized by their constituent metaedges. Here we see that our [feature selection approach](#3) retained features that cover diverse types of information. In fact, the only metaedge that lost all of its features was _Gene--participates--Cellular Component_.\r\n\r\n![Feature performance and modeling](https://github.com/dhimmel/learn/blob/a7766ea00da67f5cf03bd77e6e613a262918f1b8/prediction/figure/features.png?raw=true)\r\n\r\nPanel B shows the non-zero model coefficients from the Stage 2 model. Note that the invariant term coefficients are not shows (the intercept and the prior).",
      "comment_id": 1318,
      "profile_id": 17,
      "published": "2016-05-17T17:19:43.123603Z",
      "thread_id": 210,
      "url": "/discussion/our-hetnet-edge-prediction-methodology-the-modeling-framework-for-project-rephetio/210#4"
    },
    {
      "body_html": "<h1>Assessing prediction performance</h1>\r\n\r\n<p>We've assembled four sets of indications to assess our predictions on:</p>\r\n\r\n<ul><li><strong>Disease Modifying</strong> — the 755 disease modifying treatments in <a href=\"https://thinklab.com/discussion/announcing-pharmacotherapydb-the-open-catalog-of-drug-therapies-for-disease/182\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d182\">PharmacotherapyDB v1.0</a>. These indications are included in the hetnet as <em>treats</em> edges and used to train the logistic regression model. Due to <a href=\"https://thinklab.com/discussion/edge-dropout-contamination-in-hetnet-edge-prediction/215\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d215\">edge dropout contamination</a> and <a href=\"https://thinklab.com/discussion/network-edge-prediction-how-to-deal-with-self-testing/194\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d194\">self-testing</a>, overfitting could potentially inflate performance on this set. Therefore, for the three remaining indication sets, we remove any observations that were positives in this set.</li><li><strong>DrugCentral</strong> — We discovered the <a href=\"https://github.com/olegursu/drugtarget\">DrugCentral database</a> after completing our <a href=\"https://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d95\">physician curation</a> for PharmacotherapyDB. This database <a href=\"https://thinklab.com/discussion/incorporating-drugcentral-data-in-our-network/186#3\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d186\">contained 210 additional indications</a>. While we haven't curated these indications yet, we observed a high proportion of disease modifying therapy.</li><li><strong>Clinical Trial</strong> — We <a href=\"https://thinklab.com/discussion/cataloging-drugdisease-therapies-in-the-clinicaltrialsgov-database/212#2\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d212\">compiled indications</a> that have been investigated by clinical trial from <a href=\"https://clinicaltrials.gov/\">ClinicalTrials.gov</a>. This set contains 5,594 indications.</li><li><strong>Symptomatic</strong> — 390 symptomatic indications from PharacotherapyDB. These edges are included in the hetnet as <em>palliates</em> edges.</li></ul>\r\n\r\n<h2>Visualizing performance</h2>\r\n\r\n<p><img src=\"https://github.com/dhimmel/learn/blob/master/prediction/figure/performance.png?raw=true\" alt=\"Predictions performance on four indication sets\"></p>\r\n\r\n<p>The above figure assesses how well our predictions prioritize four sets of indications. A) The y-axis labels denote the number of indications (+) and non-indications (−) composing each set. Violin plots with quartile lines show the distribution of indications when compound–disease pairs are ordered by their prediction. In all four cases, the actual indications were ranked highly by our predictions. B) ROC Curves with AUROCs in the legend. C) Precision–Recall Curves with AUPRCs in the legend.</p>\r\n\r\n<p>A variant of Panel A above designed to be more familiar to the biologist shows where the positives lie:</p>\r\n\r\n<p><img src=\"https://github.com/dhimmel/learn/blob/e9a9a1db762dc59263eb7884a55c55e26d1d19b1/prediction/figure/performance-gel.png?raw=true\" alt=\"Predictions performance on four indication sets\"></p>",
      "body_md": "# Assessing prediction performance\r\n\r\nWe've assembled four sets of indications to assess our predictions on:\r\n\r\n+ **Disease Modifying** -- the 755 disease modifying treatments in [PharmacotherapyDB v1.0](https://thinklab.com/discussion/announcing-pharmacotherapydb-the-open-catalog-of-drug-therapies-for-disease/182). These indications are included in the hetnet as _treats_ edges and used to train the logistic regression model. Due to [edge dropout contamination](https://thinklab.com/discussion/edge-dropout-contamination-in-hetnet-edge-prediction/215) and [self-testing](https://thinklab.com/discussion/network-edge-prediction-how-to-deal-with-self-testing/194), overfitting could potentially inflate performance on this set. Therefore, for the three remaining indication sets, we remove any observations that were positives in this set.\r\n+ **DrugCentral** -- We discovered the [DrugCentral database](https://github.com/olegursu/drugtarget) after completing our [physician curation](https://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95) for PharmacotherapyDB. This database [contained 210 additional indications](https://thinklab.com/discussion/incorporating-drugcentral-data-in-our-network/186#3). While we haven't curated these indications yet, we observed a high proportion of disease modifying therapy.\r\n+ **Clinical Trial** -- We [compiled indications](https://thinklab.com/discussion/cataloging-drugdisease-therapies-in-the-clinicaltrialsgov-database/212#2) that have been investigated by clinical trial from [ClinicalTrials.gov](https://clinicaltrials.gov/). This set contains 5,594 indications.\r\n+ **Symptomatic** -- 390 symptomatic indications from PharacotherapyDB. These edges are included in the hetnet as _palliates_ edges.\r\n\r\n## Visualizing performance\r\n\r\n![Predictions performance on four indication sets](https://github.com/dhimmel/learn/blob/master/prediction/figure/performance.png?raw=true)\r\n\r\nThe above figure assesses how well our predictions prioritize four sets of indications. A) The y-axis labels denote the number of indications (+) and non-indications (−) composing each set. Violin plots with quartile lines show the distribution of indications when compound–disease pairs are ordered by their prediction. In all four cases, the actual indications were ranked highly by our predictions. B) ROC Curves with AUROCs in the legend. C) Precision–Recall Curves with AUPRCs in the legend.\r\n\r\nA variant of Panel A above designed to be more familiar to the biologist shows where the positives lie:\r\n\r\n![Predictions performance on four indication sets](https://github.com/dhimmel/learn/blob/e9a9a1db762dc59263eb7884a55c55e26d1d19b1/prediction/figure/performance-gel.png?raw=true)",
      "comment_id": 1319,
      "profile_id": 17,
      "published": "2016-05-17T21:48:48.143975Z",
      "thread_id": 203,
      "url": "/discussion/predictions-of-whether-a-compound-treats-a-disease/203#2"
    },
    {
      "body_html": "<p>One month ago, I asked a <a href=\"http://stackoverflow.com/q/37370820/4651668\">Stack Overflow question</a> on how to host a public (read only) Neo4j instance in the cloud. Now, our Neo4j instance is up and running, serving Hetionet over the World Wide Web at <strong><a href=\"https://neo4j.het.io\" title=\"Hetionet Neo4j Browser\">neo4j.het.io</a></strong>. Below is a screenshot of what the Neo4j Browser looks like:</p>\r\n\r\n<p><img src=\"https://cloud.githubusercontent.com/assets/1117703/16320501/216f2626-3966-11e6-8a0d-215f70b44be2.png\" alt=\"neo4j-browser\"></p>\r\n\r\n<p>The public browser let's anyone immediately interact with Hetionet. Since most potential users may not know the Cypher query language, we created a guide to help bring users up to speed. In addition to accessing Hetionet through the Neo4j Browser, users can programmatically query the Neo4j server using one of the <a href=\"https://neo4j.com/developer/language-guides/\" title=\"Neo4j Language Guides\">many supported languages</a>.</p>\r\n\r\n<h2>Technical details</h2>\r\n\r\n<p>Creating a public Hetionet instance using Neo4j was gratifying because it reinforced the benefits of migrating our hetnet infrastructure to Neo4j <span class=\"citation\">[<a href=\"/discussion/using-the-neo4j-graph-database-for-hetnets/112\" class=\"citation\" data-key=\"10.15363/thinklab.d112\">1</a>]</span>. We're promptly leveraging advanced Neo4j capabilities that would have been impractical to develop in house. In fact, we really pushed Neo4j to its limits and submitted several help/feature requests and bug reports. Many of the features we're using just became available in Neo4j 3.0 released on April 26, 2016. Currently, our server runs Neo4j 3.0.2.</p>\r\n\r\n<p>Many of the issues we faced had to do with Neo4j Browser Guides. We use guides to provide documentation, examples, and explanations from within the Neo4j Browser. For example, in the screenshot above, the \"Hetionet in Neo4j\" frame is a guide. We wrote our guides in asciidoc and converted them to HTML <a href=\"https://github.com/dhimmel/het.io-rep-guides\">using <code>jexp/neo4j-guides</code></a>.</p>\r\n\r\n<p>Hosting the HTML guides in a way that the Neo4j Browser could access was difficult. We ran into <a href=\"https://github.com/neo4j/neo4j-browser/issues/170\" title=\"neo4j/neo4j-browser Issue on GitHub: Playing guides from URL fails despite CORS being enabled\">CORS issues</a> but were eventually able to use the <a href=\"https://github.com/jexp/neo4j-guides/tree/master/guide-extension\"><code>guide-extension</code></a> to serve files from within the Neo4j instance (see issues <a href=\"https://github.com/jexp/neo4j-guides/issues/2\">a</a>, <a href=\"https://github.com/jexp/neo4j-guides/issues/4\">b</a>, <a href=\"https://github.com/jexp/neo4j-guides/issues/5\">c</a>) and circumvent the CORS problems.</p>\r\n\r\n<p>We also made several tweaks to make our Neo4j server appropriate for public access. We disabled authentication, set a <a href=\"http://stackoverflow.com/a/37425223/4651668\">query execution timeout</a>, created a <a href=\"http://stackoverflow.com/questions/37446895/configuring-a-neo4j-instance-to-use-a-default-grass-style\">GRASS style</a>, and enabled <a href=\"http://stackoverflow.com/a/38056689/4651668\">web analytics</a>. As far as I'm aware, there are not many other groups hosting public Neo4j instances. I did draw inspiration from <a href=\"https://github.com/ryguyrg/panama-neo4j\"><code>ryguyrg/panama-neo4j</code></a> which makes it easy for users to create a Neo4j server containing the <a href=\"https://neo4j.com/blog/analyzing-panama-papers-neo4j/\">Panama Papers Hetnet</a>. However, users still have to host the server locally. Despite being uncommon, there shouldn't be any licensing issues with hosting a public server <span class=\"citation\">[<a href=\"/discussion/licensing-neo4j/130\" class=\"citation\" data-key=\"10.15363/thinklab.d130\">2</a>]</span>.</p>\r\n\r\n<p><a href=\"https://github.com/jexp\">Michael Hunger</a>, <a href=\"https://github.com/oskarhane\">Oskar Hane</a>, <a href=\"https://github.com/ikwattro\">Christophe Willemsen</a>, and <a href=\"https://stackoverflow.com/users/4989460/stdob\">stdob</a> were super helpful — thanks! During the process we suggested several enhancements including <a href=\"https://github.com/neo4j/neo4j-browser/issues/172\">multiple post-connect commands</a>, <a href=\"https://github.com/neo4j/neo4j-browser/issues/181\">setting AUTO-COMPLETE to OFF by default</a>, <a href=\"https://github.com/neo4j/neo4j-browser/issues/184\">play-topic support for URLs with capitalized characters</a>, and <a href=\"https://github.com/jexp/neo4j-guides/issues/9\">relative path support for playing guides</a>.</p>\r\n\r\n<h3>Cloud hosting</h3>\r\n\r\n<p>We used <a href=\"https://www.digitalocean.com/\">DigitalOcean</a> for our cloud hosting. They have a Ubuntu 14.04 Droplet with Docker 1.11.1 preconfigured, which reduced setup to a minimum. We went with a 2 GB Memory / 40 GB Disk Droplet that costs $20 a month and is located in a datacenter near New York City. DigitalOcean compared favorably to AWS in terms of price–performance ratio and user interface.</p>\r\n\r\n<h3>HTTPS</h3>\r\n\r\n<p>I added HTTPS/TLS support using <a href=\"https://letsencrypt.org/\">Let's Encrypt</a>, which <a href=\"/u/alizee\" class=\"username\">@alizee</a> previously recommended <span class=\"citation\">[<a href=\"/discussion/support-and-enforce-ssl-connections-to-thinklab/197\" class=\"citation\" data-key=\"10.15363/thinklab.d197\">3</a>]</span>. The <code>certbot</code> python package made obtaining the certificates easier than I expected (<a href=\"https://github.com/dhimmel/hetionet/blob/1ee2479b2d98de331dedce600ce08fca43d3395b/hetnet/neo4j/docker/ssl/install.sh\">code</a>). The one potential downside to Let's Encrypt is that I had to schedule a <code>cron</code> job to shutdown the Neo4j server and attempt certificate renewal on a weekly basis. This will result in short service outages. One advantage of enabling encryption is that users do not have to accept a self-signed certificate to use Bolt from within the Neo4j Browser. Bolt is the <a href=\"https://neo4j.com/blog/neo4j-3-0-massive-scale-developer-productivity/\">new binary protocol</a> to enable more efficient communication with the Neo4j server.</p>\r\n\r\n<h3>Docker</h3>\r\n\r\n<p>We created a Docker image (<a href=\"https://hub.docker.com/r/dhimmel/hetionet/\" title=\"dhimmel/hetionet on Docker Hub\"><code>dhimmel/hetionet</code></a>) for running the Hetionet Neo4j server. Our docker extends the <a href=\"https://hub.docker.com/_/neo4j/\">official Neo4j docker</a> and automatically downloads and configures the Hetionet database and guides. In addition to making deployment automatable and reliable, Docker promises to improve the reproducibility of computation <span class=\"citation\">[<a href=\"https://doi.org/10.1101/056473\" class=\"citation\" data-key=\"10.1101/056473\">4</a>, <a href=\"https://doi.org/10.1186/s13742-015-0087-0\" class=\"citation\" data-key=\"10.1186/s13742-015-0087-0\">5</a>, <a href=\"https://doi.org/10.1145/2723872.2723882\" class=\"citation\" data-key=\"10.1145/2723872.2723882\">6</a>, <a href=\"https://doi.org/10.7717/peerj.1273\" class=\"citation\" data-key=\"10.7717/peerj.1273\">7</a>]</span>.</p>\r\n\r\n<h2>Suggestions</h2>\r\n\r\n<p>If you have suggestions on how to improve our Neo4j Browser or questions on how to use it, please don't by shy.</p>",
      "body_md": "One month ago, I asked a [Stack Overflow question](http://stackoverflow.com/q/37370820/4651668) on how to host a public (read only) Neo4j instance in the cloud. Now, our Neo4j instance is up and running, serving Hetionet over the World Wide Web at **[neo4j.het.io](https://neo4j.het.io \"Hetionet Neo4j Browser\")**. Below is a screenshot of what the Neo4j Browser looks like:\r\n\r\n![neo4j-browser](https://cloud.githubusercontent.com/assets/1117703/16320501/216f2626-3966-11e6-8a0d-215f70b44be2.png)\r\n\r\nThe public browser let's anyone immediately interact with Hetionet. Since most potential users may not know the Cypher query language, we created a guide to help bring users up to speed. In addition to accessing Hetionet through the Neo4j Browser, users can programmatically query the Neo4j server using one of the [many supported languages](https://neo4j.com/developer/language-guides/ \"Neo4j Language Guides\").\r\n\r\n## Technical details\r\n\r\nCreating a public Hetionet instance using Neo4j was gratifying because it reinforced the benefits of migrating our hetnet infrastructure to Neo4j [@10.15363/thinklab.d112]. We're promptly leveraging advanced Neo4j capabilities that would have been impractical to develop in house. In fact, we really pushed Neo4j to its limits and submitted several help/feature requests and bug reports. Many of the features we're using just became available in Neo4j 3.0 released on April 26, 2016. Currently, our server runs Neo4j 3.0.2.\r\n\r\nMany of the issues we faced had to do with Neo4j Browser Guides. We use guides to provide documentation, examples, and explanations from within the Neo4j Browser. For example, in the screenshot above, the \"Hetionet in Neo4j\" frame is a guide. We wrote our guides in asciidoc and converted them to HTML [using `jexp/neo4j-guides`](https://github.com/dhimmel/het.io-rep-guides).\r\n\r\nHosting the HTML guides in a way that the Neo4j Browser could access was difficult. We ran into [CORS issues](https://github.com/neo4j/neo4j-browser/issues/170 \"neo4j/neo4j-browser Issue on GitHub: Playing guides from URL fails despite CORS being enabled\") but were eventually able to use the [`guide-extension`](https://github.com/jexp/neo4j-guides/tree/master/guide-extension) to serve files from within the Neo4j instance (see issues [a](https://github.com/jexp/neo4j-guides/issues/2), [b](https://github.com/jexp/neo4j-guides/issues/4), [c](https://github.com/jexp/neo4j-guides/issues/5)) and circumvent the CORS problems.\r\n\r\nWe also made several tweaks to make our Neo4j server appropriate for public access. We disabled authentication, set a [query execution timeout](http://stackoverflow.com/a/37425223/4651668), created a [GRASS style](http://stackoverflow.com/questions/37446895/configuring-a-neo4j-instance-to-use-a-default-grass-style), and enabled [web analytics](http://stackoverflow.com/a/38056689/4651668). As far as I'm aware, there are not many other groups hosting public Neo4j instances. I did draw inspiration from [`ryguyrg/panama-neo4j`](https://github.com/ryguyrg/panama-neo4j) which makes it easy for users to create a Neo4j server containing the [Panama Papers Hetnet](https://neo4j.com/blog/analyzing-panama-papers-neo4j/). However, users still have to host the server locally. Despite being uncommon, there shouldn't be any licensing issues with hosting a public server [@10.15363/thinklab.d130].\r\n\r\n[Michael Hunger](https://github.com/jexp), [Oskar Hane](https://github.com/oskarhane), [Christophe Willemsen](https://github.com/ikwattro), and [stdob](https://stackoverflow.com/users/4989460/stdob) were super helpful -- thanks! During the process we suggested several enhancements including [multiple post-connect commands](https://github.com/neo4j/neo4j-browser/issues/172), [setting AUTO-COMPLETE to OFF by default](https://github.com/neo4j/neo4j-browser/issues/181), [play-topic support for URLs with capitalized characters](https://github.com/neo4j/neo4j-browser/issues/184), and [relative path support for playing guides](https://github.com/jexp/neo4j-guides/issues/9).\r\n\r\n### Cloud hosting\r\n\r\nWe used [DigitalOcean](https://www.digitalocean.com/) for our cloud hosting. They have a Ubuntu 14.04 Droplet with Docker 1.11.1 preconfigured, which reduced setup to a minimum. We went with a 2 GB Memory / 40 GB Disk Droplet that costs $20 a month and is located in a datacenter near New York City. DigitalOcean compared favorably to AWS in terms of price–performance ratio and user interface.\r\n\r\n### HTTPS\r\n\r\nI added HTTPS/TLS support using [Let's Encrypt](https://letsencrypt.org/), which @alizee previously recommended [@10.15363/thinklab.d197]. The `certbot` python package made obtaining the certificates easier than I expected ([code](https://github.com/dhimmel/hetionet/blob/1ee2479b2d98de331dedce600ce08fca43d3395b/hetnet/neo4j/docker/ssl/install.sh)). The one potential downside to Let's Encrypt is that I had to schedule a `cron` job to shutdown the Neo4j server and attempt certificate renewal on a weekly basis. This will result in short service outages. One advantage of enabling encryption is that users do not have to accept a self-signed certificate to use Bolt from within the Neo4j Browser. Bolt is the [new binary protocol](https://neo4j.com/blog/neo4j-3-0-massive-scale-developer-productivity/) to enable more efficient communication with the Neo4j server.\r\n\r\n### Docker\r\n\r\nWe created a Docker image ([`dhimmel/hetionet`](https://hub.docker.com/r/dhimmel/hetionet/ \"dhimmel/hetionet on Docker Hub\")) for running the Hetionet Neo4j server. Our docker extends the [official Neo4j docker](https://hub.docker.com/_/neo4j/) and automatically downloads and configures the Hetionet database and guides. In addition to making deployment automatable and reliable, Docker promises to improve the reproducibility of computation [@10.1101/056473 @10.1186/s13742-015-0087-0 @10.1145/2723872.2723882 @10.7717/peerj.1273].\r\n\r\n## Suggestions\r\n\r\nIf you have suggestions on how to improve our Neo4j Browser or questions on how to use it, please don't by shy.",
      "comment_id": 1320,
      "profile_id": 17,
      "published": "2016-06-23T23:20:21.127421Z",
      "thread_id": 216,
      "url": "/discussion/hosting-hetionet-in-the-cloud-creating-a-public-neo4j-instance/216"
    },
    {
      "body_html": "<p>Hi Everyone,</p>\r\n\r\n<p>We've done a bunch of work on improving DrugBank's terms of use, license, and privacy policy. It's taken us a little longer to release than we had hoped, but has now been released as version 5.0.0 (http://www.drugbank.ca/releases/latest).</p>\r\n\r\n<p>If you click on Downloads the first thing you will notice is that you aren't hit with a login screen. Here are some of the additional steps we've taken:</p>\r\n\r\n<ol><li><p>The licensing is now more clear, the downloads that require an account to access are all released under a straightforward Creative Common’s Attribution-NonCommercial 4.0 International License. The blurb you now agree to when signing up makes this clear (see <a href=\"http://drugbank.ca/public_users/sign_up\">http://drugbank.ca/public_users/sign_up</a>). The blurb is now just there to provide a bit of extra context and disclaimers to warn against using DrugBank data as medical advice, as well as providing a better definition of what 'Non-commercial' means.</p></li><li><p>We have created a new 'Open Data' tab. The data here is released under a Creative Common’s CC0 International License, which is public domain. We have 2 datasets here and are working on more. 1) The DrugBank vocabulary which includes DrugBank IDs, names, UNIIs, CAS, InChI Key; 2) all DrugBank structures in SDF format. You do not have to create an account to download this data. We plan on adding more open datasets soon and on a regular basis.</p></li><li><p>Our terms of use have been updated to make it clear that the data on the DrugBank website can be freely copied and shared (in publications, presentations, documents, etc.)</p></li><li><p>Additionally the requirement for users being 18 or older has been changed to permit younger users (with parental consent). However, users are still required to be 13 or older.</p></li><li><p>We have tried to improve our definitions for 'Commercial Use' - we are expanding our FAQ to include more questions people might have about this. We will probably setup a dedicated page with different use cases very soon.</p></li></ol>\r\n\r\n<p>I hope this addresses everyone's concerns. We have a few more datasets that we will be putting in the Open Data section very soon, and hope to continue to push new datasets there regularly. Thanks for your patience and input (especially Daniel and Egon!). If you have any more questions or issues please don't hesitate to comment on here or email me directly at <a href=\"mailto:craig@omx.io\">craig@omx.io</a>.</p>\r\n\r\n<p>Thanks,<br>Craig, Mike, and the rest of the OMx/DrugBank team</p>",
      "body_md": "Hi Everyone,\r\n\r\nWe've done a bunch of work on improving DrugBank's terms of use, license, and privacy policy. It's taken us a little longer to release than we had hoped, but has now been released as version 5.0.0 (http://www.drugbank.ca/releases/latest).\r\n\r\nIf you click on Downloads the first thing you will notice is that you aren't hit with a login screen. Here are some of the additional steps we've taken:\r\n\r\n1. The licensing is now more clear, the downloads that require an account to access are all released under a straightforward Creative Common’s Attribution-NonCommercial 4.0 International License. The blurb you now agree to when signing up makes this clear (see http://drugbank.ca/public_users/sign_up). The blurb is now just there to provide a bit of extra context and disclaimers to warn against using DrugBank data as medical advice, as well as providing a better definition of what 'Non-commercial' means.\r\n\r\n2. We have created a new 'Open Data' tab. The data here is released under a Creative Common’s CC0 International License, which is public domain. We have 2 datasets here and are working on more. 1) The DrugBank vocabulary which includes DrugBank IDs, names, UNIIs, CAS, InChI Key; 2) all DrugBank structures in SDF format. You do not have to create an account to download this data. We plan on adding more open datasets soon and on a regular basis.\r\n\r\n3. Our terms of use have been updated to make it clear that the data on the DrugBank website can be freely copied and shared (in publications, presentations, documents, etc.)\r\n\r\n4. Additionally the requirement for users being 18 or older has been changed to permit younger users (with parental consent). However, users are still required to be 13 or older.\r\n\r\n5. We have tried to improve our definitions for 'Commercial Use' - we are expanding our FAQ to include more questions people might have about this. We will probably setup a dedicated page with different use cases very soon.\r\n\r\nI hope this addresses everyone's concerns. We have a few more datasets that we will be putting in the Open Data section very soon, and hope to continue to push new datasets there regularly. Thanks for your patience and input (especially Daniel and Egon!). If you have any more questions or issues please don't hesitate to comment on here or email me directly at craig@omx.io.\r\n\r\nThanks,\r\nCraig, Mike, and the rest of the OMx/DrugBank team",
      "comment_id": 1324,
      "profile_id": 241,
      "published": "2016-06-21T20:49:20.454745Z",
      "thread_id": 213,
      "url": "/discussion/sounding-the-alarm-on-drugbanks-new-license-and-terms-of-use/213#10"
    },
    {
      "body_html": "<h1>Announcing Prediction Browsing and Visualization</h1>\r\n\r\n<p>The Project Rephetio Browser is live at <a href=\"http://het.io/repurpose/\"><strong>het.io/repurpose</strong></a> letting you browse 209,168 drug repurposing predictions. Users can navigate by compound or by disease. Each prediction can be investigated in the Hetionet Browser — a read only Neo4j database available at <a href=\"https://neo4j.het.io/browser/\">neo4j.het.io</a> that we <a href=\"https://thinklab.com/discussion/hosting-hetionet-in-the-cloud-creating-a-public-neo4j-instance/216\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d216\">just released</a>.</p>\r\n\r\n<p>For each prediction, we created a guide for the Neo4j Browser to provide additional information. Details include a query to visualize the top ten <a href=\"https://thinklab.com/discussion/decomposing-predictions-into-their-network-support/229#2\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d229\">paths contributing</a> to a prediction as well as links to clinical trials investigating a compound–disease pair.</p>\r\n\r\n<h2>Seeking feedback</h2>\r\n\r\n<p>We'd love to hear what people think about our predictions. Are they reasonable? Are they interesting? Where do we do well? Where do we do poorly?</p>\r\n\r\n<p>We're especially interested in a few examples that showcase our approach. So please share any compound–disease pairs where our approach did a good job capturing the relevant pharmacology and disease pathophysiology.</p>\r\n\r\n<p>Paging our contributors with clinical or pharmacological expertise: <a href=\"/u/pouyakhankhanian\" class=\"username\">@pouyakhankhanian</a> <a href=\"/u/chrissyhessler\" class=\"username\">@chrissyhessler</a> <a href=\"/u/TIOprea\" class=\"username\">@TIOprea</a> <a href=\"/u/cknoxrun\" class=\"username\">@cknoxrun</a> <a href=\"/u/mkgilson\" class=\"username\">@mkgilson</a> <a href=\"/u/alexanderpico\" class=\"username\">@alexanderpico</a> <a href=\"/u/allisonmccoy\" class=\"username\">@allisonmccoy</a> <a href=\"/u/ritukhare\" class=\"username\">@ritukhare</a>. All feedback is welcome!</p>",
      "body_md": "# Announcing Prediction Browsing and Visualization\r\n\r\nThe Project Rephetio Browser is live at [**het.io/repurpose**](http://het.io/repurpose/) letting you browse 209,168 drug repurposing predictions. Users can navigate by compound or by disease. Each prediction can be investigated in the Hetionet Browser -- a read only Neo4j database available at [neo4j.het.io](https://neo4j.het.io/browser/) that we [just released](https://thinklab.com/discussion/hosting-hetionet-in-the-cloud-creating-a-public-neo4j-instance/216).\r\n\r\nFor each prediction, we created a guide for the Neo4j Browser to provide additional information. Details include a query to visualize the top ten [paths contributing](https://thinklab.com/discussion/decomposing-predictions-into-their-network-support/229#2) to a prediction as well as links to clinical trials investigating a compound--disease pair.\r\n\r\n## Seeking feedback\r\n\r\nWe'd love to hear what people think about our predictions. Are they reasonable? Are they interesting? Where do we do well? Where do we do poorly?\r\n\r\nWe're especially interested in a few examples that showcase our approach. So please share any compound--disease pairs where our approach did a good job capturing the relevant pharmacology and disease pathophysiology.\r\n\r\nPaging our contributors with clinical or pharmacological expertise: @pouyakhankhanian @chrissyhessler @TIOprea @cknoxrun @mkgilson @alexanderpico @allisonmccoy @ritukhare. All feedback is welcome!",
      "comment_id": 1325,
      "profile_id": 17,
      "published": "2016-06-23T23:59:22.582723Z",
      "thread_id": 203,
      "url": "/discussion/predictions-of-whether-a-compound-treats-a-disease/203#3"
    },
    {
      "body_html": "<h1>Closing remarks</h1>\r\n\r\n<p>Thanks Craig, Mike, and the rest of the OMx/DrugBank team. I really appreciate your commendable communication, dedication to your userbase, and expediency addressing these issues. You've set a high bar for other resources to strive towards. While the overall process took 44 days, the changes were substantial, and it sounds like University approval took a large chunk of the time. In other words, when dealing with major licensing changes, I expect very few prominent resources will deliver in under 44 days.</p>\r\n\r\n<p>I am particularly excited about the CC0 subset that includes basic drug information. From an adoption and marketing standpoint, I think this makes sense. For someone who wants to use DrugBank identifiers and not worry about licensing, the change is huge. I'm hopeful that DrugBank taking this major step will motivate other biodata resources (even CC BY ones) to release essential components under CC0.</p>\r\n\r\n<p>Also I'm glad you removed the share-alike stipulation. Our experience suggests that license compatibility is a major obstacle to data integration <span class=\"citation\">[<a href=\"/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107\" class=\"citation\" data-key=\"10.15363/thinklab.d107\">1</a>]</span>. Hence, applying share alike should be subject to strict scrutiny.</p>\r\n\r\n<p>The new licensing arrangement does a good job of balancing free public usage and commercial revenue generation. While for some applications, we may avoid using data with a non-commercial stipulation, it's nice to have the option of NC usage.</p>",
      "body_md": "# Closing remarks\r\n\r\nThanks Craig, Mike, and the rest of the OMx/DrugBank team. I really appreciate your commendable communication, dedication to your userbase, and expediency addressing these issues. You've set a high bar for other resources to strive towards. While the overall process took 44 days, the changes were substantial, and it sounds like University approval took a large chunk of the time. In other words, when dealing with major licensing changes, I expect very few prominent resources will deliver in under 44 days.\r\n\r\nI am particularly excited about the CC0 subset that includes basic drug information. From an adoption and marketing standpoint, I think this makes sense. For someone who wants to use DrugBank identifiers and not worry about licensing, the change is huge. I'm hopeful that DrugBank taking this major step will motivate other biodata resources (even CC BY ones) to release essential components under CC0.\r\n\r\nAlso I'm glad you removed the share-alike stipulation. Our experience suggests that license compatibility is a major obstacle to data integration [@10.15363/thinklab.d107]. Hence, applying share alike should be subject to strict scrutiny.\r\n\r\nThe new licensing arrangement does a good job of balancing free public usage and commercial revenue generation. While for some applications, we may avoid using data with a non-commercial stipulation, it's nice to have the option of NC usage.",
      "comment_id": 1326,
      "profile_id": 17,
      "published": "2016-06-24T16:50:52.603123Z",
      "thread_id": 213,
      "url": "/discussion/sounding-the-alarm-on-drugbanks-new-license-and-terms-of-use/213#11"
    },
    {
      "body_html": "<p>Great work! I have just started familiarizing myself with this database so I apologize if I misunderstand the terminology. </p>\r\n\r\n<p>I notice that in migraine, amitriptyline does not have a high predicted probability of treating migraine (0.013).  Yet this is a medication often used for migraine, similar to nortriptyline, which scores higher (0.086).</p>\r\n\r\n<p> Am I understanding this correctly? If so, why does amitriptyline not score highly?</p>",
      "body_md": "Great work! I have just started familiarizing myself with this database so I apologize if I misunderstand the terminology. \r\n\r\nI notice that in migraine, amitriptyline does not have a high predicted probability of treating migraine (0.013).  Yet this is a medication often used for migraine, similar to nortriptyline, which scores higher (0.086).\r\n\r\n Am I understanding this correctly? If so, why does amitriptyline not score highly?",
      "comment_id": 1327,
      "profile_id": 172,
      "published": "2016-06-24T17:23:18.354058Z",
      "thread_id": 203,
      "url": "/discussion/predictions-of-whether-a-compound-treats-a-disease/203#4"
    },
    {
      "body_html": "<p>A small point- i think we should use the term \"epilepsy\" rather than \"epilepsy syndrome\"- the word syndrome implies that the epilepsy is part of a constellation of associated features. Perhaps Ari and Pouya can weigh in. </p>",
      "body_md": "A small point- i think we should use the term \"epilepsy\" rather than \"epilepsy syndrome\"- the word syndrome implies that the epilepsy is part of a constellation of associated features. Perhaps Ari and Pouya can weigh in.",
      "comment_id": 1328,
      "profile_id": 172,
      "published": "2016-06-24T17:37:55.436453Z",
      "thread_id": 203,
      "url": "/discussion/predictions-of-whether-a-compound-treats-a-disease/203#5"
    },
    {
      "body_html": "<blockquote><p>I think we should use the term \"epilepsy\" rather than \"epilepsy syndrome\"</p></blockquote>\r\n\r\n<p>We rely on the <a href=\"http://disease-ontology.org/\">Disease Ontology</a> for coding diseases <span class=\"citation\">[<a href=\"/discussion/unifying-disease-vocabularies/44\" class=\"citation\" data-key=\"10.15363/thinklab.d44\">1</a>, <a href=\"https://doi.org/10.1093/nar/gku1011\" class=\"citation\" data-key=\"10.1093/nar/gku1011\">2</a>]</span>. I'm hesitant to deviate from the Disease Ontology names because it adds an extra layer of complexity and upkeep. Instead, I relayed your request to the <a href=\"https://github.com/DiseaseOntology/HumanDiseaseOntology/issues/159\" title=\"DiseaseOntology/HumanDiseaseOntology#159 on GitHub: Renaming epilepsy syndrome to epilepsy\">DO Issue Tracker</a>, as we've done in the past <span class=\"citation\">[<a href=\"/discussion/disease-ontology-feature-requests/68\" class=\"citation\" data-key=\"10.15363/thinklab.d68\">3</a>]</span>.</p>\r\n\r\n<p>Presently, we also have issues with some compound names that are ALL CAPS due to upstream issues in DrugBank. If many people feel strongly about these names, I'll reconsider fixing them on our end.</p>",
      "body_md": "> I think we should use the term \"epilepsy\" rather than \"epilepsy syndrome\"\r\n\r\nWe rely on the [Disease Ontology](http://disease-ontology.org/) for coding diseases [@10.15363/thinklab.d44 @10.1093/nar/gku1011]. I'm hesitant to deviate from the Disease Ontology names because it adds an extra layer of complexity and upkeep. Instead, I relayed your request to the [DO Issue Tracker](https://github.com/DiseaseOntology/HumanDiseaseOntology/issues/159 \"DiseaseOntology/HumanDiseaseOntology#159 on GitHub: Renaming epilepsy syndrome to epilepsy\"), as we've done in the past [@10.15363/thinklab.d68].\r\n\r\nPresently, we also have issues with some compound names that are ALL CAPS due to upstream issues in DrugBank. If many people feel strongly about these names, I'll reconsider fixing them on our end.",
      "comment_id": 1329,
      "profile_id": 17,
      "published": "2016-06-24T18:52:02.049295Z",
      "thread_id": 203,
      "url": "/discussion/predictions-of-whether-a-compound-treats-a-disease/203#6"
    },
    {
      "body_html": "<h1>Amitriptyline versus nortriptyline for treating migraine</h1>\r\n\r\n<blockquote><p>I notice that in migraine, amitriptyline does not have a high predicted probability of treating migraine (0.013). Yet this is a medication often used for migraine, similar to nortriptyline, which scores higher (0.086).</p></blockquote>\r\n\r\n<p><a href=\"/u/chrissyhessler\" class=\"username\">@chrissyhessler</a>, great question regarding our <a href=\"http://het.io/repurpose/browse.html?id=DOID_6364\" title=\"Browse Project Rephetio predictions for migraine\">migraine predictions</a>.</p>\r\n\r\n<h2>Amitriptyline</h2>\r\n\r\n<p>We can use the Neo4j Browser to investigate the amitriptyline–migraine prediction (<a href=\"https://neo4j.het.io/browser/?cmd=play&amp;arg=https://neo4j.het.io/guides/rep/DB00321/DOID_6364.html\">follow this link</a> and press the play button). I've copied the first paragraph of the guide:</p>\r\n\r\n<blockquote><p>Project Rephetio predicted a <strong>probability of 1.390%</strong> that Amitriptyline (<a href=\"http://www.drugbank.ca/drugs/DB00321\"><code>DB00321</code></a>) treats migraine (<a href=\"http://www.disease-ontology.org/?id=DOID:6364\"><code>DOID:6364</code></a>). This probability represents a 2.85-fold enrichment over the background prevalence of treatment. This prediction is in the 97.8th percentile for Amitriptyline and the 93.9th percentile for migraine.</p></blockquote>\r\n\r\n<p>So one thing to note is that while the probability is low, amitriptyline comparatively scores highly. Our algorithm bases its probabilities around a positive prevalence of 0.36%, since there are 755 known treatments out of 209,168 possible compound–disease pairs. Therefore, while 1.39% sounds low, it's actually a 2.85-fold enrichment. Now let's look into the top 10 paths supporting that amitriptyline treats migraine (by executing the Cypher query in the guide):</p>\r\n\r\n<p><img src=\"https://cloud.githubusercontent.com/assets/1117703/16347762/6f9e5c7a-3a1c-11e6-8f3d-4d8abf81e2c0.png\" alt=\"Does Amitriptyline treat migraine?\"></p>\r\n\r\n<p>Amitriptyline–migraine is actually a cool example because it's not overwhelmingly supported by a single path. The 10th most influential path above (<em>amitriptyline–binds–HTR1A–associates–migraine</em>) still provides 3.53% of the total support (as shown in the second slide of the guide). <br>29.7% of the support is due to <em>CpDpCtD</em> paths (as shown in the third slide), which means amitriptyline palliates the same diseases as compounds that treat migraine. 29.0% of the support is due to <em>CbGaD</em> paths: amitriptyline binds to migraine-associated proteins. 16.7% of support is due to <em>CbGbCtD</em> paths: amitriptyline binds to similar proteins as compounds that treat migraine. 9.1% of support is due to <em>CrCrCtD</em> paths: amitriptyline is chemically similar to a compound that is chemical similar to a migraine treatment. The list goes on with support due to pathways (<em>CbGpPWpGaD</em>), side effects (<em>CcSEcCtD</em>), and tissue specificity (<em>CbGeAlD</em>).</p>\r\n\r\n<h2>Nortriptyline</h2>\r\n\r\n<p>If you already have the Neo4j Browser open, you can play the nortriptyline–migraine guide by running <code>:play https://neo4j.het.io/guides/rep/DB00540/DOID_6364.html</code>. The overview and 10 most supportive paths are copied below:</p>\r\n\r\n<blockquote><p>Project Rephetio predicted a <strong>probability of 8.615%</strong> that Nortriptyline (<a href=\"http://www.drugbank.ca/drugs/DB00540\"><code>DB00540</code></a>) treats migraine (<a href=\"http://www.disease-ontology.org/?id=DOID:6364\"><code>DOID:6364</code></a>). This probability represents a 22.86-fold enrichment over the background prevalence of treatment. This prediction is in the 100.0th percentile for Nortriptyline and the 99.4th percentile for migraine.</p></blockquote>\r\n\r\n<p><img src=\"https://cloud.githubusercontent.com/assets/1117703/16348316/c1a5ef12-3a1f-11e6-8d00-c44609f3e7fb.png\" alt=\"Does Nortriptyline treat migraine?\"></p>\r\n\r\n<p>Notice that many paths are the same for nortriptyline and amitriptyline. Both compounds target serotonin receptors that are associated with migraine. Both compounds share symptomatic uses that support their efficacy against migraine. Now the one major difference is the <em>nortriptyline–resembles–amitriptyline–treats–migraine</em> path, which provides 24.2% of the total support for the nortriptyline prediction.</p>\r\n\r\n<p>Why doesn't amitriptyline draw support from a <em>amitriptyline–resembles–nortriptyline–treats–migraine</em> path? <a href=\"https://thinklab.com/discussion/announcing-pharmacotherapydb-the-open-catalog-of-drug-therapies-for-disease/182\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d182\">PharmacotherapyDB</a> <strong>doesn't</strong> contain an indication between nortriptyline and migraine but <strong>does</strong> contain an indication between amitriptyline and migraine. While <a href=\"https://thinklab.com/discussion/path-exclusion-conditions/134#4\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d134\">we ignore</a> the amitriptyline–migraine treatment when extracting paths for the amitriptyline–migraine prediction, we do not ignore this treatment when extracting paths for the nortriptyline–migraine prediction.</p>\r\n\r\n<p>Hence, <a href=\"/u/chrissyhessler\" class=\"username\">@chrissyhessler</a> stumbled upon an interesting example of how missing knowledge in Hetionet combines with our machine learning approach to mediate predictions.</p>",
      "body_md": "# Amitriptyline versus nortriptyline for treating migraine\r\n\r\n> I notice that in migraine, amitriptyline does not have a high predicted probability of treating migraine (0.013). Yet this is a medication often used for migraine, similar to nortriptyline, which scores higher (0.086).\r\n\r\n@chrissyhessler, great question regarding our [migraine predictions](http://het.io/repurpose/browse.html?id=DOID_6364 \"Browse Project Rephetio predictions for migraine\").\r\n\r\n## Amitriptyline\r\n\r\nWe can use the Neo4j Browser to investigate the amitriptyline--migraine prediction ([follow this link](https://neo4j.het.io/browser/?cmd=play&arg=https://neo4j.het.io/guides/rep/DB00321/DOID_6364.html) and press the play button). I've copied the first paragraph of the guide:\r\n\r\n> Project Rephetio predicted a **probability of 1.390%** that Amitriptyline ([`DB00321`](http://www.drugbank.ca/drugs/DB00321)) treats migraine ([`DOID:6364`](http://www.disease-ontology.org/?id=DOID:6364)). This probability represents a 2.85-fold enrichment over the background prevalence of treatment. This prediction is in the 97.8th percentile for Amitriptyline and the 93.9th percentile for migraine.\r\n\r\nSo one thing to note is that while the probability is low, amitriptyline comparatively scores highly. Our algorithm bases its probabilities around a positive prevalence of 0.36%, since there are 755 known treatments out of 209,168 possible compound--disease pairs. Therefore, while 1.39% sounds low, it's actually a 2.85-fold enrichment. Now let's look into the top 10 paths supporting that amitriptyline treats migraine (by executing the Cypher query in the guide):\r\n\r\n![Does Amitriptyline treat migraine?](https://cloud.githubusercontent.com/assets/1117703/16347762/6f9e5c7a-3a1c-11e6-8f3d-4d8abf81e2c0.png)\r\n\r\nAmitriptyline--migraine is actually a cool example because it's not overwhelmingly supported by a single path. The 10th most influential path above (_amitriptyline--binds--HTR1A--associates--migraine_) still provides 3.53% of the total support (as shown in the second slide of the guide). \r\n29.7% of the support is due to _CpDpCtD_ paths (as shown in the third slide), which means amitriptyline palliates the same diseases as compounds that treat migraine. 29.0% of the support is due to _CbGaD_ paths: amitriptyline binds to migraine-associated proteins. 16.7% of support is due to _CbGbCtD_ paths: amitriptyline binds to similar proteins as compounds that treat migraine. 9.1% of support is due to _CrCrCtD_ paths: amitriptyline is chemically similar to a compound that is chemical similar to a migraine treatment. The list goes on with support due to pathways (_CbGpPWpGaD_), side effects (_CcSEcCtD_), and tissue specificity (_CbGeAlD_).\r\n\r\n## Nortriptyline\r\n\r\nIf you already have the Neo4j Browser open, you can play the nortriptyline--migraine guide by running `:play https://neo4j.het.io/guides/rep/DB00540/DOID_6364.html`. The overview and 10 most supportive paths are copied below:\r\n\r\n> Project Rephetio predicted a **probability of 8.615%** that Nortriptyline ([`DB00540`](http://www.drugbank.ca/drugs/DB00540)) treats migraine ([`DOID:6364`](http://www.disease-ontology.org/?id=DOID:6364)). This probability represents a 22.86-fold enrichment over the background prevalence of treatment. This prediction is in the 100.0th percentile for Nortriptyline and the 99.4th percentile for migraine.\r\n\r\n![Does Nortriptyline treat migraine?](https://cloud.githubusercontent.com/assets/1117703/16348316/c1a5ef12-3a1f-11e6-8d00-c44609f3e7fb.png)\r\n\r\nNotice that many paths are the same for nortriptyline and amitriptyline. Both compounds target serotonin receptors that are associated with migraine. Both compounds share symptomatic uses that support their efficacy against migraine. Now the one major difference is the _nortriptyline--resembles--amitriptyline--treats--migraine_ path, which provides 24.2% of the total support for the nortriptyline prediction.\r\n\r\nWhy doesn't amitriptyline draw support from a _amitriptyline--resembles--nortriptyline--treats--migraine_ path? [PharmacotherapyDB](https://thinklab.com/discussion/announcing-pharmacotherapydb-the-open-catalog-of-drug-therapies-for-disease/182) **doesn't** contain an indication between nortriptyline and migraine but **does** contain an indication between amitriptyline and migraine. While [we ignore](https://thinklab.com/discussion/path-exclusion-conditions/134#4) the amitriptyline--migraine treatment when extracting paths for the amitriptyline--migraine prediction, we do not ignore this treatment when extracting paths for the nortriptyline--migraine prediction.\r\n\r\nHence, @chrissyhessler stumbled upon an interesting example of how missing knowledge in Hetionet combines with our machine learning approach to mediate predictions.",
      "comment_id": 1330,
      "profile_id": 17,
      "published": "2016-06-24T20:35:03.139109Z",
      "thread_id": 203,
      "url": "/discussion/predictions-of-whether-a-compound-treats-a-disease/203#7"
    },
    {
      "body_html": "<p>Hetionet v1.0 is <a href=\"https://thinklab.com/discussion/hosting-hetionet-in-the-cloud-creating-a-public-neo4j-instance/216\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d216\">now available online</a> as a Neo4j database at <a href=\"https://neo4j.het.io\">https://neo4j.het.io</a>. While Project Rephetio is focusing primarily on drug repurposing, we'd like to illustrate the versatility of Hetionet for answering a broad range of biomedical questions. We want to exhibit that hetnets aren't vaporware. We want to exhibit that a dozen lines of Cypher code in Hetionet can immediately perform analyses that previously would have taken months to implement.</p>\r\n\r\n<p>If you're a biologist and have interesting questions that Hetionet may know about, ask away. If you think you have an interesting query, please share.</p>",
      "body_md": "Hetionet v1.0 is [now available online](https://thinklab.com/discussion/hosting-hetionet-in-the-cloud-creating-a-public-neo4j-instance/216) as a Neo4j database at https://neo4j.het.io. While Project Rephetio is focusing primarily on drug repurposing, we'd like to illustrate the versatility of Hetionet for answering a broad range of biomedical questions. We want to exhibit that hetnets aren't vaporware. We want to exhibit that a dozen lines of Cypher code in Hetionet can immediately perform analyses that previously would have taken months to implement.\r\n\r\nIf you're a biologist and have interesting questions that Hetionet may know about, ask away. If you think you have an interesting query, please share.",
      "comment_id": 1331,
      "profile_id": 17,
      "published": "2016-06-25T18:21:47.903005Z",
      "thread_id": 220,
      "url": "/discussion/exploring-the-power-of-hetionet-a-cypher-query-depot/220"
    },
    {
      "body_html": "<h1>GO Process enrichment for migraine genes</h1>\r\n\r\n<p>Here we'll show a query for identifying prominent GO Processes in a set of disease-associated genes. We'll use migraine as an example disease. First, we can see the 46 genes associated with migraine by querying <code>MATCH (:Disease {name: 'migraine'})-[rel:ASSOCIATES_DaG]-() RETURN rel</code>. Now we'll compute the DWPC (degree-weighted path count) between migraine and each GO Process. We'll restrict our results to processes with at least 5 participating genes (of which two or more are migraine-associated). Here's the Cypher:</p>\r\n\r\n<pre><code class=\"no-highlight hljs\">// Search for DaGpBP paths starting with migraine\r\nMATCH path = (n0:Disease)-[:ASSOCIATES_DaG]-(n1)-[:PARTICIPATES_GpBP]-(n2:BiologicalProcess)\r\nWHERE n0.name = 'migraine'\r\n// Implement the DWPC to adjust for node degree along paths\r\nWITH\r\n[\r\n  size((n0)-[:ASSOCIATES_DaG]-()),\r\n  size(()-[:ASSOCIATES_DaG]-(n1)),\r\n  size((n1)-[:PARTICIPATES_GpBP]-()),\r\n  size(()-[:PARTICIPATES_GpBP]-(n2))\r\n] AS degrees, path, n2\r\nWITH\r\n  // Return the GO Process ID and name\r\n  n2.identifier AS go_id,\r\n  n2.name AS go_name,\r\n  count(path) AS PC,\r\n  // Compute the DWPC\r\n  sum(reduce(pdp = 1.0, d in degrees| pdp * d ^ -0.4)) AS DWPC,\r\n  // Count the number of genes in the GO Process\r\n  size((n2)-[:PARTICIPATES_GpBP]-()) AS n_genes\r\n  WHERE n_genes &gt;= 5 AND PC &gt;= 2\r\nRETURN\r\n  go_id, go_name, PC, DWPC, n_genes\r\nORDER BY DWPC DESC\r\nLIMIT 5</code></pre>\r\n\r\n<p>The query took less than half of a second and performed 60,183 database hits. It returned the following top 5 GO Processes:</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>go_id</th><th>go_name</th><th>PC</th><th>DWPC</th><th>n_genes</th></tr></thead><tbody><tr><td>GO:0007210</td><td>serotonin receptor signaling pathway</td><td>8</td><td>0.061</td><td>18</td></tr><tr><td>GO:0050884</td><td>neuromuscular process controlling posture</td><td>2</td><td>0.048</td><td>15</td></tr><tr><td>GO:0042310</td><td>vasoconstriction</td><td>8</td><td>0.043</td><td>28</td></tr><tr><td>GO:0006812</td><td>cation transport</td><td>16</td><td>0.033</td><td>781</td></tr><tr><td>GO:0014821</td><td>phasic smooth muscle contraction</td><td>3</td><td>0.033</td><td>17</td></tr></tbody></table>\r\n\r\n<p>Next, we'll look bolster the query by adding protein interaction relationships.</p>",
      "body_md": "# GO Process enrichment for migraine genes\r\n\r\nHere we'll show a query for identifying prominent GO Processes in a set of disease-associated genes. We'll use migraine as an example disease. First, we can see the 46 genes associated with migraine by querying `MATCH (:Disease {name: 'migraine'})-[rel:ASSOCIATES_DaG]-() RETURN rel`. Now we'll compute the DWPC (degree-weighted path count) between migraine and each GO Process. We'll restrict our results to processes with at least 5 participating genes (of which two or more are migraine-associated). Here's the Cypher:\r\n \r\n```cypher\r\n// Search for DaGpBP paths starting with migraine\r\nMATCH path = (n0:Disease)-[:ASSOCIATES_DaG]-(n1)-[:PARTICIPATES_GpBP]-(n2:BiologicalProcess)\r\nWHERE n0.name = 'migraine'\r\n// Implement the DWPC to adjust for node degree along paths\r\nWITH\r\n[\r\n  size((n0)-[:ASSOCIATES_DaG]-()),\r\n  size(()-[:ASSOCIATES_DaG]-(n1)),\r\n  size((n1)-[:PARTICIPATES_GpBP]-()),\r\n  size(()-[:PARTICIPATES_GpBP]-(n2))\r\n] AS degrees, path, n2\r\nWITH\r\n  // Return the GO Process ID and name\r\n  n2.identifier AS go_id,\r\n  n2.name AS go_name,\r\n  count(path) AS PC,\r\n  // Compute the DWPC\r\n  sum(reduce(pdp = 1.0, d in degrees| pdp * d ^ -0.4)) AS DWPC,\r\n  // Count the number of genes in the GO Process\r\n  size((n2)-[:PARTICIPATES_GpBP]-()) AS n_genes\r\n  WHERE n_genes >= 5 AND PC >= 2\r\nRETURN\r\n  go_id, go_name, PC, DWPC, n_genes\r\nORDER BY DWPC DESC\r\nLIMIT 5\r\n```\r\n\r\nThe query took less than half of a second and performed 60,183 database hits. It returned the following top 5 GO Processes:\r\n\r\n| go_id | go_name | PC | DWPC | n_genes |\r\n|------------|-------------------------------------------|----|-------|---------|\r\n| GO:0007210 | serotonin receptor signaling pathway | 8 | 0.061 | 18 |\r\n| GO:0050884 | neuromuscular process controlling posture | 2 | 0.048 | 15 |\r\n| GO:0042310 | vasoconstriction | 8 | 0.043 | 28 |\r\n| GO:0006812 | cation transport | 16 | 0.033 | 781 |\r\n| GO:0014821 | phasic smooth muscle contraction | 3 | 0.033 | 17 |\r\n\r\nNext, we'll look bolster the query by adding protein interaction relationships.",
      "comment_id": 1332,
      "profile_id": 17,
      "published": "2016-06-25T19:09:02.506504Z",
      "thread_id": 220,
      "url": "/discussion/exploring-the-power-of-hetionet-a-cypher-query-depot/220#2"
    },
    {
      "body_html": "<h1>Tissue-specific interactomics: GO Process enrichment for multiple sclerosis</h1>\r\n\r\n<p>The following query performs a more advanced GO Process enrichment analysis for multiple sclerosis (MS) genes. First, we restrict to GWAS-associated genes, which have the advantage of being less biased by existing knowledge. Second, we add a protein interaction relationship to identify genes in the MS neighborhood of the interactome. However thirdly, we require that these genes are upregulated in an MS-affected tissue (anatomy). Therefore, we can hopefully capture some of the benefits of tissue-specific gene networks <span class=\"citation\">[<a href=\"https://doi.org/10.1038/ng.3259\" class=\"citation\" data-key=\"10.1038/ng.3259\">1</a>]</span> on our anatomy-agnostic interactome.</p>\r\n\r\n<pre><code class=\"no-highlight hljs\">MATCH path = (n0:Disease)-[e1:ASSOCIATES_DaG]-(n1)-[:INTERACTS_GiG]-(n2)-[:PARTICIPATES_GpBP]-(n3:BiologicalProcess)\r\nWHERE n0.name = 'multiple sclerosis'\r\n  AND 'GWAS Catalog' in e1.sources\r\n  AND exists((n0)-[:LOCALIZES_DlA]-()-[:UPREGULATES_AuG]-(n2))\r\nWITH\r\n[\r\n  size((n0)-[:ASSOCIATES_DaG]-()),\r\n  size(()-[:ASSOCIATES_DaG]-(n1)),\r\n  size((n1)-[:INTERACTS_GiG]-()),\r\n  size(()-[:INTERACTS_GiG]-(n2)),\r\n  size((n2)-[:PARTICIPATES_GpBP]-()),\r\n  size(()-[:PARTICIPATES_GpBP]-(n3))\r\n] AS degrees, path, n3 as target\r\nWITH\r\n  target.identifier AS go_id,\r\n  target.name AS go_name,\r\n  count(path) AS PC,\r\n  sum(reduce(pdp = 1.0, d in degrees| pdp * d ^ -0.7)) AS DWPC,\r\n  size((target)-[:PARTICIPATES_GpBP]-()) AS n_genes\r\n  WHERE 5 &lt;= n_genes &lt;= 100 AND PC &gt;= 2\r\nRETURN\r\n  go_id, go_name, PC, DWPC, n_genes\r\nORDER BY DWPC DESC\r\nLIMIT 5</code></pre>\r\n\r\n<p>The query took under 5 seconds and required 1,420,721 database hits.</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>go_id</th><th>go_name</th><th>PC</th><th>DWPC</th><th>n_genes</th></tr></thead><tbody><tr><td>GO:0045347</td><td>negative regulation of MHC class II biosynthetic process</td><td>3</td><td>0.00006</td><td>6</td></tr><tr><td>GO:0010842</td><td>retina layer formation</td><td>3</td><td>0.00006</td><td>22</td></tr><tr><td>GO:0045346</td><td>regulation of MHC class II biosynthetic process</td><td>3</td><td>0.00004</td><td>13</td></tr><tr><td>GO:0060042</td><td>retina morphogenesis in camera-type eye</td><td>4</td><td>0.00003</td><td>54</td></tr><tr><td>GO:0003407</td><td>neural retina development</td><td>4</td><td>0.00003</td><td>55</td></tr></tbody></table>\r\n\r\n<p>Interestingly three of the processes involve the retina. Note that the terms are not independent: \"retina layer formation\" is a subprocess of \"retina morphogenesis in camera-type eye\" and \"retina layer formation\". If we're interested more in the MS–\"retina layer formation\" relationship, we can retrieve the paths behind the DWPC:</p>\r\n\r\n<pre><code class=\"no-highlight hljs\">MATCH path = (n0:Disease)-[e1:ASSOCIATES_DaG]-(n1)-[:INTERACTS_GiG]-(n2)-[:PARTICIPATES_GpBP]-(n3:BiologicalProcess)\r\nWHERE n0.name = 'multiple sclerosis'\r\n  AND n3.name = 'retina layer formation'\r\n  AND 'GWAS Catalog' in e1.sources\r\n  AND exists((n0)-[:LOCALIZES_DlA]-()-[:UPREGULATES_AuG]-(n2))\r\nRETURN path</code></pre>\r\n\r\n<p><img src=\"https://cloud.githubusercontent.com/assets/1117703/16359510/2ff3a870-3b05-11e6-8e3f-b9b50bf1e937.png\" alt=\"multiple sclerosis paths to retina layer formation\"></p>",
      "body_md": "# Tissue-specific interactomics: GO Process enrichment for multiple sclerosis\r\n\r\nThe following query performs a more advanced GO Process enrichment analysis for multiple sclerosis (MS) genes. First, we restrict to GWAS-associated genes, which have the advantage of being less biased by existing knowledge. Second, we add a protein interaction relationship to identify genes in the MS neighborhood of the interactome. However thirdly, we require that these genes are upregulated in an MS-affected tissue (anatomy). Therefore, we can hopefully capture some of the benefits of tissue-specific gene networks [@10.1038/ng.3259] on our anatomy-agnostic interactome.\r\n\r\n```\r\nMATCH path = (n0:Disease)-[e1:ASSOCIATES_DaG]-(n1)-[:INTERACTS_GiG]-(n2)-[:PARTICIPATES_GpBP]-(n3:BiologicalProcess)\r\nWHERE n0.name = 'multiple sclerosis'\r\n  AND 'GWAS Catalog' in e1.sources\r\n  AND exists((n0)-[:LOCALIZES_DlA]-()-[:UPREGULATES_AuG]-(n2))\r\nWITH\r\n[\r\n  size((n0)-[:ASSOCIATES_DaG]-()),\r\n  size(()-[:ASSOCIATES_DaG]-(n1)),\r\n  size((n1)-[:INTERACTS_GiG]-()),\r\n  size(()-[:INTERACTS_GiG]-(n2)),\r\n  size((n2)-[:PARTICIPATES_GpBP]-()),\r\n  size(()-[:PARTICIPATES_GpBP]-(n3))\r\n] AS degrees, path, n3 as target\r\nWITH\r\n  target.identifier AS go_id,\r\n  target.name AS go_name,\r\n  count(path) AS PC,\r\n  sum(reduce(pdp = 1.0, d in degrees| pdp * d ^ -0.7)) AS DWPC,\r\n  size((target)-[:PARTICIPATES_GpBP]-()) AS n_genes\r\n  WHERE 5 <= n_genes <= 100 AND PC >= 2\r\nRETURN\r\n  go_id, go_name, PC, DWPC, n_genes\r\nORDER BY DWPC DESC\r\nLIMIT 5\r\n```\r\n\r\nThe query took under 5 seconds and required 1,420,721 database hits.\r\n\r\n| go_id | go_name | PC | DWPC | n_genes |\r\n|------------|----------------------------------------------------------|----|---------|---------|\r\n| GO:0045347 | negative regulation of MHC class II biosynthetic process | 3 | 0.00006 | 6 |\r\n| GO:0010842 | retina layer formation | 3 | 0.00006 | 22 |\r\n| GO:0045346 | regulation of MHC class II biosynthetic process | 3 | 0.00004 | 13 |\r\n| GO:0060042 | retina morphogenesis in camera-type eye | 4 | 0.00003 | 54 |\r\n| GO:0003407 | neural retina development | 4 | 0.00003 | 55 |\r\n\r\nInterestingly three of the processes involve the retina. Note that the terms are not independent: \"retina layer formation\" is a subprocess of \"retina morphogenesis in camera-type eye\" and \"retina layer formation\". If we're interested more in the MS--\"retina layer formation\" relationship, we can retrieve the paths behind the DWPC:\r\n\r\n```cyp\r\nMATCH path = (n0:Disease)-[e1:ASSOCIATES_DaG]-(n1)-[:INTERACTS_GiG]-(n2)-[:PARTICIPATES_GpBP]-(n3:BiologicalProcess)\r\nWHERE n0.name = 'multiple sclerosis'\r\n  AND n3.name = 'retina layer formation'\r\n  AND 'GWAS Catalog' in e1.sources\r\n  AND exists((n0)-[:LOCALIZES_DlA]-()-[:UPREGULATES_AuG]-(n2))\r\nRETURN path\r\n```\r\n\r\n![multiple sclerosis paths to retina layer formation](https://cloud.githubusercontent.com/assets/1117703/16359510/2ff3a870-3b05-11e6-8e3f-b9b50bf1e937.png)",
      "comment_id": 1333,
      "profile_id": 17,
      "published": "2016-06-25T20:03:54.062157Z",
      "thread_id": 220,
      "url": "/discussion/exploring-the-power-of-hetionet-a-cypher-query-depot/220#3"
    },
    {
      "body_html": "<h1>Which anatomies express migraine-associated genes</h1>\r\n\r\n<p>The following query looks for anatomies (tissues) which express the genes associated with migraine.</p>\r\n\r\n<pre><code class=\"no-highlight hljs\">MATCH path = (n0:Disease)-[:ASSOCIATES_DaG]-(n1)-[:EXPRESSES_AeG]-(n2:Anatomy)\r\nWHERE n0.name = 'migraine'\r\nWITH\r\n[\r\n  size((n0)-[:ASSOCIATES_DaG]-()),\r\n  size(()-[:ASSOCIATES_DaG]-(n1)),\r\n  size((n1)-[:EXPRESSES_AeG]-()),\r\n  size(()-[:EXPRESSES_AeG]-(n2))\r\n] AS degrees, path, n2 as target\r\nRETURN\r\n  target.identifier AS anatomy_id,\r\n  target.name AS anatomy_name,\r\n  count(path) AS PC,\r\n  sum(reduce(pdp = 1.0, d in degrees| pdp * d ^ -0.5)) AS DWPC,\r\n  size((target)-[:EXPRESSES_AeG]-()) AS n_genes\r\nORDER BY DWPC DESC\r\nLIMIT 5</code></pre>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>anatomy_id</th><th>anatomy_name</th><th>PC</th><th>DWPC</th><th>n_genes</th></tr></thead><tbody><tr><td>UBERON:0001645</td><td>trigeminal nerve</td><td>7</td><td>0.022</td><td>36</td></tr><tr><td>UBERON:0001785</td><td>cranial nerve</td><td>10</td><td>0.020</td><td>66</td></tr><tr><td>UBERON:0002363</td><td>dura mater</td><td>2</td><td>0.017</td><td>4</td></tr><tr><td>UBERON:0002925</td><td>trigeminal nucleus</td><td>4</td><td>0.016</td><td>7</td></tr><tr><td>UBERON:0002360</td><td>meninx</td><td>1</td><td>0.012</td><td>3</td></tr></tbody></table>\r\n\r\n<p>The query does a good job identifying migraine-relevant tissues. However, notice that the expression profiles for the retrieved tissues are not very comprehensive: only four genes are known to be expressed in the dura mater, two of which are migraine associated. Therefore, these results are dependent on our gene expression catalog <span class=\"citation\">[<a href=\"/discussion/processing-bgee-for-tissue-specific-gene-presence-and-overunder-expression/124\" class=\"citation\" data-key=\"10.15363/thinklab.d124\">1</a>]</span>, which varies considerably in comprehension by tissue.</p>",
      "body_md": "# Which anatomies express migraine-associated genes\r\n\r\nThe following query looks for anatomies (tissues) which express the genes associated with migraine.\r\n\r\n```cyp\r\nMATCH path = (n0:Disease)-[:ASSOCIATES_DaG]-(n1)-[:EXPRESSES_AeG]-(n2:Anatomy)\r\nWHERE n0.name = 'migraine'\r\nWITH\r\n[\r\n  size((n0)-[:ASSOCIATES_DaG]-()),\r\n  size(()-[:ASSOCIATES_DaG]-(n1)),\r\n  size((n1)-[:EXPRESSES_AeG]-()),\r\n  size(()-[:EXPRESSES_AeG]-(n2))\r\n] AS degrees, path, n2 as target\r\nRETURN\r\n  target.identifier AS anatomy_id,\r\n  target.name AS anatomy_name,\r\n  count(path) AS PC,\r\n  sum(reduce(pdp = 1.0, d in degrees| pdp * d ^ -0.5)) AS DWPC,\r\n  size((target)-[:EXPRESSES_AeG]-()) AS n_genes\r\nORDER BY DWPC DESC\r\nLIMIT 5\r\n```\r\n\r\n| anatomy_id | anatomy_name | PC | DWPC | n_genes |\r\n|----------|-----------|----|-------|---------|\r\n| UBERON:0001645 | trigeminal nerve | 7 | 0.022 | 36 |\r\n| UBERON:0001785 | cranial nerve | 10 | 0.020 | 66 |\r\n| UBERON:0002363 | dura mater | 2 | 0.017 | 4 |\r\n| UBERON:0002925 | trigeminal nucleus | 4 | 0.016 | 7 |\r\n| UBERON:0002360 | meninx | 1 | 0.012 | 3 |\r\n\r\nThe query does a good job identifying migraine-relevant tissues. However, notice that the expression profiles for the retrieved tissues are not very comprehensive: only four genes are known to be expressed in the dura mater, two of which are migraine associated. Therefore, these results are dependent on our gene expression catalog [@10.15363/thinklab.d124], which varies considerably in comprehension by tissue.",
      "comment_id": 1334,
      "profile_id": 17,
      "published": "2016-06-27T15:35:45.650562Z",
      "thread_id": 220,
      "url": "/discussion/exploring-the-power-of-hetionet-a-cypher-query-depot/220#4"
    },
    {
      "body_html": "<h1>Compounds that target genes involved in myelation</h1>\r\n\r\n<p>Demyelination is the cause of much disability in multiple sclerosis patients. Below is a simple query to find all compounds that bind to proteins whose genes are involved in myelination:</p>\r\n\r\n<pre><code class=\"no-highlight hljs\">MATCH path = (n0:BiologicalProcess)-[:PARTICIPATES_GpBP]-(n1)-[:BINDS_CbG]-(n2:Compound)\r\nWHERE n0.name = 'myelination'\r\nRETURN path</code></pre>\r\n\r\n<p><img src=\"https://cloud.githubusercontent.com/assets/1117703/16385926/c77bec90-3c5c-11e6-88b3-1c6d01725086.png\" alt=\"myelination-compounds\"></p>\r\n\r\n<p>The query identifies 8 myelination-involved genes that are targeted by 33 compounds. To retrieve these counts yourself, change the last line of the query to <code>RETURN count(DISTINCT n1) AS targets,  count(DISTINCT n2) AS compounds</code>. If you're interested in myelination, see <a href=\"https://github.com/dhimmel/myelinet\" title=\"dhimmel/myelinet on GitHub\"><code>dhimmel/myelinet</code></a> for additional queries.</p>\r\n\r\n<p>We can modify the above query to find compounds that upregulate rather than bind a myelination gene/protein. <em>Compound–upregulates–Gene</em> relationships in Hetionet are from LINCS L1000 <span class=\"citation\">[<a href=\"/discussion/computing-consensus-transcriptional-profiles-for-lincs-l1000-perturbations/43\" class=\"citation\" data-key=\"10.15363/thinklab.d43\">1</a>]</span>. Here we set an extreme <code>z_score</code> threshold to thin the results:</p>\r\n\r\n<pre><code class=\"no-highlight hljs\">MATCH path = (n0:BiologicalProcess)-[:PARTICIPATES_GpBP]-(n1)-[e2:UPREGULATES_CuG]-(n2:Compound)\r\nWHERE n0.name = 'myelination' AND\r\ne2.z_score &gt; 12\r\nRETURN path</code></pre>",
      "body_md": "# Compounds that target genes involved in myelation\r\n\r\nDemyelination is the cause of much disability in multiple sclerosis patients. Below is a simple query to find all compounds that bind to proteins whose genes are involved in myelination:\r\n\r\n```cypher\r\nMATCH path = (n0:BiologicalProcess)-[:PARTICIPATES_GpBP]-(n1)-[:BINDS_CbG]-(n2:Compound)\r\nWHERE n0.name = 'myelination'\r\nRETURN path\r\n```\r\n\r\n![myelination-compounds](https://cloud.githubusercontent.com/assets/1117703/16385926/c77bec90-3c5c-11e6-88b3-1c6d01725086.png)\r\n\r\nThe query identifies 8 myelination-involved genes that are targeted by 33 compounds. To retrieve these counts yourself, change the last line of the query to `RETURN count(DISTINCT n1) AS targets,  count(DISTINCT n2) AS compounds`. If you're interested in myelination, see [`dhimmel/myelinet`](https://github.com/dhimmel/myelinet \"dhimmel/myelinet on GitHub\") for additional queries.\r\n\r\nWe can modify the above query to find compounds that upregulate rather than bind a myelination gene/protein. _Compound--upregulates--Gene_ relationships in Hetionet are from LINCS L1000 [@10.15363/thinklab.d43]. Here we set an extreme `z_score` threshold to thin the results:\r\n\r\n```cypher\r\nMATCH path = (n0:BiologicalProcess)-[:PARTICIPATES_GpBP]-(n1)-[e2:UPREGULATES_CuG]-(n2:Compound)\r\nWHERE n0.name = 'myelination' AND\r\ne2.z_score > 12\r\nRETURN path\r\n```",
      "comment_id": 1335,
      "profile_id": 17,
      "published": "2016-06-27T15:51:29.762113Z",
      "thread_id": 220,
      "url": "/discussion/exploring-the-power-of-hetionet-a-cypher-query-depot/220#5"
    },
    {
      "body_html": "<h1>Bupropion for nicotine dependence</h1>\r\n\r\n<p>I was looking into several historical instances of repurposing (<a href=\"https://github.com/dhimmel/learn/blob/e5e7459532944cafcf542ef6ddfe9184548224d9/validate/repurposing-examples.tsv\">compiled from</a> a 2013 article <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.tips.2013.03.004\" class=\"citation\" data-key=\"10.1016/j.tips.2013.03.004\">1</a>]</span>). One example that caught my eye was bupropion for nicotine dependence. Here's some historical context from a 2008 review <span class=\"citation\">[<a href=\"https://doi.org/10.2147/COPD.S1121\" class=\"citation\" data-key=\"10.2147/COPD.S1121\">2</a>]</span>:</p>\r\n\r\n<blockquote><p>Bupropion was developed as an antidepressant for the treatment of major depressive disorder in 1989 as a thrice-daily immediate release formulation <span class=\"citation\">[<a href=\"https://doi.org/10.4088/pcc.v07n0305\" class=\"citation\" data-key=\"10.4088/pcc.v07n0305\">3</a>]</span>. In 1996 a twice daily sustained release (SR) formulation was produced and, in 1997 the smoking cessation properties were first noticed in the United States of America (US) <span class=\"citation\">[<a href=\"https://doi.org/10.1385/comp:32:1:26\" class=\"citation\" data-key=\"10.1385/comp:32:1:26\">4</a>]</span>. Following evaluation as an anti-smoking agent <span class=\"citation\">[<a href=\"https://doi.org/10.1056/nejm199710233371703\" class=\"citation\" data-key=\"10.1056/nejm199710233371703\">5</a>]</span>, it became licensed as an aid to smoking cessation and is now a recognised first line antismoking agent in both the UK and US.</p></blockquote>\r\n\r\n<p>The following quote from a 2012 article speaks to the serendipity of this repurposing <span class=\"citation\">[<a href=\"https://doi.org/10.1093/ntr/nts201\" class=\"citation\" data-key=\"10.1093/ntr/nts201\">6</a>]</span>:</p>\r\n\r\n<blockquote><p>The ability of bupropion to facilitate smoking cessation was discovered serendipitously when it was shown to decrease cigarette consumption in depressed patients. The precise mechanism through which bupropion facilitates abstinence is unclear but nevertheless raises the intriguing possibility that other FDA-approved medications could likewise facilitate smoking cessation through novel mechanisms of action.</p></blockquote>\r\n\r\n<p>I looked into our prediction for bupropion and nicotine dependence (<a href=\"https://neo4j.het.io/browser/?cmd=play&amp;arg=https://neo4j.het.io/guides/rep/DB01156/DOID_0050742.html\">see in browser</a>):</p>\r\n\r\n<blockquote><p>Project Rephetio predicted a probability of 1.265% that Bupropion (<a href=\"http://www.drugbank.ca/drugs/DB01156\"><code>DB01156</code></a>) treats nicotine dependence (<a href=\"http://www.disease-ontology.org/?id=DOID:0050742\"><code>DOID:0050742</code></a>). This probability represents a 2.50-fold enrichment over the background prevalance of treatment. This prediction is in the 96.3th percentile for Bupropion and the 99.5th percentile for nicotine dependence.</p></blockquote>\r\n\r\n<p>While the predicted probability is not exceptional, bupropion was in the top 99.5th percentile (<a href=\"http://het.io/repurpose/browse.html?id=DOID_0050742\">ranked 9th</a>) for nicotine dependence. The following diagram shows the 10 paths providing the most support for this prediction:</p>\r\n\r\n<p><img src=\"https://cloud.githubusercontent.com/assets/1117703/16503512/5d56d140-3ee1-11e6-9522-e820c30f67fd.png\" alt=\"bupropion-nicotine\"></p>\r\n\r\n<p>Our approach picks up that bupropion causes terminal insomnia as does varenicline — the only other FDA-approved smoking cessation compound. Indeed, insomnia is one of the primary side effects of bupropion <span class=\"citation\">[<a href=\"https://doi.org/10.1007/s00228-003-0693-0\" class=\"citation\" data-key=\"10.1007/s00228-003-0693-0\">7</a>, <a href=\"https://doi.org/10.2147/COPD.S1121\" class=\"citation\" data-key=\"10.2147/COPD.S1121\">2</a>]</span> and is also a documented side effect of varenicline <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.amjmed.2008.01.017\" class=\"citation\" data-key=\"10.1016/j.amjmed.2008.01.017\">8</a>]</span>. This shared side effect could underlie a common mechanism of action.</p>\r\n\r\n<h2>Top predictions for nicotine dependence</h2>\r\n\r\n<p>Our top 3 predictions for treating nicotine dependence (or smoking cessation) are nicotine, cytisine, and galantamine. Nicotine is included in PharmacotherapyDB as a symptomatic indication and matched 86 clinical trials. Cytisine is an encouraging prediction because it's shown efficacy in trial <span class=\"citation\">[<a href=\"https://doi.org/10.1056/NEJMoa1102035\" class=\"citation\" data-key=\"10.1056/NEJMoa1102035\">9</a>, <a href=\"https://doi.org/10.1056/NEJMoa1407764\" class=\"citation\" data-key=\"10.1056/NEJMoa1407764\">10</a>]</span> and has been used by smokers for decades as a well-tolerated and low-cost cessation therapy <span class=\"citation\">[<a href=\"https://doi.org/10.1002/14651858.CD006103.pub7\" class=\"citation\" data-key=\"10.1002/14651858.CD006103.pub7\">11</a>]</span>. There is currently an ongoing <a href=\"https://clinicaltrials.gov/ct2/show/NCT01669538\" title=\"Effect of Galantamine on Short-term Abstinence (GAL-K)\">clinical trial</a> at the University of Pennsylvania for galantamine and quitting smoking. The trial has recently shown positive early results <span class=\"citation\">[<a href=\"https://doi.org/10.1038/tp.2015.209\" class=\"citation\" data-key=\"10.1038/tp.2015.209\">12</a>]</span>.</p>",
      "body_md": "# Bupropion for nicotine dependence\r\n\r\nI was looking into several historical instances of repurposing ([compiled from](https://github.com/dhimmel/learn/blob/e5e7459532944cafcf542ef6ddfe9184548224d9/validate/repurposing-examples.tsv) a 2013 article [@10.1016/j.tips.2013.03.004]). One example that caught my eye was bupropion for nicotine dependence. Here's some historical context from a 2008 review [@10.2147/COPD.S1121]:\r\n\r\n> Bupropion was developed as an antidepressant for the treatment of major depressive disorder in 1989 as a thrice-daily immediate release formulation [@10.4088/pcc.v07n0305]. In 1996 a twice daily sustained release (SR) formulation was produced and, in 1997 the smoking cessation properties were first noticed in the United States of America (US) [@10.1385/comp:32:1:26]. Following evaluation as an anti-smoking agent [@10.1056/nejm199710233371703], it became licensed as an aid to smoking cessation and is now a recognised first line antismoking agent in both the UK and US.\r\n\r\nThe following quote from a 2012 article speaks to the serendipity of this repurposing [@10.1093/ntr/nts201]:\r\n\r\n> The ability of bupropion to facilitate smoking cessation was discovered serendipitously when it was shown to decrease cigarette consumption in depressed patients. The precise mechanism through which bupropion facilitates abstinence is unclear but nevertheless raises the intriguing possibility that other FDA-approved medications could likewise facilitate smoking cessation through novel mechanisms of action.\r\n\r\nI looked into our prediction for bupropion and nicotine dependence ([see in browser](https://neo4j.het.io/browser/?cmd=play&arg=https://neo4j.het.io/guides/rep/DB01156/DOID_0050742.html)):\r\n\r\n> Project Rephetio predicted a probability of 1.265% that Bupropion ([`DB01156`](http://www.drugbank.ca/drugs/DB01156)) treats nicotine dependence ([`DOID:0050742`](http://www.disease-ontology.org/?id=DOID:0050742)). This probability represents a 2.50-fold enrichment over the background prevalance of treatment. This prediction is in the 96.3th percentile for Bupropion and the 99.5th percentile for nicotine dependence.\r\n\r\nWhile the predicted probability is not exceptional, bupropion was in the top 99.5th percentile ([ranked 9th](http://het.io/repurpose/browse.html?id=DOID_0050742)) for nicotine dependence. The following diagram shows the 10 paths providing the most support for this prediction:\r\n\r\n![bupropion-nicotine](https://cloud.githubusercontent.com/assets/1117703/16503512/5d56d140-3ee1-11e6-9522-e820c30f67fd.png)\r\n\r\nOur approach picks up that bupropion causes terminal insomnia as does varenicline -- the only other FDA-approved smoking cessation compound. Indeed, insomnia is one of the primary side effects of bupropion [@10.1007/s00228-003-0693-0 @10.2147/COPD.S1121] and is also a documented side effect of varenicline [@10.1016/j.amjmed.2008.01.017]. This shared side effect could underlie a common mechanism of action.\r\n\r\n## Top predictions for nicotine dependence \r\n\r\nOur top 3 predictions for treating nicotine dependence (or smoking cessation) are nicotine, cytisine, and galantamine. Nicotine is included in PharmacotherapyDB as a symptomatic indication and matched 86 clinical trials. Cytisine is an encouraging prediction because it's shown efficacy in trial [@10.1056/NEJMoa1102035 @10.1056/NEJMoa1407764] and has been used by smokers for decades as a well-tolerated and low-cost cessation therapy [@10.1002/14651858.CD006103.pub7]. There is currently an ongoing [clinical trial](https://clinicaltrials.gov/ct2/show/NCT01669538 \"Effect of Galantamine on Short-term Abstinence (GAL-K)\") at the University of Pennsylvania for galantamine and quitting smoking. The trial has recently shown positive early results [@10.1038/tp.2015.209].",
      "comment_id": 1336,
      "profile_id": 17,
      "published": "2016-06-30T21:37:46.968684Z",
      "thread_id": 203,
      "url": "/discussion/predictions-of-whether-a-compound-treats-a-disease/203#8"
    },
    {
      "body_html": "<p>There are some additional Disease Ontology feature requests I created on GitHub Issues but didn't get around to posting here until now:</p>\r\n\r\n<p><strong>Resolved</strong>:</p>\r\n\r\n<ul><li><a href=\"https://github.com/DiseaseOntology/HumanDiseaseOntology/issues/161\">Rename/synonym request: \"chronic kidney failure\" to \"chronic kidney disease\"</a></li><li><a href=\"https://github.com/DiseaseOntology/HumanDiseaseOntology/issues/162\">Inaccurate cross-references for coronary artery disease</a></li></ul>\r\n\r\n<p><strong>Ongoing</strong>:</p>\r\n\r\n<ul><li><a href=\"https://github.com/DiseaseOntology/HumanDiseaseOntology/issues/160\">Improving the the depression hierarchy</a></li></ul>",
      "body_md": "There are some additional Disease Ontology feature requests I created on GitHub Issues but didn't get around to posting here until now:\r\n\r\n**Resolved**:\r\n\r\n+ [Rename/synonym request: \"chronic kidney failure\" to \"chronic kidney disease\"](https://github.com/DiseaseOntology/HumanDiseaseOntology/issues/161)\r\n+ [Inaccurate cross-references for coronary artery disease](https://github.com/DiseaseOntology/HumanDiseaseOntology/issues/162)\r\n\r\n**Ongoing**:\r\n\r\n+ [Improving the the depression hierarchy](https://github.com/DiseaseOntology/HumanDiseaseOntology/issues/160)",
      "comment_id": 1337,
      "profile_id": 17,
      "published": "2016-08-10T17:00:38.109556Z",
      "thread_id": 68,
      "url": "/discussion/disease-ontology-feature-requests/68#5"
    },
    {
      "body_html": "<h1>Data copyright article in <em>Nature News</em></h1>\r\n\r\n<p>Simon Oxenham wrote a story titled <a href=\"http://www.nature.com/news/legal-confusion-threatens-to-slow-data-science-1.20359\" title=\"Nature News: Researcher who spent months chasing permission to republish online data sets urges others to read up on the law.\">Legal confusion threatens to slow data science</a>, which was published in <em>Nature News</em> today <span class=\"citation\">[<a href=\"https://doi.org/10.1038/536016a\" class=\"citation\" data-key=\"10.1038/536016a\">1</a>]</span>. The story covers our experience with data copyright and seeking permission to reuse publicly-funded research.</p>\r\n\r\n<p>The article begins with:</p>\r\n\r\n<blockquote><p>Knowledge from millions of biological studies encoded into one network — that is Daniel Himmelstein’s alluring description of <a href=\"https://neo4j.het.io/browser/\">Hetionet</a>, a free online resource that melds data from 28 public sources on links between drugs, genes and diseases. But for a product built on public information, obtaining legal permissions has been surprisingly tough.</p></blockquote>\r\n\r\n<p>Thanks to everyone who contributed on our data licensing discussions. This post wouldn't be here if it weren't for you!</p>",
      "body_md": "# Data copyright article in _Nature News_\r\n\r\nSimon Oxenham wrote a story titled [Legal confusion threatens to slow data science](http://www.nature.com/news/legal-confusion-threatens-to-slow-data-science-1.20359 \"Nature News: Researcher who spent months chasing permission to republish online data sets urges others to read up on the law.\"), which was published in _Nature News_ today [@10.1038/536016a]. The story covers our experience with data copyright and seeking permission to reuse publicly-funded research.\r\n\r\nThe article begins with:\r\n\r\n> Knowledge from millions of biological studies encoded into one network — that is Daniel Himmelstein’s alluring description of [Hetionet](https://neo4j.het.io/browser/), a free online resource that melds data from 28 public sources on links between drugs, genes and diseases. But for a product built on public information, obtaining legal permissions has been surprisingly tough.\r\n\r\nThanks to everyone who contributed on our data licensing discussions. This post wouldn't be here if it weren't for you!",
      "comment_id": 1341,
      "profile_id": 17,
      "published": "2016-08-03T14:20:42.552142Z",
      "thread_id": 113,
      "url": "/discussion/tracking-project-reuse-citation-and-publicity/113#9"
    },
    {
      "body_html": "<h1>Graphistania Podcast on Neo4j &amp; Project Rephetio</h1>\r\n\r\n<p>Rik Van Bruggen, Regional Vice President at Neo4j, interviewed me for the <em>Graphistania</em> podcast. We discussed hetnets, Neo4j, Cypher, Hetionet, and Project Rephetio. The podcast is available on the <a href=\"http://blog.bruggen.com/2016/08/podcast-interview-with-daniel.html\">Bruggen Blog</a>, <a href=\"https://soundcloud.com/graphistania/podcast-interview-with-daniel-himmelstein-university-of-pennsylvania\">SoundCloud</a>, <a href=\"https://youtu.be/QfElj7A12Rw\">YouTube</a>, <a href=\"https://itunes.apple.com/be/podcast/podcast-on-graph-databases/id975377379\">iTunes</a>, or below.</p>\r\n\r\n<p></p><div class=\"iframe-container\"><iframe src=\"https://www.youtube.com/embed/QfElj7A12Rw\" frameborder=\"0\" allowfullscreen=\"true\"></iframe></div>",
      "body_md": "# Graphistania Podcast on Neo4j & Project Rephetio\r\n\r\nRik Van Bruggen, Regional Vice President at Neo4j, interviewed me for the _Graphistania_ podcast. We discussed hetnets, Neo4j, Cypher, Hetionet, and Project Rephetio. The podcast is available on the [Bruggen Blog](http://blog.bruggen.com/2016/08/podcast-interview-with-daniel.html), [SoundCloud](https://soundcloud.com/graphistania/podcast-interview-with-daniel-himmelstein-university-of-pennsylvania), [YouTube](https://youtu.be/QfElj7A12Rw), [iTunes](https://itunes.apple.com/be/podcast/podcast-on-graph-databases/id975377379), or below.\r\n\r\n![:youtube](QfElj7A12Rw)",
      "comment_id": 1345,
      "profile_id": 17,
      "published": "2016-08-29T18:26:31.794149Z",
      "thread_id": 113,
      "url": "/discussion/tracking-project-reuse-citation-and-publicity/113#10"
    },
    {
      "body_html": "<h1>The targets responsible for a side effect</h1>\r\n\r\n<p>Here we'll investigate a query to identify genes which cause a given side effect when targeted by a compound. Let's look at the side effect Cushingoid (<a href=\"http://identifiers.org/umls/C0332601\"><code>C0332601</code></a>). The following query identifies the genes that are commonly targeted by Cushingoid-causing compounds:</p>\r\n\r\n<pre><code class=\"no-highlight hljs\">MATCH path = (n0:SideEffect)-[r1:CAUSES_CcSE]-(n1:Compound)-[r2:BINDS_CbG]-(n2:Gene)\r\nWHERE n0.name = 'Cushingoid'\r\nWITH\r\n[\r\n  size((n0)-[:CAUSES_CcSE]-()),\r\n  size(()-[:CAUSES_CcSE]-(n1)),\r\n  size((n1)-[:BINDS_CbG]-()),\r\n  size(()-[:BINDS_CbG]-(n2))\r\n] AS degrees, path, n2\r\nWITH\r\n  n2,\r\n  count(path) AS PC,\r\n  sum(reduce(pdp = 1.0, d in degrees| pdp * d ^ -0.4)) AS DWPC\r\nRETURN\r\n  n2.identifier AS gene_id,\r\n  n2.name AS gene_symbol,\r\n  n2.description AS gene_name,\r\n  PC, DWPC\r\nORDER BY DWPC DESC, gene_symbol</code></pre>\r\n\r\n<p>The query returns 52 genes with at least one <em>GbCcSE</em> path to Cushingoid. Here are the resulting first three rows ranked by DWPC:</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>gene_id</th><th>gene_symbol</th><th>gene_name</th><th>PC</th><th>DWPC</th></tr></thead><tbody><tr><td>2908</td><td>NR3C1</td><td>nuclear receptor subfamily 3, group C, member 1 (glucocorticoid receptor)</td><td>7</td><td>0.0343</td></tr><tr><td>3290</td><td>HSD11B1</td><td>hydroxysteroid (11-beta) dehydrogenase 1</td><td>1</td><td>0.0198</td></tr><tr><td>5916</td><td>RARG</td><td>retinoic acid receptor, gamma</td><td>3</td><td>0.0196</td></tr></tbody></table>\r\n\r\n<p>We can extract the paths behind contributing to the DWPC of the top hit (<em>NR3C1</em>).</p>\r\n\r\n<pre><code class=\"no-highlight hljs\">MATCH path = (n0:SideEffect)-[r1:CAUSES_CcSE]-(n1:Compound)-[r2:BINDS_CbG]-(n2:Gene)\r\nWHERE n0.name = 'Cushingoid'\r\n  AND n2.name = 'NR3C1'\r\nRETURN path</code></pre>\r\n\r\n<p><img src=\"https://cloud.githubusercontent.com/assets/1117703/18132708/d5b53e4c-6f65-11e6-9924-7a64603a6343.png\" alt=\"Cushingoid-NR3C1 Paths\"></p>\r\n\r\n<p>The involvement of <em>NR3C1</em> in Cushingoid makes biological sense. <em>NR3C1</em> encodes the glucocorticoid receptor, and chronic elevation of glucocorticoid levels can result in Cushing’s disease <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.tips.2013.07.003\" class=\"citation\" data-key=\"10.1016/j.tips.2013.07.003\">1</a>]</span>.</p>\r\n\r\n<p>Next, we'll compare our findings to the gene targets predicted to cause Cushingoid in a 2012 study <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nature11159\" class=\"citation\" data-key=\"10.1038/nature11159\">2</a>]</span>. <a href=\"http://www.nature.com/nature/journal/v486/n7403/extref/nature11159-s2.xls\" title=\"Download Supplement: nature11159-s2.xls\">Supplementary Table 5</a> contains predicted target–ADR (adverse drug reaction) relationships. If we filter for Cushingoid, the predictions contain the following 8 targets: <em>AR</em>, <em>KDR</em>, <em>NR3C1</em>, <em>NR3C2</em>, <em>PDGFRA</em>, <em>PDGFRB</em>, <em>SERPINA6</em>, <em>TEK</em>. Of these 8 targets, <em>NR3C1</em> was the top prediction with a Chi-square statistic of 1922.5. The targets <em>NR3C2</em> and <em>SERPINA6</em> were also present in our 52 Hetionet-derived genes.</p>\r\n\r\n<p>Hetionet v1.0 contains 5,734 side effects. The workflow and queries above can be used by researchers to highlight the potential target genes responsible for a side effect of interest.</p>",
      "body_md": "# The targets responsible for a side effect\r\n\r\nHere we'll investigate a query to identify genes which cause a given side effect when targeted by a compound. Let's look at the side effect Cushingoid ([`C0332601`](http://identifiers.org/umls/C0332601)). The following query identifies the genes that are commonly targeted by Cushingoid-causing compounds:\r\n\r\n```cypher\r\nMATCH path = (n0:SideEffect)-[r1:CAUSES_CcSE]-(n1:Compound)-[r2:BINDS_CbG]-(n2:Gene)\r\nWHERE n0.name = 'Cushingoid'\r\nWITH\r\n[\r\n  size((n0)-[:CAUSES_CcSE]-()),\r\n  size(()-[:CAUSES_CcSE]-(n1)),\r\n  size((n1)-[:BINDS_CbG]-()),\r\n  size(()-[:BINDS_CbG]-(n2))\r\n] AS degrees, path, n2\r\nWITH\r\n  n2,\r\n  count(path) AS PC,\r\n  sum(reduce(pdp = 1.0, d in degrees| pdp * d ^ -0.4)) AS DWPC\r\nRETURN\r\n  n2.identifier AS gene_id,\r\n  n2.name AS gene_symbol,\r\n  n2.description AS gene_name,\r\n  PC, DWPC\r\nORDER BY DWPC DESC, gene_symbol\r\n```\r\n\r\nThe query returns 52 genes with at least one _GbCcSE_ path to Cushingoid. Here are the resulting first three rows ranked by DWPC:\r\n\r\n| gene_id | gene_symbol | gene_name | PC | DWPC |\r\n|---------|-------------|-----------------|----|----------------------|\r\n| 2908 | NR3C1 | nuclear receptor subfamily 3, group C, member 1 (glucocorticoid receptor) | 7 | 0.0343 |\r\n| 3290 | HSD11B1 | hydroxysteroid (11-beta) dehydrogenase 1 | 1 | 0.0198 |\r\n| 5916 | RARG | retinoic acid receptor, gamma | 3 | 0.0196 |\r\n\r\nWe can extract the paths behind contributing to the DWPC of the top hit (_NR3C1_).\r\n\r\n```\r\nMATCH path = (n0:SideEffect)-[r1:CAUSES_CcSE]-(n1:Compound)-[r2:BINDS_CbG]-(n2:Gene)\r\nWHERE n0.name = 'Cushingoid'\r\n  AND n2.name = 'NR3C1'\r\nRETURN path\r\n```\r\n\r\n![Cushingoid-NR3C1 Paths](https://cloud.githubusercontent.com/assets/1117703/18132708/d5b53e4c-6f65-11e6-9924-7a64603a6343.png)\r\n\r\nThe involvement of _NR3C1_ in Cushingoid makes biological sense. _NR3C1_ encodes the glucocorticoid receptor, and chronic elevation of glucocorticoid levels can result in Cushing’s disease [@10.1016/j.tips.2013.07.003].\r\n\r\nNext, we'll compare our findings to the gene targets predicted to cause Cushingoid in a 2012 study [@10.1038/nature11159]. [Supplementary Table 5](http://www.nature.com/nature/journal/v486/n7403/extref/nature11159-s2.xls \"Download Supplement: nature11159-s2.xls\") contains predicted target--ADR (adverse drug reaction) relationships. If we filter for Cushingoid, the predictions contain the following 8 targets: _AR_, _KDR_, _NR3C1_, _NR3C2_, _PDGFRA_, _PDGFRB_, _SERPINA6_, _TEK_. Of these 8 targets, _NR3C1_ was the top prediction with a Chi-square statistic of 1922.5. The targets _NR3C2_ and _SERPINA6_ were also present in our 52 Hetionet-derived genes.\r\n\r\nHetionet v1.0 contains 5,734 side effects. The workflow and queries above can be used by researchers to highlight the potential target genes responsible for a side effect of interest.",
      "comment_id": 1346,
      "profile_id": 17,
      "published": "2016-08-31T15:10:58.290678Z",
      "thread_id": 220,
      "url": "/discussion/exploring-the-power-of-hetionet-a-cypher-query-depot/220#6"
    },
    {
      "body_html": "<h1>Predictions for decitabine</h1>\r\n\r\n<p>Decitabine (<a href=\"http://www.drugbank.ca/drugs/DB01262\" title=\"Decitabine on DrugBank\"><code>DB01262</code></a>) is a treatment for myelodysplastic syndromes — which are not included in Hetionet v1.0 as a disease. In Europe, decitabine was approved for acute myeloid leukemia (AML) in 2012, but Hetionet v1.0 does not contain any indications for this drug. Therefore, all of <a href=\"http://het.io/repurpose/browse.html?id=DB01262\" title=\"Project Rephetio predictions for decitabine\">decitabine's predictions</a> are novel from the perspective of the network.</p>\r\n\r\n<p>The top prediction at 16.5% is <strong>hematologic cancer</strong>, a supertype of AML. This prediction <a href=\"https://neo4j.het.io/browser/?cmd=play&amp;arg=https://neo4j.het.io/guides/rep/DB01262/DOID_2531.html\" title=\"Hetionet Neo4j Browser: decitabine--hematologic cancer prediction\">draws support</a> from a large number of paths. Decitabine binds <em>DNMT3A</em> and <em>DCK</em>, two hematologic cancer associated genes. Furthermore, several treatments for hematologic cancer — including Pentostatin, Clofarabine, Nelarabine,  Cytarabine — belong to the \"Nucleic Acid Synthesis Inhibitors\" pharmacologic class along with decitabine. And finally, decitabine chemically resembles the four other compounds mentioned above.</p>\r\n\r\n<p>Other top cancer predictions for decitabine include the lymphatic system (4.87%), stomach (2.94%), breast (2.74%), pancreas (1.76%), bladder (1.71%), lung (1.48%), and kidney (1.47%). All of these cancers besides the stomach have clinical trials for decitabine. Below we visualizing the most <a href=\"https://neo4j.het.io/browser/?cmd=play&amp;arg=https://neo4j.het.io/guides/rep/DB01262/DOID_1324.html\" title=\"Hetionet Neo4j Browser: decitabine--lung cancer prediction\">supportive paths</a> for <strong>lung cancer</strong>. Most of the support comes from decitabine's similarity to lung-cancer-therapy gemcitabine. Our method also picked up that decitabine's target genes <em>DNMT1</em> and <em>DNMT3A</em> are expressed in relevant anatomies for lung cancer. However, we really only care about the tissue-specificity of the genes contained within potentially mechanistic paths, such as <em>DCK</em> below, which is required to enzymatically activate decitabine <span class=\"citation\">[<a href=\"https://doi.org/10.1053/j.seminhematol.2005.05.002\" class=\"citation\" data-key=\"10.1053/j.seminhematol.2005.05.002\">1</a>]</span>. Therefore, a future direction could be to engineer meta-<em>patterns</em> (rather than paths) that capture the benefits of tissue-specificity <span class=\"citation\">[<a href=\"https://doi.org/10.1038/ng.3259\" class=\"citation\" data-key=\"10.1038/ng.3259\">2</a>]</span>.</p>\r\n\r\n<p><img src=\"https://cloud.githubusercontent.com/assets/1117703/18216262/ad56cfe6-7123-11e6-96ef-60b35cf1ca1b.png\" alt=\"decitabine-lung-cancer\"></p>\r\n\r\n<p>The fifth ranking prediction, however, is not a cancer but instead <strong>multiple sclerosis</strong> (MS). The MS prediction is based on decitabine's resemblance to cladribine — an efficacious MS treatment that was never approved due to safety concerns <span class=\"citation\">[<a href=\"https://doi.org/10.1056/NEJMoa0902533\" class=\"citation\" data-key=\"10.1056/NEJMoa0902533\">3</a>, <a href=\"https://doi.org/10.4137/JCNSD.S5128\" class=\"citation\" data-key=\"10.4137/JCNSD.S5128\">4</a>, <a href=\"https://doi.org/10.1097/WNF.0b013e318204cd90\" class=\"citation\" data-key=\"10.1097/WNF.0b013e318204cd90\">5</a>]</span>, although risks may have been overstated <span class=\"citation\">[<a href=\"https://doi.org/10.1212/nxi.0000000000000158\" class=\"citation\" data-key=\"10.1212/nxi.0000000000000158\">6</a>]</span> and regulatory review <a href=\"https://multiplesclerosisnewstoday.com/2016/07/20/20160720merck-european-medicines-agency-accept-review-marketing-authorization-cladribine-tablets/\" title=\"Merck KGaA’s Investigational MS Therapy Cladribine Gets EMA Marketing Authorization Application Review. July 20, 2016. Daniela Semedo. Multiple Sclerosis News Today\">has recommenced</a>. Additional support for treating MS with decitabine came from azathioprine — a longstanding and economical MS therapy <span class=\"citation\">[<a href=\"https://doi.org/10.1002/14651858.CD003982.pub2\" class=\"citation\" data-key=\"10.1002/14651858.CD003982.pub2\">7</a>, <a href=\"https://doi.org/10.1371/journal.pone.0113371\" class=\"citation\" data-key=\"10.1371/journal.pone.0113371\">8</a>]</span> — also being a nucleic acid synthesis inhibitor. Supporting this prediction, a 2014 abstract reported that decitabine completely blocked symptoms in EAE (a preclinical model of MS) <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.jneuroim.2014.08.591\" class=\"citation\" data-key=\"10.1016/j.jneuroim.2014.08.591\">9</a>]</span>. The <a href=\"https://neo4j.het.io/browser/?cmd=play&amp;arg=https://neo4j.het.io/guides/rep/DB01262/DOID_2377.html\" title=\"Hetionet Neo4j Browser: decitabine--multiple sclerosis prediction\">decitabine–MS prediction</a> is visualized below:</p>\r\n\r\n<p><img src=\"https://cloud.githubusercontent.com/assets/1117703/18216265/ae89218e-7123-11e6-992c-6c87067330ef.png\" alt=\"decitabine-ms\"></p>",
      "body_md": "# Predictions for decitabine\r\n\r\nDecitabine ([`DB01262`](http://www.drugbank.ca/drugs/DB01262 \"Decitabine on DrugBank\")) is a treatment for myelodysplastic syndromes -- which are not included in Hetionet v1.0 as a disease. In Europe, decitabine was approved for acute myeloid leukemia (AML) in 2012, but Hetionet v1.0 does not contain any indications for this drug. Therefore, all of [decitabine's predictions](http://het.io/repurpose/browse.html?id=DB01262 \"Project Rephetio predictions for decitabine\") are novel from the perspective of the network.\r\n\r\nThe top prediction at 16.5% is **hematologic cancer**, a supertype of AML. This prediction [draws support](https://neo4j.het.io/browser/?cmd=play&arg=https://neo4j.het.io/guides/rep/DB01262/DOID_2531.html \"Hetionet Neo4j Browser: decitabine--hematologic cancer prediction\") from a large number of paths. Decitabine binds _DNMT3A_ and _DCK_, two hematologic cancer associated genes. Furthermore, several treatments for hematologic cancer -- including Pentostatin, Clofarabine, Nelarabine,  Cytarabine -- belong to the \"Nucleic Acid Synthesis Inhibitors\" pharmacologic class along with decitabine. And finally, decitabine chemically resembles the four other compounds mentioned above.\r\n\r\nOther top cancer predictions for decitabine include the lymphatic system (4.87%), stomach (2.94%), breast (2.74%), pancreas (1.76%), bladder (1.71%), lung (1.48%), and kidney (1.47%). All of these cancers besides the stomach have clinical trials for decitabine. Below we visualizing the most [supportive paths](https://neo4j.het.io/browser/?cmd=play&arg=https://neo4j.het.io/guides/rep/DB01262/DOID_1324.html \"Hetionet Neo4j Browser: decitabine--lung cancer prediction\") for **lung cancer**. Most of the support comes from decitabine's similarity to lung-cancer-therapy gemcitabine. Our method also picked up that decitabine's target genes _DNMT1_ and _DNMT3A_ are expressed in relevant anatomies for lung cancer. However, we really only care about the tissue-specificity of the genes contained within potentially mechanistic paths, such as _DCK_ below, which is required to enzymatically activate decitabine [@10.1053/j.seminhematol.2005.05.002]. Therefore, a future direction could be to engineer meta-*patterns* (rather than paths) that capture the benefits of tissue-specificity [@10.1038/ng.3259].\r\n\r\n![decitabine-lung-cancer](https://cloud.githubusercontent.com/assets/1117703/18216262/ad56cfe6-7123-11e6-96ef-60b35cf1ca1b.png)\r\n\r\nThe fifth ranking prediction, however, is not a cancer but instead **multiple sclerosis** (MS). The MS prediction is based on decitabine's resemblance to cladribine -- an efficacious MS treatment that was never approved due to safety concerns [@10.1056/NEJMoa0902533 @10.4137/JCNSD.S5128 @10.1097/WNF.0b013e318204cd90], although risks may have been overstated [@10.1212/nxi.0000000000000158] and regulatory review [has recommenced](https://multiplesclerosisnewstoday.com/2016/07/20/20160720merck-european-medicines-agency-accept-review-marketing-authorization-cladribine-tablets/ \"Merck KGaA’s Investigational MS Therapy Cladribine Gets EMA Marketing Authorization Application Review. July 20, 2016. Daniela Semedo. Multiple Sclerosis News Today\"). Additional support for treating MS with decitabine came from azathioprine -- a longstanding and economical MS therapy [@10.1002/14651858.CD003982.pub2 @10.1371/journal.pone.0113371] -- also being a nucleic acid synthesis inhibitor. Supporting this prediction, a 2014 abstract reported that decitabine completely blocked symptoms in EAE (a preclinical model of MS) [@10.1016/j.jneuroim.2014.08.591]. The [decitabine--MS prediction](https://neo4j.het.io/browser/?cmd=play&arg=https://neo4j.het.io/guides/rep/DB01262/DOID_2377.html \"Hetionet Neo4j Browser: decitabine--multiple sclerosis prediction\") is visualized below:\r\n\r\n![decitabine-ms](https://cloud.githubusercontent.com/assets/1117703/18216265/ae89218e-7123-11e6-992c-6c87067330ef.png)",
      "comment_id": 1348,
      "profile_id": 17,
      "published": "2016-09-02T20:04:14.429892Z",
      "thread_id": 203,
      "url": "/discussion/predictions-of-whether-a-compound-treats-a-disease/203#9"
    },
    {
      "body_html": "<h1>Predictions for trifluridine</h1>\r\n\r\n<p>Trifluridine (<a href=\"http://www.drugbank.ca/drugs/DB00432\" title=\"Trifluridine on DrugBank\"><code>DB00432</code></a>) is an antiviral drug most commonly applied via solution to the eye for treatment of herpes simplex virus (HSV). Trifluridine does not contain any indications in Hetionet v1.0. Here are the top five <a href=\"http://het.io/repurpose/browse.html?id=DB00432\">predictions for trifluridine</a>:</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>Name</th><th>Prediction</th><th>Compound Pctl</th><th>Disease Pctl</th><th>Visualize</th></tr></thead><tbody><tr><td>acquired immunodeficiency syndrome</td><td>14.4%</td><td>100%</td><td>99.4%</td><td><a href=\"https://neo4j.het.io/browser/?cmd=play&amp;arg=https://neo4j.het.io/guides/rep/DB00432/DOID_635.html\">browser</a></td></tr><tr><td>stomach cancer</td><td>13.1%</td><td>99.3%</td><td>99.9%</td><td><a href=\"https://neo4j.het.io/browser/?cmd=play&amp;arg=https://neo4j.het.io/guides/rep/DB00432/DOID_10534.html\">browser</a></td></tr><tr><td>hepatitis B</td><td>5.37%</td><td>98.5%</td><td>99.5%</td><td><a href=\"https://neo4j.het.io/browser/?cmd=play&amp;arg=https://neo4j.het.io/guides/rep/DB00432/DOID_2043.html\">browser</a></td></tr><tr><td>hematologic cancer</td><td>3.19%</td><td>97.8%</td><td>96.0%</td><td><a href=\"https://neo4j.het.io/browser/?cmd=play&amp;arg=https://neo4j.het.io/guides/rep/DB00432/DOID_2531.html\">browser</a></td></tr><tr><td>multiple sclerosis</td><td>2.18%</td><td>97.1%</td><td>98.2%</td><td><a href=\"https://neo4j.het.io/browser/?cmd=play&amp;arg=https://neo4j.het.io/guides/rep/DB00432/DOID_2377.html\">browser</a></td></tr></tbody></table>\r\n\r\n<p>HSV isn't included as a disease in Hetionet v1.0, yet Project Rephetio picked up on the antiviral powers of trifluridine and suggested treatment of <strong>acquired immunodeficiency syndrome</strong> (AIDS) and hepatitis B (HBV). The AIDS prediction (visualized below) is supported by the five existing AIDS therapies that are also nucleoside analogs. The similarity between trifluridine and stavudine/zidovudine is further supported by chemical resemblance and in the case of zidovudine a common binding to thymidine kinase-1 (<em>TK1</em> gene). Thymidine kinase-1 phosphorylates trifluridine into its active form, trifluridine monophosphate <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nrclinonc.2014.51\" class=\"citation\" data-key=\"10.1038/nrclinonc.2014.51\">1</a>]</span>.</p>\r\n\r\n<p><img src=\"https://cloud.githubusercontent.com/assets/1117703/18218456/d916072a-7130-11e6-9fdf-bd55ff8d6ed6.png\" alt=\"trifluridine-aids\"></p>\r\n\r\n<p>Several of the top predictions for trifluridine were cancers. It turns out that in 2015, the <a href=\"http://www.fda.gov/NewsEvents/Newsroom/PressAnnouncements/ucm463650.htm\" title=\"FDA approves new oral medication to treat patients with advanced colorectal cancer. FDA News Release. September 22, 2015\">FDA approved</a> a combination of trifluridine and tipiracil — code named TAS-102 and trade named Lonsurf — to treat advanced <strong>colorectal cancer</strong> after it increased median survival from 5.3 to 7.1 months in Phase 3 trial <span class=\"citation\">[<a href=\"https://doi.org/10.1056/NEJMoa1414325\" class=\"citation\" data-key=\"10.1056/NEJMoa1414325\">2</a>]</span>.</p>\r\n\r\n<p>The therapeutic effect of TAS-102 on colorectal cancer is due to the cytotoxicity of trifluridine monophosphate <span class=\"citation\">[<a href=\"https://doi.org/10.1111/j.1349-7006.2007.00477.x\" class=\"citation\" data-key=\"10.1111/j.1349-7006.2007.00477.x\">3</a>]</span>. Cytotoxity occurs to thymidylate synthase inhibition and DNA dysfunction <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.critrevonc.2016.05.015\" class=\"citation\" data-key=\"10.1016/j.critrevonc.2016.05.015\">4</a>, <a href=\"https://doi.org/10.1016/j.ctrv.2015.06.001\" class=\"citation\" data-key=\"10.1016/j.ctrv.2015.06.001\">5</a>]</span>. The addition of tipiracil improves the bioavailability of trifluridine by inhibiting thymidine phosphorylase which degrades trifluridine. Colon cancer was eighth highest prediction for trifluridine at 1.5% (99.0th percentile for colon cancer) and is <a href=\"https://neo4j.het.io/browser/?cmd=play&amp;arg=https://neo4j.het.io/guides/rep/DB00432/DOID_219.html\" title=\"Hetionet Neo4j Browser: trifluridine--colon cancer\">visualized</a> below:</p>\r\n\r\n<p><img src=\"https://cloud.githubusercontent.com/assets/1117703/18218455/d91001c2-7130-11e6-96aa-66e0ad94d8a4.png\" alt=\"trifluridine-colon-cancer\"></p>\r\n\r\n<p>The prediction is supported by other colon cancer treatments — capecitabine and fluorouracil — also being nucleic acid synthesis inhibitors. Furthermore, trifluridine binds to thymidylate synthetase (<em>TYMS</em> gene) and thymidine phosphorylase (<em>TYMP</em> gene), which are respectively responsible for its efficacy and short half-life as explained above. Our method picks up that <em>TYMP</em> is expressed in the endothelium. A pharmacologist could interpret this knowledge to infer that thymidine is necessary to prolong bioavailability when delivering trifluridine to endothelial cancers. Also important for identifying which cancers trifluridine will treat best is the tissue-specific expression of <em>TYMS</em> and <em>TK1</em>. In fact, a recent study found stomach cancers (our top cancer prediction for trifluridine) highly express both the <em>TYMS</em> and <em>TK1</em> proteins <span class=\"citation\">[<a href=\"https://doi.org/10.3892/or_00000770\" class=\"citation\" data-key=\"10.3892/or_00000770\">6</a>]</span>. We can query Hetionet for to see which stomach-cancer-affected tissues upregulate thymidylate genes:</p>\r\n\r\n<pre><code class=\"no-highlight hljs\">MATCH path = (compound:Compound)-[:BINDS_CbG]-(gene:Gene)-[:UPREGULATES_AuG]-(:Anatomy)-[:LOCALIZES_DlA]-(disease:Disease)\r\nWHERE\r\n  compound.name = 'Trifluridine' AND\r\n  gene.description CONTAINS 'thymid' AND\r\n  disease.name = 'stomach cancer'\r\nRETURN path</code></pre>\r\n\r\n<p>Finally, trifluridine was also predicted to treat <strong>multiple sclerosis</strong>. The mechanisms underlying this prediction are similar to <a href=\"#9\">decitabine</a>. Trifluridine resembles cladribine. Furthermore, like the MS-treatment azathioprine, trifluridine is a nucleic acid synthesis inhibitor and nucleoside analog. Additionally, the immunosuppressant methotrexate is an effective therapy for MS <span class=\"citation\">[<a href=\"https://doi.org/10.1002/14651858.CD003208.pub2\" class=\"citation\" data-key=\"10.1002/14651858.CD003208.pub2\">7</a>]</span>. While the exact mechanism of methotrexate's efficacy against MS remains elusive <span class=\"citation\">[<a href=\"https://doi.org/10.1177/1756285610379885\" class=\"citation\" data-key=\"10.1177/1756285610379885\">8</a>]</span>, our prediction highlights the potential involvement of thymidylate synthetase (<em>TYMS</em>).</p>\r\n\r\n<p><img src=\"https://cloud.githubusercontent.com/assets/1117703/18218457/d91644c4-7130-11e6-996b-6e8781281943.png\" alt=\"trifluridine-ms\"></p>\r\n\r\n<p>In conclusion, Project Rephetio identified three categories of disease — neoplastic, autoimmune, and viral — where trifluridine may exhibit efficacy. While little literature existed which probed the non-cancer applications, this appears to be an area of ongoing and relentless discovery.</p>",
      "body_md": "# Predictions for trifluridine\r\n\r\nTrifluridine ([`DB00432`](http://www.drugbank.ca/drugs/DB00432 \"Trifluridine on DrugBank\")) is an antiviral drug most commonly applied via solution to the eye for treatment of herpes simplex virus (HSV). Trifluridine does not contain any indications in Hetionet v1.0. Here are the top five [predictions for trifluridine](http://het.io/repurpose/browse.html?id=DB00432):\r\n\r\n| Name | Prediction | Compound Pctl | Disease Pctl | Visualize |\r\n|----------------|------------|---------------|--------------|-----------|\r\n| acquired immunodeficiency syndrome | 14.4% | 100% | 99.4% | [browser](https://neo4j.het.io/browser/?cmd=play&arg=https://neo4j.het.io/guides/rep/DB00432/DOID_635.html) |\r\n| stomach cancer | 13.1% | 99.3% | 99.9% | [browser](https://neo4j.het.io/browser/?cmd=play&arg=https://neo4j.het.io/guides/rep/DB00432/DOID_10534.html) |\r\n| hepatitis B | 5.37% | 98.5% | 99.5% | [browser](https://neo4j.het.io/browser/?cmd=play&arg=https://neo4j.het.io/guides/rep/DB00432/DOID_2043.html) |\r\n| hematologic cancer | 3.19% | 97.8% | 96.0% | [browser](https://neo4j.het.io/browser/?cmd=play&arg=https://neo4j.het.io/guides/rep/DB00432/DOID_2531.html) |\r\n| multiple sclerosis | 2.18% | 97.1% | 98.2% | [browser](https://neo4j.het.io/browser/?cmd=play&arg=https://neo4j.het.io/guides/rep/DB00432/DOID_2377.html) |\r\n\r\nHSV isn't included as a disease in Hetionet v1.0, yet Project Rephetio picked up on the antiviral powers of trifluridine and suggested treatment of **acquired immunodeficiency syndrome** (AIDS) and hepatitis B (HBV). The AIDS prediction (visualized below) is supported by the five existing AIDS therapies that are also nucleoside analogs. The similarity between trifluridine and stavudine/zidovudine is further supported by chemical resemblance and in the case of zidovudine a common binding to thymidine kinase-1 (_TK1_ gene). Thymidine kinase-1 phosphorylates trifluridine into its active form, trifluridine monophosphate [@10.1038/nrclinonc.2014.51].\r\n\r\n![trifluridine-aids](https://cloud.githubusercontent.com/assets/1117703/18218456/d916072a-7130-11e6-9fdf-bd55ff8d6ed6.png)\r\n\r\nSeveral of the top predictions for trifluridine were cancers. It turns out that in 2015, the [FDA approved](http://www.fda.gov/NewsEvents/Newsroom/PressAnnouncements/ucm463650.htm \"FDA approves new oral medication to treat patients with advanced colorectal cancer. FDA News Release. September 22, 2015\") a combination of trifluridine and tipiracil -- code named TAS-102 and trade named Lonsurf -- to treat advanced **colorectal cancer** after it increased median survival from 5.3 to 7.1 months in Phase 3 trial [@10.1056/NEJMoa1414325].\r\n\r\nThe therapeutic effect of TAS-102 on colorectal cancer is due to the cytotoxicity of trifluridine monophosphate [@10.1111/j.1349-7006.2007.00477.x]. Cytotoxity occurs to thymidylate synthase inhibition and DNA dysfunction [@10.1016/j.critrevonc.2016.05.015 @10.1016/j.ctrv.2015.06.001]. The addition of tipiracil improves the bioavailability of trifluridine by inhibiting thymidine phosphorylase which degrades trifluridine. Colon cancer was eighth highest prediction for trifluridine at 1.5% (99.0th percentile for colon cancer) and is [visualized](https://neo4j.het.io/browser/?cmd=play&arg=https://neo4j.het.io/guides/rep/DB00432/DOID_219.html \"Hetionet Neo4j Browser: trifluridine--colon cancer\") below:\r\n\r\n![trifluridine-colon-cancer](https://cloud.githubusercontent.com/assets/1117703/18218455/d91001c2-7130-11e6-96aa-66e0ad94d8a4.png)\r\n\r\nThe prediction is supported by other colon cancer treatments -- capecitabine and fluorouracil -- also being nucleic acid synthesis inhibitors. Furthermore, trifluridine binds to thymidylate synthetase (_TYMS_ gene) and thymidine phosphorylase (_TYMP_ gene), which are respectively responsible for its efficacy and short half-life as explained above. Our method picks up that _TYMP_ is expressed in the endothelium. A pharmacologist could interpret this knowledge to infer that thymidine is necessary to prolong bioavailability when delivering trifluridine to endothelial cancers. Also important for identifying which cancers trifluridine will treat best is the tissue-specific expression of _TYMS_ and _TK1_. In fact, a recent study found stomach cancers (our top cancer prediction for trifluridine) highly express both the _TYMS_ and _TK1_ proteins [@10.3892/or_00000770]. We can query Hetionet for to see which stomach-cancer-affected tissues upregulate thymidylate genes:\r\n\r\n\r\n```cypher\r\nMATCH path = (compound:Compound)-[:BINDS_CbG]-(gene:Gene)-[:UPREGULATES_AuG]-(:Anatomy)-[:LOCALIZES_DlA]-(disease:Disease)\r\nWHERE\r\n  compound.name = 'Trifluridine' AND\r\n  gene.description CONTAINS 'thymid' AND\r\n  disease.name = 'stomach cancer'\r\nRETURN path\r\n```\r\n\r\nFinally, trifluridine was also predicted to treat **multiple sclerosis**. The mechanisms underlying this prediction are similar to [decitabine](#9). Trifluridine resembles cladribine. Furthermore, like the MS-treatment azathioprine, trifluridine is a nucleic acid synthesis inhibitor and nucleoside analog. Additionally, the immunosuppressant methotrexate is an effective therapy for MS [@10.1002/14651858.CD003208.pub2]. While the exact mechanism of methotrexate's efficacy against MS remains elusive [@10.1177/1756285610379885], our prediction highlights the potential involvement of thymidylate synthetase (_TYMS_).\r\n\r\n![trifluridine-ms](https://cloud.githubusercontent.com/assets/1117703/18218457/d91644c4-7130-11e6-996b-6e8781281943.png)\r\n\r\nIn conclusion, Project Rephetio identified three categories of disease -- neoplastic, autoimmune, and viral -- where trifluridine may exhibit efficacy. While little literature existed which probed the non-cancer applications, this appears to be an area of ongoing and relentless discovery.",
      "comment_id": 1349,
      "profile_id": 17,
      "published": "2016-09-03T00:11:13.262634Z",
      "thread_id": 203,
      "url": "/discussion/predictions-of-whether-a-compound-treats-a-disease/203#10"
    },
    {
      "body_html": "<p>In seeking other examples, I perused somewhat randomly the top predictions of three diseases that I'm familiar with. I think it would be a very difficult process to evaluate diseases that I'm not familiar with. </p>\r\n\r\n<p>Epilepsy:<br>The top ~45 indications, all  have score greater than 10. The distribution of scores seems much higher than in other diseases. <br>scores 50-60 — 4 indications<br>scores 40-50 — 8 indications<br>scores 30-40 — 8 indications<br>scores 20-30 — 9 indications<br>scores 10-20 — 14 indications<br>Of the top ~45, all but 2 are clinically classified as \"anti-epileptics\" so that's excellent! There are three of interest:<br>– Sevoflurane is not known as an \"anti-epileptic\". But sevoflurane is an Anesthetic with rather incompletely known mechanism of action. At least a handful of other anesthetics have been repurposed for epilepsy. The mechanism of action could involve GABA receptors.<br>– Amitriptyline (score 25, 98.4 percentile) is actually relatively contraindicated in epilepsy, it can worsen epilepsy. potentially interesting to explore the mechanism why this drug was picked.<br>– Tiagabine (score 28, 98.6 percentile) I believe was mis-categorized as a \"NOT\" by all three reviewers, sadly. I think should have been a DM based on the rules.</p>\r\n\r\n<p>Multiple Sclerosis:<br>The distribution of scores is much lower.<br>Scores 10-15  — 3 indications<br>Scores 5-10    — 6 indications<br>Of these top 9, I think 7 are steroids so that makes sense. Here are the others:<br>– Clofarabine. It's a chemotherapy for cancers of leukocytes. Chemotherapies for leukocyte cancers have been previously repurposed for MS (like Rituximab and Ocrelizumab for example)<br>– Pemetrexed is a chemotherapy for small cell lung cancer (among others). Chemotherapies as a large class have been previously repurposed for MS. .</p>\r\n\r\n<p>Migraine:<br>Scores 30-40  — 1 indication<br>Scores 20-30  — 1 indication<br>Scores 10-20  — 6 indications<br>Scores 5-10 — 14 indications<br>– Oxcarbazepine, top score 33, was an outlier score, but as we have seen above the score is often less relevant than the rank. Still, I looked further into it, apparently people did believe in it (it is of a class that had already been successfully repurposed for migraine), but it failed after multiple trials. <br>All the drugs with score &gt;5 are of known drug classes that have been successfully repurposed for migraine (anti-epileptics, neuroleptics, TCAs, B-blockers, SSRI).</p>\r\n\r\n<p>In summary, the top scores come from drugs that are good candidates because they belong to a drug class that has already been repurposed for a given indication. I have not dug deep enough to find a \"novel idea\" (a repurposing suggestion for a drug that is not already in a class of drugs that has been previously repurposed successfully). In searching for a novel idea, I can think of two approaches<br>1. delve deeper into lower scores and lower percentiles in each disease, specifically scores less than 5, and percentiles less than 95%.<br>2. look for high-score / high-percentile \"novel ideas\" in all the other diseases. This would require massive user input (Ari, Chrissy, and I working together would probably require like 30 solid days of work). But it could be automated.</p>",
      "body_md": "In seeking other examples, I perused somewhat randomly the top predictions of three diseases that I'm familiar with. I think it would be a very difficult process to evaluate diseases that I'm not familiar with. \r\n\r\nEpilepsy:\r\nThe top ~45 indications, all  have score greater than 10. The distribution of scores seems much higher than in other diseases. \r\nscores 50-60 -- 4 indications\r\nscores 40-50 -- 8 indications\r\nscores 30-40 -- 8 indications\r\nscores 20-30 -- 9 indications\r\nscores 10-20 -- 14 indications\r\nOf the top ~45, all but 2 are clinically classified as \"anti-epileptics\" so that's excellent! There are three of interest:\r\n-- Sevoflurane is not known as an \"anti-epileptic\". But sevoflurane is an Anesthetic with rather incompletely known mechanism of action. At least a handful of other anesthetics have been repurposed for epilepsy. The mechanism of action could involve GABA receptors.\r\n-- Amitriptyline (score 25, 98.4 percentile) is actually relatively contraindicated in epilepsy, it can worsen epilepsy. potentially interesting to explore the mechanism why this drug was picked.\r\n-- Tiagabine (score 28, 98.6 percentile) I believe was mis-categorized as a \"NOT\" by all three reviewers, sadly. I think should have been a DM based on the rules.\r\n\r\nMultiple Sclerosis:\r\nThe distribution of scores is much lower.\r\nScores 10-15  -- 3 indications\r\nScores 5-10    -- 6 indications\r\nOf these top 9, I think 7 are steroids so that makes sense. Here are the others:\r\n-- Clofarabine. It's a chemotherapy for cancers of leukocytes. Chemotherapies for leukocyte cancers have been previously repurposed for MS (like Rituximab and Ocrelizumab for example)\r\n-- Pemetrexed is a chemotherapy for small cell lung cancer (among others). Chemotherapies as a large class have been previously repurposed for MS. .\r\n\r\nMigraine:\r\nScores 30-40  -- 1 indication\r\nScores 20-30  -- 1 indication\r\nScores 10-20  -- 6 indications\r\nScores 5-10 -- 14 indications\r\n-- Oxcarbazepine, top score 33, was an outlier score, but as we have seen above the score is often less relevant than the rank. Still, I looked further into it, apparently people did believe in it (it is of a class that had already been successfully repurposed for migraine), but it failed after multiple trials. \r\nAll the drugs with score >5 are of known drug classes that have been successfully repurposed for migraine (anti-epileptics, neuroleptics, TCAs, B-blockers, SSRI).\r\n\r\nIn summary, the top scores come from drugs that are good candidates because they belong to a drug class that has already been repurposed for a given indication. I have not dug deep enough to find a \"novel idea\" (a repurposing suggestion for a drug that is not already in a class of drugs that has been previously repurposed successfully). In searching for a novel idea, I can think of two approaches\r\n1. delve deeper into lower scores and lower percentiles in each disease, specifically scores less than 5, and percentiles less than 95%.\r\n2. look for high-score / high-percentile \"novel ideas\" in all the other diseases. This would require massive user input (Ari, Chrissy, and I working together would probably require like 30 solid days of work). But it could be automated.",
      "comment_id": 1350,
      "profile_id": 188,
      "published": "2016-09-05T17:21:56.009814Z",
      "thread_id": 203,
      "url": "/discussion/predictions-of-whether-a-compound-treats-a-disease/203#11"
    },
    {
      "body_html": "<h1>Epilepsy</h1>\r\n\r\n<p><a href=\"/u/pouyakhankhanian\" class=\"username\">@pouyakhankhanian</a>, that's exciting to hear our top <a href=\"http://het.io/repurpose/browse.html?id=DOID_1826\" title=\"Project Rephetio Predictions for epilepsy\">epilepsy predictions</a> (above 10%) had a precision of 95.5% (43 / 45). Epilepsy seems to be an interesting disease because despite the many established therapies, there's still a large portion of patients  with seizures that are uncontrolled by current medications <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nrd4126\" class=\"citation\" data-key=\"10.1038/nrd4126\">1</a>]</span>.</p>\r\n\r\n<h2>Tiagabine–Epilepsy</h2>\r\n\r\n<p>Tiagabine was classified as a non-indication in PharmacotherapyDB v1.0, but is used to treat epilepsy <span class=\"citation\">[<a href=\"https://doi.org/10.2147/NDT.S833\" class=\"citation\" data-key=\"10.2147/NDT.S833\">2</a>]</span>. However, in some settings tiagabine may also trigger seizures <span class=\"citation\">[<a href=\"https://doi.org/10.1056/NEJMc055301\" class=\"citation\" data-key=\"10.1056/NEJMc055301\">3</a>]</span>. This example brings up an interesting consideration: many anti-epileptic drugs may also be epileptogenic (epilepsy inducing) depending on the context <span class=\"citation\">[<a href=\"https://doi.org/10.1016/S0387-7604(99)00113-8\" class=\"citation\" data-key=\"10.1016/S0387-7604(99)00113-8\">4</a>]</span>.</p>\r\n\r\n<h2>Amitriptyline–Epilepsy</h2>\r\n\r\n<p><a href=\"/u/pouyakhankhanian\" class=\"username\">@pouyakhankhanian</a> brought up that amitriptyline is contraindicated for epilepsy. Accordingly, several studies suggest that amitriptyline causes seizures <span class=\"citation\">[<a href=\"https://doi.org/10.1016/S0140-6736(68)91356-1\" class=\"citation\" data-key=\"10.1016/S0140-6736(68)91356-1\">5</a>, <a href=\"https://doi.org/10.1191/0960327106ht511oa\" class=\"citation\" data-key=\"10.1191/0960327106ht511oa\">6</a>, <a href=\"https://doi.org/10.1176/ajp.137.11.1461\" class=\"citation\" data-key=\"10.1176/ajp.137.11.1461\">7</a>]</span>. Our approach found the following <a href=\"https://neo4j.het.io/browser/?cmd=play&amp;arg=https://neo4j.het.io/guides/rep/DB00321/DOID_1826.html\" title=\"Hetionet Browser: amitriptyline--epilepsy prediction\">support for</a> amitriptyline treating epilepsy:</p>\r\n\r\n<ul><li>21.5% of the prediction resulted from: Amitriptyline–treats–Migraine–resembles–Epilepsy</li><li>15.2% of the Amitriptyline–resembles–Oxcarbazepine–treats–Epilepsy</li><li>Many other paths of the following metapaths also contributed: CbGaD, CpDpCtD, CrCrCtD, CbGbCtD</li></ul>\r\n\r\n<p>It's likely that our method cannot fully differentiate between indications and contraindications. In other words, certain paths may increase the probability of indication and contraindication similarly and our predictions may also enrich for detrimental therapies.</p>\r\n\r\n<h2>Sevoflurane–Epilepsy</h2>\r\n\r\n<p>Regarding the <a href=\"https://neo4j.het.io/browser/?cmd=play&amp;arg=https://neo4j.het.io/guides/rep/DB01236/DOID_1826.html\" title=\"Hetionet Browser: sevoflurane--epilepsy prediction\">prediction</a> that sevoflurane treats epilepsy, this is the top <a href=\"http://het.io/repurpose/browse.html?id=DB01236\">prediction for sevoflurane</a> and is in the 97.3rd percentile for epilepsy. Here are the top ten paths supporting this prediction:</p>\r\n\r\n<p><img src=\"https://cloud.githubusercontent.com/assets/1117703/18256790/2c9d1312-7388-11e6-8c33-873058fc4965.png\" alt=\"sevoflurane-epilepsy\"></p>\r\n\r\n<p>However contrary to our prediction, I did find some evidence that sevoflurane could be epileptogenic <span class=\"citation\">[<a href=\"https://doi.org/10.1111/j.1460-9592.2004.01538.x\" class=\"citation\" data-key=\"10.1111/j.1460-9592.2004.01538.x\">8</a>, <a href=\"https://doi.org/10.1097/00000539-200010000-00041\" class=\"citation\" data-key=\"10.1097/00000539-200010000-00041\">9</a>, <a href=\"https://doi.org/10.1093/bja/aes027\" class=\"citation\" data-key=\"10.1093/bja/aes027\">10</a>]</span>. However, potentially a bigger concern is whether sevoflurane has appropriate pharmacokinetics for epilepsy. According to DrugBank (<a href=\"http://www.drugbank.ca/drugs/DB01236\"><code>DB01236</code></a>), sevoflurane does cross the blood–brain barrier which is important. However, sevoflurane is volatile and administered via inhalation. Now, this may not always be a disqualifying factor. For example, some pharmaceutical companies are more interested in \"drug repositioning aided by reformulation\" than solely repositioning <span class=\"citation\">[<a href=\"https://doi.org/10.3402/jmahp.v1i0.21131\" class=\"citation\" data-key=\"10.3402/jmahp.v1i0.21131\">11</a>]</span>. However, in this case, I just don't know.</p>",
      "body_md": "# Epilepsy\r\n\r\n@pouyakhankhanian, that's exciting to hear our top [epilepsy predictions](http://het.io/repurpose/browse.html?id=DOID_1826 \"Project Rephetio Predictions for epilepsy\") (above 10%) had a precision of 95.5% (43 / 45). Epilepsy seems to be an interesting disease because despite the many established therapies, there's still a large portion of patients  with seizures that are uncontrolled by current medications [@10.1038/nrd4126].\r\n\r\n## Tiagabine--Epilepsy\r\n\r\nTiagabine was classified as a non-indication in PharmacotherapyDB v1.0, but is used to treat epilepsy [@10.2147/NDT.S833]. However, in some settings tiagabine may also trigger seizures [@10.1056/NEJMc055301]. This example brings up an interesting consideration: many anti-epileptic drugs may also be epileptogenic (epilepsy inducing) depending on the context [@10.1016/S0387-7604(99)00113-8].\r\n\r\n## Amitriptyline--Epilepsy\r\n\r\n@pouyakhankhanian brought up that amitriptyline is contraindicated for epilepsy. Accordingly, several studies suggest that amitriptyline causes seizures [@10.1016/S0140-6736(68)91356-1 @10.1191/0960327106ht511oa @10.1176/ajp.137.11.1461]. Our approach found the following [support for](https://neo4j.het.io/browser/?cmd=play&arg=https://neo4j.het.io/guides/rep/DB00321/DOID_1826.html \"Hetionet Browser: amitriptyline--epilepsy prediction\") amitriptyline treating epilepsy:\r\n\r\n+ 21.5% of the prediction resulted from: Amitriptyline--treats--Migraine--resembles--Epilepsy\r\n+ 15.2% of the Amitriptyline--resembles--Oxcarbazepine--treats--Epilepsy\r\n+ Many other paths of the following metapaths also contributed: CbGaD, CpDpCtD, CrCrCtD, CbGbCtD\r\n\r\nIt's likely that our method cannot fully differentiate between indications and contraindications. In other words, certain paths may increase the probability of indication and contraindication similarly and our predictions may also enrich for detrimental therapies.\r\n\r\n## Sevoflurane--Epilepsy\r\n\r\nRegarding the [prediction](https://neo4j.het.io/browser/?cmd=play&arg=https://neo4j.het.io/guides/rep/DB01236/DOID_1826.html \"Hetionet Browser: sevoflurane--epilepsy prediction\") that sevoflurane treats epilepsy, this is the top [prediction for sevoflurane](http://het.io/repurpose/browse.html?id=DB01236) and is in the 97.3rd percentile for epilepsy. Here are the top ten paths supporting this prediction:\r\n\r\n![sevoflurane-epilepsy](https://cloud.githubusercontent.com/assets/1117703/18256790/2c9d1312-7388-11e6-8c33-873058fc4965.png)\r\n\r\nHowever contrary to our prediction, I did find some evidence that sevoflurane could be epileptogenic [@10.1111/j.1460-9592.2004.01538.x @10.1097/00000539-200010000-00041 @10.1093/bja/aes027]. However, potentially a bigger concern is whether sevoflurane has appropriate pharmacokinetics for epilepsy. According to DrugBank ([`DB01236`](http://www.drugbank.ca/drugs/DB01236)), sevoflurane does cross the blood–brain barrier which is important. However, sevoflurane is volatile and administered via inhalation. Now, this may not always be a disqualifying factor. For example, some pharmaceutical companies are more interested in \"drug repositioning aided by reformulation\" than solely repositioning [@10.3402/jmahp.v1i0.21131]. However, in this case, I just don't know.",
      "comment_id": 1351,
      "profile_id": 17,
      "published": "2016-09-06T19:31:34.269795Z",
      "thread_id": 203,
      "url": "/discussion/predictions-of-whether-a-compound-treats-a-disease/203#12"
    },
    {
      "body_html": "<h1>Clofarabine</h1>\r\n\r\n<p>Clofarabine (<a href=\"http://www.drugbank.ca/drugs/DB00631\" title=\"Clofarabine on DrugBank\"><code>DB00631</code></a>) is a purine nucleoside analogue, which was approved in 2004 for special cases of paediatric leukaemia <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nrd2055\" class=\"citation\" data-key=\"10.1038/nrd2055\">1</a>, <a href=\"https://doi.org/10.2147/btt.s10123\" class=\"citation\" data-key=\"10.2147/btt.s10123\">2</a>, <a href=\"https://doi.org/10.1016/j.bcp.2009.06.094\" class=\"citation\" data-key=\"10.1016/j.bcp.2009.06.094\">3</a>]</span> Our top <a href=\"http://het.io/repurpose/browse.html?id=DB00631\" title=\"Project Rephetio predictions for Clofarabine\">prediction for clofarabine</a>  at 18.5% is hematologic cancer — a superterm of its approved indication, which is included in the network as a disease-modifying indication. At 10.2% the second prediction is lymphatic system cancer, which has been investigated by 14 trials.</p>\r\n\r\n<p>The third prediction is multiple sclerosis (MS) at 8.80%, representing a 24-fold enrichment over the null probability. MS is the only non-cancer prediction for clofarabine in the top 10. Furthermore, clofarabine is the fourth highest <a href=\"http://het.io/repurpose/browse.html?id=DOID_2377\" title=\"Project Rephetio predictions for multiple sclerosis\">MS prediction</a> with the three higher predictions corresponding to known disease-modifying therapies. Hetnet support for <a href=\"https://neo4j.het.io/browser/?cmd=play&amp;arg=https://neo4j.het.io/guides/rep/DB00631/DOID_2377.html\" title=\"Hetionet Browser: support for treating multiple sclerosis with clofarabine\">the prediction</a> is shown below:</p>\r\n\r\n<p><img src=\"https://cloud.githubusercontent.com/assets/1117703/18327558/1ed9d890-7519-11e6-8127-773e7cb64746.png\" alt=\"clofarabine-ms\" title=\"Visualizing the prediction that Clofarabine treats multiple sclerosis\"></p>\r\n\r\n<p>Clofarabine is a hybrid of cladribine and fludarabine <span class=\"citation\">[<a href=\"https://doi.org/10.2147/btt.s10123\" class=\"citation\" data-key=\"10.2147/btt.s10123\">2</a>, <a href=\"https://doi.org/10.1182/blood-2003-06-2122\" class=\"citation\" data-key=\"10.1182/blood-2003-06-2122\">4</a>]</span> as detected by Hetionet's chemical resemblance relationships. Cladribine showed promising phase 3 results and was approved in Australia and Russia before being withdrawn due to safety concerns <span class=\"citation\">[<a href=\"https://doi.org/10.1056/NEJMoa0902533\" class=\"citation\" data-key=\"10.1056/NEJMoa0902533\">5</a>, <a href=\"https://doi.org/10.1080/14737175.2016.1176531\" class=\"citation\" data-key=\"10.1080/14737175.2016.1176531\">6</a>]</span> (see more discussion on cladribine for MS <a href=\"#10\">above</a>. Our method picked up on the similarities between cladribine and clofarabine, both in terms of structure and targets. A recent phase II add-on study,  found that fludarabine may be have greater efficacy against MS than methylprednisolone <span class=\"citation\">[<a href=\"https://doi.org/10.1177/1756285615626049\" class=\"citation\" data-key=\"10.1177/1756285615626049\">7</a>]</span>. In addition, clofarabine is a nucleic acid synthesis inhibitor like azathioprine — an effective multiple sclerosis treatment <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pone.0113371\" class=\"citation\" data-key=\"10.1371/journal.pone.0113371\">8</a>]</span>. Clofarabine relies on deoxycytidine kinase (<em>DCK</em> gene) for intracellular phosphorylation and activation <span class=\"citation\">[<a href=\"https://doi.org/10.1107/S0907444905034293\" class=\"citation\" data-key=\"10.1107/S0907444905034293\">9</a>]</span></p>\r\n\r\n<p>While I didn't see any trials for clofarabine in MS, purine nucleoside analogues have had success in autoimmune disease <span class=\"citation\">[<a href=\"https://doi.org/10.2174/092986706778742918\" class=\"citation\" data-key=\"10.2174/092986706778742918\">10</a>]</span>. Additionally, US Patent <a href=\"https://www.google.com/patents/US7772206\" title=\"Methods and compositions for the treatment of autoimmune disorders using clofarabine\">US7772206</a> claims the following application for clofarabine:</p>\r\n\r\n<blockquote><p>In a preferred embodiment, the invention encompasses a method for treating, preventing, or managing multiple sclerosis utilizing doses higher than 1 mg/kg per day, preferably higher than 1.25 mg/kg per day.</p></blockquote>",
      "body_md": "# Clofarabine\r\n\r\nClofarabine ([`DB00631`](http://www.drugbank.ca/drugs/DB00631 \"Clofarabine on DrugBank\")) is a purine nucleoside analogue, which was approved in 2004 for special cases of paediatric leukaemia [@10.1038/nrd2055 @10.2147/btt.s10123 @10.1016/j.bcp.2009.06.094] Our top [prediction for clofarabine](http://het.io/repurpose/browse.html?id=DB00631 \"Project Rephetio predictions for Clofarabine\")  at 18.5% is hematologic cancer -- a superterm of its approved indication, which is included in the network as a disease-modifying indication. At 10.2% the second prediction is lymphatic system cancer, which has been investigated by 14 trials.\r\n\r\nThe third prediction is multiple sclerosis (MS) at 8.80%, representing a 24-fold enrichment over the null probability. MS is the only non-cancer prediction for clofarabine in the top 10. Furthermore, clofarabine is the fourth highest [MS prediction](http://het.io/repurpose/browse.html?id=DOID_2377 \"Project Rephetio predictions for multiple sclerosis\") with the three higher predictions corresponding to known disease-modifying therapies. Hetnet support for [the prediction](https://neo4j.het.io/browser/?cmd=play&arg=https://neo4j.het.io/guides/rep/DB00631/DOID_2377.html \"Hetionet Browser: support for treating multiple sclerosis with clofarabine\") is shown below:\r\n\r\n![clofarabine-ms](https://cloud.githubusercontent.com/assets/1117703/18327558/1ed9d890-7519-11e6-8127-773e7cb64746.png \"Visualizing the prediction that Clofarabine treats multiple sclerosis\")\r\n\r\nClofarabine is a hybrid of cladribine and fludarabine [@10.2147/btt.s10123 @10.1182/blood-2003-06-2122] as detected by Hetionet's chemical resemblance relationships. Cladribine showed promising phase 3 results and was approved in Australia and Russia before being withdrawn due to safety concerns [@10.1056/NEJMoa0902533 @10.1080/14737175.2016.1176531] (see more discussion on cladribine for MS [above](#10). Our method picked up on the similarities between cladribine and clofarabine, both in terms of structure and targets. A recent phase II add-on study,  found that fludarabine may be have greater efficacy against MS than methylprednisolone [@10.1177/1756285615626049]. In addition, clofarabine is a nucleic acid synthesis inhibitor like azathioprine — an effective multiple sclerosis treatment [@10.1371/journal.pone.0113371]. Clofarabine relies on deoxycytidine kinase (_DCK_ gene) for intracellular phosphorylation and activation [@10.1107/S0907444905034293]\r\n\r\nWhile I didn't see any trials for clofarabine in MS, purine nucleoside analogues have had success in autoimmune disease [@10.2174/092986706778742918]. Additionally, US Patent [US7772206](https://www.google.com/patents/US7772206 \"Methods and compositions for the treatment of autoimmune disorders using clofarabine\") claims the following application for clofarabine:\r\n\r\n> In a preferred embodiment, the invention encompasses a method for treating, preventing, or managing multiple sclerosis utilizing doses higher than 1 mg/kg per day, preferably higher than 1.25 mg/kg per day.",
      "comment_id": 1352,
      "profile_id": 17,
      "published": "2016-09-07T21:28:37.016018Z",
      "thread_id": 203,
      "url": "/discussion/predictions-of-whether-a-compound-treats-a-disease/203#13"
    },
    {
      "body_html": "<p>The epilepsy discussion has been moved to:<br><a href=\"https://thinklab.com/discussion/prediction-in-epilepsy/224#2\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d224\">https://thinklab.com/discussion/prediction-in-epilepsy/224#2</a></p>",
      "body_md": "The epilepsy discussion has been moved to:\r\nhttps://thinklab.com/discussion/prediction-in-epilepsy/224#2",
      "comment_id": 1354,
      "profile_id": 188,
      "published": "2016-09-10T18:06:26.163486Z",
      "thread_id": 203,
      "url": "/discussion/predictions-of-whether-a-compound-treats-a-disease/203#14"
    },
    {
      "body_html": "<p>This is a branch of the <a href=\"https://thinklab.com/discussion/predictions-of-whether-a-compound-treats-a-disease/203\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d203\">discussion of predictions of hetnet</a>.</p>",
      "body_md": "This is a branch of the [discussion of predictions of hetnet](https://thinklab.com/discussion/predictions-of-whether-a-compound-treats-a-disease/203).",
      "comment_id": 1355,
      "profile_id": 188,
      "published": "2016-09-19T04:35:42.366864Z",
      "thread_id": 224,
      "url": "/discussion/prediction-in-epilepsy/224"
    },
    {
      "body_html": "<h1>Case Discussion of Epilepsy</h1>\r\n\r\n<h2>Why epilepsy is a good case disease to study in further detail</h2>\r\n\r\n<p>Epilepsy represents a unique case disease for us to evaluate in this project for several reasons. First, it is within the field of expertise of the three clinician collaborators (neurology). Second, a large majority of drugs undergone evaluation for repurposing in epilepsy; this means we largely know which drugs are epileptogenic (exacerbate epilepsy) and which are anti-epileptic (AEDs, drugs given in epilepsy). Thus study of this disease is a good way to validate the predictions of the rephetio project. Third, the distribution of high-scoring predictions in this disease were higher than most. This allows us to characterize the association between prediction score and likelihood of successful drug repurposing (see Daniel's post below for citations). It should be noted that it is unclear if the results seen in epilepsy would necessarily generalizable to other diseases. It would also be prudent to evaluate whether diseases with a large number of high-scoring predictions are the same diseases which had a large number of input disease-drug connections (which is certainly true in epilepsy). Perhaps it is a case of more information in, more information out, and if so it would be nice to characterize this. </p>\r\n\r\n<p>I believe it is important for drug-predictions within a given disease to be evaluated by an appropriate clinical specialists. The clinicians collaborating on this project (including myself) are all neurologists by training. I personally find it extremely difficult to evaluate drug predictions for non-neurologic diseases, I would estimate it requires 10x more time for me to research and evaluate each prediction in a non-neurologic disease. Epilepsy is one of the most commonly encountered neurologic diseases in clinic, and I do feel we are fit to evaluate it efficiently and expertly. </p>\r\n\r\n<p>Repurposing is more advanced in epilepsy than the majority of other human diseases, we know whether most drugs improve or exacerbate epilepsy. Small animal models of epilepsy are incredibly quick and inexpensive and rather highly applicable to humans. Anti-epileptics work in a dose dependent manner to increase the seizure threshold. The seizure threshold is the amount of electric stimulation that is required to induce seizure. Experimentally, this is done in small animal models by providing graduated increasing electric stimulation until a seizure is attained. The results are generally highly reproducible and thus it requires a very small number of animals. The results are often reproducible between species, further decreasing cost. Furthermore, within the same experiment, one can determine whether a medication would exacerbate epilepsy, these are the drugs that lower the seizure threshold. Given the relatively inexpensive (time and money) nature of pharmacologic testing in epilepsy, drug companies have already attempted drug-repurposing experiments on vast arrays of drugs. Thus, we have a large degree of information about which drugs would possibly work in epilepsy. This makes epilepsy an interesting case to study when looking to validate our repurposing rankings. (there are good reviews cited by Daniel below)</p>\r\n\r\n<p>Epilepsy is an outlier for prediction scores. It is the only disease where 1% of drugs had a prediction score higher than 0.35. In the attached pdf, I plotted the distribution of disease scores for each disease, and I'll make a few observations as a digression from epilepsy: hypertension and asthma also have large numbers of drugs with high prediction scores, we see that the highest single predicted scores are not in epilepsy, some diseases such as Paget's disease of bone have a few very highly predicted drugs but overall a low distribution of drug scores. It would also be prudent to evaluate whether diseases with a large number of high-scoring predictions are the same diseases which had a large number of input disease-drug connections (which is certainly true in epilepsy). This is certainly true in hypertension and asthma.</p>\r\n\r\n<h2>Epilepsy case study</h2>\r\n\r\n<p>The top 100 drug predictions for epielpsy were reviewed (henceforth called \"predicted\" drugs). This represents the top 7% of drugs predicted for epilepsy (93rd percentile and higher). </p>\r\n\r\n<p>The attached powerpoint figure one shows the percent of predicted drugs that are known Anti-Epileptic drugs (AEDs), are known to have antiepileptic activity (raise the seizure threshold), are known to be harmful in epilepsy (lower the seizure threshold), or have no prior evidence (\"unknown\"). The top 1% of predicted drugs are all known AEDs (17/17, 100%); these have prediction scores greater than 0.35. Of the top 3% of predicted drugs, the overwhelming majority (45/47, 95%) are known AEDs; these have prediction scores greater than 0.09. As we get deeper into the rankings of predicted drugs, we see an increasingly larger percentage of unknown drugs and drugs that lower the seizure threshold. By the 94th percentile, about 40% of the predicted drugs are known AEDs or have known antiepileptic properties, about 47% have unknown epileptic properties, and about 13% are known to lower the seizure threshold; the prediction scores here are around 0.03 to 0.04.</p>\r\n\r\n<p>Of the top 100 drugs, 69 are primary AEDs (AEDs that are primarily used in epilepsy), another 7 have known antiepileptic properties. Thus over three quarters (76/100, 76%) are anti-epileptics or known to have antiepileptic properties. An important minority of drugs lower the seizure threshold (15/100, 15%). The remaining drugs are unknown in epilepsy (9/100, 8%). All drugs which are not AEDs are dicussed below:</p>\r\n\r\n<h5>Drugs known anti-epileptic properties</h5>\r\n\r\n<p>The seven drugs with known anti epileptic properties include three carbonic anhydrase inhibitors (methazolamide, acetazolamide, and diclofenamide), one calcium channel blocker (verapamil), and one sodium channel blocker (Ranolazine). The other two medications are indapamide and modafinil, the mechanism of action of these two drugs in increasing the seizure threshold is unknown.</p>\r\n\r\n<h5>Drugs that induce seizures</h5>\r\n\r\n<p>The 15 predicted drugs that are known to induce seizures include five are tricyclic antidepressants (TCAs) (amitriptyline, imipramine, nortriptyline, clomipramine, desipramine) three are monoamine oxidate inhibitors (MAOIs) (isocarboxazid, phenelzine, amoxapine), and two are antipsychotics (clozapine and Loxapine) and one is an antihistamine (cyproheptadine). The reason amitriptyline was chosen was explored in the discussion above, and highlights one of the limitations of our method. The TCAs are known to act on GABA-R, which is known to be important in epilepsy (also the TCAs treat migraine and many migraine drugs are also AEDs). The limitation of our method is that it does not differentiate the direction of effect on GABA-R (agonistic versus antagonistic), and thus our method suggests TCAs may treat epilepsy. I suspect the reason MAOIs and antipsychotics were chosen is similar. The other predicted drugs that are known to lower the seizure threshold are antipyrine (an analgesic), dalfampridine (K-channel antagonist), baclofen (inhibits the transmission of both monosynaptic and polysynaptic reflexes at the spinal cord level, possibly by hyperpolarization of primary afferent fiber terminals), and memantine (anti-NMDA). </p>\r\n\r\n<h5>Drugs with unknown effect on epilepsy</h5>\r\n\r\n<p><strong>Halogenated ethers (Sevoflurane, Desflurane, and Enflurane)</strong>: These are inhaled anesthetics. Some of the halogenated ethers are used in refractory status epilepticus (RSE), such as isoflurane (classified as an AED). Desflurane is also used in RSE, this should likely be reclassified as an AED before we make our final figures/tables. Enflurane and sevoflurane withdrawal can also cause seizures, suggesting that these drugs may have anti-epileptic properties. </p>\r\n\r\n<p>Here's the quote form a review <span class=\"citation\">[<a href=\"https://doi.org/10.1093/bja/aes027\" class=\"citation\" data-key=\"10.1093/bja/aes027\">1</a>]</span>: </p>\r\n\r\n<blockquote><p>There are multiple case reports of sevoflurane-provoking seizure-like activity, particularly in children <span class=\"citation\">[<a href=\"https://doi.org/10.1111/j.1460-9592.2004.01538.x\" class=\"citation\" data-key=\"10.1111/j.1460-9592.2004.01538.x\">2</a>]</span> and where high concentrations are used in conjunction with hypocapnea <span class=\"citation\">[<a href=\"https://doi.org/10.1007/BF03022961\" class=\"citation\" data-key=\"10.1007/BF03022961\">3</a>]</span>. In high concentration, enflurane exhibits periods of suppression with paroxysmal epileptiform discharges in cats and rats <span class=\"citation\">[<a href=\"https://doi.org/10.1213/ANE.0b013e3181add06b\" class=\"citation\" data-key=\"10.1213/ANE.0b013e3181add06b\">4</a>]</span>. There have been multiple reports of seizure activity in humans after enflurane anaesthesia <span class=\"citation\">[<a href=\"https://doi.org/10.1213/00000539-199003000-00013\" class=\"citation\" data-key=\"10.1213/00000539-199003000-00013\">5</a>, <a href=\"https://doi.org/10.1097/00000542-198008000-00014\" class=\"citation\" data-key=\"10.1097/00000542-198008000-00014\">6</a>]</span>. Isoflurane has well-characterized anticonvulsant properties. Both isoflurane and desflurane can be used in refractory status epilepticus <span class=\"citation\">[<a href=\"https://doi.org/10.1001/archneur.61.8.1254\" class=\"citation\" data-key=\"10.1001/archneur.61.8.1254\">7</a>]</span> [the worst end of the epilepsy spectrum].</p></blockquote>\r\n\r\n<p><strong>Glutethimidie</strong>: This is potentially a good choice, it is a GABA agonist anesthetic which makes it a good candidate for repurposing for epilepsy. The prediction score was 0.08 and the percentile was 96th. It is an anesthetic (similar to thalidomide).</p>\r\n\r\n<p><strong>Acamprosate</strong>: This drug appears to work in promoting alcohol abstinence by acting as a GABA agonist, which makes it a good candidate for repurposing for epilepsy. The side effect profile is also reasonable. Further, if it is demonstrated to have antiepileptic, it may serve a dual benefit for recovering alcoholics (promoting alcohol abstinence while also perhaps preventing alcohol-associted seizures). The prediction score was 0.03 and the percentile ws 93rd. </p>\r\n\r\n<p><strong>Chlorthalidone</strong>: This is a blood pressure medication that acts on Na-Cl channels, potentially related to epilepsy. Other blood pressure medications (albeit of different classes) have been repurposed for epilepsy, as described in the section above). The prediction score was 0.04 and the percentile was 95th. </p>\r\n\r\n<p><strong>Phenazopyridine</strong>: a urinary analgesic which is excreted rapidly in the urine and is unlikely to have any clinical effect. </p>\r\n\r\n<p><strong>Antineoplastic agents (dabrafenib and bortezomib)</strong>: These are poor choices due to the adverse side effect profiles.</p>\r\n\r\n<p>Of note, I did not consider the drug Quinidine barbiurate, as this is a combination drug which is poorly handled by our analysis pipeline.</p>",
      "body_md": "# Case Discussion of Epilepsy\r\n\r\n## Why epilepsy is a good case disease to study in further detail\r\n\r\nEpilepsy represents a unique case disease for us to evaluate in this project for several reasons. First, it is within the field of expertise of the three clinician collaborators (neurology). Second, a large majority of drugs undergone evaluation for repurposing in epilepsy; this means we largely know which drugs are epileptogenic (exacerbate epilepsy) and which are anti-epileptic (AEDs, drugs given in epilepsy). Thus study of this disease is a good way to validate the predictions of the rephetio project. Third, the distribution of high-scoring predictions in this disease were higher than most. This allows us to characterize the association between prediction score and likelihood of successful drug repurposing (see Daniel's post below for citations). It should be noted that it is unclear if the results seen in epilepsy would necessarily generalizable to other diseases. It would also be prudent to evaluate whether diseases with a large number of high-scoring predictions are the same diseases which had a large number of input disease-drug connections (which is certainly true in epilepsy). Perhaps it is a case of more information in, more information out, and if so it would be nice to characterize this. \r\n\r\nI believe it is important for drug-predictions within a given disease to be evaluated by an appropriate clinical specialists. The clinicians collaborating on this project (including myself) are all neurologists by training. I personally find it extremely difficult to evaluate drug predictions for non-neurologic diseases, I would estimate it requires 10x more time for me to research and evaluate each prediction in a non-neurologic disease. Epilepsy is one of the most commonly encountered neurologic diseases in clinic, and I do feel we are fit to evaluate it efficiently and expertly. \r\n\r\nRepurposing is more advanced in epilepsy than the majority of other human diseases, we know whether most drugs improve or exacerbate epilepsy. Small animal models of epilepsy are incredibly quick and inexpensive and rather highly applicable to humans. Anti-epileptics work in a dose dependent manner to increase the seizure threshold. The seizure threshold is the amount of electric stimulation that is required to induce seizure. Experimentally, this is done in small animal models by providing graduated increasing electric stimulation until a seizure is attained. The results are generally highly reproducible and thus it requires a very small number of animals. The results are often reproducible between species, further decreasing cost. Furthermore, within the same experiment, one can determine whether a medication would exacerbate epilepsy, these are the drugs that lower the seizure threshold. Given the relatively inexpensive (time and money) nature of pharmacologic testing in epilepsy, drug companies have already attempted drug-repurposing experiments on vast arrays of drugs. Thus, we have a large degree of information about which drugs would possibly work in epilepsy. This makes epilepsy an interesting case to study when looking to validate our repurposing rankings. (there are good reviews cited by Daniel below)\r\n\r\nEpilepsy is an outlier for prediction scores. It is the only disease where 1% of drugs had a prediction score higher than 0.35. In the attached pdf, I plotted the distribution of disease scores for each disease, and I'll make a few observations as a digression from epilepsy: hypertension and asthma also have large numbers of drugs with high prediction scores, we see that the highest single predicted scores are not in epilepsy, some diseases such as Paget's disease of bone have a few very highly predicted drugs but overall a low distribution of drug scores. It would also be prudent to evaluate whether diseases with a large number of high-scoring predictions are the same diseases which had a large number of input disease-drug connections (which is certainly true in epilepsy). This is certainly true in hypertension and asthma.\r\n\r\n## Epilepsy case study\r\n\r\nThe top 100 drug predictions for epielpsy were reviewed (henceforth called \"predicted\" drugs). This represents the top 7% of drugs predicted for epilepsy (93rd percentile and higher). \r\n\r\nThe attached powerpoint figure one shows the percent of predicted drugs that are known Anti-Epileptic drugs (AEDs), are known to have antiepileptic activity (raise the seizure threshold), are known to be harmful in epilepsy (lower the seizure threshold), or have no prior evidence (\"unknown\"). The top 1% of predicted drugs are all known AEDs (17/17, 100%); these have prediction scores greater than 0.35. Of the top 3% of predicted drugs, the overwhelming majority (45/47, 95%) are known AEDs; these have prediction scores greater than 0.09. As we get deeper into the rankings of predicted drugs, we see an increasingly larger percentage of unknown drugs and drugs that lower the seizure threshold. By the 94th percentile, about 40% of the predicted drugs are known AEDs or have known antiepileptic properties, about 47% have unknown epileptic properties, and about 13% are known to lower the seizure threshold; the prediction scores here are around 0.03 to 0.04.\r\n\r\nOf the top 100 drugs, 69 are primary AEDs (AEDs that are primarily used in epilepsy), another 7 have known antiepileptic properties. Thus over three quarters (76/100, 76%) are anti-epileptics or known to have antiepileptic properties. An important minority of drugs lower the seizure threshold (15/100, 15%). The remaining drugs are unknown in epilepsy (9/100, 8%). All drugs which are not AEDs are dicussed below:\r\n\r\n##### Drugs known anti-epileptic properties\r\n\r\nThe seven drugs with known anti epileptic properties include three carbonic anhydrase inhibitors (methazolamide, acetazolamide, and diclofenamide), one calcium channel blocker (verapamil), and one sodium channel blocker (Ranolazine). The other two medications are indapamide and modafinil, the mechanism of action of these two drugs in increasing the seizure threshold is unknown.\r\n\r\n##### Drugs that induce seizures\r\n\r\nThe 15 predicted drugs that are known to induce seizures include five are tricyclic antidepressants (TCAs) (amitriptyline, imipramine, nortriptyline, clomipramine, desipramine) three are monoamine oxidate inhibitors (MAOIs) (isocarboxazid, phenelzine, amoxapine), and two are antipsychotics (clozapine and Loxapine) and one is an antihistamine (cyproheptadine). The reason amitriptyline was chosen was explored in the discussion above, and highlights one of the limitations of our method. The TCAs are known to act on GABA-R, which is known to be important in epilepsy (also the TCAs treat migraine and many migraine drugs are also AEDs). The limitation of our method is that it does not differentiate the direction of effect on GABA-R (agonistic versus antagonistic), and thus our method suggests TCAs may treat epilepsy. I suspect the reason MAOIs and antipsychotics were chosen is similar. The other predicted drugs that are known to lower the seizure threshold are antipyrine (an analgesic), dalfampridine (K-channel antagonist), baclofen (inhibits the transmission of both monosynaptic and polysynaptic reflexes at the spinal cord level, possibly by hyperpolarization of primary afferent fiber terminals), and memantine (anti-NMDA). \r\n\r\n##### Drugs with unknown effect on epilepsy\r\n\r\n**Halogenated ethers (Sevoflurane, Desflurane, and Enflurane)**: These are inhaled anesthetics. Some of the halogenated ethers are used in refractory status epilepticus (RSE), such as isoflurane (classified as an AED). Desflurane is also used in RSE, this should likely be reclassified as an AED before we make our final figures/tables. Enflurane and sevoflurane withdrawal can also cause seizures, suggesting that these drugs may have anti-epileptic properties. \r\n\r\nHere's the quote form a review [@10.1093/bja/aes027]: \r\n\r\n> There are multiple case reports of sevoflurane-provoking seizure-like activity, particularly in children [@10.1111/j.1460-9592.2004.01538.x] and where high concentrations are used in conjunction with hypocapnea [@10.1007/BF03022961]. In high concentration, enflurane exhibits periods of suppression with paroxysmal epileptiform discharges in cats and rats [@10.1213/ANE.0b013e3181add06b]. There have been multiple reports of seizure activity in humans after enflurane anaesthesia [@10.1213/00000539-199003000-00013 @10.1097/00000542-198008000-00014]. Isoflurane has well-characterized anticonvulsant properties. Both isoflurane and desflurane can be used in refractory status epilepticus [@10.1001/archneur.61.8.1254] [the worst end of the epilepsy spectrum].\r\n\r\n**Glutethimidie**: This is potentially a good choice, it is a GABA agonist anesthetic which makes it a good candidate for repurposing for epilepsy. The prediction score was 0.08 and the percentile was 96th. It is an anesthetic (similar to thalidomide).\r\n\r\n**Acamprosate**: This drug appears to work in promoting alcohol abstinence by acting as a GABA agonist, which makes it a good candidate for repurposing for epilepsy. The side effect profile is also reasonable. Further, if it is demonstrated to have antiepileptic, it may serve a dual benefit for recovering alcoholics (promoting alcohol abstinence while also perhaps preventing alcohol-associted seizures). The prediction score was 0.03 and the percentile ws 93rd. \r\n\r\n**Chlorthalidone**: This is a blood pressure medication that acts on Na-Cl channels, potentially related to epilepsy. Other blood pressure medications (albeit of different classes) have been repurposed for epilepsy, as described in the section above). The prediction score was 0.04 and the percentile was 95th. \r\n\r\n**Phenazopyridine**: a urinary analgesic which is excreted rapidly in the urine and is unlikely to have any clinical effect. \r\n\r\n**Antineoplastic agents (dabrafenib and bortezomib)**: These are poor choices due to the adverse side effect profiles.\r\n\r\nOf note, I did not consider the drug Quinidine barbiurate, as this is a combination drug which is poorly handled by our analysis pipeline.",
      "comment_id": 1356,
      "profile_id": 188,
      "published": "2016-09-19T04:37:17.411448Z",
      "thread_id": 224,
      "url": "/discussion/prediction-in-epilepsy/224#2"
    },
    {
      "body_html": "<h1>Clofarabine Synopsis</h1>\r\n\r\n<p>Above, <a href=\"#13\">I discussed</a> our clofarabine predictions. I created a summary of those findings for our project report. However, in private communications <a href=\"/u/pouyakhankhanian\" class=\"username\">@pouyakhankhanian</a> noted:</p>\r\n\r\n<blockquote><p>Regarding clofarabine, my only issue is that it's very obvious. I suspect that if you ask ten clinicians about using clofarabine in MS, I suspect most would guess that clofarabine would work in MS patients. Perhaps you are looking for something obvious in order to validate your approach. But it's not something that will ever result in someone repurposing a drug based on your predictions.</p></blockquote>\r\n\r\n<p>Therefore, we've decided to remove this example from the draft report. To preserve the content, I will post it here.</p>\r\n\r\n<hr>\r\n\r\n<p>Clofarabine is an FDA-approved treatment for certain cases of acute lymphoblastic leukemia (ALL) <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nrd2055\" class=\"citation\" data-key=\"10.1038/nrd2055\">1</a>]</span>. Our top <a href=\"http://het.io/repurpose/browse.html?id=DB00631\" title=\"Project Rephetio predictions for clofarabine (DB00631)\">prediction for clofarabine</a> was hematologic cancer (50.27-fold over null), which is a supertype of ALL and listed as a disease-modifying indication in PharacotherapyDB. Second was lymphatic system cancer (27.14-fold), which matched 14 clinical trials. Third was multiple sclerosis (MS, 23.37-fold). Notably, MS was the only non-cancer in the top 10 predictions for clofarabine, and clofarabine was in the 99.8th percentile of MS predictions. As shown in <a href=\"#clofarabine_ms_figure\">Figure 5</a>, our approach based this prediction on the successful repurposing of other chemotherapeutics for MS <span class=\"citation\">[<a href=\"https://doi.org/10.1177/1756285610379885\" class=\"citation\" data-key=\"10.1177/1756285610379885\">2</a>]</span> — particularly cladribine <span class=\"citation\">[<a href=\"https://doi.org/10.1056/NEJMoa0902533\" class=\"citation\" data-key=\"10.1056/NEJMoa0902533\">3</a>]</span> and azathioprine <span class=\"citation\">[<a href=\"https://doi.org/10.1002/14651858.CD003982.pub2\" class=\"citation\" data-key=\"10.1002/14651858.CD003982.pub2\">4</a>]</span>. Besides <a href=\"https://www.google.com/patents/US7772206\" title=\"US Patent 7772206: Methods and compositions for the treatment of autoimmune disorders using clofarabine. 2010\">a patent</a> that encompasses treating MS with clofarabine, there is little literature on this potential repurposing, despite the favorable pharmacological properties of clofarabine compared to cladribine <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.bcp.2009.06.094\" class=\"citation\" data-key=\"10.1016/j.bcp.2009.06.094\">5</a>]</span>.</p>\r\n\r\n<h3>Figure</h3>\r\n\r\n<p><em>Legend for <a href=\"#13\">figure above</a></em>:</p>\r\n\r\n<p><strong>Evidence supporting the repurposing of clofarabine for multiple sclerosis.</strong> In total, 769 paths of 10 types provided positive <a href=\"https://neo4j.het.io/browser/?cmd=play&amp;arg=https://neo4j.het.io/guides/rep/DB00631/DOID_2377.html\" title=\"Hetionet Browser for the prediction that clofarabine treats multiple sclerosis\">support for repurposing</a> clofarabine for MS. The ten most supportive paths are visualized. Several important aspects of clofarabine's pharmacology are illustrated. Clofarabine is a hybrid of cladribine and fludarabine and relies on deoxycytidine kinase (<em>DCK</em>) for phosphorylation into its active form <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.bcp.2009.06.094\" class=\"citation\" data-key=\"10.1016/j.bcp.2009.06.094\">5</a>]</span>. Ultimately, the purine-analog-metabolites of clofarabine, cladribine, and azathioprine inhibit nucleic acid synthesis. Since the resulting cytoxicity is pronounced in lymphocytes, these compounds are attractive MS therapeutics <span class=\"citation\">[<a href=\"https://doi.org/10.1177/1756285610379885\" class=\"citation\" data-key=\"10.1177/1756285610379885\">2</a>]</span>.</p>",
      "body_md": "# Clofarabine Synopsis\r\n\r\nAbove, [I discussed](#13) our clofarabine predictions. I created a summary of those findings for our project report. However, in private communications @pouyakhankhanian noted:\r\n\r\n> Regarding clofarabine, my only issue is that it's very obvious. I suspect that if you ask ten clinicians about using clofarabine in MS, I suspect most would guess that clofarabine would work in MS patients. Perhaps you are looking for something obvious in order to validate your approach. But it's not something that will ever result in someone repurposing a drug based on your predictions.\r\n\r\nTherefore, we've decided to remove this example from the draft report. To preserve the content, I will post it here.\r\n\r\n***\r\n\r\nClofarabine is an FDA-approved treatment for certain cases of acute lymphoblastic leukemia (ALL) [@10.1038/nrd2055]. Our top [prediction for clofarabine](http://het.io/repurpose/browse.html?id=DB00631 \"Project Rephetio predictions for clofarabine (DB00631)\") was hematologic cancer (50.27-fold over null), which is a supertype of ALL and listed as a disease-modifying indication in PharacotherapyDB. Second was lymphatic system cancer (27.14-fold), which matched 14 clinical trials. Third was multiple sclerosis (MS, 23.37-fold). Notably, MS was the only non-cancer in the top 10 predictions for clofarabine, and clofarabine was in the 99.8th percentile of MS predictions. As shown in [Figure 5](#clofarabine_ms_figure), our approach based this prediction on the successful repurposing of other chemotherapeutics for MS [@10.1177/1756285610379885] -- particularly cladribine [@10.1056/NEJMoa0902533] and azathioprine [@10.1002/14651858.CD003982.pub2]. Besides [a patent](https://www.google.com/patents/US7772206 \"US Patent 7772206: Methods and compositions for the treatment of autoimmune disorders using clofarabine. 2010\") that encompasses treating MS with clofarabine, there is little literature on this potential repurposing, despite the favorable pharmacological properties of clofarabine compared to cladribine [@10.1016/j.bcp.2009.06.094].\r\n\r\n### Figure\r\n\r\n_Legend for [figure above](#13)_:\r\n\r\n**Evidence supporting the repurposing of clofarabine for multiple sclerosis.** In total, 769 paths of 10 types provided positive [support for repurposing](https://neo4j.het.io/browser/?cmd=play&arg=https://neo4j.het.io/guides/rep/DB00631/DOID_2377.html \"Hetionet Browser for the prediction that clofarabine treats multiple sclerosis\") clofarabine for MS. The ten most supportive paths are visualized. Several important aspects of clofarabine's pharmacology are illustrated. Clofarabine is a hybrid of cladribine and fludarabine and relies on deoxycytidine kinase (_DCK_) for phosphorylation into its active form [@10.1016/j.bcp.2009.06.094]. Ultimately, the purine-analog-metabolites of clofarabine, cladribine, and azathioprine inhibit nucleic acid synthesis. Since the resulting cytoxicity is pronounced in lymphocytes, these compounds are attractive MS therapeutics [@10.1177/1756285610379885].",
      "comment_id": 1359,
      "profile_id": 17,
      "published": "2016-09-19T17:28:29.579442Z",
      "thread_id": 203,
      "url": "/discussion/predictions-of-whether-a-compound-treats-a-disease/203#16"
    },
    {
      "body_html": "<p>Hi Daniel,</p>\r\n\r\n<p>In cell 2 of <a href=\"https://github.com/dhimmel/integrate/blob/master/compile/DaG-association.ipynb\">this notebook</a> I notice that you're reading the <code>data/slim-terms.tsv</code> file from the <code>dhimmel/disease-ontology</code> repository. However, I could not determine how the <code>slim-terms.tsv</code> file was generated by looking at the files in the <code>disease-ontology</code> repository.</p>\r\n\r\n<p>The only mention of a <code>slim-terms.tsv</code> file in the DO repository is in cell 42 of <a href=\"https://github.com/dhimmel/disease-ontology/blob/72614ade9f1cc5a5317b8f6836e1e464b31d5587/slim.ipynb\">this notebook</a>, but here the file seems to have been created already.</p>\r\n\r\n<p>Do you know how this file was generated? I am trying to replicate the Rephetio workflow with up-to-date data.</p>\r\n\r\n<p>Thanks!</p>",
      "body_md": "Hi Daniel,\r\n\r\nIn cell 2 of [this notebook](https://github.com/dhimmel/integrate/blob/master/compile/DaG-association.ipynb) I notice that you're reading the `data/slim-terms.tsv` file from the `dhimmel/disease-ontology` repository. However, I could not determine how the `slim-terms.tsv` file was generated by looking at the files in the `disease-ontology` repository.\r\n\r\nThe only mention of a `slim-terms.tsv` file in the DO repository is in cell 42 of [this notebook](https://github.com/dhimmel/disease-ontology/blob/72614ade9f1cc5a5317b8f6836e1e464b31d5587/slim.ipynb), but here the file seems to have been created already.\r\n\r\nDo you know how this file was generated? I am trying to replicate the Rephetio workflow with up-to-date data.\r\n\r\nThanks!",
      "comment_id": 1360,
      "profile_id": 176,
      "published": "2016-09-21T22:01:23.999528Z",
      "thread_id": 44,
      "url": "/discussion/unifying-disease-vocabularies/44#8"
    },
    {
      "body_html": "<p><a href=\"/u/tongli\" class=\"username\">@tongli</a>, <code>slim-terms.tsv</code> was created manually according to the <a href=\"#6\">post above</a>. In short, I created the table in a <a href=\"https://docs.google.com/spreadsheets/d/1jVRHiBH4lvTHRVpVBm1UbWt7y_0jIYpVWKDWkM_Lnq8/edit?usp=sharing\" title=\"DO Slim on Google Drive\">spreadsheet</a> by combining the two disease sets (hetio-dag <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1004259\">1</a>]</span> and TOPNodes_DOcancerslim <span class=\"citation\">[<a href=\"https://doi.org/10.1093/database/bav032\" class=\"citation\" data-key=\"10.1093/database/bav032\">2</a>]</span>) and removing any problematic terms based on ad hoc rules. The pathophysiology classification was manually done by <a href=\"/u/pouyakhankhanian\" class=\"username\">@pouyakhankhanian</a> and I — I believe primarily for hetio-dag <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1004259\">1</a>]</span> — and was not used in Project Rephetio.</p>\r\n\r\n<blockquote><p>I am trying to replicate the Rephetio workflow with up-to-date data.</p></blockquote>\r\n\r\n<p>The problem with the slim approach we took is that it's difficult to automate and potentially requires some clinical expertise. In other words, it's difficult to update. Therefore, I'm thinking of alternatives for the future. One option would be to include the entire ontology. You could then pick your slim term set at analysis time rather than network construction time. This would make the network more versatile. Since Cypher is capable of <a href=\"http://graphaware.com/graphaware/2015/05/19/neo4j-cypher-variable-length-relationships-by-example.html\">variable length relationship</a> queries, you could do on-the-fly propagation. However, this would require some additional implementation and theoretical work.</p>\r\n\r\n<p>Along these ends, I started playing around with <a href=\"https://github.com/greenelab/hetontology\">creating Hetontology</a> — a public Neo4j database of open biomedical ontologies. Depending on how much ground you're looking to break, this may be of interest.</p>",
      "body_md": "@tongli, `slim-terms.tsv` was created manually according to the [post above](#6). In short, I created the table in a [spreadsheet](https://docs.google.com/spreadsheets/d/1jVRHiBH4lvTHRVpVBm1UbWt7y_0jIYpVWKDWkM_Lnq8/edit?usp=sharing \"DO Slim on Google Drive\") by combining the two disease sets (hetio-dag [@10.1371/journal.pcbi.1004259] and TOPNodes_DOcancerslim [@10.1093/database/bav032]) and removing any problematic terms based on ad hoc rules. The pathophysiology classification was manually done by @pouyakhankhanian and I -- I believe primarily for hetio-dag [@10.1371/journal.pcbi.1004259] -- and was not used in Project Rephetio.\r\n\r\n> I am trying to replicate the Rephetio workflow with up-to-date data.\r\n\r\nThe problem with the slim approach we took is that it's difficult to automate and potentially requires some clinical expertise. In other words, it's difficult to update. Therefore, I'm thinking of alternatives for the future. One option would be to include the entire ontology. You could then pick your slim term set at analysis time rather than network construction time. This would make the network more versatile. Since Cypher is capable of [variable length relationship](http://graphaware.com/graphaware/2015/05/19/neo4j-cypher-variable-length-relationships-by-example.html) queries, you could do on-the-fly propagation. However, this would require some additional implementation and theoretical work.\r\n\r\nAlong these ends, I started playing around with [creating Hetontology](https://github.com/greenelab/hetontology) -- a public Neo4j database of open biomedical ontologies. Depending on how much ground you're looking to break, this may be of interest.",
      "comment_id": 1362,
      "profile_id": 17,
      "published": "2016-09-22T23:01:46.079405Z",
      "thread_id": 44,
      "url": "/discussion/unifying-disease-vocabularies/44#9"
    },
    {
      "body_html": "<h1>Epilepsy literature</h1>\r\n\r\n<p>Here are relevant papers I found while learning about the pharmacotherapy of epilepsy.</p>\r\n\r\n<ul><li><p>Animal models of epilepsy <span class=\"citation\">[<a href=\"https://doi.org/10.1358/mf.2009.31.2.1338414\" class=\"citation\" data-key=\"10.1358/mf.2009.31.2.1338414\">1</a>, <a href=\"https://doi.org/10.1016/j.seizure.2011.01.003\" class=\"citation\" data-key=\"10.1016/j.seizure.2011.01.003\">2</a>, <a href=\"https://doi.org/10.1002/0471141755.ph0522s45\" class=\"citation\" data-key=\"10.1002/0471141755.ph0522s45\">3</a>, <a href=\"https://doi.org/10.1038/nn.3934\" class=\"citation\" data-key=\"10.1038/nn.3934\">4</a>, <a href=\"https://doi.org/10.2147/NDT.S50371\" class=\"citation\" data-key=\"10.2147/NDT.S50371\">5</a>]</span></p></li><li><p>Antiepileptic drugs <span class=\"citation\">[<a href=\"https://doi.org/10.1136/bmj.g254\" class=\"citation\" data-key=\"10.1136/bmj.g254\">6</a>, <a href=\"https://doi.org/10.1016/j.nurt.2006.11.009\" class=\"citation\" data-key=\"10.1016/j.nurt.2006.11.009\">7</a>, <a href=\"https://doi.org/10.1016/S1474-4422(07)70215-6\" class=\"citation\" data-key=\"10.1016/S1474-4422(07)70215-6\">8</a>, <a href=\"https://doi.org/10.1038/nrd2997\" class=\"citation\" data-key=\"10.1038/nrd2997\">9</a>, <a href=\"https://doi.org/10.1038/nrd4126\" class=\"citation\" data-key=\"10.1038/nrd4126\">10</a>]</span></p></li></ul>",
      "body_md": "# Epilepsy literature\r\n\r\nHere are relevant papers I found while learning about the pharmacotherapy of epilepsy.\r\n\r\n+ Animal models of epilepsy [@10.1358/mf.2009.31.2.1338414 @10.1016/j.seizure.2011.01.003 @10.1002/0471141755.ph0522s45 @10.1038/nn.3934 @10.2147/NDT.S50371]\r\n\r\n+ Antiepileptic drugs [@10.1136/bmj.g254 @10.1016/j.nurt.2006.11.009 @10.1016/S1474-4422(07)70215-6 @10.1038/nrd2997 @10.1038/nrd4126]",
      "comment_id": 1363,
      "profile_id": 17,
      "published": "2016-10-12T16:41:34.531105Z",
      "thread_id": 224,
      "url": "/discussion/prediction-in-epilepsy/224#3"
    },
    {
      "body_html": "<h1>Plot of prediction scores by disease</h1>\r\n\r\n<p><img src=\"https://cloud.githubusercontent.com/assets/1117703/18564280/d392df62-7b58-11e6-9c6f-16b6f977458b.png\" alt=\"prediction score by disease\"></p>\r\n\r\n<p>The y-axis is the prediction score (the predicted probability of treatment) for compounds in each disease. The 97th, 98th, and 99th percentile prediction scores in each disease are also shown. Allergic rhinitis, asthma, coronary artery disease, epilepsy, hematologic cancer, hypertension, osteoporosis, psoriasis, and type 2 diabetes are highlighted in red; these diseases had the highest prediction score tail distributions. </p>",
      "body_md": "# Plot of prediction scores by disease\r\n\r\n![prediction score by disease](https://cloud.githubusercontent.com/assets/1117703/18564280/d392df62-7b58-11e6-9c6f-16b6f977458b.png)\r\n\r\nThe y-axis is the prediction score (the predicted probability of treatment) for compounds in each disease. The 97th, 98th, and 99th percentile prediction scores in each disease are also shown. Allergic rhinitis, asthma, coronary artery disease, epilepsy, hematologic cancer, hypertension, osteoporosis, psoriasis, and type 2 diabetes are highlighted in red; these diseases had the highest prediction score tail distributions.",
      "comment_id": 1365,
      "profile_id": 188,
      "published": "2016-10-16T17:09:36.453378Z",
      "thread_id": 203,
      "url": "/discussion/predictions-of-whether-a-compound-treats-a-disease/203#17"
    },
    {
      "body_html": "<h1>Nomenclature change for the manuscript</h1>\r\n\r\n<p>In the manuscript and in the further discussion of this topic, for simplicity and better precision, we chose to call any drug with anti-seizure properties as an anti-ictogenic drug (<code>AIGD</code>), this includes known AEDs as well as drugs which are used as ancillary drugs in the treatment of status epileptics.  We chose to call drugs which lower the seizure threshold ictogenic drugs (<code>IGD</code>).</p>",
      "body_md": "# Nomenclature change for the manuscript\r\n\r\nIn the manuscript and in the further discussion of this topic, for simplicity and better precision, we chose to call any drug with anti-seizure properties as an anti-ictogenic drug (`AIGD`), this includes known AEDs as well as drugs which are used as ancillary drugs in the treatment of status epileptics.  We chose to call drugs which lower the seizure threshold ictogenic drugs (`IGD`).",
      "comment_id": 1366,
      "profile_id": 188,
      "published": "2016-10-16T17:14:19.888465Z",
      "thread_id": 224,
      "url": "/discussion/prediction-in-epilepsy/224#4"
    },
    {
      "body_html": "<h1>Visualizing the top epilepsy predictions</h1>\r\n\r\n<p><a href=\"/u/pouyakhankhanian\" class=\"username\">@pouyakhankhanian</a> completed his curation of the top 100 epilepsy predictions (excluding <a href=\"https://www.drugbank.ca/drugs/DB01346\">quinidine barbiurate</a> since it's a combination drug). As <a href=\"#4\">explained above</a>, the classifications were:</p>\r\n\r\n<ul><li>AIGD for anti-ictogenic drug</li><li>UNKD for drug with an unknown effect on ictogenesis</li><li>IGD for ictogenic drug</li></ul>\r\n\r\n<p>His classifications are available as a <a href=\"https://github.com/dhimmel/rephetio/blob/127b094076684b40ea35f6e42aca8967afdb9f56/epilepsy/data/PK-curation.tsv\">TSV on GitHub</a> (versioned link) and on <a href=\"https://docs.google.com/spreadsheets/d/1GJvqWp7WkMyboJ49Hts4eSOQCdJc_rcQenmqPLk6Bsw\">Google Sheets</a> (unversioned link).</p>\r\n\r\n<p>Of the top epilepsy predictions, 77 were AIGDs, 8 were UNKDs, and 15 were IGDs (<a href=\"https://github.com/dhimmel/rephetio/blob/127b094076684b40ea35f6e42aca8967afdb9f56/epilepsy/epylepsy.ipynb\">notebook</a>). Of the 25 disease-modifying epilepsy drugs in PharmacotherapyDB, 23 were in the top predictions. Propofol and vigabatrin were the two that did not make the top 100 predictions and were respectively in the 90.6th and 83.7th percentile for epilepsy predictions.</p>\r\n\r\n<p>I created the following visualizations of the top predictions. First, the plot of predicted probability versus compound's rank (ignoring quinidine barbiurate):</p>\r\n\r\n<p><img src=\"https://github.com/dhimmel/rephetio/raw/127b094076684b40ea35f6e42aca8967afdb9f56/epilepsy/figure/epilepsy-labeled.png\" alt=\"Project Rephetio Top Epilepsy Predictions with Compounds Labeled\" title=\"AIGD stands for anti-ictogenic drug; UNKD stands for drug with an unknown effect on ictogenesis; IGD stands for ictogenic drug\"></p>\r\n\r\n<p>Here is a more complex version of the above plot which uses a sliding window that looks 7 predictions ahead/behind to compute category frequency within the window. The plot shows that top predictions are primarily AIGDs with some UNKDs and IGDs creeping in for lower predictions.</p>\r\n\r\n<p><img src=\"https://github.com/dhimmel/rephetio/raw/127b094076684b40ea35f6e42aca8967afdb9f56/epilepsy/figure/epilepsy-windows.png\" alt=\"Project Rephetio Top Epilepsy Prediction Windows\" title=\"AIGD stands for anti-ictogenic drug; UNKD stands for drug with an unknown effect on ictogenesis; IGD stands for ictogenic drug\"></p>",
      "body_md": "# Visualizing the top epilepsy predictions\r\n\r\n@pouyakhankhanian completed his curation of the top 100 epilepsy predictions (excluding [quinidine barbiurate](https://www.drugbank.ca/drugs/DB01346) since it's a combination drug). As [explained above](#4), the classifications were:\r\n\r\n+ AIGD for anti-ictogenic drug\r\n+ UNKD for drug with an unknown effect on ictogenesis\r\n+ IGD for ictogenic drug\r\n\r\nHis classifications are available as a [TSV on GitHub](https://github.com/dhimmel/rephetio/blob/127b094076684b40ea35f6e42aca8967afdb9f56/epilepsy/data/PK-curation.tsv) (versioned link) and on [Google Sheets](https://docs.google.com/spreadsheets/d/1GJvqWp7WkMyboJ49Hts4eSOQCdJc_rcQenmqPLk6Bsw) (unversioned link).\r\n\r\nOf the top epilepsy predictions, 77 were AIGDs, 8 were UNKDs, and 15 were IGDs ([notebook](https://github.com/dhimmel/rephetio/blob/127b094076684b40ea35f6e42aca8967afdb9f56/epilepsy/epylepsy.ipynb)). Of the 25 disease-modifying epilepsy drugs in PharmacotherapyDB, 23 were in the top predictions. Propofol and vigabatrin were the two that did not make the top 100 predictions and were respectively in the 90.6th and 83.7th percentile for epilepsy predictions.\r\n\r\nI created the following visualizations of the top predictions. First, the plot of predicted probability versus compound's rank (ignoring quinidine barbiurate):\r\n\r\n![Project Rephetio Top Epilepsy Predictions with Compounds Labeled](https://github.com/dhimmel/rephetio/raw/127b094076684b40ea35f6e42aca8967afdb9f56/epilepsy/figure/epilepsy-labeled.png \"AIGD stands for anti-ictogenic drug; UNKD stands for drug with an unknown effect on ictogenesis; IGD stands for ictogenic drug\")\r\n\r\nHere is a more complex version of the above plot which uses a sliding window that looks 7 predictions ahead/behind to compute category frequency within the window. The plot shows that top predictions are primarily AIGDs with some UNKDs and IGDs creeping in for lower predictions.\r\n\r\n![Project Rephetio Top Epilepsy Prediction Windows](https://github.com/dhimmel/rephetio/raw/127b094076684b40ea35f6e42aca8967afdb9f56/epilepsy/figure/epilepsy-windows.png \"AIGD stands for anti-ictogenic drug; UNKD stands for drug with an unknown effect on ictogenesis; IGD stands for ictogenic drug\")",
      "comment_id": 1367,
      "profile_id": 17,
      "published": "2016-10-17T15:02:59.921143Z",
      "thread_id": 224,
      "url": "/discussion/prediction-in-epilepsy/224#5"
    },
    {
      "body_html": "<p><a href=\"/u/sergiobaranzini\" class=\"username\">@sergiobaranzini</a>, very nice. Arranging compounds and diseases in a line helps communicate our application of Hetionet to predict drug efficacy. Below is a labeled, landscape version:</p>\r\n\r\n<p><img src=\"https://github.com/dhimmel/rephetio/raw/127b094076684b40ea35f6e42aca8967afdb9f56/figure/hetionet-v1.0-labeled-landscape.png\" alt=\"hetionet v1.0 labeled landscape\" title=\"Hetionet 1.0: The hetnet visualized. Nodes are drawn as dots and laid out orbitally, thus forming circles. Edges are colored by type.\"></p>",
      "body_md": "@sergiobaranzini, very nice. Arranging compounds and diseases in a line helps communicate our application of Hetionet to predict drug efficacy. Below is a labeled, landscape version:\r\n\r\n![hetionet v1.0 labeled landscape](https://github.com/dhimmel/rephetio/raw/127b094076684b40ea35f6e42aca8967afdb9f56/figure/hetionet-v1.0-labeled-landscape.png \"Hetionet 1.0: The hetnet visualized. Nodes are drawn as dots and laid out orbitally, thus forming circles. Edges are colored by type.\")",
      "comment_id": 1368,
      "profile_id": 17,
      "published": "2016-10-17T16:25:27.513603Z",
      "thread_id": 202,
      "url": "/discussion/describing-hetionet-v10-through-visualization-and-statistics/202#8"
    },
    {
      "body_html": "<h1>Enflurane has established ictogenic properties?</h1>\r\n\r\n<p><a href=\"/u/pouyakhankhanian\" class=\"username\">@pouyakhankhanian</a>, I was looking into enflurane and <a href=\"http://www.epilepsy.com/information/professionals/diagnosis-treatment/procedures-epilepsy-patients/general-anesthetics-6\" title=\"Information For Health Care Professionals: Enflurane\">found the following material</a> from the Epilepsy Foundation. The website says the material was adapted from the book <a href=\"http://www.isbnsearch.org/isbn/9780750672412\"><em>Managing epilepsy and co-existing disorders</em></a> from 2002 and was reviewed in 2004.</p>\r\n\r\n<blockquote><p>Enflurane is the inhalation agent that anesthesiologists most often avoid when caring for patients with epilepsy, because it lowers seizure threshold. In children and adults with no history of epilepsy, enflurane can cause epileptiform activity with concomitant facial or appendicular myoclonus or generalized tonic-clonic movements <span class=\"citation\">[<a href=\"https://doi.org/10.1213/00000539-197707000-00010\" class=\"citation\" data-key=\"10.1213/00000539-197707000-00010\">1</a>, <a href=\"https://doi.org/10.1212/wnl.38.6.924\" class=\"citation\" data-key=\"10.1212/wnl.38.6.924\">2</a>, <a href=\"https://doi.org/10.1213/00000539-197001000-00001\" class=\"citation\" data-key=\"10.1213/00000539-197001000-00001\">3</a>]</span>. In epilepsy patients, the extent but not the frequency of spike activity on the electrocorticogram is increased <span class=\"citation\">[<a href=\"https://doi.org/10.1212/wnl.38.6.924\" class=\"citation\" data-key=\"10.1212/wnl.38.6.924\">2</a>]</span>. Epileptogenic foci may be activated during epilepsy surgery <span class=\"citation\">[<a href=\"https://doi.org/10.1213/00000539-199004000-00016\" class=\"citation\" data-key=\"10.1213/00000539-199004000-00016\">4</a>, <a href=\"https://doi.org/10.1097/00000542-198005000-00010\" class=\"citation\" data-key=\"10.1097/00000542-198005000-00010\">5</a>]</span>. As the depth of anesthesia is increased with enflurane, the EEG demonstrates high-voltage spikes and spike and slow-wave complexes, the spikes with burst suppression.</p><p>The mechanism of enflurane-induced hyperexcitability in humans is unclear. In animals, enflurane inhibits synapses and stimulates excitatory neuronal transmission in cortical and subcortical areas <span class=\"citation\">[<a href=\"https://doi.org/10.1016/0013-4694(75)90199-6\" class=\"citation\" data-key=\"10.1016/0013-4694(75)90199-6\">6</a>]</span> (page 555).</p><p>Although low enflurane concentrations (1.0–1.5%) administered to a normocarbic patient (arterial partial pressure of carbon dioxide [PaCO2] equals 40 mm Hg) are not frequently associated with seizure activity <span class=\"citation\">[<a href=\"https://doi.org/10.1097/00000542-197111000-00006\" class=\"citation\" data-key=\"10.1097/00000542-197111000-00006\">7</a>]</span>, increasing enflurane concentrations (2–3%) or hyperventilating an anesthetized patient enhances seizure activity. Hyperventilation to a PaCO2 of 20 mm Hg from 40 mm Hg is associated with seizure activity at a 1% lower enflurane concentration. Because hyperventilation is frequently used by neuroanesthesiologists to decrease cerebral blood flow and intracranial pressure, enflurane is avoided when hyperventilation is indicated. An increase in PaCO2 from 40 mm Hg to 60 mm Hg increases the minimum enflurane concentration at which seizures occur by 1% <span class=\"citation\">[<a href=\"https://doi.org/10.1016/0013-4694(75)90199-6\" class=\"citation\" data-key=\"10.1016/0013-4694(75)90199-6\">6</a>]</span>.</p><p>Generalized tonic-clonic and myoclonic seizures can occur within the immediate postoperative period and, potentially, for a few days after enflurane anesthesia. The role of other CNS-active drugs remains uncertain in these cases <span class=\"citation\">[<a href=\"https://doi.org/10.1097/00000542-197503000-00026\" class=\"citation\" data-key=\"10.1097/00000542-197503000-00026\">8</a>]</span>. The convulsant effects may result from enflurane's organic and inorganic nonvolatile fluorinated metabolites <span class=\"citation\">[<a href=\"https://doi.org/10.1097/00000542-197109000-00007\" class=\"citation\" data-key=\"10.1097/00000542-197109000-00007\">9</a>]</span>.</p><p>Although anesthesiologists consider diazepam and thiopental to be anticonvulsants and use them extensively to treat seizure activity, there is some evidence that these drugs may potentiate enflurane-related epileptiform activity in humans <span class=\"citation\">[<a href=\"https://doi.org/10.1007/bf03006812\" class=\"citation\" data-key=\"10.1007/bf03006812\">10</a>]</span>. Nitrous oxide (N2O) does not alter epileptiform activity induced by enflurane <span class=\"citation\">[<a href=\"https://doi.org/10.1097/00000542-197111000-00006\" class=\"citation\" data-key=\"10.1097/00000542-197111000-00006\">7</a>]</span>.</p></blockquote>\r\n\r\n<p><a href=\"/u/pouyakhankhanian\" class=\"username\">@pouyakhankhanian</a> do you think this is sufficient evidence to classify enflurane as a IGD? It's likely this information was overlooked due to the poor discoverability of these old studies.</p>",
      "body_md": "# Enflurane has established ictogenic properties?\r\n\r\n@pouyakhankhanian, I was looking into enflurane and [found the following material](http://www.epilepsy.com/information/professionals/diagnosis-treatment/procedures-epilepsy-patients/general-anesthetics-6 \"Information For Health Care Professionals: Enflurane\") from the Epilepsy Foundation. The website says the material was adapted from the book [_Managing epilepsy and co-existing disorders_](http://www.isbnsearch.org/isbn/9780750672412) from 2002 and was reviewed in 2004.\r\n\r\n> Enflurane is the inhalation agent that anesthesiologists most often avoid when caring for patients with epilepsy, because it lowers seizure threshold. In children and adults with no history of epilepsy, enflurane can cause epileptiform activity with concomitant facial or appendicular myoclonus or generalized tonic-clonic movements [@10.1213/00000539-197707000-00010 @10.1212/wnl.38.6.924 @10.1213/00000539-197001000-00001]. In epilepsy patients, the extent but not the frequency of spike activity on the electrocorticogram is increased [@10.1212/wnl.38.6.924]. Epileptogenic foci may be activated during epilepsy surgery [@10.1213/00000539-199004000-00016 @10.1097/00000542-198005000-00010]. As the depth of anesthesia is increased with enflurane, the EEG demonstrates high-voltage spikes and spike and slow-wave complexes, the spikes with burst suppression.\r\n\r\n> The mechanism of enflurane-induced hyperexcitability in humans is unclear. In animals, enflurane inhibits synapses and stimulates excitatory neuronal transmission in cortical and subcortical areas [@10.1016/0013-4694(75)90199-6] (page 555).\r\n\r\n> Although low enflurane concentrations (1.0–1.5%) administered to a normocarbic patient (arterial partial pressure of carbon dioxide [PaCO2] equals 40 mm Hg) are not frequently associated with seizure activity [@10.1097/00000542-197111000-00006], increasing enflurane concentrations (2–3%) or hyperventilating an anesthetized patient enhances seizure activity. Hyperventilation to a PaCO2 of 20 mm Hg from 40 mm Hg is associated with seizure activity at a 1% lower enflurane concentration. Because hyperventilation is frequently used by neuroanesthesiologists to decrease cerebral blood flow and intracranial pressure, enflurane is avoided when hyperventilation is indicated. An increase in PaCO2 from 40 mm Hg to 60 mm Hg increases the minimum enflurane concentration at which seizures occur by 1% [@10.1016/0013-4694(75)90199-6].\r\n\r\n> Generalized tonic-clonic and myoclonic seizures can occur within the immediate postoperative period and, potentially, for a few days after enflurane anesthesia. The role of other CNS-active drugs remains uncertain in these cases [@10.1097/00000542-197503000-00026]. The convulsant effects may result from enflurane's organic and inorganic nonvolatile fluorinated metabolites [@10.1097/00000542-197109000-00007].\r\n\r\n> Although anesthesiologists consider diazepam and thiopental to be anticonvulsants and use them extensively to treat seizure activity, there is some evidence that these drugs may potentiate enflurane-related epileptiform activity in humans [@10.1007/bf03006812]. Nitrous oxide (N2O) does not alter epileptiform activity induced by enflurane [@10.1097/00000542-197111000-00006].\r\n\r\n@pouyakhankhanian do you think this is sufficient evidence to classify enflurane as a IGD? It's likely this information was overlooked due to the poor discoverability of these old studies.",
      "comment_id": 1369,
      "profile_id": 17,
      "published": "2016-10-17T20:02:21.351172Z",
      "thread_id": 224,
      "url": "/discussion/prediction-in-epilepsy/224#6"
    },
    {
      "body_html": "<p>I wanted a black background version of the figures, so I quickly color rotated and inverted the images. I couldn't figure out how to upload figures on thinklab - perhaps I don't have access to the project manager. In any case, you can generate them yourself easily with this command:</p>\r\n\r\n<p><code>convert hetionet-v1.0-labeled-landscape.png -modulate 100,100,0 -negate hetionet-v1.0-labeled-landscape-invertcr.png</code></p>\r\n\r\n<p>Thanks to <a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a>'s note below:</p>\r\n\r\n<p><img src=\"https://cloud.githubusercontent.com/assets/542643/19480670/41b61926-9519-11e6-8db3-126980293bcb.png\" alt=\"hetionet-v1 0-labeled-landscape-invertcr\"></p>\r\n\r\n<p><img src=\"https://cloud.githubusercontent.com/assets/542643/19480669/41b30d8a-9519-11e6-84d2-721f5d0aeece.png\" alt=\"hetionet-v1 0-labeled-invertcr\"></p>",
      "body_md": "I wanted a black background version of the figures, so I quickly color rotated and inverted the images. I couldn't figure out how to upload figures on thinklab - perhaps I don't have access to the project manager. In any case, you can generate them yourself easily with this command:\r\n\r\n`convert hetionet-v1.0-labeled-landscape.png -modulate 100,100,0 -negate hetionet-v1.0-labeled-landscape-invertcr.png`\r\n\r\nThanks to @dhimmel's note below:\r\n\r\n![hetionet-v1 0-labeled-landscape-invertcr](https://cloud.githubusercontent.com/assets/542643/19480670/41b61926-9519-11e6-8db3-126980293bcb.png)\r\n\r\n![hetionet-v1 0-labeled-invertcr](https://cloud.githubusercontent.com/assets/542643/19480669/41b30d8a-9519-11e6-84d2-721f5d0aeece.png)",
      "comment_id": 1371,
      "profile_id": 22,
      "published": "2016-10-18T12:20:45.079385Z",
      "thread_id": 202,
      "url": "/discussion/describing-hetionet-v10-through-visualization-and-statistics/202#9"
    },
    {
      "body_html": "<h1>Updated contribution stats &amp; visualization</h1>\r\n\r\n<p>I updated <a href=\"/u/alizee\" class=\"username\">@alizee</a>'s <a href=\"#2\">contribution plot</a> with contribution data up to 2016-10-18:</p>\r\n\r\n<p><img src=\"https://github.com/dhimmel/thinklytics/raw/d0be2252f7c21da2489e97f5105a9c6c8bf15100/viz/rephetio-contribution.png\" alt=\"rephetio contribution\" title=\"The growth the Project Rephetio corpus on Thinklab over time\"></p>\r\n\r\n<p>The figure caption from our forthcoming project report is:</p>\r\n\r\n<blockquote><p>This figure shows Project Rephetio contributions by user over time. Each band represented the cumulative contribution of a Thinklab user to discussions in the Rephetio project. Users are ordered by date of first contribution. Users who contributed over 4,000 characters are named. The square root transformation of characters written per user accentuates the activity of new contributors, thereby emphasizing collaboration and diverse input.</p></blockquote>\r\n\r\n<p>The <a href=\"https://github.com/dhimmel/thinklytics/blob/d0be2252f7c21da2489e97f5105a9c6c8bf15100/viz/rephetio-rviz.ipynb\">notebook that creates the visualization</a> also contains project contribution stats across all Rephetio discussions, which at time of writing total:</p>\r\n\r\n<ul><li>80 discussions</li><li>488 comments</li><li>161 notes</li><li>44 contributors, 36 of which were from the community (non-team members)</li><li>680,121 characters</li><li>108,699 words (equivalent in volume to ~15.53 journal publications, based on <a href=\"http://academia.stackexchange.com/q/35133\" title=\"Academia StackExchange: How many words is a typical scientific publication (particularly in biology)?\">an estimate</a> of 7,000 words per publication)</li></ul>\r\n\r\n<p>If in addition to discussions, <a href=\"https://github.com/dhimmel/thinklytics/blob/d0be2252f7c21da2489e97f5105a9c6c8bf15100/process/table/summaries.tsv#L10\">the stats</a> include project documents — which at the moment only includes the proposal <span class=\"citation\">[<a href=\"/p/rephetio/proposal\" class=\"citation\" data-key=\"10.15363/thinklab.a5\">1</a>]</span>, but will include the report once published — the summary is:</p>\r\n\r\n<ul><li>445 total cited DOIs</li><li>698,830 total characters</li><li>111,425 total words (equivalent in volume to ~15.92 journal publications)</li></ul>",
      "body_md": "# Updated contribution stats & visualization\r\n\r\nI updated @alizee's [contribution plot](#2) with contribution data up to 2016-10-18:\r\n\r\n![rephetio contribution](https://github.com/dhimmel/thinklytics/raw/d0be2252f7c21da2489e97f5105a9c6c8bf15100/viz/rephetio-contribution.png \"The growth the Project Rephetio corpus on Thinklab over time\")\r\n\r\nThe figure caption from our forthcoming project report is:\r\n\r\n> This figure shows Project Rephetio contributions by user over time. Each band represented the cumulative contribution of a Thinklab user to discussions in the Rephetio project. Users are ordered by date of first contribution. Users who contributed over 4,000 characters are named. The square root transformation of characters written per user accentuates the activity of new contributors, thereby emphasizing collaboration and diverse input.\r\n\r\nThe [notebook that creates the visualization](https://github.com/dhimmel/thinklytics/blob/d0be2252f7c21da2489e97f5105a9c6c8bf15100/viz/rephetio-rviz.ipynb) also contains project contribution stats across all Rephetio discussions, which at time of writing total:\r\n\r\n+ 80 discussions\r\n+ 488 comments\r\n+ 161 notes\r\n+ 44 contributors, 36 of which were from the community (non-team members)\r\n+ 680,121 characters\r\n+ 108,699 words (equivalent in volume to ~15.53 journal publications, based on [an estimate](http://academia.stackexchange.com/q/35133 \"Academia StackExchange: How many words is a typical scientific publication (particularly in biology)?\") of 7,000 words per publication)\r\n\r\nIf in addition to discussions, [the stats](https://github.com/dhimmel/thinklytics/blob/d0be2252f7c21da2489e97f5105a9c6c8bf15100/process/table/summaries.tsv#L10) include project documents -- which at the moment only includes the proposal [@10.15363/thinklab.a5], but will include the report once published -- the summary is:\r\n\r\n+ 445 total cited DOIs\r\n+ 698,830 total characters\r\n+ 111,425 total words (equivalent in volume to ~15.92 journal publications)",
      "comment_id": 1372,
      "profile_id": 17,
      "published": "2016-10-31T20:47:53.133611Z",
      "thread_id": 200,
      "url": "/discussion/measuring-user-contribution-and-content-creation/200#4"
    },
    {
      "body_html": "<h1>Interactive metaedge table</h1>\r\n\r\n<p>An interactive metaedge table is available online at <a href=\"http://het.io/repurpose/metapaths.html\">http://het.io/repurpose/metapaths.html</a>. Here you can browse and search through all 1,206 metapaths. The interface currently looks like:</p>\r\n\r\n<p><img src=\"https://cloud.githubusercontent.com/assets/1117703/20021803/df14bac8-a2ad-11e6-904e-8c12813582e0.png\" alt=\"Screenshot of the Project Rephetio Metaedge Browser at http://het.io/repurpose/metapaths.html\"></p>",
      "body_md": "# Interactive metaedge table\r\n\r\nAn interactive metaedge table is available online at http://het.io/repurpose/metapaths.html. Here you can browse and search through all 1,206 metapaths. The interface currently looks like:\r\n\r\n![Screenshot of the Project Rephetio Metaedge Browser at http://het.io/repurpose/metapaths.html](https://cloud.githubusercontent.com/assets/1117703/20021803/df14bac8-a2ad-11e6-904e-8c12813582e0.png)",
      "comment_id": 1374,
      "profile_id": 17,
      "published": "2016-11-04T20:46:33.348400Z",
      "thread_id": 115,
      "url": "/discussion/assessing-the-informativeness-of-features/115#5"
    },
    {
      "body_html": "<h1>Additional references</h1>\r\n\r\n<p>I'll try to keep the following list up to date with webpages or papers I come across that provide relevant data licensing information.</p>\r\n\r\n<ul><li><strong>Legal confusion threatens to slow data science</strong> <span class=\"citation\">[<a href=\"https://doi.org/10.1038/536016a\" class=\"citation\" data-key=\"10.1038/536016a\">1</a>]</span> — which discusses our licensing struggles in creating Hetionet</li><li><strong>Sharing Research Data and Intellectual Property Law: A Primer</strong> <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pbio.1002235\" class=\"citation\" data-key=\"10.1371/journal.pbio.1002235\">2</a>]</span></li><li><strong>Legal Interoperability of Research Data: Principles and Implementation Guidelines</strong> <span class=\"citation\">[<a href=\"https://doi.org/10.5281/zenodo.162241\" class=\"citation\" data-key=\"10.5281/zenodo.162241\">3</a>]</span></li><li><strong>Who “owns” your data?</strong> by <a href=\"/u/katiefortney\" class=\"username\">@katiefortney</a> <a href=\"http://osc.universityofcalifornia.edu/2016/09/who-owns-your-data/\">published on</a> the University of California, Office of Scholarly Communication Blog.</li><li><strong>Create guidelines for OBO maintainers who want to be included in Wikidata</strong> — <a href=\"https://github.com/OBOFoundry/OBOFoundry.github.io/issues/285\">Issue #285 on the OBOFoundry GitHub</a> discussing licensing options for biomedical ontologies.</li></ul>",
      "body_md": "# Additional references\r\n\r\nI'll try to keep the following list up to date with webpages or papers I come across that provide relevant data licensing information.\r\n\r\n+ **Legal confusion threatens to slow data science** [@10.1038/536016a] -- which discusses our licensing struggles in creating Hetionet\r\n+ **Sharing Research Data and Intellectual Property Law: A Primer** [@10.1371/journal.pbio.1002235]\r\n+ **Legal Interoperability of Research Data: Principles and Implementation Guidelines** [@10.5281/zenodo.162241]\r\n+ **Who “owns” your data?** by @katiefortney [published on](http://osc.universityofcalifornia.edu/2016/09/who-owns-your-data/) the University of California, Office of Scholarly Communication Blog.\r\n+ **Create guidelines for OBO maintainers who want to be included in Wikidata** -- [Issue #285 on the OBOFoundry GitHub](https://github.com/OBOFoundry/OBOFoundry.github.io/issues/285) discussing licensing options for biomedical ontologies.",
      "comment_id": 1375,
      "profile_id": 17,
      "published": "2016-11-13T15:27:24.684544Z",
      "thread_id": 107,
      "url": "/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#15"
    },
    {
      "body_html": "<h1>Project PrePrint / Report</h1>\r\n\r\n<p>We've posted the manuscript describing Project Rephetio as a <a href=\"https://thinklab.com/p/rephetio/report\">report on Thinklab</a> <span class=\"citation\">[<a href=\"/p/rephetio/report\" class=\"citation\" data-key=\"10.15363/thinklab.a7\">1</a>]</span> and <a href=\"http://biorxiv.org/content/early/2016/11/14/087619\">preprint on bioRxiv</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1101/087619\" class=\"citation\" data-key=\"10.1101/087619\">2</a>]</span>. We're submitting the study to the journal <a href=\"https://elifesciences.org/\"><em>eLife</em></a>. Thanks again to the tremendous efferts of everyone who helped us reach this point!</p>\r\n\r\n<p>I posted the preprint while at <a href=\"http://www.opencon2016.org/\" title=\"OpenCon in Washington, DC\">OpenCon 2016</a>, which turned out to be a bit of a saga that unfolded through the following series of tweets: <a href=\"https://twitter.com/mbeisen/status/798010364969549824\" title=\"Tweet by Michael Eisen\">1</a>, <a href=\"https://twitter.com/dhimmel/status/798013336386473984\" title=\"Tweet by Daniel Himmelstein\">2</a>, <a href=\"https://twitter.com/dhimmel/status/798030657352073217\" title=\"Tweet by Daniel Himmelstein\">3</a>, <a href=\"https://twitter.com/RadicevSlobodan/status/799621719195521029\" title=\"Tweet by Slobodan Radicev\">4</a>, <a href=\"https://twitter.com/RadicevSlobodan/status/798346337326657536\" title=\"Tweet by Sean Davis\">5</a>.</p>",
      "body_md": "# Project PrePrint / Report\r\n\r\nWe've posted the manuscript describing Project Rephetio as a [report on Thinklab](https://thinklab.com/p/rephetio/report) [@10.15363/thinklab.a7] and [preprint on bioRxiv](http://biorxiv.org/content/early/2016/11/14/087619) [@10.1101/087619]. We're submitting the study to the journal [_eLife_](https://elifesciences.org/). Thanks again to the tremendous efferts of everyone who helped us reach this point!\r\n\r\nI posted the preprint while at [OpenCon 2016](http://www.opencon2016.org/ \"OpenCon in Washington, DC\"), which turned out to be a bit of a saga that unfolded through the following series of tweets: [1](https://twitter.com/mbeisen/status/798010364969549824 \"Tweet by Michael Eisen\"), [2](https://twitter.com/dhimmel/status/798013336386473984 \"Tweet by Daniel Himmelstein\"), [3](https://twitter.com/dhimmel/status/798030657352073217 \"Tweet by Daniel Himmelstein\"), [4](https://twitter.com/RadicevSlobodan/status/799621719195521029 \"Tweet by Slobodan Radicev\"), [5](https://twitter.com/RadicevSlobodan/status/798346337326657536 \"Tweet by Sean Davis\").",
      "comment_id": 1376,
      "profile_id": 17,
      "published": "2016-11-14T22:20:56.565123Z",
      "thread_id": 113,
      "url": "/discussion/tracking-project-reuse-citation-and-publicity/113#11"
    },
    {
      "body_html": "<h2>GraphConnect Presentation</h2>\r\n\r\n<p>I gave a <a href=\"http://graphconnect.com/speaker/daniel-himmelstein/\">lighting talk</a> at GraphConnect 2016 — a conference devoted to graph databases that is hosted by Neo4j. The recording is below:</p>\r\n\r\n<p></p><div class=\"iframe-container\"><iframe src=\"https://www.youtube.com/embed/jwhAlNgjvMA\" frameborder=\"0\" allowfullscreen=\"true\"></iframe></div>\r\n\r\n<h2>Hetionet poster</h2>\r\n\r\n<p>I created a poster to raise awareness of hetnets, especially Hetionet v1.0, which is <a href=\"https://doi.org/br6n\">available on figshare</a> <span class=\"citation\">[<a href=\"https://doi.org/10.6084/m9.figshare.4054902\" class=\"citation\" data-key=\"10.6084/m9.figshare.4054902\">1</a>]</span>. I presented the poster at the Moore Data-Driven Discovery Investigator Symposium, the <a href=\"http://www.med.upenn.edu/bprs/abstracts.html?id=26486#Poster23\">Penn Biomedical Postdoctoral Research Symposium</a>, and the upcoming <a href=\"https://www.iscb.org/cms_addon/conferences/rocky2016/track/postersbrief.php#P71\">Rocky Bioinformatics Conference</a>.</p>",
      "body_md": "## GraphConnect Presentation\r\n\r\nI gave a [lighting talk](http://graphconnect.com/speaker/daniel-himmelstein/) at GraphConnect 2016 -- a conference devoted to graph databases that is hosted by Neo4j. The recording is below:\r\n\r\n![:youtube](jwhAlNgjvMA)\r\n\r\n## Hetionet poster\r\n\r\nI created a poster to raise awareness of hetnets, especially Hetionet v1.0, which is [available on figshare](https://doi.org/br6n) [@10.6084/m9.figshare.4054902]. I presented the poster at the Moore Data-Driven Discovery Investigator Symposium, the [Penn Biomedical Postdoctoral Research Symposium](http://www.med.upenn.edu/bprs/abstracts.html?id=26486#Poster23), and the upcoming [Rocky Bioinformatics Conference](https://www.iscb.org/cms_addon/conferences/rocky2016/track/postersbrief.php#P71).",
      "comment_id": 1377,
      "profile_id": 17,
      "published": "2016-11-14T22:29:38.456454Z",
      "thread_id": 113,
      "url": "/discussion/tracking-project-reuse-citation-and-publicity/113#12"
    },
    {
      "body_html": "<h1>Acamprosate for epilepsy</h1>\r\n\r\n<p>Epilepsy was the top <a href=\"http://het.io/repurpose/browse.html?id=DB00659\" title=\"Project Rephetio acamprosate predictions\">prediction for acamprosate</a> — an approved treatment for alcohol dependence. From the results of our initial project report <span class=\"citation\">[<a href=\"/p/rephetio/report\" class=\"citation\" data-key=\"10.15363/thinklab.a7\">1</a>, <a href=\"https://doi.org/10.1101/087619\" class=\"citation\" data-key=\"10.1101/087619\">2</a>]</span>:</p>\r\n\r\n<blockquote><p>Given this high precision (77%), the 8 compounds of unknown effect are promising repurposing candidates. For example, acamprosate — whose top prediction was epilepsy — is a taurine analog that promotes alcohol abstinence. Support for this repurposing arose from acamprosate's positive modulation of the GABAᴬ receptor and inhibition of the glutamate receptor. If effective against epilepsy, acamprosate could serve a dual benefit for recovering alcoholics who experience seizures from alcohol withdrawal.</p></blockquote>\r\n\r\n<p>And from the discussion:</p>\r\n\r\n<blockquote><p>Accordingly, we hope certain predictions will spur further research, such as trials to investigate the off-label use of acamprosate for epilepsy.</p></blockquote>\r\n\r\n<p>More recently, <a href=\"/u/pouyakhankhanian\" class=\"username\">@pouyakhankhanian</a> identified a 2008 study (Farook et al.) that provides evidence in a single animal model that acamprosate treats epilepsy  <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.physbeh.2008.05.020\" class=\"citation\" data-key=\"10.1016/j.physbeh.2008.05.020\">3</a>]</span>. The study found that both acampasate and diazepam (positive control) reduced \"handling induced convulsions\":</p>\r\n\r\n<blockquote><p><img src=\"https://cloud.githubusercontent.com/assets/1117703/20408655/6d95be10-ace4-11e6-8c50-51afaa048f0b.jpg\" alt=\"Figure 2 of https://doi.org/cnfsgc\" title=\"Effects of IP administration of diazepam (0.25, 0.5 and 1 mg/kg) and acamprosate (100, 200 and 300 mg/kg) in male Swiss Webster mice 10 h after the last ‘alcohol + 4-MP’ injection on day 3 in HIC test. Drug solutions or saline (for ‘control’ or ‘alcohol + 4-MP’ treated animals) were administered 30 min prior to the test. Values are expressed as ± S.E.M. ⁎p &lt; 0.05, ⁎⁎p &lt; 0.001 by post hoc Tukey HSD against the alcohol + 4-MP group.\"></p></blockquote>\r\n\r\n<p>In the Hetionet Browser, we <a href=\"https://neo4j.het.io/browser/?cmd=play&amp;arg=https://neo4j.het.io/guides/rep/DB00659/DOID_1826.html\" title=\"Neo4j Browser for acamprosate-epilepsy\">find the following support</a> (only the ten most supportive paths are shown):</p>\r\n\r\n<p><img src=\"https://cloud.githubusercontent.com/assets/1117703/20409718/a8f1e066-ace8-11e6-9ff2-d31fc2d9d7d5.png\" alt=\"Rephetio paths supporting that acamprosate treats epilepsy\"></p>\r\n\r\n<p>We pick up that acamprosate binds to the GABAA receptor as a positive modular. Furthermore, acamprosate binds to the glutamate receptor as an antagonist. Felbamate and rufinamide — which treat epilepsy — are also glutamate receptor antagonists/inhibitors. The network support provides similar reasoning to the authors of Farook et al.:</p>\r\n\r\n<blockquote><p>It was anticipated that diazepam would reduce alcohol withdrawal-induced seizures and this was the case. It is of particular interest that acamprosate had similar anticonvulsant actions with that of diazepam. The underlying mechanism or mechanisms for acamprosate's action are still not well understood. Early on, it was believed that the actions of acamprosate were via its effects on the inhibitory neurotransmitter GABA but this was based primarily on structural analysis with little empirical evidence to support this. Some of the strongest recent evidence supports the actions of acamprosate on glutamate function and/or receptors as the putative mechanism <span class=\"citation\">[<a href=\"https://doi.org/10.2165/00023210-200519060-00004\" class=\"citation\" data-key=\"10.2165/00023210-200519060-00004\">4</a>]</span>.</p></blockquote>\r\n\r\n<p>Accordingly, we continue to be excited the use of acamprosate to treat seizures from alcohol withdrawal syndrome.</p>",
      "body_md": "# Acamprosate for epilepsy\r\n\r\nEpilepsy was the top [prediction for acamprosate](http://het.io/repurpose/browse.html?id=DB00659 \"Project Rephetio acamprosate predictions\") -- an approved treatment for alcohol dependence. From the results of our initial project report [@10.15363/thinklab.a7 @10.1101/087619]:\r\n\r\n> Given this high precision (77%), the 8 compounds of unknown effect are promising repurposing candidates. For example, acamprosate — whose top prediction was epilepsy — is a taurine analog that promotes alcohol abstinence. Support for this repurposing arose from acamprosate's positive modulation of the GABAᴬ receptor and inhibition of the glutamate receptor. If effective against epilepsy, acamprosate could serve a dual benefit for recovering alcoholics who experience seizures from alcohol withdrawal.\r\n\r\nAnd from the discussion:\r\n\r\n> Accordingly, we hope certain predictions will spur further research, such as trials to investigate the off-label use of acamprosate for epilepsy.\r\n\r\nMore recently, @pouyakhankhanian identified a 2008 study (Farook et al.) that provides evidence in a single animal model that acamprosate treats epilepsy  [@10.1016/j.physbeh.2008.05.020]. The study found that both acampasate and diazepam (positive control) reduced \"handling induced convulsions\":\r\n\r\n> ![Figure 2 of https://doi.org/cnfsgc](https://cloud.githubusercontent.com/assets/1117703/20408655/6d95be10-ace4-11e6-8c50-51afaa048f0b.jpg \"Effects of IP administration of diazepam (0.25, 0.5 and 1 mg/kg) and acamprosate (100, 200 and 300 mg/kg) in male Swiss Webster mice 10 h after the last ‘alcohol + 4-MP’ injection on day 3 in HIC test. Drug solutions or saline (for ‘control’ or ‘alcohol + 4-MP’ treated animals) were administered 30 min prior to the test. Values are expressed as ± S.E.M. ⁎p < 0.05, ⁎⁎p < 0.001 by post hoc Tukey HSD against the alcohol + 4-MP group.\")\r\n\r\nIn the Hetionet Browser, we [find the following support](https://neo4j.het.io/browser/?cmd=play&arg=https://neo4j.het.io/guides/rep/DB00659/DOID_1826.html \"Neo4j Browser for acamprosate-epilepsy\") (only the ten most supportive paths are shown):\r\n\r\n![Rephetio paths supporting that acamprosate treats epilepsy](https://cloud.githubusercontent.com/assets/1117703/20409718/a8f1e066-ace8-11e6-9ff2-d31fc2d9d7d5.png)\r\n\r\nWe pick up that acamprosate binds to the GABAA receptor as a positive modular. Furthermore, acamprosate binds to the glutamate receptor as an antagonist. Felbamate and rufinamide -- which treat epilepsy -- are also glutamate receptor antagonists/inhibitors. The network support provides similar reasoning to the authors of Farook et al.:\r\n\r\n> It was anticipated that diazepam would reduce alcohol withdrawal-induced seizures and this was the case. It is of particular interest that acamprosate had similar anticonvulsant actions with that of diazepam. The underlying mechanism or mechanisms for acamprosate's action are still not well understood. Early on, it was believed that the actions of acamprosate were via its effects on the inhibitory neurotransmitter GABA but this was based primarily on structural analysis with little empirical evidence to support this. Some of the strongest recent evidence supports the actions of acamprosate on glutamate function and/or receptors as the putative mechanism [@10.2165/00023210-200519060-00004].\r\n\r\nAccordingly, we continue to be excited the use of acamprosate to treat seizures from alcohol withdrawal syndrome.",
      "comment_id": 1378,
      "profile_id": 17,
      "published": "2016-11-17T22:29:05.987464Z",
      "thread_id": 224,
      "url": "/discussion/prediction-in-epilepsy/224#7"
    },
    {
      "body_html": "<h1>CC BY and data: Not always a good fit</h1>\r\n\r\n<p>In a recent blog post for the University of California's Office of Scholarly Communication Blog, titled <a href=\"http://osc.universityofcalifornia.edu/2016/09/cc-by-and-data-not-always-a-good-fit/\"><em>CC BY and data: Not always a good fit</em></a>, <a href=\"/u/katiefortney\" class=\"username\">@katiefortney</a> writes:</p>\r\n\r\n<blockquote><p><strong>And licenses that dictate exactly how later projects reuse data and provide attribution can hobble those projects</strong>. For just one example, see <a href=\"https://thinklab.com/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d107\">this discussion</a> of licensing issues in Rephetio, a project that’s done a particularly good job documenting the challenges faced in attempting to reuse drug repurposing data. Data reusers should follow best practices for data citation in their field given their particular project. If data sharers can trust them to do just that, rather than trying to shoehorn attribution practices into one-size-fits-all copyright licenses, they can make it much easier for others to reuse their data.</p></blockquote>\r\n\r\n<p>Regarding explanatory notes alongside licenses, she writes:</p>\r\n\r\n<blockquote><p>Explanatory notes about your expectations alongside a CC license may help by showing that you’re aware that there’s complexity, or by inviting data users to initiate a conversation about desired uses. But avoid adding language to your notes that contradicts your chosen license; see <a href=\"https://thinklab.com/discussion/sounding-the-alarm-on-drugbanks-new-license-and-terms-of-use/213\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d213\">another discussion</a> from the Rephetio project mentioned above for an example of custom terms of use that conflicted with a CC license, leading to confusion.</p></blockquote>\r\n\r\n<p>Great to see that our discussions on the legal barriers to data use were helpful examples! Awesome post <a href=\"/u/katiefortney\" class=\"username\">@katiefortney</a>!</p>",
      "body_md": "# CC BY and data: Not always a good fit\r\n\r\nIn a recent blog post for the University of California's Office of Scholarly Communication Blog, titled [_CC BY and data: Not always a good fit_](http://osc.universityofcalifornia.edu/2016/09/cc-by-and-data-not-always-a-good-fit/), @katiefortney writes:\r\n\r\n> **And licenses that dictate exactly how later projects reuse data and provide attribution can hobble those projects**. For just one example, see [this discussion](https://thinklab.com/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107) of licensing issues in Rephetio, a project that’s done a particularly good job documenting the challenges faced in attempting to reuse drug repurposing data. Data reusers should follow best practices for data citation in their field given their particular project. If data sharers can trust them to do just that, rather than trying to shoehorn attribution practices into one-size-fits-all copyright licenses, they can make it much easier for others to reuse their data.\r\n\r\nRegarding explanatory notes alongside licenses, she writes:\r\n\r\n> Explanatory notes about your expectations alongside a CC license may help by showing that you’re aware that there’s complexity, or by inviting data users to initiate a conversation about desired uses. But avoid adding language to your notes that contradicts your chosen license; see [another discussion](https://thinklab.com/discussion/sounding-the-alarm-on-drugbanks-new-license-and-terms-of-use/213) from the Rephetio project mentioned above for an example of custom terms of use that conflicted with a CC license, leading to confusion.\r\n\r\nGreat to see that our discussions on the legal barriers to data use were helpful examples! Awesome post @katiefortney!",
      "comment_id": 1379,
      "profile_id": 17,
      "published": "2016-11-19T15:16:40.378617Z",
      "thread_id": 113,
      "url": "/discussion/tracking-project-reuse-citation-and-publicity/113#13"
    },
    {
      "body_html": "<p>Last Friday, in an <a href=\"http://greenelab-onboarding.readthedocs.io/en/latest/communication.html#meetings\" title=\"Greene Lab Onboarding: Meetings\">applied imagination</a> meeting for the <a href=\"/u/caseygreene\" class=\"username\">@caseygreene</a> lab, we brainstormed future directions for Hetionet. The timing worked out well as we had just released our <a href=\"https://thinklab.com/p/rephetio/report\">initial report</a> <span class=\"citation\">[<a href=\"/p/rephetio/report\" class=\"citation\" data-key=\"10.15363/thinklab.a7\">1</a>, <a href=\"https://doi.org/10.1101/087619\" class=\"citation\" data-key=\"10.1101/087619\">2</a>]</span>.</p>\r\n\r\n<p><strong>The following modifications to Hetionet were brought up:</strong></p>\r\n\r\n<ul><li>Adding biologic drugs, e.g. antibodies, since Hetionet v1.0 <a href=\"https://thinklab.com/discussion/unifying-drug-vocabularies/40#5\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d40\">only includes</a> approved small molecules. In previous private communications, <a href=\"/u/sergiobaranzini\" class=\"username\">@sergiobaranzini</a> has also strongly supported adding biologics as well as a more comprehensive set of small molecules.</li><li>Adding metabolites since the efficacy of many small molecules results from metabolites.</li><li>Updating Hetionet continuously in an automated fashion. Versioning could enable updates, using a scheme similar to API versioning. For example, we could use versioned URLs for our Neo4j Browser, such as <code>v1.het.io</code>.</li><li>Adding microbiome information, such as microbial communities and drug-microbe interactions.</li><li>Create the network by <a href=\"https://github.com/HazyResearch/snorkel\">snorkeling</a> the literature. Hetionet v1.0 could be used as the \"ground truth\" to extract labeling functions. We alluded to data programming techniques in the report, writing \"Going forward, advances in automated mining of the scientific literature could enable extraction of precise relationship types at omics scale <span class=\"citation\">[<a href=\"https://doi.org/10.1145/2939502.2939515\" class=\"citation\" data-key=\"10.1145/2939502.2939515\">3</a>]</span>.\"</li><li>Adding SNPs, potentially using <a href=\"http://exac.broadinstitute.org/\">ExAC</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nature19057\" class=\"citation\" data-key=\"10.1038/nature19057\">4</a>]</span> for allele frequencies.</li><li>Adding a discovery date property to relationships. Year of earliest publication could provide a proxy for some relationship types with source publication metadata. This could allow us to see if we can predict future knowledge from past knowledge and help address <a href=\"https://thinklab.com/discussion/text-as-a-resource-for-network-population/48#2\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d48\">knowledge biases</a>.</li><li>Incorporating universal edge weights representing confidence in a relationship. In the past, <a href=\"/u/larsjuhljensen\" class=\"username\">@larsjuhljensen</a> has also <a href=\"https://thinklab.com/discussion/the-tissues-resource-for-the-tissue-specificity-of-genes/91#3\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d91\">strongly advocated</a> against our binarization of uncertain relationships.</li><li>Supporting the addition of user-supplied relationships</li><li>Adopting more ontologies. Perform propagation during query-time. See <a href=\"https://github.com/greenelab/hetontology\">Hetontology</a> which aims to host all openly-licensed OBOFoundry ontologies in a public Neo4j instance.</li></ul>\r\n\r\n<p><strong>The following modifications to Project Rephetio were brought up:</strong></p>\r\n\r\n<ul><li>Quantifying the significance of a predication. Showing enrichment over null rather than probability of treatment to provide more context.</li><li>Algorithms that account for relationship weight/confidence when measuring path prevalence for a given metapath between two nodes.</li><li>Focusing on drugs and diseases as perturbations to biological systems/pathways.</li><li>Better capturing tissue specific effects. Accounting for which tissues/anatomies drug efficacy occurs in for a specific compound and disease. How do drugs work in a specific tissue?</li><li>Queries that leverage metapatterns, rather than just metapaths. Metapatterns encompass queries that search for more than just a simple path. Metapatterns could help create tissue-specific aware features and drill down on the mechanisms of drug efficacy. Currently, we identify when a drug will work, but not necessarily why a drug will work (mechanisms).</li></ul>\r\n\r\n<p><strong>The following new applications of Hetionet were discussed:</strong></p>\r\n\r\n<ul><li>Predicting drug-drug interactions.</li><li>Allowing users to provide their own gene sets. Enabling some sort of gene set enrichment queries. For example, what drugs interact with a given gene set?</li><li>When multiple drugs are available for a disease, what are the differences and which drug should be used for a given patient?</li><li>Clustering nodes, such as extracting gene modules.</li></ul>\r\n\r\n<p>Thanks to everyone who participated: <a href=\"/u/caseygreene\" class=\"username\">@caseygreene</a>, Jaclyn Taroni, Jie Tan 💻, <a href=\"/u/gregway\" class=\"username\">@gregway</a>, Brett Beaulieu-Jones, René Zelaya, Matt Huyck 💻, Dongbo Hu, Amy Campbell, Kathy Chen, Timothy Chang, Linda Zhou, and Stephen Woloszynek (💻 denotes virtual participation). There're clearly more ideas than time, which is why these discussions are important — so we pursue only the best!</p>",
      "body_md": "Last Friday, in an [applied imagination](http://greenelab-onboarding.readthedocs.io/en/latest/communication.html#meetings \"Greene Lab Onboarding: Meetings\") meeting for the @caseygreene lab, we brainstormed future directions for Hetionet. The timing worked out well as we had just released our [initial report](https://thinklab.com/p/rephetio/report) [@10.15363/thinklab.a7 @10.1101/087619].\r\n\r\n**The following modifications to Hetionet were brought up:**\r\n\r\n+ Adding biologic drugs, e.g. antibodies, since Hetionet v1.0 [only includes](https://thinklab.com/discussion/unifying-drug-vocabularies/40#5) approved small molecules. In previous private communications, @sergiobaranzini has also strongly supported adding biologics as well as a more comprehensive set of small molecules.\r\n+ Adding metabolites since the efficacy of many small molecules results from metabolites.\r\n+ Updating Hetionet continuously in an automated fashion. Versioning could enable updates, using a scheme similar to API versioning. For example, we could use versioned URLs for our Neo4j Browser, such as `v1.het.io`.\r\n+ Adding microbiome information, such as microbial communities and drug-microbe interactions.\r\n+ Create the network by [snorkeling](https://github.com/HazyResearch/snorkel) the literature. Hetionet v1.0 could be used as the \"ground truth\" to extract labeling functions. We alluded to data programming techniques in the report, writing \"Going forward, advances in automated mining of the scientific literature could enable extraction of precise relationship types at omics scale [@10.1145/2939502.2939515].\"\r\n+ Adding SNPs, potentially using [ExAC](http://exac.broadinstitute.org/) [@10.1038/nature19057] for allele frequencies.\r\n+ Adding a discovery date property to relationships. Year of earliest publication could provide a proxy for some relationship types with source publication metadata. This could allow us to see if we can predict future knowledge from past knowledge and help address [knowledge biases](https://thinklab.com/discussion/text-as-a-resource-for-network-population/48#2).\r\n+ Incorporating universal edge weights representing confidence in a relationship. In the past, @larsjuhljensen has also [strongly advocated](https://thinklab.com/discussion/the-tissues-resource-for-the-tissue-specificity-of-genes/91#3) against our binarization of uncertain relationships.\r\n+ Supporting the addition of user-supplied relationships\r\n+ Adopting more ontologies. Perform propagation during query-time. See [Hetontology](https://github.com/greenelab/hetontology) which aims to host all openly-licensed OBOFoundry ontologies in a public Neo4j instance.\r\n\r\n**The following modifications to Project Rephetio were brought up:**\r\n\r\n+ Quantifying the significance of a predication. Showing enrichment over null rather than probability of treatment to provide more context.\r\n+ Algorithms that account for relationship weight/confidence when measuring path prevalence for a given metapath between two nodes.\r\n+ Focusing on drugs and diseases as perturbations to biological systems/pathways.\r\n+ Better capturing tissue specific effects. Accounting for which tissues/anatomies drug efficacy occurs in for a specific compound and disease. How do drugs work in a specific tissue?\r\n+ Queries that leverage metapatterns, rather than just metapaths. Metapatterns encompass queries that search for more than just a simple path. Metapatterns could help create tissue-specific aware features and drill down on the mechanisms of drug efficacy. Currently, we identify when a drug will work, but not necessarily why a drug will work (mechanisms).\r\n\r\n**The following new applications of Hetionet were discussed:**\r\n\r\n+ Predicting drug-drug interactions.\r\n+ Allowing users to provide their own gene sets. Enabling some sort of gene set enrichment queries. For example, what drugs interact with a given gene set?\r\n+ When multiple drugs are available for a disease, what are the differences and which drug should be used for a given patient?\r\n+ Clustering nodes, such as extracting gene modules.\r\n\r\nThanks to everyone who participated: @caseygreene, Jaclyn Taroni, Jie Tan 💻, @gregway, Brett Beaulieu-Jones, René Zelaya, Matt Huyck 💻, Dongbo Hu, Amy Campbell, Kathy Chen, Timothy Chang, Linda Zhou, and Stephen Woloszynek (💻 denotes virtual participation). There're clearly more ideas than time, which is why these discussions are important -- so we pursue only the best!",
      "comment_id": 1380,
      "profile_id": 17,
      "published": "2016-11-19T22:35:44.035074Z",
      "thread_id": 227,
      "url": "/discussion/brainstorming-future-directions-for-hetionet/227"
    },
    {
      "body_html": "<p>Building on <strong>Adopting more ontologies. Perform propagation during query-time</strong>, here is text I had sitting in a draft:</p>\r\n\r\n<blockquote><p>Currently, we don't include ontological edges. For example, there is no <em>myelination→is_a→axon ensheathment</em> relationship despite its presence in the Gene Ontology. We omitted this information because we didn't have a query framework that accommodated its complexity. However, Neo4j supports <a href=\"https://neo4j.com/docs/developer-manual/3.0/cypher/#_variable_length\">variable-length pattern matching</a>, which will make realtime transitive closure feasible.</p></blockquote>",
      "body_md": "Building on **Adopting more ontologies. Perform propagation during query-time**, here is text I had sitting in a draft:\r\n\r\n> Currently, we don't include ontological edges. For example, there is no _myelination→is_a→axon ensheathment_ relationship despite its presence in the Gene Ontology. We omitted this information because we didn't have a query framework that accommodated its complexity. However, Neo4j supports [variable-length pattern matching](https://neo4j.com/docs/developer-manual/3.0/cypher/#_variable_length), which will make realtime transitive closure feasible.",
      "comment_id": 1381,
      "profile_id": 17,
      "published": "2016-11-19T23:49:53.908355Z",
      "thread_id": 227,
      "url": "/discussion/brainstorming-future-directions-for-hetionet/227#2"
    },
    {
      "body_html": "<h1>Noting MRCOC</h1>\r\n\r\n<p>Head this through a <a href=\"https://twitter.com/bgood/status/800130613076336640\">Tweet</a> by <a href=\"/u/b_good\" class=\"username\">@b_good</a>. It appears that the National Library of Medicine precomputes literature co-occurrences for MeSH terms. See the page <a href=\"https://ii.nlm.nih.gov/MRCOC.shtml\">MEDLINE Co-Occurrences (MRCOC) Files</a>.</p>\r\n\r\n<p>This could replace some or all functionality of <a href=\"https://github.com/dhimmel/medline\"><code>dhimmel/medline</code></a> — however, I haven't actually looked into whether it's a user friendly substitute. Just wanted to take note.</p>",
      "body_md": "# Noting MRCOC\r\n\r\nHead this through a [Tweet](https://twitter.com/bgood/status/800130613076336640) by @b_good. It appears that the National Library of Medicine precomputes literature co-occurrences for MeSH terms. See the page [MEDLINE Co-Occurrences (MRCOC) Files](https://ii.nlm.nih.gov/MRCOC.shtml).\r\n\r\nThis could replace some or all functionality of [`dhimmel/medline`](https://github.com/dhimmel/medline) -- however, I haven't actually looked into whether it's a user friendly substitute. Just wanted to take note.",
      "comment_id": 1382,
      "profile_id": 17,
      "published": "2016-11-20T16:40:30.508850Z",
      "thread_id": 67,
      "url": "/discussion/mining-knowledge-from-medline-articles-and-their-indexed-mesh-terms/67#7"
    },
    {
      "body_html": "<p><a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a> I would really like to find a way to collaborate more directly.  We have two PhD students and a postdoc all working on extensions to the hetionet project - <strong>thanks entirely to your efforts to be open here on ThinkLab</strong>.  They are interested in: DeepDive/SNorkel, extending to rare genetic diseases, expanding drug coverage (particularly in relation to the <a href=\"http://www.calibr.org\">Calibr</a> collection we now will have access to), and generally improving the framework itself.  </p>\r\n\r\n<p>Apart from their interests, one of the things I would personally like to see is a better exposure of the network you have assembled to the community beyond bioinformaticians.  The purposes are both to support hypothesis generation for them and to tap into their collective expertise to crowdsource the curation and extension of the network.  One way that might be achieved would be to load it into an incarnation of an application I am building in partnership with Richard Bruskiewich and his team at <a href=\"http://medgeninformatics.net/\">Star Informatics</a> called knowledge.bio.  The <a href=\"http://knowledge.bio\">first version of knowledge.bio</a> is online now, described in a <a href=\"http://biorxiv.org/content/early/2016/05/26/055525\">BioarXiv article</a> and available on in the <a href=\"https://bitbucket.org/sulab/kb1\">kb1 bitbucket repo</a>.  The next version is due to be released at the end of the year, is a complete rewrite (including a move to neo4j), makes extensive use of wikidata,  supports limited social features, and is available in the <a href=\"https://bitbucket.org/sulab/kb2\">kb2 repo</a>.  </p>\r\n\r\n<p>Everything above is at the 'strong starting point' phase.  If you or other members of your group are interested in joining forces to take them to fruition, let us know!</p>",
      "body_md": "@dhimmel I would really like to find a way to collaborate more directly.  We have two PhD students and a postdoc all working on extensions to the hetionet project - **thanks entirely to your efforts to be open here on ThinkLab**.  They are interested in: DeepDive/SNorkel, extending to rare genetic diseases, expanding drug coverage (particularly in relation to the [Calibr] (http://www.calibr.org) collection we now will have access to), and generally improving the framework itself.  \r\n\r\nApart from their interests, one of the things I would personally like to see is a better exposure of the network you have assembled to the community beyond bioinformaticians.  The purposes are both to support hypothesis generation for them and to tap into their collective expertise to crowdsource the curation and extension of the network.  One way that might be achieved would be to load it into an incarnation of an application I am building in partnership with Richard Bruskiewich and his team at [Star Informatics](http://medgeninformatics.net/) called knowledge.bio.  The [first version of knowledge.bio] (http://knowledge.bio) is online now, described in a [BioarXiv article] (http://biorxiv.org/content/early/2016/05/26/055525) and available on in the [kb1 bitbucket repo] (https://bitbucket.org/sulab/kb1).  The next version is due to be released at the end of the year, is a complete rewrite (including a move to neo4j), makes extensive use of wikidata,  supports limited social features, and is available in the [kb2 repo](https://bitbucket.org/sulab/kb2).  \r\n\r\nEverything above is at the 'strong starting point' phase.  If you or other members of your group are interested in joining forces to take them to fruition, let us know!",
      "comment_id": 1383,
      "profile_id": 48,
      "published": "2016-11-23T16:29:16.175193Z",
      "thread_id": 227,
      "url": "/discussion/brainstorming-future-directions-for-hetionet/227#3"
    },
    {
      "body_html": "<p>We are also working with the Monarch consortium on a large knowledge integration project known as TransMed.  This will be leveraging and extending the <a href=\"https://github.com/SciGraph/SciGraph\">SciGraph</a> system they built for Monarch.  SciGraph exposes OWL ontologies and associated knowledge bases for query in the form of graph databases like neo4j.</p>",
      "body_md": "We are also working with the Monarch consortium on a large knowledge integration project known as TransMed.  This will be leveraging and extending the [SciGraph](https://github.com/SciGraph/SciGraph) system they built for Monarch.  SciGraph exposes OWL ontologies and associated knowledge bases for query in the form of graph databases like neo4j.",
      "comment_id": 1384,
      "profile_id": 48,
      "published": "2016-11-23T16:34:51.531201Z",
      "thread_id": 227,
      "url": "/discussion/brainstorming-future-directions-for-hetionet/227#4"
    },
    {
      "body_html": "<p><a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a> thats an excellent list of potential ideas. I'd fully agree with expanding to include (reliable) data types as much as possible. The idea of automated continuous updating is very cool, but seems like a ton of workhours to maintain long term. Drug-drug interactions can easily be tested against a \"gold standard\" database. I'm guessing it's relatively cheap (in work hours) for you to re-write the code to create drug-drug matches?</p>",
      "body_md": "@dhimmel thats an excellent list of potential ideas. I'd fully agree with expanding to include (reliable) data types as much as possible. The idea of automated continuous updating is very cool, but seems like a ton of workhours to maintain long term. Drug-drug interactions can easily be tested against a \"gold standard\" database. I'm guessing it's relatively cheap (in work hours) for you to re-write the code to create drug-drug matches?",
      "comment_id": 1385,
      "profile_id": 188,
      "published": "2016-11-24T03:28:22.276132Z",
      "thread_id": 227,
      "url": "/discussion/brainstorming-future-directions-for-hetionet/227#5"
    },
    {
      "body_html": "<p>Just saw \"<a href=\"http://bib.oxfordjournals.org/content/early/2016/11/13/bib.bbw110.short\">A review of validation strategies for computational drug repositioning</a>\" <span class=\"citation\">[<a href=\"https://doi.org/10.1093/bib/bbw110\" class=\"citation\" data-key=\"10.1093/bib/bbw110\">1</a>]</span>. This review offers the following recommendation:</p>\r\n\r\n<blockquote><p>creating a true ‘gold standard’ that contains both repositioning successes and failures is one way to improve consistency in the field, and allows for equitable comparisons between methods. We believe that such a ‘gold standard’ database can improve the accuracy of drug repositioning methods and increase the probability of success in clinical trials.</p></blockquote>\r\n\r\n<p>For this project <span class=\"citation\">[<a href=\"/p/rephetio/report\" class=\"citation\" data-key=\"10.15363/thinklab.a7\">2</a>]</span>, we created <a href=\"https://thinklab.com/discussion/announcing-pharmacotherapydb-the-open-catalog-of-drug-therapies-for-disease/182\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d182\">PharmacotherapyDB</a> as a gold standard database that distinguishes disease-modifying treatments <span class=\"citation\">[<a href=\"/discussion/announcing-pharmacotherapydb-the-open-catalog-of-drug-therapies-for-disease/182\" class=\"citation\" data-key=\"10.15363/thinklab.d182\">3</a>, <a href=\"https://doi.org/10.6084/m9.figshare.3103054\" class=\"citation\" data-key=\"10.6084/m9.figshare.3103054\">4</a>]</span>. While PharmacotherapyDB was not designed to compile \"repositioning successes and failures\", it can still be used to assess the performance of drug efficacy predictions as suggested by the authors:</p>\r\n\r\n<blockquote><p>We propose a new direction in repositioning validation through the creation of a repositioning database to promote reproducible calculations of sensitivity and specificity.</p></blockquote>\r\n\r\n<p>Essentially, predicting whether a drug treats a disease is a superset of the drug repurposing problem. Therefore, I don't thinks it's problematic that we don't assess our predictions on repurposing successes versus failures. However, I do know that there are some treatment catalogs in the works by other groups that focus solely on drug repurposing, rather than all treatments. Once these are available, it would be nice to see how our predictions fare.</p>",
      "body_md": "Just saw \"[A review of validation strategies for computational drug repositioning](http://bib.oxfordjournals.org/content/early/2016/11/13/bib.bbw110.short)\" [@10.1093/bib/bbw110]. This review offers the following recommendation:\r\n\r\n> creating a true ‘gold standard’ that contains both repositioning successes and failures is one way to improve consistency in the field, and allows for equitable comparisons between methods. We believe that such a ‘gold standard’ database can improve the accuracy of drug repositioning methods and increase the probability of success in clinical trials.\r\n\r\nFor this project [@10.15363/thinklab.a7], we created [PharmacotherapyDB](https://thinklab.com/discussion/announcing-pharmacotherapydb-the-open-catalog-of-drug-therapies-for-disease/182) as a gold standard database that distinguishes disease-modifying treatments [@10.15363/thinklab.d182 @10.6084/m9.figshare.3103054]. While PharmacotherapyDB was not designed to compile \"repositioning successes and failures\", it can still be used to assess the performance of drug efficacy predictions as suggested by the authors:\r\n\r\n> We propose a new direction in repositioning validation through the creation of a repositioning database to promote reproducible calculations of sensitivity and specificity.\r\n\r\nEssentially, predicting whether a drug treats a disease is a superset of the drug repurposing problem. Therefore, I don't thinks it's problematic that we don't assess our predictions on repurposing successes versus failures. However, I do know that there are some treatment catalogs in the works by other groups that focus solely on drug repurposing, rather than all treatments. Once these are available, it would be nice to see how our predictions fare.",
      "comment_id": 1386,
      "profile_id": 17,
      "published": "2016-11-25T07:23:21.011200Z",
      "thread_id": 47,
      "url": "/discussion/evaluation-framework/47#4"
    },
    {
      "body_html": "<p>Should this be nAChR rather than nAChRs? Or  nAChRs but after genes?</p>",
      "body_md": "Should this be nAChR rather than nAChRs? Or  nAChRs but after genes?",
      "comment_id": 1387,
      "profile_id": 17,
      "published": "2016-11-28T16:44:14.572439Z",
      "thread_id": 226,
      "url": "/doc/7/review#1"
    },
    {
      "body_html": "<p>In this figure, <em>CHRNA3</em> should participate in not cause \"Nicotine Activity on Chromaffin Cells.\"</p>",
      "body_md": "In this figure, _CHRNA3_ should participate in not cause \"Nicotine Activity on Chromaffin Cells.\"",
      "comment_id": 1388,
      "profile_id": 17,
      "published": "2016-11-28T16:47:46.280429Z",
      "thread_id": 226,
      "url": "/doc/7/review#2"
    },
    {
      "body_html": "<p>Add \"which is supported by one animal model <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.physbeh.2008.05.020\" class=\"citation\" data-key=\"10.1016/j.physbeh.2008.05.020\">1</a>]</span>.\" See <a href=\"https://thinklab.com/discussion/prediction-in-epilepsy/224#7\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d224\">this comment</a> for more detail. Credit to <a href=\"/u/pouyakhankhanian\" class=\"username\">@pouyakhankhanian</a> for this suggesting and finding the study.</p>",
      "body_md": "Add \"which is supported by one animal model [@10.1016/j.physbeh.2008.05.020].\" See [this comment](https://thinklab.com/discussion/prediction-in-epilepsy/224#7) for more detail. Credit to @pouyakhankhanian for this suggesting and finding the study.",
      "comment_id": 1389,
      "profile_id": 17,
      "published": "2016-11-28T16:51:11.748664Z",
      "thread_id": 226,
      "url": "/doc/7/review#3"
    },
    {
      "body_html": "<p>yes I think the usual nomenclature is AChR or nAChR.</p>\n\n<p>the \"s\" would be to make is plural which I don't  think is needed</p>",
      "body_md": "yes I think the usual nomenclature is AChR or nAChR.\n\nthe \"s\" would be to make is plural which I don't  think is needed",
      "comment_id": 1390,
      "profile_id": 188,
      "published": "2016-11-28T21:41:43.231266Z",
      "thread_id": 226,
      "url": "/doc/7/review#4"
    },
    {
      "body_html": "<blockquote><p>The idea of automated continuous updating is very cool, but seems like a ton of workhours to maintain long term.</p></blockquote>\r\n\r\n<p><a href=\"/u/pouyakhankhanian\" class=\"username\">@pouyakhankhanian</a>, if we move to more automated techniques on more standardized inputs, I thinks it's possible to entirely automate updates. One area of interest in my current lab, the <a href=\"http://www.greenelab.com/\">Greene Lab</a>, is automation <span class=\"citation\">[<a href=\"https://doi.org/10.1101/056473\" class=\"citation\" data-key=\"10.1101/056473\">1</a>]</span>. As a simple example, see <a href=\"https://github.com/dhimmel/thinklytics\"><code>dhimmel/thinklytics</code></a> which automatically backs up and analyzes <em>Thinklab</em> content on a daily basis. Obviously, building Hetionet is much more complex, which means automation will be more difficult but also more valuable.</p>\r\n\r\n<blockquote><p>Drug-drug interactions can easily be tested against a \"gold standard\" database. I'm guessing it's relatively cheap (in work hours) for you to re-write the code to create drug-drug matches?</p></blockquote>\r\n\r\n<p>Yeah that wouldn't be too bad. I'd probably rework some of the current analysis pipeline to be more reproducible and automatable. Currently, it's difficult for others to re-execute and extend our computations — see for example, <a href=\"https://github.com/dhimmel/integrate/issues/9\">this issue</a> by <a href=\"/u/tongli\" class=\"username\">@tongli</a>.</p>",
      "body_md": "> The idea of automated continuous updating is very cool, but seems like a ton of workhours to maintain long term.\r\n\r\n@pouyakhankhanian, if we move to more automated techniques on more standardized inputs, I thinks it's possible to entirely automate updates. One area of interest in my current lab, the [Greene Lab](http://www.greenelab.com/), is automation [@10.1101/056473]. As a simple example, see [`dhimmel/thinklytics`](https://github.com/dhimmel/thinklytics) which automatically backs up and analyzes _Thinklab_ content on a daily basis. Obviously, building Hetionet is much more complex, which means automation will be more difficult but also more valuable.\r\n\r\n> Drug-drug interactions can easily be tested against a \"gold standard\" database. I'm guessing it's relatively cheap (in work hours) for you to re-write the code to create drug-drug matches?\r\n\r\nYeah that wouldn't be too bad. I'd probably rework some of the current analysis pipeline to be more reproducible and automatable. Currently, it's difficult for others to re-execute and extend our computations -- see for example, [this issue](https://github.com/dhimmel/integrate/issues/9) by @tongli.",
      "comment_id": 1391,
      "profile_id": 17,
      "published": "2016-11-30T18:33:04.938499Z",
      "thread_id": 227,
      "url": "/discussion/brainstorming-future-directions-for-hetionet/227#6"
    },
    {
      "body_html": "<blockquote><p><a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a> I would really like to find a way to collaborate more directly. We have two PhD students and a postdoc all working on extensions to the hetionet project - thanks entirely to your efforts to be open here on ThinkLab.</p></blockquote>\r\n\r\n<p><a href=\"/u/b_good\" class=\"username\">@b_good</a> definitely. First, let me say that it's been super encouraging to see your team extend Hetionet / Rephetio. I'm not entirely sure what extensions you're working on, but the GitHub Issues opened have helped me see the sticking points of my old workflows.</p>\r\n\r\n<p>From your comment, I think we're all thinking along the same lines. All biomedical knowledge should be mined from the literature into a hetnet. The hetnet should be stored in Neo4j. Nodes should be from ontologies and standardized vocabularies that can be automatically maintained. Curation should be fully outsourced or, if necessary, crowdsourced. Layers on top of the Neo4j database will likely be needed to provide biologists with user-friendly interfaces for domain-specific functionality.</p>\r\n\r\n<p>I think that we're at a point where we can achieve the above objectives. One outstanding issue that I'd love input on is how to deal with context-specific relationships. For example, protein interactions that only exist in a certain tissue <span class=\"citation\">[<a href=\"https://doi.org/10.1186/s13059-016-0913-4\" class=\"citation\" data-key=\"10.1186/s13059-016-0913-4\">1</a>]</span>. I don't think my conception of hetnets or Neo4j's graph model are well-suited for this task.</p>\r\n\r\n<p>But to the point, let's not duplicate efforts. I'm hoping that everyone who shares our vision can join forces into a collaborative open source development community. There's lot's of overlap with the NCATS Biomedical Translator Program, which funded <a href=\"https://ncats.nih.gov/translator/projects\">investigators from 11 Universities</a>. <a href=\"/u/b_good\" class=\"username\">@b_good</a> are you affiliated with any of these projects and are they something we could also leverage — i.e. will their development be open source and are they pursuing related or complementary approaches to what we've outlined?</p>\r\n\r\n<p>So any suggestions on how best to structure collaboration? I personally think open source GitHub repos that operate on a pull request model are ideal. The difficultly will be coordination, recruitment, and providing an incentive structure that rewards collaboration.</p>",
      "body_md": "> @dhimmel I would really like to find a way to collaborate more directly. We have two PhD students and a postdoc all working on extensions to the hetionet project - thanks entirely to your efforts to be open here on ThinkLab.\r\n\r\n@b_good definitely. First, let me say that it's been super encouraging to see your team extend Hetionet / Rephetio. I'm not entirely sure what extensions you're working on, but the GitHub Issues opened have helped me see the sticking points of my old workflows.\r\n\r\nFrom your comment, I think we're all thinking along the same lines. All biomedical knowledge should be mined from the literature into a hetnet. The hetnet should be stored in Neo4j. Nodes should be from ontologies and standardized vocabularies that can be automatically maintained. Curation should be fully outsourced or, if necessary, crowdsourced. Layers on top of the Neo4j database will likely be needed to provide biologists with user-friendly interfaces for domain-specific functionality.\r\n\r\nI think that we're at a point where we can achieve the above objectives. One outstanding issue that I'd love input on is how to deal with context-specific relationships. For example, protein interactions that only exist in a certain tissue [@10.1186/s13059-016-0913-4]. I don't think my conception of hetnets or Neo4j's graph model are well-suited for this task.\r\n\r\nBut to the point, let's not duplicate efforts. I'm hoping that everyone who shares our vision can join forces into a collaborative open source development community. There's lot's of overlap with the NCATS Biomedical Translator Program, which funded [investigators from 11 Universities](https://ncats.nih.gov/translator/projects). @b_good are you affiliated with any of these projects and are they something we could also leverage -- i.e. will their development be open source and are they pursuing related or complementary approaches to what we've outlined?\r\n\r\nSo any suggestions on how best to structure collaboration? I personally think open source GitHub repos that operate on a pull request model are ideal. The difficultly will be coordination, recruitment, and providing an incentive structure that rewards collaboration.",
      "comment_id": 1392,
      "profile_id": 17,
      "published": "2016-11-30T19:02:35.375518Z",
      "thread_id": 227,
      "url": "/discussion/brainstorming-future-directions-for-hetionet/227#7"
    },
    {
      "body_html": "<h1>Mining knowledge from the literature</h1>\r\n\r\n<p>In the early days of Project Rephetio, <a href=\"/u/b_good\" class=\"username\">@b_good</a> <a href=\"https://thinklab.com/discussion/text-as-a-resource-for-network-population/48\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d48\">suggested</a> mining text to populate our network. We didn't end up doing much text mining to construct Hetionet v1.0. We did indirectly use relationships extracted from the literature, though <a href=\"https://thinklab.com/discussion/mining-knowledge-from-medline-articles-and-their-indexed-mesh-terms/67\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d67\">MEDLINE term co-occurrence</a> and <a href=\"https://thinklab.com/d/48#3\">resources</a> that curated literature.</p>\r\n\r\n<p>In general, we were more excited about \"edges from systematic technologies that are not subject to knowledge biases\" and invested our time in integrating resources such as <a href=\"https://thinklab.com/discussion/computing-consensus-transcriptional-profiles-for-lincs-l1000-perturbations/43\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d43\">LINCS L1000</a> and <a href=\"https://thinklab.com/discussion/stargeo-expression-signatures-for-disease-using-crowdsourced-geo-annotation/96\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d96\">STARGEO</a>. Our hope was to leverage systematic high-throughput technologies to make novel and insightful drug repurposing predictions. However, as we discuss in our report <span class=\"citation\">[<a href=\"/p/rephetio/report\" class=\"citation\" data-key=\"10.15363/thinklab.a7\">1</a>]</span>:</p>\r\n\r\n<blockquote><p>Ideally, different data types would provide orthogonal information. However, our model for whether a compound treats a disease focused on 11 metapaths — a small portion of the hundreds of metapaths available. While parsimony aids interpretation, our model did not draw on the weakly-predictive high-throughput data types — which are intriguing for their novelty, scalability, and cost-effectiveness — as much as we had hypothesized. Instead our model selected types of information traditionally considered in pharmacology. </p></blockquote>\r\n\r\n<p>I think increasing our number of positives and fixing <a href=\"https://thinklab.com/discussion/edge-dropout-contamination-in-hetnet-edge-prediction/215\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d215\">edge dropout contamination</a> — for example by training on novel <a href=\"https://thinklab.com/discussion/cataloging-drugdisease-therapies-in-the-clinicaltrialsgov-database/212\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d212\">clinical trail indications</a> — could help incorporate weakly predictive metapaths into our models. However, the findings of Project Rephetio suggest that we should redirect focus to incorporating established knowledge embedded in the literature.</p>\r\n\r\n<p><a href=\"/u/b_good\" class=\"username\">@b_good</a>, I saw that <a href=\"http://knowledge.bio\">knowledge.bio</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1101/055525\" class=\"citation\" data-key=\"10.1101/055525\">2</a>]</span> uses the <a href=\"https://skr3.nlm.nih.gov/SemMedDB/\">Semantic MEDLINE Database</a> (SemMedDB) <span class=\"citation\">[<a href=\"https://doi.org/10.1093/bioinformatics/bts591\" class=\"citation\" data-key=\"10.1093/bioinformatics/bts591\">3</a>]</span>. How good is SemMedDB? Unfortunately, SemMedDB appears to have troubling terms &amp; conditions despite being a US government work and primarily factual. I know <a href=\"/u/andrewsu\" class=\"username\">@andrewsu</a> is in communication with the National Library of Medicine to fix these legal impediments to reuse. In my next post, I'll discuss Snorkel — the question being whether implementing Snorkel will provide sufficient advantages over existing databases, such as SemMedDB.</p>",
      "body_md": "# Mining knowledge from the literature\r\n\r\nIn the early days of Project Rephetio, @b_good [suggested](https://thinklab.com/discussion/text-as-a-resource-for-network-population/48) mining text to populate our network. We didn't end up doing much text mining to construct Hetionet v1.0. We did indirectly use relationships extracted from the literature, though [MEDLINE term co-occurrence](https://thinklab.com/discussion/mining-knowledge-from-medline-articles-and-their-indexed-mesh-terms/67) and [resources](https://thinklab.com/d/48#3) that curated literature.\r\n\r\nIn general, we were more excited about \"edges from systematic technologies that are not subject to knowledge biases\" and invested our time in integrating resources such as [LINCS L1000](https://thinklab.com/discussion/computing-consensus-transcriptional-profiles-for-lincs-l1000-perturbations/43) and [STARGEO](https://thinklab.com/discussion/stargeo-expression-signatures-for-disease-using-crowdsourced-geo-annotation/96). Our hope was to leverage systematic high-throughput technologies to make novel and insightful drug repurposing predictions. However, as we discuss in our report [@10.15363/thinklab.a7]:\r\n\r\n> Ideally, different data types would provide orthogonal information. However, our model for whether a compound treats a disease focused on 11 metapaths — a small portion of the hundreds of metapaths available. While parsimony aids interpretation, our model did not draw on the weakly-predictive high-throughput data types — which are intriguing for their novelty, scalability, and cost-effectiveness — as much as we had hypothesized. Instead our model selected types of information traditionally considered in pharmacology. \r\n\r\nI think increasing our number of positives and fixing [edge dropout contamination](https://thinklab.com/discussion/edge-dropout-contamination-in-hetnet-edge-prediction/215) -- for example by training on novel [clinical trail indications](https://thinklab.com/discussion/cataloging-drugdisease-therapies-in-the-clinicaltrialsgov-database/212) -- could help incorporate weakly predictive metapaths into our models. However, the findings of Project Rephetio suggest that we should redirect focus to incorporating established knowledge embedded in the literature.\r\n\r\n@b_good, I saw that [knowledge.bio](http://knowledge.bio) [@10.1101/055525] uses the [Semantic MEDLINE Database](https://skr3.nlm.nih.gov/SemMedDB/) (SemMedDB) [@10.1093/bioinformatics/bts591]. How good is SemMedDB? Unfortunately, SemMedDB appears to have troubling terms & conditions despite being a US government work and primarily factual. I know @andrewsu is in communication with the National Library of Medicine to fix these legal impediments to reuse. In my next post, I'll discuss Snorkel -- the question being whether implementing Snorkel will provide sufficient advantages over existing databases, such as SemMedDB.",
      "comment_id": 1393,
      "profile_id": 17,
      "published": "2016-11-30T20:15:37.965819Z",
      "thread_id": 227,
      "url": "/discussion/brainstorming-future-directions-for-hetionet/227#8"
    },
    {
      "body_html": "<h1>DrugCentral now published</h1>\r\n\r\n<p>DrugCentral is now available at <a href=\"http://drugcentral.org/\">http://drugcentral.org/</a> and published in <a href=\"https://doi.org/10.1093/nar/gkw993\"><em>Nucleic Acids Research</em></a> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkw993\" class=\"citation\" data-key=\"10.1093/nar/gkw993\">1</a>]</span>.</p>\r\n\r\n<p>According to the <a href=\"http://drugcentral.org/privacy\">website</a>, the resource is available under a <a href=\"https://creativecommons.org/licenses/by-sa/4.0/legalcode\">CC BY-SA 4.0 License</a>.</p>",
      "body_md": "# DrugCentral now published\r\n\r\nDrugCentral is now available at http://drugcentral.org/ and published in [_Nucleic Acids Research_](https://doi.org/10.1093/nar/gkw993) [@10.1093/nar/gkw993].\r\n\r\nAccording to the [website](http://drugcentral.org/privacy), the resource is available under a [CC BY-SA 4.0 License](https://creativecommons.org/licenses/by-sa/4.0/legalcode).",
      "comment_id": 1394,
      "profile_id": 17,
      "published": "2016-11-30T19:50:34.568867Z",
      "thread_id": 186,
      "url": "/discussion/incorporating-drugcentral-data-in-our-network/186#7"
    },
    {
      "body_html": "<p>Add citation to <code>10.1093/nar/gkw993</code> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkw993\" class=\"citation\" data-key=\"10.1093/nar/gkw993\">1</a>]</span>.</p>",
      "body_md": "Add citation to `10.1093/nar/gkw993` [@10.1093/nar/gkw993].",
      "comment_id": 1395,
      "profile_id": 17,
      "published": "2016-11-30T19:53:35.487626Z",
      "thread_id": 226,
      "url": "/doc/7/review#5"
    },
    {
      "body_html": "<p>Link to <a href=\"http://het.io/repurpose/metapaths.html\">http://het.io/repurpose/metapaths.html</a>.</p>",
      "body_md": "Link to http://het.io/repurpose/metapaths.html.",
      "comment_id": 1396,
      "profile_id": 17,
      "published": "2016-11-30T20:00:46.030699Z",
      "thread_id": 226,
      "url": "/doc/7/review#6"
    },
    {
      "body_html": "<h1>Snorkeling the literature</h1>\r\n\r\n<p>Snorkel describes itself as a \"a lightweight platform for developing information extraction systems using <a href=\"https://arxiv.org/abs/1605.07723\" title=\"Data Programming: Creating Large Training Sets, Quickly. arXiv.\">data programming</a>\" (<a href=\"https://github.com/HazyResearch/snorkel\" title=\"GitHub\"><code>HazyResearch/snorkel</code></a> on GitHub) <span class=\"citation\">[<a href=\"https://doi.org/10.1145/2939502.2939515\" class=\"citation\" data-key=\"10.1145/2939502.2939515\">1</a>]</span>. There's a <a href=\"https://youtu.be/iSQHelJ1xxU\" title=\"Data Programming NIPS 2016 Spotlight Video\">short video</a> describing data programming, although the terminology is a bit foreign to me. Therefore, <a href=\"/u/caseygreene\" class=\"username\">@caseygreene</a> and I videochatted with the lead developer, <a href=\"https://github.com/ajratner\">Alex Ratner</a>, of the Christopher Ré Lab at Stanford.</p>\r\n\r\n<p>Here were the takeaways. We could use snorkel to fill in missing relationships in Hetionet. Each of the 24 relationship types would be a distinct classification problem, where we instruct snorkel to learn how to extract that relationship type from the literature. We would start with a single labeling function, which would return true for relationships in Hetionet and false otherwise (distant supervision). Snorkel would fit a generative model that outputs the existing relationships <strong>and more</strong>.</p>\r\n\r\n<p>This approach is intriguing for several reasons:</p>\r\n\r\n<ul><li>We could fill in missing relationships where Hetionet doesn't currently contain all of the knowledge from the literature.</li><li>Each extracted relationship could refer back to the specific phrases supporting it throughout the literature.</li><li>The resulting hetnets would be free of <a href=\"https://thinklab.com/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d107\">licensing restrictions</a> and therefore could be released fully as CC0.</li><li>The approach can be largely automated and deployed as new literature enters the corpus.</li><li>The approach scales whereas existing human curation approaches do not.</li><li>The approach generalizes meaning each relationship type doesn't require an entirely new processing pipeline.</li></ul>\r\n\r\n<p>Alex mentioned the following three steps that take the most time:</p>\r\n\r\n<ol><li><strong>data processing</strong> and munging — preparing the input data. Hopefully, the burden here could be minimized since Hetionet v1.0 is already standardized and integrated. Furthermore, Alex mentioned that they've indexed certain portions of PubMed, so we wouldn't have to spend lot's of time configuring a literature corpus in the beginning.</li><li><strong>test set curation</strong> — expert curation of specific phrases from the literature corpus as negative or positives to evaluate performance. Potentially, we could withhold relationships and use them for testing, but the relationships are downstream from the actual classification which occurs at the level of actual text. It sounded like uneven prior probabilities of relationship based on node degree, which <a href=\"https://thinklab.com/discussion/network-edge-prediction-estimating-the-prior/201\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d201\">we've experienced</a>, could be an issue with testing on withheld relationships.</li><li><strong>error analysis</strong> — investigating where errors are being made and adding labeling functions to rectify the errors (direct supervision). This step could be amenable to crowdsourcing by community review.</li></ol>\r\n\r\n<p>We discussed doing a pilot project based on a single relationship type in Hetionet v1.0 — perhaps <em>Compound–treats–Disease</em> since we've already done substantial curation to create <a href=\"https://thinklab.com/discussion/announcing-pharmacotherapydb-the-open-catalog-of-drug-therapies-for-disease/182\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d182\">PharmacotherapyDB</a>.</p>",
      "body_md": "# Snorkeling the literature\r\n\r\nSnorkel describes itself as a \"a lightweight platform for developing information extraction systems using [data programming](https://arxiv.org/abs/1605.07723 \"Data Programming: Creating Large Training Sets, Quickly. arXiv.\")\" ([`HazyResearch/snorkel`](https://github.com/HazyResearch/snorkel \"GitHub\") on GitHub) [@10.1145/2939502.2939515]. There's a [short video](https://youtu.be/iSQHelJ1xxU \"Data Programming NIPS 2016 Spotlight Video\") describing data programming, although the terminology is a bit foreign to me. Therefore, @caseygreene and I videochatted with the lead developer, [Alex Ratner](https://github.com/ajratner), of the Christopher Ré Lab at Stanford.\r\n\r\nHere were the takeaways. We could use snorkel to fill in missing relationships in Hetionet. Each of the 24 relationship types would be a distinct classification problem, where we instruct snorkel to learn how to extract that relationship type from the literature. We would start with a single labeling function, which would return true for relationships in Hetionet and false otherwise (distant supervision). Snorkel would fit a generative model that outputs the existing relationships **and more**.\r\n\r\nThis approach is intriguing for several reasons:\r\n\r\n+ We could fill in missing relationships where Hetionet doesn't currently contain all of the knowledge from the literature.\r\n+ Each extracted relationship could refer back to the specific phrases supporting it throughout the literature.\r\n+ The resulting hetnets would be free of [licensing restrictions](https://thinklab.com/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107) and therefore could be released fully as CC0.\r\n+ The approach can be largely automated and deployed as new literature enters the corpus.\r\n+ The approach scales whereas existing human curation approaches do not.\r\n+ The approach generalizes meaning each relationship type doesn't require an entirely new processing pipeline.\r\n\r\nAlex mentioned the following three steps that take the most time:\r\n\r\n1. **data processing** and munging -- preparing the input data. Hopefully, the burden here could be minimized since Hetionet v1.0 is already standardized and integrated. Furthermore, Alex mentioned that they've indexed certain portions of PubMed, so we wouldn't have to spend lot's of time configuring a literature corpus in the beginning.\r\n2. **test set curation** -- expert curation of specific phrases from the literature corpus as negative or positives to evaluate performance. Potentially, we could withhold relationships and use them for testing, but the relationships are downstream from the actual classification which occurs at the level of actual text. It sounded like uneven prior probabilities of relationship based on node degree, which [we've experienced](https://thinklab.com/discussion/network-edge-prediction-estimating-the-prior/201), could be an issue with testing on withheld relationships.\r\n3. **error analysis** -- investigating where errors are being made and adding labeling functions to rectify the errors (direct supervision). This step could be amenable to crowdsourcing by community review.\r\n\r\nWe discussed doing a pilot project based on a single relationship type in Hetionet v1.0 -- perhaps _Compound--treats--Disease_ since we've already done substantial curation to create [PharmacotherapyDB](https://thinklab.com/discussion/announcing-pharmacotherapydb-the-open-catalog-of-drug-therapies-for-disease/182).",
      "comment_id": 1397,
      "profile_id": 17,
      "published": "2016-11-30T22:49:06.844576Z",
      "thread_id": 227,
      "url": "/discussion/brainstorming-future-directions-for-hetionet/227#9"
    },
    {
      "body_html": "<h1>Additional resources</h1>\r\n\r\n<p>Here are some additional resources that claim to do similar things:</p>\r\n\r\n<ul><li>CRowd Extracted Expression of Differential Signatures (<a href=\"http://amp.pharm.mssm.edu/creeds\">CREEDS</a>) <span class=\"citation\">[<a href=\"https://doi.org/10.1038/ncomms12846\" class=\"citation\" data-key=\"10.1038/ncomms12846\">1</a>]</span></li><li>OMics Compendia Commons (<a href=\"https://omicc.niaid.nih.gov/\">OMiCC</a>) <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nbt.3603\" class=\"citation\" data-key=\"10.1038/nbt.3603\">2</a>]</span></li></ul>\r\n\r\n<p>I haven't had time to look into them, but wanted to note them here in case I ever do!</p>",
      "body_md": "# Additional resources\r\n\r\nHere are some additional resources that claim to do similar things:\r\n\r\n+ CRowd Extracted Expression of Differential Signatures ([CREEDS](http://amp.pharm.mssm.edu/creeds)) [@10.1038/ncomms12846]\r\n+ OMics Compendia Commons ([OMiCC](https://omicc.niaid.nih.gov/)) [@10.1038/nbt.3603]\r\n\r\nI haven't had time to look into them, but wanted to note them here in case I ever do!",
      "comment_id": 1398,
      "profile_id": 17,
      "published": "2016-11-30T23:10:49.552512Z",
      "thread_id": 96,
      "url": "/discussion/stargeo-expression-signatures-for-disease-using-crowdsourced-geo-annotation/96#11"
    },
    {
      "body_html": "<p>Looks cool. </p>\r\n\r\n<p>I tested it by searching for \"lipitor\", and was surprised to find hypertension listed as an \"indication\".  I don't think this is right, and I don't immediately see a way to determine how hypertension was assigned as an indication for lipitor.</p>\r\n\r\n<p>However, there is a lot of good information here as well.  For example, a search for \"nifedipine\" turned up a contraindication of which I was entirely unaware, and which I could easily confirm by a web search.</p>",
      "body_md": "Looks cool. \r\n\r\nI tested it by searching for \"lipitor\", and was surprised to find hypertension listed as an \"indication\".  I don't think this is right, and I don't immediately see a way to determine how hypertension was assigned as an indication for lipitor.\r\n\r\nHowever, there is a lot of good information here as well.  For example, a search for \"nifedipine\" turned up a contraindication of which I was entirely unaware, and which I could easily confirm by a web search.",
      "comment_id": 1399,
      "profile_id": 80,
      "published": "2016-12-01T16:16:08.841208Z",
      "thread_id": 186,
      "url": "/discussion/incorporating-drugcentral-data-in-our-network/186#8"
    },
    {
      "body_html": "<h2>Atorvastatin for hypertension</h2>\r\n\r\n<p><a href=\"/u/mkgilson\" class=\"username\">@mkgilson</a>, thanks for the feedback. According to the DrugCentral publication, here's their method for compiling indications <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkw993\" class=\"citation\" data-key=\"10.1093/nar/gkw993\">1</a>]</span>:</p>\r\n\r\n<blockquote><p>Indications (10,707), contra-indications (27,851) and off-label indications (2496) were initially extracted from OMOP data model version 4.4 (http://omop.org/Vocabularies). Since the OMOP project transitioned to OHDSI (http://www.ohdsi.org), updated drug indication and contra-indication data are covered under a revised license agreement that in turn requires subscription licenses (i.e. it is no longer open-access). Therefore, indications for drugs approved after 2012 (322 pairs) were extracted from approved drug labels and mapped onto SNOMED-CT and UMLS concepts.</p></blockquote>\r\n\r\n<p>Note that we also created a catalog of indications called <a href=\"https://thinklab.com/discussion/announcing-pharmacotherapydb-the-open-catalog-of-drug-therapies-for-disease/182\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d182\">PharmacotherapyDB</a>. When creating this resource, we had three physicians <a href=\"https://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d95\">curate</a> all of our indications. Interestingly, all three of our curators <a href=\"https://github.com/dhimmel/indications/blob/11d535ba0884ee56c3cd5756fdfb4985f313bd80/curation/results-three-curators.tsv#L636\">classified</a> atorvastatin (lipitor) as a disease-modifying indication for hypertension. Atorvastatin <a href=\"http://het.io/repurpose/browse.html?id=DB01076\" title=\"Project Rephetio predictions for Atorvastatin\">was also considered</a> disease-modifying for coronary artery disease but not for type 2 diabetes mellitus.</p>\r\n\r\n<p>It appears that the verdict is still out on whether statins lower blood pressure <span class=\"citation\">[<a href=\"https://doi.org/10.5114/aoms.2012.27270\" class=\"citation\" data-key=\"10.5114/aoms.2012.27270\">2</a>, <a href=\"https://doi.org/10.1038/jhh.2011.80\" class=\"citation\" data-key=\"10.1038/jhh.2011.80\">3</a>, <a href=\"https://doi.org/10.1177/1074248407300380\" class=\"citation\" data-key=\"10.1177/1074248407300380\">4</a>, <a href=\"https://doi.org/10.3109/08037050903576726\" class=\"citation\" data-key=\"10.3109/08037050903576726\">5</a>]</span>, but <a href=\"http://www.healthline.com/health/statins-will-they-lower-my-blood-pressure#Statins4\">perhaps</a> physicians are prescribing atorvastatin as an off-label treatment for hypertension and this is what our curators picked up on. <a href=\"/u/pouyakhankhanian\" class=\"username\">@pouyakhankhanian</a>, do you remember your reasoning here?</p>",
      "body_md": "## Atorvastatin for hypertension\r\n\r\n@mkgilson, thanks for the feedback. According to the DrugCentral publication, here's their method for compiling indications [@10.1093/nar/gkw993]:\r\n\r\n> Indications (10,707), contra-indications (27,851) and off-label indications (2496) were initially extracted from OMOP data model version 4.4 (http://omop.org/Vocabularies). Since the OMOP project transitioned to OHDSI (http://www.ohdsi.org), updated drug indication and contra-indication data are covered under a revised license agreement that in turn requires subscription licenses (i.e. it is no longer open-access). Therefore, indications for drugs approved after 2012 (322 pairs) were extracted from approved drug labels and mapped onto SNOMED-CT and UMLS concepts.\r\n\r\nNote that we also created a catalog of indications called [PharmacotherapyDB](https://thinklab.com/discussion/announcing-pharmacotherapydb-the-open-catalog-of-drug-therapies-for-disease/182). When creating this resource, we had three physicians [curate](https://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95) all of our indications. Interestingly, all three of our curators [classified](https://github.com/dhimmel/indications/blob/11d535ba0884ee56c3cd5756fdfb4985f313bd80/curation/results-three-curators.tsv#L636) atorvastatin (lipitor) as a disease-modifying indication for hypertension. Atorvastatin [was also considered](http://het.io/repurpose/browse.html?id=DB01076 \"Project Rephetio predictions for Atorvastatin\") disease-modifying for coronary artery disease but not for type 2 diabetes mellitus.\r\n\r\nIt appears that the verdict is still out on whether statins lower blood pressure [@10.5114/aoms.2012.27270 @10.1038/jhh.2011.80 @10.1177/1074248407300380 @10.3109/08037050903576726], but [perhaps](http://www.healthline.com/health/statins-will-they-lower-my-blood-pressure#Statins4) physicians are prescribing atorvastatin as an off-label treatment for hypertension and this is what our curators picked up on. @pouyakhankhanian, do you remember your reasoning here?",
      "comment_id": 1400,
      "profile_id": 17,
      "published": "2016-12-02T16:55:45.072846Z",
      "thread_id": 186,
      "url": "/discussion/incorporating-drugcentral-data-in-our-network/186#11"
    },
    {
      "body_html": "<p>Hi Mike,</p>\r\n\r\n<p>Thank you for feedback! Regarding indications for atorvastatin, most of indications for drugs approved before 2012 come from OMOP v4 which in turn imported data from First Data Bank, while quality assessed by us for few samples for this dataset appears to be high there are still indications which either address a disease symptom or associated co-morbidity and it is not clear what is the actual association. We will amend the data and re-upload. </p>",
      "body_md": "Hi Mike,\r\n\r\nThank you for feedback! Regarding indications for atorvastatin, most of indications for drugs approved before 2012 come from OMOP v4 which in turn imported data from First Data Bank, while quality assessed by us for few samples for this dataset appears to be high there are still indications which either address a disease symptom or associated co-morbidity and it is not clear what is the actual association. We will amend the data and re-upload.",
      "comment_id": 1401,
      "profile_id": 242,
      "published": "2016-12-02T16:43:15.457692Z",
      "thread_id": 186,
      "url": "/discussion/incorporating-drugcentral-data-in-our-network/186#9"
    },
    {
      "body_html": "<p>You're welcome!  I just now looked for info on OMOP on line, but am not finding any relevant dataset. Is there a link you could provide?</p>",
      "body_md": "You're welcome!  I just now looked for info on OMOP on line, but am not finding any relevant dataset. Is there a link you could provide?",
      "comment_id": 1402,
      "profile_id": 80,
      "published": "2016-12-02T16:51:36.829483Z",
      "thread_id": 186,
      "url": "/discussion/incorporating-drugcentral-data-in-our-network/186#10"
    },
    {
      "body_html": "<p>Most likely the association is via cholesterol which is risk factor for hypertension, and statins lower cholesterol.</p>",
      "body_md": "Most likely the association is via cholesterol which is risk factor for hypertension, and statins lower cholesterol.",
      "comment_id": 1403,
      "profile_id": 242,
      "published": "2016-12-02T16:59:08.684208Z",
      "thread_id": 186,
      "url": "/discussion/incorporating-drugcentral-data-in-our-network/186#12"
    },
    {
      "body_html": "<p><a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a> Thanks, Daniel.  Before posting my original comment, I did a quick web search for atorvastatin and HTN, and found something very equivocal: there seemed to be supportive statistics, but the mean drop in BP observed was paltry, something like 0.5 - 1 mm Hg, on typical systolic and diastolic values of 120 and 70 mmHg.  I'd be interested to know if a more robust effect has in fact been observed.</p>",
      "body_md": "@dhimmel Thanks, Daniel.  Before posting my original comment, I did a quick web search for atorvastatin and HTN, and found something very equivocal: there seemed to be supportive statistics, but the mean drop in BP observed was paltry, something like 0.5 - 1 mm Hg, on typical systolic and diastolic values of 120 and 70 mmHg.  I'd be interested to know if a more robust effect has in fact been observed.",
      "comment_id": 1404,
      "profile_id": 80,
      "published": "2016-12-02T17:01:27.650719Z",
      "thread_id": 186,
      "url": "/discussion/incorporating-drugcentral-data-in-our-network/186#13"
    },
    {
      "body_html": "<p>Though I cannot speak for the other curators, my own clinical suspicion was call atorvastatin as NOT for hypertension (HTN), because, for example, the other two statins in our curation database are also listed as NOT for HTN. As the only curator who was not blind to the other two curators' selections, I saw the choice of DM by the other two reviewers and therefore did a cursory round of research, found <span class=\"citation\">[<a href=\"https://doi.org/10.3109/08037050903576726\" class=\"citation\" data-key=\"10.3109/08037050903576726\">1</a>]</span>, which is specific for atorvastatin, and therefore agreed with the other reviewers. Upon more detailed review of this, my thoughts below.</p>\r\n\r\n<p>Hyperlipidema (HLD) is treated with an HMG-COARi (the 'statins', such as atorvastatin, simvastatin, lovastatin). The decision to treat HLD with a statin, and the strength of statin to use, is a decision guided by a \"risk factor\" score which predicts poor cardiovascular outcomes, the ASCVD score is the latest in use in the last few years. The ASCVD risk score and many other scoring systems use your blood pressure as a major factor in determining if and how much statin you get for your HLD.</p>\r\n\r\n<p>HTN is treated with antihypertensives, commonly guided by the JNC8 paradigm <span class=\"citation\">[<a href=\"https://doi.org/10.1001/jama.2013.284427\" class=\"citation\" data-key=\"10.1001/jama.2013.284427\">2</a>]</span>. The decision to treat HTN and the aggressiveness of therapy is also guided toward reducing poor cardiovascular outcomes.</p>\r\n\r\n<p>Therefore, in clinical practice, the treatment of HTN and HLD is generally thought to be really two parts of the same battle, with the goal being to decrease the number of poor cardiovascular outcomes (death or major disability from MI or stroke or PVD). And the latest trend is combination treatments which include statins and antihypertensives such as <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.clinthera.2016.09.005\" class=\"citation\" data-key=\"10.1016/j.clinthera.2016.09.005\">3</a>]</span>.</p>\r\n\r\n<p>Given that clinically we are moving toward the use of mixing antihypertensive drugs with statins in clinical practice, I'm not sure we will have more evidence in the future as to the efficacy of a statin alone (in the absence of antihypertensive use) on hypertension alone (in the absence of hyperlipidemia). For example, note the possibility of confounding between HTN and HLD in the articles referenced by Daniel above. Therefore, the best evidence we have would be <span class=\"citation\">[<a href=\"https://doi.org/10.3109/08037050903576726\" class=\"citation\" data-key=\"10.3109/08037050903576726\">1</a>]</span>. In that case, I suppose one could say atorvastatin is DM for HTN, but I wouldn't disagree with calling it NOT for HTN. Furthermore, one could make a case that all three statins should be DM if one of them is DM, but I would personally think that's too much of a stretch. Here is the list of how the all of the statins were designated by the three curators. You will note the lack of completeness of the PharmacotherapyDB list (every statin not listed for every indication), and I would say this was quite usual other drug classes in the database as well.</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>drug</th><th>disease</th><th>CSH</th><th>AJG</th><th>PK</th></tr></thead><tbody><tr><td>Lovastatin</td><td>atherosclerosis</td><td>DM</td><td>DM</td><td>DM</td></tr><tr><td>Pravastatin</td><td>atherosclerosis</td><td>DM</td><td>DM</td><td>DM</td></tr><tr><td>Rosuvastatin</td><td>atherosclerosis</td><td>DM</td><td>DM</td><td>DM</td></tr><tr><td>Simvastatin</td><td>atherosclerosis</td><td>DM</td><td>DM</td><td>DM</td></tr><tr><td>Atorvastatin</td><td>coronary artery disease</td><td>DM</td><td>DM</td><td>DM</td></tr><tr><td>Lovastatin</td><td>coronary artery disease</td><td>DM</td><td>DM</td><td>DM</td></tr><tr><td>Pitavastatin</td><td>coronary artery disease</td><td>DM</td><td>DM</td><td>DM</td></tr><tr><td>Pravastatin</td><td>coronary artery disease</td><td>DM</td><td>DM</td><td>DM</td></tr><tr><td>Rosuvastatin</td><td>coronary artery disease</td><td>DM</td><td>DM</td><td>DM</td></tr><tr><td>Simvastatin</td><td>coronary artery disease</td><td>DM</td><td>DM</td><td>DM</td></tr><tr><td>Atorvastatin</td><td>hypertension</td><td>DM</td><td>DM</td><td>DM</td></tr><tr><td>Lovastatin</td><td>hypertension</td><td>NOT</td><td>NOT</td><td>NOT</td></tr><tr><td>Simvastatin</td><td>hypertension</td><td>NOT</td><td>NOT</td><td>NOT</td></tr><tr><td>Pravastatin</td><td>prostate cancer</td><td>NOT</td><td>DM</td><td>NOT</td></tr><tr><td>Atorvastatin</td><td>type 2 diabetes mellitus</td><td>NOT</td><td>NOT</td><td>NOT</td></tr><tr><td>Simvastatin</td><td>type 2 diabetes mellitus</td><td>NOT</td><td>NOT</td><td>NOT</td></tr></tbody></table>\r\n\r\n<p>Also of interest is how the statins were ranked to help in each disease.</p>",
      "body_md": "Though I cannot speak for the other curators, my own clinical suspicion was call atorvastatin as NOT for hypertension (HTN), because, for example, the other two statins in our curation database are also listed as NOT for HTN. As the only curator who was not blind to the other two curators' selections, I saw the choice of DM by the other two reviewers and therefore did a cursory round of research, found [@10.3109/08037050903576726], which is specific for atorvastatin, and therefore agreed with the other reviewers. Upon more detailed review of this, my thoughts below.\r\n\r\nHyperlipidema (HLD) is treated with an HMG-COARi (the 'statins', such as atorvastatin, simvastatin, lovastatin). The decision to treat HLD with a statin, and the strength of statin to use, is a decision guided by a \"risk factor\" score which predicts poor cardiovascular outcomes, the ASCVD score is the latest in use in the last few years. The ASCVD risk score and many other scoring systems use your blood pressure as a major factor in determining if and how much statin you get for your HLD.\r\n\r\nHTN is treated with antihypertensives, commonly guided by the JNC8 paradigm [@10.1001/jama.2013.284427]. The decision to treat HTN and the aggressiveness of therapy is also guided toward reducing poor cardiovascular outcomes.\r\n\r\nTherefore, in clinical practice, the treatment of HTN and HLD is generally thought to be really two parts of the same battle, with the goal being to decrease the number of poor cardiovascular outcomes (death or major disability from MI or stroke or PVD). And the latest trend is combination treatments which include statins and antihypertensives such as [@10.1016/j.clinthera.2016.09.005].\r\n\r\nGiven that clinically we are moving toward the use of mixing antihypertensive drugs with statins in clinical practice, I'm not sure we will have more evidence in the future as to the efficacy of a statin alone (in the absence of antihypertensive use) on hypertension alone (in the absence of hyperlipidemia). For example, note the possibility of confounding between HTN and HLD in the articles referenced by Daniel above. Therefore, the best evidence we have would be [@10.3109/08037050903576726]. In that case, I suppose one could say atorvastatin is DM for HTN, but I wouldn't disagree with calling it NOT for HTN. Furthermore, one could make a case that all three statins should be DM if one of them is DM, but I would personally think that's too much of a stretch. Here is the list of how the all of the statins were designated by the three curators. You will note the lack of completeness of the PharmacotherapyDB list (every statin not listed for every indication), and I would say this was quite usual other drug classes in the database as well.\r\n\r\n| drug | disease | CSH | AJG | PK |\r\n|------|---------|-----|-----|----|\r\n| Lovastatin | atherosclerosis | DM | DM | DM |\r\n| Pravastatin | atherosclerosis | DM | DM | DM |\r\n| Rosuvastatin | atherosclerosis | DM | DM | DM |\r\n| Simvastatin | atherosclerosis | DM | DM | DM |\r\n| Atorvastatin | coronary artery disease | DM | DM | DM |\r\n| Lovastatin | coronary artery disease | DM | DM | DM |\r\n| Pitavastatin | coronary artery disease | DM | DM | DM |\r\n| Pravastatin | coronary artery disease | DM | DM | DM |\r\n| Rosuvastatin | coronary artery disease | DM | DM | DM |\r\n| Simvastatin | coronary artery disease | DM | DM | DM |\r\n| Atorvastatin | hypertension | DM | DM | DM |\r\n| Lovastatin | hypertension | NOT | NOT | NOT |\r\n| Simvastatin | hypertension | NOT | NOT | NOT |\r\n| Pravastatin | prostate cancer | NOT | DM | NOT |\r\n| Atorvastatin | type 2 diabetes mellitus | NOT | NOT | NOT |\r\n| Simvastatin | type 2 diabetes mellitus | NOT | NOT | NOT |\r\n\r\nAlso of interest is how the statins were ranked to help in each disease.",
      "comment_id": 1405,
      "profile_id": 188,
      "published": "2016-12-04T16:46:44.482568Z",
      "thread_id": 186,
      "url": "/discussion/incorporating-drugcentral-data-in-our-network/186#14"
    },
    {
      "body_html": "<p>The algorithm predicts hypertension fairly highly for some of the other statins as well. Here are the top predictions of the algorithm for any statin:</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>compound_name</th><th>disease_name</th><th>category</th><th>prediction</th><th>disease_percentile</th></tr></thead><tbody><tr><td>Lovastatin</td><td>atherosclerosis</td><td>DM</td><td>28.4%</td><td>100.0%</td></tr><tr><td>Simvastatin</td><td>atherosclerosis</td><td>DM</td><td>23.6%</td><td>99.9%</td></tr><tr><td>Pravastatin</td><td>atherosclerosis</td><td>DM</td><td>20.2%</td><td>99.9%</td></tr><tr><td>Simvastatin</td><td>coronary artery disease</td><td>DM</td><td>19.0%</td><td>99.5%</td></tr><tr><td>Pitavastatin</td><td>atherosclerosis</td><td></td><td>17.1%</td><td>99.8%</td></tr><tr><td>Lovastatin</td><td>coronary artery disease</td><td>DM</td><td>16.9%</td><td>99.4%</td></tr><tr><td>Pravastatin</td><td>coronary artery disease</td><td>DM</td><td>14.8%</td><td>99.3%</td></tr><tr><td>Rosuvastatin</td><td>coronary artery disease</td><td>DM</td><td>13.2%</td><td>99.0%</td></tr><tr><td>Fluvastatin</td><td>coronary artery disease</td><td></td><td>6.7%</td><td>98.4%</td></tr><tr><td>Fluvastatin</td><td>atherosclerosis</td><td></td><td>6.2%</td><td>99.7%</td></tr><tr><td>Pitavastatin</td><td>coronary artery disease</td><td>DM</td><td>4.8%</td><td>97.4%</td></tr><tr><td>Atorvastatin</td><td>atherosclerosis</td><td></td><td>3.4%</td><td>99.7%</td></tr><tr><td>Atorvastatin</td><td>coronary artery disease</td><td>DM</td><td>3.2%</td><td>96.7%</td></tr><tr><td>Fluvastatin</td><td>hypertension</td><td></td><td>3.1%</td><td>92.0%</td></tr><tr><td>Pitavastatin</td><td>hypertension</td><td></td><td>2.6%</td><td>91.0%</td></tr><tr><td>Simvastatin</td><td>type 2 diabetes mellitus</td><td>NOT</td><td>1.6%</td><td>95.4%</td></tr><tr><td>Rosuvastatin</td><td>atherosclerosis</td><td>DM</td><td>1.4%</td><td>98.7%</td></tr><tr><td>Pravastatin</td><td>type 2 diabetes mellitus</td><td></td><td>1.3%</td><td>94.5%</td></tr><tr><td>Lovastatin</td><td>type 2 diabetes mellitus</td><td></td><td>1.3%</td><td>94.4%</td></tr><tr><td>Rosuvastatin</td><td>type 2 diabetes mellitus</td><td></td><td>1.3%</td><td>94.3%</td></tr><tr><td>Pitavastatin</td><td>type 2 diabetes mellitus</td><td></td><td>1.2%</td><td>93.6%</td></tr><tr><td>Atorvastatin</td><td>type 2 diabetes mellitus</td><td>NOT</td><td>1.1%</td><td>93.1%</td></tr><tr><td>Rosuvastatin</td><td>hypertension</td><td></td><td>1.0%</td><td>79.5%</td></tr></tbody></table>\r\n\r\n<p>It appears above the algorithm likes some of the other statins more than atorvastatin for hypertension. Here are the top <a href=\"http://het.io/repurpose/browse.html?id=DB01076\">results for atorvastatin</a>:</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>compound_name</th><th>disease_name</th><th>category</th><th>prediction</th><th>compound_percentile</th><th>disease_percentile</th></tr></thead><tbody><tr><td>Atorvastatin</td><td>atherosclerosis</td><td></td><td>3.39%</td><td>100.00%</td><td>99.67%</td></tr><tr><td>Atorvastatin</td><td>coronary artery disease</td><td>DM</td><td>3.23%</td><td>99.26%</td><td>96.75%</td></tr><tr><td>Atorvastatin</td><td>type 2 diabetes mellitus</td><td>NOT</td><td>1.09%</td><td>98.53%</td><td>93.11%</td></tr><tr><td>Atorvastatin</td><td>obesity</td><td></td><td>0.46%</td><td>97.79%</td><td>76.20%</td></tr><tr><td>Atorvastatin</td><td>chronic kidney failure</td><td></td><td>0.42%</td><td>97.06%</td><td>95.45%</td></tr><tr><td>Atorvastatin</td><td>metabolic syndrome X</td><td></td><td>0.42%</td><td>96.32%</td><td>95.77%</td></tr><tr><td>Atorvastatin</td><td>epilepsy syndrome</td><td></td><td>0.36%</td><td>95.59%</td><td>53.38%</td></tr><tr><td>Atorvastatin</td><td>Kawasaki disease</td><td></td><td>0.36%</td><td>94.85%</td><td>95.12%</td></tr><tr><td>Atorvastatin</td><td>hypertension</td><td>DM</td><td>0.35%</td><td>94.12%</td><td>45.64%</td></tr><tr><td>Atorvastatin</td><td>focal segmental glomerulosclerosis</td><td></td><td>0.33%</td><td>93.38%</td><td>93.89%</td></tr><tr><td>Atorvastatin</td><td>primary biliary cirrhosis</td><td></td><td>0.32%</td><td>92.65%</td><td>87.78%</td></tr><tr><td>Atorvastatin</td><td>prostate cancer</td><td></td><td>0.32%</td><td>91.91%</td><td>66.38%</td></tr><tr><td>Atorvastatin</td><td>acquired immunodeficiency syndrome</td><td></td><td>0.30%</td><td>91.18%</td><td>62.74%</td></tr><tr><td>Atorvastatin</td><td>rheumatoid arthritis</td><td></td><td>0.29%</td><td>90.44%</td><td>79.00%</td></tr><tr><td>Atorvastatin</td><td>breast cancer</td><td></td><td>0.28%</td><td>89.71%</td><td>58.13%</td></tr><tr><td>Atorvastatin</td><td>pancreatic cancer</td><td></td><td>0.27%</td><td>88.97%</td><td>80.17%</td></tr><tr><td>Atorvastatin</td><td>lung cancer</td><td></td><td>0.27%</td><td>88.24%</td><td>73.02%</td></tr></tbody></table>\r\n\r\n<p>Hypertension is highly ranked for atorvastatin, but atorvastatin is not highly ranked for hypertension.</p>",
      "body_md": "The algorithm predicts hypertension fairly highly for some of the other statins as well. Here are the top predictions of the algorithm for any statin:\r\n\r\n| compound_name | disease_name | category | prediction | disease_percentile |\r\n|---------------|--------------|----------|------------|----------|\r\n| Lovastatin | atherosclerosis | DM | 28.4% | 100.0% |\r\n| Simvastatin | atherosclerosis | DM | 23.6% | 99.9% |\r\n| Pravastatin | atherosclerosis | DM | 20.2% | 99.9% |\r\n| Simvastatin | coronary artery disease | DM | 19.0% | 99.5% |\r\n| Pitavastatin | atherosclerosis |  | 17.1% | 99.8% |\r\n| Lovastatin | coronary artery disease | DM | 16.9% | 99.4% |\r\n| Pravastatin | coronary artery disease | DM | 14.8% | 99.3% |\r\n| Rosuvastatin | coronary artery disease | DM | 13.2% | 99.0% |\r\n| Fluvastatin | coronary artery disease |  | 6.7% | 98.4% |\r\n| Fluvastatin | atherosclerosis |  | 6.2% | 99.7% |\r\n| Pitavastatin | coronary artery disease | DM | 4.8% | 97.4% |\r\n| Atorvastatin | atherosclerosis |  | 3.4% | 99.7% |\r\n| Atorvastatin | coronary artery disease | DM | 3.2% | 96.7% |\r\n| Fluvastatin | hypertension |  | 3.1% | 92.0% |\r\n| Pitavastatin | hypertension |  | 2.6% | 91.0% |\r\n| Simvastatin | type 2 diabetes mellitus | NOT | 1.6% | 95.4% |\r\n| Rosuvastatin | atherosclerosis | DM | 1.4% | 98.7% |\r\n| Pravastatin | type 2 diabetes mellitus |  | 1.3% | 94.5% |\r\n| Lovastatin | type 2 diabetes mellitus |  | 1.3% | 94.4% |\r\n| Rosuvastatin | type 2 diabetes mellitus |  | 1.3% | 94.3% |\r\n| Pitavastatin | type 2 diabetes mellitus |  | 1.2% | 93.6% |\r\n| Atorvastatin | type 2 diabetes mellitus | NOT | 1.1% | 93.1% |\r\n| Rosuvastatin | hypertension |  | 1.0% | 79.5% |\r\n\r\nIt appears above the algorithm likes some of the other statins more than atorvastatin for hypertension. Here are the top [results for atorvastatin](http://het.io/repurpose/browse.html?id=DB01076):\r\n\r\n| compound_name | disease_name | category | prediction | compound_percentile | disease_percentile |\r\n|---------------|-----------------|----------|------------|-------------|--------------|\r\n| Atorvastatin | atherosclerosis |  | 3.39% | 100.00% | 99.67% |\r\n| Atorvastatin | coronary artery disease | DM | 3.23% | 99.26% | 96.75% |\r\n| Atorvastatin | type 2 diabetes mellitus | NOT | 1.09% | 98.53% | 93.11% |\r\n| Atorvastatin | obesity |  | 0.46% | 97.79% | 76.20% |\r\n| Atorvastatin | chronic kidney failure |  | 0.42% | 97.06% | 95.45% |\r\n| Atorvastatin | metabolic syndrome X |  | 0.42% | 96.32% | 95.77% |\r\n| Atorvastatin | epilepsy syndrome |  | 0.36% | 95.59% | 53.38% |\r\n| Atorvastatin | Kawasaki disease |  | 0.36% | 94.85% | 95.12% |\r\n| Atorvastatin | hypertension | DM | 0.35% | 94.12% | 45.64% |\r\n| Atorvastatin | focal segmental glomerulosclerosis |  | 0.33% | 93.38% | 93.89% |\r\n| Atorvastatin | primary biliary cirrhosis |  | 0.32% | 92.65% | 87.78% |\r\n| Atorvastatin | prostate cancer |  | 0.32% | 91.91% | 66.38% |\r\n| Atorvastatin | acquired immunodeficiency syndrome |  | 0.30% | 91.18% | 62.74% |\r\n| Atorvastatin | rheumatoid arthritis |  | 0.29% | 90.44% | 79.00% |\r\n| Atorvastatin | breast cancer |  | 0.28% | 89.71% | 58.13% |\r\n| Atorvastatin | pancreatic cancer |  | 0.27% | 88.97% | 80.17% |\r\n| Atorvastatin | lung cancer |  | 0.27% | 88.24% | 73.02% |\r\n\r\nHypertension is highly ranked for atorvastatin, but atorvastatin is not highly ranked for hypertension.",
      "comment_id": 1406,
      "profile_id": 188,
      "published": "2016-12-04T17:01:44.203055Z",
      "thread_id": 186,
      "url": "/discussion/incorporating-drugcentral-data-in-our-network/186#15"
    },
    {
      "body_html": "<p>Thanks, this is very informative!  I agree that treatment of HTN and HLD are two parts of the same battle — reduction of cardiovascular risk — but this in itself would not be a good rationale for saying atorvastatin is indicated for HTN; only that elevated cardiovscular risk may be viewed as an indication for both statins and antihypertensives.  If being two parts of the same battle were valid, then one would, by the same token, say that hypercholesterolemia is an indication for antihypertensives!</p>\r\n\r\n<p>As to the literature regarding antihypertensive effects of statins– I'm skeptical that any physician would regard HTN as an off-label indication for a statin. I wonder if there is a way to find out...</p>",
      "body_md": "Thanks, this is very informative!  I agree that treatment of HTN and HLD are two parts of the same battle -- reduction of cardiovascular risk -- but this in itself would not be a good rationale for saying atorvastatin is indicated for HTN; only that elevated cardiovscular risk may be viewed as an indication for both statins and antihypertensives.  If being two parts of the same battle were valid, then one would, by the same token, say that hypercholesterolemia is an indication for antihypertensives!\r\n\r\nAs to the literature regarding antihypertensive effects of statins-- I'm skeptical that any physician would regard HTN as an off-label indication for a statin. I wonder if there is a way to find out...",
      "comment_id": 1407,
      "profile_id": 80,
      "published": "2016-12-04T17:25:34.285701Z",
      "thread_id": 186,
      "url": "/discussion/incorporating-drugcentral-data-in-our-network/186#16"
    },
    {
      "body_html": "<p>Thanks again.  What exactly does DM mean?</p>",
      "body_md": "Thanks again.  What exactly does DM mean?",
      "comment_id": 1408,
      "profile_id": 80,
      "published": "2016-12-04T17:49:34.042657Z",
      "thread_id": 186,
      "url": "/discussion/incorporating-drugcentral-data-in-our-network/186#17"
    },
    {
      "body_html": "<p>Interesting classification. So for HTN, are all drugs either DM or NOT, given that HTN is typically asymptomatic?</p>",
      "body_md": "Interesting classification. So for HTN, are all drugs either DM or NOT, given that HTN is typically asymptomatic?",
      "comment_id": 1409,
      "profile_id": 80,
      "published": "2016-12-04T17:59:13.135204Z",
      "thread_id": 186,
      "url": "/discussion/incorporating-drugcentral-data-in-our-network/186#18"
    },
    {
      "body_html": "<p>I can relate to the challenge of arriving at hard definitions for concepts in biology and medicine that turn out to be complicated and case-dependent!  </p>\r\n\r\n<p>One thing that comes to mind is that, in medicine, a \"symptom\" is something a patient experiences. Thus,  HTN is not a symptom. Instead, it is a \"sign\", something the physician may observe.  There's the further complexity that essential HTN is probably best regarded as its own disease, whereas secondary HTN (e.g. due to renal artery stenosis), might not be best to regard as its own disease. </p>",
      "body_md": "I can relate to the challenge of arriving at hard definitions for concepts in biology and medicine that turn out to be complicated and case-dependent!  \r\n\r\nOne thing that comes to mind is that, in medicine, a \"symptom\" is something a patient experiences. Thus,  HTN is not a symptom. Instead, it is a \"sign\", something the physician may observe.  There's the further complexity that essential HTN is probably best regarded as its own disease, whereas secondary HTN (e.g. due to renal artery stenosis), might not be best to regard as its own disease.",
      "comment_id": 1410,
      "profile_id": 80,
      "published": "2016-12-04T18:11:10.507927Z",
      "thread_id": 186,
      "url": "/discussion/incorporating-drugcentral-data-in-our-network/186#19"
    },
    {
      "body_html": "<p><a href=\"/u/mkgilson\" class=\"username\">@mkgilson</a> posts an interesting question about disease classification in hypertension.</p>\r\n\r\n<p>The answer is found in <a href=\"https://github.com/dhimmel/indications/blob/d3d57b07abcf8d7af55f8e42ef7c4c99acd87ca8/curation/pk/template-pk%20final.xlsx\">this file</a> which documents our decision making for each call (in the first sheet). Also the <a href=\"https://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95#7\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d95\">discussion of the file here</a>. </p>\r\n\r\n<p>To answer your specific question, there were two medications (diazoxide and phentolamine) which were classified as SYM for HTN because they were only used in the treatment of hypertensive emergency, which we decided was a sort of symptom of hypertension. Again, a very grey line and open to <a href=\"https://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95#7\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d95\">debate regarding what \"hypertension\" is and what it means to be DM vs SYM, (if you search the word \"hypertension\" on this page)</a>. Interesting to note in the predictions for these two drugs, both were predicted to be good treatments for hypertension (the entity of hypertension as we have defined it). </p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>compound_id</th><th>DB01119</th><th>DB00692</th></tr></thead><tbody><tr><td>compound_name</td><td>Diazoxide</td><td>Phentolamine</td></tr><tr><td>disease_id</td><td>DOID:10763</td><td>DOID:10763</td></tr><tr><td>disease_name</td><td>hypertension</td><td>hypertension</td></tr><tr><td>category</td><td>SYM</td><td>SYM</td></tr><tr><td>status</td><td>0</td><td>0</td></tr><tr><td>prior_prob</td><td>0</td><td>0</td></tr><tr><td>prediction</td><td>0.117634071</td><td>0.022183046</td></tr><tr><td>training_prediction</td><td></td><td></td></tr><tr><td>compound_percentile</td><td>1</td><td>1</td></tr><tr><td>disease_percentile</td><td>0.976592978</td><td>0.900520156</td></tr></tbody></table>",
      "body_md": "@mkgilson posts an interesting question about disease classification in hypertension.\r\n\r\nThe answer is found in [this file] (https://github.com/dhimmel/indications/blob/d3d57b07abcf8d7af55f8e42ef7c4c99acd87ca8/curation/pk/template-pk%20final.xlsx) which documents our decision making for each call (in the first sheet). Also the [discussion of the file here] (https://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95#7). \r\n\r\nTo answer your specific question, there were two medications (diazoxide and phentolamine) which were classified as SYM for HTN because they were only used in the treatment of hypertensive emergency, which we decided was a sort of symptom of hypertension. Again, a very grey line and open to [debate regarding what \"hypertension\" is and what it means to be DM vs SYM, (if you search the word \"hypertension\" on this page)] (https://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95#7). Interesting to note in the predictions for these two drugs, both were predicted to be good treatments for hypertension (the entity of hypertension as we have defined it). \r\n\r\n|compound_id|DB01119|DB00692|\r\n|---------------|--------------|----------|\r\n|compound_name|Diazoxide|Phentolamine|\r\n|disease_id|DOID:10763|DOID:10763|\r\n|disease_name|hypertension|hypertension|\r\n|category|SYM|SYM|\r\n|status|0|0|\r\n|prior_prob|0|0|\r\n|prediction|0.117634071|0.022183046|\r\n|training_prediction|||\r\n|compound_percentile|1|1|\r\n|disease_percentile|0.976592978|0.900520156|",
      "comment_id": 1411,
      "profile_id": 188,
      "published": "2016-12-05T00:47:28.776837Z",
      "thread_id": 186,
      "url": "/discussion/incorporating-drugcentral-data-in-our-network/186#20"
    },
    {
      "body_html": "<p>Since other people may have similar questions to mine, how about putting your definitions/usage of DM, SYM and NOT in, e.g., the FAQ? Sorry if it's there and I'm missing it.</p>\r\n\r\n<p>Back to the details... my off the cuff thought would have been that essentially none of the common HTN drugs are disease modifying because they don't treat the underlying cause. They only compensate for it, so if you stop taking them, the HTN is back the same as ever.  So the disease isn't modified. In contrast, an antibiotic truly eliminates the root cause of an infection. </p>",
      "body_md": "Since other people may have similar questions to mine, how about putting your definitions/usage of DM, SYM and NOT in, e.g., the FAQ? Sorry if it's there and I'm missing it.\r\n\r\nBack to the details... my off the cuff thought would have been that essentially none of the common HTN drugs are disease modifying because they don't treat the underlying cause. They only compensate for it, so if you stop taking them, the HTN is back the same as ever.  So the disease isn't modified. In contrast, an antibiotic truly eliminates the root cause of an infection.",
      "comment_id": 1412,
      "profile_id": 80,
      "published": "2016-12-05T01:49:37.338543Z",
      "thread_id": 186,
      "url": "/discussion/incorporating-drugcentral-data-in-our-network/186#21"
    },
    {
      "body_html": "<p>Regarding your comment about a drug not being designated as DM because withdrawal of the drug causes relapse of the disease, one could make the same argument for many other diseases: anti-epileptic drugs do not cure epilepsy, immuno-suppressants do not cure auto-immune disease, and chemo-therapies do not cure most cases of cancer. But this decision (DM vs SYM) is actually academic.</p>\r\n\r\n<p>When looking at the input to the algorithm, as you do here, recall that the data feeds in essentially as binary (and I believe SYM was essentially treated as \"on\" in the main report but we also ran it as \"off\", <a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a> would have to confirm this). So to switch all of a disease's agents from SYM to DM would not really change the output of the algorithm. Also recall that there are abundant false negatives in the input data. This level of false negatives was unfortunately quite necessary but also very proved very important in testing the output of the data. </p>\r\n\r\n<p>So, assuming a connection is truly DM but we mis-label it as NOT, then that would add to the already abundant false negative rate in the input data and presumably have little effect on the output. Therefore, I would not be strongly against removing any edge (changing DM to NOT) in the input data in general. And I know that <a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a> tested his algorithm to be robust to such perturbations in the input. </p>\r\n\r\n<p>Moving forward, the algorithm is meant to be automatically update-able in the future. I think it would be cool to crowdsource the input, essentially taking a vote as to whether things should be DM or SYM or NOT. </p>",
      "body_md": "Regarding your comment about a drug not being designated as DM because withdrawal of the drug causes relapse of the disease, one could make the same argument for many other diseases: anti-epileptic drugs do not cure epilepsy, immuno-suppressants do not cure auto-immune disease, and chemo-therapies do not cure most cases of cancer. But this decision (DM vs SYM) is actually academic.\r\n\r\nWhen looking at the input to the algorithm, as you do here, recall that the data feeds in essentially as binary (and I believe SYM was essentially treated as \"on\" in the main report but we also ran it as \"off\", @dhimmel would have to confirm this). So to switch all of a disease's agents from SYM to DM would not really change the output of the algorithm. Also recall that there are abundant false negatives in the input data. This level of false negatives was unfortunately quite necessary but also very proved very important in testing the output of the data. \r\n\r\nSo, assuming a connection is truly DM but we mis-label it as NOT, then that would add to the already abundant false negative rate in the input data and presumably have little effect on the output. Therefore, I would not be strongly against removing any edge (changing DM to NOT) in the input data in general. And I know that @dhimmel tested his algorithm to be robust to such perturbations in the input. \r\n\r\nMoving forward, the algorithm is meant to be automatically update-able in the future. I think it would be cool to crowdsource the input, essentially taking a vote as to whether things should be DM or SYM or NOT.",
      "comment_id": 1413,
      "profile_id": 188,
      "published": "2016-12-05T02:11:01.857288Z",
      "thread_id": 186,
      "url": "/discussion/incorporating-drugcentral-data-in-our-network/186#22"
    },
    {
      "body_html": "<p>I'm perhaps overly influenced by the use of \"disease modifying\" in the context of rhematoid arthritis: <a href=\"https://en.wikipedia.org/wiki/Disease-modifying_antirheumatic_drug\">https://en.wikipedia.org/wiki/Disease-modifying_antirheumatic_drug</a> The specific meaning is that such a drug prevents joint damage, rather than just reducing pain. By analogy, I'd agree that antiepileptics are not disease modifying.  Other cases get tougher.  I'm impressed in any case by the level of care you guys have put into all of this.  </p>\r\n\r\n<p>Dumb question: what algorithm? I was viewing this only as a database.</p>",
      "body_md": "I'm perhaps overly influenced by the use of \"disease modifying\" in the context of rhematoid arthritis: https://en.wikipedia.org/wiki/Disease-modifying_antirheumatic_drug The specific meaning is that such a drug prevents joint damage, rather than just reducing pain. By analogy, I'd agree that antiepileptics are not disease modifying.  Other cases get tougher.  I'm impressed in any case by the level of care you guys have put into all of this.  \r\n\r\nDumb question: what algorithm? I was viewing this only as a database.",
      "comment_id": 1414,
      "profile_id": 80,
      "published": "2016-12-05T03:22:35.665064Z",
      "thread_id": 186,
      "url": "/discussion/incorporating-drugcentral-data-in-our-network/186#23"
    },
    {
      "body_html": "<p>Regarding the initial preprocessing (e.g. splitting, NER) of PubMed, I wonder if the <a href=\"http://pubannotation.org\">PubAnnotation</a> project might provide some useful structures and data ?  </p>",
      "body_md": "Regarding the initial preprocessing (e.g. splitting, NER) of PubMed, I wonder if the [PubAnnotation] (http://pubannotation.org) project might provide some useful structures and data ?",
      "comment_id": 1415,
      "profile_id": 48,
      "published": "2016-12-05T16:42:13.418290Z",
      "thread_id": 227,
      "url": "/discussion/brainstorming-future-directions-for-hetionet/227#10"
    },
    {
      "body_html": "<p>To answer <a href=\"/u/mkgilson\" class=\"username\">@mkgilson</a> 's question, the <a href=\"https://thinklab.com/discussion/predictions-of-whether-a-compound-treats-a-disease/203\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d203\">algorithm (described here)</a> used the database of connections to predict what drugs would treat what disease. The <a href=\"https://thinklab.com/discussion/predictions-of-whether-a-compound-treats-a-disease/203\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d203\">results</a> are also found in the same discussion.</p>",
      "body_md": "To answer @mkgilson 's question, the [algorithm (described here)](https://thinklab.com/discussion/predictions-of-whether-a-compound-treats-a-disease/203) used the database of connections to predict what drugs would treat what disease. The [results] (https://thinklab.com/discussion/predictions-of-whether-a-compound-treats-a-disease/203) are also found in the same discussion.",
      "comment_id": 1416,
      "profile_id": 188,
      "published": "2016-12-05T17:46:40.193756Z",
      "thread_id": 186,
      "url": "/discussion/incorporating-drugcentral-data-in-our-network/186#24"
    },
    {
      "body_html": "<p>Should have responded sooner, but got side-tracked with my own work and was told by <a href=\"/u/olegursu\" class=\"username\">@olegursu</a> that he had answered this. So here's my two cents as to why Atorvastatin got annotated as treatment for essential hypertension, an indication \"bleeding\" from OMOP (now rebranded as OHDSI) that probably should have been carefully revised. <br>First off, I agree with <a href=\"/u/mkgilson\" class=\"username\">@mkgilson</a>, atorvastatin has no business treating HTN. It simply does not lower blood pressure. Some preliminary results suggested this to be the case, but systematic analysis did not reproduce this. <a href=\"http://www.medscape.org/viewarticle/494555\">http://www.medscape.org/viewarticle/494555</a> - in particular the study from Ostra Sjuikuset / Gothenburg / Sweden shows no difference (though the UCSD Statin Study claims a small effect). <br>I went to STITCH and looked at direct evidence for interacting partners between atorvastatin and proteins (http://stitch.embl.de/cgi/network.pl?taskId=JEpR8IjKFotd) but could not piece together any direct (or even indirect) way for this molecule to lower blood pressure. As additional qualifier, I did my PhD in molecular physiology and studied catecholamines for 5 years, and am somewhat familiar with mechanisms for lowering blood pressure. <br>Second, and here's where I <em>hypothesize</em> that FirstDataBank annotators (hence OMOP and now DrugCentral) got this wrong: Atorvastatin is formulated not only as LIPITOR but also as CADUET. And CADUET contains amlodipine besylate in addition to atorvastatin calcium (https://dailymed.nlm.nih.gov/dailymed/drugInfo.cfm?setid=909fad96-a941-443a-a39f-4f93607410fb). Error understandable, case closed.</p>",
      "body_md": "Should have responded sooner, but got side-tracked with my own work and was told by @olegursu that he had answered this. So here's my two cents as to why Atorvastatin got annotated as treatment for essential hypertension, an indication \"bleeding\" from OMOP (now rebranded as OHDSI) that probably should have been carefully revised. \r\nFirst off, I agree with @mkgilson, atorvastatin has no business treating HTN. It simply does not lower blood pressure. Some preliminary results suggested this to be the case, but systematic analysis did not reproduce this. http://www.medscape.org/viewarticle/494555 - in particular the study from Ostra Sjuikuset / Gothenburg / Sweden shows no difference (though the UCSD Statin Study claims a small effect). \r\nI went to STITCH and looked at direct evidence for interacting partners between atorvastatin and proteins (http://stitch.embl.de/cgi/network.pl?taskId=JEpR8IjKFotd) but could not piece together any direct (or even indirect) way for this molecule to lower blood pressure. As additional qualifier, I did my PhD in molecular physiology and studied catecholamines for 5 years, and am somewhat familiar with mechanisms for lowering blood pressure. \r\nSecond, and here's where I *hypothesize* that FirstDataBank annotators (hence OMOP and now DrugCentral) got this wrong: Atorvastatin is formulated not only as LIPITOR but also as CADUET. And CADUET contains amlodipine besylate in addition to atorvastatin calcium (https://dailymed.nlm.nih.gov/dailymed/drugInfo.cfm?setid=909fad96-a941-443a-a39f-4f93607410fb). Error understandable, case closed.",
      "comment_id": 1417,
      "profile_id": 75,
      "published": "2016-12-06T05:46:27.527483Z",
      "thread_id": 186,
      "url": "/discussion/incorporating-drugcentral-data-in-our-network/186#25"
    },
    {
      "body_html": "<p>Hi Tudor. I can see how the caduet case could have generated this anomaly.  Is the lesson to  omit data for combination drugs?</p>",
      "body_md": "Hi Tudor. I can see how the caduet case could have generated this anomaly.  Is the lesson to  omit data for combination drugs?",
      "comment_id": 1418,
      "profile_id": 80,
      "published": "2016-12-06T21:52:05.582056Z",
      "thread_id": 186,
      "url": "/discussion/incorporating-drugcentral-data-in-our-network/186#26"
    },
    {
      "body_html": "<p><a href=\"/u/mkgilson\" class=\"username\">@mkgilson</a>: definitely, I would start with 1-active ingredient drugs only, and build my Indications that way. Then go through 2-APIs and match known indications, and look for synergies (e.g., are there new indications for the combo that do not work when taking the 2 drugs separately). And so forth...</p>",
      "body_md": "@mkgilson: definitely, I would start with 1-active ingredient drugs only, and build my Indications that way. Then go through 2-APIs and match known indications, and look for synergies (e.g., are there new indications for the combo that do not work when taking the 2 drugs separately). And so forth...",
      "comment_id": 1419,
      "profile_id": 75,
      "published": "2016-12-06T23:01:40.250172Z",
      "thread_id": 186,
      "url": "/discussion/incorporating-drugcentral-data-in-our-network/186#27"
    },
    {
      "body_html": "<p>Just one additional point of clarification, with respect to the 1-2 mm Hg blood pressure lowering effect of atorvastatin from the UCSD Statin Study group (http://www.medscape.org/viewarticle/494555). In the first 4 years of medical school, I measured blood pressure (manually) for more than 100 patients, as well as 20 healthy volunteers. Differences of 5 mm Hg are found just by shifting from left hand to right hand; measuring the same person the same time, next day, can give that variation; measurements done by someone else (recall this was done using a stethoscope under the cuff) can give even more variations; and so forth. This is important enough that it warrants its own error table... <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3104931/table/T2/\">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3104931/table/T2/</a>. Since that Statin Study group Medscape reference is an abstract at a conference (i.e., no follow-up peer reviewed paper), we can most likely attribute those differences to experimental error, and conclude that the effect is not there.</p>",
      "body_md": "Just one additional point of clarification, with respect to the 1-2 mm Hg blood pressure lowering effect of atorvastatin from the UCSD Statin Study group (http://www.medscape.org/viewarticle/494555). In the first 4 years of medical school, I measured blood pressure (manually) for more than 100 patients, as well as 20 healthy volunteers. Differences of 5 mm Hg are found just by shifting from left hand to right hand; measuring the same person the same time, next day, can give that variation; measurements done by someone else (recall this was done using a stethoscope under the cuff) can give even more variations; and so forth. This is important enough that it warrants its own error table... https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3104931/table/T2/. Since that Statin Study group Medscape reference is an abstract at a conference (i.e., no follow-up peer reviewed paper), we can most likely attribute those differences to experimental error, and conclude that the effect is not there.",
      "comment_id": 1420,
      "profile_id": 75,
      "published": "2016-12-07T12:29:49.847011Z",
      "thread_id": 186,
      "url": "/discussion/incorporating-drugcentral-data-in-our-network/186#28"
    },
    {
      "body_html": "<p>I agree with you, Tudor. That's why I characterized the drop as \"paltry\" :-)  (Though, in principle, if one averages over enough data, one could resolve a shift in the mean of 2 mm Hg using data with a 5 mm Hg standard deviation.)</p>",
      "body_md": "I agree with you, Tudor. That's why I characterized the drop as \"paltry\" :-)  (Though, in principle, if one averages over enough data, one could resolve a shift in the mean of 2 mm Hg using data with a 5 mm Hg standard deviation.)",
      "comment_id": 1421,
      "profile_id": 80,
      "published": "2016-12-07T15:25:19.193128Z",
      "thread_id": 186,
      "url": "/discussion/incorporating-drugcentral-data-in-our-network/186#29"
    },
    {
      "body_html": "<p>Consider citing <code>10.1126/science.aah6168</code> <span class=\"citation\">[<a href=\"https://doi.org/10.1126/science.aah6168\" class=\"citation\" data-key=\"10.1126/science.aah6168\">1</a>]</span></p>",
      "body_md": "Consider citing `10.1126/science.aah6168` [@10.1126/science.aah6168]",
      "comment_id": 1422,
      "profile_id": 17,
      "published": "2016-12-08T20:10:31.078726Z",
      "thread_id": 226,
      "url": "/doc/7/review#7"
    },
    {
      "body_html": "<p>Queries such as this result in a timeout on Hetionet's Neo4j browser:<br>match (s:Symptom)-[em,4]-(a:Anatomy) return count()</p>",
      "body_md": "Queries such as this result in a timeout on Hetionet's Neo4j browser:\nmatch (s:Symptom)-[*4]-(a:Anatomy) return count(*)",
      "comment_id": 1424,
      "profile_id": 315,
      "published": "2016-12-15T04:15:28.467649Z",
      "thread_id": 226,
      "url": "/doc/7/review#8"
    },
    {
      "body_html": "<p>What are the the features in the Degree box above and DWPC box below? How is the logistic regression coefficient calculated?</p>",
      "body_md": "What are the the features in the Degree box above and DWPC box below? How is the logistic regression coefficient calculated?",
      "comment_id": 1425,
      "profile_id": 315,
      "published": "2016-12-15T04:16:54.733830Z",
      "thread_id": 226,
      "url": "/doc/7/review#9"
    },
    {
      "body_html": "<p>Why are these meta paths different to those in Fig 1?</p>",
      "body_md": "Why are these meta paths different to those in Fig 1?",
      "comment_id": 1426,
      "profile_id": 315,
      "published": "2016-12-15T04:18:13.552137Z",
      "thread_id": 226,
      "url": "/doc/7/review#10"
    },
    {
      "body_html": "<p>Only see 30 features in Fig 2B</p>",
      "body_md": "Only see 30 features in Fig 2B",
      "comment_id": 1427,
      "profile_id": 315,
      "published": "2016-12-15T04:19:48.389218Z",
      "thread_id": 226,
      "url": "/doc/7/review#11"
    },
    {
      "body_html": "<p>Only see 10 in Table 3 with positive coefficients</p>",
      "body_md": "Only see 10 in Table 3 with positive coefficients",
      "comment_id": 1428,
      "profile_id": 315,
      "published": "2016-12-15T04:20:44.874988Z",
      "thread_id": 226,
      "url": "/doc/7/review#12"
    },
    {
      "body_html": "<p>Only see two mentioned; GO and Disease Ontology</p>",
      "body_md": "Only see two mentioned; GO and Disease Ontology",
      "comment_id": 1429,
      "profile_id": 315,
      "published": "2016-12-15T04:22:34.888786Z",
      "thread_id": 226,
      "url": "/doc/7/review#13"
    },
    {
      "body_html": "<p>What is the 4th dataset, Symptomatic? Is this in any way related to the 'palliates' relationship?</p>",
      "body_md": "What is the 4th dataset, Symptomatic? Is this in any way related to the 'palliates' relationship?",
      "comment_id": 1430,
      "profile_id": 315,
      "published": "2016-12-15T04:24:00.126439Z",
      "thread_id": 226,
      "url": "/doc/7/review#14"
    },
    {
      "body_html": "<p>What were the criteria for meta edges selection? Were they a certain group of relationships you sought after or did you try to obtain as many relationships as possible?</p>",
      "body_md": "What were the criteria for meta edges selection? Were they a certain group of relationships you sought after or did you try to obtain as many relationships as possible?",
      "comment_id": 1431,
      "profile_id": 315,
      "published": "2016-12-15T04:25:13.994938Z",
      "thread_id": 226,
      "url": "/doc/7/review#15"
    },
    {
      "body_html": "<p>How long did the data integration take? Was raw data to hetnet conversion more laborious than migrating hetnets to Hetionet?</p>",
      "body_md": "How long did the data integration take? Was raw data to hetnet conversion more laborious than migrating hetnets to Hetionet?",
      "comment_id": 1432,
      "profile_id": 315,
      "published": "2016-12-15T04:28:58.756467Z",
      "thread_id": 226,
      "url": "/doc/7/review#16"
    },
    {
      "body_html": "<p>How long did the (logistic regression) training take given that you have strong predictive features?</p>",
      "body_md": "How long did the (logistic regression) training take given that you have strong predictive features?",
      "comment_id": 1433,
      "profile_id": 315,
      "published": "2016-12-15T04:31:39.368703Z",
      "thread_id": 226,
      "url": "/doc/7/review#17"
    },
    {
      "body_html": "<p>Is the data used to evaluate this work (209,168 compound–disease pairs and their metapaths), open freely for experimentation?</p>",
      "body_md": "Is the data used to evaluate this work (209,168 compound–disease pairs and their metapaths), open freely for experimentation?",
      "comment_id": 1434,
      "profile_id": 315,
      "published": "2016-12-15T04:40:15.986372Z",
      "thread_id": 226,
      "url": "/doc/7/review#18"
    },
    {
      "body_html": "<p>I think you have the following query you have in mind:</p>\n\n<pre><code class=\"no-highlight hljs\">MATCH (s:Symptom)-[*4]-(a:Anatomy)\nRETURN count(*)</code></pre>\n\n<p>This query looks for all paths of length four between any symptom node and any anatomy node. However, Figure 1C shows the number of metapaths (types of paths), not the overall number of paths. I modified your query to return distinct metapaths (and changed Anatomy to Compound and length 4 to 2 to make things more computationally tractable):</p>\n\n<pre><code class=\"no-highlight hljs\">MATCH path = (:Symptom)-[*2]-(:Compound)\nWITH\n  [rel IN relationships(path) | type(rel) ] AS metapath\nRETURN DISTINCT metapath</code></pre>\n\n<p>You can read more about <a href=\"https://thinklab.com/discussion/describing-hetionet-v10-through-visualization-and-statistics/202#4\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d202\">Figure 1C here</a>, When we calculated the number of metapaths (<a href=\"https://github.com/dhimmel/integrate/blob/725f4e4b4a737cfb15abe55ef36386c23e1c4f1f/viz/auto/1-prepare.ipynb\">notebook</a>), we didn't use Neo4j at all. Instead we used our <a href=\"https://github.com/dhimmel/hetio\"><code>hetio</code></a> python package <span class=\"citation\">[<a href=\"https://doi.org/10.5281/zenodo.61571\" class=\"citation\" data-key=\"10.5281/zenodo.61571\">1</a>]</span> which computed the number of metapaths directly from the metagraph for greater efficiency.</p>",
      "body_md": "I think you have the following query you have in mind:\n\n```cypher\nMATCH (s:Symptom)-[*4]-(a:Anatomy)\nRETURN count(*)\n```\n\nThis query looks for all paths of length four between any symptom node and any anatomy node. However, Figure 1C shows the number of metapaths (types of paths), not the overall number of paths. I modified your query to return distinct metapaths (and changed Anatomy to Compound and length 4 to 2 to make things more computationally tractable):\n\n```cypher\nMATCH path = (:Symptom)-[*2]-(:Compound)\nWITH\n  [rel IN relationships(path) | type(rel) ] AS metapath\nRETURN DISTINCT metapath\n```\n\nYou can read more about [Figure 1C here](https://thinklab.com/discussion/describing-hetionet-v10-through-visualization-and-statistics/202#4), When we calculated the number of metapaths ([notebook](https://github.com/dhimmel/integrate/blob/725f4e4b4a737cfb15abe55ef36386c23e1c4f1f/viz/auto/1-prepare.ipynb)), we didn't use Neo4j at all. Instead we used our [`hetio`](https://github.com/dhimmel/hetio) python package [@10.5281/zenodo.61571] which computed the number of metapaths directly from the metagraph for greater efficiency.",
      "comment_id": 1435,
      "profile_id": 17,
      "published": "2016-12-15T15:40:55.970481Z",
      "thread_id": 226,
      "url": "/doc/7/review#19"
    },
    {
      "body_html": "<p>All of these metapaths can be generated by walking the metagraph in <a href=\"#hetionet_figure\">Figure 1A</a>.</p>",
      "body_md": "All of these metapaths can be generated by walking the metagraph in [Figure 1A](#hetionet_figure).",
      "comment_id": 1436,
      "profile_id": 17,
      "published": "2016-12-15T15:46:10.347357Z",
      "thread_id": 226,
      "url": "/doc/7/review#20"
    },
    {
      "body_html": "<p>Figure 2B shows the logistic regression coefficients <a href=\"https://thinklab.com/discussion/our-hetnet-edge-prediction-methodology-the-modeling-framework-for-project-rephetio/210#4\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d210\">as described here</a>.</p>\n\n<p>We have <a href=\"https://thinklab.com/discussion/our-hetnet-edge-prediction-methodology-the-modeling-framework-for-project-rephetio/210#2\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d210\">three types of features</a>: the prior (not shown in Figure 2), degree features (showin in Figure 2B), and DWPCs (shown in Figure 2A–B). Degree features</p>\n\n<blockquote><p>assess the degree of a specific metaedge for either the source compound or target disease.</p></blockquote>",
      "body_md": "Figure 2B shows the logistic regression coefficients [as described here](https://thinklab.com/discussion/our-hetnet-edge-prediction-methodology-the-modeling-framework-for-project-rephetio/210#4).\n\nWe have [three types of features](https://thinklab.com/discussion/our-hetnet-edge-prediction-methodology-the-modeling-framework-for-project-rephetio/210#2): the prior (not shown in Figure 2), degree features (showin in Figure 2B), and DWPCs (shown in Figure 2A--B). Degree features\n\n> assess the degree of a specific metaedge for either the source compound or target disease.\n\n",
      "comment_id": 1437,
      "profile_id": 17,
      "published": "2016-12-15T15:58:45.966789Z",
      "thread_id": 226,
      "url": "/doc/7/review#21"
    },
    {
      "body_html": "<p>Great 👀. The missing feature is <em>CrCbGaD</em> (Compound–resembles–Compound–binds–Gene–associates–Disease). I should either consider the coefficient for this feature negligible or include the feature in Table 3 (what I'm leaning towards). Note there's an <a href=\"http://het.io/repurpose/metapaths.html\">online version</a> of Table 3 with all metapaths.</p>",
      "body_md": "Great 👀. The missing feature is _CrCbGaD_ (Compound–resembles–Compound–binds–Gene–associates–Disease). I should either consider the coefficient for this feature negligible or include the feature in Table 3 (what I'm leaning towards). Note there's an [online version](http://het.io/repurpose/metapaths.html) of Table 3 with all metapaths.",
      "comment_id": 1438,
      "profile_id": 17,
      "published": "2016-12-15T16:07:43.183272Z",
      "thread_id": 226,
      "url": "/doc/7/review#22"
    },
    {
      "body_html": "<p>See <a href=\"indication-sets\">Indication sets</a><a href=\"https://thinklab.com/doc/7/review#section-87\">https://thinklab.com/doc/7/review#section-87</a></p>\n\n<blockquote><p><strong>Symptomatic</strong> — 390 symptomatic indications from PharacotherapyDB. These edges are included in the hetnet as <em>palliates</em> edges.</p></blockquote>\n\n<p>So yes they are the <em>palliates</em> relationships.</p>",
      "body_md": "See [Indication sets](indication-sets)https://thinklab.com/doc/7/review#section-87\n\n> **Symptomatic** — 390 symptomatic indications from PharacotherapyDB. These edges are included in the hetnet as _palliates_ edges.\n\nSo yes they are the _palliates_ relationships.",
      "comment_id": 1439,
      "profile_id": 17,
      "published": "2016-12-15T16:11:47.023060Z",
      "thread_id": 226,
      "url": "/doc/7/review#23"
    },
    {
      "body_html": "<p>The prior is a feature but is not shown in <a href=\"#feature_figure\">Figure 2B</a>. It <a href=\"https://thinklab.com/discussion/our-hetnet-edge-prediction-methodology-the-modeling-framework-for-project-rephetio/210#4\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d210\">was omitted</a> since it's </p>\n\n<ol><li>invariant during prediction (set to correspond to the null probability of treatment across all compound-disease pairs, 0.36%)</li><li>much greater than another other coefficient at 0.70. Unlike the 30 features shown in Figure 2B, we didn't standardize the <code>prior_logit</code> feature.</li></ol>",
      "body_md": "The prior is a feature but is not shown in [Figure 2B](#feature_figure). It [was omitted](https://thinklab.com/discussion/our-hetnet-edge-prediction-methodology-the-modeling-framework-for-project-rephetio/210#4) since it's \n\n1. invariant during prediction (set to correspond to the null probability of treatment across all compound-disease pairs, 0.36%)\n2. much greater than another other coefficient at 0.70. Unlike the 30 features shown in Figure 2B, we didn't standardize the `prior_logit` feature.",
      "comment_id": 1440,
      "profile_id": 17,
      "published": "2016-12-15T16:24:27.146258Z",
      "thread_id": 226,
      "url": "/doc/7/review#24"
    },
    {
      "body_html": "<p>The five ontologies are:</p>\n\n<ol><li>Disease Ontology for diseases</li><li>Gene Ontology for biological processes, cellular components, and molecular functions</li><li>MeSH for symptoms</li><li>Uberon for anatomies</li><li>UMLS for side effects</li></ol>",
      "body_md": "The five ontologies are:\n\n1. Disease Ontology for diseases\n2. Gene Ontology for biological processes, cellular components, and molecular functions\n3. MeSH for symptoms\n4. Uberon for anatomies\n5. UMLS for side effects",
      "comment_id": 1441,
      "profile_id": 17,
      "published": "2016-12-15T16:32:57.050741Z",
      "thread_id": 226,
      "url": "/doc/7/review#25"
    },
    {
      "body_html": "<p>We were most interested in relationships that were plausibly informative for modeling drug efficacy. We also focused on integrating relationships from <a href=\"https://thinklab.com/discussion/text-as-a-resource-for-network-population/48#3\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d48\">high-throughput/systematic methods</a> (see for example LINCS, STARGEO, Bgee, evolutionary rate covariation, and the Human Interactome Database) that we hoped would help make novel predictions. In addition,</p>\n\n<blockquote><p>Practical considerations such as data availability, licensing, reusability, documentation, throughput, and standardization informed our choice of resources.</p></blockquote>",
      "body_md": "We were most interested in relationships that were plausibly informative for modeling drug efficacy. We also focused on integrating relationships from [high-throughput/systematic methods](https://thinklab.com/discussion/text-as-a-resource-for-network-population/48#3) (see for example LINCS, STARGEO, Bgee, evolutionary rate covariation, and the Human Interactome Database) that we hoped would help make novel predictions. In addition,\n\n> Practical considerations such as data availability, licensing, reusability, documentation, throughput, and standardization informed our choice of resources.",
      "comment_id": 1442,
      "profile_id": 17,
      "published": "2016-12-15T16:42:31.415721Z",
      "thread_id": 226,
      "url": "/doc/7/review#26"
    },
    {
      "body_html": "<p>Yes, it's available under a CC0 public domain dedication.</p>\n\n<ul><li><p>The data for the all-features stage is <a href=\"https://github.com/dhimmel/learn/tree/d2251a942813015d0362a90f179c961016336e77/all-features/data\">available here</a>.</p></li><li><p>The matrix for the all-observations stage (with 209,168 compound–disease pairs as rows) is <a href=\"https://github.com/dhimmel/learn/blob/d2251a942813015d0362a90f179c961016336e77/prediction/features/transformed-features.tsv.bz2\">available here</a>.</p></li></ul>\n\n<p>If you have questions on data or other content in <code>dhimmel/learn</code>, the best thing to do will probably be to open a new <a href=\"https://github.com/dhimmel/learn/issues\">GitHub Issue</a>.</p>",
      "body_md": "Yes, it's available under a CC0 public domain dedication.\n\n+ The data for the all-features stage is [available here](https://github.com/dhimmel/learn/tree/d2251a942813015d0362a90f179c961016336e77/all-features/data).\n\n+ The matrix for the all-observations stage (with 209,168 compound–disease pairs as rows) is [available here](https://github.com/dhimmel/learn/blob/d2251a942813015d0362a90f179c961016336e77/prediction/features/transformed-features.tsv.bz2).\n\nIf you have questions on data or other content in `dhimmel/learn`, the best thing to do will probably be to open a new [GitHub Issue](https://github.com/dhimmel/learn/issues).",
      "comment_id": 1443,
      "profile_id": 17,
      "published": "2016-12-15T16:56:09.284080Z",
      "thread_id": 226,
      "url": "/doc/7/review#27"
    },
    {
      "body_html": "<p>Fitting the logistic regression model using <code>glmnet</code> took under an hour, if I remember correctly. I'm not sure if having strongly predictive features actually speeds up model fitting. I do remember that having lot's of observations — we had 29,799 — can really slow it down.</p>\n\n<p>Overall, feature extraction was much more computationally insensitive than model fitting. Getting feature extraction to complete in a reasonable time took <a href=\"https://thinklab.com/discussion/using-the-neo4j-graph-database-for-hetnets/112#6\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d112\">query optimizations</a>, <a href=\"https://thinklab.com/discussion/estimating-the-complexity-of-hetnet-traversal/187\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d187\">complexity benchmarking</a>, and the <a href=\"https://thinklab.com/discussion/our-hetnet-edge-prediction-methodology-the-modeling-framework-for-project-rephetio/210#2\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d210\">two-stage</a> machine learning bifurcation.</p>",
      "body_md": "Fitting the logistic regression model using `glmnet` took under an hour, if I remember correctly. I'm not sure if having strongly predictive features actually speeds up model fitting. I do remember that having lot's of observations -- we had 29,799 -- can really slow it down.\n\nOverall, feature extraction was much more computationally insensitive than model fitting. Getting feature extraction to complete in a reasonable time took [query optimizations](https://thinklab.com/discussion/using-the-neo4j-graph-database-for-hetnets/112#6), [complexity benchmarking](https://thinklab.com/discussion/estimating-the-complexity-of-hetnet-traversal/187), and the [two-stage](https://thinklab.com/discussion/our-hetnet-edge-prediction-methodology-the-modeling-framework-for-project-rephetio/210#2) machine learning bifurcation.\n\n",
      "comment_id": 1444,
      "profile_id": 17,
      "published": "2016-12-15T17:05:01.645700Z",
      "thread_id": 226,
      "url": "/doc/7/review#28"
    },
    {
      "body_html": "<p>As a reminder, the degree-weighted path count (DWPC) measures the prevalence of metapath between a specific source and target node <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation \" data-key=\"10.1371/journal.pcbi.1004259\">1</a>]</span>. It equals the sum of path degree products (PDPs), which provide a score for a single path based on the degrees along the path.</p>\r\n\r\n<p>Traditionally, the DWPC sums the PDPs for all paths connecting the source and target node along a specified metapath. Here I propose a new type of DWPCs that only sums paths that traverse the same intermediate node at a specified position. In other words, traditional DWPCs are defined for a source–target–metapath combination, whereas the proposed DWPCs are defined for a source–target–metapath–position combination. Position refers to an intermediate metanode. However, this approach would also work with an intermediate metaedge as the position. Note that choosing either the source or target metanode as the position is equivalent to the traditional DWPC.</p>\r\n\r\n<p>The purpose of this approach is to assess the contribution of intermediate nodes (or edges) in composing the DWPC. Remember that the sum of all \"partial\" DWPCs equals the traditional DWPC. This approach doesn't replace the need for traditional DWPCs — they serve different needs and answer different questions.</p>\r\n\r\n<p>I'm not satisfied with the traditional versus partial nomenclature. <a href=\"/u/alizee\" class=\"username\">@alizee</a>, any advice?</p>",
      "body_md": "As a reminder, the degree-weighted path count (DWPC) measures the prevalence of metapath between a specific source and target node [@10.1371/journal.pcbi.1004259]. It equals the sum of path degree products (PDPs), which provide a score for a single path based on the degrees along the path.\r\n\r\nTraditionally, the DWPC sums the PDPs for all paths connecting the source and target node along a specified metapath. Here I propose a new type of DWPCs that only sums paths that traverse the same intermediate node at a specified position. In other words, traditional DWPCs are defined for a source--target--metapath combination, whereas the proposed DWPCs are defined for a source--target--metapath--position combination. Position refers to an intermediate metanode. However, this approach would also work with an intermediate metaedge as the position. Note that choosing either the source or target metanode as the position is equivalent to the traditional DWPC.\r\n\r\nThe purpose of this approach is to assess the contribution of intermediate nodes (or edges) in composing the DWPC. Remember that the sum of all \"partial\" DWPCs equals the traditional DWPC. This approach doesn't replace the need for traditional DWPCs -- they serve different needs and answer different questions.\r\n\r\nI'm not satisfied with the traditional versus partial nomenclature. @alizee, any advice?",
      "comment_id": 1445,
      "profile_id": 17,
      "published": "2016-12-15T21:16:12.403408Z",
      "thread_id": 228,
      "url": "/discussion/decomposing-the-dwpc-to-assess-intermediate-node-or-edge-contributions/228"
    },
    {
      "body_html": "<h1>Enalapril for coronary artery disease example</h1>\r\n\r\n<p><strong>Prelude:</strong> I recently helped <a href=\"/u/cgreene\" class=\"username\">@cgreene</a> with a grant proposal titled \"Network-based algorithms for drug discovery from genetic associations\" (application <code>1R01HG009516-01A1</code>). For this proposal, we wanted to show an example where considering the tissue-specificity of paths helped identify the mechanisms of drug efficacy. In the course of this analysis, we came up with the partial DWPC method and the following example (the tissue-specific additions are <em>not</em> included below).</p>\r\n\r\n<hr>\r\n\r\n<p>Enalapril treats coronary artery disease (CAD) by inhibiting angiotensin-converting enzyme (ACE) <span class=\"citation\">[<a href=\"https://doi.org/10.1001/archinte.166.7.787\" class=\"citation\" data-key=\"10.1001/archinte.166.7.787\">1</a>]</span>. Traditionally, if we were interested in potential pathways contributing to drug efficacy we may search for <em>CbGpPWpGaD</em> paths between enalapril and CAD. Below is the Cypher query to return all paths, ranked by PDP (run the query at <a href=\"https://neo4j.het.io\">https://neo4j.het.io</a>):</p>\r\n\r\n<pre><code class=\"no-highlight hljs\">MATCH path = (n0:Compound)-[:BINDS_CbG]-(n1)-[:PARTICIPATES_GpPW]-\r\n  (n2)-[:PARTICIPATES_GpPW]-(n3)-[:ASSOCIATES_DaG]-(n4:Disease)\r\nUSING JOIN ON n2\r\nWHERE n0.name = 'Enalapril'\r\n  AND n4.name = 'coronary artery disease'\r\n  AND n1 &lt;&gt; n3\r\nWITH\r\n  path,\r\n[\r\n  size((n0)-[:BINDS_CbG]-()),\r\n  size(()-[:BINDS_CbG]-(n1)),\r\n  size((n1)-[:PARTICIPATES_GpPW]-()),\r\n  size(()-[:PARTICIPATES_GpPW]-(n2)),\r\n  size((n2)-[:PARTICIPATES_GpPW]-()),\r\n  size(()-[:PARTICIPATES_GpPW]-(n3)),\r\n  size((n3)-[:ASSOCIATES_DaG]-()),\r\n  size(()-[:ASSOCIATES_DaG]-(n4))\r\n] AS degrees\r\nRETURN\r\n  substring(reduce(s = '', node IN nodes(path)| s + '–' + node.name), 1) AS nodes,\r\n  reduce(pdp = 1.0, d in degrees| pdp * d ^ -0.4) AS PDP\r\nORDER BY PDP DESC</code></pre>\r\n\r\n<p>Overall, 757 paths were returned. The top 3 paths are:</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>nodes</th><th>PDP</th></tr></thead><tbody><tr><td>Enalapril–ACE–Metabolism of Angiotensinogen to Angiotensins–ACE2–coronary artery disease</td><td>0.000258</td></tr><tr><td>Enalapril–ACE–ACE Inhibitor Pathway–NR3C2–coronary artery disease</td><td>0.000252</td></tr><tr><td>Enalapril–ACE–ACE Inhibitor Pathway–ACE2–coronary artery disease</td><td>0.000245</td></tr></tbody></table>\r\n\r\n<p>Now let's assume we're more interested in the contributions of specific pathway nodes rather than specific paths. In other words, we don't really care what genes got us to a pathway, we just want an overal score per pathway. In this case, we can select <code>n2</code> as the position. Now we're computing a DWPC for <em>Enalapril</em>–binds–Gene–participates–<strong>Pathway</strong>–participates–Gene–associates–<em>coronary artery disease</em>, where bold indicates position. The query becomes:</p>\r\n\r\n<pre><code class=\"no-highlight hljs\">MATCH path = (n0:Compound)-[:BINDS_CbG]-(n1)-[:PARTICIPATES_GpPW]-\r\n  (n2)-[:PARTICIPATES_GpPW]-(n3)-[:ASSOCIATES_DaG]-(n4:Disease)\r\nUSING JOIN ON n2\r\nWHERE n0.name = 'Enalapril'\r\n  AND n4.name = 'coronary artery disease'\r\n  AND n1 &lt;&gt; n3\r\nWITH\r\n  path,\r\n  n2 AS pathway,\r\n[\r\n  size((n0)-[:BINDS_CbG]-()),\r\n  size(()-[:BINDS_CbG]-(n1)),\r\n  size((n1)-[:PARTICIPATES_GpPW]-()),\r\n  size(()-[:PARTICIPATES_GpPW]-(n2)),\r\n  size((n2)-[:PARTICIPATES_GpPW]-()),\r\n  size(()-[:PARTICIPATES_GpPW]-(n3)),\r\n  size((n3)-[:ASSOCIATES_DaG]-()),\r\n  size(()-[:ASSOCIATES_DaG]-(n4))\r\n] AS degrees\r\nRETURN\r\n  pathway.identifier AS pathway_id,\r\n  pathway.name AS pathway_name,\r\n  count(*) AS PC,\r\n  sum(reduce(pdp = 1.0, d in degrees| pdp * d ^ -0.4)) AS DWPC\r\nORDER BY DWPC DESC, pathway_name</code></pre>\r\n\r\n<p>40 pathways are returned, of which the top 5 are displayed below:</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>pathway_id</th><th>pathway_name</th><th>PC</th><th>DWPC</th></tr></thead><tbody><tr><td>WP554_r84372</td><td>ACE Inhibitor Pathway</td><td>11</td><td>0.0015</td></tr><tr><td>PC7_8339</td><td>Transmembrane transport of small molecules</td><td>150</td><td>0.0008</td></tr><tr><td>PC7_5323</td><td>Metabolism of Angiotensinogen to Angiotensins</td><td>3</td><td>0.0005</td></tr><tr><td>PC7_7290</td><td>SLC-mediated transmembrane transport</td><td>40</td><td>0.0004</td></tr><tr><td>PC7_5322</td><td>Metabolism</td><td>309</td><td>0.0004</td></tr></tbody></table>\r\n\r\n<p>As shown, we now have a ranking of pathways based on their contribution to the overall <em>CbGpPWpGaD</em> metapath. Currently, I don't see a huge role for this approach for feature extraction, but think it's useful for following up on specific predictions and highlighting mechanisms of drug efficacy.</p>",
      "body_md": "# Enalapril for coronary artery disease example\r\n\r\n**Prelude:** I recently helped @cgreene with a grant proposal titled \"Network-based algorithms for drug discovery from genetic associations\" (application `1R01HG009516-01A1`). For this proposal, we wanted to show an example where considering the tissue-specificity of paths helped identify the mechanisms of drug efficacy. In the course of this analysis, we came up with the partial DWPC method and the following example (the tissue-specific additions are _not_ included below).\r\n\r\n***\r\n\r\nEnalapril treats coronary artery disease (CAD) by inhibiting angiotensin-converting enzyme (ACE) [@10.1001/archinte.166.7.787]. Traditionally, if we were interested in potential pathways contributing to drug efficacy we may search for _CbGpPWpGaD_ paths between enalapril and CAD. Below is the Cypher query to return all paths, ranked by PDP (run the query at https://neo4j.het.io):\r\n\r\n```cypher\r\nMATCH path = (n0:Compound)-[:BINDS_CbG]-(n1)-[:PARTICIPATES_GpPW]-\r\n  (n2)-[:PARTICIPATES_GpPW]-(n3)-[:ASSOCIATES_DaG]-(n4:Disease)\r\nUSING JOIN ON n2\r\nWHERE n0.name = 'Enalapril'\r\n  AND n4.name = 'coronary artery disease'\r\n  AND n1 <> n3\r\nWITH\r\n  path,\r\n[\r\n  size((n0)-[:BINDS_CbG]-()),\r\n  size(()-[:BINDS_CbG]-(n1)),\r\n  size((n1)-[:PARTICIPATES_GpPW]-()),\r\n  size(()-[:PARTICIPATES_GpPW]-(n2)),\r\n  size((n2)-[:PARTICIPATES_GpPW]-()),\r\n  size(()-[:PARTICIPATES_GpPW]-(n3)),\r\n  size((n3)-[:ASSOCIATES_DaG]-()),\r\n  size(()-[:ASSOCIATES_DaG]-(n4))\r\n] AS degrees\r\nRETURN\r\n  substring(reduce(s = '', node IN nodes(path)| s + '–' + node.name), 1) AS nodes,\r\n  reduce(pdp = 1.0, d in degrees| pdp * d ^ -0.4) AS PDP\r\nORDER BY PDP DESC\r\n```\r\n\r\nOverall, 757 paths were returned. The top 3 paths are:\r\n\r\n| nodes | PDP |\r\n|-----------------|----------|\r\n| Enalapril–ACE–Metabolism of Angiotensinogen to Angiotensins–ACE2–coronary artery disease | 0.000258 |\r\n| Enalapril–ACE–ACE Inhibitor Pathway–NR3C2–coronary artery disease | 0.000252 |\r\n| Enalapril–ACE–ACE Inhibitor Pathway–ACE2–coronary artery disease | 0.000245 |\r\n\r\nNow let's assume we're more interested in the contributions of specific pathway nodes rather than specific paths. In other words, we don't really care what genes got us to a pathway, we just want an overal score per pathway. In this case, we can select `n2` as the position. Now we're computing a DWPC for *Enalapril*–binds–Gene–participates–**Pathway**–participates–Gene–associates–*coronary artery disease*, where bold indicates position. The query becomes:\r\n\r\n```cypher\r\nMATCH path = (n0:Compound)-[:BINDS_CbG]-(n1)-[:PARTICIPATES_GpPW]-\r\n  (n2)-[:PARTICIPATES_GpPW]-(n3)-[:ASSOCIATES_DaG]-(n4:Disease)\r\nUSING JOIN ON n2\r\nWHERE n0.name = 'Enalapril'\r\n  AND n4.name = 'coronary artery disease'\r\n  AND n1 <> n3\r\nWITH\r\n  path,\r\n  n2 AS pathway,\r\n[\r\n  size((n0)-[:BINDS_CbG]-()),\r\n  size(()-[:BINDS_CbG]-(n1)),\r\n  size((n1)-[:PARTICIPATES_GpPW]-()),\r\n  size(()-[:PARTICIPATES_GpPW]-(n2)),\r\n  size((n2)-[:PARTICIPATES_GpPW]-()),\r\n  size(()-[:PARTICIPATES_GpPW]-(n3)),\r\n  size((n3)-[:ASSOCIATES_DaG]-()),\r\n  size(()-[:ASSOCIATES_DaG]-(n4))\r\n] AS degrees\r\nRETURN\r\n  pathway.identifier AS pathway_id,\r\n  pathway.name AS pathway_name,\r\n  count(*) AS PC,\r\n  sum(reduce(pdp = 1.0, d in degrees| pdp * d ^ -0.4)) AS DWPC\r\nORDER BY DWPC DESC, pathway_name\r\n```\r\n\r\n40 pathways are returned, of which the top 5 are displayed below:\r\n\r\n| pathway_id | pathway_name | PC | DWPC |\r\n|--------------|-----------------------------------------------|-----|--------|\r\n| WP554_r84372 | ACE Inhibitor Pathway | 11 | 0.0015 |\r\n| PC7_8339 | Transmembrane transport of small molecules | 150 | 0.0008 |\r\n| PC7_5323 | Metabolism of Angiotensinogen to Angiotensins | 3 | 0.0005 |\r\n| PC7_7290 | SLC-mediated transmembrane transport | 40 | 0.0004 |\r\n| PC7_5322 | Metabolism | 309 | 0.0004 |\r\n\r\nAs shown, we now have a ranking of pathways based on their contribution to the overall _CbGpPWpGaD_ metapath. Currently, I don't see a huge role for this approach for feature extraction, but think it's useful for following up on specific predictions and highlighting mechanisms of drug efficacy.",
      "comment_id": 1446,
      "profile_id": 17,
      "published": "2016-12-15T21:41:18.549540Z",
      "thread_id": 228,
      "url": "/discussion/decomposing-the-dwpc-to-assess-intermediate-node-or-edge-contributions/228#2"
    },
    {
      "body_html": "<p>Here's the <a href=\"https://github.com/dhimmel/integrate/blob/725f4e4b4a737cfb15abe55ef36386c23e1c4f1f/integrate.ipynb\">notebook</a> that creates Hetionet using the <code>hetio</code> package. It should give you a better idea of how we create the network.</p>\n\n<blockquote><p>How long did the data integration take?</p></blockquote>\n\n<p>It took me about a year to construct the network. However, you could now repeat the process in less time. I believe <a href=\"/u/tongli\" class=\"username\">@tongli</a> has repeated much of the process, with some tweaks. <a href=\"/u/tongli\" class=\"username\">@tongli</a> do you want to comment on how long things take.</p>\n\n<blockquote><p>Was raw data to hetnet conversion more laborious than migrating hetnets to Hetionet?</p></blockquote>\n\n<p>Importing the JSON/hetio format for storing the hetnet takes <a href=\"https://github.com/dhimmel/integrate/issues/10#issuecomment-250845865\" title=\"GitHub Issue\">about a day</a> on a decent system.</p>",
      "body_md": "Here's the [notebook](https://github.com/dhimmel/integrate/blob/725f4e4b4a737cfb15abe55ef36386c23e1c4f1f/integrate.ipynb) that creates Hetionet using the `hetio` package. It should give you a better idea of how we create the network.\n\n> How long did the data integration take?\n\nIt took me about a year to construct the network. However, you could now repeat the process in less time. I believe @tongli has repeated much of the process, with some tweaks. @tongli do you want to comment on how long things take.\n\n> Was raw data to hetnet conversion more laborious than migrating hetnets to Hetionet?\n\nImporting the JSON/hetio format for storing the hetnet takes [about a day](https://github.com/dhimmel/integrate/issues/10#issuecomment-250845865 \"GitHub Issue\") on a decent system.",
      "comment_id": 1447,
      "profile_id": 17,
      "published": "2016-12-16T15:31:26.181121Z",
      "thread_id": 226,
      "url": "/doc/7/review#29"
    },
    {
      "body_html": "<p>The actual runtime of the individual notebooks (especially the data integration ones) has never been the problem for me. Rather it is understanding and modifying the notebooks which is time intensive and difficult.</p>\n\n<p>I have had success running the data integration portion of the full sized Hetionet on AWS, but am currently working on a cross-validation evaluation scheme which is currently using a substantially reduced network (consisting only of gene, disease, compound nodes and their relations).</p>\n\n<p>My personal version of the data integration code can be found <a href=\"https://github.com/veleritas/integrate\">here</a>.</p>",
      "body_md": "The actual runtime of the individual notebooks (especially the data integration ones) has never been the problem for me. Rather it is understanding and modifying the notebooks which is time intensive and difficult.\n\nI have had success running the data integration portion of the full sized Hetionet on AWS, but am currently working on a cross-validation evaluation scheme which is currently using a substantially reduced network (consisting only of gene, disease, compound nodes and their relations).\n\nMy personal version of the data integration code can be found [here](https://github.com/veleritas/integrate).\n",
      "comment_id": 1448,
      "profile_id": 176,
      "published": "2016-12-16T20:33:48.959931Z",
      "thread_id": 226,
      "url": "/doc/7/review#30"
    },
    {
      "body_html": "<p>Consider updating GWAS Catalog citation to <code>10.1093/nar/gkw1133</code> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkw1133\" class=\"citation\" data-key=\"10.1093/nar/gkw1133\">1</a>]</span>.</p>",
      "body_md": "Consider updating GWAS Catalog citation to `10.1093/nar/gkw1133` [@10.1093/nar/gkw1133].",
      "comment_id": 1449,
      "profile_id": 17,
      "published": "2016-12-19T15:37:26.501858Z",
      "thread_id": 226,
      "url": "/doc/7/review#31"
    },
    {
      "body_html": "<h1>Grouping paths by their source or target edge</h1>\r\n\r\n<p>The <a href=\"#2\">previous comment</a> discussed grouping paths by an intermediate node and then calculating partial DWPCs. This comment introduces an alternative grouping method: grouping either by the source edge (first edge in the path) or target edge (last edge in the path).</p>\r\n\r\n<p>Here's the intuition behind this approach. In a hetnet, a node derives its meaning from its relationships. For example, our algorithm is based solely on relationships. Therefore, a good way to investigate a prediction is to consider which edges of either the source compound or target disease mattered. We can this for a specific source–target–metapath combination, by grouping paths by their source or target edge.</p>\r\n\r\n<p>For example, the following query takes the enalapril–CAD example and asks which target edges are composing the <em>CbGpPWpGaD</em> paths.</p>\r\n\r\n<pre><code class=\"no-highlight hljs\">MATCH path = (n0:Compound)-[:BINDS_CbG]-(n1)-[:PARTICIPATES_GpPW]-\r\n  (n2)-[:PARTICIPATES_GpPW]-(n3)-[:ASSOCIATES_DaG]-(n4:Disease)\r\nUSING JOIN ON n2\r\nWHERE n0.name = 'Enalapril'\r\n  AND n4.name = 'coronary artery disease'\r\n  AND n1 &lt;&gt; n3\r\nWITH\r\n  path,\r\n[\r\n  size((n0)-[:BINDS_CbG]-()),\r\n  size(()-[:BINDS_CbG]-(n1)),\r\n  size((n1)-[:PARTICIPATES_GpPW]-()),\r\n  size(()-[:PARTICIPATES_GpPW]-(n2)),\r\n  size((n2)-[:PARTICIPATES_GpPW]-()),\r\n  size(()-[:PARTICIPATES_GpPW]-(n3)),\r\n  size((n3)-[:ASSOCIATES_DaG]-()),\r\n  size(()-[:ASSOCIATES_DaG]-(n4))\r\n] AS degrees, n3, n4\r\nRETURN\r\n  n4.name AS target_name,\r\n  type(relationships(path)[3]) AS target_edge_type,\r\n  n3.name AS n3_name,\r\n  sum(reduce(pdp = 1.0, d in degrees| pdp * d ^ -0.4)) AS DWPC\r\nORDER BY DWPC DESC</code></pre>\r\n\r\n<p>The top five results are:</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>target_name</th><th>target_edge_type</th><th>n3_name</th><th>DWPC</th></tr></thead><tbody><tr><td>coronary artery disease</td><td>BINDS_CbG</td><td>SLC22A3</td><td>0.00072</td></tr><tr><td>coronary artery disease</td><td>BINDS_CbG</td><td>ACE2</td><td>0.00058</td></tr><tr><td>coronary artery disease</td><td>BINDS_CbG</td><td>REN</td><td>0.00044</td></tr><tr><td>coronary artery disease</td><td>BINDS_CbG</td><td>SLC6A6</td><td>0.00038</td></tr><tr><td>coronary artery disease</td><td>BINDS_CbG</td><td>NR3C2</td><td>0.00025</td></tr></tbody></table>\r\n\r\n<p>These are the top ranking CAD-associated genes that participate in pathways with enalapril targets. As shown by the DWPC column, several of the top target edges are contributing to a similar extent. There is no one CAD-associated gene that is responsible for the bulk of the <em>CbGpPWpGaD</em> DWPC.</p>\r\n\r\n<p>In instances where only one path composes the bulk of the total DWPC, you know that a single relationship is driving the score. For example, we can rewrite the above query to analyze the source edge:</p>\r\n\r\n<pre><code class=\"no-highlight hljs\">MATCH path = (n0:Compound)-[:BINDS_CbG]-(n1)-[:PARTICIPATES_GpPW]-\r\n  (n2)-[:PARTICIPATES_GpPW]-(n3)-[:ASSOCIATES_DaG]-(n4:Disease)\r\nUSING JOIN ON n2\r\nWHERE n0.name = 'Enalapril'\r\n  AND n4.name = 'coronary artery disease'\r\n  AND n1 &lt;&gt; n3\r\nWITH\r\n  path,\r\n[\r\n  size((n0)-[:BINDS_CbG]-()),\r\n  size(()-[:BINDS_CbG]-(n1)),\r\n  size((n1)-[:PARTICIPATES_GpPW]-()),\r\n  size(()-[:PARTICIPATES_GpPW]-(n2)),\r\n  size((n2)-[:PARTICIPATES_GpPW]-()),\r\n  size(()-[:PARTICIPATES_GpPW]-(n3)),\r\n  size((n3)-[:ASSOCIATES_DaG]-()),\r\n  size(()-[:ASSOCIATES_DaG]-(n4))\r\n] AS degrees, n0, n1\r\nRETURN\r\n  n0.name AS source_name,\r\n  type(head(relationships(path))) AS source_edge_type,\r\n  n1.name AS n1_name,\r\n  sum(reduce(pdp = 1.0, d in degrees| pdp * d ^ -0.4)) AS DWPC\r\nORDER BY DWPC DESC</code></pre>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>source_name</th><th>source_edge_type</th><th>n1_name</th><th>DWPC</th></tr></thead><tbody><tr><td>Enalapril</td><td>BINDS_CbG</td><td>ACE</td><td>0.00273</td></tr><tr><td>Enalapril</td><td>BINDS_CbG</td><td>SLCO1A2</td><td>0.00081</td></tr><tr><td>Enalapril</td><td>BINDS_CbG</td><td>ABCB1</td><td>0.00081</td></tr><tr><td>Enalapril</td><td>BINDS_CbG</td><td>SLC22A7</td><td>0.00068</td></tr></tbody></table>\r\n\r\n<p>These results show that enalapril's binding <em>ACE</em> is driving the <em>CbGpPWpGaD</em> DWPC. In other words, if enalapril did not bind <em>ACE</em>, the <em>CbGpPWpGaD</em> DWPC would be ~40% lower (the total <em>CbGpPWpGaD</em> DWPC between enalapril and CAD is 0.00677).</p>",
      "body_md": "# Grouping paths by their source or target edge\r\n\r\nThe [previous comment](#2) discussed grouping paths by an intermediate node and then calculating partial DWPCs. This comment introduces an alternative grouping method: grouping either by the source edge (first edge in the path) or target edge (last edge in the path).\r\n\r\nHere's the intuition behind this approach. In a hetnet, a node derives its meaning from its relationships. For example, our algorithm is based solely on relationships. Therefore, a good way to investigate a prediction is to consider which edges of either the source compound or target disease mattered. We can this for a specific source–target–metapath combination, by grouping paths by their source or target edge.\r\n\r\nFor example, the following query takes the enalapril–CAD example and asks which target edges are composing the _CbGpPWpGaD_ paths.\r\n\r\n```\r\nMATCH path = (n0:Compound)-[:BINDS_CbG]-(n1)-[:PARTICIPATES_GpPW]-\r\n  (n2)-[:PARTICIPATES_GpPW]-(n3)-[:ASSOCIATES_DaG]-(n4:Disease)\r\nUSING JOIN ON n2\r\nWHERE n0.name = 'Enalapril'\r\n  AND n4.name = 'coronary artery disease'\r\n  AND n1 <> n3\r\nWITH\r\n  path,\r\n[\r\n  size((n0)-[:BINDS_CbG]-()),\r\n  size(()-[:BINDS_CbG]-(n1)),\r\n  size((n1)-[:PARTICIPATES_GpPW]-()),\r\n  size(()-[:PARTICIPATES_GpPW]-(n2)),\r\n  size((n2)-[:PARTICIPATES_GpPW]-()),\r\n  size(()-[:PARTICIPATES_GpPW]-(n3)),\r\n  size((n3)-[:ASSOCIATES_DaG]-()),\r\n  size(()-[:ASSOCIATES_DaG]-(n4))\r\n] AS degrees, n3, n4\r\nRETURN\r\n  n4.name AS target_name,\r\n  type(relationships(path)[3]) AS target_edge_type,\r\n  n3.name AS n3_name,\r\n  sum(reduce(pdp = 1.0, d in degrees| pdp * d ^ -0.4)) AS DWPC\r\nORDER BY DWPC DESC\r\n```\r\n\r\nThe top five results are:\r\n\r\n| target_name | target_edge_type | n3_name | DWPC |\r\n|--------------|------------------|---------|-------|\r\n| coronary artery disease | BINDS_CbG | SLC22A3 | 0.00072 |\r\n| coronary artery disease | BINDS_CbG | ACE2 | 0.00058 |\r\n| coronary artery disease | BINDS_CbG | REN | 0.00044 |\r\n| coronary artery disease | BINDS_CbG | SLC6A6 | 0.00038 |\r\n| coronary artery disease | BINDS_CbG | NR3C2 | 0.00025 |\r\n\r\nThese are the top ranking CAD-associated genes that participate in pathways with enalapril targets. As shown by the DWPC column, several of the top target edges are contributing to a similar extent. There is no one CAD-associated gene that is responsible for the bulk of the _CbGpPWpGaD_ DWPC.\r\n\r\nIn instances where only one path composes the bulk of the total DWPC, you know that a single relationship is driving the score. For example, we can rewrite the above query to analyze the source edge:\r\n\r\n```\r\nMATCH path = (n0:Compound)-[:BINDS_CbG]-(n1)-[:PARTICIPATES_GpPW]-\r\n  (n2)-[:PARTICIPATES_GpPW]-(n3)-[:ASSOCIATES_DaG]-(n4:Disease)\r\nUSING JOIN ON n2\r\nWHERE n0.name = 'Enalapril'\r\n  AND n4.name = 'coronary artery disease'\r\n  AND n1 <> n3\r\nWITH\r\n  path,\r\n[\r\n  size((n0)-[:BINDS_CbG]-()),\r\n  size(()-[:BINDS_CbG]-(n1)),\r\n  size((n1)-[:PARTICIPATES_GpPW]-()),\r\n  size(()-[:PARTICIPATES_GpPW]-(n2)),\r\n  size((n2)-[:PARTICIPATES_GpPW]-()),\r\n  size(()-[:PARTICIPATES_GpPW]-(n3)),\r\n  size((n3)-[:ASSOCIATES_DaG]-()),\r\n  size(()-[:ASSOCIATES_DaG]-(n4))\r\n] AS degrees, n0, n1\r\nRETURN\r\n  n0.name AS source_name,\r\n  type(head(relationships(path))) AS source_edge_type,\r\n  n1.name AS n1_name,\r\n  sum(reduce(pdp = 1.0, d in degrees| pdp * d ^ -0.4)) AS DWPC\r\nORDER BY DWPC DESC\r\n```\r\n\r\n| source_name | source_edge_type | n1_name | DWPC |\r\n|-----------|-----------|---------|-----------------------|\r\n| Enalapril | BINDS_CbG | ACE | 0.00273 |\r\n| Enalapril | BINDS_CbG | SLCO1A2 | 0.00081 |\r\n| Enalapril | BINDS_CbG | ABCB1 | 0.00081 |\r\n| Enalapril | BINDS_CbG | SLC22A7 | 0.00068 |\r\n\r\nThese results show that enalapril's binding _ACE_ is driving the _CbGpPWpGaD_ DWPC. In other words, if enalapril did not bind _ACE_, the _CbGpPWpGaD_ DWPC would be ~40% lower (the total _CbGpPWpGaD_ DWPC between enalapril and CAD is 0.00677).",
      "comment_id": 1450,
      "profile_id": 17,
      "published": "2016-12-23T16:29:41.310951Z",
      "thread_id": 228,
      "url": "/discussion/decomposing-the-dwpc-to-assess-intermediate-node-or-edge-contributions/228#3"
    },
    {
      "body_html": "<p>The result of Project Rephetio is <a href=\"https://thinklab.com/discussion/predictions-of-whether-a-compound-treats-a-disease/203\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d203\">predicted probabilities of treatment</a> for 209,168 compound–disease pairs. In addition to providing the predictions, we provide Neo4j browser guides with details for each individual prediction.</p>\r\n\r\n<p>The guides include the following:</p>\r\n\r\n<ul><li>a table of metapaths supporting the prediction</li><li>a table of the top 25 paths supporting the prediction</li><li>a visualization of the top 10 network paths supporting the prediction</li></ul>\r\n\r\n<p>As an example, see the guide for the prediction that <a href=\"https://neo4j.het.io/browser/?cmd=play&amp;arg=https://neo4j.het.io/guides/rep/DB01156/DOID_0050742.html\" title=\"Hetionet v1.0 Neo4j Browser\">bupropion treats nicotine dependence</a> (you've got to click play to show the guide). This discussion will go over how we assign contribution scores to specific metapaths and paths.</p>",
      "body_md": "The result of Project Rephetio is [predicted probabilities of treatment](https://thinklab.com/discussion/predictions-of-whether-a-compound-treats-a-disease/203) for 209,168 compound–disease pairs. In addition to providing the predictions, we provide Neo4j browser guides with details for each individual prediction.\r\n\r\nThe guides include the following:\r\n\r\n+ a table of metapaths supporting the prediction\r\n+ a table of the top 25 paths supporting the prediction\r\n+ a visualization of the top 10 network paths supporting the prediction\r\n\r\nAs an example, see the guide for the prediction that [bupropion treats nicotine dependence](https://neo4j.het.io/browser/?cmd=play&arg=https://neo4j.het.io/guides/rep/DB01156/DOID_0050742.html \"Hetionet v1.0 Neo4j Browser\") (you've got to click play to show the guide). This discussion will go over how we assign contribution scores to specific metapaths and paths.",
      "comment_id": 1451,
      "profile_id": 17,
      "published": "2016-12-21T22:32:28.054612Z",
      "thread_id": 229,
      "url": "/discussion/decomposing-predictions-into-their-network-support/229"
    },
    {
      "body_html": "<h1>Calculating metapath and path contributions</h1>\r\n\r\n<p>The computation of contribution stats for each prediction occurs in <a href=\"https://github.com/dhimmel/learn/blob/0fbb1a533d378da6fbc213682e7b7e11c582aa98/prediction/5-contribution.ipynb\">this notebook</a>. The code is rather gnarly, so I'm going to describe the method by example. Specifically, what specific network evidence do we observe for bupropion treating nicotine dependence, something we've <a href=\"https://thinklab.com/discussion/predictions-of-whether-a-compound-treats-a-disease/203#8\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d203\">discussed before</a>.</p>\r\n\r\n<p>The first step is to compile the list of metapaths that provide support for the prediction. Our <a href=\"https://thinklab.com/discussion/our-hetnet-edge-prediction-methodology-the-modeling-framework-for-project-rephetio/210#4\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d210\">logistic regression model</a> assigned positive coefficients to 12 DWPC features. Going forward, we only consider these 12 metapaths. A metapath is considered to positively contribute if its logistic regression term is positive. The following table shows the process:</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>Metapath</th><th>Path Count</th><th>DWPC</th><th>Transformed DWPC</th><th>Coefficient</th><th>Term</th><th>Contribution</th></tr></thead><tbody><tr><td>CbGaD</td><td>1</td><td>0.0261</td><td>3.859</td><td>0.198</td><td>0.765</td><td>41.26%</td></tr><tr><td>CbGbCtD</td><td>1</td><td>0.0287</td><td>3.201</td><td>0.223</td><td>0.713</td><td>38.48%</td></tr><tr><td>CcSEcCtD</td><td>208</td><td>0.0371</td><td>2.360</td><td>0.081</td><td>0.192</td><td>10.36%</td></tr><tr><td>CbGpPWpGaD</td><td>142</td><td>0.0329</td><td>3.211</td><td>0.055</td><td>0.176</td><td>9.47%</td></tr><tr><td>CbGeAlD</td><td>13</td><td>0.0019</td><td>0.211</td><td>0.037</td><td>0.008</td><td>0.42%</td></tr></tbody></table>\r\n\r\n<p>The table shows that there are 5 metapaths providing positive support. The metapath's Transformed DWPC (which has been <a href=\"https://thinklab.com/discussion/transforming-dwpcs-for-hetnet-edge-prediction/193#6\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d193\">IHS-transformed</a> and standardized) is multiplied by the logistic regression coefficient to compute the Term. Only metapaths with positive terms retrained. So for example, if a specific compound-disease pair has a negative Transformed DWPC, it is not considered to contribute. In reality a lack of paths of the given type is negatively contributing to the prediction — but this effect cannot be decomposed to specific paths, so we ignore it. Finally, all of the terms can be scaled to sum to one, yielding Contribution — the proportion of the total support provided by a specific metapath.</p>\r\n\r\n<p>Once we know the contribution of a metapath, it's easy to calculate the contribution of a specific path, since we know how much each path contributes to the untransformed DWPC. To compute the contribution of a path, we multiply its metapath's contribution by its contribution to that metapath. For the bupropion example, we can calculate the overall contribution of each CbGpPWpGaD path, using the DWPC and Contribution values from the above table:</p>\r\n\r\n<pre><code class=\"no-highlight hljs\">MATCH path = (n0:Compound)-[:BINDS_CbG]-(n1)-[:PARTICIPATES_GpPW]-(n2)-[:PARTICIPATES_GpPW]-(n3)-[:ASSOCIATES_DaG]-(n4:Disease)\r\n  USING JOIN ON n2\r\nWHERE n0.name = 'Bupropion'\r\n  AND n4.name = 'nicotine dependence'\r\n  AND n1 &lt;&gt; n3\r\nWITH\r\n[\r\n  size((n0)-[:BINDS_CbG]-()),\r\n  size(()-[:BINDS_CbG]-(n1)),\r\n  size((n1)-[:PARTICIPATES_GpPW]-()),\r\n  size(()-[:PARTICIPATES_GpPW]-(n2)),\r\n  size((n2)-[:PARTICIPATES_GpPW]-()),\r\n  size(()-[:PARTICIPATES_GpPW]-(n3)),\r\n  size((n3)-[:ASSOCIATES_DaG]-()),\r\n  size(()-[:ASSOCIATES_DaG]-(n4))\r\n] AS degrees, path\r\nWITH\r\n  extract(n in nodes(path)| n.name) AS nodes,\r\n  // Input the untransformed DWPC in the next line\r\n  sum(reduce(pdp = 1.0, d in degrees| pdp * d ^ -0.4)) / 0.03288 AS dwpc_contribution\r\nWITH\r\n  nodes,\r\n  dwpc_contribution, // Contribution of the PDP to the DWPC\r\n  // Input the metapath contribution in the next line\r\n  dwpc_contribution * 0.0947 AS contribution // Contribution of the PDP to the overall prediction\r\nRETURN nodes, dwpc_contribution, contribution\r\nORDER BY contribution DESC</code></pre>\r\n\r\n<p>The contribution values returned by this query equal the values in the path table of the <a href=\"https://neo4j.het.io/browser/?cmd=play&amp;arg=https://neo4j.het.io/guides/rep/DB01156/DOID_0050742.html\">browser guide</a> (copied below).</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>Percent of Prediction</th><th>Percent of DWPC</th><th>Metapath</th><th>Length</th><th>Verbose Path</th></tr></thead><tbody><tr><td>41.30%</td><td>100.00%</td><td>CbGaD</td><td>2</td><td>Bupropion–binds–CHRNA3–associates–nicotine dependence</td></tr><tr><td>38.50%</td><td>100.00%</td><td>CbGbCtD</td><td>3</td><td>Bupropion–binds–CHRNA3–binds–Varenicline–treats–nicotine dependence</td></tr><tr><td>0.52%</td><td>5.47%</td><td>CbGpPWpGaD</td><td>4</td><td>Bupropion–binds–CHRNA3–participates–Nicotine Activity on Chromaffin Cells–participates–CHRNB4–associates–nicotine dependence</td></tr><tr><td>0.41%</td><td>4.35%</td><td>CbGpPWpGaD</td><td>4</td><td>Bupropion–binds–CHRNA3–participates–Highly calcium permeable nicotinic acetylcholine receptors–participates–CHRNB3–associates–nicotine dependence</td></tr></tbody></table>\r\n\r\n<p>One limitation of our approach is that it overlooks paths that contribute to a prediction but correspond to a metapath whose transformed DWPC was negative (which occurs for DWPCs that are below the mean).</p>",
      "body_md": "# Calculating metapath and path contributions\r\n\r\nThe computation of contribution stats for each prediction occurs in [this notebook](https://github.com/dhimmel/learn/blob/0fbb1a533d378da6fbc213682e7b7e11c582aa98/prediction/5-contribution.ipynb). The code is rather gnarly, so I'm going to describe the method by example. Specifically, what specific network evidence do we observe for bupropion treating nicotine dependence, something we've [discussed before](https://thinklab.com/discussion/predictions-of-whether-a-compound-treats-a-disease/203#8).\r\n\r\nThe first step is to compile the list of metapaths that provide support for the prediction. Our [logistic regression model](https://thinklab.com/discussion/our-hetnet-edge-prediction-methodology-the-modeling-framework-for-project-rephetio/210#4) assigned positive coefficients to 12 DWPC features. Going forward, we only consider these 12 metapaths. A metapath is considered to positively contribute if its logistic regression term is positive. The following table shows the process:\r\n\r\n| Metapath | Path Count | DWPC | Transformed DWPC | Coefficient | Term | Contribution |\r\n|------------|------------|--------|------------------|-------------|--------------|------------|\r\n| CbGaD | 1 | 0.0261 | 3.859 | 0.198 | 0.765 | 41.26% |\r\n| CbGbCtD | 1 | 0.0287 | 3.201 | 0.223 | 0.713 | 38.48% |\r\n| CcSEcCtD | 208 | 0.0371 | 2.360 | 0.081 | 0.192 | 10.36% |\r\n| CbGpPWpGaD | 142 | 0.0329 | 3.211 | 0.055 | 0.176 | 9.47% |\r\n| CbGeAlD | 13 | 0.0019 | 0.211 | 0.037 | 0.008 | 0.42% |\r\n\r\nThe table shows that there are 5 metapaths providing positive support. The metapath's Transformed DWPC (which has been [IHS-transformed](https://thinklab.com/discussion/transforming-dwpcs-for-hetnet-edge-prediction/193#6) and standardized) is multiplied by the logistic regression coefficient to compute the Term. Only metapaths with positive terms retrained. So for example, if a specific compound-disease pair has a negative Transformed DWPC, it is not considered to contribute. In reality a lack of paths of the given type is negatively contributing to the prediction -- but this effect cannot be decomposed to specific paths, so we ignore it. Finally, all of the terms can be scaled to sum to one, yielding Contribution -- the proportion of the total support provided by a specific metapath.\r\n\r\nOnce we know the contribution of a metapath, it's easy to calculate the contribution of a specific path, since we know how much each path contributes to the untransformed DWPC. To compute the contribution of a path, we multiply its metapath's contribution by its contribution to that metapath. For the bupropion example, we can calculate the overall contribution of each CbGpPWpGaD path, using the DWPC and Contribution values from the above table:\r\n\r\n```cypher\r\nMATCH path = (n0:Compound)-[:BINDS_CbG]-(n1)-[:PARTICIPATES_GpPW]-(n2)-[:PARTICIPATES_GpPW]-(n3)-[:ASSOCIATES_DaG]-(n4:Disease)\r\n  USING JOIN ON n2\r\nWHERE n0.name = 'Bupropion'\r\n  AND n4.name = 'nicotine dependence'\r\n  AND n1 <> n3\r\nWITH\r\n[\r\n  size((n0)-[:BINDS_CbG]-()),\r\n  size(()-[:BINDS_CbG]-(n1)),\r\n  size((n1)-[:PARTICIPATES_GpPW]-()),\r\n  size(()-[:PARTICIPATES_GpPW]-(n2)),\r\n  size((n2)-[:PARTICIPATES_GpPW]-()),\r\n  size(()-[:PARTICIPATES_GpPW]-(n3)),\r\n  size((n3)-[:ASSOCIATES_DaG]-()),\r\n  size(()-[:ASSOCIATES_DaG]-(n4))\r\n] AS degrees, path\r\nWITH\r\n  extract(n in nodes(path)| n.name) AS nodes,\r\n  // Input the untransformed DWPC in the next line\r\n  sum(reduce(pdp = 1.0, d in degrees| pdp * d ^ -0.4)) / 0.03288 AS dwpc_contribution\r\nWITH\r\n  nodes,\r\n  dwpc_contribution, // Contribution of the PDP to the DWPC\r\n  // Input the metapath contribution in the next line\r\n  dwpc_contribution * 0.0947 AS contribution // Contribution of the PDP to the overall prediction\r\nRETURN nodes, dwpc_contribution, contribution\r\nORDER BY contribution DESC\r\n```\r\n\r\nThe contribution values returned by this query equal the values in the path table of the [browser guide](https://neo4j.het.io/browser/?cmd=play&arg=https://neo4j.het.io/guides/rep/DB01156/DOID_0050742.html) (copied below).\r\n\r\n| Percent of Prediction | Percent of DWPC | Metapath | Length | Verbose Path |\r\n|-----------------------|-----------------|------------|--------|-----------|\r\n| 41.30% | 100.00% | CbGaD | 2 | Bupropion–binds–CHRNA3–associates–nicotine dependence |\r\n| 38.50% | 100.00% | CbGbCtD | 3 | Bupropion–binds–CHRNA3–binds–Varenicline–treats–nicotine dependence |\r\n| 0.52% | 5.47% | CbGpPWpGaD | 4 | Bupropion–binds–CHRNA3–participates–Nicotine Activity on Chromaffin Cells–participates–CHRNB4–associates–nicotine dependence |\r\n| 0.41% | 4.35% | CbGpPWpGaD | 4 | Bupropion–binds–CHRNA3–participates–Highly calcium permeable nicotinic acetylcholine receptors–participates–CHRNB3–associates–nicotine dependence |\r\n\r\nOne limitation of our approach is that it overlooks paths that contribute to a prediction but correspond to a metapath whose transformed DWPC was negative (which occurs for DWPCs that are below the mean).",
      "comment_id": 1452,
      "profile_id": 17,
      "published": "2016-12-21T23:59:00.028255Z",
      "thread_id": 229,
      "url": "/discussion/decomposing-predictions-into-their-network-support/229#2"
    },
    {
      "body_html": "<p>So were most of the metapath (type) counts done using Python instead of Cypher? I wondered if one of the reasons for migrating the network to Neo4j was for improving feature extraction, e.g. metapath counts.</p>",
      "body_md": "So were most of the metapath (type) counts done using Python instead of Cypher? I wondered if one of the reasons for migrating the network to Neo4j was for improving feature extraction, e.g. metapath counts.",
      "comment_id": 1453,
      "profile_id": 315,
      "published": "2016-12-22T07:33:14.090563Z",
      "thread_id": 226,
      "url": "/doc/7/review#32"
    },
    {
      "body_html": "<p>All operations on the metagraph are done in Python, as Neo4j does not have any way to interact with the metagraph. Figure 1, Table 1, and Table 2 are created using the <code>hetio</code> Python package, before the hetnet is imported into Neo4j.</p>\n\n<p>The <a href=\"https://thinklab.com/discussion/using-the-neo4j-graph-database-for-hetnets/112\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d112\">adoption of Neo4j</a> was primarily motivated by the need for immediate network access and a versatile graph query language. Regarding feature extraction, both <code>hetio</code> and Cypher can calculate the DWPC, although the Cypher implementation is more readable. Note that feature extraction (calculating the DWPC for a compound–disease–metapath combination) relies on extracting paths not metapaths.</p>",
      "body_md": "All operations on the metagraph are done in Python, as Neo4j does not have any way to interact with the metagraph. Figure 1, Table 1, and Table 2 are created using the `hetio` Python package, before the hetnet is imported into Neo4j.\n\nThe [adoption of Neo4j](https://thinklab.com/discussion/using-the-neo4j-graph-database-for-hetnets/112) was primarily motivated by the need for immediate network access and a versatile graph query language. Regarding feature extraction, both `hetio` and Cypher can calculate the DWPC, although the Cypher implementation is more readable. Note that feature extraction (calculating the DWPC for a compound--disease--metapath combination) relies on extracting paths not metapaths.",
      "comment_id": 1454,
      "profile_id": 17,
      "published": "2016-12-22T15:45:54.213561Z",
      "thread_id": 226,
      "url": "/doc/7/review#33"
    },
    {
      "body_html": "<p>Typo, it should be: Why are these meta paths different to those in Fig 2B?</p>",
      "body_md": "Typo, it should be: Why are these meta paths different to those in Fig 2B?",
      "comment_id": 1455,
      "profile_id": 315,
      "published": "2016-12-23T01:55:20.619152Z",
      "thread_id": 226,
      "url": "/doc/7/review#34"
    },
    {
      "body_html": "<p><a href=\"#feature_figure\">Figure 2B</a> shows the features selected by the logistic regression model. This table shows metapaths that we think are noteworthy. As we <a href=\"https://thinklab.com/doc/7/review#22\">discuss below</a>, I generally tried to include all metapaths with \"non-negligible positive coefficients\" in this table, since those features play such an important role in our predictions.</p>\n\n<p>Since the logistic regression was minimalist and conservative, it selected only a small subset of the predictive features. Additionally, many predictive features are highly correlated and will therefore be filtered out by the elastic net. Nonetheless these features are interesting because their performance (Δ AUROC) indicates its utility for predicting drug efficacy. See our comments on many of these metapaths <a href=\"https://thinklab.com/doc/7/review#section-41\">in the discussion</a>.</p>",
      "body_md": "[Figure 2B](#feature_figure) shows the features selected by the logistic regression model. This table shows metapaths that we think are noteworthy. As we [discuss below]( https://thinklab.com/doc/7/review#22), I generally tried to include all metapaths with \"non-negligible positive coefficients\" in this table, since those features play such an important role in our predictions.\n\nSince the logistic regression was minimalist and conservative, it selected only a small subset of the predictive features. Additionally, many predictive features are highly correlated and will therefore be filtered out by the elastic net. Nonetheless these features are interesting because their performance (Δ AUROC) indicates its utility for predicting drug efficacy. See our comments on many of these metapaths [in the discussion](https://thinklab.com/doc/7/review#section-41).",
      "comment_id": 1456,
      "profile_id": 17,
      "published": "2016-12-23T14:58:50.192649Z",
      "thread_id": 226,
      "url": "/doc/7/review#35"
    },
    {
      "body_html": "<h1>Calculating source / target edge contributions</h1>\r\n\r\n<p>In <a href=\"https://thinklab.com/discussion/decomposing-the-dwpc-to-assess-intermediate-node-contributions/228\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d228\">another discussion</a> we introduced partial DWPCs, whereby a DWPC is divided into components by grouping paths based on a chosen attribute. The attribute <a href=\"https://thinklab.com/discussion/decomposing-the-dwpc-to-assess-intermediate-node-contributions/228#2\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d228\">could be</a> the node the path traverses at a given position. Or the attribute <a href=\"https://thinklab.com/discussion/decomposing-the-dwpc-to-assess-intermediate-node-contributions/228#3\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d228\">could be</a> the source edge of the path.</p>\r\n\r\n<p>The term partial DWPC applies to computing a DWPC for any source–target–metapath–attribute combination. However, we can use a similar approach of grouping paths and summing their scores for source–target (compound–disease) pairs. For example, we can group all paths contributing to a prediction by their source edge to get the contribution of each source edge.</p>\r\n\r\n<p>For the bupropion–nicotine dependence example, here are the top five contributing source edges:</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>Source Edge</th><th>Percent of Prediction</th><th>Path Count</th><th>Distinct Metapaths</th></tr></thead><tbody><tr><td>Bupropion—binds—CHRNA3</td><td>87.77%</td><td>57</td><td>4</td></tr><tr><td>Bupropion—causes—Terminal insomnia</td><td>0.37%</td><td>1</td><td>1</td></tr><tr><td>Bupropion—causes—Snoring</td><td>0.32%</td><td>1</td><td>1</td></tr><tr><td>Bupropion—binds—CYP2B6</td><td>0.31%</td><td>12</td><td>2</td></tr><tr><td>Bupropion—causes—Middle insomnia</td><td>0.28%</td><td>1</td><td>1</td></tr></tbody></table>\r\n\r\n<p>Notice that the <em>Bupropion—binds—CHRNA3</em> relationship is responsible for bulk of the prediction. This indicates that binding <em>CHRNA3</em> is likely sufficient to give a compound a high nicotine dependence prediction. We can also look at the five contributing target edges:</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>Target Edge</th><th>Percent of Prediction</th><th>Path Count</th><th>Distinct Metapaths</th></tr></thead><tbody><tr><td>nicotine dependence—treats—Varenicline</td><td>48.86%</td><td>209</td><td>2</td></tr><tr><td>nicotine dependence—associates—CHRNA3</td><td>41.31%</td><td>3</td><td>2</td></tr><tr><td>nicotine dependence—associates—CHRNB4</td><td>1.85%</td><td>11</td><td>1</td></tr><tr><td>nicotine dependence—associates—CHRNA6</td><td>1.64%</td><td>10</td><td>1</td></tr><tr><td>nicotine dependence—associates—CHRNB3</td><td>1.52%</td><td>9</td><td>1</td></tr></tbody></table>\r\n\r\n<p>Here we see that the prediction primarily picks up on two aspects of nicotine dependence. First, that its treated by varenicline and second, that it's associated with <em>CHRNA3</em>.</p>\r\n\r\n<p>I'm in the process of adding source/target edge contribution tables to our Neo4j Browser guides with a deployment target of the next 24 hours.</p>",
      "body_md": "# Calculating source / target edge contributions\r\n\r\nIn [another discussion](https://thinklab.com/discussion/decomposing-the-dwpc-to-assess-intermediate-node-contributions/228) we introduced partial DWPCs, whereby a DWPC is divided into components by grouping paths based on a chosen attribute. The attribute [could be](https://thinklab.com/discussion/decomposing-the-dwpc-to-assess-intermediate-node-contributions/228#2) the node the path traverses at a given position. Or the attribute [could be](https://thinklab.com/discussion/decomposing-the-dwpc-to-assess-intermediate-node-contributions/228#3) the source edge of the path.\r\n\r\nThe term partial DWPC applies to computing a DWPC for any source–target–metapath–attribute combination. However, we can use a similar approach of grouping paths and summing their scores for source–target (compound–disease) pairs. For example, we can group all paths contributing to a prediction by their source edge to get the contribution of each source edge.\r\n\r\nFor the bupropion--nicotine dependence example, here are the top five contributing source edges:\r\n\r\n| Source Edge | Percent of Prediction | Path Count | Distinct Metapaths |\r\n|-------------|-----------------------|------------|--------------------|\r\n| Bupropion—binds—CHRNA3 | 87.77% | 57 | 4 |\r\n| Bupropion—causes—Terminal insomnia | 0.37% | 1 | 1 |\r\n| Bupropion—causes—Snoring | 0.32% | 1 | 1 |\r\n| Bupropion—binds—CYP2B6 | 0.31% | 12 | 2 |\r\n| Bupropion—causes—Middle insomnia | 0.28% | 1 | 1 |\r\n\r\nNotice that the _Bupropion—binds—CHRNA3_ relationship is responsible for bulk of the prediction. This indicates that binding _CHRNA3_ is likely sufficient to give a compound a high nicotine dependence prediction. We can also look at the five contributing target edges:\r\n\r\n| Target Edge | Percent of Prediction | Path Count | Distinct Metapaths |\r\n|---------|------------|------------|--------------------|\r\n| nicotine dependence—treats—Varenicline | 48.86% | 209 | 2 |\r\n| nicotine dependence—associates—CHRNA3 | 41.31% | 3 | 2 |\r\n| nicotine dependence—associates—CHRNB4 | 1.85% | 11 | 1 |\r\n| nicotine dependence—associates—CHRNA6 | 1.64% | 10 | 1 |\r\n| nicotine dependence—associates—CHRNB3 | 1.52% | 9 | 1 |\r\n\r\nHere we see that the prediction primarily picks up on two aspects of nicotine dependence. First, that its treated by varenicline and second, that it's associated with _CHRNA3_.\r\n\r\nI'm in the process of adding source/target edge contribution tables to our Neo4j Browser guides with a deployment target of the next 24 hours.",
      "comment_id": 1457,
      "profile_id": 17,
      "published": "2016-12-23T17:12:31.052626Z",
      "thread_id": 229,
      "url": "/discussion/decomposing-predictions-into-their-network-support/229#3"
    },
    {
      "body_html": "<h1>Source/target edge contributions in epilepsy predictions</h1>\r\n\r\n<p>We've recently developed a new way to assess which nodes or relationships are contributing to a specific prediction. <a href=\"/u/pouyakhankhanian\" class=\"username\">@pouyakhankhanian</a> <a href=\"https://thinklab.com/discussion/decomposing-the-dwpc-to-assess-intermediate-node-contributions/228#note-297\">mentioned</a>:</p>\r\n\r\n<blockquote><p>I'd love to see the weight given to various nodes in the top predictions for epilepsy, especially the ones in the top 100 which were not classified as AEDs.</p></blockquote>\r\n\r\n<p>For each prediction, <a href=\"https://thinklab.com/discussion/decomposing-predictions-into-their-network-support/229#3\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d229\">we calculated</a> source / target edge contributions and deployed them as tables in our Neo4j Browser guides. Here we will evaluate which source edges contributed to the <a href=\"#5\">100 top epilepsy predictions</a>. To do this, we summed source edge contributions across the 100 predictions, replacing the specific source compound with the generic \"Compound\" (<a href=\"https://github.com/dhimmel/rephetio/blob/c80cdae446d51d1368f83c7bffff5c94780afc58/epilepsy/partial-DWPC.ipynb\">notebook</a>, <a href=\"https://github.com/dhimmel/rephetio/blob/c80cdae446d51d1368f83c7bffff5c94780afc58/epilepsy/data/source-edge-contributions.tsv\">dataset</a>).</p>\r\n\r\n<p>In total, 1,667 source edges contributed to the predictions. Here are the top 10:</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>Relationship</th><th>PC</th><th>Contribution</th></tr></thead><tbody><tr><td>Compound—includes—Decreased Central Nervous System Disorganized Electrical Activity</td><td>238</td><td>6.34</td></tr><tr><td>Compound—includes—Benzodiazepines</td><td>52</td><td>3.84</td></tr><tr><td>Compound—binds—GABRA1</td><td>12,385</td><td>2.82</td></tr><tr><td>Compound—resembles—Diazepam</td><td>402</td><td>2.71</td></tr><tr><td>Compound—includes—General Anesthesia</td><td>6</td><td>2.46</td></tr><tr><td>Compound—binds—GABRG2</td><td>8,522</td><td>2.40</td></tr><tr><td>Compound—palliates—multiple sclerosis</td><td>84</td><td>2.16</td></tr><tr><td>Compound—resembles—Amobarbital</td><td>87</td><td>2.13</td></tr><tr><td>Compound—resembles—Clobazam</td><td>227</td><td>2.13</td></tr></tbody></table>\r\n\r\n<p>The top edge (<em>Compound—includes—Decreased Central Nervous System Disorganized Electrical Activity</em>) represents a pharmacologic class which overlaps with the indication of epilepsy. We attempted to <a href=\"https://thinklab.com/discussion/incorporating-drugcentral-data-in-our-network/186#4\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d186\">avoid including such pharmacologic classes</a>, but our solution was imperfect. Nonetheless, this edge is only responsible for 6% of the top 100 epilepsy predictions. Overall, the predictions drew on a multitude of edges: 22 source edges each contributed over 1%, while 166 contributed over 0.1%. </p>\r\n\r\n<p>We also computed the contribution of each target edge to the top epilepsy predictions (<a href=\"https://github.com/dhimmel/rephetio/blob/c80cdae446d51d1368f83c7bffff5c94780afc58/epilepsy/data/target-edge-contributions.tsv\">dataset</a>).<br>In Hetionet v1.0, epilepsy has 531 relationships, of which 375 contributed to at least one prediction. Wanted to get the data up here — a more detailed analysis will follow.</p>",
      "body_md": "# Source/target edge contributions in epilepsy predictions\r\n\r\nWe've recently developed a new way to assess which nodes or relationships are contributing to a specific prediction. @pouyakhankhanian [mentioned](https://thinklab.com/discussion/decomposing-the-dwpc-to-assess-intermediate-node-contributions/228#note-297):\r\n\r\n> I'd love to see the weight given to various nodes in the top predictions for epilepsy, especially the ones in the top 100 which were not classified as AEDs.\r\n\r\nFor each prediction, [we calculated](https://thinklab.com/discussion/decomposing-predictions-into-their-network-support/229#3) source / target edge contributions and deployed them as tables in our Neo4j Browser guides. Here we will evaluate which source edges contributed to the [100 top epilepsy predictions](#5). To do this, we summed source edge contributions across the 100 predictions, replacing the specific source compound with the generic \"Compound\" ([notebook](https://github.com/dhimmel/rephetio/blob/c80cdae446d51d1368f83c7bffff5c94780afc58/epilepsy/partial-DWPC.ipynb), [dataset](https://github.com/dhimmel/rephetio/blob/c80cdae446d51d1368f83c7bffff5c94780afc58/epilepsy/data/source-edge-contributions.tsv)).\r\n\r\nIn total, 1,667 source edges contributed to the predictions. Here are the top 10:\r\n\r\n| Relationship | PC | Contribution |\r\n|-----------------|-------|--------------------|\r\n| Compound—includes—Decreased Central Nervous System Disorganized Electrical Activity | 238 | 6.34 |\r\n| Compound—includes—Benzodiazepines | 52 | 3.84 |\r\n| Compound—binds—GABRA1 | 12,385 | 2.82 |\r\n| Compound—resembles—Diazepam | 402 | 2.71 |\r\n| Compound—includes—General Anesthesia | 6 | 2.46 |\r\n| Compound—binds—GABRG2 | 8,522 | 2.40 |\r\n| Compound—palliates—multiple sclerosis | 84 | 2.16 |\r\n| Compound—resembles—Amobarbital | 87 | 2.13 |\r\n| Compound—resembles—Clobazam | 227 | 2.13 |\r\n\r\nThe top edge (_Compound—includes—Decreased Central Nervous System Disorganized Electrical Activity_) represents a pharmacologic class which overlaps with the indication of epilepsy. We attempted to [avoid including such pharmacologic classes](https://thinklab.com/discussion/incorporating-drugcentral-data-in-our-network/186#4), but our solution was imperfect. Nonetheless, this edge is only responsible for 6% of the top 100 epilepsy predictions. Overall, the predictions drew on a multitude of edges: 22 source edges each contributed over 1%, while 166 contributed over 0.1%. \r\n\r\nWe also computed the contribution of each target edge to the top epilepsy predictions ([dataset](https://github.com/dhimmel/rephetio/blob/c80cdae446d51d1368f83c7bffff5c94780afc58/epilepsy/data/target-edge-contributions.tsv)).\r\nIn Hetionet v1.0, epilepsy has 531 relationships, of which 375 contributed to at least one prediction. Wanted to get the data up here -- a more detailed analysis will follow.",
      "comment_id": 1458,
      "profile_id": 17,
      "published": "2017-01-03T21:13:11.685475Z",
      "thread_id": 224,
      "url": "/discussion/prediction-in-epilepsy/224#8"
    },
    {
      "body_html": "<p>How did you separate the dataset into train and test data? Since it has imbalanced labels, the way of data selection seems critical to the performance.</p>",
      "body_md": "How did you separate the dataset into train and test data? Since it has imbalanced labels, the way of data selection seems critical to the performance.",
      "comment_id": 1459,
      "profile_id": 319,
      "published": "2017-01-02T08:01:48.053367Z",
      "thread_id": 226,
      "url": "/doc/7/review#36"
    },
    {
      "body_html": "<p>We didn't use the training / testing language in the report, since our approach is slightly more complicated. However, in our case \"testing performance\" would refer to performance on any indication set whose positives or negatives do not include any <em>treats</em> or <em>palliates</em> relationships in Hetionet v1.0. Of the <a href=\"#section-87\">indication sets</a> we compiled, <strong>DrugCentral</strong> and <strong>Clinical Trial</strong> meet this criterion. Hence, we call them \"external validation sets\".</p>\n\n<p>In <a href=\"#performance_figure\">Figure 3A</a>, look at the number of positives and negatives in the y-axis labels. <strong>Disease Modifying</strong>, the  \"training set\", includes 755 positives and 208,413 negatives, which together make up all 209,168 possible compound–disease pairs. <strong>Symptomatic</strong>, whose positives are <em>palliates</em> relationships in Hetionet v1.0, splits the 208,413 observations into 390 positives and 208,023 negatives. Hence, the two \"testing sets\" both have 208,023 observations. In other words, their positives were negatives in the \"training set\".</p>\n\n<p>Now a few points that are worth considering.</p>\n\n<ol><li><p>We used a conservative cross-validation approach to minimize overfitting (by adopting the \"one-standard-error\" rule <span class=\"citation\">[<a href=\"https://doi.org/10.18637/jss.v033.i01\" class=\"citation hm \" data-key=\"10.18637/jss.v033.i01\">1</a>]</span> to identify the optimal regularization strength (λ in <code>glmnet</code>). However, overfitting on the \"training set\" could still occur for complicated reasons <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d215\" class=\"citation hm citation-self\" data-key=\"10.15363/thinklab.d215\">2</a>, <a href=\"https://doi.org/10.15363/thinklab.d194\" class=\"citation hm citation-self\" data-key=\"10.15363/thinklab.d194\">3</a>]</span>.</p></li><li><p>We only fit our model on the 29,799 observations with a <a href=\"#section-84\">nonzero prior</a> <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d201\" class=\"citation hm citation-self\" data-key=\"10.15363/thinklab.d201\">4</a>, <a href=\"https://doi.org/10.15363/thinklab.d210\" class=\"citation hm citation-self\" data-key=\"10.15363/thinklab.d210\">5</a>]</span>. Therefore, many negatives in our \"training set\" were not actually used to fit the model. However, these zero prior negatives are included when evaluating performance, since we're able to make predictions for all observations by setting a uniform prior (corresponding to a null probability of treatment of 0.36%).</p></li><li><p>We primarily use AUROC to evaluate performance, which is not affected by dataset balance. The AUPRC is affected however, which can be seen in Figure 3C: <strong>Clinical Trials</strong> has the lowest AUROC, but second highest AUPRC, since it contains so many positives.</p></li></ol>\n\n<p><a href=\"/u/hanockkwak\" class=\"username\">@hanockkwak</a>, does that answer your question?</p>",
      "body_md": "We didn't use the training / testing language in the report, since our approach is slightly more complicated. However, in our case \"testing performance\" would refer to performance on any indication set whose positives or negatives do not include any _treats_ or _palliates_ relationships in Hetionet v1.0. Of the [indication sets](#section-87) we compiled, **DrugCentral** and **Clinical Trial** meet this criterion. Hence, we call them \"external validation sets\".\n\nIn [Figure 3A](#performance_figure), look at the number of positives and negatives in the y-axis labels. **Disease Modifying**, the  \"training set\", includes 755 positives and 208,413 negatives, which together make up all 209,168 possible compound–disease pairs. **Symptomatic**, whose positives are _palliates_ relationships in Hetionet v1.0, splits the 208,413 observations into 390 positives and 208,023 negatives. Hence, the two \"testing sets\" both have 208,023 observations. In other words, their positives were negatives in the \"training set\".\n\nNow a few points that are worth considering.\n\n1. We used a conservative cross-validation approach to minimize overfitting (by adopting the \"one-standard-error\" rule [@10.18637/jss.v033.i01] to identify the optimal regularization strength (λ in `glmnet`). However, overfitting on the \"training set\" could still occur for complicated reasons [@10.15363/thinklab.d215 @10.15363/thinklab.d194].\n\n2. We only fit our model on the 29,799 observations with a [nonzero prior](#section-84) [@10.15363/thinklab.d201 @10.15363/thinklab.d210]. Therefore, many negatives in our \"training set\" were not actually used to fit the model. However, these zero prior negatives are included when evaluating performance, since we're able to make predictions for all observations by setting a uniform prior (corresponding to a null probability of treatment of 0.36%).\n\n3. We primarily use AUROC to evaluate performance, which is not affected by dataset balance. The AUPRC is affected however, which can be seen in Figure 3C: **Clinical Trials** has the lowest AUROC, but second highest AUPRC, since it contains so many positives.\n\n@hanockkwak, does that answer your question?",
      "comment_id": 1460,
      "profile_id": 17,
      "published": "2017-01-03T19:40:26.228761Z",
      "thread_id": 226,
      "url": "/doc/7/review#37"
    },
    {
      "body_html": "<p>Hi <a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a> this is really exciting!  Thoughts (some others also in the issues discussion of your repo):</p>\r\n\r\n<ul><li><p>Is <em>compound</em> functionally too different from chemical?  We have tags for chemical and disease in Snorkel format already, for PubMed abstracts via <a href=\"https://www.ncbi.nlm.nih.gov/CBBresearch/Lu/Demo/PubTator/\">PubTator</a>.  If compound is different, we also have / are working on tools for building custom entity taggers for this, but it's just another step that would have to be tackled</p></li><li><p>I definitely agree with <a href=\"/u/b_good\" class=\"username\">@b_good</a>'s general sentiment of starting with simpler relation types, although don't have a lot of intuition for which are more tractable.  Easy things to check off when selecting extraction schema:</p><ul><li>Make sure that the relation type is well defined / unambiguous enough that you can cleanly annotate some example yourself</li><li>Test some simple baseline methods (e.g. a regex or two) to make sure it's not too simple / general (if it is, maybe the regex is good enough, and no need for Snorkel; or maybe this is good cue to jump to the more specific, complex relation type you actually care about!)</li></ul></li><li><p><a href=\"/u/b_good\" class=\"username\">@b_good</a> that resource looks really cool, thanks for sharing!</p></li></ul>\r\n\r\n<p>We're trying to wrap up a bunch of dev stuff that's been scattered about over last month or so, hoping to push something to dev and master in next 1-2 weeks, stay tuned!</p>\r\n\r\n<p>Thanks,<br>Alex</p>",
      "body_md": "Hi @dhimmel this is really exciting!  Thoughts (some others also in the issues discussion of your repo):\r\n\r\n* Is *compound* functionally too different from chemical?  We have tags for chemical and disease in Snorkel format already, for PubMed abstracts via [PubTator](https://www.ncbi.nlm.nih.gov/CBBresearch/Lu/Demo/PubTator/).  If compound is different, we also have / are working on tools for building custom entity taggers for this, but it's just another step that would have to be tackled\r\n\r\n* I definitely agree with @b_good's general sentiment of starting with simpler relation types, although don't have a lot of intuition for which are more tractable.  Easy things to check off when selecting extraction schema:\r\n  - Make sure that the relation type is well defined / unambiguous enough that you can cleanly annotate some example yourself\r\n  - Test some simple baseline methods (e.g. a regex or two) to make sure it's not too simple / general (if it is, maybe the regex is good enough, and no need for Snorkel; or maybe this is good cue to jump to the more specific, complex relation type you actually care about!)\r\n\r\n* @b_good that resource looks really cool, thanks for sharing!\r\n\r\nWe're trying to wrap up a bunch of dev stuff that's been scattered about over last month or so, hoping to push something to dev and master in next 1-2 weeks, stay tuned!\r\n\r\nThanks,\r\nAlex",
      "comment_id": 1461,
      "profile_id": 313,
      "published": "2017-01-07T20:22:25.448770Z",
      "thread_id": 227,
      "url": "/discussion/brainstorming-future-directions-for-hetionet/227#11"
    },
    {
      "body_html": "<p>Unfortunately unicode <a href=\"https://en.wikipedia.org/wiki/Unicode_subscripts_and_superscripts\">doesn't currently</a> contain a subscript capital letter A. However, \"GABAᴀ\" may be better than \"GABAᴬ\" as a unicode representation for the GABA alpha receptor. The <a href=\"http://www.fileformat.info/info/unicode/char/1d00/index.htm\">small capital A</a> more closely imitates a subscript A.</p>",
      "body_md": "Unfortunately unicode [doesn't currently](https://en.wikipedia.org/wiki/Unicode_subscripts_and_superscripts) contain a subscript capital letter A. However, \"GABAᴀ\" may be better than \"GABAᴬ\" as a unicode representation for the GABA alpha receptor. The [small capital A](http://www.fileformat.info/info/unicode/char/1d00/index.htm) more closely imitates a subscript A.",
      "comment_id": 1463,
      "profile_id": 17,
      "published": "2017-01-08T17:54:47.796040Z",
      "thread_id": 226,
      "url": "/doc/7/review#38"
    },
    {
      "body_html": "<h1>Chemical similarities between of the top epilepsy predictions</h1>\r\n\r\n<p>Hetionet v1.0 includes a <em>Compound–resembles–Compound</em> relationship based on <a href=\"https://thinklab.com/discussion/calculating-molecular-similarities-between-drugbank-compounds/70\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d70\">chemical similarity</a>. Resembles relationships were included for compounds with a Dice coefficient ≥ 0.5 <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.a7\" class=\"citation hm citation-self\" data-key=\"10.15363/thinklab.a7\">1</a>]</span>.</p>\r\n\r\n<p>We can use the Hetionet Browser at <a href=\"https://neo4j.het.io\">https://neo4j.het.io</a> to visualize the chemical similarity between the top epilepsy predictions. First, set a Cypher parameter for <code>epilepsy_predictions</code> by executing:</p>\r\n\r\n<pre><code class=\"no-highlight hljs\">:param epilepsy_predictions: ['Topiramate', 'Ethotoin', 'Quazepam', 'Alprazolam', 'Primidone', 'Lorazepam', 'Gabapentin', 'Diazepam', 'Methsuximide', 'Estazolam', 'Valproic Acid', 'Triazolam', 'Oxazepam', 'Temazepam', 'Phenytoin', 'Clorazepate', 'Clonazepam', 'Oxcarbazepine', 'Carbamazepine', 'Midazolam', 'Flurazepam', 'Tiagabine', 'Felbamate', 'Chlordiazepoxide', 'Amitriptyline', 'Lacosamide', 'Fosphenytoin', 'Lamotrigine', 'Clobazam', 'Pentobarbital', 'Butabarbital', 'Secobarbital', 'Bromazepam', 'Zonisamide', 'Levetiracetam', 'Talbutal', 'Methylphenobarbital', 'Heptabarbital', 'Nitrazepam', 'Butethal', 'Clotiazepam', 'Fospropofol', 'Sevoflurane', 'Aprobarbital', 'Thiopental', 'Halazepam', 'Phenobarbital', 'Desflurane', 'Fludiazepam', 'Amobarbital', 'Butalbital', 'Prazepam', 'Thiamylal', 'Cinolazepam', 'Glutethimide', 'Isoflurane', 'Adinazolam', 'Quinidine', 'Flunitrazepam', 'Clozapine', 'Ethosuximide', 'Trimethadione', 'Ketamine', 'Imipramine', 'Methazolamide', 'Ketazolam', 'Etomidate', 'Nortriptyline', 'Clomipramine', 'Acetazolamide', 'Enflurane', 'Modafinil', 'Phensuximide', 'Paramethadione', 'Verapamil', 'Chlorthalidone', 'Indapamide', 'Antipyrine', 'Cyproheptadine', 'Isocarboxazid', 'Bortezomib', 'Phenelzine', 'Diclofenamide', 'Pregabalin', 'Hexobarbital', 'Loxapine', 'Dalfampridine', 'Phenazopyridine', 'Zopiclone', 'Ranolazine', 'Amoxapine', 'Baclofen', 'Phenacemide', 'Eszopiclone', 'Desipramine', 'Dabrafenib', 'Rufinamide', 'Memantine', 'Zolpidem', 'Acamprosate']</code></pre>\r\n\r\n<p>To see the network: run the following  (with auto-complete turned on):</p>\r\n\r\n<pre><code class=\"no-highlight hljs\">MATCH (c:Compound)\r\nWHERE c.name in $epilepsy_predictions\r\nRETURN c</code></pre>\r\n\r\n<p><img src=\"https://cloud.githubusercontent.com/assets/1117703/21754174/c5ceafc6-d5c8-11e6-85da-111d94ec5525.png\" alt=\"epilepsy-prediction-resemblance\" title=\"Chemical similarity network of Project Rephetio top epilepsy predictions\"></p>\r\n\r\n<p>And to get a table with the number of similar epilepsy predictions for each compound, run:</p>\r\n\r\n<pre><code class=\"no-highlight hljs\">MATCH (c0:Compound)-[rel:RESEMBLES_CrC]-(c1:Compound)\r\nWHERE c0.name in $epilepsy_predictions AND c1.name in $epilepsy_predictions\r\nRETURN c0.name AS compound_name, count(rel) AS n_similar_compounds\r\nORDER BY n_similar_compounds DESC, compound_name</code></pre>\r\n\r\n<p>This analysis shows that our top epilepsy predictions include many structurally similar compounds as well as many structurally dissimilar compounds. 29 of the 100 compounds resemble diazepam. Indeed, the benzodiazepines form the largest strongly connected component. The second largest strongly connected component appears to consist of barbiturates, such as phenobarbital which has 14 similar compounds. Halogenated ethers (e.g. enflurane) form a disjoint connected component.</p>\r\n\r\n<p>In total, 75 of the 100 compounds resemble at least one other compound. The median number of similar compounds was 6. Finally, 40 compounds had 2 or fewer similar compounds. This analysis shows our top epilepsy predictions pick up clusters of similar compounds, but not to the exclusion of dissimilar compounds.</p>",
      "body_md": "# Chemical similarities between of the top epilepsy predictions\r\n\r\nHetionet v1.0 includes a _Compound--resembles--Compound_ relationship based on [chemical similarity](https://thinklab.com/discussion/calculating-molecular-similarities-between-drugbank-compounds/70). Resembles relationships were included for compounds with a Dice coefficient ≥ 0.5 [@10.15363/thinklab.a7].\r\n\r\nWe can use the Hetionet Browser at https://neo4j.het.io to visualize the chemical similarity between the top epilepsy predictions. First, set a Cypher parameter for `epilepsy_predictions` by executing:\r\n\r\n```cypher\r\n:param epilepsy_predictions: ['Topiramate', 'Ethotoin', 'Quazepam', 'Alprazolam', 'Primidone', 'Lorazepam', 'Gabapentin', 'Diazepam', 'Methsuximide', 'Estazolam', 'Valproic Acid', 'Triazolam', 'Oxazepam', 'Temazepam', 'Phenytoin', 'Clorazepate', 'Clonazepam', 'Oxcarbazepine', 'Carbamazepine', 'Midazolam', 'Flurazepam', 'Tiagabine', 'Felbamate', 'Chlordiazepoxide', 'Amitriptyline', 'Lacosamide', 'Fosphenytoin', 'Lamotrigine', 'Clobazam', 'Pentobarbital', 'Butabarbital', 'Secobarbital', 'Bromazepam', 'Zonisamide', 'Levetiracetam', 'Talbutal', 'Methylphenobarbital', 'Heptabarbital', 'Nitrazepam', 'Butethal', 'Clotiazepam', 'Fospropofol', 'Sevoflurane', 'Aprobarbital', 'Thiopental', 'Halazepam', 'Phenobarbital', 'Desflurane', 'Fludiazepam', 'Amobarbital', 'Butalbital', 'Prazepam', 'Thiamylal', 'Cinolazepam', 'Glutethimide', 'Isoflurane', 'Adinazolam', 'Quinidine', 'Flunitrazepam', 'Clozapine', 'Ethosuximide', 'Trimethadione', 'Ketamine', 'Imipramine', 'Methazolamide', 'Ketazolam', 'Etomidate', 'Nortriptyline', 'Clomipramine', 'Acetazolamide', 'Enflurane', 'Modafinil', 'Phensuximide', 'Paramethadione', 'Verapamil', 'Chlorthalidone', 'Indapamide', 'Antipyrine', 'Cyproheptadine', 'Isocarboxazid', 'Bortezomib', 'Phenelzine', 'Diclofenamide', 'Pregabalin', 'Hexobarbital', 'Loxapine', 'Dalfampridine', 'Phenazopyridine', 'Zopiclone', 'Ranolazine', 'Amoxapine', 'Baclofen', 'Phenacemide', 'Eszopiclone', 'Desipramine', 'Dabrafenib', 'Rufinamide', 'Memantine', 'Zolpidem', 'Acamprosate']\r\n```\r\n\r\nTo see the network: run the following  (with auto-complete turned on):\r\n\r\n```cypher\r\nMATCH (c:Compound)\r\nWHERE c.name in $epilepsy_predictions\r\nRETURN c\r\n```\r\n\r\n![epilepsy-prediction-resemblance](https://cloud.githubusercontent.com/assets/1117703/21754174/c5ceafc6-d5c8-11e6-85da-111d94ec5525.png \"Chemical similarity network of Project Rephetio top epilepsy predictions\")\r\n\r\nAnd to get a table with the number of similar epilepsy predictions for each compound, run:\r\n\r\n```cypher\r\nMATCH (c0:Compound)-[rel:RESEMBLES_CrC]-(c1:Compound)\r\nWHERE c0.name in $epilepsy_predictions AND c1.name in $epilepsy_predictions\r\nRETURN c0.name AS compound_name, count(rel) AS n_similar_compounds\r\nORDER BY n_similar_compounds DESC, compound_name\r\n```\r\n\r\nThis analysis shows that our top epilepsy predictions include many structurally similar compounds as well as many structurally dissimilar compounds. 29 of the 100 compounds resemble diazepam. Indeed, the benzodiazepines form the largest strongly connected component. The second largest strongly connected component appears to consist of barbiturates, such as phenobarbital which has 14 similar compounds. Halogenated ethers (e.g. enflurane) form a disjoint connected component.\r\n\r\nIn total, 75 of the 100 compounds resemble at least one other compound. The median number of similar compounds was 6. Finally, 40 compounds had 2 or fewer similar compounds. This analysis shows our top epilepsy predictions pick up clusters of similar compounds, but not to the exclusion of dissimilar compounds.",
      "comment_id": 1464,
      "profile_id": 17,
      "published": "2017-01-08T23:11:41.200175Z",
      "thread_id": 224,
      "url": "/discussion/prediction-in-epilepsy/224#9"
    },
    {
      "body_html": "<h1>Categorizing the top epilepsy predictions</h1>\r\n\r\n<p>This post will investigate the categories of compounds in the top 100 epilepsy predictions. For this analysis (<a href=\"https://github.com/dhimmel/rephetio/blob/898ba3e8dec371af168af14ed316c9a9e49f32bc/epilepsy/3.contribution.ipynb\">notebook</a>), We'll use three categorizations of compounds: DrugBank categories, third-level ATC Codes, and DrugCentral pharmacologic classes.</p>\r\n\r\n<h2>DrugBank categories</h2>\r\n\r\n<p>DrugBank annotates compounds with <a href=\"https://www.drugbank.ca/categories\">categories</a> \"based on pharmacological action\" <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkt1068\" class=\"citation hm \" data-key=\"10.1093/nar/gkt1068\">1</a>]</span>. Compounds can have zero or more categories. 84 of the 100 compounds had at least one annotated category. The top eight categories are shown below (<a href=\"https://github.com/dhimmel/rephetio/blob/898ba3e8dec371af168af14ed316c9a9e49f32bc/epilepsy/data/compounds-categories.tsv\">full table here</a>):</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>Category</th><th>Count</th><th>Compounds (in the top epilepsy predictions)</th></tr></thead><tbody><tr><td>Anticonvulsants</td><td>28</td><td>Acetazolamide, Carbamazepine, Clobazam, Clonazepam, Diazepam, Ethosuximide, Ethotoin, Felbamate, Fosphenytoin, Gabapentin, Lacosamide, Lamotrigine, Levetiracetam, Methsuximide, Methylphenobarbital, Nitrazepam, Oxcarbazepine, Phenobarbital, Phensuximide, Phenytoin, Pregabalin, Primidone, Thiopental, Tiagabine, Topiramate, Trimethadione, Valproic Acid, Zonisamide</td></tr><tr><td>Hypnotics and Sedatives</td><td>24</td><td>Alprazolam, Butabarbital, Butethal, Chlordiazepoxide, Cinolazepam, Diazepam, Eszopiclone, Etomidate, Fospropofol, Glutethimide, Halazepam, Hexobarbital, Lorazepam, Methylphenobarbital, Midazolam, Nitrazepam, Oxazepam, Pentobarbital, Phenobarbital, Quazepam, Secobarbital, Thiopental, Zolpidem, Zopiclone</td></tr><tr><td>GABA Modulators</td><td>17</td><td>Alprazolam, Bromazepam, Chlordiazepoxide, Clonazepam, Diazepam, Flunitrazepam, Hexobarbital, Methylphenobarbital, Midazolam, Nitrazepam, Oxazepam, Pentobarbital, Phenobarbital, Prazepam, Secobarbital, Thiopental, Triazolam</td></tr><tr><td>Benzodiazepines</td><td>15</td><td>Alprazolam, Bromazepam, Chlordiazepoxide, Cinolazepam, Clobazam, Clonazepam, Clotiazepam, Fludiazepam, Flunitrazepam, Halazepam, Ketazolam, Lorazepam, Quazepam, Temazepam, Triazolam</td></tr><tr><td>Anti-Anxiety Agents</td><td>12</td><td>Alprazolam, Bromazepam, Chlordiazepoxide, Diazepam, Flunitrazepam, Gabapentin, Halazepam, Midazolam, Nitrazepam, Oxazepam, Prazepam, Triazolam</td></tr><tr><td>Barbiturates</td><td>7</td><td>Butabarbital, Butethal, Heptabarbital, Hexobarbital, Pentobarbital, Primidone, Secobarbital</td></tr><tr><td>Antidepressive Agents</td><td>6</td><td>Adinazolam, Desipramine, Isocarboxazid, Lamotrigine, Nortriptyline, Phenelzine</td></tr><tr><td>Adjuvants, Anesthesia</td><td>6</td><td>Chlordiazepoxide, Diazepam, Midazolam, Pentobarbital, Secobarbital, Triazolam</td></tr></tbody></table>\r\n\r\n<p>In total, the 100 epilepsy predictions covered 64 DrugBank compounds. Less common categories included stimulants (modafinil), vasodilators (verapamil), potassium channel blockers (dalfampridine), and antipruritics (cyproheptadine).</p>\r\n\r\n<h2>Third-level ATC Codes</h2>\r\n\r\n<p>The Anatomical Therapeutic Chemical (ATC) Classification System is a classification of drugs produced by the WHOCC <span class=\"citation\">[<a href=\"https://doi.org/10.4135/9781483349985.n37\" class=\"citation hm \" data-key=\"10.4135/9781483349985.n37\">2</a>]</span>. The third-level indicates a therapeutic/pharmacological subgroup. DrugBank compounds are annotated with zero or more ATC codes. 91 of the 100 compounds had at least 1 ATC code. Together, the predictions included 26 third-level ATC codes.</p>\r\n\r\n<p>See the <a href=\"https://github.com/dhimmel/rephetio/blob/898ba3e8dec371af168af14ed316c9a9e49f32bc/epilepsy/data/compounds-third-level-atc-codes.tsv\">full table here</a>. The most common codes in the 100 predictions were antiepileptics (25 compounds), hypnotics and sedatives (21 compounds), anxiolytics (12 compounds), \"anesthetics, general\" (8 compounds), antidepressants (8 compounds), and antiglaucoma preparations and miotics (3 compounds). Less common codes included antiarrhythmics (quinidine), urologicals (phenazopyridine), and antiinfectives (primidone).</p>\r\n\r\n<h2>DrugCentral Pharmacologic Classes</h2>\r\n\r\n<p>DrugCentral contains pharmacologic classes of six types (Chemical/Ingredient, Mechanism of Action, Physiologic Effect, Established Pharmacologic Class, Pharmacological Action, Application) from 3 publicly-available source (FDA, MeSH, and ChEBI) <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkw993\" class=\"citation hm \" data-key=\"10.1093/nar/gkw993\">3</a>, <a href=\"https://doi.org/10.15363/thinklab.d186\" class=\"citation hm citation-self\" data-key=\"10.15363/thinklab.d186\">4</a>]</span>. We included <a href=\"https://thinklab.com/discussion/incorporating-drugcentral-data-in-our-network/186#4\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d186\">three of the six types</a> in Hetionet v1.0. This analysis however will look at all 6 types.</p>\r\n\r\n<p>See the <a href=\"https://github.com/dhimmel/rephetio/blob/898ba3e8dec371af168af14ed316c9a9e49f32bc/epilepsy/data/compounds-pharmacologic-classes.tsv\">full table here</a>. 92 compounds had at least 1 pharmacologic class. Overall, the epilepsy predictions included 206 distinct pharmacologic classes. Due to the large size and diverse nature of this table, it's difficult to quantify. However, it's a good place to work backwards from class to compounds for the epilepsy predictions. For example, you can search for \"Monoamine Oxidase Inhibitors\" to find the compounds isocarboxazid and phenelzine.</p>\r\n\r\n<h2>Conclusion</h2>\r\n\r\n<p>The top epilepsy predictions pick up on several drug categories with known anti-ictogenic properties, such as anesthetics, GABA modulators, and of course known anti-epileptics. In addition, the predictions cover categories of drugs that wouldn't traditionally be considered, such as the antimalarial quinidine. In addition, we pick up on classes of AEDs whose primary indication is not epilepsy, such as the carbonic anhydrase inhibitors acetazolamide, diclofenamide, methazolamide, zonisamide that have traditionally been used for glaucoma, but are also effective anti-ictogenic drugs <span class=\"citation\">[<a href=\"https://doi.org/10.2174/156802607780636726\" class=\"citation hm \" data-key=\"10.2174/156802607780636726\">5</a>, <a href=\"https://doi.org/10.1517/13543776.2013.782394\" class=\"citation hm \" data-key=\"10.1517/13543776.2013.782394\">6</a>]</span>. <a href=\"/u/pouyakhankhanian\" class=\"username\">@pouyakhankhanian</a> those are my thoughts, you likely have more!</p>",
      "body_md": "# Categorizing the top epilepsy predictions\r\n\r\nThis post will investigate the categories of compounds in the top 100 epilepsy predictions. For this analysis ([notebook](https://github.com/dhimmel/rephetio/blob/898ba3e8dec371af168af14ed316c9a9e49f32bc/epilepsy/3.contribution.ipynb)), We'll use three categorizations of compounds: DrugBank categories, third-level ATC Codes, and DrugCentral pharmacologic classes.\r\n\r\n## DrugBank categories\r\n\r\nDrugBank annotates compounds with [categories](https://www.drugbank.ca/categories) \"based on pharmacological action\" [@10.1093/nar/gkt1068]. Compounds can have zero or more categories. 84 of the 100 compounds had at least one annotated category. The top eight categories are shown below ([full table here](https://github.com/dhimmel/rephetio/blob/898ba3e8dec371af168af14ed316c9a9e49f32bc/epilepsy/data/compounds-categories.tsv)):\r\n\r\n| Category | Count | Compounds (in the top epilepsy predictions) |\r\n|-------------------------|-------|---------------|\r\n| Anticonvulsants | 28 | Acetazolamide, Carbamazepine, Clobazam, Clonazepam, Diazepam, Ethosuximide, Ethotoin, Felbamate, Fosphenytoin, Gabapentin, Lacosamide, Lamotrigine, Levetiracetam, Methsuximide, Methylphenobarbital, Nitrazepam, Oxcarbazepine, Phenobarbital, Phensuximide, Phenytoin, Pregabalin, Primidone, Thiopental, Tiagabine, Topiramate, Trimethadione, Valproic Acid, Zonisamide |\r\n| Hypnotics and Sedatives | 24 | Alprazolam, Butabarbital, Butethal, Chlordiazepoxide, Cinolazepam, Diazepam, Eszopiclone, Etomidate, Fospropofol, Glutethimide, Halazepam, Hexobarbital, Lorazepam, Methylphenobarbital, Midazolam, Nitrazepam, Oxazepam, Pentobarbital, Phenobarbital, Quazepam, Secobarbital, Thiopental, Zolpidem, Zopiclone |\r\n| GABA Modulators | 17 | Alprazolam, Bromazepam, Chlordiazepoxide, Clonazepam, Diazepam, Flunitrazepam, Hexobarbital, Methylphenobarbital, Midazolam, Nitrazepam, Oxazepam, Pentobarbital, Phenobarbital, Prazepam, Secobarbital, Thiopental, Triazolam |\r\n| Benzodiazepines | 15 | Alprazolam, Bromazepam, Chlordiazepoxide, Cinolazepam, Clobazam, Clonazepam, Clotiazepam, Fludiazepam, Flunitrazepam, Halazepam, Ketazolam, Lorazepam, Quazepam, Temazepam, Triazolam |\r\n| Anti-Anxiety Agents | 12 | Alprazolam, Bromazepam, Chlordiazepoxide, Diazepam, Flunitrazepam, Gabapentin, Halazepam, Midazolam, Nitrazepam, Oxazepam, Prazepam, Triazolam |\r\n| Barbiturates | 7 | Butabarbital, Butethal, Heptabarbital, Hexobarbital, Pentobarbital, Primidone, Secobarbital |\r\n| Antidepressive Agents | 6 | Adinazolam, Desipramine, Isocarboxazid, Lamotrigine, Nortriptyline, Phenelzine |\r\n| Adjuvants, Anesthesia | 6 | Chlordiazepoxide, Diazepam, Midazolam, Pentobarbital, Secobarbital, Triazolam |\r\n\r\nIn total, the 100 epilepsy predictions covered 64 DrugBank compounds. Less common categories included stimulants (modafinil), vasodilators (verapamil), potassium channel blockers (dalfampridine), and antipruritics (cyproheptadine).\r\n\r\n## Third-level ATC Codes\r\n\r\nThe Anatomical Therapeutic Chemical (ATC) Classification System is a classification of drugs produced by the WHOCC [@10.4135/9781483349985.n37]. The third-level indicates a therapeutic/pharmacological subgroup. DrugBank compounds are annotated with zero or more ATC codes. 91 of the 100 compounds had at least 1 ATC code. Together, the predictions included 26 third-level ATC codes.\r\n\r\nSee the [full table here](https://github.com/dhimmel/rephetio/blob/898ba3e8dec371af168af14ed316c9a9e49f32bc/epilepsy/data/compounds-third-level-atc-codes.tsv). The most common codes in the 100 predictions were antiepileptics (25 compounds), hypnotics and sedatives (21 compounds), anxiolytics (12 compounds), \"anesthetics, general\" (8 compounds), antidepressants (8 compounds), and antiglaucoma preparations and miotics (3 compounds). Less common codes included antiarrhythmics (quinidine), urologicals (phenazopyridine), and antiinfectives (primidone).\r\n\r\n## DrugCentral Pharmacologic Classes\r\n\r\nDrugCentral contains pharmacologic classes of six types (Chemical/Ingredient, Mechanism of Action, Physiologic Effect, Established Pharmacologic Class, Pharmacological Action, Application) from 3 publicly-available source (FDA, MeSH, and ChEBI) [@10.1093/nar/gkw993 @10.15363/thinklab.d186]. We included [three of the six types](https://thinklab.com/discussion/incorporating-drugcentral-data-in-our-network/186#4) in Hetionet v1.0. This analysis however will look at all 6 types.\r\n\r\nSee the [full table here](https://github.com/dhimmel/rephetio/blob/898ba3e8dec371af168af14ed316c9a9e49f32bc/epilepsy/data/compounds-pharmacologic-classes.tsv). 92 compounds had at least 1 pharmacologic class. Overall, the epilepsy predictions included 206 distinct pharmacologic classes. Due to the large size and diverse nature of this table, it's difficult to quantify. However, it's a good place to work backwards from class to compounds for the epilepsy predictions. For example, you can search for \"Monoamine Oxidase Inhibitors\" to find the compounds isocarboxazid and phenelzine.\r\n\r\n## Conclusion\r\n\r\nThe top epilepsy predictions pick up on several drug categories with known anti-ictogenic properties, such as anesthetics, GABA modulators, and of course known anti-epileptics. In addition, the predictions cover categories of drugs that wouldn't traditionally be considered, such as the antimalarial quinidine. In addition, we pick up on classes of AEDs whose primary indication is not epilepsy, such as the carbonic anhydrase inhibitors acetazolamide, diclofenamide, methazolamide, zonisamide that have traditionally been used for glaucoma, but are also effective anti-ictogenic drugs [@10.2174/156802607780636726 @10.1517/13543776.2013.782394]. @pouyakhankhanian those are my thoughts, you likely have more!",
      "comment_id": 1465,
      "profile_id": 17,
      "published": "2017-01-09T00:06:27.192296Z",
      "thread_id": 224,
      "url": "/discussion/prediction-in-epilepsy/224#10"
    },
    {
      "body_html": "<p>I think it would be a great experimental setup to begin your extraction work using the relationships in your current hetnet as your gold standard (standards.. one per relation type).  First that means you have a gold standard already which is a huge part of the work in building up an NLP system (and can likely publish good results in NLP-related arenas).  Second, if it works, you have an automated way to grow the hetnet on a daily basis and potentially to scrub out the licensed content.  Third you set yourself up for a great experiment - can a drug-treats-disease automatic relation finder outperform your results from the hetnet + R inference model?   How can those methods be harmonized?</p>\r\n\r\n<p>This will be a great project... </p>",
      "body_md": "I think it would be a great experimental setup to begin your extraction work using the relationships in your current hetnet as your gold standard (standards.. one per relation type).  First that means you have a gold standard already which is a huge part of the work in building up an NLP system (and can likely publish good results in NLP-related arenas).  Second, if it works, you have an automated way to grow the hetnet on a daily basis and potentially to scrub out the licensed content.  Third you set yourself up for a great experiment - can a drug-treats-disease automatic relation finder outperform your results from the hetnet + R inference model?   How can those methods be harmonized?\r\n\r\nThis will be a great project...",
      "comment_id": 1466,
      "profile_id": 48,
      "published": "2017-01-09T04:22:26.918064Z",
      "thread_id": 227,
      "url": "/discussion/brainstorming-future-directions-for-hetionet/227#12"
    },
    {
      "body_html": "<p><a href=\"/u/b_good\" class=\"username\">@b_good</a>, <a href=\"#12\">your comment</a> nails the promise of snorkeling hetnets. I was envisioning using Snorkel for network construction rather than relationship prediction. In other words, I'd want each literature extracted relationship to derive from specific phrases that directly attest to the relationships' existence. However you bring up an interesting point — will Snorkel begin to infer relationships and become a substitute for hetnet edge prediction?</p>\r\n\r\n<h2>The <em>Compound–treats–Disease</em> Pilot</h2>\r\n\r\n<blockquote><p>you might consider starting with a relation type (or 2) that are less semantically complex and more plentiful in the research literature than 'treats'.</p></blockquote>\r\n\r\n<p>Is whether a compound <em>treats</em> a disease really so semantically complex? For example, here is an example abstract sentence which implies a CtD relationship from <a href=\"https://www.ncbi.nlm.nih.gov/CBBresearch/Lu/Demo/PubTator/curator_identifier.cgi?user=User636411530&amp;pmid=8694680&amp;searchtype=PubMed_Search&amp;query=8694680&amp;page=1&amp;Species_display=1&amp;Chemical_display=1&amp;Gene_display=1&amp;Disease_display=1&amp;Mutation_display=1&amp;tax=\">an abstract</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1001/archpsyc.1996.01830080023006\" class=\"citation hm \" data-key=\"10.1001/archpsyc.1996.01830080023006\">1</a>]</span>:</p>\r\n\r\n<blockquote><p>Acamprosate proved to be a safe and effective aid in treating alcohol-dependent patients and in maintaining the abstinence of patients during 2 years.</p></blockquote>\r\n\r\n<p>I'm hoping we can steer Snorkel away from making inferences say based on the genes involved in alcohol dependence and instead focus on actual statements of clinical efficacy. PharmacotherapyDB has 755 disease-modifying treatments — <a href=\"/u/ajratner\" class=\"username\">@ajratner</a> will this be sufficient to support an effective labeling function? If not, we could expand to all <a href=\"https://thinklab.com/discussion/cataloging-drugdisease-therapies-in-the-clinicaltrialsgov-database/212#2\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d212\">clinical trial indications</a>, which would give us ~30,000 gold standard relationships.</p>\r\n\r\n<p><a href=\"/u/b_good\" class=\"username\">@b_good</a> if we struggle at snorkeling <em>treats</em> relationships, we could always pilot another relationship type that was more semantically straightforward and plentiful. <em>Gene–interacts–Gene</em> <a href=\"https://thinklab.com/discussion/creating-a-catalog-of-protein-interactions/85#9\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d85\">relationships</a> would be one possibility.</p>\r\n\r\n<h2>Entity tagging and mapping</h2>\r\n\r\n<blockquote><p>Is compound functionally too different from chemical? We have tags for chemical and disease in Snorkel format already, for PubMed abstracts via <a href=\"https://www.ncbi.nlm.nih.gov/CBBresearch/Lu/Demo/PubTator/\">PubTator</a>.</p></blockquote>\r\n\r\n<p><a href=\"/u/alexratner\" class=\"username\">@alexratner</a>, compound and chemical are the same thing. Looks like PubTator tags<br>genes, diseases, species, chemicals, and mutations <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkt441\" class=\"citation hm \" data-key=\"10.1093/nar/gkt441\">2</a>, <a href=\"https://doi.org/10.1093/database/bas041\" class=\"citation hm \" data-key=\"10.1093/database/bas041\">3</a>]</span>. Of these, Hetionet contains genes, diseases, and chemicals. </p>\r\n\r\n<ul><li><p>PubTator uses Entrez Gene for genes, as <a href=\"https://thinklab.com/discussion/using-entrez-gene-as-our-gene-vocabulary/34#12\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d34\">do we</a>. Genes are tagged using <a href=\"https://www.ncbi.nlm.nih.gov/CBBresearch/Lu/Demo/tmTools/#GNormPlus\">GNormPlus</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1155/2015/918710\" class=\"citation hm \" data-key=\"10.1155/2015/918710\">4</a>]</span>.</p></li><li><p>PubTator uses <a href=\"https://www.ncbi.nlm.nih.gov/CBBresearch/Lu/Demo/tmTools/#DNorm\">DNorm</a> to tag diseases <span class=\"citation\">[<a href=\"https://doi.org/10.1093/bioinformatics/btt474\" class=\"citation hm \" data-key=\"10.1093/bioinformatics/btt474\">5</a>]</span>, which uses MEDIC. MEDIC is the disease vocabulary used by the Comparative Toxicogenomics Database (CTD) <span class=\"citation\">[<a href=\"https://doi.org/10.1093/database/bar065\" class=\"citation hm \" data-key=\"10.1093/database/bar065\">6</a>]</span>, which consists of OMIM and MeSH terms.</p></li><li><p>Compounds in PubTator are tagged with <a href=\"https://www.ncbi.nlm.nih.gov/CBBresearch/Lu/Demo/tmTools/#tmChem\">tmChem</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1186/1758-2946-7-S1-S3\" class=\"citation hm \" data-key=\"10.1186/1758-2946-7-S1-S3\">7</a>]</span>, which uses MeSH and ChEBI, so we'll have to find <a href=\"https://twitter.com/biocs/status/818376472641544192\">a way</a> to map MeSH to Drugbank.</p></li></ul>\r\n\r\n<h2>Future Snorkel discussion</h2>\r\n\r\n<p>I'd like to make sure this brainstorming discussion doesn't explode with Snorkel implementation details. So for any Snorkel comments that will generate lot's of discussion, let's either create new discussions on Thinklab or <a href=\"https://github.com/greenelab/snorkeling/issues\">issues</a> on <code>greenelab/snorkeling</code>. We can also make a new Thinklab project for snorkeling.</p>",
      "body_md": "@b_good, [your comment](#12) nails the promise of snorkeling hetnets. I was envisioning using Snorkel for network construction rather than relationship prediction. In other words, I'd want each literature extracted relationship to derive from specific phrases that directly attest to the relationships' existence. However you bring up an interesting point -- will Snorkel begin to infer relationships and become a substitute for hetnet edge prediction?\r\n\r\n##  The _Compound--treats--Disease_ Pilot\r\n\r\n> you might consider starting with a relation type (or 2) that are less semantically complex and more plentiful in the research literature than 'treats'.\r\n\r\nIs whether a compound _treats_ a disease really so semantically complex? For example, here is an example abstract sentence which implies a CtD relationship from [an abstract](https://www.ncbi.nlm.nih.gov/CBBresearch/Lu/Demo/PubTator/curator_identifier.cgi?user=User636411530&pmid=8694680&searchtype=PubMed_Search&query=8694680&page=1&Species_display=1&Chemical_display=1&Gene_display=1&Disease_display=1&Mutation_display=1&tax=) [@10.1001/archpsyc.1996.01830080023006]:\r\n\r\n> Acamprosate proved to be a safe and effective aid in treating alcohol-dependent patients and in maintaining the abstinence of patients during 2 years.\r\n\r\nI'm hoping we can steer Snorkel away from making inferences say based on the genes involved in alcohol dependence and instead focus on actual statements of clinical efficacy. PharmacotherapyDB has 755 disease-modifying treatments -- @ajratner will this be sufficient to support an effective labeling function? If not, we could expand to all [clinical trial indications](https://thinklab.com/discussion/cataloging-drugdisease-therapies-in-the-clinicaltrialsgov-database/212#2), which would give us ~30,000 gold standard relationships.\r\n\r\n@b_good if we struggle at snorkeling _treats_ relationships, we could always pilot another relationship type that was more semantically straightforward and plentiful. _Gene--interacts--Gene_ [relationships](https://thinklab.com/discussion/creating-a-catalog-of-protein-interactions/85#9) would be one possibility.\r\n\r\n## Entity tagging and mapping\r\n\r\n> Is compound functionally too different from chemical? We have tags for chemical and disease in Snorkel format already, for PubMed abstracts via [PubTator](https://www.ncbi.nlm.nih.gov/CBBresearch/Lu/Demo/PubTator/).\r\n\r\n@alexratner, compound and chemical are the same thing. Looks like PubTator tags\r\ngenes, diseases, species, chemicals, and mutations [@10.1093/nar/gkt441 @10.1093/database/bas041]. Of these, Hetionet contains genes, diseases, and chemicals. \r\n\r\n+ PubTator uses Entrez Gene for genes, as [do we](https://thinklab.com/discussion/using-entrez-gene-as-our-gene-vocabulary/34#12). Genes are tagged using [GNormPlus](https://www.ncbi.nlm.nih.gov/CBBresearch/Lu/Demo/tmTools/#GNormPlus) [@10.1155/2015/918710].\r\n\r\n+ PubTator uses [DNorm](https://www.ncbi.nlm.nih.gov/CBBresearch/Lu/Demo/tmTools/#DNorm) to tag diseases [@10.1093/bioinformatics/btt474], which uses MEDIC. MEDIC is the disease vocabulary used by the Comparative Toxicogenomics Database (CTD) [@10.1093/database/bar065], which consists of OMIM and MeSH terms.\r\n\r\n+ Compounds in PubTator are tagged with [tmChem](https://www.ncbi.nlm.nih.gov/CBBresearch/Lu/Demo/tmTools/#tmChem) [@10.1186/1758-2946-7-S1-S3], which uses MeSH and ChEBI, so we'll have to find [a way](https://twitter.com/biocs/status/818376472641544192) to map MeSH to Drugbank.\r\n\r\n## Future Snorkel discussion\r\n\r\nI'd like to make sure this brainstorming discussion doesn't explode with Snorkel implementation details. So for any Snorkel comments that will generate lot's of discussion, let's either create new discussions on Thinklab or [issues](https://github.com/greenelab/snorkeling/issues) on `greenelab/snorkeling`. We can also make a new Thinklab project for snorkeling.",
      "comment_id": 1467,
      "profile_id": 17,
      "published": "2017-01-13T17:43:04.333124Z",
      "thread_id": 227,
      "url": "/discussion/brainstorming-future-directions-for-hetionet/227#13"
    },
    {
      "body_html": "<h1>Quantifying the biological evidence behind the top epilepsy predicitons</h1>\r\n\r\n<p>In a <a href=\"#8\">previous comment</a>, I introduced aggregating individual path contributions for all 100 top epilepsy predictions. This post will go into further depth on the topic — specifically, we're trying to understand what biomedical evidence in Hetionet supports our top epilepsy predictions. These analyses were performed by <a href=\"https://nbviewer.jupyter.org/github/dhimmel/rephetio/blob/898ba3e8dec371af168af14ed316c9a9e49f32bc/epilepsy/3.contribution.ipynb\">this notebook</a>.</p>\r\n\r\n<h2>Contributions by metapath</h2>\r\n\r\n<p>First, we'll aggregate path contributions by their metapath. Here we're asking what types of paths contributed to the top epilepsy predictions (<a href=\"https://github.com/dhimmel/rephetio/blob/898ba3e8dec371af168af14ed316c9a9e49f32bc/epilepsy/data/metapath-contributions.tsv\">source</a>).</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>Metapath</th><th>Paths</th><th>Contribution</th></tr></thead><tbody><tr><td>CbGbCtD</td><td>6,358</td><td>20.624</td></tr><tr><td>CrCtD</td><td>160</td><td>18.266</td></tr><tr><td>CbGaD</td><td>562</td><td>17.568</td></tr><tr><td>CiPCiCtD</td><td>322</td><td>15.051</td></tr><tr><td>CrCrCtD</td><td>2,559</td><td>11.902</td></tr><tr><td>CpDpCtD</td><td>212</td><td>5.3199</td></tr><tr><td>CcSEcCtD</td><td>117,720</td><td>4.4182</td></tr><tr><td>CbGpPWpGaD</td><td>248,740</td><td>3.9824</td></tr><tr><td>CbGeAlD</td><td>10,522</td><td>1.6028</td></tr><tr><td>CtDrD</td><td>5</td><td>1.13</td></tr><tr><td>CrCbGaD</td><td>5,788</td><td>0.13895</td></tr><tr><td>CbGdCrCtD</td><td>8</td><td>0.001348</td></tr></tbody></table>\r\n\r\n<p>Note that the total contribution of all paths across all predictions is 100. So for example, 6,358 <em>Compound–binds–Gene–binds–Compound–treats–Disease</em> (CbGbCtD) paths provide 20.6% of the support for the top epilepsy predictions combined. Illustrating the importance of integrative drug repurposing in epilepsy, 10 different metapaths each provided at least 1% of the total support.</p>\r\n\r\n<p>Next, we aggregated metapath contributions by their source metaedge. This analysis asks what types of edges inform the algorithm about compounds for treating epilepsy?</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>Source Metaedge</th><th>Paths</th><th>Contribution</th></tr></thead><tbody><tr><td>Compound—binds—Gene</td><td>266,192</td><td>43.78</td></tr><tr><td>Compound—resembles—Compound</td><td>8,507</td><td>30.31</td></tr><tr><td>Compound—includes—Pharmacologic Class</td><td>322</td><td>15.05</td></tr><tr><td>Compound—palliates—Disease</td><td>212</td><td>5.32</td></tr><tr><td>Compound—causes—Side Effect</td><td>117,724</td><td>4.42</td></tr><tr><td>Compound—treats—Disease</td><td>5</td><td>1.13</td></tr></tbody></table>\r\n\r\n<p>We see that 43.8% of the support for predicted epilepsy treatments came from their targeted genes. We see that our method is leveraging many different types of information on compounds to make its epilepsy predictions. Note that which diseases a compound treats (excluding epilepsy of course) did not play a major role, as we <a href=\"https://thinklab.com/discussion/our-hetnet-edge-prediction-methodology-the-modeling-framework-for-project-rephetio/210#4\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d210\">suppressed</a> many of these features <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d215\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d215\">1</a>]</span>. </p>\r\n\r\n<p>If we aggregate instead by target metaedge, we can understand what aspects of epilepsy our algorithm leveraged:</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>Target Metaedge</th><th>Paths</th><th>Contribution</th></tr></thead><tbody><tr><td>epilepsy syndrome—treats—Compound</td><td>127,343</td><td>75.58</td></tr><tr><td>epilepsy syndrome—associates—Gene</td><td>255,092</td><td>21.69</td></tr><tr><td>epilepsy syndrome—localizes—Anatomy</td><td>10,522</td><td>1.60</td></tr><tr><td>epilepsy syndrome—resembles—Disease</td><td>5</td><td>1.13</td></tr></tbody></table>\r\n\r\n<p>In the context of top predictions, our algorithm understood epilepsy primarily by its known treatments (76%) and genetic associations (22%).</p>\r\n\r\n<h2>Contribution by target gene groups</h2>\r\n\r\n<p>43.8% of the support for epilepsy predictions came from paths that start with a <em>Compound—binds—Gene</em> metaedge. Let's dig deeper here. Are all the compounds binding to the same family or functional group of genes? To answer this question, I aggregated all paths by the gene node in their source relationship. Paths without a gene as the first intermediate node dropped out.</p>\r\n\r\n<p>However, an issue arose where many genes belonged to the same family or functional group, such as encoding proteins for the same receptor. For example, see the following symbol to name mappings:</p>\r\n\r\n<ul><li><em>GRIA2</em>: \"glutamate receptor, ionotropic, AMPA 2\"</li><li><em>GRIK2</em>: \"glutamate receptor, ionotropic, kainate 2\"</li><li><em>GRIN2A</em>: \"glutamate receptor, ionotropic, N-methyl D-aspartate 2A\"</li><li><em>GRM5</em>: \"glutamate receptor, metabotropic 5\"</li></ul>\r\n\r\n<p>To resolve this issue, I truncated gene names at their first comma not in parentheses. Note that this this approach does not appear to work with current HGNC gene names, but does appear to work for our version of Entrez Gene <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d34\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d34\">2</a>, <a href=\"https://doi.org/10.5281/zenodo.45524\" class=\"citation citation-figure\" data-key=\"10.5281/zenodo.45524\">3</a>]</span>. I also truncated gene names after the word \"receptor\" or \"anhydrase\". I also investigated grouping genes by their <a href=\"https://thinklab.com/discussion/using-entrez-gene-as-our-gene-vocabulary/34#13\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d34\">HGNC family</a>, but this became complicated since genes can belong to many families with varying levels of specificity.</p>\r\n\r\n<p>The top 8 gene groups — all groups with contribution &gt; 1% — are shown below (<a href=\"https://github.com/dhimmel/rephetio/blob/3f3e6ecb7a9b8bb64cde76ac8176d31fc19fdc42/epilepsy/data/source-edge-binds-contributions.tsv\">full table here</a>):</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>Gene Group</th><th>Paths</th><th>Contribution</th><th>Genes</th></tr></thead><tbody><tr><td>gamma-aminobutyric acid (GABA) A receptor</td><td>91,967</td><td>15.329</td><td>GABRA1, GABRA2, GABRA3, GABRA4, GABRA5, GABRA6, GABRB1, GABRB2, GABRB3, GABRD, GABRE, GABRG1, GABRG2, GABRG3, GABRP, GABRQ, GABRR1, GABRR2, GABRR3</td></tr><tr><td>cytochrome P450</td><td>34,323</td><td>5.5857</td><td>CYP11A1, CYP11B1, CYP11B2, CYP19A1, CYP1A1, CYP1A2, CYP1B1, CYP2A6, CYP2B6, CYP2C18, CYP2C19, CYP2C8, CYP2C9, CYP2D6, CYP2E1, CYP3A4, CYP3A43, CYP3A5, CYP3A7, CYP4A11, CYP4B1</td></tr><tr><td>sodium channel</td><td>8,771</td><td>4.5576</td><td>SCN10A, SCN11A, SCN1A, SCN1B, SCN2A, SCN2B, SCN3A, SCN3B, SCN4A, SCN4B, SCN5A, SCN7A, SCN8A, SCN9A</td></tr><tr><td>glutamate receptor</td><td>11,441</td><td>3.8415</td><td>GRIA1, GRIA2, GRIA3, GRIA4, GRIK1, GRIK2, GRIK3, GRIK4, GRIK5, GRIN1, GRIN2A, GRIN2B, GRIN2C, GRIN2D, GRIN3A, GRM5</td></tr><tr><td>calcium channel</td><td>4,579</td><td>2.665</td><td>CACNA1A, CACNA1B, CACNA1C, CACNA1D, CACNA1F, CACNA1G, CACNA1H, CACNA1I, CACNA1S, CACNA2D1, CACNA2D2, CACNB1, CACNB2, CACNB3, CACNB4</td></tr><tr><td>carbonic anhydrase</td><td>5,483</td><td>2.4512</td><td>CA1, CA10, CA11, CA12, CA13, CA14, CA2, CA3, CA4, CA5A, CA5B, CA6, CA7, CA8, CA9</td></tr><tr><td>cholinergic receptor</td><td>19,114</td><td>2.0839</td><td>CHRM1, CHRM2, CHRM3, CHRM4, CHRM5, CHRNA4, CHRNA7</td></tr><tr><td>potassium channel</td><td>7,958</td><td>1.4308</td><td>KCNA1, KCNA10, KCNA2, KCNA3, KCNA4, KCNA5, KCNA6, KCNA7, KCNB1, KCNB2, KCNC1, KCNC2, KCNC3, KCNC4, KCND1, KCND2, KCND3, KCNE1, KCNF1, KCNG1, KCNG2, KCNG3, KCNG4, KCNH1, KCNH2, KCNH3, KCNH4, KCNH5, KCNH6, KCNH7, KCNH8, KCNJ11, KCNJ8, KCNK1, KCNK10, KCNK18, KCNK2, KCNK3, KCNK6, KCNK9, KCNN4, KCNQ1, KCNQ2, KCNQ3, KCNQ4, KCNQ5, KCNV1, KCNV2</td></tr></tbody></table>\r\n\r\n<p>We see that 15.3% of the support for the top epilepsy predictions is based on the predicted compound binding to GABAᴀ receptors <span class=\"citation\">[<a href=\"https://doi.org/10.1046/j.1528-1157.2001.042suppl.3008.x\" class=\"citation \" data-key=\"10.1046/j.1528-1157.2001.042suppl.3008.x\">4</a>]</span>. In addition, 5.6% can be attributed to compounds binding cytochrome P450 proteins, which metabolize many drugs and are important for the pharmacokinetics of AEDs <span class=\"citation\">[<a href=\"https://doi.org/10.2174/157015910792246254\" class=\"citation \" data-key=\"10.2174/157015910792246254\">5</a>]</span>. Compounds that bound sodium channels — an established therapeutic target for epilepsy <span class=\"citation\">[<a href=\"https://doi.org/10.2174/156802612800229206\" class=\"citation \" data-key=\"10.2174/156802612800229206\">6</a>]</span> — contributed 4.6%. The list continues, attesting to the ability of our method to detect and leverage bonafide targets for treating epilepsy <span class=\"citation\">[<a href=\"https://doi.org/10.2174/1568026053386962\" class=\"citation \" data-key=\"10.2174/1568026053386962\">7</a>, <a href=\"https://doi.org/10.1016/j.nurt.2006.11.010\" class=\"citation \" data-key=\"10.1016/j.nurt.2006.11.010\">8</a>, <a href=\"https://doi.org/10.1038/nrn1430\" class=\"citation \" data-key=\"10.1038/nrn1430\">9</a>, <a href=\"https://doi.org/10.1016/j.seizure.2010.10.027\" class=\"citation \" data-key=\"10.1016/j.seizure.2010.10.027\">10</a>]</span>. For example, the next genes groups were glutamate receptors <span class=\"citation\">[<a href=\"https://doi.org/10.1093/med/9780199746545.003.0010\" class=\"citation \" data-key=\"10.1093/med/9780199746545.003.0010\">11</a>]</span>, the calcium channel <span class=\"citation\">[<a href=\"https://doi.org/10.1007/0-387-27526-6_13\" class=\"citation \" data-key=\"10.1007/0-387-27526-6_13\">12</a>, <a href=\"https://doi.org/10.1111/j.1528-1167.2010.02797.x\" class=\"citation \" data-key=\"10.1111/j.1528-1167.2010.02797.x\">13</a>]</span>, carbonic anhydrases <span class=\"citation\">[<a href=\"https://doi.org/10.2174/156802607780636726\" class=\"citation \" data-key=\"10.2174/156802607780636726\">14</a>, <a href=\"https://doi.org/10.1517/13543776.2013.782394\" class=\"citation \" data-key=\"10.1517/13543776.2013.782394\">15</a>]</span>, cholinergic receptors <span class=\"citation\">[<a href=\"https://doi.org/10.2174/1568007023339193\" class=\"citation \" data-key=\"10.2174/1568007023339193\">16</a>, <a href=\"https://doi.org/10.1007/s11064-007-9429-3\" class=\"citation \" data-key=\"10.1007/s11064-007-9429-3\">17</a>]</span>, and the potassium channel <span class=\"citation\">[<a href=\"https://doi.org/10.1101/cshperspect.a022871\" class=\"citation \" data-key=\"10.1101/cshperspect.a022871\">18</a>, <a href=\"https://doi.org/10.1517/14740338.2013.823399\" class=\"citation \" data-key=\"10.1517/14740338.2013.823399\">19</a>]</span>.</p>\r\n\r\n<p>In total, 90 gene groups provided support, 11 of which contributed over 0.5%.</p>\r\n\r\n<h2>Contribution by Side Effect node</h2>\r\n\r\n<p>117,720 <em>CcSEcCtD</em> paths provided 4.4% of the support for our epilepsy predictions. These paths traverse 1,137 specific side effects.  If we restrict ourselves to <em>Compound—causes—Side Effect</em> source edge contributions, we can rank side effects by their aggregate contribution to our epilepsy predictions. The top five side effects reflect known adverse adverse of AEDs. In order, this approach highlights Ataxia (0.069% of total support) <span class=\"citation\">[<a href=\"https://doi.org/10.1136/jnnp.2006.100222\" class=\"citation \" data-key=\"10.1136/jnnp.2006.100222\">20</a>]</span>, Nystagmus (0.049%) <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.ebcr.2015.07.003\" class=\"citation \" data-key=\"10.1016/j.ebcr.2015.07.003\">21</a>]</span>, Diplopia (0.045%) <span class=\"citation\">[<a href=\"https://doi.org/10.1016/S1059-1311(03)00082-7\" class=\"citation \" data-key=\"10.1016/S1059-1311(03)00082-7\">22</a>]</span>, Somnolence (0.044%) <span class=\"citation\">[<a href=\"https://doi.org/10.1016/S1388-2457(00)00411-9\" class=\"citation \" data-key=\"10.1016/S1388-2457(00)00411-9\">23</a>]</span>, and Vomiting (0.043%) <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.seizure.2010.12.011\" class=\"citation \" data-key=\"10.1016/j.seizure.2010.12.011\">24</a>]</span>.</p>\r\n\r\n<h2>Contributions by Anatomy node</h2>\r\n\r\n<p>Finally, Hetionet contained <em>Disease–localizes–Anatomy</em> relationships automatically generated from <a href=\"https://thinklab.com/discussion/mining-knowledge-from-medline-articles-and-their-indexed-mesh-terms/67#5\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d67\">MEDLINE co-occurrence</a>. Epilepsy ended having relationships with 24 anatomies (anatomical structures, e.g. tissues) that contributed to the predictions through <em>Compound–binds–Gene–expresses–Anatomy–localizes–Disease</em> (CbGeAlD) paths. By aggregating CbGeAlD paths by their Anatomy node, we computed <a href=\"https://github.com/dhimmel/rephetio/blob/898ba3e8dec371af168af14ed316c9a9e49f32bc/epilepsy/data/anatomy-node-contributions.tsv\">the contribution</a> of each anatomy to our epilepsy predictions. What caught my eye is that anatomies that are more relevant to parthenogenesis and drug efficacy were near the top of the list. Examples include the telencephalon, forebrain, and nervous system. The anatomies that are related to epilepsy but primarily through its symptoms were near the bottom of the list. These examples include the tongue and meninx. This particular observation isn't well controlled, but I wanted to mention it as a future avenue of research.</p>\r\n\r\n<h2>Conclusion</h2>\r\n\r\n<p>Our top epilepsy predictions derive from a diverse set of supporting evidence that is supported by the current understanding of epilepsy. Aggregating path contributions allows us to evaluate the overall contribution of each network component, for a given context.</p>",
      "body_md": "# Quantifying the biological evidence behind the top epilepsy predicitons\r\n\r\nIn a [previous comment](#8), I introduced aggregating individual path contributions for all 100 top epilepsy predictions. This post will go into further depth on the topic -- specifically, we're trying to understand what biomedical evidence in Hetionet supports our top epilepsy predictions. These analyses were performed by [this notebook](https://nbviewer.jupyter.org/github/dhimmel/rephetio/blob/898ba3e8dec371af168af14ed316c9a9e49f32bc/epilepsy/3.contribution.ipynb).\r\n\r\n## Contributions by metapath\r\n\r\nFirst, we'll aggregate path contributions by their metapath. Here we're asking what types of paths contributed to the top epilepsy predictions ([source](https://github.com/dhimmel/rephetio/blob/898ba3e8dec371af168af14ed316c9a9e49f32bc/epilepsy/data/metapath-contributions.tsv)).\r\n\r\n| Metapath | Paths | Contribution |\r\n|------------|------------|--------------|\r\n| CbGbCtD | 6,358 | 20.624 |\r\n| CrCtD | 160 | 18.266 |\r\n| CbGaD | 562 | 17.568 |\r\n| CiPCiCtD | 322 | 15.051 |\r\n| CrCrCtD | 2,559 | 11.902 |\r\n| CpDpCtD | 212 | 5.3199 |\r\n| CcSEcCtD | 117,720 | 4.4182 |\r\n| CbGpPWpGaD | 248,740 | 3.9824 |\r\n| CbGeAlD | 10,522 | 1.6028 |\r\n| CtDrD | 5 | 1.13 |\r\n| CrCbGaD | 5,788 | 0.13895 |\r\n| CbGdCrCtD | 8 | 0.001348 |\r\n\r\nNote that the total contribution of all paths across all predictions is 100. So for example, 6,358 _Compound–binds–Gene–binds–Compound–treats–Disease_ (CbGbCtD) paths provide 20.6% of the support for the top epilepsy predictions combined. Illustrating the importance of integrative drug repurposing in epilepsy, 10 different metapaths each provided at least 1% of the total support.\r\n\r\nNext, we aggregated metapath contributions by their source metaedge. This analysis asks what types of edges inform the algorithm about compounds for treating epilepsy?\r\n\r\n| Source Metaedge | Paths | Contribution |\r\n|--------------------|---------|--------------|\r\n| Compound—binds—Gene | 266,192 | 43.78 |\r\n| Compound—resembles—Compound | 8,507 | 30.31 |\r\n| Compound—includes—Pharmacologic Class | 322 | 15.05 |\r\n| Compound—palliates—Disease | 212 | 5.32 |\r\n| Compound—causes—Side Effect | 117,724 | 4.42 |\r\n| Compound—treats—Disease | 5 | 1.13 |\r\n\r\nWe see that 43.8% of the support for predicted epilepsy treatments came from their targeted genes. We see that our method is leveraging many different types of information on compounds to make its epilepsy predictions. Note that which diseases a compound treats (excluding epilepsy of course) did not play a major role, as we [suppressed](https://thinklab.com/discussion/our-hetnet-edge-prediction-methodology-the-modeling-framework-for-project-rephetio/210#4) many of these features [@10.15363/thinklab.d215]. \r\n\r\nIf we aggregate instead by target metaedge, we can understand what aspects of epilepsy our algorithm leveraged:\r\n\r\n| Target Metaedge | Paths | Contribution |\r\n|----------|---------|--------------|\r\n| epilepsy syndrome—treats—Compound | 127,343 | 75.58 |\r\n| epilepsy syndrome—associates—Gene | 255,092 | 21.69 |\r\n| epilepsy syndrome—localizes—Anatomy | 10,522 | 1.60 |\r\n| epilepsy syndrome—resembles—Disease | 5 | 1.13 |\r\n\r\nIn the context of top predictions, our algorithm understood epilepsy primarily by its known treatments (76%) and genetic associations (22%).\r\n\r\n## Contribution by target gene groups\r\n\r\n43.8% of the support for epilepsy predictions came from paths that start with a _Compound—binds—Gene_ metaedge. Let's dig deeper here. Are all the compounds binding to the same family or functional group of genes? To answer this question, I aggregated all paths by the gene node in their source relationship. Paths without a gene as the first intermediate node dropped out.\r\n\r\nHowever, an issue arose where many genes belonged to the same family or functional group, such as encoding proteins for the same receptor. For example, see the following symbol to name mappings:\r\n\r\n+ _GRIA2_: \"glutamate receptor, ionotropic, AMPA 2\"\r\n+ _GRIK2_: \"glutamate receptor, ionotropic, kainate 2\"\r\n+ _GRIN2A_: \"glutamate receptor, ionotropic, N-methyl D-aspartate 2A\"\r\n+ _GRM5_: \"glutamate receptor, metabotropic 5\"\r\n\r\nTo resolve this issue, I truncated gene names at their first comma not in parentheses. Note that this this approach does not appear to work with current HGNC gene names, but does appear to work for our version of Entrez Gene [@10.15363/thinklab.d34 @10.5281/zenodo.45524]. I also truncated gene names after the word \"receptor\" or \"anhydrase\". I also investigated grouping genes by their [HGNC family](https://thinklab.com/discussion/using-entrez-gene-as-our-gene-vocabulary/34#13), but this became complicated since genes can belong to many families with varying levels of specificity.\r\n\r\nThe top 8 gene groups -- all groups with contribution > 1% -- are shown below ([full table here](https://github.com/dhimmel/rephetio/blob/3f3e6ecb7a9b8bb64cde76ac8176d31fc19fdc42/epilepsy/data/source-edge-binds-contributions.tsv)):\r\n\r\n| Gene Group | Paths | Contribution | Genes |\r\n|------------|--------|--------------|----------------|\r\n| gamma-aminobutyric acid (GABA) A receptor | 91,967 | 15.329 | GABRA1, GABRA2, GABRA3, GABRA4, GABRA5, GABRA6, GABRB1, GABRB2, GABRB3, GABRD, GABRE, GABRG1, GABRG2, GABRG3, GABRP, GABRQ, GABRR1, GABRR2, GABRR3 |\r\n| cytochrome P450 | 34,323 | 5.5857 | CYP11A1, CYP11B1, CYP11B2, CYP19A1, CYP1A1, CYP1A2, CYP1B1, CYP2A6, CYP2B6, CYP2C18, CYP2C19, CYP2C8, CYP2C9, CYP2D6, CYP2E1, CYP3A4, CYP3A43, CYP3A5, CYP3A7, CYP4A11, CYP4B1 |\r\n| sodium channel | 8,771 | 4.5576 | SCN10A, SCN11A, SCN1A, SCN1B, SCN2A, SCN2B, SCN3A, SCN3B, SCN4A, SCN4B, SCN5A, SCN7A, SCN8A, SCN9A |\r\n| glutamate receptor | 11,441 | 3.8415 | GRIA1, GRIA2, GRIA3, GRIA4, GRIK1, GRIK2, GRIK3, GRIK4, GRIK5, GRIN1, GRIN2A, GRIN2B, GRIN2C, GRIN2D, GRIN3A, GRM5 |\r\n| calcium channel | 4,579 | 2.665 | CACNA1A, CACNA1B, CACNA1C, CACNA1D, CACNA1F, CACNA1G, CACNA1H, CACNA1I, CACNA1S, CACNA2D1, CACNA2D2, CACNB1, CACNB2, CACNB3, CACNB4 |\r\n| carbonic anhydrase | 5,483 | 2.4512 | CA1, CA10, CA11, CA12, CA13, CA14, CA2, CA3, CA4, CA5A, CA5B, CA6, CA7, CA8, CA9 |\r\n| cholinergic receptor | 19,114 | 2.0839 | CHRM1, CHRM2, CHRM3, CHRM4, CHRM5, CHRNA4, CHRNA7 |\r\n| potassium channel | 7,958 | 1.4308 | KCNA1, KCNA10, KCNA2, KCNA3, KCNA4, KCNA5, KCNA6, KCNA7, KCNB1, KCNB2, KCNC1, KCNC2, KCNC3, KCNC4, KCND1, KCND2, KCND3, KCNE1, KCNF1, KCNG1, KCNG2, KCNG3, KCNG4, KCNH1, KCNH2, KCNH3, KCNH4, KCNH5, KCNH6, KCNH7, KCNH8, KCNJ11, KCNJ8, KCNK1, KCNK10, KCNK18, KCNK2, KCNK3, KCNK6, KCNK9, KCNN4, KCNQ1, KCNQ2, KCNQ3, KCNQ4, KCNQ5, KCNV1, KCNV2 |\r\n\r\nWe see that 15.3% of the support for the top epilepsy predictions is based on the predicted compound binding to GABAᴀ receptors [@10.1046/j.1528-1157.2001.042suppl.3008.x]. In addition, 5.6% can be attributed to compounds binding cytochrome P450 proteins, which metabolize many drugs and are important for the pharmacokinetics of AEDs [@10.2174/157015910792246254]. Compounds that bound sodium channels -- an established therapeutic target for epilepsy [@10.2174/156802612800229206] -- contributed 4.6%. The list continues, attesting to the ability of our method to detect and leverage bonafide targets for treating epilepsy [@10.2174/1568026053386962 @10.1016/j.nurt.2006.11.010 @10.1038/nrn1430 @10.1016/j.seizure.2010.10.027]. For example, the next genes groups were glutamate receptors [@10.1093/med/9780199746545.003.0010], the calcium channel [@10.1007/0-387-27526-6_13 @10.1111/j.1528-1167.2010.02797.x], carbonic anhydrases [@10.2174/156802607780636726 @10.1517/13543776.2013.782394], cholinergic receptors [@10.2174/1568007023339193 @10.1007/s11064-007-9429-3], and the potassium channel [@10.1101/cshperspect.a022871 @10.1517/14740338.2013.823399].\r\n\r\nIn total, 90 gene groups provided support, 11 of which contributed over 0.5%.\r\n\r\n## Contribution by Side Effect node\r\n\r\n117,720 _CcSEcCtD_ paths provided 4.4% of the support for our epilepsy predictions. These paths traverse 1,137 specific side effects.  If we restrict ourselves to _Compound—causes—Side Effect_ source edge contributions, we can rank side effects by their aggregate contribution to our epilepsy predictions. The top five side effects reflect known adverse adverse of AEDs. In order, this approach highlights Ataxia (0.069% of total support) [@10.1136/jnnp.2006.100222], Nystagmus (0.049%) [@10.1016/j.ebcr.2015.07.003], Diplopia (0.045%) [@10.1016/S1059-1311(03)00082-7], Somnolence (0.044%) [@10.1016/S1388-2457(00)00411-9], and Vomiting (0.043%) [@10.1016/j.seizure.2010.12.011].\r\n\r\n## Contributions by Anatomy node\r\n\r\nFinally, Hetionet contained _Disease–localizes–Anatomy_ relationships automatically generated from [MEDLINE co-occurrence](https://thinklab.com/discussion/mining-knowledge-from-medline-articles-and-their-indexed-mesh-terms/67#5). Epilepsy ended having relationships with 24 anatomies (anatomical structures, e.g. tissues) that contributed to the predictions through _Compound–binds–Gene–expresses–Anatomy–localizes–Disease_ (CbGeAlD) paths. By aggregating CbGeAlD paths by their Anatomy node, we computed [the contribution](https://github.com/dhimmel/rephetio/blob/898ba3e8dec371af168af14ed316c9a9e49f32bc/epilepsy/data/anatomy-node-contributions.tsv) of each anatomy to our epilepsy predictions. What caught my eye is that anatomies that are more relevant to parthenogenesis and drug efficacy were near the top of the list. Examples include the telencephalon, forebrain, and nervous system. The anatomies that are related to epilepsy but primarily through its symptoms were near the bottom of the list. These examples include the tongue and meninx. This particular observation isn't well controlled, but I wanted to mention it as a future avenue of research.\r\n\r\n## Conclusion\r\n\r\nOur top epilepsy predictions derive from a diverse set of supporting evidence that is supported by the current understanding of epilepsy. Aggregating path contributions allows us to evaluate the overall contribution of each network component, for a given context.",
      "comment_id": 1468,
      "profile_id": 17,
      "published": "2017-01-10T20:08:57.254807Z",
      "thread_id": 224,
      "url": "/discussion/prediction-in-epilepsy/224#11"
    },
    {
      "body_html": "<h1>Entrez Gene Catalog for Project Rephetio</h1>\r\n\r\n<p>Sorry that I'm a bit late to posting this. Our final list of 56,352 human Entrez Genes is available in <a href=\"https://github.com/dhimmel/entrez-gene/blob/a7362748a34211e5df6f2d185bb3246279760546/data/genes-human.tsv\"><code>genes-human.tsv</code></a> <span class=\"citation\">[<a href=\"https://doi.org/10.5281/zenodo.45524\" class=\"citation hm citation-figure\" data-key=\"10.5281/zenodo.45524\">1</a>]</span>. The <code>dhimmel/entrez-gene</code> repository also contains several convenient files for doing analyses using Entrez Genes.</p>\r\n\r\n<p>In Hetionet v1.0, we only included the 20,945 protein-coding genes.</p>",
      "body_md": "# Entrez Gene Catalog for Project Rephetio\r\n\r\nSorry that I'm a bit late to posting this. Our final list of 56,352 human Entrez Genes is available in [`genes-human.tsv`](https://github.com/dhimmel/entrez-gene/blob/a7362748a34211e5df6f2d185bb3246279760546/data/genes-human.tsv) [@10.5281/zenodo.45524]. The `dhimmel/entrez-gene` repository also contains several convenient files for doing analyses using Entrez Genes.\r\n\r\nIn Hetionet v1.0, we only included the 20,945 protein-coding genes.",
      "comment_id": 1469,
      "profile_id": 17,
      "published": "2017-01-10T20:30:23.163407Z",
      "thread_id": 34,
      "url": "/discussion/using-entrez-gene-as-our-gene-vocabulary/34#12"
    },
    {
      "body_html": "<p><a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a> Sorry for the delayed response here.  I 100% agree with your statement <em>\"I was envisioning using Snorkel for network construction rather than relationship prediction. In other words, I'd want each literature extracted relationship to derive from specific phrases that directly attest to the relationships' existence.\"</em></p>\r\n\r\n<p>In some sense this is an engineering decision: we <em>could</em> train any predictive model, but it seems best in our experience to train one to extract the concrete explicit <em>mentions</em> of relations, and then to do further reasoning / prediction / analysis over these.</p>\r\n\r\n<p>In terms of the complexity of the <em>treats</em> relationship is probably higher than you'd expect... thank you natural language... but definitely very doable (actually, we have a chemical-induced disease extraction application using CTD distant supervision which beats state-of-the-art on a BioCreatives task, will clean up as tutorial soon...)</p>\r\n\r\n<p>However as to which labeling functions / weak supervision will be good enough... no great easy answers, let's see what happens!</p>\r\n\r\n<p>Great to hear that our entity types are aligned.</p>\r\n\r\n<p>Also, we just released v0.5.0, so hopefully this helps!</p>",
      "body_md": "@dhimmel Sorry for the delayed response here.  I 100% agree with your statement _\"I was envisioning using Snorkel for network construction rather than relationship prediction. In other words, I'd want each literature extracted relationship to derive from specific phrases that directly attest to the relationships' existence.\"_\r\n\r\nIn some sense this is an engineering decision: we _could_ train any predictive model, but it seems best in our experience to train one to extract the concrete explicit _mentions_ of relations, and then to do further reasoning / prediction / analysis over these.\r\n\r\nIn terms of the complexity of the _treats_ relationship is probably higher than you'd expect... thank you natural language... but definitely very doable (actually, we have a chemical-induced disease extraction application using CTD distant supervision which beats state-of-the-art on a BioCreatives task, will clean up as tutorial soon...)\r\n\r\nHowever as to which labeling functions / weak supervision will be good enough... no great easy answers, let's see what happens!\r\n\r\nGreat to hear that our entity types are aligned.\r\n\r\nAlso, we just released v0.5.0, so hopefully this helps!",
      "comment_id": 1470,
      "profile_id": 313,
      "published": "2017-01-18T19:47:15.375200Z",
      "thread_id": 227,
      "url": "/discussion/brainstorming-future-directions-for-hetionet/227#14"
    },
    {
      "body_html": "<p>We're focusing on epilepsy as case study in our Project Rephetio <a href=\"https://doi.org/10.15363/thinklab.a7\">report</a> <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.a7\" class=\"citation hm citation-self\" data-key=\"10.15363/thinklab.a7\">1</a>, <a href=\"https://doi.org/10.1101/087619\" class=\"citation hm \" data-key=\"10.1101/087619\">2</a>]</span>. Specifically, we're interested in the <a href=\"https://thinklab.com/discussion/prediction-in-epilepsy/224#5\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d224\">top 100 compounds</a> predicted to treat epilepsy.</p>\r\n\r\n<p>One way to investigate these 100 epilepsy predictions is to view them in a chemical similarity network. In a <a href=\"https://thinklab.com/discussion/prediction-in-epilepsy/224#9\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d224\">previous comment</a>, I exported this visualization from our Hetionet Neo4j Browser. However, now I'd like to pursue this visualization further, so here we'll discuss how to perfect this visualization in <a href=\"http://www.cytoscape.org/\">Cytoscape</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1101/gr.1239303\" class=\"citation hm \" data-key=\"10.1101/gr.1239303\">3</a>, <a href=\"https://doi.org/10.1002/0471250953.bi0813s47\" class=\"citation hm \" data-key=\"10.1002/0471250953.bi0813s47\">4</a>]</span>.</p>\r\n\r\n<p>For this project, we've already used Cytoscape to <a href=\"https://thinklab.com/discussion/describing-hetionet-v10-through-visualization-and-statistics/202#8\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d202\">visualize Hetionet</a>. Here we'll be using it for a much more zoomed-in plot!</p>",
      "body_md": "We're focusing on epilepsy as case study in our Project Rephetio [report](https://doi.org/10.15363/thinklab.a7) [@10.15363/thinklab.a7 @10.1101/087619]. Specifically, we're interested in the [top 100 compounds](https://thinklab.com/discussion/prediction-in-epilepsy/224#5) predicted to treat epilepsy.\r\n\r\nOne way to investigate these 100 epilepsy predictions is to view them in a chemical similarity network. In a [previous comment](https://thinklab.com/discussion/prediction-in-epilepsy/224#9), I exported this visualization from our Hetionet Neo4j Browser. However, now I'd like to pursue this visualization further, so here we'll discuss how to perfect this visualization in [Cytoscape](http://www.cytoscape.org/) [@10.1101/gr.1239303 @10.1002/0471250953.bi0813s47].\r\n\r\nFor this project, we've already used Cytoscape to [visualize Hetionet](https://thinklab.com/discussion/describing-hetionet-v10-through-visualization-and-statistics/202#8). Here we'll be using it for a much more zoomed-in plot!",
      "comment_id": 1471,
      "profile_id": 17,
      "published": "2017-01-24T17:23:18.254424Z",
      "thread_id": 230,
      "url": "/discussion/visualizing-the-top-epilepsy-predictions-in-cytoscape/230"
    },
    {
      "body_html": "<h1>From Neo4j to Cytoscape</h1>\r\n\r\n<p><a href=\"http://apps.cytoscape.org/apps/cyneo4j\">cyNeo4j</a> is a Cytoscape app that allows you to load networks from Cypher queries on a remote Neo4j instance <span class=\"citation\">[<a href=\"https://doi.org/10.1093/bioinformatics/btv460\" class=\"citation hm \" data-key=\"10.1093/bioinformatics/btv460\">1</a>]</span>. Sadly, <a href=\"https://github.com/gsummer/cyNeo4j\">development</a> of cyNeo4j has stalled, but I was able get it to import the <a href=\"https://thinklab.com/discussion/prediction-in-epilepsy/224#9\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d224\">compound network</a> from <a href=\"https://neo4j.het.io\">https://neo4j.het.io</a> using two steps:</p>\r\n\r\n<ol><li>Query the 100 compound nodes</li><li>Query for <code>RESEMBLES_CrC</code> relationships between the 100 compounds</li></ol>\r\n\r\n<p>The resulting Cytoscape session is online at <a href=\"https://github.com/dhimmel/rephetio/blob/ce1d95a1166feaf08ca2f3c8a869a5d754c044ea/epilepsy/figure/compound-network/compound-network.cys\"><code>compound-network.cys</code></a>. Here is the resulting visualization:</p>\r\n\r\n<p><img src=\"https://github.com/dhimmel/rephetio/raw/ce1d95a1166feaf08ca2f3c8a869a5d754c044ea/epilepsy/figure/compound-network/compound-network.png\" alt=\"Chemical similarity network of the top 100 epilepsy predictions from Project Rephetio\" title=\"Colors represent the compound's effect on ictogenesis\"></p>\r\n\r\n<p>Compounds are colored by their effect on ictogenesis — whether they suppress seizures (blue), have an unknown effect (white), or generate seizures (red). Tagging <a href=\"/u/pouyakhankhanian\" class=\"username\">@pouyakhankhanian</a>, as yesterday we discussed additional ways to visualize our epilepsy predictions.</p>",
      "body_md": "# From Neo4j to Cytoscape\r\n\r\n[cyNeo4j](http://apps.cytoscape.org/apps/cyneo4j) is a Cytoscape app that allows you to load networks from Cypher queries on a remote Neo4j instance [@10.1093/bioinformatics/btv460]. Sadly, [development](https://github.com/gsummer/cyNeo4j) of cyNeo4j has stalled, but I was able get it to import the [compound network](https://thinklab.com/discussion/prediction-in-epilepsy/224#9) from https://neo4j.het.io using two steps:\r\n\r\n1. Query the 100 compound nodes\r\n2. Query for `RESEMBLES_CrC` relationships between the 100 compounds\r\n\r\nThe resulting Cytoscape session is online at [`compound-network.cys`](https://github.com/dhimmel/rephetio/blob/ce1d95a1166feaf08ca2f3c8a869a5d754c044ea/epilepsy/figure/compound-network/compound-network.cys). Here is the resulting visualization:\r\n\r\n![Chemical similarity network of the top 100 epilepsy predictions from Project Rephetio](https://github.com/dhimmel/rephetio/raw/ce1d95a1166feaf08ca2f3c8a869a5d754c044ea/epilepsy/figure/compound-network/compound-network.png \"Colors represent the compound's effect on ictogenesis\")\r\n\r\nCompounds are colored by their effect on ictogenesis -- whether they suppress seizures (blue), have an unknown effect (white), or generate seizures (red). Tagging @pouyakhankhanian, as yesterday we discussed additional ways to visualize our epilepsy predictions.",
      "comment_id": 1472,
      "profile_id": 17,
      "published": "2017-01-24T17:43:21.573763Z",
      "thread_id": 230,
      "url": "/discussion/visualizing-the-top-epilepsy-predictions-in-cytoscape/230#2"
    },
    {
      "body_html": "<h1>Improving the visualization</h1>\r\n\r\n<p>I'd like to improve the visualization <a href=\"#2\">above</a>.</p>\r\n\r\n<p>But before going any further, is a network with 100 labeled nodes too expansive for a manuscript visualization? If we do have labeled nodes — which is really helpful — can we make the labels a readable font size?</p>\r\n\r\n<p>One alternative to compound names would be drawing compound structures using <a href=\"http://apps.cytoscape.org/apps/chemViz2\">chemViz2</a>. We could then made nodes circular or square to conserve space.</p>\r\n\r\n<p>I'd also like to make text always fit within a node.</p>\r\n\r\n<p>Finally, I'm really interested in drawing rings around the nodes that are composed of colored arcs. Each arc would represent how much a certain target of the compound contributed to the prediction (following from <a href=\"https://thinklab.com/discussion/prediction-in-epilepsy/224#11\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d224\">this comment</a>).</p>\r\n\r\n<p>Cytoscape 3.4.0 has a <a href=\"http://manual.cytoscape.org/en/3.4.0/Styles.html#using-graphics-in-styles\">ring chart</a>. Alternatively, the <a href=\"http://apps.cytoscape.org/apps/enhancedgraphics\">enhancedGraphics</a> app <span class=\"citation\">[<a href=\"https://doi.org/10.12688/f1000research.4460.1\" class=\"citation hm \" data-key=\"10.12688/f1000research.4460.1\">1</a>]</span> has circle/circos charts that may do the job. I briefly tried out the builtin ring chart but couldn't get the rings to surround the \"round rectangle\" node shape — instead the rights were drawn inside the nodes.</p>\r\n\r\n<p>Tagging <a href=\"/u/sergiobaranzini\" class=\"username\">@sergiobaranzini</a> &amp; <a href=\"/u/alexanderpico\" class=\"username\">@alexanderpico</a> — two experts of Cytoscape. Any suggestions?</p>",
      "body_md": "# Improving the visualization\r\n\r\nI'd like to improve the visualization [above](#2).\r\n\r\nBut before going any further, is a network with 100 labeled nodes too expansive for a manuscript visualization? If we do have labeled nodes -- which is really helpful -- can we make the labels a readable font size?\r\n\r\nOne alternative to compound names would be drawing compound structures using [chemViz2](http://apps.cytoscape.org/apps/chemViz2). We could then made nodes circular or square to conserve space.\r\n\r\nI'd also like to make text always fit within a node.\r\n\r\nFinally, I'm really interested in drawing rings around the nodes that are composed of colored arcs. Each arc would represent how much a certain target of the compound contributed to the prediction (following from [this comment](https://thinklab.com/discussion/prediction-in-epilepsy/224#11)).\r\n\r\nCytoscape 3.4.0 has a [ring chart](http://manual.cytoscape.org/en/3.4.0/Styles.html#using-graphics-in-styles). Alternatively, the [enhancedGraphics](http://apps.cytoscape.org/apps/enhancedgraphics) app [@10.12688/f1000research.4460.1] has circle/circos charts that may do the job. I briefly tried out the builtin ring chart but couldn't get the rings to surround the \"round rectangle\" node shape -- instead the rights were drawn inside the nodes.\r\n\r\nTagging @sergiobaranzini & @alexanderpico -- two experts of Cytoscape. Any suggestions?",
      "comment_id": 1473,
      "profile_id": 17,
      "published": "2017-01-24T18:10:04.182351Z",
      "thread_id": 230,
      "url": "/discussion/visualizing-the-top-epilepsy-predictions-in-cytoscape/230#3"
    },
    {
      "body_html": "<p>The network displayed above is already interesting. There is a clear barbiturate cluster and a clear benzodiazepine cluster. The tricyclic antidepressants (TCAs) cluster together as well in the lower right, and are colored pink because they are ictogenic. Overall, I think this is a good figure with a lot of information. </p>\r\n\r\n<p>We discussed adding more layers of information, specifically to use the edges. I would be in favor of trying to display the source edge information. Specifically, I'm interested in the times when the source edge is Compound-Gene. The reason for this is that I was particularly amazed at how many of the \"modern epilepsy genes\" (the SCNs, the CACNAs, the GRIN/GRIK/GRIAs, KCNs) were included as source edges (note that these are not target edges, these genes are too modern and were presumably not included in the network as gene-epilepsy edges). In particular, I'd want to see if there is some clustering of drugs based on what gene target they act one. This may serve to reclassify the AEDs, a class of drugs which has historically been difficult to classify cleanly. I showed this to Ingo Helbig an epilepsy geneticist who shared my interest, hope he can join thinklab to share some of his insight. </p>\r\n\r\n<p>Regarding the use of chemical shapes rather than names, I personally prefer the names. I would never be able to pick out patterns in chemical shapes, but names for me reveal obvious clusters. Consider 3-letter abbreviations for drugs if you want to decrease the size of the text label (there are pretty standard 3-letter abbreviations for epilepsy drugs, we would have to create 3-letter abbreviations for the other drugs, CBZ: Carbamazepine, LTG: Lamotrigine, OXC: oxcarbazpine, VPA: sodium valproate, TPM: Topiramate, CLB: clobazam, GBP: gabapentin, LEV: levetiracetam, PHT: Phenytoin, TGM: tiagabine, ZON: zonisamide, PGN: pregabalin, ESM: Ethosuximide, CLN: clonazepam, RUF: rufinamide, VGB: vigabatrin).</p>\r\n\r\n<p>Hope <a href=\"/u/sergiobaranzini\" class=\"username\">@sergiobaranzini</a> and/or <a href=\"/u/alexanderpico\" class=\"username\">@alexanderpico</a> can help with the visualization. </p>",
      "body_md": "The network displayed above is already interesting. There is a clear barbiturate cluster and a clear benzodiazepine cluster. The tricyclic antidepressants (TCAs) cluster together as well in the lower right, and are colored pink because they are ictogenic. Overall, I think this is a good figure with a lot of information. \r\n\r\nWe discussed adding more layers of information, specifically to use the edges. I would be in favor of trying to display the source edge information. Specifically, I'm interested in the times when the source edge is Compound-Gene. The reason for this is that I was particularly amazed at how many of the \"modern epilepsy genes\" (the SCNs, the CACNAs, the GRIN/GRIK/GRIAs, KCNs) were included as source edges (note that these are not target edges, these genes are too modern and were presumably not included in the network as gene-epilepsy edges). In particular, I'd want to see if there is some clustering of drugs based on what gene target they act one. This may serve to reclassify the AEDs, a class of drugs which has historically been difficult to classify cleanly. I showed this to Ingo Helbig an epilepsy geneticist who shared my interest, hope he can join thinklab to share some of his insight. \r\n\r\nRegarding the use of chemical shapes rather than names, I personally prefer the names. I would never be able to pick out patterns in chemical shapes, but names for me reveal obvious clusters. Consider 3-letter abbreviations for drugs if you want to decrease the size of the text label (there are pretty standard 3-letter abbreviations for epilepsy drugs, we would have to create 3-letter abbreviations for the other drugs, CBZ: Carbamazepine, LTG: Lamotrigine, OXC: oxcarbazpine, VPA: sodium valproate, TPM: Topiramate, CLB: clobazam, GBP: gabapentin, LEV: levetiracetam, PHT: Phenytoin, TGM: tiagabine, ZON: zonisamide, PGN: pregabalin, ESM: Ethosuximide, CLN: clonazepam, RUF: rufinamide, VGB: vigabatrin).\r\n\r\nHope @sergiobaranzini and/or @alexanderpico can help with the visualization.",
      "comment_id": 1474,
      "profile_id": 188,
      "published": "2017-01-24T19:22:56.308575Z",
      "thread_id": 230,
      "url": "/discussion/visualizing-the-top-epilepsy-predictions-in-cytoscape/230#4"
    },
    {
      "body_html": "<p>In terms of Cytoscape tips, you're on the right track with enhancedGraphics. There is a new version coming soon that will provide more label options as well, like drop-shadows, to make them easier to read on various backgrounds. You can email Scooter at <a href=\"mailto:scooter@cgl.ucsf.edu\">scooter@cgl.ucsf.edu</a> for an advanced copy if you want to try it now.</p>\r\n\r\n<p>Circle charts only work with circle nodes, as far as I understand, so you'll have to compromise between labels inside rectangles and circular data graphics. Alternative would be striped chart within the rectangle that would \"fill\" from left to right per the contribution to the prediction, i.e., in 3-5 stages (depending on what your data look like).</p>\r\n\r\n<p>I would shy away from showing compound structures for <em>all</em> the nodes in this example, since there are so many. If it make sense, you could show selected structures to make particular points.</p>",
      "body_md": "In terms of Cytoscape tips, you're on the right track with enhancedGraphics. There is a new version coming soon that will provide more label options as well, like drop-shadows, to make them easier to read on various backgrounds. You can email Scooter at scooter@cgl.ucsf.edu for an advanced copy if you want to try it now.\r\n\r\nCircle charts only work with circle nodes, as far as I understand, so you'll have to compromise between labels inside rectangles and circular data graphics. Alternative would be striped chart within the rectangle that would \"fill\" from left to right per the contribution to the prediction, i.e., in 3-5 stages (depending on what your data look like).\r\n\r\nI would shy away from showing compound structures for *all* the nodes in this example, since there are so many. If it make sense, you could show selected structures to make particular points.",
      "comment_id": 1475,
      "profile_id": 104,
      "published": "2017-01-24T19:39:06.175804Z",
      "thread_id": 230,
      "url": "/discussion/visualizing-the-top-epilepsy-predictions-in-cytoscape/230#5"
    },
    {
      "body_html": "<h1>HGNC Gene Families</h1>\r\n\r\n<p>HGNC — the authority in charge of human genes — curates a resource of <a href=\"http://www.genenames.org/cgi-bin/genefamilies/\">gene families</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1186/s40246-016-0062-6\" class=\"citation hm \" data-key=\"10.1186/s40246-016-0062-6\">1</a>]</span>. Families are described as follows <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkw1033\" class=\"citation hm \" data-key=\"10.1093/nar/gkw1033\">2</a>]</span>:</p>\r\n\r\n<blockquote><p>Genes are grouped into families based on homology or a shared characteristic such as a common function and/or phenotype, or membership of a complex.</p></blockquote>\r\n\r\n<p>These gene families are a helpful resource for grouping genes together. For example, <em>GRIA2</em> (glutamate ionotropic receptor AMPA type subunit 2) and <em>GRIN2C</em> (glutamate ionotropic receptor NMDA type subunit 2C) both belong to the \"<a href=\"http://www.genenames.org/cgi-bin/genefamilies/set/282\">Glutamate receptors</a>\" family.</p>\r\n\r\n<p>I created the <a href=\"https://github.com/dhimmel/hgnc\"><code>dhimmel/hgnc</code></a> repository to annotate Entrez Genes with their corresponding HGNC gene families (<a href=\"https://github.com/dhimmel/hgnc/tree/fd79a33e8308a419b6c75a0ade0e878620d26ca0\">versioned repo link</a>).</p>\r\n\r\n<p>Gene families in HGNC are arranged into a hierarchy. I'd venture to call it an ontology, but I haven't seen HGNC use that term. The network of families is a directed acyclic graph. Families can have multiple superfamilies. For example \"<a href=\"http://www.genenames.org/cgi-bin/genefamilies/set/284\">Glutamate ionotropic receptors</a>\" is a subfamily of \"Glutamate receptors\" and \"Ligand gated ion channels\". Note there is no single root family. Instead there are many disconnected family hierarchies, i.e. few families are more general than \"Ion channels\".</p>\r\n\r\n<p>Genes can be directly annotated to multiple families. For example, <em>AAAS</em> (aladin WD repeat nucleoporin) belongs to the \"Nucleoporins\" and \"WD repeat domain containing\" families. In addition to direct family annotations, <code>dhimmel/hgnc</code> propagates annotations so that genes belonging to \"Glutamate metabotropic receptors\" also belong to \"Glutamate receptors\".</p>",
      "body_md": "# HGNC Gene Families\r\n\r\nHGNC -- the authority in charge of human genes -- curates a resource of [gene families](http://www.genenames.org/cgi-bin/genefamilies/) [@10.1186/s40246-016-0062-6]. Families are described as follows [@10.1093/nar/gkw1033]:\r\n\r\n> Genes are grouped into families based on homology or a shared characteristic such as a common function and/or phenotype, or membership of a complex.\r\n\r\nThese gene families are a helpful resource for grouping genes together. For example, _GRIA2_ (glutamate ionotropic receptor AMPA type subunit 2) and _GRIN2C_ (glutamate ionotropic receptor NMDA type subunit 2C) both belong to the \"[Glutamate receptors](http://www.genenames.org/cgi-bin/genefamilies/set/282)\" family.\r\n\r\nI created the [`dhimmel/hgnc`](https://github.com/dhimmel/hgnc) repository to annotate Entrez Genes with their corresponding HGNC gene families ([versioned repo link](https://github.com/dhimmel/hgnc/tree/fd79a33e8308a419b6c75a0ade0e878620d26ca0)).\r\n\r\nGene families in HGNC are arranged into a hierarchy. I'd venture to call it an ontology, but I haven't seen HGNC use that term. The network of families is a directed acyclic graph. Families can have multiple superfamilies. For example \"[Glutamate ionotropic receptors](http://www.genenames.org/cgi-bin/genefamilies/set/284)\" is a subfamily of \"Glutamate receptors\" and \"Ligand gated ion channels\". Note there is no single root family. Instead there are many disconnected family hierarchies, i.e. few families are more general than \"Ion channels\".\r\n\r\nGenes can be directly annotated to multiple families. For example, _AAAS_ (aladin WD repeat nucleoporin) belongs to the \"Nucleoporins\" and \"WD repeat domain containing\" families. In addition to direct family annotations, `dhimmel/hgnc` propagates annotations so that genes belonging to \"Glutamate metabotropic receptors\" also belong to \"Glutamate receptors\".",
      "comment_id": 1476,
      "profile_id": 17,
      "published": "2017-01-26T19:58:12.422911Z",
      "thread_id": 34,
      "url": "/discussion/using-entrez-gene-as-our-gene-vocabulary/34#13"
    },
    {
      "body_html": "<h1>Version 2 with target piecharts</h1>\r\n\r\n<p>Thanks <a href=\"/u/alexanderpico\" class=\"username\">@alexanderpico</a> and <a href=\"/u/pouyakhankhanian\" class=\"username\">@pouyakhankhanian</a> for the feedback. Here's the latest version that shows the normalized contribution of each target (gene group) to the prediction. It's way more informative and interesting than before (and hopefully still legible)!</p>\r\n\r\n<p><img src=\"https://github.com/dhimmel/rephetio/raw/3f3e6ecb7a9b8bb64cde76ac8176d31fc19fdc42/epilepsy/figure/compound-network/compound-network.png\" alt=\"Predicted epilepsy compound network\"></p>\r\n\r\n<p>Making the legend was a pain. I had to first choose colors, which I selected from <a href=\"https://github.com/d3/d3-scale/blob/2225fe65f3b0aa2c76588d78a18e4412adfc5795/README.md#schemeCategory10\">d3's category10</a>. Then I manually applied the colors to the Cytoscape chart options. However, I couldn't generate the legend in Cytoscape, so I used <code>ggplot2</code> in R and pieced together the SVG exports in Inkscape. So lot's of opportunity for errors and difficult to automate.</p>\r\n\r\n<blockquote><p>Alternative would be striped chart within the rectangle that would \"fill\" from left to right per the contribution to the prediction</p></blockquote>\r\n\r\n<p><a href=\"/u/alexanderpico\" class=\"username\">@alexanderpico</a> great idea regarding a striped chart within the node. Unfortunately, I couldn't find any other good properties besides fill color for representing the compound's effect on ictogenesis, which the striped chart would displace.</p>\r\n\r\n<blockquote><p>In particular, I'd want to see if there is some clustering of drugs based on what gene target they act one.</p></blockquote>\r\n\r\n<p><a href=\"/u/pouyakhankhanian\" class=\"username\">@pouyakhankhanian</a> hopefully this is now within reach. The raw data for the piecharts is available in <a href=\"https://github.com/dhimmel/rephetio/blob/3f3e6ecb7a9b8bb64cde76ac8176d31fc19fdc42/epilepsy/figure/compound-network/target-contributions-wide.tsv\"><code>target-contributions-wide.tsv</code></a> if anything is hard to see in the network. </p>\r\n\r\n<p>I manually laid out disconnected compounds. The visualization could be improved by placing similar compounds together. For example, I placed sevoflurane with the other halogenated ethers even though it's chemical similarity was not strong enough to have any <em>resembles</em> relationships. So <a href=\"/u/pouyakhankhanian\" class=\"username\">@pouyakhankhanian</a>, feel free to play with the <a href=\"https://github.com/dhimmel/rephetio/blob/3f3e6ecb7a9b8bb64cde76ac8176d31fc19fdc42/epilepsy/figure/compound-network/compound-network.cys\">cytoscape session</a> to help organize things.</p>",
      "body_md": "# Version 2 with target piecharts\r\n\r\nThanks @alexanderpico and @pouyakhankhanian for the feedback. Here's the latest version that shows the normalized contribution of each target (gene group) to the prediction. It's way more informative and interesting than before (and hopefully still legible)!\r\n\r\n![Predicted epilepsy compound network](https://github.com/dhimmel/rephetio/raw/3f3e6ecb7a9b8bb64cde76ac8176d31fc19fdc42/epilepsy/figure/compound-network/compound-network.png)\r\n\r\nMaking the legend was a pain. I had to first choose colors, which I selected from [d3's category10](https://github.com/d3/d3-scale/blob/2225fe65f3b0aa2c76588d78a18e4412adfc5795/README.md#schemeCategory10). Then I manually applied the colors to the Cytoscape chart options. However, I couldn't generate the legend in Cytoscape, so I used `ggplot2` in R and pieced together the SVG exports in Inkscape. So lot's of opportunity for errors and difficult to automate.\r\n\r\n> Alternative would be striped chart within the rectangle that would \"fill\" from left to right per the contribution to the prediction\r\n\r\n@alexanderpico great idea regarding a striped chart within the node. Unfortunately, I couldn't find any other good properties besides fill color for representing the compound's effect on ictogenesis, which the striped chart would displace.\r\n\r\n> In particular, I'd want to see if there is some clustering of drugs based on what gene target they act one.\r\n\r\n@pouyakhankhanian hopefully this is now within reach. The raw data for the piecharts is available in [`target-contributions-wide.tsv`](https://github.com/dhimmel/rephetio/blob/3f3e6ecb7a9b8bb64cde76ac8176d31fc19fdc42/epilepsy/figure/compound-network/target-contributions-wide.tsv) if anything is hard to see in the network. \r\n\r\nI manually laid out disconnected compounds. The visualization could be improved by placing similar compounds together. For example, I placed sevoflurane with the other halogenated ethers even though it's chemical similarity was not strong enough to have any _resembles_ relationships. So @pouyakhankhanian, feel free to play with the [cytoscape session](https://github.com/dhimmel/rephetio/blob/3f3e6ecb7a9b8bb64cde76ac8176d31fc19fdc42/epilepsy/figure/compound-network/compound-network.cys) to help organize things.",
      "comment_id": 1477,
      "profile_id": 17,
      "published": "2017-01-26T21:48:46.584505Z",
      "thread_id": 230,
      "url": "/discussion/visualizing-the-top-epilepsy-predictions-in-cytoscape/230#6"
    },
    {
      "body_html": "<h1>Cytoscape in the web browser?</h1>\r\n\r\n<p>Obviousely, having the above visualization as an interactive web visualization would be super cool and useful. I've heard about <a href=\"http://js.cytoscape.org/\">cytoscape.js</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/bioinformatics/btv557\" class=\"citation hm \" data-key=\"10.1093/bioinformatics/btv557\">1</a>]</span> which is designed for this purpose. Hence, I exported the visualization from Cytoscape to a webpage <span class=\"citation\">[<a href=\"https://doi.org/10.12688/f1000research.4510.2\" class=\"citation hm \" data-key=\"10.12688/f1000research.4510.2\">2</a>]</span> with the commands:</p>\r\n\r\n<blockquote><p>File &gt; Export &gt; Network View(s) as Web Page</p></blockquote>\r\n\r\n<p>After unzipping the export, I launched a webserver using Python 3 (<code>python -m http.server</code>). The resulting webpage, hosted locally, showed an interactive version of the <a href=\"#2\">initial graph</a>. Awesome! Unfortunately, the pie charts were not included in the visualization.</p>\r\n\r\n<p>One final feature I'd like to implement that cytoscape.js may support is node hyperlinks. So for example, clicking the Isocarboxazid node would <a href=\"https://neo4j.het.io/browser/?cmd=play&amp;arg=https://neo4j.het.io/guides/rep/DB01247/DOID_1826.html\" title=\"Hetionet Neo4j Browser. Does Isocarboxazid treat epilepsy syndrome?\">navigate you here</a>. Scripted editing of the SVG may also be a viable <a href=\"http://bl.ocks.org/d3noob/8150631\" title=\"Adding links to objects\">option here</a>.</p>",
      "body_md": "# Cytoscape in the web browser?\r\n\r\nObviousely, having the above visualization as an interactive web visualization would be super cool and useful. I've heard about [cytoscape.js](http://js.cytoscape.org/) [@10.1093/bioinformatics/btv557] which is designed for this purpose. Hence, I exported the visualization from Cytoscape to a webpage [@10.12688/f1000research.4510.2] with the commands:\r\n\r\n> File > Export > Network View(s) as Web Page\r\n\r\nAfter unzipping the export, I launched a webserver using Python 3 (`python -m http.server`). The resulting webpage, hosted locally, showed an interactive version of the [initial graph](#2). Awesome! Unfortunately, the pie charts were not included in the visualization.\r\n\r\nOne final feature I'd like to implement that cytoscape.js may support is node hyperlinks. So for example, clicking the Isocarboxazid node would [navigate you here](https://neo4j.het.io/browser/?cmd=play&arg=https://neo4j.het.io/guides/rep/DB01247/DOID_1826.html \"Hetionet Neo4j Browser. Does Isocarboxazid treat epilepsy syndrome?\"). Scripted editing of the SVG may also be a viable [option here](http://bl.ocks.org/d3noob/8150631 \"Adding links to objects\").",
      "comment_id": 1478,
      "profile_id": 17,
      "published": "2017-01-26T22:09:01.578683Z",
      "thread_id": 230,
      "url": "/discussion/visualizing-the-top-epilepsy-predictions-in-cytoscape/230#7"
    },
    {
      "body_html": "<p>It's incredibly busy but I really do find it quite informative. The big benzo cluster on the upper right is clearly GABA heavy. The other big cluster is the barbituate cluster on the bottom, just left of center. This cluster is GABA/glutamate/Choline heavy. The halogentated ethers on the bottom right (I guess sevoflurane was not connected but moved closer for clarity) are also interesting, they seem to have potassium channels in common as well as GABA.</p>\r\n\r\n<p>Perhaps one of the most interesting clusters is the TCA (tricyclic antidepressant) cluster. We can tell they are ictogenic because they are shaded pink. It's interesting that these seem to share the CYP genes in common. Recall that CYP genes are actually not mechanistically related to epilepsy, but it just so happens that many seizure meds interact with the CYP protein. I'm a little surprised that there is not as much GABA in this cluster. </p>\r\n\r\n<p>The carbonic anhydrase inhibitors are clustered and are associated with the carbonic anhydrase proteins as expected.</p>\r\n\r\n<p>One very note-worthy thing is that the hetionet was not a prior \"aware\" of all these genes that are associated with epilepsy (i.e. there was no direct gene-disease connection in the network for most of these genes), and yet it still used these epilepsy genes to make it's predictions. The likely reason that genes associated with epilepsy were not connected to epilepsy via a gene-disease connection is because these are very rare mutations, most of these genes have been reported in only a handful of people. <a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a> any thoughts about using this network for gene discovery? (sounds like a rabbit-hole though)</p>",
      "body_md": "It's incredibly busy but I really do find it quite informative. The big benzo cluster on the upper right is clearly GABA heavy. The other big cluster is the barbituate cluster on the bottom, just left of center. This cluster is GABA/glutamate/Choline heavy. The halogentated ethers on the bottom right (I guess sevoflurane was not connected but moved closer for clarity) are also interesting, they seem to have potassium channels in common as well as GABA.\r\n\r\nPerhaps one of the most interesting clusters is the TCA (tricyclic antidepressant) cluster. We can tell they are ictogenic because they are shaded pink. It's interesting that these seem to share the CYP genes in common. Recall that CYP genes are actually not mechanistically related to epilepsy, but it just so happens that many seizure meds interact with the CYP protein. I'm a little surprised that there is not as much GABA in this cluster. \r\n\r\nThe carbonic anhydrase inhibitors are clustered and are associated with the carbonic anhydrase proteins as expected.\r\n\r\nOne very note-worthy thing is that the hetionet was not a prior \"aware\" of all these genes that are associated with epilepsy (i.e. there was no direct gene-disease connection in the network for most of these genes), and yet it still used these epilepsy genes to make it's predictions. The likely reason that genes associated with epilepsy were not connected to epilepsy via a gene-disease connection is because these are very rare mutations, most of these genes have been reported in only a handful of people. @dhimmel any thoughts about using this network for gene discovery? (sounds like a rabbit-hole though)",
      "comment_id": 1479,
      "profile_id": 188,
      "published": "2017-01-26T22:39:07.293325Z",
      "thread_id": 230,
      "url": "/discussion/visualizing-the-top-epilepsy-predictions-in-cytoscape/230#8"
    },
    {
      "body_html": "<p>I have made an alternative suggestion for the pie chart figure:</p>\r\n\r\n<p><img src=\"https://cloud.githubusercontent.com/assets/1117703/22377022/557b3946-e47e-11e6-957f-0130ada2f6ca.png\" alt=\"compound-network-ljj\"><br>What I changed was to make the nodes be just the pie charts, move the text labels to not be on top of the pie charts (to improve readability), recolor the pie charts using a color scale from ColorBrewer, and reduce edge width to reduce clutter.</p>",
      "body_md": "I have made an alternative suggestion for the pie chart figure:\r\n\r\n![compound-network-ljj](https://cloud.githubusercontent.com/assets/1117703/22377022/557b3946-e47e-11e6-957f-0130ada2f6ca.png)\r\nWhat I changed was to make the nodes be just the pie charts, move the text labels to not be on top of the pie charts (to improve readability), recolor the pie charts using a color scale from ColorBrewer, and reduce edge width to reduce clutter.",
      "comment_id": 1480,
      "profile_id": 125,
      "published": "2017-01-27T07:19:06.515982Z",
      "thread_id": 230,
      "url": "/discussion/visualizing-the-top-epilepsy-predictions-in-cytoscape/230#9"
    },
    {
      "body_html": "<p><a href=\"/u/larsjuhljensen\" class=\"username\">@larsjuhljensen</a> thanks for the suggestions. I'm excited about reducing clutter and improving readability. Stay tuned for a version that incorporates your modifications.</p>\r\n\r\n<blockquote><p>there was no direct gene-disease connection in the network for most of these genes</p></blockquote>\r\n\r\n<p><a href=\"/u/pouyakhankhanian\" class=\"username\">@pouyakhankhanian</a>, I'm not so sure about this. You can run the following query at <a href=\"https://neo4j.het.io\">https://neo4j.het.io</a> to see all epilepsy-associated genes in Hetionet v1.0.</p>\r\n\r\n<pre><code class=\"no-highlight hljs\">MATCH (disease:Disease)-[assoc:ASSOCIATES_DaG]-(gene:Gene)\r\nWHERE disease.name = 'epilepsy syndrome'\r\nRETURN\r\n  gene.name AS gene_symbol,\r\n  gene.description AS gene_name,\r\n  assoc.sources AS sources\r\n ORDER BY gene_symbol</code></pre>\r\n\r\n<p>I suspect these 399 associations contain many of the \"very rare mutations … reported in only a handful of people\" that you're thinking of. Quoting <a href=\"https://thinklab.com/p/rephetio/report\">our report</a>:</p>\r\n\r\n<blockquote><p><em>Disease–associates–Gene</em> edges were extracted from the GWAS Catalog <span class=\"citation\">[<a href=\"https://doi.org/10.5281/zenodo.48428\" class=\"citation hm citation-figure\" data-key=\"10.5281/zenodo.48428\">1</a>]</span>, DISEASES <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d106\" class=\"citation hm citation-self\" data-key=\"10.15363/thinklab.d106\">2</a>, <a href=\"https://doi.org/10.5281/zenodo.48425\" class=\"citation hm citation-figure\" data-key=\"10.5281/zenodo.48425\">3</a>]</span>, DisGeNET <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d105\" class=\"citation hm citation-self\" data-key=\"10.15363/thinklab.d105\">4</a>, <a href=\"https://doi.org/10.5281/zenodo.48426\" class=\"citation hm citation-figure\" data-key=\"10.5281/zenodo.48426\">5</a>]</span>, and DOAF <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d94\" class=\"citation hm citation-self\" data-key=\"10.15363/thinklab.d94\">6</a>, <a href=\"https://doi.org/10.5281/zenodo.48427\" class=\"citation hm citation-figure\" data-key=\"10.5281/zenodo.48427\">7</a>]</span>.</p></blockquote>\r\n\r\n<p>I think DISEASES, DisGeNET, and possibly DOAF are capable of containing associations based on rare mutations that were discovered prior to ~2015.</p>\r\n\r\n<p>Another way we can approach the issue is by looking at the contribution of <em>Epilepsy–associates–Gene</em> (target edges) on our top 100 predictions. <a href=\"https://github.com/dhimmel/rephetio/blob/3f3e6ecb7a9b8bb64cde76ac8176d31fc19fdc42/epilepsy/data/target-edge-associates-contributions.tsv\">This table</a> shows how much each gene group that was associated with epilepsy contributed to the top predictions. The gene groups with contributions greater than 1% are shown below:</p>\r\n\r\n<table class=\"table markdown-table\"><thead><tr><th>Gene Group</th><th>Paths</th><th>Contribution</th><th>Genes</th></tr></thead><tbody><tr><td>gamma-aminobutyric acid (GABA) A receptor</td><td>23347</td><td>6.834</td><td>GABRA1, GABRA5, GABRB2, GABRB3, GABRD, GABRG2</td></tr><tr><td>glutamate receptor</td><td>20142</td><td>2.2849</td><td>GRIA1, GRIA2, GRIA4, GRIK1, GRIK2, GRIK5, GRIN2A, GRIN2B, GRM1, GRM2, GRM3, GRM4, GRM5, GRM8</td></tr><tr><td>sodium channel</td><td>2678</td><td>2.1133</td><td>SCN1A, SCN1B, SCN2A, SCN3A, SCN4A, SCN8A, SCN9A</td></tr><tr><td>calcium channel</td><td>10209</td><td>1.5873</td><td>CACNA1A, CACNA1D, CACNA1G, CACNA1H, CACNA2D2, CACNB4, CACNG2, CACNG3</td></tr><tr><td>potassium channel</td><td>15467</td><td>1.547</td><td>KCNAB2, KCNB1, KCNC1, KCNC4, KCND2, KCNH1, KCNJ10, KCNJ11, KCNK3, KCNK9, KCNMA1, KCNQ2, KCNQ3, KCNQ4, KCNV1</td></tr><tr><td>cholinergic receptor</td><td>13397</td><td>1.5254</td><td>CHRM1, CHRM2, CHRM3, CHRNA2, CHRNA4, CHRNA7, CHRNB2</td></tr><tr><td>cytochrome P450</td><td>9365</td><td>1.1146</td><td>CYP11A1, CYP2C19, CYP2D6</td></tr><tr><td>carbonic anhydrase</td><td>1268</td><td>0.79162</td><td>CA13, CA4</td></tr></tbody></table>\r\n\r\n<p>These are the same gene groups as the <a href=\"https://thinklab.com/discussion/prediction-in-epilepsy/224#11\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d224\">source edge analysis identified</a>. However, in this list, the cytochrome P450 family is demoted, as it's the only group that's not mechanistically related to epilepsy pathophysiology.</p>",
      "body_md": "@larsjuhljensen thanks for the suggestions. I'm excited about reducing clutter and improving readability. Stay tuned for a version that incorporates your modifications.\r\n\r\n> there was no direct gene-disease connection in the network for most of these genes\r\n\r\n@pouyakhankhanian, I'm not so sure about this. You can run the following query at https://neo4j.het.io to see all epilepsy-associated genes in Hetionet v1.0.\r\n\r\n```cypher\r\nMATCH (disease:Disease)-[assoc:ASSOCIATES_DaG]-(gene:Gene)\r\nWHERE disease.name = 'epilepsy syndrome'\r\nRETURN\r\n  gene.name AS gene_symbol,\r\n  gene.description AS gene_name,\r\n  assoc.sources AS sources\r\n ORDER BY gene_symbol\r\n```\r\n\r\nI suspect these 399 associations contain many of the \"very rare mutations … reported in only a handful of people\" that you're thinking of. Quoting [our report](https://thinklab.com/p/rephetio/report):\r\n\r\n> _Disease–associates–Gene_ edges were extracted from the GWAS Catalog [@10.5281/zenodo.48428], DISEASES [@10.15363/thinklab.d106 @10.5281/zenodo.48425], DisGeNET [@10.15363/thinklab.d105 @10.5281/zenodo.48426], and DOAF [@10.15363/thinklab.d94 @10.5281/zenodo.48427].\r\n\r\nI think DISEASES, DisGeNET, and possibly DOAF are capable of containing associations based on rare mutations that were discovered prior to ~2015.\r\n\r\nAnother way we can approach the issue is by looking at the contribution of _Epilepsy–associates–Gene_ (target edges) on our top 100 predictions. [This table](https://github.com/dhimmel/rephetio/blob/3f3e6ecb7a9b8bb64cde76ac8176d31fc19fdc42/epilepsy/data/target-edge-associates-contributions.tsv) shows how much each gene group that was associated with epilepsy contributed to the top predictions. The gene groups with contributions greater than 1% are shown below:\r\n\r\n| Gene Group | Paths | Contribution | Genes |\r\n|--------------------|-------|--------------|---------------------|\r\n| gamma-aminobutyric acid (GABA) A receptor | 23347 | 6.834 | GABRA1, GABRA5, GABRB2, GABRB3, GABRD, GABRG2 |\r\n| glutamate receptor | 20142 | 2.2849 | GRIA1, GRIA2, GRIA4, GRIK1, GRIK2, GRIK5, GRIN2A, GRIN2B, GRM1, GRM2, GRM3, GRM4, GRM5, GRM8 |\r\n| sodium channel | 2678 | 2.1133 | SCN1A, SCN1B, SCN2A, SCN3A, SCN4A, SCN8A, SCN9A |\r\n| calcium channel | 10209 | 1.5873 | CACNA1A, CACNA1D, CACNA1G, CACNA1H, CACNA2D2, CACNB4, CACNG2, CACNG3 |\r\n| potassium channel | 15467 | 1.547 | KCNAB2, KCNB1, KCNC1, KCNC4, KCND2, KCNH1, KCNJ10, KCNJ11, KCNK3, KCNK9, KCNMA1, KCNQ2, KCNQ3, KCNQ4, KCNV1 |\r\n| cholinergic receptor | 13397 | 1.5254 | CHRM1, CHRM2, CHRM3, CHRNA2, CHRNA4, CHRNA7, CHRNB2 |\r\n| cytochrome P450 | 9365 | 1.1146 | CYP11A1, CYP2C19, CYP2D6 |\r\n| carbonic anhydrase | 1268 | 0.79162 | CA13, CA4 |\r\n\r\nThese are the same gene groups as the [source edge analysis identified](https://thinklab.com/discussion/prediction-in-epilepsy/224#11). However, in this list, the cytochrome P450 family is demoted, as it's the only group that's not mechanistically related to epilepsy pathophysiology.",
      "comment_id": 1481,
      "profile_id": 17,
      "published": "2017-01-27T16:38:05.361393Z",
      "thread_id": 230,
      "url": "/discussion/visualizing-the-top-epilepsy-predictions-in-cytoscape/230#10"
    },
    {
      "body_html": "<h1>Version 3 to decrease clutter</h1>\r\n\r\n<p>Based on <a href=\"/u/larsjuhljensen\" class=\"username\">@larsjuhljensen</a> <a href=\"#9\">suggestions</a>, I created the next iteration of the visualization (<a href=\"https://github.com/dhimmel/rephetio/blob/f969a7356e54dfdc2659cefbaec937fc0d0f6c4d/epilepsy/figure/compound-network/compound-network.cys\"><code>compound-network.cys</code></a>):</p>\r\n\r\n<p><img src=\"https://github.com/dhimmel/rephetio/raw/f969a7356e54dfdc2659cefbaec937fc0d0f6c4d/epilepsy/figure/compound-network/compound-network.png\" alt=\"Top epilepsy prediction viz\"></p>\r\n\r\n<p>Nodes are now entirely their target-contribution piechart. Ditching the rounded rectangles and moving the text atop nodes saved space. The compound names will still be small but should be readable at printout size. I moved the effect on ictogenesis to the node border, since I think this information is crucial.</p>\r\n\r\n<p>I also moved the disconnected nodes around to put similar compounds (either by name or target contributions) together.</p>\r\n\r\n<p>Of course, suggestions still welcome.</p>",
      "body_md": "# Version 3 to decrease clutter\r\n\r\nBased on @larsjuhljensen [suggestions](#9), I created the next iteration of the visualization ([`compound-network.cys`](https://github.com/dhimmel/rephetio/blob/f969a7356e54dfdc2659cefbaec937fc0d0f6c4d/epilepsy/figure/compound-network/compound-network.cys)):\r\n\r\n![Top epilepsy prediction viz](https://github.com/dhimmel/rephetio/raw/f969a7356e54dfdc2659cefbaec937fc0d0f6c4d/epilepsy/figure/compound-network/compound-network.png)\r\n\r\nNodes are now entirely their target-contribution piechart. Ditching the rounded rectangles and moving the text atop nodes saved space. The compound names will still be small but should be readable at printout size. I moved the effect on ictogenesis to the node border, since I think this information is crucial.\r\n\r\nI also moved the disconnected nodes around to put similar compounds (either by name or target contributions) together.\r\n\r\nOf course, suggestions still welcome.",
      "comment_id": 1482,
      "profile_id": 17,
      "published": "2017-01-27T23:10:29.107285Z",
      "thread_id": 230,
      "url": "/discussion/visualizing-the-top-epilepsy-predictions-in-cytoscape/230#11"
    },
    {
      "body_html": "<p>I find it is too packed and that it is thus hard to spot clusters because there are nodes everywhere. I would make the figure taller to get some more real estate and rearrange the nodes so that there is some free space between your clusters. There is an element of horror vacui to this visualization; white space should be your friend.</p>\r\n\r\n<p>And sorry to be so negative, but I still find the figure to overloaded in terms of visual properties. Maybe the effect on ictogenesis is important to show, but in that case you'll have to remove something else. Right now, by attempting to show everything at the same time, you in my opinion effectively end up showing nothing.</p>\r\n\r\n<p>Here are some questions to consider for improving the figure further:</p>\r\n\r\n<ul><li>What is the main conclusion that you want people to draw from looking at this figure?</li><li>You have two types of effect on ictogenesis coded in light blue and light red. Are both equally important? If not, could you maybe just highlight the one that is important?</li><li>Part of what makes this hard to look at is the number of target classes. By having so many classes, you use up a lot of color space, making it hard to show anything else. Could some classes be left out? Could some be combined (e.g. calcium channels + potassium channels + sodium channels = cation channels)?</li><li>Are the relevant target classes shown? When I try to find the target class that best discriminates between nodes with red circles and nodes with blue circles, it appears to be the class \"other\". This suggests to me that, despite showing so much, you are in fact not showing what matters most.</li><li>And last but certainly not least: are you sure this should even be shown as a network? Your focus seems to be all kinds of properties of the nodes, whereas the edges barely matter, except for showing that there are certain groups of chemically similar compounds. Simply categorizing the compounds might be a much better way to represent this.</li></ul>\r\n\r\n<p>Just trying to be constructive here.</p>",
      "body_md": "I find it is too packed and that it is thus hard to spot clusters because there are nodes everywhere. I would make the figure taller to get some more real estate and rearrange the nodes so that there is some free space between your clusters. There is an element of horror vacui to this visualization; white space should be your friend.\r\n\r\nAnd sorry to be so negative, but I still find the figure to overloaded in terms of visual properties. Maybe the effect on ictogenesis is important to show, but in that case you'll have to remove something else. Right now, by attempting to show everything at the same time, you in my opinion effectively end up showing nothing.\r\n\r\nHere are some questions to consider for improving the figure further:\r\n\r\n - What is the main conclusion that you want people to draw from looking at this figure?\r\n - You have two types of effect on ictogenesis coded in light blue and light red. Are both equally important? If not, could you maybe just highlight the one that is important?\r\n - Part of what makes this hard to look at is the number of target classes. By having so many classes, you use up a lot of color space, making it hard to show anything else. Could some classes be left out? Could some be combined (e.g. calcium channels + potassium channels + sodium channels = cation channels)?\r\n - Are the relevant target classes shown? When I try to find the target class that best discriminates between nodes with red circles and nodes with blue circles, it appears to be the class \"other\". This suggests to me that, despite showing so much, you are in fact not showing what matters most.\r\n - And last but certainly not least: are you sure this should even be shown as a network? Your focus seems to be all kinds of properties of the nodes, whereas the edges barely matter, except for showing that there are certain groups of chemically similar compounds. Simply categorizing the compounds might be a much better way to represent this.\r\n\r\nJust trying to be constructive here.",
      "comment_id": 1483,
      "profile_id": 125,
      "published": "2017-01-28T06:57:03.299577Z",
      "thread_id": 230,
      "url": "/discussion/visualizing-the-top-epilepsy-predictions-in-cytoscape/230#12"
    },
    {
      "body_html": "<p>Sorry to be late to the discussion!  One thing you may want to try is using an edge-weighted layout like the one below.  I added the 2D structure diagrams using chemViz2, as an example, but I frankly wouldn't recommend it — I think that the pie charts are more informative and you would have to zoom in pretty far to be able to see any of the differences in the compound structures.  The edge-weighted layout does show some subtlety that is lost on the more compact representation IMHO, but at the cost of reduced visibility of individual nodes.<br><img src=\"http://www.cgl.ucsf.edu/home/scooter/chemical-similarity.png\" alt=\"Edge Weighted Version\" title=\"Edge Weighted\"></p>",
      "body_md": "Sorry to be late to the discussion!  One thing you may want to try is using an edge-weighted layout like the one below.  I added the 2D structure diagrams using chemViz2, as an example, but I frankly wouldn't recommend it -- I think that the pie charts are more informative and you would have to zoom in pretty far to be able to see any of the differences in the compound structures.  The edge-weighted layout does show some subtlety that is lost on the more compact representation IMHO, but at the cost of reduced visibility of individual nodes.\r\n![Edge Weighted Version](http://www.cgl.ucsf.edu/home/scooter/chemical-similarity.png \"Edge Weighted\")",
      "comment_id": 1484,
      "profile_id": 323,
      "published": "2017-01-30T04:09:42.787425Z",
      "thread_id": 230,
      "url": "/discussion/visualizing-the-top-epilepsy-predictions-in-cytoscape/230#13"
    },
    {
      "body_html": "<h1>Version 4 three panel format</h1>\r\n\r\n<p>Thanks <a href=\"/u/larsjuhljensen\" class=\"username\">@larsjuhljensen</a> and <a href=\"/u/scootermorris\" class=\"username\">@scootermorris</a> for the help. Your comments help guide this iteration. Unfortunately, I have little more time to work on this visualization, so while I'll appreciate more suggestions, I may not incorporate them here (although they'll guide my future thinking).</p>\r\n\r\n<p>The new version contains three panels (<a href=\"https://github.com/dhimmel/rephetio/blob/54ce1bacfe6392c04d6afd164df7718a0d2769b3/epilepsy/figure/combined/compound-network-combined.pdf\">pdf</a>, <a href=\"https://github.com/dhimmel/rephetio/blob/54ce1bacfe6392c04d6afd164df7718a0d2769b3/epilepsy/figure/compound-network/compound-network.cys\">session</a>). Panel A shows the ranked top 100 epilepsy predictions, colored by their effect on ictogenesis (<a href=\"https://thinklab.com/doc/7/review#section-31\">more info</a>). The curve denotes the predicted probability of treatment. Panel B shows the structural similarity network for these compounds with structures drawn. Panel C is the same network and layout as Panel B, but shows target contributions as pie charts.</p>\r\n\r\n<p><img src=\"https://github.com/dhimmel/rephetio/raw/54ce1bacfe6392c04d6afd164df7718a0d2769b3/epilepsy/figure/combined/compound-network-combined.png\" alt=\"compound-network-combined\"></p>\r\n\r\n<p>Thanks <a href=\"/u/scootermorris\" class=\"username\">@scootermorris</a> for having made <a href=\"http://apps.cytoscape.org/apps/layoutsaver\">layoutSaver</a>, which saved me lot's of time by syncing the node positions between the structure and target networks.</p>\r\n\r\n<p><a href=\"/u/larsjuhljensen\" class=\"username\">@larsjuhljensen</a> call me a kenophobe 😉, but I do think minimizing space usage, especially with this monstrosity, is important. I agree that the extra space and grid alignment of <a href=\"https://thinklab.com/discussion/visualizing-the-top-epilepsy-predictions-in-cytoscape/230#9\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d230\">your figure</a> improve the aesthetics and readability. However, I couldn't achieve the correct dimensionality (printable and readable on a single page) without a bit of horror vacui.</p>\r\n\r\n<blockquote><p>What is the main conclusion that you want people to draw from looking at this figure?</p></blockquote>\r\n\r\n<p>The figure is supposed to provide pharmacological context to our top 100 epilepsy predictions. It's certainly exploratory — there are a few conclusions we'll point out, but I'm hoping the viewer will be able to generate their own observations or questions. In part, this figure helps us answer our own questions as well.</p>\r\n\r\n<blockquote><p>You have two types of effect on ictogenesis coded in light blue and light red. Are both equally important? If not, could you maybe just highlight the one that is important?</p></blockquote>\r\n\r\n<p>All three categories (red, blue, white) are crucial.</p>\r\n\r\n<blockquote><p>Part of what makes this hard to look at is the number of target classes. By having so many classes, you use up a lot of color space, making it hard to show anything else. Could some classes be left out? Could some be combined (e.g. calcium channels + potassium channels + sodium channels = cation channels)?</p></blockquote>\r\n\r\n<p>Something I'll consider. The categories were automatically generated and ordered. I like showing how we detect almost all of the bonafide anticonvulsant targets.</p>\r\n\r\n<blockquote><p>Are the relevant target classes shown? When I try to find the target class that best discriminates between nodes with red circles and nodes with blue circles, it appears to be the class \"other\". This suggests to me that, despite showing so much, you are in fact not showing what matters most.</p></blockquote>\r\n\r\n<p>Still have to look into the ictogenic compounds more in light of this visualization. The fact that our method cannot differentiate the ictogenic compounds is a shortcoming, although one that is important to highlight and that we are comfortable with.</p>\r\n\r\n<blockquote><p>And last but certainly not least: are you sure this should even be shown as a network? Your focus seems to be all kinds of properties of the nodes, whereas the edges barely matter, except for showing that there are certain groups of chemically similar compounds. Simply categorizing the compounds might be a much better way to represent this.</p></blockquote>\r\n\r\n<p>It's not imperative that's its shown as a network. But I do think a 2-dimensional projection of the compounds that places similar compounds together is most effective. A network of chemical structure seemed like the easiest way to get there.</p>",
      "body_md": "# Version 4 three panel format\r\n\r\nThanks @larsjuhljensen and @scootermorris for the help. Your comments help guide this iteration. Unfortunately, I have little more time to work on this visualization, so while I'll appreciate more suggestions, I may not incorporate them here (although they'll guide my future thinking).\r\n\r\nThe new version contains three panels ([pdf](https://github.com/dhimmel/rephetio/blob/54ce1bacfe6392c04d6afd164df7718a0d2769b3/epilepsy/figure/combined/compound-network-combined.pdf), [session](https://github.com/dhimmel/rephetio/blob/54ce1bacfe6392c04d6afd164df7718a0d2769b3/epilepsy/figure/compound-network/compound-network.cys)). Panel A shows the ranked top 100 epilepsy predictions, colored by their effect on ictogenesis ([more info](https://thinklab.com/doc/7/review#section-31)). The curve denotes the predicted probability of treatment. Panel B shows the structural similarity network for these compounds with structures drawn. Panel C is the same network and layout as Panel B, but shows target contributions as pie charts.\r\n\r\n![compound-network-combined](https://github.com/dhimmel/rephetio/raw/54ce1bacfe6392c04d6afd164df7718a0d2769b3/epilepsy/figure/combined/compound-network-combined.png)\r\n\r\nThanks @scootermorris for having made [layoutSaver](http://apps.cytoscape.org/apps/layoutsaver), which saved me lot's of time by syncing the node positions between the structure and target networks.\r\n\r\n@larsjuhljensen call me a kenophobe 😉, but I do think minimizing space usage, especially with this monstrosity, is important. I agree that the extra space and grid alignment of [your figure](https://thinklab.com/discussion/visualizing-the-top-epilepsy-predictions-in-cytoscape/230#9) improve the aesthetics and readability. However, I couldn't achieve the correct dimensionality (printable and readable on a single page) without a bit of horror vacui.\r\n\r\n> What is the main conclusion that you want people to draw from looking at this figure?\r\n\r\nThe figure is supposed to provide pharmacological context to our top 100 epilepsy predictions. It's certainly exploratory -- there are a few conclusions we'll point out, but I'm hoping the viewer will be able to generate their own observations or questions. In part, this figure helps us answer our own questions as well.\r\n\r\n>You have two types of effect on ictogenesis coded in light blue and light red. Are both equally important? If not, could you maybe just highlight the one that is important?\r\n\r\nAll three categories (red, blue, white) are crucial.\r\n\r\n> Part of what makes this hard to look at is the number of target classes. By having so many classes, you use up a lot of color space, making it hard to show anything else. Could some classes be left out? Could some be combined (e.g. calcium channels + potassium channels + sodium channels = cation channels)?\r\n\r\nSomething I'll consider. The categories were automatically generated and ordered. I like showing how we detect almost all of the bonafide anticonvulsant targets.\r\n\r\n> Are the relevant target classes shown? When I try to find the target class that best discriminates between nodes with red circles and nodes with blue circles, it appears to be the class \"other\". This suggests to me that, despite showing so much, you are in fact not showing what matters most.\r\n\r\nStill have to look into the ictogenic compounds more in light of this visualization. The fact that our method cannot differentiate the ictogenic compounds is a shortcoming, although one that is important to highlight and that we are comfortable with.\r\n\r\n> And last but certainly not least: are you sure this should even be shown as a network? Your focus seems to be all kinds of properties of the nodes, whereas the edges barely matter, except for showing that there are certain groups of chemically similar compounds. Simply categorizing the compounds might be a much better way to represent this.\r\n\r\nIt's not imperative that's its shown as a network. But I do think a 2-dimensional projection of the compounds that places similar compounds together is most effective. A network of chemical structure seemed like the easiest way to get there.",
      "comment_id": 1485,
      "profile_id": 17,
      "published": "2017-01-31T01:07:31.634234Z",
      "thread_id": 230,
      "url": "/discussion/visualizing-the-top-epilepsy-predictions-in-cytoscape/230#14"
    },
    {
      "body_html": "<p>The epilepsy section of our <a href=\"https://thinklab.com/doc/7/review#section-34\">initial report</a> states:</p>\r\n\r\n<blockquote><p>As an example, we predicted five tricyclic antidepressants primarily based on their binding to the GABAᴬ receptor.</p></blockquote>\r\n\r\n<p>This statement derived from an <a href=\"https://thinklab.com/discussion/prediction-in-epilepsy/224#2\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d224\">earlier comment</a> that.</p>\r\n\r\n<blockquote><p>The 15 predicted drugs that are known to induce seizures include five are tricyclic antidepressants (TCAs) (amitriptyline, imipramine, nortriptyline, clomipramine, desipramine)</p></blockquote>\r\n\r\n<p>However, our <a href=\"https://thinklab.com/discussion/visualizing-the-top-epilepsy-predictions-in-cytoscape/230#14\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d230\">new visualization</a> of the top epilepsy predictions and their targeted genes makes it clear that binding GABAᴬ isn't the cause of these predictions. For convenience, this visualization is reproduced below:</p>\r\n\r\n<p><img src=\"https://github.com/dhimmel/rephetio/raw/54ce1bacfe6392c04d6afd164df7718a0d2769b3/epilepsy/figure/combined/compound-network-combined.png\" alt=\"Top epilepsy predictions\"></p>\r\n\r\n<p>Specifically, I'm referring to <a href=\"https://neo4j.het.io/browser/?cmd=play&amp;arg=https://neo4j.het.io/guides/rep/DB00321/DOID_1826.html\">amitriptyline</a>, <a href=\"https://neo4j.het.io/browser/?cmd=play&amp;arg=https://neo4j.het.io/guides/rep/DB00543/DOID_1826.html\">amoxapine</a>, <a href=\"https://neo4j.het.io/browser/?cmd=play&amp;arg=https://neo4j.het.io/guides/rep/DB01242/DOID_1826.html\">clomipramine</a>, <a href=\"https://neo4j.het.io/browser/?cmd=play&amp;arg=https://neo4j.het.io/guides/rep/DB00363/DOID_1826.html\">clozapine</a>, <a href=\"https://neo4j.het.io/browser/?cmd=play&amp;arg=https://neo4j.het.io/guides/rep/DB00434/DOID_1826.html\">cyproheptadine</a>, <a href=\"https://neo4j.het.io/browser/?cmd=play&amp;arg=https://neo4j.het.io/guides/rep/DB01151/DOID_1826.html\">desipramine</a>, <a href=\"https://neo4j.het.io/browser/?cmd=play&amp;arg=https://neo4j.het.io/guides/rep/DB00458/DOID_1826.html\">imipramine</a>, <a href=\"https://neo4j.het.io/browser/?cmd=play&amp;arg=https://neo4j.het.io/guides/rep/DB00408/DOID_1826.html\">loxapine</a>, and <a href=\"https://neo4j.het.io/browser/?cmd=play&amp;arg=https://neo4j.het.io/guides/rep/DB00540/DOID_1826.html\">nortriptyline</a>, which all share a tricyclic structure and cluster together in the visualization.</p>",
      "body_md": "The epilepsy section of our [initial report](https://thinklab.com/doc/7/review#section-34) states:\r\n\r\n> As an example, we predicted five tricyclic antidepressants primarily based on their binding to the GABAᴬ receptor.\r\n\r\nThis statement derived from an [earlier comment](https://thinklab.com/discussion/prediction-in-epilepsy/224#2) that.\r\n\r\n> The 15 predicted drugs that are known to induce seizures include five are tricyclic antidepressants (TCAs) (amitriptyline, imipramine, nortriptyline, clomipramine, desipramine)\r\n\r\nHowever, our [new visualization](https://thinklab.com/discussion/visualizing-the-top-epilepsy-predictions-in-cytoscape/230#14) of the top epilepsy predictions and their targeted genes makes it clear that binding GABAᴬ isn't the cause of these predictions. For convenience, this visualization is reproduced below:\r\n\r\n![Top epilepsy predictions](https://github.com/dhimmel/rephetio/raw/54ce1bacfe6392c04d6afd164df7718a0d2769b3/epilepsy/figure/combined/compound-network-combined.png)\r\n\r\nSpecifically, I'm referring to [amitriptyline](https://neo4j.het.io/browser/?cmd=play&arg=https://neo4j.het.io/guides/rep/DB00321/DOID_1826.html), [amoxapine](https://neo4j.het.io/browser/?cmd=play&arg=https://neo4j.het.io/guides/rep/DB00543/DOID_1826.html), [clomipramine](https://neo4j.het.io/browser/?cmd=play&arg=https://neo4j.het.io/guides/rep/DB01242/DOID_1826.html), [clozapine](https://neo4j.het.io/browser/?cmd=play&arg=https://neo4j.het.io/guides/rep/DB00363/DOID_1826.html), [cyproheptadine](https://neo4j.het.io/browser/?cmd=play&arg=https://neo4j.het.io/guides/rep/DB00434/DOID_1826.html), [desipramine](https://neo4j.het.io/browser/?cmd=play&arg=https://neo4j.het.io/guides/rep/DB01151/DOID_1826.html), [imipramine](https://neo4j.het.io/browser/?cmd=play&arg=https://neo4j.het.io/guides/rep/DB00458/DOID_1826.html), [loxapine](https://neo4j.het.io/browser/?cmd=play&arg=https://neo4j.het.io/guides/rep/DB00408/DOID_1826.html), and [nortriptyline](https://neo4j.het.io/browser/?cmd=play&arg=https://neo4j.het.io/guides/rep/DB00540/DOID_1826.html), which all share a tricyclic structure and cluster together in the visualization.",
      "comment_id": 1486,
      "profile_id": 17,
      "published": "2017-01-31T19:43:50.619915Z",
      "thread_id": 231,
      "url": "/discussion/why-we-predicted-ictogenic-tricyclic-compounds-treat-epilepsy/231"
    },
    {
      "body_html": "<h1>Literature survey</h1>\r\n\r\n<p>Below is a collection of related literature, which I may update as the research continuous. The primary questions is why the 9 cyclic compounds listed above are ictogenic.</p>\r\n\r\n<p>From a 2010 article <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.seizure.2009.11.005\" class=\"citation hm \" data-key=\"10.1016/j.seizure.2009.11.005\">1</a>]</span>:</p>\r\n\r\n<blockquote><p>The mechanisms through which antidepressants alter neuronal excitability and modify seizure threshold are still largely unknown. Antidepressants act mainly by blocking the re-uptake of monoamines. Both animal and human data have shown that blocking the re-uptake of norepinephrine and/or serotonin has an anticonvulsant effect <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.yebeh.2005.07.014\" class=\"citation hm \" data-key=\"10.1016/j.yebeh.2005.07.014\">2</a>]</span>. The convulsive properties of antidepressants have been suggested to be the result of their possible local anaesthetic or anticholinergic effect <span class=\"citation\">[<a href=\"https://doi.org/10.1016/s0006-2952(96)00509-6\" class=\"citation hm \" data-key=\"10.1016/s0006-2952(96)00509-6\">3</a>]</span>. It has been proposed that selective serotonin re-uptake inhibitors (SSRIs) are less likely to cause seizures than cyclic antidepressants <span class=\"citation\">[<a href=\"https://doi.org/10.1016/s0736-4679(97)00072-3\" class=\"citation hm \" data-key=\"10.1016/s0736-4679(97)00072-3\">4</a>]</span>. On the other hand, seizures have been associated with SSRIs in previous studies of adverse events as in the case of escitaloprame <span class=\"citation\">[<a href=\"https://doi.org/10.2165/00002018-199920030-00007\" class=\"citation hm \" data-key=\"10.2165/00002018-199920030-00007\">5</a>]</span>.</p></blockquote>\r\n\r\n<p>From a 2016 article <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.yebeh.2016.01.029\" class=\"citation hm \" data-key=\"10.1016/j.yebeh.2016.01.029\">6</a>]</span>:</p>\r\n\r\n<blockquote><p>Antidepressants may disturb the neuronal balance and control of excitability, leading to seizures. Seizures may occur as a consequence of a misbalance between inhibitory GABAergic and excitatory glutamatergic neurotransmission with increase in glutamatergic activation and, thus, excessive calcium influx, initiating intracellular processes. The underlying mechanisms are not clear <span class=\"citation\">[<a href=\"https://doi.org/10.2165/00002018-199818020-00004\" class=\"citation hm \" data-key=\"10.2165/00002018-199818020-00004\">7</a>]</span>.</p></blockquote>\r\n\r\n<p>From a 2002 article <span class=\"citation\">[<a href=\"https://doi.org/10.2165/00002018-200225020-00004\" class=\"citation hm \" data-key=\"10.2165/00002018-200225020-00004\">8</a>]</span></p>\r\n\r\n<blockquote><p>Different specific mechanisms may be involved, which are mediated by the γ-aminobutyric acid (GABA) system and other neurotransmitters. Discussion of these mechanisms is beyond the scope of this review and readers may refer to specific reviews <span class=\"citation\">[<a href=\"https://doi.org/10.1111/j.1528-1157.1998.tb01268.x\" class=\"citation hm \" data-key=\"10.1111/j.1528-1157.1998.tb01268.x\">9</a>]</span>.</p></blockquote>\r\n\r\n<p>From a 1996 article <span class=\"citation\">[<a href=\"https://doi.org/10.1016/s0006-2952(96)00509-6\" class=\"citation hm \" data-key=\"10.1016/s0006-2952(96)00509-6\">3</a>]</span> (referenced in <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.seizure.2009.11.005\" class=\"citation hm \" data-key=\"10.1016/j.seizure.2009.11.005\">1</a>]</span> above):</p>\r\n\r\n<blockquote><p>Taken together, the total body of information strongly suggests that the pharmacodynamic action by which antidepressant drugs cause seizures is unrelated to their ability to block norepinephrine or serotonin reuptake. Rather, it seems more likely that these drugs produce convulsions by virtue of their local anesthetic or their antihistaminic/antimuscarinic properties.</p></blockquote>\r\n\r\n<p>Other references: <span class=\"citation\">[<a href=\"https://doi.org/10.1007/s11910-016-0670-5\" class=\"citation hm \" data-key=\"10.1007/s11910-016-0670-5\">10</a>]</span></p>",
      "body_md": "# Literature survey\r\n\r\nBelow is a collection of related literature, which I may update as the research continuous. The primary questions is why the 9 cyclic compounds listed above are ictogenic.\r\n\r\nFrom a 2010 article [@10.1016/j.seizure.2009.11.005]:\r\n\r\n> The mechanisms through which antidepressants alter neuronal excitability and modify seizure threshold are still largely unknown. Antidepressants act mainly by blocking the re-uptake of monoamines. Both animal and human data have shown that blocking the re-uptake of norepinephrine and/or serotonin has an anticonvulsant effect [@10.1016/j.yebeh.2005.07.014]. The convulsive properties of antidepressants have been suggested to be the result of their possible local anaesthetic or anticholinergic effect [@10.1016/s0006-2952(96)00509-6]. It has been proposed that selective serotonin re-uptake inhibitors (SSRIs) are less likely to cause seizures than cyclic antidepressants [@10.1016/s0736-4679(97)00072-3]. On the other hand, seizures have been associated with SSRIs in previous studies of adverse events as in the case of escitaloprame [@10.2165/00002018-199920030-00007].\r\n\r\nFrom a 2016 article [@10.1016/j.yebeh.2016.01.029]:\r\n\r\n> Antidepressants may disturb the neuronal balance and control of excitability, leading to seizures. Seizures may occur as a consequence of a misbalance between inhibitory GABAergic and excitatory glutamatergic neurotransmission with increase in glutamatergic activation and, thus, excessive calcium influx, initiating intracellular processes. The underlying mechanisms are not clear [@10.2165/00002018-199818020-00004].\r\n\r\nFrom a 2002 article [@10.2165/00002018-200225020-00004]\r\n\r\n> Different specific mechanisms may be involved, which are mediated by the γ-aminobutyric acid (GABA) system and other neurotransmitters. Discussion of these mechanisms is beyond the scope of this review and readers may refer to specific reviews [@10.1111/j.1528-1157.1998.tb01268.x].\r\n\r\nFrom a 1996 article [@10.1016/s0006-2952(96)00509-6] (referenced in [@10.1016/j.seizure.2009.11.005] above):\r\n\r\n> Taken together, the total body of information strongly suggests that the pharmacodynamic action by which antidepressant drugs cause seizures is unrelated to their ability to block norepinephrine or serotonin reuptake. Rather, it seems more likely that these drugs produce convulsions by virtue of their local anesthetic or their antihistaminic/antimuscarinic properties.\r\n\r\nOther references: [@10.1007/s11910-016-0670-5]",
      "comment_id": 1487,
      "profile_id": 17,
      "published": "2017-01-31T21:40:42.244669Z",
      "thread_id": 231,
      "url": "/discussion/why-we-predicted-ictogenic-tricyclic-compounds-treat-epilepsy/231#2"
    },
    {
      "body_html": "<h1>Cholinergic receptors?</h1>\r\n\r\n<p>One visually striking pattern is that of the 9 ictogenic tricyclic compounds, 8 target cholinergic receptors. Furthermore, clomipramine also likely exhibits anti-cholinergic effects <span class=\"citation\">[<a href=\"https://doi.org/10.1016/S0014-2999(02)01556-X\" class=\"citation hm \" data-key=\"10.1016/S0014-2999(02)01556-X\">1</a>, <a href=\"https://doi.org/10.1016/S0014-2999(02)02557-8\" class=\"citation hm \" data-key=\"10.1016/S0014-2999(02)02557-8\">2</a>, <a href=\"https://doi.org/10.1177/030006057300100537\" class=\"citation hm \" data-key=\"10.1177/030006057300100537\">3</a>]</span>, which would mean all 9 ictogenic tricyclic compounds bind to cholinergic receptors. I have not confirmed this, but I believe these compounds are all antagonists of cholinergic receptors.</p>\r\n\r\n<p>There are two anti-ictogenic tricyclic compounds: oxcarbazepine and carbamazepine. Although these compounds likely have anti-cholinergic effects <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.ejphar.2010.05.063\" class=\"citation hm \" data-key=\"10.1016/j.ejphar.2010.05.063\">4</a>, <a href=\"https://doi.org/10.1016/0028-3908(76)90031-9\" class=\"citation hm \" data-key=\"10.1016/0028-3908(76)90031-9\">5</a>, <a href=\"https://doi.org/10.1111/j.1528-1157.1999.tb00848.x\" class=\"citation hm \" data-key=\"10.1111/j.1528-1157.1999.tb00848.x\">6</a>]</span>, they are unique in their targeting of the sodium channel (according to our visualization).</p>\r\n\r\n<p>Interestingly, there's evidence that cholinergic receptor inhibition may a therapeutic mechanism of action for carbamazepine <span class=\"citation\">[<a href=\"https://doi.org/10.3389/fphys.2015.00022\" class=\"citation hm \" data-key=\"10.3389/fphys.2015.00022\">7</a>]</span>. Quoting from <span class=\"citation\">[<a href=\"https://doi.org/10.1111/j.1528-1157.1999.tb00848.x\" class=\"citation hm \" data-key=\"10.1111/j.1528-1157.1999.tb00848.x\">6</a>]</span>:</p>\r\n\r\n<blockquote><p>The increased sensitivity of these mutant receptors supports the hypothesis that the antiepileptic activity of carbamazepine can, at least to some extent, be attributed to the nAChR inhibition.</p></blockquote>\r\n\r\n<p>And furthermore, the barbiturates — which clustered together and were all anti-ictogenic — also inhibit cholinergic receptors <span class=\"citation\">[<a href=\"https://doi.org/10.1085/jgp.109.3.401\" class=\"citation hm \" data-key=\"10.1085/jgp.109.3.401\">8</a>]</span>. Pharmacologists believe the primary mechanisms of action for barbituates on epilepsy are GABAᴀ agonism, blocking AMPA/kainate receptors, and inhibiting glutamate release <span class=\"citation\">[<a href=\"https://doi.org/10.1111/epi.12025\" class=\"citation hm \" data-key=\"10.1111/epi.12025\">9</a>]</span>. Potentially, the anti-cholinergic effects of barbiturates are overshadowed by these other mechanisms.</p>\r\n\r\n<p><a href=\"/u/pouyakhankhanian\" class=\"username\">@pouyakhankhanian</a>, do you also find the cholinergic receptors interesting here?</p>",
      "body_md": "# Cholinergic receptors?\r\n\r\nOne visually striking pattern is that of the 9 ictogenic tricyclic compounds, 8 target cholinergic receptors. Furthermore, clomipramine also likely exhibits anti-cholinergic effects [@10.1016/S0014-2999(02)01556-X @10.1016/S0014-2999(02)02557-8 @10.1177/030006057300100537], which would mean all 9 ictogenic tricyclic compounds bind to cholinergic receptors. I have not confirmed this, but I believe these compounds are all antagonists of cholinergic receptors.\r\n\r\nThere are two anti-ictogenic tricyclic compounds: oxcarbazepine and carbamazepine. Although these compounds likely have anti-cholinergic effects [@10.1016/j.ejphar.2010.05.063 @10.1016/0028-3908(76)90031-9 @10.1111/j.1528-1157.1999.tb00848.x], they are unique in their targeting of the sodium channel (according to our visualization).\r\n\r\nInterestingly, there's evidence that cholinergic receptor inhibition may a therapeutic mechanism of action for carbamazepine [@10.3389/fphys.2015.00022]. Quoting from [@10.1111/j.1528-1157.1999.tb00848.x]:\r\n\r\n> The increased sensitivity of these mutant receptors supports the hypothesis that the antiepileptic activity of carbamazepine can, at least to some extent, be attributed to the nAChR inhibition.\r\n\r\nAnd furthermore, the barbiturates -- which clustered together and were all anti-ictogenic -- also inhibit cholinergic receptors [@10.1085/jgp.109.3.401]. Pharmacologists believe the primary mechanisms of action for barbituates on epilepsy are GABAᴀ agonism, blocking AMPA/kainate receptors, and inhibiting glutamate release [@10.1111/epi.12025]. Potentially, the anti-cholinergic effects of barbiturates are overshadowed by these other mechanisms.\r\n\r\n@pouyakhankhanian, do you also find the cholinergic receptors interesting here?",
      "comment_id": 1488,
      "profile_id": 17,
      "published": "2017-02-01T18:01:48.521665Z",
      "thread_id": 231,
      "url": "/discussion/why-we-predicted-ictogenic-tricyclic-compounds-treat-epilepsy/231#3"
    },
    {
      "body_html": "<h1>Final resource counts</h1>\r\n\r\n<p>Since stats help provide context, we often mention how many resources Hetionet integrates. Our <a href=\"https://github.com/dhimmel/integrate/blob/725f4e4b4a737cfb15abe55ef36386c23e1c4f1f/licenses/README.md\">licensing table</a> lists 31 resources, but 2 were removed. Hence, we claim Hetionet v1.0 integrates 29 resources. This is the number of resources that directly contributed data that was encoded as nodes or edges in the hetnet.</p>\r\n\r\n<p><strong>Caveats:</strong> The number 29 underestimates the extent of integration required for a project such as Rephetio. First, we used additional resources, such as <a href=\"https://thinklab.com/discussion/unifying-drug-vocabularies/40#4\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d40\">UniChem</a>, to help standardize and integrate these 29 resources. Additionally, several resources were themselves compilations of other resources, such as <a href=\"https://thinklab.com/discussion/integrating-drug-target-information-from-bindingdb/53\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d53\">BindingDB</a> and the <a href=\"https://thinklab.com/discussion/creating-a-catalog-of-protein-interactions/85#9\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d85\">resources for protein-interactions</a>. Finally, we rely on several other databases to interpret our findings, such as <a href=\"https://thinklab.com/discussion/prediction-in-epilepsy/224#10\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d224\">ATC Codes</a> and <a href=\"https://thinklab.com/discussion/using-entrez-gene-as-our-gene-vocabulary/34#13\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d34\">HGNC Gene Families</a>.</p>\r\n\r\n<p>Nonetheless here are the 31 resources divided by their copyright and licensing situation. Note that this stratification requires some subjectivity. In other words, I used my best judgement to help simplify complex legal considerations into 6 categories. The categories are slightly different <a href=\"#14\">than above</a>. Furthermore, this post reflects the <a href=\"https://thinklab.com/discussion/msigdb-licensing/108#3\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d108\">removal of MSigDB</a> and the <a href=\"https://thinklab.com/discussion/adding-pathway-resources-to-your-network/72#11\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d72\">corresponding addition</a> of two pathway resources (Reactome &amp; Pathway Interaction Database).</p>\r\n\r\n<h2>5 public domain resources</h2>\r\n\r\n<p>Five resources were created by the United States Government. Hence I consider them not subject to copyright and part of the public domain. Nodes and edges from these resources are CC0 licensed in Hetionet v1.0.</p>\r\n\r\n<ol><li>Entrez Gene</li><li>LabeledIn</li><li>MEDLINE</li><li>MeSH</li><li>Pathway Interaction Database</li></ol>\r\n\r\n<p><strong>Caveats:</strong> The public domain status of these resources is complicated. None of them adopted a CC0 license to unambiguously place them in the public domain, including outside of the United States. Furthermore, they often come with custom legal statements and terms of use. See for example, the MeSH <a href=\"https://github.com/dhimmel/integrate/blob/725f4e4b4a737cfb15abe55ef36386c23e1c4f1f/licenses/custom/MeSH.md\">Memorandum of Understanding</a>. These custom terms make one question whether these are actually public domain resources. It's a mess. <a href=\"/u/andrewsu\" class=\"username\">@andrewsu</a> is a leading expert on this mess and reform efforts.</p>\r\n\r\n<h2>12 openly licensed resources</h2>\r\n\r\n<p>Twelve resources had licenses that met the <a href=\"http://opendefinition.org/od/2.1/en/\">Open Definition version 2.1</a>, which is summarized as:</p>\r\n\r\n<blockquote><p>Knowledge is open if anyone is free to access, use, modify, and share it — subject, at most, to measures that preserve provenance and openness.</p></blockquote>\r\n\r\n<p>Those resources are:</p>\r\n\r\n<ol><li>Disease Ontology</li><li>DISEASES</li><li>DrugCentral</li><li>Gene Ontology</li><li>GWAS Catalog</li><li>Reactome</li><li>LINCS L1000</li><li>TISSUES</li><li>Uberon</li><li>WikiPathways</li><li>BindingDB</li><li>DisGeNET</li></ol>\r\n\r\n<p><strong>Caveats:</strong> Not all of these resources used a standard license that <a href=\"http://opendefinition.org/licenses/\">officially conforms</a> with the Open Definition. Therefore, I used my best judgement whether custom license terms were compatible with open licensing. For the most part, nodes and edges from these resources are openly licensed in Hetionet v1.0.</p>\r\n\r\n<h2>4 resources that allow non-commercial reuse</h2>\r\n\r\n<p>Four resources had licenses that allowed non-commercial reuse only. Nodes and edges from these resources use the least-restrictive compatible Creative Commons license in Hetionet v1.0.</p>\r\n\r\n<ol><li>DrugBank 4.2</li><li>MEDI</li><li>PREDICT</li><li>SIDER 4</li></ol>\r\n\r\n<p>Besides DrugBank, these resources did use standard Creative Commons licenses, which while not being open are at least legally straightforward. And DrugBank <a href=\"https://thinklab.com/discussion/sounding-the-alarm-on-drugbanks-new-license-and-terms-of-use/213#10\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d213\">switched to a Creative Commons license</a> part of the way through Project Rephetio, based in part on our feedback.</p>\r\n\r\n<h2>9 unlicensed resources</h2>\r\n\r\n<p>Nine resources did not have a license. For the most part, nodes and edges from these resources don't have a license attribute in Hetionet v1.0.</p>\r\n\r\n<ol><li>ADEPTUS (removed)</li><li>Bgee</li><li>DOAF</li><li>ehrlink</li><li>Evolutionary Rate Covariation</li><li>hetio-dag</li><li>Incomplete Interactome</li><li>Human Interactome Database</li><li>STARGEO</li></ol>\r\n\r\n<p><strong>Caveats:</strong> In these cases, I believe the researchers generally put the data online for others to use but are unaware of the legal barriers to data reuse. Or in other instances, they would like to openly license their work but are not the data owners or are unsure of the legal considerations of doing so.</p>\r\n\r\n<h2>MSigDB explicitly forbids redistribution</h2>\r\n\r\n<p>Ultimately, one resource explicitly forbid redistribution.</p>\r\n\r\n<ol><li>MSigDB (removed)</li></ol>\r\n\r\n<h2>Conclusion</h2>\r\n\r\n<p><span class=\"math\">$$5 + 12 + 4 + 9 + 1 - 2 = 29$$</span></p>\r\n\r\n<p>Phew!</p>",
      "body_md": "# Final resource counts\r\n\r\nSince stats help provide context, we often mention how many resources Hetionet integrates. Our [licensing table](https://github.com/dhimmel/integrate/blob/725f4e4b4a737cfb15abe55ef36386c23e1c4f1f/licenses/README.md) lists 31 resources, but 2 were removed. Hence, we claim Hetionet v1.0 integrates 29 resources. This is the number of resources that directly contributed data that was encoded as nodes or edges in the hetnet.\r\n\r\n**Caveats:** The number 29 underestimates the extent of integration required for a project such as Rephetio. First, we used additional resources, such as [UniChem](https://thinklab.com/discussion/unifying-drug-vocabularies/40#4), to help standardize and integrate these 29 resources. Additionally, several resources were themselves compilations of other resources, such as [BindingDB](https://thinklab.com/discussion/integrating-drug-target-information-from-bindingdb/53) and the [resources for protein-interactions](https://thinklab.com/discussion/creating-a-catalog-of-protein-interactions/85#9). Finally, we rely on several other databases to interpret our findings, such as [ATC Codes](https://thinklab.com/discussion/prediction-in-epilepsy/224#10) and [HGNC Gene Families](https://thinklab.com/discussion/using-entrez-gene-as-our-gene-vocabulary/34#13).\r\n\r\nNonetheless here are the 31 resources divided by their copyright and licensing situation. Note that this stratification requires some subjectivity. In other words, I used my best judgement to help simplify complex legal considerations into 6 categories. The categories are slightly different [than above](#14). Furthermore, this post reflects the [removal of MSigDB](https://thinklab.com/discussion/msigdb-licensing/108#3) and the [corresponding addition](https://thinklab.com/discussion/adding-pathway-resources-to-your-network/72#11) of two pathway resources (Reactome & Pathway Interaction Database).\r\n\r\n## 5 public domain resources\r\n\r\nFive resources were created by the United States Government. Hence I consider them not subject to copyright and part of the public domain. Nodes and edges from these resources are CC0 licensed in Hetionet v1.0.\r\n\r\n1. Entrez Gene\r\n+ LabeledIn\r\n+ MEDLINE\r\n+ MeSH\r\n+ Pathway Interaction Database\r\n\r\n**Caveats:** The public domain status of these resources is complicated. None of them adopted a CC0 license to unambiguously place them in the public domain, including outside of the United States. Furthermore, they often come with custom legal statements and terms of use. See for example, the MeSH [Memorandum of Understanding](https://github.com/dhimmel/integrate/blob/725f4e4b4a737cfb15abe55ef36386c23e1c4f1f/licenses/custom/MeSH.md). These custom terms make one question whether these are actually public domain resources. It's a mess. @andrewsu is a leading expert on this mess and reform efforts.\r\n\r\n## 12 openly licensed resources\r\n\r\nTwelve resources had licenses that met the [Open Definition version 2.1](http://opendefinition.org/od/2.1/en/), which is summarized as:\r\n\r\n> Knowledge is open if anyone is free to access, use, modify, and share it — subject, at most, to measures that preserve provenance and openness.\r\n\r\nThose resources are:\r\n\r\n1. Disease Ontology\r\n+ DISEASES\r\n+ DrugCentral\r\n+ Gene Ontology\r\n+ GWAS Catalog\r\n+ Reactome\r\n+ LINCS L1000\r\n+ TISSUES\r\n+ Uberon\r\n+ WikiPathways\r\n+ BindingDB\r\n+ DisGeNET\r\n\r\n**Caveats:** Not all of these resources used a standard license that [officially conforms](http://opendefinition.org/licenses/) with the Open Definition. Therefore, I used my best judgement whether custom license terms were compatible with open licensing. For the most part, nodes and edges from these resources are openly licensed in Hetionet v1.0.\r\n\r\n## 4 resources that allow non-commercial reuse\r\n\r\nFour resources had licenses that allowed non-commercial reuse only. Nodes and edges from these resources use the least-restrictive compatible Creative Commons license in Hetionet v1.0.\r\n\r\n1. DrugBank 4.2\r\n+ MEDI\r\n+ PREDICT\r\n+ SIDER 4\r\n\r\nBesides DrugBank, these resources did use standard Creative Commons licenses, which while not being open are at least legally straightforward. And DrugBank [switched to a Creative Commons license](https://thinklab.com/discussion/sounding-the-alarm-on-drugbanks-new-license-and-terms-of-use/213#10) part of the way through Project Rephetio, based in part on our feedback.\r\n\r\n## 9 unlicensed resources\r\n\r\nNine resources did not have a license. For the most part, nodes and edges from these resources don't have a license attribute in Hetionet v1.0.\r\n\r\n1. ADEPTUS (removed)\r\n+ Bgee\r\n+ DOAF\r\n+ ehrlink\r\n+ Evolutionary Rate Covariation\r\n+ hetio-dag\r\n+ Incomplete Interactome\r\n+ Human Interactome Database\r\n+ STARGEO\r\n\r\n**Caveats:** In these cases, I believe the researchers generally put the data online for others to use but are unaware of the legal barriers to data reuse. Or in other instances, they would like to openly license their work but are not the data owners or are unsure of the legal considerations of doing so.\r\n\r\n## MSigDB explicitly forbids redistribution\r\n\r\nUltimately, one resource explicitly forbid redistribution.\r\n\r\n1. MSigDB (removed)\r\n\r\n## Conclusion\r\n\r\n$$5 + 12 + 4 + 9 + 1 - 2 = 29$$\r\n\r\nPhew!",
      "comment_id": 1490,
      "profile_id": 17,
      "published": "2017-02-02T22:27:16.882353Z",
      "thread_id": 107,
      "url": "/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#16"
    },
    {
      "body_html": "<p>Thank you for the detailed explanation. <br>To get auroc of Disease Modifying, you may had split the data into n% of train data and (100-n)% of test data. What was n? If not, is the result was measured from the training data itself without test data?</p>",
      "body_md": "Thank you for the detailed explanation. \nTo get auroc of Disease Modifying, you may had split the data into n% of train data and (100-n)% of test data. What was n? If not, is the result was measured from the training data itself without test data?",
      "comment_id": 1491,
      "profile_id": 319,
      "published": "2017-02-04T07:02:54.688999Z",
      "thread_id": 226,
      "url": "/doc/7/review#39"
    },
    {
      "body_html": "<h1>Hetionet v1.0 released</h1>\r\n\r\n<p>Just wanted to update this thread. The final version of the hetnet for Project Rephetio has been released (for a while now). The network is named Hetionet and Project Rephetio is based on version 1.0, which is <a href=\"https://github.com/dhimmel/hetionet/tree/59c448fd912555f84b9822b4f49b431b696aea15\">available on GitHub</a> <span class=\"citation\">[<a href=\"https://doi.org/10.5281/zenodo.268568\" class=\"citation hm citation-figure\" data-key=\"10.5281/zenodo.268568\">1</a>]</span> in JSON, TSV, and Neo4j database formats. We also host a public Neo4j database instance at <a href=\"https://neo4j.het.io\">https://neo4j.het.io</a> <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d216\" class=\"citation hm citation-self\" data-key=\"10.15363/thinklab.d216\">2</a>]</span>. </p>\r\n\r\n<p>For details on the construction of Hetionet v1.0, see the Methods section of the project report/manuscript <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.a7\" class=\"citation hm citation-self\" data-key=\"10.15363/thinklab.a7\">3</a>, <a href=\"https://doi.org/10.1101/087619\" class=\"citation hm \" data-key=\"10.1101/087619\">4</a>]</span>. Quoting from the abstract:</p>\r\n\r\n<blockquote><p>Hetionet v1.0 consists of 47,031 nodes of 11 types and 2,250,197 relationships of 24 types. Data was integrated from 29 public resources to connect compounds, diseases, genes, anatomies, pathways, biological processes, molecular functions, cellular components, pharmacologic classes, side effects, and symptoms.</p></blockquote>\r\n\r\n<p>Here is a <a href=\"https://thinklab.com/discussion/describing-hetionet-v10-through-visualization-and-statistics/202#8\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d202\">visualization</a>:</p>\r\n\r\n<p><img src=\"https://raw.githubusercontent.com/dhimmel/rephetio/54ce1bacfe6392c04d6afd164df7718a0d2769b3/figure/hetionet-v1.0-labeled-landscape.png\" alt=\"Hetionet v1.0 landscape labeled\"></p>\r\n\r\n<p>Just to be clear, Hetionet v1.0 is not the same as the \"initial version of our network\" mentioned <a href=\"#1\">above</a>. Please use Hetionet v1.0 rather than earlier versions, which had a less developed <a href=\"https://thinklab.com/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#14\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d107\">licensing solution</a> and should therefore be avoided.</p>",
      "body_md": "# Hetionet v1.0 released\r\n\r\nJust wanted to update this thread. The final version of the hetnet for Project Rephetio has been released (for a while now). The network is named Hetionet and Project Rephetio is based on version 1.0, which is [available on GitHub](https://github.com/dhimmel/hetionet/tree/59c448fd912555f84b9822b4f49b431b696aea15) [@10.5281/zenodo.268568] in JSON, TSV, and Neo4j database formats. We also host a public Neo4j database instance at https://neo4j.het.io [@10.15363/thinklab.d216]. \r\n\r\nFor details on the construction of Hetionet v1.0, see the Methods section of the project report/manuscript [@10.15363/thinklab.a7 @10.1101/087619]. Quoting from the abstract:\r\n\r\n> Hetionet v1.0 consists of 47,031 nodes of 11 types and 2,250,197 relationships of 24 types. Data was integrated from 29 public resources to connect compounds, diseases, genes, anatomies, pathways, biological processes, molecular functions, cellular components, pharmacologic classes, side effects, and symptoms.\r\n\r\nHere is a [visualization](https://thinklab.com/discussion/describing-hetionet-v10-through-visualization-and-statistics/202#8):\r\n\r\n![Hetionet v1.0 landscape labeled](https://raw.githubusercontent.com/dhimmel/rephetio/54ce1bacfe6392c04d6afd164df7718a0d2769b3/figure/hetionet-v1.0-labeled-landscape.png)\r\n\r\nJust to be clear, Hetionet v1.0 is not the same as the \"initial version of our network\" mentioned [above](#1). Please use Hetionet v1.0 rather than earlier versions, which had a less developed [licensing solution](https://thinklab.com/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#14) and should therefore be avoided.",
      "comment_id": 1492,
      "profile_id": 17,
      "published": "2017-02-04T20:55:54.177731Z",
      "thread_id": 102,
      "url": "/discussion/one-network-to-rule-them-all/102#6"
    },
    {
      "body_html": "<h1>GitHub Repository</h1>\r\n\r\n<p>I just touched up the machine learning repository for Project Rephetio, <a href=\"https://github.com/dhimmel/learn/tree/e00a61f4ae493dcc95a6264905f0d534494db2d8\"><code>dhimmel/learn</code></a> on GitHub <span class=\"citation\">[<a href=\"https://doi.org/10.5281/zenodo.268654\" class=\"citation hm citation-figure\" data-key=\"10.5281/zenodo.268654\">1</a>]</span>. Mainly, I created a lot more documentation. However, since it's quite a complex repo with lot's of notebooks and pieces, users will still likely have questions. So don't hesitate to open <a href=\"https://github.com/dhimmel/learn/issues\" title=\"GitHub Issues for dhimmel/learn\">issues</a> with requests for additional documentation.</p>",
      "body_md": "# GitHub Repository\r\n\r\nI just touched up the machine learning repository for Project Rephetio, [`dhimmel/learn`](https://github.com/dhimmel/learn/tree/e00a61f4ae493dcc95a6264905f0d534494db2d8) on GitHub [@10.5281/zenodo.268654]. Mainly, I created a lot more documentation. However, since it's quite a complex repo with lot's of notebooks and pieces, users will still likely have questions. So don't hesitate to open [issues](https://github.com/dhimmel/learn/issues \"GitHub Issues for dhimmel/learn\") with requests for additional documentation.",
      "comment_id": 1493,
      "profile_id": 17,
      "published": "2017-02-04T23:29:52.116590Z",
      "thread_id": 210,
      "url": "/discussion/our-hetnet-edge-prediction-methodology-the-modeling-framework-for-project-rephetio/210#5"
    },
    {
      "body_html": "<p>We did not withhold compound–disease pairs from the \"Disease Modifying\" indication set for testing. I <a href=\"https://thinklab.com/discussion/network-edge-prediction-how-to-deal-with-self-testing/194#4\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d194\">explain this decision here</a> <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d194\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d194\">1</a>]</span>. Hence, the \"Disease Modifying\" AUROC is calculated on observations that we used to train. While I'm confident that our logistic regression model doesn't overfit due the cross-validated regularization, you should still regard the  \"Disease Modifying\" AUROC as a <em>training </em> (not testing) AUROC.</p>\n\n<p>For testing AUROCs, please look to the two external validation sets:</p>\n\n<ol><li>DrugCentral: AUROC = 85.5%</li><li>Clinical Trial: AUROC = 70.0%</li></ol>",
      "body_md": "We did not withhold compound--disease pairs from the \"Disease Modifying\" indication set for testing. I [explain this decision here](https://thinklab.com/discussion/network-edge-prediction-how-to-deal-with-self-testing/194#4) [@10.15363/thinklab.d194]. Hence, the \"Disease Modifying\" AUROC is calculated on observations that we used to train. While I'm confident that our logistic regression model doesn't overfit due the cross-validated regularization, you should still regard the  \"Disease Modifying\" AUROC as a _training _ (not testing) AUROC.\n\nFor testing AUROCs, please look to the two external validation sets:\n\n1. DrugCentral: AUROC = 85.5%\n2. Clinical Trial: AUROC = 70.0%",
      "comment_id": 1494,
      "profile_id": 17,
      "published": "2017-02-07T18:31:08.658327Z",
      "thread_id": 226,
      "url": "/doc/7/review#40"
    },
    {
      "body_html": "<h1>Rephetio Contributions as of 2017-02-07</h1>\r\n\r\n<p>I updated the figure above to be current and increased the character threshold for name display to 4,500 (<a href=\"https://github.com/dhimmel/thinklytics/blob/1b15ab11576ef2538da5f34b900593b5dc61a103/viz/rephetio-rviz.ipynb\">notebook</a>). Here's the new figure:</p>\r\n\r\n<p><img src=\"https://github.com/dhimmel/thinklytics/raw/1b15ab11576ef2538da5f34b900593b5dc61a103/viz/rephetio-contribution.png\" alt=\"Rephetio Thinklab Contibution Plot\" title=\"As of 2017-02-07\"></p>\r\n\r\n<p>And here are the new discussion statistics from the notebook:</p>\r\n\r\n<ul><li>86 discussions</li><li>607 comments</li><li>190 notes</li><li>48 contributors, 40 of which were from the community (non-team members)</li><li>815,744 characters</li><li>130,128 words (equivalent in volume to ~18.59 journal publications)</li></ul>\r\n\r\n<p>If in addition to discussions, <a href=\"https://github.com/dhimmel/thinklytics/blob/1b15ab11576ef2538da5f34b900593b5dc61a103/process/table/summaries.tsv#L10\">the stats</a> include project documents — which now includes the project report <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.a7\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.a7\">1</a>]</span> in addition to the proposal <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.a5\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.a5\">2</a>]</span> — the summary is:</p>\r\n\r\n<ul><li>639 total cited DOIs</li><li>901,672 total characters</li><li>143,056 total words (equivalent in volume to ~20.44 journal publications)</li></ul>\r\n\r\n<p>Wow!</p>",
      "body_md": "# Rephetio Contributions as of 2017-02-07\r\n\r\nI updated the figure above to be current and increased the character threshold for name display to 4,500 ([notebook](https://github.com/dhimmel/thinklytics/blob/1b15ab11576ef2538da5f34b900593b5dc61a103/viz/rephetio-rviz.ipynb)). Here's the new figure:\r\n\r\n![Rephetio Thinklab Contibution Plot](https://github.com/dhimmel/thinklytics/raw/1b15ab11576ef2538da5f34b900593b5dc61a103/viz/rephetio-contribution.png \"As of 2017-02-07\")\r\n\r\n\r\nAnd here are the new discussion statistics from the notebook:\r\n\r\n+ 86 discussions\r\n+ 607 comments\r\n+ 190 notes\r\n+ 48 contributors, 40 of which were from the community (non-team members)\r\n+ 815,744 characters\r\n+ 130,128 words (equivalent in volume to ~18.59 journal publications)\r\n\r\nIf in addition to discussions, [the stats](https://github.com/dhimmel/thinklytics/blob/1b15ab11576ef2538da5f34b900593b5dc61a103/process/table/summaries.tsv#L10) include project documents -- which now includes the project report [@10.15363/thinklab.a7] in addition to the proposal [@10.15363/thinklab.a5] -- the summary is:\r\n\r\n+ 639 total cited DOIs\r\n+ 901,672 total characters\r\n+ 143,056 total words (equivalent in volume to ~20.44 journal publications)\r\n\r\nWow!",
      "comment_id": 1495,
      "profile_id": 17,
      "published": "2017-02-08T01:11:51.153909Z",
      "thread_id": 200,
      "url": "/discussion/measuring-user-contribution-and-content-creation/200#5"
    },
    {
      "body_html": "<p>In \"https://thinklab.com/discussion/cataloging-drugdisease-therapies-in-the-clinicaltrialsgov-database/212\", there is a text saying \"The slim clinical trial catalog contains 6,382 drug–disease pairs\", but it does match with the number 5,594. How did you select 5,594 indications? <br>I also downloaded DrugBank-DO-slim.tsv and found that there are 6,382 unique drug–disease pairs.</p>",
      "body_md": "In \"https://thinklab.com/discussion/cataloging-drugdisease-therapies-in-the-clinicaltrialsgov-database/212\", there is a text saying \"The slim clinical trial catalog contains 6,382 drug–disease pairs\", but it does match with the number 5,594. How did you select 5,594 indications? \nI also downloaded DrugBank-DO-slim.tsv and found that there are 6,382 unique drug–disease pairs.",
      "comment_id": 1496,
      "profile_id": 319,
      "published": "2017-03-07T09:56:41.362609Z",
      "thread_id": 226,
      "url": "/doc/7/review#41"
    },
    {
      "body_html": "<p>Good observation. There are 788 clinical trial indications from <a href=\"https://github.com/dhimmel/clintrials/blob/7c65dec7b69322ca2f8ba2b170c1b3dbd92ebff8/data/DrugBank-DO-slim.tsv\"><code>DrugBank-DO-slim.tsv</code></a> <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d212\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d212\">1</a>]</span> that are not included in the <strong>Clinical Trial</strong> indication set.</p>\n\n<p>See the note in the <strong>Disease Modifying</strong> indication set description:</p>\n\n<blockquote><p>for the three remaining indication sets, we removed any observations that were positives in this set.</p></blockquote>\n\n<p>Here is the line of code that filters indications based on their existence in PharmacotherapyDB (from <a href=\"https://github.com/dhimmel/learn/blob/e00a61f4ae493dcc95a6264905f0d534494db2d8/validate/1-validation-datasets.ipynb\">this notebook</a> in <code>dhimmel/learn</code>)</p>\n\n<pre><code class=\"python\">pair_df = pair_df[pair_df.category.isnull()]</code></pre>\n\n<p>Hence, according to the source code, I filtered any of the 1,388 compound–disease pairs that were categorized in PharmacotherapyDB <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d182\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d182\">2</a>]</span>. This includes disease-modifying, symptomatic, and non indications. So of the 1,388 compound–disease pairs in PharmacotherapyDB, 788 had clinical trials.</p>\n\n<p>I will think about how to make the manuscript description more clear. As per the source code, the <strong>DrugCentral</strong> and <strong>Clinical Trial</strong> indication sets used to evaluate performance omit all compound–disease pairs in PharmacotherapyDB.</p>",
      "body_md": "Good observation. There are 788 clinical trial indications from [`DrugBank-DO-slim.tsv`](https://github.com/dhimmel/clintrials/blob/7c65dec7b69322ca2f8ba2b170c1b3dbd92ebff8/data/DrugBank-DO-slim.tsv) [@10.15363/thinklab.d212] that are not included in the **Clinical Trial** indication set.\n\nSee the note in the **Disease Modifying** indication set description:\n\n> for the three remaining indication sets, we removed any observations that were positives in this set.\n\nHere is the line of code that filters indications based on their existence in PharmacotherapyDB (from [this notebook](https://github.com/dhimmel/learn/blob/e00a61f4ae493dcc95a6264905f0d534494db2d8/validate/1-validation-datasets.ipynb) in `dhimmel/learn`)\n\n```python\npair_df = pair_df[pair_df.category.isnull()]\n```\n\nHence, according to the source code, I filtered any of the 1,388 compound--disease pairs that were categorized in PharmacotherapyDB [@10.15363/thinklab.d182]. This includes disease-modifying, symptomatic, and non indications. So of the 1,388 compound--disease pairs in PharmacotherapyDB, 788 had clinical trials.\n\nI will think about how to make the manuscript description more clear. As per the source code, the **DrugCentral** and **Clinical Trial** indication sets used to evaluate performance omit all compound--disease pairs in PharmacotherapyDB.",
      "comment_id": 1497,
      "profile_id": 17,
      "published": "2017-03-09T16:58:58.570149Z",
      "thread_id": 226,
      "url": "/doc/7/review#42"
    },
    {
      "body_html": "<h1>Feature / machine learning diagram</h1>\r\n\r\n<p>Here's didactic diagram illustrating the classification problem and features composing Rephetio's machine learning. The diagram is created using real data (<a href=\"https://github.com/dhimmel/learn/blob/25093893ed53730ab5cfdac49561c4b6bd3376c5/prediction/8-feature-example-viz.ipynb\">notebook</a>), but only shows a subset of observations (compound–disease pairs, rows) and features (metapaths, columns). The diagram shows the feature matrix (continuous values, from the \"all observations\" stage) as well as treatment status (binary values).</p>\r\n\r\n<p><img src=\"https://github.com/dhimmel/learn/raw/25093893ed53730ab5cfdac49561c4b6bd3376c5/prediction/figure/example-feature-matrix.png\" alt=\"Rephetio Machine Learning Diagram\" title=\"Compound–disease pairs versus feature matrix\"></p>\r\n\r\n<p>The top six compound–disease pairs are not treatments (negatives, gray), while the bottom six are treatments (positives, green). Each column is a feature corresponding to a metapath. Use <a href=\"http://het.io/repurpose/metapaths.html\">this table</a> to lookup metapath abbreviations. For example, <em>CbGiGaD</em> is shorthand for <em>Compound–binds–Gene–interacts–Gene–associates–Disease</em>.</p>\r\n\r\n<p>Feature values are transformed and standardized DWPCs, which assess the connectivity along the specified type of path between the specific compound and disease. The maroon colored values indicate above-average connectivity, whereas the blue colored values indicate below average connectivity. In general, positives have greater connectivity for the selected metapaths than negatives.</p>\r\n\r\n<p>The logistic regression model predicts whether a compound–disease pair is a treatment based on its features. In essence, the model learns the effect of each type of connectivity (feature) on the likelihood that a compound treats a disease.</p>",
      "body_md": "# Feature / machine learning diagram\r\n\r\nHere's didactic diagram illustrating the classification problem and features composing Rephetio's machine learning. The diagram is created using real data ([notebook](https://github.com/dhimmel/learn/blob/25093893ed53730ab5cfdac49561c4b6bd3376c5/prediction/8-feature-example-viz.ipynb)), but only shows a subset of observations (compound--disease pairs, rows) and features (metapaths, columns). The diagram shows the feature matrix (continuous values, from the \"all observations\" stage) as well as treatment status (binary values).\r\n\r\n![Rephetio Machine Learning Diagram](https://github.com/dhimmel/learn/raw/25093893ed53730ab5cfdac49561c4b6bd3376c5/prediction/figure/example-feature-matrix.png \"Compound–disease pairs versus feature matrix\")\r\n\r\nThe top six compound--disease pairs are not treatments (negatives, gray), while the bottom six are treatments (positives, green). Each column is a feature corresponding to a metapath. Use [this table](http://het.io/repurpose/metapaths.html) to lookup metapath abbreviations. For example, _CbGiGaD_ is shorthand for _Compound–binds–Gene–interacts–Gene–associates–Disease_.\r\n\r\nFeature values are transformed and standardized DWPCs, which assess the connectivity along the specified type of path between the specific compound and disease. The maroon colored values indicate above-average connectivity, whereas the blue colored values indicate below average connectivity. In general, positives have greater connectivity for the selected metapaths than negatives.\r\n\r\nThe logistic regression model predicts whether a compound--disease pair is a treatment based on its features. In essence, the model learns the effect of each type of connectivity (feature) on the likelihood that a compound treats a disease.",
      "comment_id": 1499,
      "profile_id": 17,
      "published": "2017-03-13T15:08:02.365991Z",
      "thread_id": 210,
      "url": "/discussion/our-hetnet-edge-prediction-methodology-the-modeling-framework-for-project-rephetio/210#6"
    },
    {
      "body_html": "<h1>MIA Talk at the Broad Institute</h1>\r\n\r\n<p><a href=\"/u/caseygreene\" class=\"username\">@caseygreene</a> and I took a trip to Cambridge and presented at the Broad Institute's  <a href=\"https://www.broadinstitute.org/MIA#2017\">Models, Inference &amp; Algorithms</a> (MIA) series.</p>\r\n\r\n<p>I gave a primer on Project Rephetio and Hetionet. The recording is on <a href=\"https://www.youtube.com/watch?v=t7HQ-r7kg0c&amp;list=PLlMMtlgw6qNjROoMNTBQjAcdx53kV50cS\">YouTube</a> (<a href=\"http://slides.com/dhimmel/mia\">slides</a>):</p>\r\n\r\n<p></p><div class=\"iframe-container\"><iframe src=\"https://www.youtube.com/embed/t7HQ-r7kg0c\" frameborder=\"0\" allowfullscreen=\"true\"></iframe></div>\r\n\r\n<p>Thanks Broad for making the YouTube video available under a <a href=\"https://support.google.com/youtube/answer/2797468\" title=\"Copyright on YouTube: Creative Commons\">CC BY</a> license!</p>",
      "body_md": "# MIA Talk at the Broad Institute\r\n\r\n@caseygreene and I took a trip to Cambridge and presented at the Broad Institute's  [Models, Inference & Algorithms](https://www.broadinstitute.org/MIA#2017) (MIA) series.\r\n\r\nI gave a primer on Project Rephetio and Hetionet. The recording is on [YouTube](https://www.youtube.com/watch?v=t7HQ-r7kg0c&list=PLlMMtlgw6qNjROoMNTBQjAcdx53kV50cS) ([slides](http://slides.com/dhimmel/mia)):\r\n\r\n![:youtube](t7HQ-r7kg0c)\r\n\r\nThanks Broad for making the YouTube video available under a [CC BY](https://support.google.com/youtube/answer/2797468 \"Copyright on YouTube: Creative Commons\") license!",
      "comment_id": 1500,
      "profile_id": 17,
      "published": "2017-03-17T16:09:18.084504Z",
      "thread_id": 113,
      "url": "/discussion/tracking-project-reuse-citation-and-publicity/113#14"
    },
    {
      "body_html": "<p>Could you specify the steps and subset of data taken for each of your source? This is my understanding so far of the process:<br>0) Compounds (DrugBank) - Approved small molecule compounds<br>1) Diseases (DO Slim) - 137 terms included diseases that have been studied by GWAS and cancer types from TopNodes_DOcancerslim <br>2) Symptoms (MeSH) - 438 descendants of Signs and Symptoms <br>3) Side effects (SIDER +UMLS identifiers)  - which ones?<br>4) Pharmacologic class (DrugCentral) - which ones?<br>5) Gene (Entrez Gene) - All Protein-coding human genes?<br>6) Anatomy (Uberon) - 402 terms by excluding terms known not to exist in humans and terms that were overly broad or arcane<br>7) Pathway (WikiPathways, Pathway Commons (Reactome+PID)) - All except for duplicate pathways and pathways without multiple participating genes?<br>8) BP, MF, CC (GOA) - only terms with 2–1000 annotated genes were included</p>\n\n<p>a) Could you confirm that the above information is correct for items 0,1,2,6 and 8?<br>b) Could you give more details on which terms were extracted for items 3, 4, 5 and 7?<br>c) Were there any dependencies when extracting information, e.g. only take genes associated with the approved drugs, or were they all extracted independently and then links were created between them despite not considering only those with relevance with one another or were the links (edges) created first and the nodes were populated according to the edges taken?</p>",
      "body_md": "Could you specify the steps and subset of data taken for each of your source? This is my understanding so far of the process:\n0) Compounds (DrugBank) - Approved small molecule compounds\n1) Diseases (DO Slim) - 137 terms included diseases that have been studied by GWAS and cancer types from TopNodes_DOcancerslim \n2) Symptoms (MeSH) - 438 descendants of Signs and Symptoms \n3) Side effects (SIDER +UMLS identifiers)  - which ones?\n4) Pharmacologic class (DrugCentral) - which ones?\n5) Gene (Entrez Gene) - All Protein-coding human genes?\n6) Anatomy (Uberon) - 402 terms by excluding terms known not to exist in humans and terms that were overly broad or arcane\n7) Pathway (WikiPathways, Pathway Commons (Reactome+PID)) - All except for duplicate pathways and pathways without multiple participating genes?\n8) BP, MF, CC (GOA) - only terms with 2–1000 annotated genes were included\n\na) Could you confirm that the above information is correct for items 0,1,2,6 and 8?\nb) Could you give more details on which terms were extracted for items 3, 4, 5 and 7?\nc) Were there any dependencies when extracting information, e.g. only take genes associated with the approved drugs, or were they all extracted independently and then links were created between them despite not considering only those with relevance with one another or were the links (edges) created first and the nodes were populated according to the edges taken?",
      "comment_id": 1501,
      "profile_id": 315,
      "published": "2017-03-29T01:19:00.031591Z",
      "thread_id": 226,
      "url": "/doc/7/review#43"
    },
    {
      "body_html": "<p>For reference, the best way to determine the exact steps that went into creating any node or relationship is to look at the <a href=\"https://github.com/dhimmel/integrate/blob/08510696b8d55534b133d66331a97654600469c8/integrate.ipynb\"><code>integrate.ipynb</code> notebook</a>. This notebook builds Hetionet v1.0 by loading data from other Rephetio repositories on GitHub. All links are versioned using git commit hashes, so you know the exact state of the input data.</p>\n\n<p>Confirming that <a href=\"/u/gaya_n\" class=\"username\">@gaya_n</a>'s understanding of how nodes were created is correct for points 0, 1, 2, 6, 8.</p>\n\n<blockquote><p>3) Side effects (SIDER + UMLS identifiers) - which ones?</p></blockquote>\n\n<p>Compound side effects from SIDER 4.1 were mapped to DrugBank compounds. The UMLS concept identifiers corresponding to MedDRA side effects, as provided by SIDER, were used to uniquely identify side effects. If a UMLS side effect was not associated with any DrugBank compounds, it was removed. 5,734 side effect nodes remained. 33 side effects nodes are disconnected in Hetionet v1.0, since Hetionet v1.0 does not include every DrugBank compound. Fore more information, see the SIDER processing <a href=\"https://github.com/dhimmel/SIDER4/blob/be3adebc0d845baaddb907a880890cb5e85f5801/SIDER4.ipynb\">source notebook</a>.</p>\n\n<p>4) Pharmacologic class (DrugCentral) - which ones?</p>\n\n<p>See <a href=\"https://thinklab.com/discussion/incorporating-drugcentral-data-in-our-network/186#4\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d186\">this comment</a>, cell 15 of <code>integrate.ipynb</code>, and <a href=\"https://github.com/dhimmel/drugcentral/blob/0e085ddb6aa42be367c85eba424edea716bebd94/drugcentral-to-rephetio.ipynb\"><code>drugcentral-to-rephetio.ipynb</code></a>. Only pharmacologic classes with the following class types were included: Physiologic Effect, Mechanism of Action, and Chemical/Ingredient. The processing method of <code>drugcentral-to-rephetio.ipynb</code> removes any pharmacologic classes that don't involve any DrugBank Slim (Hetionet v1.0) compounds.</p>\n\n<blockquote><p>5) Gene (Entrez Gene) - All Protein-coding human genes?</p></blockquote>\n\n<p>All protein-coding <em>homo sapiens</em> genes from EntrezGene. See <a href=\"https://thinklab.com/discussion/using-entrez-gene-as-our-gene-vocabulary/34#12\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d34\">discussion</a>.</p>\n\n<blockquote><p>7) Pathway (WikiPathways, Pathway Commons (Reactome+PID)) - All except for duplicate pathways and pathways without multiple participating genes?</p></blockquote>\n\n<p>Yes, see <a href=\"https://thinklab.com/discussion/adding-pathway-resources-to-your-network/72#11\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d72\">this comment</a> and the <a href=\"https://github.com/dhimmel/pathways/blob/1bd2c68853e38297d20f8f885419ff81fc0608a8/merge-resources.ipynb\">source notebook</a>. Only WikiPathways for <em>homo sapiens</em> were included.</p>\n\n<blockquote><p>c) Were there any dependencies when extracting information, e.g. only take genes associated with the approved drugs</p></blockquote>\n\n<p>Sometimes relationships were created for all terms. Sometimes relationships were only created for nodes in Hetionet v1.0. Sometimes nodes in Hetionet v1.0 (e.g. pharmacologic classes) are the only the nodes with relationships in Hetionet v1.0. There is no categorical answer here, you'll have to look at the source code.</p>",
      "body_md": "For reference, the best way to determine the exact steps that went into creating any node or relationship is to look at the [`integrate.ipynb` notebook](https://github.com/dhimmel/integrate/blob/08510696b8d55534b133d66331a97654600469c8/integrate.ipynb). This notebook builds Hetionet v1.0 by loading data from other Rephetio repositories on GitHub. All links are versioned using git commit hashes, so you know the exact state of the input data.\n\nConfirming that @gaya_n's understanding of how nodes were created is correct for points 0, 1, 2, 6, 8.\n\n> 3) Side effects (SIDER + UMLS identifiers) - which ones?\n\nCompound side effects from SIDER 4.1 were mapped to DrugBank compounds. The UMLS concept identifiers corresponding to MedDRA side effects, as provided by SIDER, were used to uniquely identify side effects. If a UMLS side effect was not associated with any DrugBank compounds, it was removed. 5,734 side effect nodes remained. 33 side effects nodes are disconnected in Hetionet v1.0, since Hetionet v1.0 does not include every DrugBank compound. Fore more information, see the SIDER processing [source notebook](https://github.com/dhimmel/SIDER4/blob/be3adebc0d845baaddb907a880890cb5e85f5801/SIDER4.ipynb).\n\n4) Pharmacologic class (DrugCentral) - which ones?\n\nSee [this comment](https://thinklab.com/discussion/incorporating-drugcentral-data-in-our-network/186#4), cell 15 of `integrate.ipynb`, and [`drugcentral-to-rephetio.ipynb`](https://github.com/dhimmel/drugcentral/blob/0e085ddb6aa42be367c85eba424edea716bebd94/drugcentral-to-rephetio.ipynb). Only pharmacologic classes with the following class types were included: Physiologic Effect, Mechanism of Action, and Chemical/Ingredient. The processing method of `drugcentral-to-rephetio.ipynb` removes any pharmacologic classes that don't involve any DrugBank Slim (Hetionet v1.0) compounds.\n\n> 5) Gene (Entrez Gene) - All Protein-coding human genes?\n\nAll protein-coding _homo sapiens_ genes from EntrezGene. See [discussion](https://thinklab.com/discussion/using-entrez-gene-as-our-gene-vocabulary/34#12).\n\n> 7) Pathway (WikiPathways, Pathway Commons (Reactome+PID)) - All except for duplicate pathways and pathways without multiple participating genes?\n\nYes, see [this comment](https://thinklab.com/discussion/adding-pathway-resources-to-your-network/72#11) and the [source notebook](https://github.com/dhimmel/pathways/blob/1bd2c68853e38297d20f8f885419ff81fc0608a8/merge-resources.ipynb). Only WikiPathways for _homo sapiens_ were included.\n\n> c) Were there any dependencies when extracting information, e.g. only take genes associated with the approved drugs\n\nSometimes relationships were created for all terms. Sometimes relationships were only created for nodes in Hetionet v1.0. Sometimes nodes in Hetionet v1.0 (e.g. pharmacologic classes) are the only the nodes with relationships in Hetionet v1.0. There is no categorical answer here, you'll have to look at the source code.",
      "comment_id": 1502,
      "profile_id": 17,
      "published": "2017-04-01T16:03:48.951697Z",
      "thread_id": 226,
      "url": "/doc/7/review#44"
    },
    {
      "body_html": "<h1>Lysenko et al 2016</h1>\r\n\r\n<p>I just came across a study titled \"Representing and querying disease networks using graph databases\" <span class=\"citation\">[<a href=\"https://doi.org/10.1186/s13040-016-0102-8\" class=\"citation \" data-key=\"10.1186/s13040-016-0102-8\">1</a>]</span> that was published on July 25, 2016. The study takes a similar approach to Hetionet: a hetnet was created from publicly available data to encode disease biology.</p>\r\n\r\n<p>The code to produce the database is on GitHub at <a href=\"https://github.com/ibalaur/ProteinFramework\"><code>ibalaur/ProteinFramework</code></a>. Additionally, there is a corresponding public Neo4j instance at <a href=\"https://diseaseknowledgebase.etriks.org/protein/browser/\">https://diseaseknowledgebase.etriks.org/protein/browser/</a>.</p>\r\n\r\n<p>Since the paper was submitted on December 16, 2015, the availability of their public Neo4j instance likely predates <a href=\"https://neo4j.het.io/browser/\">https://neo4j.het.io/browser/</a>. It's reassuring that it's still running, although the instance does not appear to be read-only, which means that anyone can modify it. For example, if a new user tries out the builtin movie graph guide, they will end up creating nodes and relationships.</p>",
      "body_md": "# Lysenko et al 2016\r\n\r\nI just came across a study titled \"Representing and querying disease networks using graph databases\" [@10.1186/s13040-016-0102-8] that was published on July 25, 2016. The study takes a similar approach to Hetionet: a hetnet was created from publicly available data to encode disease biology.\r\n\r\nThe code to produce the database is on GitHub at [`ibalaur/ProteinFramework`](https://github.com/ibalaur/ProteinFramework). Additionally, there is a corresponding public Neo4j instance at https://diseaseknowledgebase.etriks.org/protein/browser/.\r\n\r\nSince the paper was submitted on December 16, 2015, the availability of their public Neo4j instance likely predates https://neo4j.het.io/browser/. It's reassuring that it's still running, although the instance does not appear to be read-only, which means that anyone can modify it. For example, if a new user tries out the builtin movie graph guide, they will end up creating nodes and relationships.",
      "comment_id": 1503,
      "profile_id": 17,
      "published": "2017-04-10T19:51:54.799528Z",
      "thread_id": 216,
      "url": "/discussion/hosting-hetionet-in-the-cloud-creating-a-public-neo4j-instance/216#2"
    },
    {
      "body_html": "<p>Update reference to <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nbt.3780\" class=\"citation \" data-key=\"10.1038/nbt.3780\">1</a>]</span> or consider removing if out of scope.</p>",
      "body_md": "Update reference to [@10.1038/nbt.3780] or consider removing if out of scope.",
      "comment_id": 1504,
      "profile_id": 17,
      "published": "2017-04-10T19:57:52.716546Z",
      "thread_id": 226,
      "url": "/doc/7/review#45"
    },
    {
      "body_html": "<p>Cite <span class=\"citation\">[<a href=\"https://doi.org/10.1186/s13040-016-0102-8\" class=\"citation \" data-key=\"10.1186/s13040-016-0102-8\">1</a>]</span> (see <a href=\"https://thinklab.com/discussion/hosting-hetionet-in-the-cloud-creating-a-public-neo4j-instance/216#2\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d216\">comment here</a>)</p>",
      "body_md": "Cite [@10.1186/s13040-016-0102-8] (see [comment here](https://thinklab.com/discussion/hosting-hetionet-in-the-cloud-creating-a-public-neo4j-instance/216#2))",
      "comment_id": 1505,
      "profile_id": 17,
      "published": "2017-04-10T19:58:49.539787Z",
      "thread_id": 226,
      "url": "/doc/7/review#46"
    },
    {
      "body_html": "<h1>Literature on using Neo4j for biomedical hetnets</h1>\r\n\r\n<p>Here we'll compile a list of studies that discuss using Neo4j or graph databases for hetnets related to biology or medicine.</p>\r\n\r\n<ul><li><p>\"Are graph databases ready for bioinformatics?\" by <a href=\"/u/larsjuhljensen\" class=\"username\">@larsjuhljensen</a> as <a href=\"#note-219\">noted above</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/bioinformatics/btt549\" class=\"citation \" data-key=\"10.1093/bioinformatics/btt549\">1</a>]</span></p></li><li><p>\"Representing and querying disease networks using graph databases\" which we <a href=\"https://thinklab.com/discussion/hosting-hetionet-in-the-cloud-creating-a-public-neo4j-instance/216#2\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d216\">discussed here</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1186/s13040-016-0102-8\" class=\"citation \" data-key=\"10.1186/s13040-016-0102-8\">2</a>]</span></p></li><li><p>\"Use of Graph Database for the Integration of Heterogeneous Biological Data\" which found that Neo4j was faster than MySQL for some common queries on a biological hetnet <span class=\"citation\">[<a href=\"https://doi.org/10.5808/GI.2017.15.1.19\" class=\"citation \" data-key=\"10.5808/GI.2017.15.1.19\">3</a>]</span>.</p></li></ul>",
      "body_md": "# Literature on using Neo4j for biomedical hetnets\r\n\r\nHere we'll compile a list of studies that discuss using Neo4j or graph databases for hetnets related to biology or medicine.\r\n\r\n+ \"Are graph databases ready for bioinformatics?\" by @larsjuhljensen as [noted above](#note-219) [@10.1093/bioinformatics/btt549]\r\n\r\n+ \"Representing and querying disease networks using graph databases\" which we [discussed here](https://thinklab.com/discussion/hosting-hetionet-in-the-cloud-creating-a-public-neo4j-instance/216#2) [@10.1186/s13040-016-0102-8]\r\n\r\n+ \"Use of Graph Database for the Integration of Heterogeneous Biological Data\" which found that Neo4j was faster than MySQL for some common queries on a biological hetnet [@10.5808/GI.2017.15.1.19].",
      "comment_id": 1506,
      "profile_id": 17,
      "published": "2017-04-27T14:44:00.193017Z",
      "thread_id": 112,
      "url": "/discussion/using-the-neo4j-graph-database-for-hetnets/112#9"
    },
    {
      "body_html": "<h1>Thinkable Bioinformatics Peer Prize</h1>\r\n\r\n<p>We've entered the <a href=\"https://the-bioinformatics-peer-prize.thinkable.org\">Bioinformatics Peer Prize</a> by Thinkable. You can <a href=\"https://www.thinkable.org/submission_entries/Y8g4lO9Q\"><strong>see our entry here</strong></a>, which is based on version 2 of our <em>bioRxiv</em> preprint <span class=\"citation\">[<a href=\"https://doi.org/10.1101/087619\" class=\"citation \" data-key=\"10.1101/087619\">1</a>]</span>.</p>\r\n\r\n<p>To vote, you'll need to <a href=\"https://www.thinkable.org/researcher_signup\">signup</a> for an account and submit verification of your researcher status in the form of:</p>\r\n\r\n<ol><li>a University email address</li><li>a link to a peer-reviewed publication from the last five years</li></ol>\r\n\r\n<p>Thinkable can take up to two days to verify your status. Voting closes on May 11, 2017, so don't delay. You can also vote for multiple projects, so once verified you may also find other projects you'd like to support!</p>\r\n\r\n<p>Just to clarify: there is no relationship between Thinklab and Thinkable — they just happen to have a <a href=\"https://en.wikipedia.org/wiki/Levenshtein_distance\">Levenshtein distance</a> of only 3!</p>",
      "body_md": "# Thinkable Bioinformatics Peer Prize\r\n\r\nWe've entered the [Bioinformatics Peer Prize](https://the-bioinformatics-peer-prize.thinkable.org) by Thinkable. You can [**see our entry here**](https://www.thinkable.org/submission_entries/Y8g4lO9Q), which is based on version 2 of our _bioRxiv_ preprint [@10.1101/087619].\r\n\r\nTo vote, you'll need to [signup](https://www.thinkable.org/researcher_signup) for an account and submit verification of your researcher status in the form of:\r\n\r\n1. a University email address\r\n2. a link to a peer-reviewed publication from the last five years\r\n\r\nThinkable can take up to two days to verify your status. Voting closes on May 11, 2017, so don't delay. You can also vote for multiple projects, so once verified you may also find other projects you'd like to support!\r\n\r\nJust to clarify: there is no relationship between Thinklab and Thinkable -- they just happen to have a [Levenshtein distance](https://en.wikipedia.org/wiki/Levenshtein_distance) of only 3!",
      "comment_id": 1507,
      "profile_id": 17,
      "published": "2017-05-02T16:18:01.851943Z",
      "thread_id": 113,
      "url": "/discussion/tracking-project-reuse-citation-and-publicity/113#15"
    },
    {
      "body_html": "<h1>DigitalOcean Sponsorship</h1>\r\n\r\n<p><a href=\"https://www.digitalocean.com/\">DigitalOcean</a> has sponsored the Hetionet Browser for at least the next year, as part of their program to support open source (see <a href=\"https://twitter.com/digitalocean/status/859511358026633218\">Tweet</a>). As a reminder, our hosting costs are $20 a month for <a href=\"https://neo4j.het.io\">https://neo4j.het.io</a>. Thanks DigitalOcean!</p>\r\n\r\n<p>From this and other projects, I've found the user interfaces and prices at DigitalOcean and Google Cloud are favorable compared to Amazon Web Services.</p>",
      "body_md": "# DigitalOcean Sponsorship\r\n\r\n[DigitalOcean](https://www.digitalocean.com/) has sponsored the Hetionet Browser for at least the next year, as part of their program to support open source (see [Tweet](https://twitter.com/digitalocean/status/859511358026633218)). As a reminder, our hosting costs are $20 a month for https://neo4j.het.io. Thanks DigitalOcean!\r\n\r\nFrom this and other projects, I've found the user interfaces and prices at DigitalOcean and Google Cloud are favorable compared to Amazon Web Services.",
      "comment_id": 1508,
      "profile_id": 17,
      "published": "2017-05-17T15:04:14.577190Z",
      "thread_id": 216,
      "url": "/discussion/hosting-hetionet-in-the-cloud-creating-a-public-neo4j-instance/216#3"
    }
  ],
  "documents": [
    {
      "body_html": "<h1 id=\"abstract\">Abstract</h1>\r\n\r\n<p>This project aims to predict new therapeutic indications for small molecules. We will focus on repurposing drugs for well-studied complex human diseases, relying on recently-available high-throughput data sources. The approach is integrative, seeking to combine multiple information domains through heterogeneous networks and modern machine learning techniques.</p>\r\n\r\n<h1 id=\"objectives\">Objectives</h1>\r\n\r\n<ol><li><p><strong>Create an open resource for integrative drug repurposing.</strong> <br>A slew of bioinformatics resources have recently come online. Yet, these resources frequently rely on different vocabularies and require cleaning. We plan to release a network capturing a systems biology perspective of drug efficacy. Standardized vocabularies will form a network template and will be connected by the results of high-throughput experimentation. Structuring the resource as a network ensures the data is processed and reusable. The complete resource will be posted to our <a href=\"http://het.io\">online portal for heterogeneous data integration</a> under a <a href=\"https://creativecommons.org/licenses/by/4.0/\">CC-BY license</a> and will provide a goto dataset for researchers implementing systems/network/computational pharmacology analyses.</p></li><li><p><strong>Compare and identify influential mechanisms of drug efficacy.</strong> <br>The mechanism of action is poorly understood for many prevalent small molecule therapies. Discovering mechanisms through target identification has proven difficult. High-throughput drug and disease signatures offer an alternative approach for investigating a compound's mechanism of action. We plan to identify influential network connections that underlie drug efficacy. Greater insight into how existing drugs work will help us understand current treatments and predict future treatments. More immediately, our results will compare the informativeness of data sources, providing a solid foundation for computational drug repurposing.</p></li><li><p><strong>Predict probabilities for each small molecule's efficacy in treating each complex disease.</strong> <br>Serendipity was responsible for the discovery of many breakthrough small molecule therapies <span class=\"citation\">[<a href=\"http://www.dialogues-cns.com/publication/the-role-of-serendipity-in-drug-discovery/\" class=\"citation\" data-key=\"Ban06\">1</a>]</span>. Additionally, small molecules frequently treat multiple distinct diseases <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.drudis.2012.08.005\" class=\"citation\" data-key=\"10.1016/j.drudis.2012.08.005\">2</a>]</span>. Rational systems-based drug repurposing overcomes the inefficiency and unreliability of serendipity, while capturing the benefits of polypharmacology and network pharmacology. From the integrative network, we will predict the probability that a given small molecule will treat a given complex disease. Our predictions will provide pharmacologists with evidence-based drug leads, which could develop into novel approved uses for existing drug.</p></li></ol>\r\n\r\n\r\n\r\n<h1 id=\"background\">Background</h1>\r\n\r\n<p>Pharmaceutical companies seeking to bring a novel therapeutic compound to market face a single digit success rate, price tag in the billions, and duration spanning decades <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nrd1468\" class=\"citation\" data-key=\"10.1038/nrd1468\">3</a>]</span>. The trend in research efficiency is equally grim: the cost of developing a new drug has increased exponentially, doubling approximately every nine years since 1950 <span class=\"citation\">[<a href=\"https://doi.org/10.6084/m9.figshare.937004\" class=\"citation\" data-key=\"10.6084/m9.figshare.937004\">4</a>]</span>.</p>\r\n\r\n<p>Since the 90&#8217;s, the prevailing model of drug discovery has focused on identifying compounds that target a single protein with maximum specificity. Through a molecular, reductionist approach to understanding disease, a plausible target is selected. Drugs are then designed to modulate the target or small molecules with a strong target affinity are identified using high throughput screens. However, overwhelming evidence suggests that the potential of the 'one drug, one target, one disease' approach is limited. Biological systems are characterized by phenotypic robustness: knockout experiments in model organisms reveal that less than one fifth of genes are essential for survival <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nchembio.118\" class=\"citation\" data-key=\"10.1038/nchembio.118\">5</a>]</span>. Similarly, pathology may represent a resilient homeostatic state, resistant to disruptions of a single protein. Approved small molecules affect on average 2.7 known targets, and when accounting for speculative targets that number jumps to 6.3 <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nbt0908-983\" class=\"citation\" data-key=\"10.1038/nbt0908-983\">6</a>]</span>. This promiscuity can play an important role in drug efficacy as exemplified by clozapine which remains the preeminent anti-psychotic drug over compounds engineered to bind a subset of its dozen-plus targets <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nrd1346\" class=\"citation\" data-key=\"10.1038/nrd1346\">7</a>]</span>.</p>\r\n\r\n<p>Uncovering disease therapies that rely on multiple mechanisms, known as <strong>polypharmacology</strong>, requires escaping the limitations of the 'magic bullet' paradigm in favor of a 'magic 00 buckshot' understanding of drug efficacy. An approach called <strong>network pharmacology</strong> seeks to characterize the multitude of corruptions embodying a pathology. With that knowledge, drugs are selected to restore a normal state. Network pharmacology encompasses polypharmacology by evaluating drugs which intervene at multiple points to achieve healthy homeostasis.</p>\r\n\r\n<p>Drug <strong>repurposing</strong> &#8212; identifying novel uses for existing therapeutics &#8212; avoids many pitfalls and challenges of designing drugs from scratch. FDA approved drugs have undergone extensive toxicology profiling during development and safety evaluation in Phase III clinical trials. Given ample time on the market, post-marketing trials and adverse event reporting uncover potential flaws that could lead to withdrawal. The wealth of information surrounding approved drugs creates a favorable outcome for repurposed compounds compared to new molecular entities: time to approval is cut in half to as low as three years <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nrd1468\" class=\"citation\" data-key=\"10.1038/nrd1468\">3</a>]</span>; the success rate of advancing from phase II trials to approval increases from 10 to 25 percent <span class=\"citation\">[<a href=\"http://cen.acs.org/articles/90/i40/Drug-Repurposing.html\" class=\"citation\" data-key=\"Thayer12\">8</a>]</span>; and the average development cost for successful drugs plummets from 1.3 billion to as low as 8.4 million dollars <span class=\"citation\">[<a href=\"http://www.ddw-online.com/media/32/2226/drug-repositioning.pdf\" class=\"citation\" data-key=\"Persidis11\">9</a>]</span>.</p>\r\n\r\n<p>Between 1999 and 2008, more first-in-class small-molecule drugs were discovered with phenotypic screening than target-centric approaches, despite preferential investment towards the later <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nrd3480\" class=\"citation\" data-key=\"10.1038/nrd3480\">10</a>]</span>. The advent of omics-technologies has enabled the quantification of several intermediate phenotypes between a disease's (or drug's) molecular basis and clinical manifestation. Intermediate phenotypes include transcriptional profiles, biological pathways, and genetic susceptibility markers. Traditional phenotypic approaches have focused on <em>in vivo</em> screening to identify compounds that alter a primary clinical indicator. <em>In silico</em> screening that instead relies on intermediate phenotypes offers a less costly and time-consuming way forward. Such approaches are easily amenable to leveraging repurposing, polypharmacology, and network pharmacology.</p>\r\n\r\n<p>We propose an integrative method for repurposing approved small molecules to treat additional complex diseases. The approach relies on characterizing the effect of compounds and diseases using high-throughput resources &#8212; many of which provide intermediate-phenotypic profiles for compounds and diseases &#8212; and, from this information, calculating features that describe specific aspects of a compound-disease relationship. From these features, a machine learning approach identifies the influential mechanisms behind drug efficacy and predicts additional indications for existing drugs.</p>\r\n\r\n<p>We chose to focus on complex diseases because they frequently exhibit:</p>\r\n\r\n<ul><li>poorly understood molecular bases</li><li>modest efficacy of approved therapies</li><li>multifactorial etiologies that highlight multiple modalities for intervention</li><li>good coverage in high-throughput bioinformatic resources</li></ul>\r\n\r\n<p>We chose to focus on small molecules because they exhibit:</p>\r\n\r\n<ul><li>known structures</li><li>greater data-availability than biologics</li><li>promiscuous binding, which enables polypharmacology</li><li>incomplete target knowledge, which can be overcome with phenotypic profiling</li></ul>\r\n\r\n\r\n\r\n\r\n\r\n<h1 id=\"research-plan\">Research Plan</h1>\r\n\r\n<h2 id=\"part-1-resource-construction\">Part 1. Resource Construction</h2>\r\n\r\n<p>First, we will construct a resource that encodes a systems perspective of pathogenesis and pharmacology. We will structure the resource as a network where entities (nodes) are connected by their relationships (edges). Nodes and edges belong to predefined types &#8212; respectively called metanodes (<a href=\"#metanodes\">Table 1</a>) and metaedges (<a href=\"#metaedges\">Table 2</a>). The schematic view showing how types relate is called a metagraph (<a href=\"#metagraph\">Figure 1</a>). </p>\r\n\r\n<a name=\"metanodes\"></a><div class=\"figure\" figure-id=\"metanodes\">\n            <div class=\"signature-3\">\n                <div class=\"figure-title\">Table 1. Metanodes</div>\n                <div class=\"figure-description\"><p>The network will consist of the following node types. Domain-specific vocabularies provide standardized terminologies for each node type.</p></div>\n            </div>\n        <div class=\"figure-content\"><table class=\"table markdown-table\"><thead><tr><th>Type</th><th>Resource</th><th>Cite</th></tr></thead><tbody><tr><td>Compound</td><td><a href=\"http://www.drugbank.ca/\">DrugBank</a></td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkt1068\" class=\"citation\" data-key=\"10.1093/nar/gkt1068\">11</a>]</span></td></tr><tr><td>Disease</td><td><a href=\"http://disease-ontology.org/\">Disease Ontology</a></td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkr972\" class=\"citation\" data-key=\"10.1093/nar/gkr972\">12</a>]</span></td></tr><tr><td>Gene</td><td><a href=\"//www.ncbi.nlm.nih.gov/gene\">Entrez Gene</a></td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gki031\" class=\"citation\" data-key=\"10.1093/nar/gki031\">13</a>]</span></td></tr><tr><td>Anatomy</td><td><a href=\"https://uberon.github.io/\">Uberon</a></td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1186/gb-2012-13-1-r5\" class=\"citation\" data-key=\"10.1186/gb-2012-13-1-r5\">14</a>]</span></td></tr><tr><td>Cellular Component</td><td><a href=\"http://geneontology.org/\">Gene Ontology</a></td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gku1179\" class=\"citation\" data-key=\"10.1093/nar/gku1179\">15</a>, <a href=\"https://doi.org/10.1038/75556\" class=\"citation\" data-key=\"10.1038/75556\">16</a>]</span></td></tr><tr><td>Molecular Function</td><td><a href=\"http://geneontology.org/\">Gene Ontology</a></td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gku1179\" class=\"citation\" data-key=\"10.1093/nar/gku1179\">15</a>, <a href=\"https://doi.org/10.1038/75556\" class=\"citation\" data-key=\"10.1038/75556\">16</a>]</span></td></tr><tr><td>Biological Process</td><td><a href=\"http://geneontology.org/\">Gene Ontology</a></td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gku1179\" class=\"citation\" data-key=\"10.1093/nar/gku1179\">15</a>, <a href=\"https://doi.org/10.1038/75556\" class=\"citation\" data-key=\"10.1038/75556\">16</a>]</span></td></tr><tr><td>Perturbation Gene Set</td><td><a href=\"https://www.broadinstitute.org/gsea/msigdb/index.jsp\">Molecular Signatures Database</a> (MSigDB 5.0)</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1093/bioinformatics/btr260\" class=\"citation\" data-key=\"10.1093/bioinformatics/btr260\">17</a>]</span></td></tr><tr><td>Pathway</td><td><a href=\"https://www.broadinstitute.org/gsea/msigdb/index.jsp\">Molecular Signatures Database</a> (MSigDB 5.0)</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1093/bioinformatics/btr260\" class=\"citation\" data-key=\"10.1093/bioinformatics/btr260\">17</a>]</span></td></tr><tr><td>Pathway</td><td><a href=\"//www.wikipathways.org/index.php/WikiPathways\">WikiPathways</a></td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pbio.0060184\" class=\"citation\" data-key=\"10.1371/journal.pbio.0060184\">18</a>]</span></td></tr><tr><td>Side Effect</td><td><a href=\"http://www.nlm.nih.gov/pubs/factsheets/umlsmeta.html\">UMLS Metathesaurus</a></td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkh061\" class=\"citation\" data-key=\"10.1093/nar/gkh061\">19</a>]</span></td></tr><tr><td>Symptom</td><td><a href=\"//www.nlm.nih.gov/mesh/\">MeSH</a></td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1001/jama.1994.03510380059038\" class=\"citation\" data-key=\"10.1001/jama.1994.03510380059038\">20</a>]</span></td></tr></tbody></table></div></div>\r\n\r\n<a name=\"metaedges\"></a><div class=\"figure\" figure-id=\"metaedges\">\n            <div class=\"signature-3\">\n                <div class=\"figure-title\">Table 2. Metaedges</div>\n                <div class=\"figure-description\"><p>The network will consist of the following edge types. High-throughput bioinformatics resources provide the necessary information for connecting nodes.</p></div>\n            </div>\n        <div class=\"figure-content\"><table class=\"table markdown-table\"><thead><tr><th>Source</th><th>Target</th><th>Type</th><th>Resource</th><th>Cite</th></tr></thead><tbody><tr><td>Compound</td><td>Disease</td><td>Indication</td><td><a href=\"http://knowledgemap.mc.vanderbilt.edu/research/content/MEDI\">MEDI</a></td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1136/amiajnl-2012-001431\" class=\"citation\" data-key=\"10.1136/amiajnl-2012-001431\">21</a>]</span></td></tr><tr><td>Compound</td><td>Disease</td><td>Indication</td><td><a href=\"http://ftp.ncbi.nlm.nih.gov/pub/lu/LabeledIn/\">LabeledIn</a></td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.jbi.2014.08.004\" class=\"citation\" data-key=\"10.1016/j.jbi.2014.08.004\">22</a>, <a href=\"https://doi.org/10.1093/database/bav016\" class=\"citation\" data-key=\"10.1093/database/bav016\">23</a>]</span></td></tr><tr><td>Compound</td><td>Disease</td><td>Indication</td><td>ehrlink</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1136/amiajnl-2012-000852\" class=\"citation\" data-key=\"10.1136/amiajnl-2012-000852\">24</a>]</span></td></tr><tr><td>Compound</td><td>Disease</td><td>Indication</td><td>PREDICT</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1021/ci100050t\" class=\"citation\" data-key=\"10.1021/ci100050t\">25</a>]</span></td></tr><tr><td>Compound</td><td>Compound</td><td>Similarity</td><td>Dice index of ECFPs</td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1038/msb.2011.26\" class=\"citation\" data-key=\"10.1038/msb.2011.26\">26</a>]</span></td></tr><tr><td>Compound</td><td>Gene</td><td>Binding</td><td><a href=\"//www.bindingdb.org/bind/index.jsp\">BindingDB</a></td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkl999\" class=\"citation\" data-key=\"10.1093/nar/gkl999\">27</a>]</span></td></tr><tr><td>Compound</td><td>Gene</td><td>Target</td><td><a href=\"http://www.drugbank.ca/\">DrugBank</a></td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkt1068\" class=\"citation\" data-key=\"10.1093/nar/gkt1068\">11</a>]</span></td></tr><tr><td>Compound</td><td>Gene</td><td>Expression</td><td><a href=\"http://www.lincscloud.org/l1000/\">LINCS</a></td><td></td></tr><tr><td>Compound</td><td>Side Effect</td><td>Causation</td><td><a href=\"https://www.pharmgkb.org/downloads/\">OFFSIDES</a></td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1126/scitranslmed.3003377\" class=\"citation\" data-key=\"10.1126/scitranslmed.3003377\">28</a>]</span></td></tr><tr><td>Compound</td><td>Side Effect</td><td>Causation</td><td><a href=\"http://sideeffects.embl.de/\">SIDER 4</a></td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1038/msb.2009.98\" class=\"citation\" data-key=\"10.1038/msb.2009.98\">29</a>]</span></td></tr><tr><td>Disease</td><td>Gene</td><td>Variation</td><td><a href=\"https://www.ebi.ac.uk/gwas/\">GWAS Catalog</a></td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkt1229\" class=\"citation\" data-key=\"10.1093/nar/gkt1229\">30</a>]</span></td></tr><tr><td>Disease</td><td>Gene</td><td>Association</td><td><a href=\"http://diseases.jensenlab.org/Search\">DISEASES</a></td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.ymeth.2014.11.020\" class=\"citation\" data-key=\"10.1016/j.ymeth.2014.11.020\">31</a>]</span></td></tr><tr><td>Disease</td><td>Gene</td><td>Association</td><td><a href=\"http://www.disgenet.org/web/DisGeNET/menu/home\">DisGeNET</a></td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1093/database/bav028\" class=\"citation\" data-key=\"10.1093/database/bav028\">32</a>]</span></td></tr><tr><td>Disease</td><td>Gene</td><td>Association</td><td><a href=\"http://doa.nubic.northwestern.edu/pages/search.php\">DOAF</a></td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pone.0049686\" class=\"citation\" data-key=\"10.1371/journal.pone.0049686\">33</a>]</span></td></tr><tr><td>Disease</td><td>Gene</td><td>Expression</td><td><a href=\"http://dev.stargeo.io/\">STAR-GEO</a></td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/30.1.207\" class=\"citation\" data-key=\"10.1093/nar/30.1.207\">34</a>]</span></td></tr><tr><td>Disease</td><td>Symptom</td><td>Causation</td><td><a href=\"//www.nlm.nih.gov/pubs/factsheets/medline.html\">MEDLINE</a> Cooccurrence</td><td></td></tr><tr><td>Disease</td><td>Anatomy</td><td>Localization</td><td><a href=\"//www.nlm.nih.gov/pubs/factsheets/medline.html\">MEDLINE</a> Cooccurrence</td><td></td></tr><tr><td>Disease</td><td>Disease</td><td>Similarity</td><td><a href=\"//www.nlm.nih.gov/pubs/factsheets/medline.html\">MEDLINE</a> Cooccurrence</td><td></td></tr><tr><td>Gene</td><td>Gene</td><td>Interaction</td><td><a href=\"http://interactome.dfci.harvard.edu/H_sapiens/index.php?page=download\">Human Interactome Project</a></td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.cell.2014.10.050\" class=\"citation\" data-key=\"10.1016/j.cell.2014.10.050\">35</a>]</span></td></tr><tr><td>Gene</td><td>Gene</td><td>Interaction</td><td><a href=\"http://www.sciencemag.org/content/347/6224/1257601/suppl/DC1\">The Incomplete Interactome</a></td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1126/science.1257601\" class=\"citation\" data-key=\"10.1126/science.1257601\">36</a>]</span></td></tr><tr><td>Gene</td><td>Gene</td><td>Evolution</td><td><a href=\"http://csb.pitt.edu/erc_analysis/Methods.php\">Evolutionary Rate Covariation</a></td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pgen.1004967\" class=\"citation\" data-key=\"10.1371/journal.pgen.1004967\">37</a>]</span></td></tr><tr><td>Gene</td><td>Pathway</td><td>Membership</td><td><a href=\"http://www.wikipathways.org/index.php/WikiPathways\">WikiPathways</a></td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pbio.0060184\" class=\"citation\" data-key=\"10.1371/journal.pbio.0060184\">18</a>]</span></td></tr><tr><td>Gene</td><td>Pathway</td><td>Membership</td><td><a href=\"http://www.broadinstitute.org/gsea/msigdb/index.jsp\">MSigDB 5.0</a></td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1093/bioinformatics/btr260\" class=\"citation\" data-key=\"10.1093/bioinformatics/btr260\">17</a>]</span></td></tr><tr><td>Gene</td><td>Perturbation Gene Set</td><td>Regulation</td><td><a href=\"http://www.broadinstitute.org/gsea/msigdb/index.jsp\">MSigDB 5.0</a></td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1093/bioinformatics/btr260\" class=\"citation\" data-key=\"10.1093/bioinformatics/btr260\">17</a>]</span></td></tr><tr><td>Gene</td><td>Biological Process</td><td>Membership</td><td><a href=\"http://geneontology.org/page/download-annotations\">Gene Ontology annotations</a></td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gku1179\" class=\"citation\" data-key=\"10.1093/nar/gku1179\">15</a>, <a href=\"https://doi.org/10.1038/75556\" class=\"citation\" data-key=\"10.1038/75556\">16</a>]</span></td></tr><tr><td>Gene</td><td>Molecular Function</td><td>Membership</td><td><a href=\"http://geneontology.org/page/download-annotations\">Gene Ontology annotations</a></td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gku1179\" class=\"citation\" data-key=\"10.1093/nar/gku1179\">15</a>, <a href=\"https://doi.org/10.1038/75556\" class=\"citation\" data-key=\"10.1038/75556\">16</a>]</span></td></tr><tr><td>Gene</td><td>Cellular Component</td><td>Membership</td><td><a href=\"http://geneontology.org/page/download-annotations\">Gene Ontology annotations</a></td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gku1179\" class=\"citation\" data-key=\"10.1093/nar/gku1179\">15</a>, <a href=\"https://doi.org/10.1038/75556\" class=\"citation\" data-key=\"10.1038/75556\">16</a>]</span></td></tr><tr><td>Gene</td><td>Anatomy</td><td>Expression</td><td><a href=\"http://bgee.unil.ch/\">Bgee</a></td><td><span class=\"citation\">[<a href=\"https://doi.org/10.1007/978-3-540-69828-9_12\" class=\"citation\" data-key=\"10.1007/978-3-540-69828-9_12\">38</a>]</span></td></tr><tr><td>Gene</td><td>Anatomy</td><td>Expression</td><td><a href=\"http://tissues.jensenlab.org/Search\">TISSUES</a></td><td><span class=\"citation\">[<a href=\"https://doi.org/10.7717/peerj.1054\" class=\"citation\" data-key=\"10.7717/peerj.1054\">39</a>]</span></td></tr></tbody></table></div></div>\r\n\r\n<p>Each node type will be populated using a domain-specific vocabulary (<a href=\"#metanodes\">Table 1</a>). Controlled vocabularies provide a backbone for data integration, ensure entities are conceptually unique, and enable easy annotation for future users. Edges will be extracted from high-throughput bioinformatics resources (<a href=\"#metaedges\">Table 2</a>). We aim to incorporate resources that are high-throughput, high-quality, and publicly-available. When possible, systematic resources that circumvent knowledge biases will be employed.</p>\r\n\r\n<a name=\"metagraph\"></a><div class=\"figure\" figure-id=\"metagraph\"><div class=\"figure-content\"><img src=\"http://think-lab.s3.amazonaws.com/m/figures/3.png\"></div>\n            <div class=\"signature-1\">\n                <div class=\"figure-title\">Figure 1. Metagraph of the heterogeneous network</div>\n                <div class=\"figure-description\"><p>A schematic view of the node and edge types composing the network.</p></div>\n            </div>\n        </div>\r\n\r\n<p>We are <a href=\"http://thinklab.org/p/rephetio/how-should-we-construct-a-catalog-of-drug-indications/21\">currently exploring</a> various resources to provide a high-throughput catalog of indications. Feedback here would be appreciated.</p>\r\n\r\n<h2 id=\"part-2-discovering-mechanisms-of-drug-efficacy\">Part 2. Discovering Mechanisms of Drug Efficacy</h2>\r\n\r\n<p>Features describe the relationship between a compound and disease. Each feature measures a certain aspect of a compound-disease relationship: for example, whether the compound targets a susceptibility gene of the disease or whether the compound downregulates genes that are overexpressed in the disease state. Features that distinguish therapeutic from untherapeutic compound-disease pairs represent mechanisms of drug efficacy. We refer to the discriminatory power of each feature as its performance. The performance of each feature indicates its pharmacological importance. And by comparing performance across features, we can contrast the informativeness of orthogonal domains of information. Finally, features describing the same general relationship but based on different data sources can identify the most informative resource or technology out of many.</p>\r\n\r\n<p>Features will be computed from the network. Each feature will measure the prevalence of a specific type of path between a compound and disease. This approach was initially developed for social network analysis <span class=\"citation\">[<a href=\"https://doi.org/10.1109/ASONAM.2011.112\" class=\"citation\" data-key=\"10.1109/ASONAM.2011.112\">40</a>]</span>, and later adapted by us for predicting disease-associated genes <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1004259\">41</a>]</span>. Briefly, the method identifies all paths between a source and target node that follow a specified type of path (metapath). The contribution of each path is weighted by its specificity: paths through high-degree nodes, which are likely to be less informative, are downweighted. The sum of the weighted paths results in a value of 0 or greater, where 0 indicates no connectivity. We plan to use the <a href=\"http://het.io/hnep\"><em>degree-weighted path count</em> metric</a> for computing features <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1004259\">41</a>]</span>. The interpretation of a specific feature depends on its corresponding metapath. <a href=\"#metapaths\">Table 3</a> provides example metapaths and describes their pharmacological significance.</p>\r\n\r\n<a name=\"metapaths\"></a><div class=\"figure\" figure-id=\"metapaths\">\n            <div class=\"signature-3\">\n                <div class=\"figure-title\">Table 3. The interpretation of features for select metapaths</div>\n                <div class=\"figure-description\"><p>Features measure the prevalence of a specific metapath between the source compound and target disease. Metapaths are abbreviated using the first letter of each metanode (uppercase) and metaedge (lowercase). Refer to <a href=\"#metagraph\">Figure 1</a> for metanode and metaedge names.</p></div>\n            </div>\n        <div class=\"figure-content\"><table class=\"table markdown-table\"><thead><tr><th>Metapath</th><th>Measures the extent that ...</th></tr></thead><tbody><tr><td><em>CuGdD</em></td><td>genes downregulated by the disease are upregulated by the compound</td></tr><tr><td><em>CtGaD</em></td><td>the compound targets genes associated with the disease</td></tr><tr><td><em>CtGiGaD</em></td><td>the compound targets genes that interact with genes associated with the disease</td></tr><tr><td><em>CcScCiD</em></td><td>the compound shares side effects with compounds indicated for the disease</td></tr><tr><td><em>CtGeTlD</em></td><td>the compound targets genes that are expressed in tissues affected by the disease</td></tr><tr><td><em>CiDmPmD</em></td><td>the compound is indicated for diseases with the same pathophysiology as the target disease</td></tr></tbody></table></div></div>\r\n\r\n<p>Metapath-based approaches have several advantages for predictive data integration including <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1004259\">41</a>]</span>:</p>\r\n\r\n<blockquote><ul><li>versatility (most biological phenomena are decomposable into entities connected by relationships)</li><li>scalability (no theoretical limit to metagraph complexity or graph size)</li><li>efficiency (low marginal cost to including an additional network component)</li></ul></blockquote>\r\n\r\n<p>Harnessing these advantages, we hope to evaluate and compare a diverse and broad set of potential mechanisms of efficacy.</p>\r\n\r\n<h2 id=\"part-3-predicting-probabilities-of-efficacy\">Part 3. Predicting Probabilities of Efficacy</h2>\r\n\r\n<p>We plan to predict probabilities of efficacy for compound-disease pairs using heterogeneous network edge prediction <span class=\"citation\">[<a href=\"https://doi.org/10.1109/ASONAM.2011.112\" class=\"citation\" data-key=\"10.1109/ASONAM.2011.112\">40</a>, <a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1004259\">41</a>]</span>. This approach trains a model from the network-based features and can return a probability of efficacy for any compound-disease pair. Previously, our implementation relied on regularized logistic regression, but <a href=\"https://topepo.github.io/caret/index.html\">modern software packages</a> will allow us to rigorously evaluate a broad range of machine learning algorithms.</p>\r\n\r\n<p><a name=\"open-science\"></a></p>\r\n\r\n<h1 id=\"open-science\">Open science</h1>\r\n\r\n<p>We are committed to a transparent, freely available, reusable, and reproducible scientific process and believe open science can revolutionize medicine <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pbio.1002164\" class=\"citation\" data-key=\"10.1371/journal.pbio.1002164\">42</a>]</span>. To this end, we will release all project related code on <a href=\"https://github.com/dhimmel\">GitHub</a>. Datasets that are too large for GitHub will be published on <a href=\"http://figshare.com/authors/Daniel_Himmelstein/523637\">figshare</a>. All original materials will be released under <a href=\"https://creativecommons.org/licenses/by/4.0/\">CC-BY</a> (requires attribution) or <a href=\"https://creativecommons.org/publicdomain/zero/1.0/\">CC-0</a> (public domain) licences. Derivatives of restrictively-licensed works will be released under the most permissive option available. Our analyses will be made available in real-time using <a href=\"https://pages.github.com/\">GitHub pages</a> to host <a href=\"http://rmarkdown.rstudio.com/\">R Markdown</a> documents and <a href=\"http://ipython.org/notebook.html\">IPython Notebooks</a>. Finally, we plan to follow <a href=\"http://dx.doi.org/10.1371/journal.pcbi.1003285\">10 proposed rules</a> for reproducible research in computational biology <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1003285\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1003285\">43</a>]</span>. </p>\r\n\r\n<h1 id=\"thoughts\">Thoughts?</h1>\r\n\r\n<p>Share your ideas by commenting on an existing discussion or by starting a new thread. Our goal in joining ThinkLab is to generate as much interaction as possible.</p>\r\n\r\n<h1 id=\"team-resources\">Team &amp; Resources</h1>\r\n\r\n<p><a href=\"http://dhimmel.com\">Daniel Himmelstein</a> is a PhD candidate in the <em>Biological &amp; Medical Informatics</em> program at UCSF. Daniel works in the <a href=\"http://baranzinilab.ucsf.edu/\">Sergio Baranzini Lab</a> whose mission is to apply cutting-edge bioinformatic approaches to genomic data, with a focus on multiple sclerosis. Dr. Baranzini has extensive experience with data integration, genomic profiling, and disease bioinformatics.</p>\r\n\r\n<p>UCSF and the surrounding Bay Area are hotspots for drug development and data analytics. The team has access to <a href=\"http://qb3.org/\">QB3</a> resources, which include a <a href=\"http://qb3.ucsf.edu/computing/cluster.html\">computing cluster</a> and <a href=\"https://smdc.ucsf.edu/\">small molecule discovery center</a>.</p>\r\n\r\n<p>This material is based upon work supported by the National Science Foundation Graduate Research Fellowship under Grant Number 1144247. We would like to thank <a href=\"https://www.browserstack.com/\">BrowserStack</a> for providing cross browser testing to help us <em>compatibly</em> share our research.</p>",
      "body_md": "# Abstract\r\n\r\nThis project aims to predict new therapeutic indications for small molecules. We will focus on repurposing drugs for well-studied complex human diseases, relying on recently-available high-throughput data sources. The approach is integrative, seeking to combine multiple information domains through heterogeneous networks and modern machine learning techniques.\r\n\r\n# Objectives\r\n\r\n1. **Create an open resource for integrative drug repurposing.** \r\nA slew of bioinformatics resources have recently come online. Yet, these resources frequently rely on different vocabularies and require cleaning. We plan to release a network capturing a systems biology perspective of drug efficacy. Standardized vocabularies will form a network template and will be connected by the results of high-throughput experimentation. Structuring the resource as a network ensures the data is processed and reusable. The complete resource will be posted to our [online portal for heterogeneous data integration](http://het.io) under a [CC-BY license](https://creativecommons.org/licenses/by/4.0/) and will provide a goto dataset for researchers implementing systems/network/computational pharmacology analyses.\r\n\r\n2. **Compare and identify influential mechanisms of drug efficacy.** \r\nThe mechanism of action is poorly understood for many prevalent small molecule therapies. Discovering mechanisms through target identification has proven difficult. High-throughput drug and disease signatures offer an alternative approach for investigating a compound's mechanism of action. We plan to identify influential network connections that underlie drug efficacy. Greater insight into how existing drugs work will help us understand current treatments and predict future treatments. More immediately, our results will compare the informativeness of data sources, providing a solid foundation for computational drug repurposing.\r\n\r\n3. **Predict probabilities for each small molecule's efficacy in treating each complex disease.** \r\nSerendipity was responsible for the discovery of many breakthrough small molecule therapies [@Ban06]. Additionally, small molecules frequently treat multiple distinct diseases [@10.1016/j.drudis.2012.08.005]. Rational systems-based drug repurposing overcomes the inefficiency and unreliability of serendipity, while capturing the benefits of polypharmacology and network pharmacology. From the integrative network, we will predict the probability that a given small molecule will treat a given complex disease. Our predictions will provide pharmacologists with evidence-based drug leads, which could develop into novel approved uses for existing drug.\r\n\r\n[@Ban06]: http://www.dialogues-cns.com/publication/the-role-of-serendipity-in-drug-discovery/ \"Ban TA (2006) The role of serendipity in drug discovery. Dialogues in clinical neuroscience 8.3: 335.\"\r\n\r\n# Background\r\n\r\nPharmaceutical companies seeking to bring a novel therapeutic compound to market face a single digit success rate, price tag in the billions, and duration spanning decades [@10.1038/nrd1468]. The trend in research efficiency is equally grim: the cost of developing a new drug has increased exponentially, doubling approximately every nine years since 1950 [@10.6084/m9.figshare.937004].\r\n\r\nSince the 90’s, the prevailing model of drug discovery has focused on identifying compounds that target a single protein with maximum specificity. Through a molecular, reductionist approach to understanding disease, a plausible target is selected. Drugs are then designed to modulate the target or small molecules with a strong target affinity are identified using high throughput screens. However, overwhelming evidence suggests that the potential of the 'one drug, one target, one disease' approach is limited. Biological systems are characterized by phenotypic robustness: knockout experiments in model organisms reveal that less than one fifth of genes are essential for survival [@10.1038/nchembio.118]. Similarly, pathology may represent a resilient homeostatic state, resistant to disruptions of a single protein. Approved small molecules affect on average 2.7 known targets, and when accounting for speculative targets that number jumps to 6.3 [@10.1038/nbt0908-983]. This promiscuity can play an important role in drug efficacy as exemplified by clozapine which remains the preeminent anti-psychotic drug over compounds engineered to bind a subset of its dozen-plus targets [@10.1038/nrd1346].\r\n\r\nUncovering disease therapies that rely on multiple mechanisms, known as **polypharmacology**, requires escaping the limitations of the 'magic bullet' paradigm in favor of a 'magic 00 buckshot' understanding of drug efficacy. An approach called **network pharmacology** seeks to characterize the multitude of corruptions embodying a pathology. With that knowledge, drugs are selected to restore a normal state. Network pharmacology encompasses polypharmacology by evaluating drugs which intervene at multiple points to achieve healthy homeostasis.\r\n\r\nDrug **repurposing** -- identifying novel uses for existing therapeutics -- avoids many pitfalls and challenges of designing drugs from scratch. FDA approved drugs have undergone extensive toxicology profiling during development and safety evaluation in Phase III clinical trials. Given ample time on the market, post-marketing trials and adverse event reporting uncover potential flaws that could lead to withdrawal. The wealth of information surrounding approved drugs creates a favorable outcome for repurposed compounds compared to new molecular entities: time to approval is cut in half to as low as three years [@10.1038/nrd1468]; the success rate of advancing from phase II trials to approval increases from 10 to 25 percent [@Thayer12]; and the average development cost for successful drugs plummets from 1.3 billion to as low as 8.4 million dollars [@Persidis11].\r\n\r\nBetween 1999 and 2008, more first-in-class small-molecule drugs were discovered with phenotypic screening than target-centric approaches, despite preferential investment towards the later [@10.1038/nrd3480]. The advent of omics-technologies has enabled the quantification of several intermediate phenotypes between a disease's (or drug's) molecular basis and clinical manifestation. Intermediate phenotypes include transcriptional profiles, biological pathways, and genetic susceptibility markers. Traditional phenotypic approaches have focused on *in vivo* screening to identify compounds that alter a primary clinical indicator. *In silico* screening that instead relies on intermediate phenotypes offers a less costly and time-consuming way forward. Such approaches are easily amenable to leveraging repurposing, polypharmacology, and network pharmacology.\r\n\r\nWe propose an integrative method for repurposing approved small molecules to treat additional complex diseases. The approach relies on characterizing the effect of compounds and diseases using high-throughput resources -- many of which provide intermediate-phenotypic profiles for compounds and diseases -- and, from this information, calculating features that describe specific aspects of a compound-disease relationship. From these features, a machine learning approach identifies the influential mechanisms behind drug efficacy and predicts additional indications for existing drugs.\r\n\r\nWe chose to focus on complex diseases because they frequently exhibit:\r\n\r\n+ poorly understood molecular bases\r\n+ modest efficacy of approved therapies\r\n+ multifactorial etiologies that highlight multiple modalities for intervention\r\n+ good coverage in high-throughput bioinformatic resources\r\n\r\nWe chose to focus on small molecules because they exhibit:\r\n\r\n+ known structures\r\n+ greater data-availability than biologics\r\n+ promiscuous binding, which enables polypharmacology\r\n+ incomplete target knowledge, which can be overcome with phenotypic profiling\r\n\r\n[@Thayer12]: http://cen.acs.org/articles/90/i40/Drug-Repurposing.html \"Thayer AM (2012) Drug Repurposing. Chemical & Engineering News, 90(40), 15-25\"\r\n\r\n[@Persidis11]: http://www.ddw-online.com/media/32/2226/drug-repositioning.pdf \"Persidis, A. (2011). The benefits of drug repositioning. Drug Discovery, 9.\"\r\n\r\n# Research Plan\r\n\r\n## Part 1. Resource Construction\r\n\r\nFirst, we will construct a resource that encodes a systems perspective of pathogenesis and pharmacology. We will structure the resource as a network where entities (nodes) are connected by their relationships (edges). Nodes and edges belong to predefined types -- respectively called metanodes ([Table 1](#metanodes)) and metaedges ([Table 2](#metaedges)). The schematic view showing how types relate is called a metagraph ([Figure 1](#metagraph)). \r\n\r\n[:table](metanodes)\r\n\r\n[:table](metaedges)\r\n\r\nEach node type will be populated using a domain-specific vocabulary ([Table 1](#metanodes)). Controlled vocabularies provide a backbone for data integration, ensure entities are conceptually unique, and enable easy annotation for future users. Edges will be extracted from high-throughput bioinformatics resources ([Table 2](#metaedges)). We aim to incorporate resources that are high-throughput, high-quality, and publicly-available. When possible, systematic resources that circumvent knowledge biases will be employed.\r\n\r\n[:figure](metagraph)\r\n\r\nWe are [currently exploring](http://thinklab.org/p/rephetio/how-should-we-construct-a-catalog-of-drug-indications/21) various resources to provide a high-throughput catalog of indications. Feedback here would be appreciated.\r\n\r\n## Part 2. Discovering Mechanisms of Drug Efficacy\r\n\r\nFeatures describe the relationship between a compound and disease. Each feature measures a certain aspect of a compound-disease relationship: for example, whether the compound targets a susceptibility gene of the disease or whether the compound downregulates genes that are overexpressed in the disease state. Features that distinguish therapeutic from untherapeutic compound-disease pairs represent mechanisms of drug efficacy. We refer to the discriminatory power of each feature as its performance. The performance of each feature indicates its pharmacological importance. And by comparing performance across features, we can contrast the informativeness of orthogonal domains of information. Finally, features describing the same general relationship but based on different data sources can identify the most informative resource or technology out of many.\r\n\r\nFeatures will be computed from the network. Each feature will measure the prevalence of a specific type of path between a compound and disease. This approach was initially developed for social network analysis [@10.1109/ASONAM.2011.112], and later adapted by us for predicting disease-associated genes [@10.1371/journal.pcbi.1004259]. Briefly, the method identifies all paths between a source and target node that follow a specified type of path (metapath). The contribution of each path is weighted by its specificity: paths through high-degree nodes, which are likely to be less informative, are downweighted. The sum of the weighted paths results in a value of 0 or greater, where 0 indicates no connectivity. We plan to use the [*degree-weighted path count* metric](http://het.io/hnep) for computing features [@10.1371/journal.pcbi.1004259]. The interpretation of a specific feature depends on its corresponding metapath. [Table 3](#metapaths) provides example metapaths and describes their pharmacological significance.\r\n\r\n[:table](metapaths)\r\n\r\nMetapath-based approaches have several advantages for predictive data integration including [@10.1371/journal.pcbi.1004259]:\r\n\r\n> - versatility (most biological phenomena are decomposable into entities connected by relationships)\r\n> - scalability (no theoretical limit to metagraph complexity or graph size)\r\n> - efficiency (low marginal cost to including an additional network component)\r\n\r\nHarnessing these advantages, we hope to evaluate and compare a diverse and broad set of potential mechanisms of efficacy.\r\n\r\n## Part 3. Predicting Probabilities of Efficacy\r\n\r\nWe plan to predict probabilities of efficacy for compound-disease pairs using heterogeneous network edge prediction [@10.1109/ASONAM.2011.112 @10.1371/journal.pcbi.1004259]. This approach trains a model from the network-based features and can return a probability of efficacy for any compound-disease pair. Previously, our implementation relied on regularized logistic regression, but [modern software packages](https://topepo.github.io/caret/index.html) will allow us to rigorously evaluate a broad range of machine learning algorithms.\r\n\r\n<a name=\"open-science\"></a>\r\n# Open science\r\n\r\nWe are committed to a transparent, freely available, reusable, and reproducible scientific process and believe open science can revolutionize medicine [@10.1371/journal.pbio.1002164]. To this end, we will release all project related code on [GitHub](https://github.com/dhimmel). Datasets that are too large for GitHub will be published on [figshare](http://figshare.com/authors/Daniel_Himmelstein/523637). All original materials will be released under [CC-BY](https://creativecommons.org/licenses/by/4.0/) (requires attribution) or [CC-0](https://creativecommons.org/publicdomain/zero/1.0/) (public domain) licences. Derivatives of restrictively-licensed works will be released under the most permissive option available. Our analyses will be made available in real-time using [GitHub pages](https://pages.github.com/) to host [R Markdown](http://rmarkdown.rstudio.com/) documents and [IPython Notebooks](http://ipython.org/notebook.html). Finally, we plan to follow [10 proposed rules](http://dx.doi.org/10.1371/journal.pcbi.1003285) for reproducible research in computational biology [@10.1371/journal.pcbi.1003285]. \r\n\r\n# Thoughts?\r\nShare your ideas by commenting on an existing discussion or by starting a new thread. Our goal in joining ThinkLab is to generate as much interaction as possible.\r\n\r\n# Team & Resources\r\n\r\n[Daniel Himmelstein](http://dhimmel.com) is a PhD candidate in the *Biological & Medical Informatics* program at UCSF. Daniel works in the [Sergio Baranzini Lab](http://baranzinilab.ucsf.edu/) whose mission is to apply cutting-edge bioinformatic approaches to genomic data, with a focus on multiple sclerosis. Dr. Baranzini has extensive experience with data integration, genomic profiling, and disease bioinformatics.\r\n\r\nUCSF and the surrounding Bay Area are hotspots for drug development and data analytics. The team has access to [QB3](http://qb3.org/) resources, which include a [computing cluster](http://qb3.ucsf.edu/computing/cluster.html) and [small molecule discovery center](https://smdc.ucsf.edu/).\r\n\r\nThis material is based upon work supported by the National Science Foundation Graduate Research Fellowship under Grant Number 1144247. We would like to thank [BrowserStack](https://www.browserstack.com/) for providing cross browser testing to help us *compatibly* share our research.",
      "doc_published": "2015-01-12T22:40:57Z",
      "document_id": 5,
      "doi": "10.15363/thinklab.a5",
      "intro_html": "",
      "intro_md": "",
      "title": "",
      "topic_field": "",
      "url": "/p/rephetio/proposal",
      "views": 1119
    },
    {
      "body_html": "<h1 id=\"abstract\">Abstract</h1>\r\n\r\n<p>The ability to computationally predict whether a compound treats a disease would improve the economy and success rate of drug approval. This study describes Project Rephetio to systematically model drug efficacy based on 755 existing treatments. First, we constructed Hetionet (<a href=\"https://neo4j.het.io\" title=\"Neo4j Hetionet Browser\">neo4j.het.io</a>), an integrative network encoding knowledge from millions of biomedical studies. Hetionet v1.0 consists of 47,031 nodes of 11 types and 2,250,197 relationships of 24 types. Data was integrated from 29 public resources to connect compounds, diseases, genes, anatomies, pathways, biological processes, molecular functions, cellular components, pharmacologic classes, side effects, and symptoms. Next, we identified network patterns that distinguish treatments from non-treatments. Then we predicted the probability of treatment for 209,168 compound&#8211;disease pairs (<a href=\"http://het.io/repurpose/\" title=\"Project Rephetio Prediction Browser\">het.io/repurpose</a>). Our predictions validated on two external sets of treatment and provided pharmacological insights on epilepsy, suggesting they will help prioritize drug repurposing candidates. This study was entirely open and received realtime feedback from 40 community members.</p>\r\n\r\n<h1 id=\"introduction\">Introduction</h1>\r\n\r\n<p>The cost of developing a new therapeutic drug has been estimated at 1.4 billion dollars <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.jhealeco.2016.01.012\" class=\"citation \" data-key=\"10.1016/j.jhealeco.2016.01.012\">1</a>]</span>, the process typically takes 15 years from lead compound to market <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nrd1178\" class=\"citation \" data-key=\"10.1038/nrd1178\">2</a>]</span>, and the likelihood of success is stunningly low <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nbt.2786\" class=\"citation \" data-key=\"10.1038/nbt.2786\">3</a>]</span>. Strikingly, the costs have been doubling every 9 years since 1970, a sort of inverse Moore's law, which is far from an optimal strategy from both a business and public health perspective <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nrd3681\" class=\"citation \" data-key=\"10.1038/nrd3681\">4</a>]</span>. Drug repurposing &#8212; identifying novel uses for existing therapeutics &#8212; can drastically reduce the duration, failure rates, and costs of approval <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nrd1468\" class=\"citation \" data-key=\"10.1038/nrd1468\">5</a>]</span>. These benefits stem from the rich preexisting information on approved drugs, including extensive toxicology profiling performed during development, preclinical models, clinical trials, and postmarketing surveillance.</p>\r\n\r\n<p>Drug repurposing is poised to become more efficient as mining of electronic health records (EHRs) to retrospectively assess the effect of drugs gains feasibility <span class=\"citation\">[<a href=\"https://doi.org/10.1093/jamia/ocv102\" class=\"citation \" data-key=\"10.1093/jamia/ocv102\">6</a>, <a href=\"https://doi.org/10.1136/amiajnl-2014-002649\" class=\"citation \" data-key=\"10.1136/amiajnl-2014-002649\">7</a>, <a href=\"https://doi.org/10.1016/j.amjmed.2015.10.015\" class=\"citation \" data-key=\"10.1016/j.amjmed.2015.10.015\">8</a>, <a href=\"https://doi.org/10.1126/scitranslmed.3003377\" class=\"citation \" data-key=\"10.1126/scitranslmed.3003377\">9</a>]</span>. However, systematic approaches to repurpose drugs based on mining EHRs alone will likely lack power due to multiple testing. Similar to the approach followed to increase the power of genome-wide association studies (GWAS) <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nrg2615\" class=\"citation \" data-key=\"10.1038/nrg2615\">10</a>, <a href=\"https://doi.org/10.1093/brain/awn081\" class=\"citation \" data-key=\"10.1093/brain/awn081\">11</a>]</span>, integration of biological knowledge to prioritize drug repurposing will help overcome limited EHR sample size and data quality.</p>\r\n\r\n<p>In addition to repurposing, several other paradigm shifts in drug development have been proposed to improve efficiency. Since small molecules tend to bind to many targets, polypharmacology aims to find synergy in the multiple effects of a drug <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nrd1346\" class=\"citation \" data-key=\"10.1038/nrd1346\">12</a>]</span>. Network pharmacology assumes diseases consist of a multitude of molecular alterations resulting in a robust disease state. Network pharmacology seeks to uncover multiple points of intervention into a specific pathophysiological state that together rehabilitate an otherwise resilient disease process <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nchembio.118\" class=\"citation \" data-key=\"10.1038/nchembio.118\">13</a>, <a href=\"https://doi.org/10.1038/nbt1007-1110\" class=\"citation \" data-key=\"10.1038/nbt1007-1110\">14</a>]</span>. Although target-centric drug discovery has dominated the field for decades, phenotypic screens have more recently resulted in a comparatively higher number of first-in-class small molecules <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nrd3480\" class=\"citation \" data-key=\"10.1038/nrd3480\">15</a>]</span>. Recent technological advances have enabled a new paradigm in which mid- to high-throughput assessment of intermediate phenotypes, such as the molecular response to drugs, is replacing the classic target discovery approach&#160;<span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.copbio.2011.11.010\" class=\"citation \" data-key=\"10.1016/j.copbio.2011.11.010\">16</a>, <a href=\"https://doi.org/10.1038/nrc2044\" class=\"citation \" data-key=\"10.1038/nrc2044\">17</a>, <a href=\"https://doi.org/10.1016/j.drudis.2012.07.017\" class=\"citation \" data-key=\"10.1016/j.drudis.2012.07.017\">18</a>]</span>. Furthermore, integration of multiple channels of evidence, particularly diverse types of data, can overcome the limitations and weak performance inherent to data of a single domain <span class=\"citation\">[<a href=\"https://doi.org/10.1002/wsbm.1337\" class=\"citation \" data-key=\"10.1002/wsbm.1337\">19</a>]</span>. Modern computational approaches offer a convenient platform to tie these developments together as the reduced cost and increased velocity of <em>in silico</em> experimentation massively lowers the barriers to entry and price of failure <span class=\"citation\">[<a href=\"https://doi.org/10.1038/clpt.2013.1\" class=\"citation \" data-key=\"10.1038/clpt.2013.1\">20</a>, <a href=\"https://doi.org/10.1016/j.drudis.2012.08.005\" class=\"citation \" data-key=\"10.1016/j.drudis.2012.08.005\">21</a>]</span>.</p>\r\n\r\n<p>Hetnets (short for heterogeneous networks) are networks with multiple types of nodes and relationships. They offer an intuitive, versatile and powerful structure for data integration. In this study, we developed a hetnet (Hetionet v1.0) by integrating knowledge and experimental findings from decades of biomedical research spanning millions of publications. We adapted an algorithm originally developed for social network analysis and applied it to Hetionet v1.0 to identify patterns of efficacy and predict new uses for drugs. The algorithm performs edge prediction through a machine learning framework that accommodates the breadth and depth of information contained in Hetionet v1.0 <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation \" data-key=\"10.1371/journal.pcbi.1004259\">22</a>, <a href=\"https://doi.org/10.1109/ASONAM.2011.112\" class=\"citation \" data-key=\"10.1109/ASONAM.2011.112\">23</a>]</span>. Our approach represents an&#160;<em>in silico</em>&#160;implementation of network pharmacology that natively incorporates polypharmacology and high-throughput phenotypic screening.</p>\r\n\r\n<p>One fundamental characteristic of our method is that it learns and evaluates itself on existing medical indications (i.e. a \"gold standard\"). Next, we introduce previous approaches that also performed comprehensive evaluation on existing treatments. A 2011 study, named PREDICT, compiled 1,933 treatments between 593 drugs and 313 diseases <span class=\"citation\">[<a href=\"https://doi.org/10.1038/msb.2011.26\" class=\"citation \" data-key=\"10.1038/msb.2011.26\">24</a>]</span>. Starting from the premise that similar drugs treat similar diseases, PREDICT trained a classifier that incorporates 5 types of drug-drug and 2 types of disease-disease similarity. A 2014 study compiled 890 treatments between 152 drugs and 145 diseases with transcriptional signatures <span class=\"citation\">[<a href=\"https://doi.org/10.1186/s13073-014-0095-1\" class=\"citation \" data-key=\"10.1186/s13073-014-0095-1\">25</a>]</span>. The authors found that compounds triggering an opposing transcriptional response to the disease were more likely to be treatments, although this effect was weak and limited to cancers. A 2016 study compiled 402 treatments between 238 drugs and 78 diseases and used a single proximity score &#8212; the average shortest path distance between a drug's targets and disease's associated proteins on the interactome &#8212; as a classifier <span class=\"citation\">[<a href=\"https://doi.org/10.1038/ncomms10331\" class=\"citation \" data-key=\"10.1038/ncomms10331\">26</a>]</span>.</p>\r\n\r\n<p>We build on these successes by creating a framework for incorporating the effects of any biological relationship into the prediction of whether a drug treats a disease. By doing this, we were able to capture a multitude of effects that have been suggested as influential for drug repurposing including drug-drug similarity <span class=\"citation\">[<a href=\"https://doi.org/10.1038/msb.2011.26\" class=\"citation \" data-key=\"10.1038/msb.2011.26\">24</a>, <a href=\"https://doi.org/10.1109/BIBM.2012.6392722\" class=\"citation \" data-key=\"10.1109/BIBM.2012.6392722\">27</a>]</span>, disease-disease similarity <span class=\"citation\">[<a href=\"https://doi.org/10.1038/msb.2011.26\" class=\"citation \" data-key=\"10.1038/msb.2011.26\">24</a>, <a href=\"https://doi.org/10.1038/clpt.2009.103\" class=\"citation \" data-key=\"10.1038/clpt.2009.103\">28</a>]</span>, transcriptional signatures <span class=\"citation\">[<a href=\"https://doi.org/10.1186/s13073-014-0095-1\" class=\"citation \" data-key=\"10.1186/s13073-014-0095-1\">25</a>, <a href=\"https://doi.org/10.1126/science.1132939\" class=\"citation \" data-key=\"10.1126/science.1132939\">29</a>, <a href=\"https://doi.org/10.1038/nrc2044\" class=\"citation \" data-key=\"10.1038/nrc2044\">17</a>, <a href=\"https://doi.org/10.1016/j.drudis.2012.07.014\" class=\"citation \" data-key=\"10.1016/j.drudis.2012.07.014\">30</a>, <a href=\"https://doi.org/10.1016/j.drudis.2012.07.017\" class=\"citation \" data-key=\"10.1016/j.drudis.2012.07.017\">18</a>]</span>, protein interactions <span class=\"citation\">[<a href=\"https://doi.org/10.1038/ncomms10331\" class=\"citation \" data-key=\"10.1038/ncomms10331\">26</a>]</span>, genetic association <span class=\"citation\">[<a href=\"https://doi.org/10.1038/ng.3314\" class=\"citation \" data-key=\"10.1038/ng.3314\">31</a>, <a href=\"https://doi.org/10.1038/nbt.2151\" class=\"citation \" data-key=\"10.1038/nbt.2151\">32</a>]</span>, drug side effects <span class=\"citation\">[<a href=\"https://doi.org/10.1126/science.1158140\" class=\"citation \" data-key=\"10.1126/science.1158140\">33</a>, <a href=\"https://doi.org/10.7717/peerj-cs.46\" class=\"citation \" data-key=\"10.7717/peerj-cs.46\">34</a>]</span>, disease symptoms <span class=\"citation\">[<a href=\"https://doi.org/10.1038/ncomms5212\" class=\"citation \" data-key=\"10.1038/ncomms5212\">35</a>]</span>, and molecular pathways <span class=\"citation\">[<a href=\"https://doi.org/10.1039/C4MB00014E\" class=\"citation \" data-key=\"10.1039/C4MB00014E\">36</a>]</span>. Our ability to create such an integrative model of drug efficacy relies on the hetnet data structure to unite diverse information. On Hetionet v1.0, our algorithm learns which types of compound&#8211;disease paths discriminate treatments from non-treatments in order to predict the probability that a compound treats a disease.</p>\r\n\r\n<p>We refer to this study as Project Rephetio (pronounced as <strong>rep</strong>-<em>het</em>-<em>ee</em>-oh). Both Rephetio and Hetionet are portmanteaus combining the words <strong>rep</strong>urpose, <strong>het</strong>erogeneous, and <strong>net</strong>work with the URL <a href=\"http://het.io\">het.<strong>io</strong></a>.</p>\r\n\r\n<h1 id=\"results\">Results</h1>\r\n\r\n<h2 id=\"hetionet-v10\">Hetionet v1.0</h2>\r\n\r\n<p>We obtained and integrated data from 29 publicly available resources to create Hetionet v1.0 (<a href=\"#hetionet_figure\">Figure 1</a>). The hetnet contains 47,031 nodes of 11 types (<a href=\"#metanode_table\">Table 1</a>) and 2,250,197 relationships of 24 types (<a href=\"#metaedge_table\">Table 2</a>). The nodes consist of 1,552 small molecule compounds and 137 complex diseases, as well as genes, anatomies, pathways, biological processes, molecular functions, cellular components, perturbations, pharmacologic classes, drug side effects, and disease symptoms. The edges represent relationships between these nodes and encompass the collective knowledge produced by millions of studies over the last half century.</p>\r\n\r\n<a name=\"hetionet_figure\"></a><div class=\"figure\" figure-id=\"hetionet_figure\"><div class=\"figure-content\"><img src=\"https://think-lab.s3.amazonaws.com/m/figures/29.png\"></div>\n            <div class=\"signature-1\">\n                <div class=\"figure-title\">Figure 1. Hetionet v1.0</div>\n                <div class=\"figure-description\"><p>A) The metagraph, a schema of the network types. B) The hetnet visualized. Nodes are drawn as dots and laid out orbitally, thus forming circles. Edges are colored by type. C) Metapath counts by path length. The number of different types of paths of a given length that connect two node types is shown. For example, the top-left tile in the Length 1 panel denotes that Anatomy nodes are not connected to themselves (i.e. no edges connect nodes of this type between themselves). However, the bottom-left tile of the Length 4 panel denotes that 88 types of length-four paths connect Symptom to Anatomy nodes.</p></div>\n            </div>\n        </div>\r\n\r\n<p>For example, <em>Compound&#8211;binds&#8211;Gene</em> edges represent when a compound binds to a protein encoded by a gene. This information has been extracted from the literature by human curators and compiled into databases such as DrugBank, ChEMBL, DrugCentral, and BindingDB. We combined these databases to create 11,571 binding edges between 1,389 compounds and 1,689 genes. These edges were compiled from 10,646 distinct publications, which Hetionet binding edges reference as an attribute. Binding edges represent a comprehensive catalog constructed from low throughput experimentation. However, we also integrated findings from high throughput technologies &#8212; many of which have only recently become available. For example, we generated consensus transcriptional signatures for compounds in LINCS L1000 and diseases in STARGEO.</p>\r\n\r\n<a name=\"metanode_table\"></a><div class=\"figure\" figure-id=\"metanode_table\">\n            <div class=\"signature-3\">\n                <div class=\"figure-title\">Table 1. Metanodes</div>\n                <div class=\"figure-description\"><p>Hetionet v1.0 includes 11 node types (metanodes). For each metanode, this table shows the abbreviation, number of nodes, number of nodes without any edges, and the number of metaedges connecting the metanode.</p></div>\n            </div>\n        <div class=\"figure-content\"><table class=\"table markdown-table\"><thead><tr><th>Metanode</th><th>Abbr</th><th>Nodes</th><th>Disconnected</th><th>Metaedges</th></tr></thead><tbody><tr><td>Anatomy</td><td>A</td><td>402</td><td>2</td><td>4</td></tr><tr><td>Biological Process</td><td>BP</td><td>11,381</td><td>0</td><td>1</td></tr><tr><td>Cellular Component</td><td>CC</td><td>1,391</td><td>0</td><td>1</td></tr><tr><td>Compound</td><td>C</td><td>1,552</td><td>14</td><td>8</td></tr><tr><td>Disease</td><td>D</td><td>137</td><td>1</td><td>8</td></tr><tr><td>Gene</td><td>G</td><td>20,945</td><td>1,800</td><td>16</td></tr><tr><td>Molecular Function</td><td>MF</td><td>2,884</td><td>0</td><td>1</td></tr><tr><td>Pathway</td><td>PW</td><td>1,822</td><td>0</td><td>1</td></tr><tr><td>Pharmacologic Class</td><td>PC</td><td>345</td><td>0</td><td>1</td></tr><tr><td>Side Effect</td><td>SE</td><td>5,734</td><td>33</td><td>1</td></tr><tr><td>Symptom</td><td>S</td><td>438</td><td>23</td><td>1</td></tr></tbody></table></div></div>\r\n\r\n<a name=\"metaedge_table\"></a><div class=\"figure\" figure-id=\"metaedge_table\">\n            <div class=\"signature-3\">\n                <div class=\"figure-title\">Table 2. Metaedges</div>\n                <div class=\"figure-description\"><p>Hetionet v1.0 contains 24 edge types (metaedges). For each metaedge, the table reports the abbreviation, the number of edges, the number of source nodes connected by the edges, and the number of target nodes connected by the edges. Note that all metaedges besides <em>Gene&#8594;regulates&#8594;Gene</em> are undirected.</p></div>\n            </div>\n        <div class=\"figure-content\"><table class=\"table markdown-table\"><thead><tr><th>Metaedge</th><th>Abbr</th><th>Edges</th><th>Sources</th><th>Targets</th></tr></thead><tbody><tr><td>Anatomy&#8211;downregulates&#8211;Gene</td><td>AdG</td><td>102,240</td><td>36</td><td>15,097</td></tr><tr><td>Anatomy&#8211;expresses&#8211;Gene</td><td>AeG</td><td>526,407</td><td>241</td><td>18,094</td></tr><tr><td>Anatomy&#8211;upregulates&#8211;Gene</td><td>AuG</td><td>97,848</td><td>36</td><td>15,929</td></tr><tr><td>Compound&#8211;binds&#8211;Gene</td><td>CbG</td><td>11,571</td><td>1,389</td><td>1,689</td></tr><tr><td>Compound&#8211;causes&#8211;Side Effect</td><td>CcSE</td><td>138,944</td><td>1,071</td><td>5,701</td></tr><tr><td>Compound&#8211;downregulates&#8211;Gene</td><td>CdG</td><td>21,102</td><td>734</td><td>2,880</td></tr><tr><td>Compound&#8211;palliates&#8211;Disease</td><td>CpD</td><td>390</td><td>221</td><td>50</td></tr><tr><td>Compound&#8211;resembles&#8211;Compound</td><td>CrC</td><td>6,486</td><td>1,042</td><td>1,054</td></tr><tr><td>Compound&#8211;treats&#8211;Disease</td><td>CtD</td><td>755</td><td>387</td><td>77</td></tr><tr><td>Compound&#8211;upregulates&#8211;Gene</td><td>CuG</td><td>18,756</td><td>703</td><td>3,247</td></tr><tr><td>Disease&#8211;associates&#8211;Gene</td><td>DaG</td><td>12,623</td><td>134</td><td>5,392</td></tr><tr><td>Disease&#8211;downregulates&#8211;Gene</td><td>DdG</td><td>7,623</td><td>44</td><td>5,745</td></tr><tr><td>Disease&#8211;localizes&#8211;Anatomy</td><td>DlA</td><td>3,602</td><td>133</td><td>398</td></tr><tr><td>Disease&#8211;presents&#8211;Symptom</td><td>DpS</td><td>3,357</td><td>133</td><td>415</td></tr><tr><td>Disease&#8211;resembles&#8211;Disease</td><td>DrD</td><td>543</td><td>112</td><td>106</td></tr><tr><td>Disease&#8211;upregulates&#8211;Gene</td><td>DuG</td><td>7,731</td><td>44</td><td>5,630</td></tr><tr><td>Gene&#8211;covaries&#8211;Gene</td><td>GcG</td><td>61,690</td><td>9,043</td><td>9,532</td></tr><tr><td>Gene&#8211;interacts&#8211;Gene</td><td>GiG</td><td>147,164</td><td>9,526</td><td>14,084</td></tr><tr><td>Gene&#8211;participates&#8211;Biological Process</td><td>GpBP</td><td>559,504</td><td>14,772</td><td>11,381</td></tr><tr><td>Gene&#8211;participates&#8211;Cellular Component</td><td>GpCC</td><td>73,566</td><td>10,580</td><td>1,391</td></tr><tr><td>Gene&#8211;participates&#8211;Molecular Function</td><td>GpMF</td><td>97,222</td><td>13,063</td><td>2,884</td></tr><tr><td>Gene&#8211;participates&#8211;Pathway</td><td>GpPW</td><td>84,372</td><td>8,979</td><td>1,822</td></tr><tr><td>Gene&#8594;regulates&#8594;Gene</td><td>Gr&gt;G</td><td>265,672</td><td>4,634</td><td>7,048</td></tr><tr><td>Pharmacologic Class&#8211;includes&#8211;Compound</td><td>PCiC</td><td>1,029</td><td>345</td><td>724</td></tr></tbody></table></div></div>\r\n\r\n<p>While Hetionet v1.0 is ideally suited for drug repurposing, the network has broader biological applicability. For example, we have prototyped queries for a) identifying drugs that target a specific pathway, b) identifying biological processes involved in a specific disease, c) identifying the drug targets responsible for causing a specific side effect, and d) identifying anatomies with transcriptional relevance for a specific disease <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d220\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d220\">37</a>]</span>. Each of these queries was simple to write and took less than a second to run on our publicly available Hetionet Browser. While it is possible that existing services provide much of the aforementioned functionality, they offer less versatility. Hetionet differentiates itself in its ability to flexibly query across multiple domains of information. As a proof of concept, we enhanced the biological process query (b), which identified processes that were enriched for disease-associated genes, using multiple sclerosis (MS) as an example disease. The enhanced query identified genes that interact with MS GWAS-genes. However, interacting genes were discarded unless they were upregulated in an MS-related anatomy (i.e. anatomical structure, e.g. organ or tissue). Then relevant biological processes were identified. Thus, the single query spanned 4 node and 5 relationship types. Furthermore, the portion of the query to identify paths meeting the above specification required only four lines of Cypher code.</p>\r\n\r\n<p>The integrative potential of Hetionet v1.0 is reflected by its connectivity. Among the 11 metanodes, there are 66 possible source&#8211;target pairs. However, only 11 of them have at least one direct connection. In contrast, for paths of length 2, 50 pairs have connectivity (paths types that start on the source node type and end on the target node type, see <a href=\"#hetionet_figure\">Figure 1C</a>). At length 3, all 66 pairs are connected. At length 4, the source&#8211;target pair with the fewest types of connectivity (Side Effect to Symptom) has 13 metapaths, while the pair with the most connectivity types (Gene to Gene) has 3,542 pairs. This high level of connectivity across a diversity of biomedical entities forms the foundation for automated translation of knowledge into biomedical insight.</p>\r\n\r\n<p>Hetionet v1.0 is accessible via a Neo4j Browser at <a href=\"https://neo4j.het.io\">https://neo4j.het.io</a>. This public Neo4j instance provides users an installation-free method to query and visualize the network. The Browser contains a tutorial guide as well as guides with the details of each Project Rephetio prediction. Hetionet v1.0 is also <a href=\"https://github.com/dhimmel/hetionet\" title=\"Hetionet on GitHub\">available for download</a> in JSON, Neo4j, and TSV formats <span class=\"citation\">[<a href=\"https://doi.org/10.5281/zenodo.268568\" class=\"citation citation-figure\" data-key=\"10.5281/zenodo.268568\">38</a>]</span>. The JSON and Neo4j database formats include node and edge properties &#8212; such as URLs, source and license information, and confidence scores &#8212; and are thus recommended.</p>\r\n\r\n<h2 id=\"systematic-mechanisms-of-efficacy\">Systematic mechanisms of efficacy</h2>\r\n\r\n<p>One aim of Project Rephetio was to systematically evaluate how drugs exert their therapeutic potential. To address this question, we compiled a gold standard of 755 disease-modifying indications, which form the <em>Compound&#8211;treats&#8211;Disease</em> edges in Hetionet v1.0. Next, we identified types of paths (metapaths) that occurred more frequently between treatments than non-treatments (any compound&#8211;disease pair that is not a treatment). The advantage of this approach is that metapaths naturally correspond to mechanisms of pharmacological efficacy. For example, the <em>Compound&#8211;binds&#8211;Gene&#8211;associates&#8211;Disease</em> (<em>CbGaD</em>) metapath identifies when a drug binds  to a protein corresponding to a gene involved in the disease.</p>\r\n\r\n<p>We evaluated all 1,206 metapaths that traverse from compound to disease and have length of 2&#8211;4 (<a href=\"#feature_figure\">Figure 2A</a>). To control for the different degrees of nodes, we used the degree-weighted path count (<em>DWPC</em>) &#8212; which downweights paths going through highly-connected nodes <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation \" data-key=\"10.1371/journal.pcbi.1004259\">22</a>]</span> &#8212; to assess path prevalence. In addition, we compared the performance of each metapath to a baseline computed from permuted networks. Hetnet permutation preserves node degree while eliminating edge specificity, allowing us to isolate the portion of unpermuted metapath performance resulting from actual network paths. We refer to the permutation-adjusted performance measure as &#916; AUROC.</p>\r\n\r\n<a name=\"feature_figure\"></a><div class=\"figure\" figure-id=\"feature_figure\"><div class=\"figure-content\"><img src=\"https://think-lab.s3.amazonaws.com/m/figures/33.png\"></div>\n            <div class=\"signature-1\">\n                <div class=\"figure-title\">Figure 2. Performance by type and model coefficients</div>\n                <div class=\"figure-description\"><p>A) The performance of the DWPCs for <a href=\"http://het.io/repurpose/metapaths.html\" title=\"Project Rephetio Metapath Browser\">1,206 metapaths</a>, organized by their composing metaedges. The larger dots represent metapaths that were significantly affected by permutation (false discovery rate &lt; 5%). Metaedges are ordered by their best performing metapath. Since a metapath's performance is limited by its least informative metaedge, the best performing metapath for a metaedge provides a lower bound on the pharmacologic utility of a given domain of information. B) Barplot of the model coefficients. Features were standardized prior to model fitting to make the coefficients comparable <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d205\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d205\">39</a>]</span>.</p></div>\n            </div>\n        </div>\r\n\r\n<p>Overall, 709 of the 1,206 metapaths exhibited a statistically significant &#916; AUROC at a false discovery rate cutoff of 5%. These 709 metapaths included all 24 metaedges, suggesting that each type of relationship we integrated provided at least some therapeutic utility. However, not all metaedges were equally present in significant metapaths: 259 significant metapaths included a <em>Compound&#8211;binds&#8211;Gene</em> metaedge, whereas only 4 included a <em>Gene&#8211;participates&#8211;Cellular Component</em> metaedge. <a href=\"#metapath_table\">Table 3</a> lists the predictiveness of several metapaths of interest. Refer to the <a href=\"#discussion\">Discussion</a> for our interpretation of these findings.</p>\r\n\r\n<a name=\"metapath_table\"></a><div class=\"figure\" figure-id=\"metapath_table\">\n            <div class=\"signature-3\">\n                <div class=\"figure-title\">Table 3. The predictiveness of select metapaths</div>\n                <div class=\"figure-description\"><p>A small selection of the <a href=\"http://het.io/repurpose/metapaths.html\" title=\"Project Rephetio Metapath Browser\">1,206 metapaths</a> is provided. Len. refers to number of metaedges composing the metapath. &#916; AUROC and &#8722;log10(<em>p</em>) assess the performance of a metapath's DWPC in discriminating treatments from non-treatments (in the all-features stage as <a href=\"#machine-learning-approach\">described in Methods</a>). <em>p</em> assesses whether permutation affected AUROC. For reference, <em>p</em> = 0.05 corresponds to &#8722;log10(<em>p</em>) = 1.30. Note that several metapaths shown here provided little evidence that &#916; AUROC &#8800; 0 underscoring their poor ability to predict whether a compound treated a disease. Coef. reports a metapath's logistic regression coefficient as seen in <a href=\"#feature_figure\">Figure 2B</a>. Metapaths removed in feature selection have missing coefficients whereas metapaths given zero-weight by the elastic net have coef. = 0.0.</p></div>\n            </div>\n        <div class=\"figure-content\"><table class=\"table markdown-table\"><thead><tr><th>Abbrev.</th><th>Len.</th><th>&#916; AUROC</th><th>&#8722;log&#8321;&#8320;(<em>p</em>)</th><th>Coef.</th><th>Metapath</th></tr></thead><tbody><tr><td>CbGaD</td><td>2</td><td>14.5%</td><td>6.2</td><td>0.20</td><td>Compound&#8211;binds&#8211;Gene&#8211;associates&#8211;Disease</td></tr><tr><td>CdGuD</td><td>2</td><td>1.7%</td><td>4.5</td><td></td><td>Compound&#8211;downregulates&#8211;Gene&#8211;upregulates&#8211;Disease</td></tr><tr><td>CrCtD</td><td>2</td><td>22.8%</td><td>6.9</td><td>0.15</td><td>Compound&#8211;resembles&#8211;Compound&#8211;treats&#8211;Disease</td></tr><tr><td>CtDrD</td><td>2</td><td>17.2%</td><td>5.8</td><td>0.13</td><td>Compound&#8211;treats&#8211;Disease&#8211;resembles&#8211;Disease</td></tr><tr><td>CuGdD</td><td>2</td><td>1.1%</td><td>2.6</td><td></td><td>Compound&#8211;upregulates&#8211;Gene&#8211;downregulates&#8211;Disease</td></tr><tr><td>CbGbCtD</td><td>3</td><td>21.7%</td><td>6.5</td><td>0.22</td><td>Compound&#8211;binds&#8211;Gene&#8211;binds&#8211;Compound&#8211;treats&#8211;Disease</td></tr><tr><td>CbGeAlD</td><td>3</td><td>8.4%</td><td>5.2</td><td>0.04</td><td>Compound&#8211;binds&#8211;Gene&#8211;expresses&#8211;Anatomy&#8211;localizes&#8211;Disease</td></tr><tr><td>CbGiGaD</td><td>3</td><td>9.0%</td><td>4.4</td><td>0.00</td><td>Compound&#8211;binds&#8211;Gene&#8211;interacts&#8211;Gene&#8211;associates&#8211;Disease</td></tr><tr><td>CcSEcCtD</td><td>3</td><td>14.0%</td><td>6.8</td><td>0.08</td><td>Compound&#8211;causes&#8211;Side Effect&#8211;causes&#8211;Compound&#8211;treats&#8211;Disease</td></tr><tr><td>CdGdCtD</td><td>3</td><td>3.8%</td><td>4.6</td><td>0.00</td><td>Compound&#8211;downregulates&#8211;Gene&#8211;downregulates&#8211;Compound&#8211;treats&#8211;Disease</td></tr><tr><td>CdGuCtD</td><td>3</td><td>-2.1%</td><td>2.4</td><td></td><td>Compound&#8211;downregulates&#8211;Gene&#8211;upregulates&#8211;Compound&#8211;treats&#8211;Disease</td></tr><tr><td>CiPCiCtD</td><td>3</td><td>23.3%</td><td>7.5</td><td>0.16</td><td>Compound&#8211;includes&#8211;Pharmacologic Class&#8211;includes&#8211;Compound&#8211;treats&#8211;Disease</td></tr><tr><td>CpDpCtD</td><td>3</td><td>4.3%</td><td>3.9</td><td>0.06</td><td>Compound&#8211;palliates&#8211;Disease&#8211;palliates&#8211;Compound&#8211;treats&#8211;Disease</td></tr><tr><td>CrCrCtD</td><td>3</td><td>17.0%</td><td>5.0</td><td>0.12</td><td>Compound&#8211;resembles&#8211;Compound&#8211;resembles&#8211;Compound&#8211;treats&#8211;Disease</td></tr><tr><td>CrCbGaD</td><td>3</td><td>8.2%</td><td>6.1</td><td>0.002</td><td>Compound&#8211;resembles&#8211;Compound&#8211;binds&#8211;Gene&#8211;associates&#8211;Disease</td></tr><tr><td>CtDdGdD</td><td>3</td><td>4.2%</td><td>3.9</td><td></td><td>Compound&#8211;treats&#8211;Disease&#8211;downregulates&#8211;Gene&#8211;downregulates&#8211;Disease</td></tr><tr><td>CtDdGuD</td><td>3</td><td>0.5%</td><td>1.0</td><td></td><td>Compound&#8211;treats&#8211;Disease&#8211;downregulates&#8211;Gene&#8211;upregulates&#8211;Disease</td></tr><tr><td>CtDlAlD</td><td>3</td><td>12.4%</td><td>6.0</td><td></td><td>Compound&#8211;treats&#8211;Disease&#8211;localizes&#8211;Anatomy&#8211;localizes&#8211;Disease</td></tr><tr><td>CtDpSpD</td><td>3</td><td>13.9%</td><td>6.1</td><td></td><td>Compound&#8211;treats&#8211;Disease&#8211;presents&#8211;Symptom&#8211;presents&#8211;Disease</td></tr><tr><td>CtDuGdD</td><td>3</td><td>0.7%</td><td>1.3</td><td></td><td>Compound&#8211;treats&#8211;Disease&#8211;upregulates&#8211;Gene&#8211;downregulates&#8211;Disease</td></tr><tr><td>CtDuGuD</td><td>3</td><td>1.1%</td><td>1.4</td><td></td><td>Compound&#8211;treats&#8211;Disease&#8211;upregulates&#8211;Gene&#8211;upregulates&#8211;Disease</td></tr><tr><td>CuGdCtD</td><td>3</td><td>-1.6%</td><td>2.9</td><td></td><td>Compound&#8211;upregulates&#8211;Gene&#8211;downregulates&#8211;Compound&#8211;treats&#8211;Disease</td></tr><tr><td>CuGuCtD</td><td>3</td><td>4.4%</td><td>3.5</td><td>0.00</td><td>Compound&#8211;upregulates&#8211;Gene&#8211;upregulates&#8211;Compound&#8211;treats&#8211;Disease</td></tr><tr><td>CbGiGiGaD</td><td>4</td><td>7.0%</td><td>5.1</td><td>0.00</td><td>Compound&#8211;binds&#8211;Gene&#8211;interacts&#8211;Gene&#8211;interacts&#8211;Gene&#8211;associates&#8211;Disease</td></tr><tr><td>CbGpBPpGaD</td><td>4</td><td>4.9%</td><td>3.8</td><td>0.00</td><td>Compound&#8211;binds&#8211;Gene&#8211;participates&#8211;Biological Process&#8211;participates&#8211;Gene&#8211;associates&#8211;Disease</td></tr><tr><td>CbGpPWpGaD</td><td>4</td><td>7.6%</td><td>7.9</td><td>0.05</td><td>Compound&#8211;binds&#8211;Gene&#8211;participates&#8211;Pathway&#8211;participates&#8211;Gene&#8211;associates&#8211;Disease</td></tr></tbody></table></div></div>\r\n\r\n<h2 id=\"predictions-of-drug-efficacy\">Predictions of drug efficacy</h2>\r\n\r\n<p>We implemented a machine learning approach to translate the network connectivity between a compound and a disease into a probability of treatment <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d210\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d210\">40</a>, <a href=\"https://doi.org/10.5281/zenodo.268654\" class=\"citation citation-figure\" data-key=\"10.5281/zenodo.268654\">41</a>]</span>. The approach relies on the 755 known treatments as positives and 29,044 non-treatments as negatives to train a logistic regression model. The features consisted of a prior probability of treatment, node degrees for 14 metaedges, and DWPCs for 123 metapaths that were well suited for modeling. A cross-validated elastic net was used to minimize overfitting, yielding a model with 31 features (<a href=\"#feature_figure\">Figure 2B</a>). The DWPC features with negative coefficients appear to be included as node-degree-capturing covariates, i.e. they reflect the general connectivity of the compound and disease rather than specific paths between them. However, the 11 DWPC features with non-negligible positive coefficients represent the most salient types of connectivity for systematically modeling drug efficacy. See the metapaths with positive coefficients in <a href=\"#metapath_table\">Table 3</a> for unabbreviated names. As an example, the <em>CcSEcCtD</em> feature assesses whether the compound causes the same side effects as compounds that treat the disease. Alternatively, the <em>CbGeAlD</em> feature assesses whether the compound binds to genes that are expressed in the anatomies affected by the disease.</p>\r\n\r\n<p>We applied this model to predict the probability of treatment between each of 1,538 connected compounds and each of 136 connected diseases, resulting in predictions for 209,168 compound&#8211;disease pairs <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d203\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d203\">42</a>]</span>, available at <a href=\"http://het.io/repurpose/\">http://het.io/repurpose/</a>. The 755 known disease-modifying indications were highly ranked (AUROC = 97.4%, <a href=\"#performance_figure\">Figure 3</a>). The predictions also successfully prioritized two external validation sets: novel indications from DrugCentral (AUROC = 85.5%) and novel indications in clinical trial (AUROC = 70.0%). Together, these findings indicate that Project Rephetio has the ability to recognize efficacious compound&#8211;disease pairs.</p>\r\n\r\n<a name=\"performance_figure\"></a><div class=\"figure\" figure-id=\"performance_figure\"><div class=\"figure-content\"><img src=\"https://think-lab.s3.amazonaws.com/m/figures/32.png\"></div>\n            <div class=\"signature-1\">\n                <div class=\"figure-title\">Figure 3. Predictions performance on four indication sets</div>\n                <div class=\"figure-description\"><p>We assess how well our predictions prioritize four sets of indications. A) The y-axis labels denote the number of indications (+) and non-indications (&#8722;) composing each set. Violin plots with quartile lines show the distribution of indications when compound&#8211;disease pairs are ordered by their prediction. In all four cases, the actual indications were ranked highly by our predictions. B) ROC Curves with AUROCs in the legend. C) Precision&#8211;Recall Curves with AUPRCs in the legend.</p></div>\n            </div>\n        </div>\r\n\r\n<p>Predictions were scaled to the overall prevalence of treatments (0.36%). Hence a compound&#8211;disease pair that received a prediction of 1% represents a 2-fold enrichment over the null probability. Of the 3,980 predictions with a probability exceeding 1%, 586 corresponded to known disease-modifying indications, leaving 3,394 repurposing candidates. For a given compound or disease, we provide the percentile rank of each prediction. Therefore, users can assess whether a given prediction is a top prediction for the compound or disease. In addition, our table-based prediction browser links to a custom guide for each prediction, which displays in the Neo4j Hetionet Browser. Each guide includes a query to display the top paths supporting the prediction and lists clinical trials investigating the indication.</p>\r\n\r\n<h3>Nicotine dependence case study</h3>\r\n\r\n<p>There are currently two FDA-approved medications for smoking cessation (varenicline and bupropion) that are not nicotine replacement therapies. PharmacotherapyDB v1.0 lists varenicline as a disease-modifying indication and nicotine itself as a symptomatic indication for nicotine dependence, but is missing bupropion. Bupropion was first approved for depression in 1985. Owing to the serendipitous observation that it decreased smoking in depressed patients taking this drug, Bupropion was approved for smoking cessation in 1997 <span class=\"citation\">[<a href=\"https://doi.org/10.1093/ntr/nts201\" class=\"citation \" data-key=\"10.1093/ntr/nts201\">43</a>]</span>. Therefore we looked whether Project Rephetio could have predicted this repurposing. Bupropion was the 9th best <a href=\"http://het.io/repurpose/browse.html?id=DOID_0050742\" title=\"Project Rephetio predictions for nicotine dependence (DOID:0050742)\">prediction for nicotine dependence</a> (99.5th percentile) with a probability 2.50-fold greater than the null. <a href=\"#bupropion_nicotine_figure\">Figure 4</a> shows the top paths supporting the repurposing of bupropion.</p>\r\n\r\n<a name=\"bupropion_nicotine_figure\"></a><div class=\"figure\" figure-id=\"bupropion_nicotine_figure\"><div class=\"figure-content\"><img src=\"https://think-lab.s3.amazonaws.com/m/figures/36.png\"></div>\n            <div class=\"signature-1\">\n                <div class=\"figure-title\">Figure 4. Evidence supporting the repurposing of bupropion for smoking cessation</div>\n                <div class=\"figure-description\"><p>This figure shows the 10 most supportive paths (out of 365 total) for treating nicotine dependence with bupropion, as available in this prediction's <a href=\"https://neo4j.het.io/browser/?cmd=play&amp;arg=https://neo4j.het.io/guides/rep/DB01156/DOID_0050742.html\" title=\"Hetionet Neo4j Browser with a prefilled command to play the bupropion&#8211;nicotine-dependence guide\">Neo4j Browser guide</a>. Our method detected that bupropion targets the <em>CHRNA3</em> gene, which is also targeted by the known-treatment varenicline <span class=\"citation\">[<a href=\"https://doi.org/10.1124/mol.106.025130\" class=\"citation \" data-key=\"10.1124/mol.106.025130\">44</a>]</span>. Furthermore, <em>CHRNA3</em> is associated with nicotine dependence <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nature06846\" class=\"citation \" data-key=\"10.1038/nature06846\">45</a>]</span> and participates in several pathways that contain other nicotinic-acetylcholine-receptor (nAChR) genes associated with nicotine dependence. Finally, bupropion causes terminal insomnia <span class=\"citation\">[<a href=\"https://doi.org/10.1007/s00228-003-0693-0\" class=\"citation \" data-key=\"10.1007/s00228-003-0693-0\">46</a>]</span> as does varenicline <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.amjmed.2008.01.017\" class=\"citation \" data-key=\"10.1016/j.amjmed.2008.01.017\">47</a>]</span>, which could indicate an underlying common mechanism of action.</p></div>\n            </div>\n        </div>\r\n\r\n<p>Atop the nicotine dependence predictions were nicotine (10.97-fold over null), cytisine (10.58-fold), and galantamine (9.50-fold). Cytisine is widely used in Eastern Europe for smoking cessation due to its availability at a fraction of the cost of other pharmaceutical options <span class=\"citation\">[<a href=\"https://doi.org/10.1002/14651858.CD006103.pub7\" class=\"citation \" data-key=\"10.1002/14651858.CD006103.pub7\">48</a>]</span>. In the last half decade, large scale clinical trials have confirmed cytisine's efficacy <span class=\"citation\">[<a href=\"https://doi.org/10.1056/NEJMoa1102035\" class=\"citation \" data-key=\"10.1056/NEJMoa1102035\">49</a>, <a href=\"https://doi.org/10.1056/NEJMoa1407764\" class=\"citation \" data-key=\"10.1056/NEJMoa1407764\">50</a>]</span>. Galantamine, an approved Alzheimer's treatment, is currently in <a href=\"https://clinicaltrials.gov/ct2/show/NCT01669538\" title=\"Effect of Galantamine on Short-term Abstinence (GAL-K)\">Phase 2 trial</a> for smoking cessation and is showing promising results <span class=\"citation\">[<a href=\"https://doi.org/10.1038/tp.2015.209\" class=\"citation \" data-key=\"10.1038/tp.2015.209\">51</a>]</span>. In summary, nicotine dependence illustrates Project Rephetio's ability to predict efficacious treatments and prioritize historic and contemporary repurposing opportunities.</p>\r\n\r\n<h3>Epilepsy case study</h3>\r\n\r\n<p>Several factors make epilepsy an interesting disease for evaluating repurposing predictions <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d224\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d224\">52</a>]</span>. Antiepileptic drugs work by increasing the seizure threshold &#8212; the amount of electric stimulation that is required to induce seizure. The effect of a drug on the seizure threshold can be cheaply and reliably tested in rodent models. As a result, the viability of most approved drugs in treating epilepsy is known.</p>\r\n\r\n<p>We focused our evaluation on the top 100 scoring compounds &#8212; referred to as the epilepsy predictions in this section &#8212; after discarding a single combination drug. We classified each compound as anti-ictogenic (seizure suppressing), unknown (no established effect on the seizure threshold), or ictogenic (seizure generating) according to medical literature <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d224\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d224\">52</a>]</span>. Of the top 100 epilepsy predictions, 77 were anti-ictogenic, 8 were unknown, and 15 were ictogenic (<a href=\"#epilepsy_figure\">Figure 5A</a>). Notably, the predictions contained 23 of the 25 disease-modifying antiepileptics in PharamcotherapyDB v1.0.</p>\r\n\r\n<a name=\"epilepsy_figure\"></a><div class=\"figure\" figure-id=\"epilepsy_figure\"><div class=\"figure-content\"><img src=\"https://think-lab.s3.amazonaws.com/m/figures/37.png\"></div>\n            <div class=\"signature-1\">\n                <div class=\"figure-title\">Figure 5. Top 100 epilepsy predictions</div>\n                <div class=\"figure-description\"><p>A) Compounds &#8212; ranked from 1 to 100 by their predicted probability of treating epilepsy &#8212; are colored by their effect on seizures <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d224\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d224\">52</a>]</span>. The highest predictions are almost exclusively anti-ictogenic. Further down the prediction list, the prevalence of drugs with an ictogenic (contraindication) or unknown (novel repurposing candidate) effect on epilepsy increases. All compounds shown received probabilities far exceeding the null probability of treatment (0.36%).<br>B) A chemical similarity network of the epilepsy predictions, with each compound's 2D structure <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d230\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d230\">53</a>]</span>. Edges are <em>Compound&#8211;resembles&#8211;Compound</em> relationships from Hetionet v1.0. Nodes are colored by their effect on seizures.<br>C) The relative contribution of important drug targets to each epilepsy prediction <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d230\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d230\">53</a>]</span>. Specifically, pie charts show how the 8 most-supportive drug targets across all 100 epilepsy predictions contribute to individual predictions. Other Targets represents the aggregate contribution of all targets not listed. The network layout is identical to B.</p></div>\n            </div>\n        </div>\r\n\r\n<p>Many of the 77 anti-ictogenic compounds were not first-line antiepileptic drugs. Instead, they were used as ancillary drugs in the treatment of status epilepticus. For example, we predicted four halogenated ethers, two of which (isoflurane and desflurane) are used clinically to treat life-threatening seizures that persist despite treatment <span class=\"citation\">[<a href=\"https://doi.org/10.1001/archneur.61.8.1254\" class=\"citation \" data-key=\"10.1001/archneur.61.8.1254\">54</a>]</span>. As inhaled anesthetics, these compounds are not appropriate as daily epilepsy medications, but are feasible for refractory status epilepticus where patients are intubated.</p>\r\n\r\n<p>Given this high precision (77%), the 8 compounds of unknown effect are promising repurposing candidates. For example, acamprosate &#8212; whose top prediction was epilepsy &#8212; is a taurine analog that promotes alcohol abstinence. Support for this repurposing arose from acamprosate's inhibition of the glutamate receptor and positive modulation of the GABA&#7424; receptor (<a href=\"#epilepsy_figure\">Figure 5C</a>). If effective against epilepsy, acamprosate could serve a dual benefit for recovering alcoholics who experience seizures from alcohol withdrawal.</p>\r\n\r\n<p>While certain classes of compounds were highly represented in our epilepsy predictions, such benzodiazepines and barbiturates, there was also considerable diversity <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d224\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d224\">52</a>]</span>. The 100 predicted compounds encompassed 26 third-level ATC codes <span class=\"citation\">[<a href=\"https://doi.org/10.4135/9781483349985.n37\" class=\"citation \" data-key=\"10.4135/9781483349985.n37\">55</a>]</span>, such as antiarrhythmics (quinidine, classified as anti-ictogenic) and urologicals (phenazopyridine, classified as unknown). Furthermore, 25 of the compounds were chemically distinct, i.e. they did not resemble any of the other epilepsy predictions (<a href=\"#epilepsy_figure\">Figure 5B</a>).</p>\r\n\r\n<p>Next, we investigated which components of Hetionet contributed to the epilepsy predictions <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d224\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d224\">52</a>]</span>. In total, 392,956 paths of 12 types supported the predictions. Using several different methods for grouping paths, we were able to quantify the aggregate biological evidence. Our algorithm primarily drew on two aspects of epilepsy: its known treatments (76% of the total support) and its genetic associations (22% of support). In contrast, our algorithm drew heavily on several aspects of the predicted compounds: their targeted genes (44%), their chemically similar compounds (30%), their pharmacologic classes, their palliative indications (5%), and their side effects (4%).</p>\r\n\r\n<p>Specifically, 266,192 supporting paths originated with a <em>Compound&#8211;binds&#8211;Gene</em> relationship. Aggregating support by these genes shows the extent that 121 different drug targets contributed to the predictions <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d224\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d224\">52</a>]</span>. In order of importance, the predictions targeted GABA&#7424; receptors (15.3% of total support), cytochrome P450 enzymes (5.6%), the sodium channel (4.6%), glutamate receptors (3.8%), the calcium channel (2.7%), carbonic anhydrases (2.5%), cholinergic receptors (2.1%) and the potassium channel (1.4%). Besides cytochrome P450, which primarily influences pharmacokinetics <span class=\"citation\">[<a href=\"https://doi.org/10.2174/157015910792246254\" class=\"citation \" data-key=\"10.2174/157015910792246254\">56</a>]</span>, our method detected and leveraged bonafide anti-ictogenic mechanisms <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nrn1430\" class=\"citation \" data-key=\"10.1038/nrn1430\">57</a>]</span>. <a href=\"#epilepsy_figure\">Figure 5C</a> shows drug target contributions per compound and illustrates the considerable mechanistic diversity among the predictions.</p>\r\n\r\n<p>Also notable are the 15 ictogenic compounds in our top 100 predictions. Nine of the ictogenic compounds share a tricyclic structure (<a href=\"#epilepsy_figure\">Figure 5B</a>), five of which are tricyclic antidepressants. While the ictogenic mechanisms of these antidepressants are still unclear <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.yebeh.2016.01.029\" class=\"citation \" data-key=\"10.1016/j.yebeh.2016.01.029\">58</a>]</span>, <a href=\"#epilepsy_figure\">Figure 5C</a> suggests their anticholinergic effects may be responsible <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d231\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d231\">59</a>]</span>, in accordance with previous theories <span class=\"citation\">[<a href=\"https://doi.org/10.1016/s0006-2952(96)00509-6\" class=\"citation \" data-key=\"10.1016/s0006-2952(96)00509-6\">60</a>]</span>.</p>\r\n\r\n<p>We also ranked the contribution of the 1,137 side effects that supported the epilepsy predictions through 117,720 <em>CcSEcCtD</em> paths. The top five side effects &#8212; ataxia (0.069% of total support), nystagmus (0.049%), diplopia (0.045%), somnolence (0.044%), and vomiting (0.043%) &#8212; reflect established adverse effects of antiepileptic drugs <span class=\"citation\">[<a href=\"https://doi.org/10.1136/jnnp.2006.100222\" class=\"citation \" data-key=\"10.1136/jnnp.2006.100222\">61</a>, <a href=\"https://doi.org/10.1016/j.ebcr.2015.07.003\" class=\"citation \" data-key=\"10.1016/j.ebcr.2015.07.003\">62</a>, <a href=\"https://doi.org/10.1016/S1059-1311(03)00082-7\" class=\"citation \" data-key=\"10.1016/S1059-1311(03)00082-7\">63</a>, <a href=\"https://doi.org/10.1016/S1388-2457(00)00411-9\" class=\"citation \" data-key=\"10.1016/S1388-2457(00)00411-9\">64</a>, <a href=\"https://doi.org/10.1016/j.seizure.2010.12.011\" class=\"citation \" data-key=\"10.1016/j.seizure.2010.12.011\">65</a>]</span>. In summary, our method simultaneously identified the hallmark side effects of antiepileptic drugs while incorporating this knowledge to prioritize 1,538 compounds for anti-ictogenic activity.</p>\r\n\r\n<h1 id=\"discussion\">Discussion</h1>\r\n\r\n<p>We created Hetionet v1.0 by integrating 29 resources into a single data structure &#8212; the hetnet. Consisting of 11 types of nodes and 24 types of relationships, Hetionet v1.0 brings more types of information together than previous leading-studies in biological data integration <span class=\"citation\">[<a href=\"https://doi.org/10.1098/rsif.2015.0571\" class=\"citation \" data-key=\"10.1098/rsif.2015.0571\">66</a>]</span>. Moreover, we strove to create a reusable, extensible, and property-rich network. While all of the resources we include are publicly available, their integration was a time-intensive undertaking. Hetionet allows researchers to begin answering integrative questions without having to first spend months processing data.</p>\r\n\r\n<p>Our public Neo4j instance allows users to immediately interact with Hetionet. Through the Cypher language, users can perform highly specialized graph queries with only a few lines of code. Queries can be executed in the web browser or programmatically from a language with a Neo4j driver. For users that are unfamiliar with Cypher, we include several example queries in a Browser guide. In contrast to traditional REST APIs, our public Neo4j instance provides users with maximal flexibility to construct custom queries by exposing the underlying database.</p>\r\n\r\n<p>As data has grown more plentiful and diverse, so has the applicability of hetnets. Unfortunately, network science has been naturally fragmented by discipline resulting in relatively slow progress in integrating heterogeneous data. A 2014 analysis identified 78 studies using multilayer networks &#8212; a superset of hetnets with the potential for a time dimension. However, the studies relied on 26 different terms, 9 of which had multiple definitions <span class=\"citation\">[<a href=\"https://doi.org/10.1093/comnet/cnu016\" class=\"citation \" data-key=\"10.1093/comnet/cnu016\">67</a>, <a href=\"https://doi.org/10.15363/thinklab.d104\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d104\">68</a>]</span>. Nonetheless, core infrastructure and algorithms for hetnets are emerging. One goal of our project has been to unite hetnet research across disciplines. We approached this goal by making Project Rephetio entirely available online and inviting community feedback throughout the process <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.4\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.4\">69</a>]</span>.</p>\r\n\r\n<p>Integrating every resource into a single interconnected data structure allowed us to assess systematic mechanisms of drug efficacy. Using the max performing metapath to assess the pharmacological utility of a metaedge (<a href=\"#feature_figure\">Figure 2A</a>), we can divide our relationships into tiers of informativeness. The top tier consists of the types of information traditionally considered by pharmacology: <em>Compound&#8211;treats&#8211;Disease</em>, <em>Pharmacologic Class&#8211;includes&#8211;Compound</em>, <em>Compound&#8211;resembles&#8211;Compound</em>, <em>Disease&#8211;resembles&#8211;Disease</em>, and <em>Compound&#8211;binds&#8211;Gene</em>. The upper-middle tier consists of types of information that have been the focus of substantial medical study, but have only recently started to play a bigger role in drug development, namely the metaedges <em>Disease&#8211;associates&#8211;Gene</em>, <em>Compound&#8211;causes&#8211;Side Effect</em>, <em>Disease&#8211;presents&#8211;Symptom</em>, <em>Disease&#8211;localizes&#8211;Anatomy</em>, and <em>Gene&#8211;interacts&#8211;Gene</em>.</p>\r\n\r\n<p>The lower-middle tier contains the transcriptomics metaedges such as <em>Compound&#8211;downregulates&#8211;Gene</em>, <em>Anatomy&#8211;expresses&#8211;Gene</em>, <em>Gene&#8594;regulates&#8594;Gene</em>, and <em>Disease&#8211;downregulates&#8211;Gene</em>. Much excitement surrounds these resources due to their high throughput and genome-wide scope, which offers a route to drug discovery that is less biased by existing knowledge. However, our findings suggest that these resources are only moderately informative of drug efficacy. Other lower-middle tier metaedges were the product of time-intensive biological experimentation, such as <em>Gene&#8211;participates&#8211;Pathway</em>,  <em>Gene&#8211;participates&#8211;Molecular Function</em>, and <em>Gene&#8211;participates&#8211;Biological Process</em>. Unlike the top tier resources, this knowledge has historically been pursued for basic science rather than primarily medical applications. The weak yet appreciable performance of the <em>Gene&#8211;covaries&#8211;Gene</em> suggests the synergy between the fields of evolutionary genomics and disease biology. The lower tier included the <em>Gene&#8211;participates&#8211;Cellular Component</em> metaedge, which may reflect that the relevance of cellular location to pharmacology is highly case dependent and not amenable to systematic profiling.</p>\r\n\r\n<p>The performance of specific metapaths (<a href=\"#metapath_table\">Table 3</a>) provides further insight. For example, significant emphasis has been put on the use of transcriptional data for drug repurposing <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.drudis.2012.07.014\" class=\"citation \" data-key=\"10.1016/j.drudis.2012.07.014\">30</a>]</span>. One common approach has been to identify compounds with opposing transcriptional signatures to a disease <span class=\"citation\">[<a href=\"https://doi.org/10.1126/scitranslmed.3001318\" class=\"citation \" data-key=\"10.1126/scitranslmed.3001318\">70</a>, <a href=\"https://doi.org/10.1016/j.drudis.2012.07.017\" class=\"citation \" data-key=\"10.1016/j.drudis.2012.07.017\">18</a>]</span>. However, several systematic studies report underwhelming performance of this approach <span class=\"citation\">[<a href=\"https://doi.org/10.1186/s13073-014-0095-1\" class=\"citation \" data-key=\"10.1186/s13073-014-0095-1\">25</a>, <a href=\"https://doi.org/10.1038/msb.2011.26\" class=\"citation \" data-key=\"10.1038/msb.2011.26\">24</a>, <a href=\"https://doi.org/10.1038/ncomms10331\" class=\"citation \" data-key=\"10.1038/ncomms10331\">26</a>]</span> &#8212; a finding supported by the low performance of the <em>CuGdD</em> and <em>CdGuD</em> metapaths in Project Rephetio. Nonetheless, other transcription-based methods showed some promise. Compounds with similar transcriptional signatures were prone to treating the same disease (<em>CuGuCtD</em> and <em>CdGdCtD</em> metapaths), while compounds with opposing transcriptional signatures were slightly averse to treating the same disease (<em>CuGdCtD</em> and <em>CdGuCtD</em> metapaths). In contrast, diseases with similar transcriptional profiles were not prone to treatment by the same compound (<em>CtDdGuD</em> and <em>CtDuGdD</em>).</p>\r\n\r\n<p>By comparably assessing the informativeness of different metaedges and metapaths, Project Rephetio aims to guide future research towards promising data types and analyses. Encouragingly, most data types were at least weakly informative and hence suitable for further study. Ideally, different data types would provide orthogonal information. However, our model for whether a compound treats a disease focused on 11 metapaths &#8212; a small portion of the hundreds of metapaths available. While parsimony aids interpretation, our model did not draw on the weakly-predictive high-throughput data types &#8212; which are intriguing for their novelty, scalability, and cost-effectiveness &#8212; as much as we had hypothesized.</p>\r\n\r\n<p>Instead our model selected types of information traditionally considered in pharmacology. However unlike a pharmacologist whose area of expertise may be limited to a few drug classes, our model was able to predict probabilities of treatment for all 209,168 compound&#8211;disease pairs. Furthermore, our model systematically learned the importance of each type of network connectivity. For any compound&#8211;disease pair, we now can immediately provide the top network paths supporting its therapeutic efficacy. A traditional pharmacologist may be able to produce a similar explanation, but likely not until spending substantial time researching the compound's pharmacology, the disease's pathophysiology, and the molecular relationships in between. Accordingly, we hope certain predictions will spur further research, such as trials to investigate the off-label use of acamprosate for epilepsy, which is supported by one animal model <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.physbeh.2008.05.020\" class=\"citation \" data-key=\"10.1016/j.physbeh.2008.05.020\">71</a>]</span>.</p>\r\n\r\n<p>As demonstrated by the 15 ictogenic compounds in our top 100 epilepsy predictions, Project Rephetio's predictions can include contraindications in addition to indications. Since many of Hetionet v1.0's relationship types are general (e.g. the <em>Compound&#8211;binds&#8211;Gene</em> relationship type conflates antagonist with agonist effects), we expect some high scoring predictions to exacerbate rather than treat the disease. However, the predictions made by Hetionet v1.0 represent such substantial relative enrichment over the null that uncovering the correct directionality is a logical next step and worth undertaking. Going forward, advances in automated mining of the scientific literature could enable extraction of precise relationship types at omics scale <span class=\"citation\">[<a href=\"https://doi.org/10.1145/2939502.2939515\" class=\"citation \" data-key=\"10.1145/2939502.2939515\">72</a>, <a href=\"https://doi.org/10.15363/thinklab.d227\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d227\">73</a>]</span>.</p>\r\n\r\n<p>Future research should focus on gleaning orthogonal information from data types that are so expansive that computational methods are the only option. Our <em>CuGuCtD</em> feature &#8212; measuring whether a compound upregulates the same genes as compounds which treat the disease &#8212; is a good example. This metapath was informative by itself (&#916; AUROC = 4.4%) but was not selected by the model, despite its orthogonal origin (gene expression) to selected metapaths. Using a more extensive catalog of treatments as the gold standard would be one possible approach to increase the power of feature selection.</p>\r\n\r\n<p>Integrating more types of information into Hetionet should also be a future priority. The \"network effect\" phenomenon suggests that the addition of each new piece of information will enhance the value of Hetionet's existing information. We envision a future where all biological knowledge is encoded into a single hetnet. Hetionet v1.0 was an early attempt, and we hope the strong performance of Project Rephetio in repurposing drugs foreshadows the many applications that will thrive from encoding biology in hetnets.</p>\r\n\r\n<h1 id=\"methods\">Methods</h1>\r\n\r\n<p>Hetionet was built entirely from publicly available resources with the goal of integrating a broad diversity of information types of medical relevance, ranging in scale from molecular to organismal. Practical considerations such as data availability, licensing, reusability, documentation, throughput, and standardization informed our choice of resources. We abided by a simple litmus test for determining how to encode information in a hetnet: nodes represent nouns, relationships represent verbs <span class=\"citation\">[<a href=\"https://doi.org/10.1016/s0169-023x(97)00017-7\" class=\"citation \" data-key=\"10.1016/s0169-023x(97)00017-7\">74</a>, <a href=\"https://doi.org/10.15363/thinklab.d162\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d162\">75</a>]</span>.</p>\r\n\r\n<p>Our method for relationship prediction creates a strong incentive to avoid redundancy, which increases the computational burden without improving performance. In a previous study to predict disease&#8211;gene associations using a hetnet of pathophysiology <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation \" data-key=\"10.1371/journal.pcbi.1004259\">22</a>]</span>, we found that different types of gene sets contributed highly redundant information. Therefore, in Hetionet v1.0 we reduced the number of gene set node types from 14 to 3 by omitting several gene set collections and aggregating all pathway nodes.</p>\r\n\r\n<h2 id=\"nodes\">Nodes</h2>\r\n\r\n<p>Nodes encode entities. We extracted nodes from standard terminologies, which provide curated vocabularies to enable data integration and prevent concept duplication. The ease of mapping external vocabularies, adoption, and comprehensiveness were primary selection criteria. Hetionet v1.0 includes nodes from 5 ontologies &#8212; which provide hierarchy of entities for a specific domain &#8212; selected for their conformity to current best practices <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004743\" class=\"citation \" data-key=\"10.1371/journal.pcbi.1004743\">76</a>]</span>.</p>\r\n\r\n<p>We selected 137 terms from the <a href=\"http://disease-ontology.org/\">Disease Ontology</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkr972\" class=\"citation \" data-key=\"10.1093/nar/gkr972\">77</a>, <a href=\"https://doi.org/10.1093/nar/gku1011\" class=\"citation \" data-key=\"10.1093/nar/gku1011\">78</a>]</span> (which we refer to as DO Slim <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d44\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d44\">79</a>, <a href=\"https://doi.org/10.5281/zenodo.45584\" class=\"citation citation-figure\" data-key=\"10.5281/zenodo.45584\">80</a>]</span>) as our disease set. Our goal was to identify complex diseases that are distinct and specific enough to be clinically relevant yet general enough to be well annotated. To this end, we included diseases that have been studied by GWAS and cancer types from <code>TopNodes_DOcancerslim</code> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/database/bav032\" class=\"citation \" data-key=\"10.1093/database/bav032\">81</a>]</span>. We ensured that no DO Slim disease was a subtype of another DO Slim disease. Symptoms were extracted from <a href=\"http://www.ncbi.nlm.nih.gov/mesh\">MeSH</a> by taking the 438 descendants of <em>Signs and Symptoms</em> <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d67\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d67\">82</a>, <a href=\"https://doi.org/10.5281/zenodo.45586\" class=\"citation citation-figure\" data-key=\"10.5281/zenodo.45586\">83</a>]</span>.</p>\r\n\r\n<p>Approved small molecule compounds with documented chemical structures were extracted from <a href=\"http://www.drugbank.ca/\">DrugBank</a> version 4.2 <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkt1068\" class=\"citation \" data-key=\"10.1093/nar/gkt1068\">84</a>, <a href=\"https://doi.org/10.15363/thinklab.d40\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d40\">85</a>, <a href=\"https://doi.org/10.5281/zenodo.45579\" class=\"citation citation-figure\" data-key=\"10.5281/zenodo.45579\">86</a>]</span>. Unapproved compounds were excluded because our focus was repurposing. In addition, unapproved compounds tend to be less studied than approved compounds making them less attractive for our approach where robust network connectivity is critical. Finally, restricting to small molecules with known documented structures enabled us to map between compound vocabularies (see <a href=\"#mappings\">Mappings</a>).</p>\r\n\r\n<p>Side effects were extracted from <a href=\"http://sideeffects.embl.de/\">SIDER</a> version 4.1 <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkv1075\" class=\"citation \" data-key=\"10.1093/nar/gkv1075\">87</a>, <a href=\"https://doi.org/10.15363/thinklab.d97\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d97\">88</a>, <a href=\"https://doi.org/10.5281/zenodo.45521\" class=\"citation citation-figure\" data-key=\"10.5281/zenodo.45521\">89</a>]</span>. SIDER codes side effects using <a href=\"https://www.nlm.nih.gov/research/umls/\">UMLS</a> identifiers <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkh061\" class=\"citation \" data-key=\"10.1093/nar/gkh061\">90</a>]</span>, which we also adopted. Pharmacologic Classes were extracted from the DrugCentral <a href=\"https://github.com/olegursu/drugtarget\" title=\"DrugCentral data: olegursu/drugtarget on GitHub\">data repository</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkw993\" class=\"citation \" data-key=\"10.1093/nar/gkw993\">91</a>, <a href=\"https://doi.org/10.15363/thinklab.d186\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d186\">92</a>]</span>.</p>\r\n\r\n<p>Protein-coding human genes were extracted from <a href=\"http://www.ncbi.nlm.nih.gov/gene\">Entrez Gene</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkq1237\" class=\"citation \" data-key=\"10.1093/nar/gkq1237\">93</a>, <a href=\"https://doi.org/10.15363/thinklab.d34\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d34\">94</a>, <a href=\"https://doi.org/10.5281/zenodo.45524\" class=\"citation citation-figure\" data-key=\"10.5281/zenodo.45524\">95</a>]</span>. Anatomical structures, which we refer to as anatomies, were extracted from <a href=\"http://uberon.org\">Uberon</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1186/gb-2012-13-1-r5\" class=\"citation \" data-key=\"10.1186/gb-2012-13-1-r5\">96</a>]</span>. We selected a subset of 402 Uberon terms by excluding terms known not to exist in humans and terms that were overly broad or arcane <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d41\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d41\">97</a>, <a href=\"https://doi.org/10.5281/zenodo.45527\" class=\"citation citation-figure\" data-key=\"10.5281/zenodo.45527\">98</a>]</span>.</p>\r\n\r\n<p>Pathways were extracted by combining human pathways from <a href=\"http://www.wikipathways.org/\">WikiPathways</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkv1024\" class=\"citation \" data-key=\"10.1093/nar/gkv1024\">99</a>, <a href=\"https://doi.org/10.1371/journal.pbio.0060184\" class=\"citation \" data-key=\"10.1371/journal.pbio.0060184\">100</a>]</span>, <a href=\"http://www.reactome.org/\">Reactome</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkv1351\" class=\"citation \" data-key=\"10.1093/nar/gkv1351\">101</a>]</span>, and the <a href=\"http://pid.nci.nih.gov/\">Pathway Interaction Database</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkn653\" class=\"citation \" data-key=\"10.1093/nar/gkn653\">102</a>]</span>. The latter two resources were retrieved from <a href=\"http://www.pathwaycommons.org/pc2/\">Pathway Commons</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkq1039\" class=\"citation \" data-key=\"10.1093/nar/gkq1039\">103</a>]</span>, which compiles pathways from several providers. Duplicate pathways and pathways without multiple participating genes were removed <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d72\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d72\">104</a>, <a href=\"https://doi.org/10.5281/zenodo.48810\" class=\"citation citation-figure\" data-key=\"10.5281/zenodo.48810\">105</a>]</span>. Biological processes, cellular components, and molecular functions were extracted from the <a href=\"http://geneontology.org/\">Gene Ontology</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1038/75556\" class=\"citation \" data-key=\"10.1038/75556\">106</a>]</span>. Only terms with 2&#8211;1000 annotated genes were included.</p>\r\n\r\n<h2 id=\"mappings\">Mappings</h2>\r\n\r\n<p>Before adding relationships, all identifiers needed to be converted into the vocabularies matching that of our nodes. Oftentimes, our node vocabularies included external mappings. For example, the Disease Ontology includes mappings to MeSH, UMLS, and the ICD, several of which we submitted during the course of this study <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d68\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d68\">107</a>]</span>. In a few cases, the only option was to map using gene symbols, a disfavored method given that it can lead to ambiguities.</p>\r\n\r\n<p>When mapping external disease concepts onto DO Slim, we used transitive closure. For example, the UMLS concept for primary progressive multiple sclerosis (<a href=\"http://linkedlifedata.com/resource/umls-concept/C0751964\"><code>C0751964</code></a>) was mapped to the DO Slim term for multiple sclerosis (<a href=\"http://purl.obolibrary.org/obo/DOID_2377\"><code>DOID:2377</code></a>).</p>\r\n\r\n<p>Chemical vocabularies presented the greatest mapping challenge <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d40\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d40\">85</a>]</span>, since these are poorly standardized <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.ddtec.2015.01.005\" class=\"citation \" data-key=\"10.1016/j.ddtec.2015.01.005\">108</a>]</span>. UniChem's <span class=\"citation\">[<a href=\"https://doi.org/10.1186/1758-2946-5-3\" class=\"citation \" data-key=\"10.1186/1758-2946-5-3\">109</a>]</span> Connectivity Search <span class=\"citation\">[<a href=\"https://doi.org/10.1186/s13321-014-0043-5\" class=\"citation \" data-key=\"10.1186/s13321-014-0043-5\">110</a>]</span> was used to map compounds, which maps by atomic connectivity (based on First InChIKey Hash Blocks <span class=\"citation\">[<a href=\"https://doi.org/10.1186/1758-2946-5-7\" class=\"citation \" data-key=\"10.1186/1758-2946-5-7\">111</a>]</span>) and ignores small molecular differences.</p>\r\n\r\n<h2 id=\"edges\">Edges</h2>\r\n\r\n<p><em>Anatomy&#8211;downregulates&#8211;Gene</em> and <em>Anatomy&#8211;upregulates&#8211;Gene</em> edges <span class=\"citation\">[<a href=\"https://doi.org/10.5281/zenodo.47157\" class=\"citation citation-figure\" data-key=\"10.5281/zenodo.47157\">112</a>, <a href=\"https://doi.org/10.15363/thinklab.d124\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d124\">113</a>, <a href=\"https://doi.org/10.15363/thinklab.d81\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d81\">114</a>]</span> were extracted from  <a href=\"http://bgee.org/\">Bgee</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1007/978-3-540-69828-9_12\" class=\"citation \" data-key=\"10.1007/978-3-540-69828-9_12\">115</a>]</span>, which computes differentially expressed genes by anatomy in post-juvenile adult humans. <em>Anatomy&#8211;expresses&#8211;Gene</em> edges were extracted from Bgee and <a href=\"http://tissues.jensenlab.org/\">TISSUES</a> <span class=\"citation\">[<a href=\"https://doi.org/10.7717/peerj.1054\" class=\"citation \" data-key=\"10.7717/peerj.1054\">116</a>, <a href=\"https://doi.org/10.5281/zenodo.27244\" class=\"citation citation-figure\" data-key=\"10.5281/zenodo.27244\">117</a>, <a href=\"https://doi.org/10.15363/thinklab.d91\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d91\">118</a>]</span>.</p>\r\n\r\n<p><em>Compound&#8211;binds&#8211;Gene</em> edges were aggregated from <a href=\"https://bindingdb.org\">BindingDB</a> <span class=\"citation\">[<a href=\"https://doi.org/10.2174/1386207013330670\" class=\"citation \" data-key=\"10.2174/1386207013330670\">119</a>, <a href=\"https://doi.org/10.1093/nar/gkv1072\" class=\"citation \" data-key=\"10.1093/nar/gkv1072\">120</a>]</span>, <a href=\"http://www.drugbank.ca/\">DrugBank</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkj067\" class=\"citation \" data-key=\"10.1093/nar/gkj067\">121</a>, <a href=\"https://doi.org/10.1093/nar/gkt1068\" class=\"citation \" data-key=\"10.1093/nar/gkt1068\">84</a>]</span>, and <a href=\"http://drugcentral.org/\">DrugCentral</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkw993\" class=\"citation \" data-key=\"10.1093/nar/gkw993\">91</a>]</span>. Only binding relationships to single proteins with affinities of at least 1 &#956;M (as determined by Kd, K&#7522;, or IC&#8325;&#8320;) were selected&#160;from the October 2015 release of BindingDB <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d53\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d53\">122</a>, <a href=\"https://doi.org/10.5281/zenodo.33987\" class=\"citation citation-figure\" data-key=\"10.5281/zenodo.33987\">123</a>]</span>. Target, carrier, transporter, and enzyme interactions with single proteins (i.e. excluding protein groups)&#160;were extracted from DrugBank 4.2 <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d65\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d65\">124</a>, <a href=\"https://doi.org/10.5281/zenodo.45579\" class=\"citation citation-figure\" data-key=\"10.5281/zenodo.45579\">86</a>]</span>. In addition, all mapping DrugCentral target relationships&#160;were included <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d186\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d186\">92</a>]</span>.</p>\r\n\r\n<p><em>Compound&#8211;treats&#8211;Disease</em> (disease-modifying indications) and <em>Compound&#8211;palliates&#8211;Disease</em> (symptomatic indications) edges are from PharmacotherapyDB as described in <a href=\"#intermediate-resources\">Intermediate resources</a>. <em>Compound&#8211;causes&#8211;Side Effect</em> edges were obtained from <a href=\"http://sideeffects.embl.de/\">SIDER</a> 4.1 <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkv1075\" class=\"citation \" data-key=\"10.1093/nar/gkv1075\">87</a>, <a href=\"https://doi.org/10.15363/thinklab.d97\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d97\">88</a>, <a href=\"https://doi.org/10.5281/zenodo.45521\" class=\"citation citation-figure\" data-key=\"10.5281/zenodo.45521\">89</a>]</span>, which uses natural language processing to identify side effects in drug labels. <em>Compound&#8211;resembles&#8211;Compound</em> relationships <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d70\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d70\">125</a>, <a href=\"https://doi.org/10.5281/zenodo.45579\" class=\"citation citation-figure\" data-key=\"10.5281/zenodo.45579\">86</a>, <a href=\"https://doi.org/10.6084/m9.figshare.1418386\" class=\"citation citation-figure\" data-key=\"10.6084/m9.figshare.1418386\">126</a>]</span> represent chemical similarity and correspond to a Dice coefficient &#8805; 0.5 <span class=\"citation\">[<a href=\"https://doi.org/10.2307/1932409\" class=\"citation \" data-key=\"10.2307/1932409\">127</a>]</span> between extended connectivity fingerprints <span class=\"citation\">[<a href=\"https://doi.org/10.1021/ci100050t\" class=\"citation \" data-key=\"10.1021/ci100050t\">128</a>, <a href=\"https://doi.org/10.1021/c160017a018\" class=\"citation \" data-key=\"10.1021/c160017a018\">129</a>]</span>.  <em>Compound&#8211;downregulates&#8211;Gene</em> and <em>Compound&#8211;upregulates&#8211;Gene</em> relationships were computed from LINCS L1000 as described in <a href=\"#intermediate-resources\">Intermediate resources</a>.</p>\r\n\r\n<p><em>Disease&#8211;associates&#8211;Gene</em> edges were extracted from the GWAS Catalog <span class=\"citation\">[<a href=\"https://doi.org/10.5281/zenodo.48428\" class=\"citation citation-figure\" data-key=\"10.5281/zenodo.48428\">130</a>]</span>, DISEASES <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d106\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d106\">131</a>, <a href=\"https://doi.org/10.5281/zenodo.48425\" class=\"citation citation-figure\" data-key=\"10.5281/zenodo.48425\">132</a>]</span>, DisGeNET <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d105\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d105\">133</a>, <a href=\"https://doi.org/10.5281/zenodo.48426\" class=\"citation citation-figure\" data-key=\"10.5281/zenodo.48426\">134</a>]</span>, and DOAF <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d94\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d94\">135</a>, <a href=\"https://doi.org/10.5281/zenodo.48427\" class=\"citation citation-figure\" data-key=\"10.5281/zenodo.48427\">136</a>]</span>. The <a href=\"https://www.ebi.ac.uk/gwas/\">GWAS Catalog</a> compiles disease&#8211;SNP associations from published GWAS <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkw1133\" class=\"citation \" data-key=\"10.1093/nar/gkw1133\">137</a>]</span>. We aggregated overlapping loci associated with each disease and identified the mode reported gene for each high confidence locus <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d80\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d80\">138</a>, <a href=\"https://doi.org/10.15363/thinklab.d71\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d71\">139</a>]</span>. <a href=\"http://diseases.jensenlab.org/Search\">DISEASES</a> integrates evidence of association from text mining, curated catalogs, and experimental data <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.ymeth.2014.11.020\" class=\"citation \" data-key=\"10.1016/j.ymeth.2014.11.020\">140</a>]</span>. Associations from DISEASES with integrated scores &#8805; 2 were included after removing the contribution of DistiLD. <a href=\"http://www.disgenet.org\">DisGeNET</a> integrates evidence from over 10 sources and reports a single score for each association <span class=\"citation\">[<a href=\"https://doi.org/10.1093/database/bav028\" class=\"citation \" data-key=\"10.1093/database/bav028\">141</a>]</span>. Associations with scores &#8805; 0.06 were included. DOAF mines Entrez Gene GeneRIFs (textual annotations of gene function) for disease mentions <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pone.0049686\" class=\"citation \" data-key=\"10.1371/journal.pone.0049686\">142</a>]</span>. Associations with 3 or more supporting GeneRIFs were included. <em>Disease&#8211;downregulates&#8211;Gene</em> and <em>Disease&#8211;upregulates&#8211;Gene</em> relationships <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d96\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d96\">143</a>, <a href=\"https://doi.org/10.5281/zenodo.46866\" class=\"citation citation-figure\" data-key=\"10.5281/zenodo.46866\">144</a>]</span> were computed using <a href=\"http://stargeo.org/\">STARGEO</a> as described in <a href=\"#intermediate-resources\">Intermediate resources</a>.</p>\r\n\r\n<p><em>Disease&#8211;localizes&#8211;Anatomy</em>, <em>Disease&#8211;presents&#8211;Symptom</em>, and <em>Disease&#8211;resembles&#8211;Disease</em> edges were calculated from MEDLINE co-occurrence <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d67\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d67\">82</a>, <a href=\"https://doi.org/10.5281/zenodo.48445\" class=\"citation citation-figure\" data-key=\"10.5281/zenodo.48445\">145</a>]</span>. MEDLINE is a subset of 21 million PubMed articles for which designated human curators have assigned topics. When retrieving articles for a given topic (MeSH term), we activated two non-default search options as specified below: <code>majr</code> for selecting only articles where the topic is major and <code>noexp</code> for suppressing explosion (returning articles linked to MeSH subterms). We identified 4,161,769 articles with two or more disease topics; 696,252 articles with both a disease topic (<code>majr</code>) and an anatomy topic (<code>noexp</code>) <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d93\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d93\">146</a>]</span>; and 363,928 articles with both a disease topic (<code>majr</code>) and a symptom topic (<code>noexp</code>). We used a Fisher's exact test <span class=\"citation\">[<a href=\"https://doi.org/10.2307/2340521\" class=\"citation \" data-key=\"10.2307/2340521\">147</a>]</span> to identify pairs of terms that occurred together more than would be expected by chance in their respective corpus. We included co-occurring terms with <em>p</em> &lt; 0.005 in Hetionet v1.0.</p>\r\n\r\n<p><em>Gene&#8211;covaries&#8211;Gene</em> edges represent evolutionary rate covariation &#8805; 0.75 <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pgen.1004967\" class=\"citation \" data-key=\"10.1371/journal.pgen.1004967\">148</a>, <a href=\"https://doi.org/10.15363/thinklab.d57\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d57\">149</a>, <a href=\"https://doi.org/10.5281/zenodo.48444\" class=\"citation citation-figure\" data-key=\"10.5281/zenodo.48444\">150</a>]</span>. <em>Gene&#8211;interacts&#8211;Gene</em> edges <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d85\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d85\">151</a>, <a href=\"https://doi.org/10.5281/zenodo.48443\" class=\"citation citation-figure\" data-key=\"10.5281/zenodo.48443\">152</a>]</span> represent when two genes produce physically-interacting proteins. We compiled these interactions from the Human Interactome Database <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nature04209\" class=\"citation \" data-key=\"10.1038/nature04209\">153</a>, <a href=\"https://doi.org/10.1038/nmeth.1280\" class=\"citation \" data-key=\"10.1038/nmeth.1280\">154</a>, <a href=\"https://doi.org/10.1038/nmeth.1597\" class=\"citation \" data-key=\"10.1038/nmeth.1597\">155</a>, <a href=\"https://doi.org/10.1016/j.cell.2014.10.050\" class=\"citation \" data-key=\"10.1016/j.cell.2014.10.050\">156</a>]</span>, the Incomplete Interactome <span class=\"citation\">[<a href=\"https://doi.org/10.1126/science.1257601\" class=\"citation \" data-key=\"10.1126/science.1257601\">157</a>]</span>, and our previous study <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation \" data-key=\"10.1371/journal.pcbi.1004259\">22</a>]</span>. <em>Gene&#8211;participates&#8211;Biological Process</em>, <em>Gene&#8211;participates&#8211;Cellular Component</em>, and <em>Gene&#8211;participates&#8211;Molecular Function</em> edges are from Gene Ontology annotations <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gku1113\" class=\"citation \" data-key=\"10.1093/nar/gku1113\">158</a>]</span>. As described in <a href=\"#intermediate-resources\">Intermediate resources</a>, annotations were propagated <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d39\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d39\">159</a>, <a href=\"https://doi.org/10.5281/zenodo.21711\" class=\"citation citation-figure\" data-key=\"10.5281/zenodo.21711\">160</a>]</span>.</p>\r\n\r\n<h2 id=\"intermediate-resources\">Intermediate resources</h2>\r\n\r\n<p>In the process of creating Hetionet, we produced several datasets with broad applicability that extended beyond Project Rephetio. These resources are referred to as intermediate resources and described below.</p>\r\n\r\n<h3>Transcriptional signatures of disease using STARGEO</h3>\r\n\r\n<p><a href=\"http://stargeo.org/\">STARGEO</a> is a nascent platform for annotating and meta-analyzing differential gene expression experiments. The STAR acronym stands for Search-Tag-Analyze Resources, while GEO refers to the Gene Expression Omnibus <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/30.1.207\" class=\"citation \" data-key=\"10.1093/nar/30.1.207\">161</a>, <a href=\"https://doi.org/10.1093/nar/gks1193\" class=\"citation \" data-key=\"10.1093/nar/gks1193\">162</a>]</span>. STARGEO is a layer on top of GEO that crowdsources sample annotation and automates meta-analysis.</p>\r\n\r\n<p>Using STARGEO, we computed differentially expressed genes between healthy and diseased samples for 49 diseases <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d96\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d96\">143</a>, <a href=\"https://doi.org/10.5281/zenodo.46866\" class=\"citation citation-figure\" data-key=\"10.5281/zenodo.46866\">144</a>]</span>. First, we and others created case/control tags for 66 diseases. After combing through GEO series and tagging samples, 49 diseases had sufficient data for case-control meta-analysis: multiple series with at least 3 cases and 3 controls. For each disease, we performed a random effects meta-analysis on each gene to combine log2 fold-change across series. These analyses incorporated 27,019 unique samples from 460 series on 107 platforms.</p>\r\n\r\n<p>Differentially expressed genes (false discovery rate &#8804; 0.05) were identified for each disease. The median number of upregulated genes per disease was 351 and the median number of downregulated genes was 340. Endogenous depression was the only of the 49 diseases without any significantly dysregulated genes.</p>\r\n\r\n<h3>Transcriptional signatures of perturbation from LINCS L1000</h3>\r\n\r\n<p><a href=\"http://www.lincscloud.org/l1000/\">LINCS L1000</a> profiled the transcriptional response to small molecule and genetic interference perturbations. To increase throughput, expression was only measured for 978 genes, which were selected for their ability to impute expression of the remaining genes. A single perturbation was often assayed under a variety of conditions including cell types, dosages, timepoints, and concentrations. Each condition generates a single signature of dysregulation <em>z</em>-scores. We further processed these signatures to fit into our approach <span class=\"citation\">[<a href=\"https://doi.org/10.5281/zenodo.47223\" class=\"citation citation-figure\" data-key=\"10.5281/zenodo.47223\">163</a>, <a href=\"https://doi.org/10.6084/m9.figshare.3085837.v1\" class=\"citation citation-figure\" data-key=\"10.6084/m9.figshare.3085837.v1\">164</a>]</span>.</p>\r\n\r\n<p>First we computed consensus signatures &#8212; which meta-analyze multiple signatures to condense them into one &#8212; for DrugBank small molecules, Entrez genes, and all L1000 perturbations <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d43\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d43\">165</a>, <a href=\"https://doi.org/10.6084/m9.figshare.3085426.v1\" class=\"citation citation-figure\" data-key=\"10.6084/m9.figshare.3085426.v1\">166</a>]</span>. First, we discarded non-gold (non-replicating or indistinct) signatures. Then we meta-analyzed <em>z</em>-scores using Stouffer's method. Each signature was weighted by its average Spearman's correlation to other signatures, with a 0.05 minimum, to de-emphasize discordant signatures. Our signatures include the 978 measured genes and the 6,489 imputed genes from the \"best inferred gene subset\". To identify significantly dysregulated genes, we selected genes using a Bonferroni cutoff of <em>p</em> = 0.05 and limited the number of imputed genes to 1,000.</p>\r\n\r\n<p>The consensus signatures for genetic perturbations allowed us to assess various characteristics of the L1000 dataset. First, we looked at whether genetic interference dysregulated its target gene in the expected direction <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d185\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d185\">167</a>]</span>. Looking at measured z-scores for target genes, we found that the knockdown perturbations were highly reliable, while the overexpression perturbations were only moderately reliable with 36% of overexpression perturbations downregulating their target. However, imputed z-scores for target genes barely exceeded chance at responding in the expected direction to interference. Hence, we concluded that the imputation quality of LINCS L1000 is poor. However, when restricting to significantly dyseregulated targets, 22 out of 29 imputed genes responded in the expected direction. This provides some evidence that the directional fidelity of imputation is higher for significantly dysregulated genes. Finally, we found that the transcriptional signatures of knocking down and overexpressing the same gene were positively correlated 65% of the time, suggesting the presence of a general stress response <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d171\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d171\">168</a>]</span>.</p>\r\n\r\n<p>Based on these findings, we performed additional filtering of signifcantly dysregulated genes when building Hetionet v1.0. <em>Compound&#8211;down/up-regulates&#8211;Gene</em> relationships were restricted to the 125 most significant per compound-direction-status combination (status refers to measured versus imputed). For genetic interference perturbations, we restricted to the 50 most significant genes per gene-direction-status combination and merged the remaining edges into a single <em>Gene&#8594;regulates&#8594;Gene</em> relationship type containing both knockdown and overexpression perturbations.</p>\r\n\r\n<h3>PharmacotherapyDB: physician curated indications</h3>\r\n\r\n<p>We created PharmacotherapyDB, an open catalog of drug therapies for disease <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d182\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d182\">169</a>, <a href=\"https://doi.org/10.6084/m9.figshare.3103054\" class=\"citation citation-figure\" data-key=\"10.6084/m9.figshare.3103054\">170</a>, <a href=\"https://doi.org/10.5281/zenodo.47664\" class=\"citation citation-figure\" data-key=\"10.5281/zenodo.47664\">171</a>]</span>. Version 1.0 contains 755 disease-modifying therapies and 390 symptomatic therapies between 97 diseases and 601 compounds.</p>\r\n\r\n<p>This resource was motivated by the need for a gold standard of medical indications to train and evaluate our approach. Initially, we identified four existing indication catalogs <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d21\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d21\">172</a>]</span>: MEDI-HPS which mined indications from RxNorm, SIDER 2, MedlinePlus, and Wikipedia <span class=\"citation\">[<a href=\"https://doi.org/10.1136/amiajnl-2012-001431\" class=\"citation \" data-key=\"10.1136/amiajnl-2012-001431\">173</a>]</span>; LabeledIn which extracted indications from drug labels via human curation <span class=\"citation\">[<a href=\"https://doi.org/10.1016/j.jbi.2014.08.004\" class=\"citation \" data-key=\"10.1016/j.jbi.2014.08.004\">174</a>, <a href=\"https://doi.org/10.1093/database/bav016\" class=\"citation \" data-key=\"10.1093/database/bav016\">175</a>, <a href=\"https://doi.org/10.15363/thinklab.d46\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d46\">176</a>]</span>; EHRLink which identified medication&#8211;problem pairs that clinicians linked together in electronic health records <span class=\"citation\">[<a href=\"https://doi.org/10.1136/amiajnl-2012-000852\" class=\"citation \" data-key=\"10.1136/amiajnl-2012-000852\">177</a>, <a href=\"https://doi.org/10.15363/thinklab.d62\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d62\">178</a>]</span>; and indications from PREDICT, which were compiled from UMLS relationships, drugs.com, and drug labels <span class=\"citation\">[<a href=\"https://doi.org/10.1038/msb.2011.26\" class=\"citation \" data-key=\"10.1038/msb.2011.26\">24</a>]</span>. After mapping to DO Slim and DrugBank Slim, the four resources contained 1,388 distinct indications.</p>\r\n\r\n<p>However, we noticed that many indications were palliative and hence problematic as a gold standard of pharmacotherapy for our <em>in silico</em> approach. Therefore, we recruited two practicing physicians to curate the 1,388 preliminary indications <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d95\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d95\">179</a>]</span>. After a pilot on 50 indications, we defined three classifications: <em>disease modifying</em> meaning a drug that therapeutically changes the underlying or downstream biology of the disease; <em>symptomatic</em> meaning a drug that treats a significant symptom of the disease; and <em>non-indication</em> meaning a drug that neither therapeutically changes the underlying or downstream biology nor treats a significant symptom of the disease. Both curators independently classified all 1,388 indications.</p>\r\n\r\n<p>The two curators disagreed on 444 calls (Cohen's &#954; = 49.9%). We then recruited a third practicing physician, who reviewed all 1,388 calls and created a detailed explanation of his methodology <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d95\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d95\">179</a>]</span>. We proceeded with the third curator's calls as the consensus curation. The first two curators did have reservations with classifying steroids as disease modifying for autoimmune diseases. We ultimately considered that these indications met our definition of disease modifying, which is based on a pathophysiological rather than clinical standard. Accordingly, therapies we consider disease modifying may not be used to alter long-term disease course in the modern clinic due to a poor risk&#8211;benefit ratio.</p>\r\n\r\n<h3>User-friendly Gene Ontology annotations</h3>\r\n\r\n<p>We created a browser (http://git.dhimmel.com/gene-ontology/) to provide straightforward access to Gene Ontology annotations <span class=\"citation\">[<a href=\"https://doi.org/10.5281/zenodo.21711\" class=\"citation citation-figure\" data-key=\"10.5281/zenodo.21711\">160</a>, <a href=\"https://doi.org/10.15363/thinklab.d39\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d39\">159</a>]</span>. Our service provides annotations between Gene Ontology terms and Entrez Genes. The user chooses propagated/direct annotation and all/experimental evidence. Annotations are currently available for 37 species and downloadable as user-friendly TSV files.</p>\r\n\r\n<h2 id=\"data-copyright-and-licensing\">Data copyright and licensing</h2>\r\n\r\n<p>We committed to openly releasing our data and analyses from the origin of the project <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d23\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d23\">180</a>]</span>. Our goals were to contribute to the advancement of science <span class=\"citation\">[<a href=\"https://doi.org/10.1629/2431\" class=\"citation \" data-key=\"10.1629/2431\">181</a>, <a href=\"https://doi.org/10.1371/journal.pbio.1001195\" class=\"citation \" data-key=\"10.1371/journal.pbio.1001195\">182</a>]</span>, maximize our impact <span class=\"citation\">[<a href=\"https://doi.org/10.7554/eLife.16800\" class=\"citation \" data-key=\"10.7554/eLife.16800\">183</a>, <a href=\"https://doi.org/10.7717/peerj.175\" class=\"citation \" data-key=\"10.7717/peerj.175\">184</a>]</span>, and enable reproducibility <span class=\"citation\">[<a href=\"https://doi.org/10.1126/science.aah6168\" class=\"citation \" data-key=\"10.1126/science.aah6168\">185</a>, <a href=\"https://doi.org/10.5334/jors.ay\" class=\"citation \" data-key=\"10.5334/jors.ay\">186</a>, <a href=\"https://doi.org/10.1038/467401b\" class=\"citation \" data-key=\"10.1038/467401b\">187</a>]</span>. These objectives required publicly distributing and openly licensing Hetionet and Project Rephetio data and analyses <span class=\"citation\">[<a href=\"https://doi.org/10.1186/1756-0500-5-494\" class=\"citation \" data-key=\"10.1186/1756-0500-5-494\">188</a>, <a href=\"https://doi.org/10.3897/zookeys.150.2189\" class=\"citation \" data-key=\"10.3897/zookeys.150.2189\">189</a>]</span>.</p>\r\n\r\n<p>Since we integrated only public resources, which were overwhelmingly funded by academic grants, we had assumed that our project and open sharing of our network would not be an issue. However, upon releasing a preliminary version of Hetionet <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d102\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d102\">190</a>]</span>, a community reviewer informed us of legal barriers to integrating public data. In essence, both copyright (rights of exclusivity automatically granted to original works) and terms of use (rules that users must agree to in order to use a resource) place legally-binding restrictions on data reuse. In short, public data is not by default open data.</p>\r\n\r\n<p>Hetionet v1.0 integrates 29 resources, but two resources were removed prior to the v1.0 release. Of the total <a href=\"https://github.com/dhimmel/integrate/blob/725f4e4b4a737cfb15abe55ef36386c23e1c4f1f/licenses/README.md\" title=\"Source license table on GitHub\">31 resources</a> <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d107\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d107\">191</a>]</span>, five were United States government works not subject to copyright, and twelve had licenses that met the <a href=\"http://opendefinition.org/od/2.1/en/\">Open Definition</a> of knowledge version 2.1. Four resources allowed only non-commercial reuse. Most problematic were the remaining nine resources that had no license &#8212; which equates to all rights reserved by default and forbids reuse <span class=\"citation\">[<a href=\"https://doi.org/10.1038/536016a\" class=\"citation \" data-key=\"10.1038/536016a\">192</a>]</span> &#8212; and one resource that explicitly forbid redistribution.</p>\r\n\r\n<p>Additional difficulty resulted from license incompatibles across resources, which was caused primarily by non-commercial and share-alike stipulations. Furthermore, it was often unclear who owned the data <span class=\"citation\">[<a href=\"https://doi.org/10.1087/0953151053584984\" class=\"citation \" data-key=\"10.1087/0953151053584984\">193</a>]</span>. Therefore, we sought input from legal experts and chronicled our progress <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d107\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d107\">191</a>, <a href=\"https://doi.org/10.15363/thinklab.d108\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d108\">194</a>, <a href=\"https://doi.org/10.15363/thinklab.d111\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d111\">195</a>, <a href=\"https://doi.org/10.15363/thinklab.d110\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d110\">196</a>, <a href=\"https://doi.org/10.15363/thinklab.d213\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d213\">197</a>]</span>.</p>\r\n\r\n<p>Ultimately, we did not find an ideal solution. We had to choose between absolute compliance and Hetionet: strictly adhering to copyright and licensing arrangements would have decimated the network. On the other hand, in the United States, mere facts are not subject to copyright, and fair use doctrine helps protect reuse that is transformative and educational. Hence, we choose a path forward which balanced legal, normative, ethical, and scientific considerations.</p>\r\n\r\n<p>If a resource was in the public domain, we licensed any derivatives as CC0 1.0. For resources licensed to allow reuse, redistribution, and modification, we transmitted their licenses as properties on the specific nodes and relationships in Hetionet v1.0. For all other resources &#8212; for example, resources without licenses or with licenses that forbid redistribution &#8212; we sent permission requests to their creators. The median time till first response to our permission requests was 16 days, with only 2 resources affirmatively granting us permission. We did not receive any responses asking us to remove a resource. However, we did voluntarily remove MSigDB <span class=\"citation\">[<a href=\"https://doi.org/10.1093/bioinformatics/btr260\" class=\"citation \" data-key=\"10.1093/bioinformatics/btr260\">198</a>]</span>, since its license was highly problematic <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d108\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d108\">194</a>]</span>. As a result of our experience, we recommend that publicly-funded data should be explicitly dedicated to the public domain whenever possible.</p>\r\n\r\n<h2 id=\"permuted-hetnets\">Permuted Hetnets</h2>\r\n\r\n<p>From Hetionet, we derived five permuted hetnets <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d178\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d178\">199</a>]</span>. The permutations preserve node degree but eliminate edge specificity by employing an algorithm called XSwap to randomly swap edges <span class=\"citation\">[<a href=\"https://doi.org/10.1137/1.9781611972795.67\" class=\"citation \" data-key=\"10.1137/1.9781611972795.67\">200</a>]</span>. Permuted networks are useful for computing the baseline performance of meaningless edges while preserving node degree <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d136\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d136\">201</a>]</span>.</p>\r\n\r\n<h2 id=\"neo4j\">Neo4j</h2>\r\n\r\n<p>Graph database adoption in bioinformatics has thus far been limited <span class=\"citation\">[<a href=\"https://doi.org/10.1093/bioinformatics/btt549\" class=\"citation \" data-key=\"10.1093/bioinformatics/btt549\">202</a>]</span>. We used the Neo4j graph database for storing and operating on Hetionet and noticed major benefits from tapping into this large open source ecosystem <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d112\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d112\">203</a>]</span>. Persistent storage with immediate access and the Cypher query language &#8212; a sort of SQL for hetnets &#8212; were two of the biggest benefits. To facilitate our migration to Neo4j, we updated <a href=\"https://github.com/dhimmel/hetio\" title=\"dhimmel/hetio on GitHub\"><code>hetio</code></a> &#8212; our existing Python package for hetnets <span class=\"citation\">[<a href=\"https://doi.org/10.5281/zenodo.61571\" class=\"citation citation-figure\" data-key=\"10.5281/zenodo.61571\">204</a>]</span> &#8212; to export networks into Neo4j and DWPC queries to Cypher. In addition, we created an <a href=\"http://portal.graphgist.org/graph_gists/drug-repurposing-by-hetnet-relationship-prediction-a-new-hope\" title=\"Neo4j GraphGist: Drug repurposing by hetnet relationship prediction\">interactive GraphGist</a> for Project Rephetio, which introduces our approach and showcases its Cypher queries. Finally, we created a <a href=\"https://neo4j.het.io\" title=\"Hetionet Neo4j Browser\">public Neo4j instance</a> <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d216\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d216\">205</a>]</span>, which leverages several modern technologies such Neo4j Browser guides, cloud hosting with HTTPS, and Docker deployment <span class=\"citation\">[<a href=\"https://doi.org/10.1186/s13742-015-0087-0\" class=\"citation \" data-key=\"10.1186/s13742-015-0087-0\">206</a>, <a href=\"https://doi.org/10.1101/056473\" class=\"citation \" data-key=\"10.1101/056473\">207</a>]</span>.</p>\r\n\r\n<h2 id=\"machine-learning-approach\">Machine learning approach</h2>\r\n\r\n<p>We made several refinements to metapath-based hetnet edge prediction compared to previous studies <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation \" data-key=\"10.1371/journal.pcbi.1004259\">22</a>, <a href=\"https://doi.org/10.1109/ASONAM.2011.112\" class=\"citation \" data-key=\"10.1109/ASONAM.2011.112\">23</a>]</span>. First, we transformed DWPCs by mean scaling and then taking the inverse hyperbolic sine <span class=\"citation\">[<a href=\"https://doi.org/10.2307/2288929\" class=\"citation \" data-key=\"10.2307/2288929\">208</a>]</span> to make them more amenable to modeling <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d193\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d193\">209</a>]</span>. Second, we bifurcated the workflow into an all-features stage and an all-observations stage <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d210\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d210\">40</a>]</span>. The all-features stage assesses feature performance and does not require computing features for all negatives. Here we selected a random subset of 3,020 (4 &#215; 755) negatives. Little error was introduced by this optimization, since the predominant limitation to performance assessment was the small number of positives (755) rather than negatives. Based on the all-features performance assessment <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d115\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d115\">210</a>]</span>, we selected 142 DWPCs to compute on all observations (all 209,168 compound&#8211;disease pairs). The feature selection was designed to remove uninformative features (according to permutation) and guard against edge-dropout contamination <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d215\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d215\">211</a>]</span>. Third, we included 14 degree features, which assess the degree of a specific metaedge for either the source compound or target disease.</p>\r\n\r\n<h3>Network support of predictions</h3>\r\n\r\n<p>To improve the interpretability of the predictions, we developed a method for decomposing a prediction into its network support <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d229\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d229\">212</a>]</span>. This information is deployed to our Neo4j Browser guides, allowing users to assess the biomedical evidence contributing to a given prediction. First, we used logistic regression terms to quantify the contribution of metapaths that positively support a prediction. Second, we decomposed a metapath's contribution, according to its DWPC, into specific paths contributions. Finally, we aggregated paths based on their source (first) or target (last) edge to quantify the contribution of specific edges of the source compound or target disease <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d228\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d228\">213</a>]</span>.</p>\r\n\r\n<p>Using the <a href=\"https://neo4j.het.io/browser/?cmd=play&amp;arg=https://neo4j.het.io/guides/rep/DB00659/DOID_1826.html\" title=\"Hetionet Neo4j Browser with the network evidence that acamprosate treats epilepsy syndrome\">acamprosate&#8211;epilepsy prediction</a> as an example, we first quantified metapath contributions: 40% of the prediction was supported by <em>CbGbCtD</em> paths, 36% by <em>CbGaD</em> paths, 11% by <em>CcSEcCtD</em> paths, 8% by <em>CbGpPWpGaD</em> paths, and 5% by <em>CbGeAlD</em> paths. Second, we calculated path contributions: <em>Acamprosate&#8211;binds&#8211;GRM5&#8211;associates&#8211;epilepsy syndrome</em> was the most supportive path, contributing 11% of the prediction. Finally, we aggregated path contributions to calculate that the source edge of <em>Acamprosate&#8212;binds&#8212;GRM5</em> contributed 23% of the prediction, while the target edge of <em>epilepsy syndrome&#8211;treats&#8211;Felbamate</em> contributed 12%.</p>\r\n\r\n<h3>Prior probability of treatment</h3>\r\n\r\n<p>The 755 treatments in Hetionet v1.0 are not evenly distributed between all compounds and diseases. For example, methotrexate treats 19 diseases and hypertension is treated by 68 compounds. We estimated a prior probability of treatment &#8212; based only on the treatment degree of the source compound and target disease &#8212; on 744,975 permutations of the bipartite treatment network <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d201\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d201\">214</a>]</span>. Methotrexate received a 79.6% prior probability of treating hypertension, whereas a compound and disease that both had only one treatment received a prior of 0.12%.</p>\r\n\r\n<p>Across the 209,168 compound&#8211;disease pairs, the prior predicted the known treatments with AUROC = 97.9%. The strength of this association threatened to dominate our predictions. However, not modeling the prior can lead to omitted-variable bias and confounded proxy variables. To address the issue, we included the logit-transformed prior, without any regularization, as a term in the model. This restricted model fitting to the 29,799 observations with a nonzero prior &#8212; corresponding to the 387 compounds and 77 diseases with at least one treatment. To enable predictions for all 209,168 observations, we set the prior for each compound&#8211;disease pair to the overall prevalence of positives (0.36%).</p>\r\n\r\n<p>This method succeeded at accommodating the treatment degrees. The prior probabilities performed poorly on the validation sets with AUROC = 54.1% on DrugCentral indications and AUROC = 62.5% on clinical trials. This performance dropoff compared to training shows the danger of encoding treatment degree into predictions. The benefits of our solution are highlighted by the superior validation performance of our predictions compared to the prior (<a href=\"#performance_figure\">Figure 3</a>).</p>\r\n\r\n<h2 id=\"indication-sets\">Indication sets</h2>\r\n\r\n<p>We evaluated our predictions on four sets of indications as shown in <a href=\"#performance_figure\">Figure 3</a>.</p>\r\n\r\n<ul><li><strong>Disease Modifying</strong> &#8212; the 755 disease modifying treatments in PharmacotherapyDB v1.0. These indications are included in the hetnet as <em>treats</em> edges and used to train the logistic regression model. Due to edge dropout contamination and self-testing <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d215\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d215\">211</a>, <a href=\"https://doi.org/10.15363/thinklab.d194\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d194\">215</a>]</span>, overfitting could potentially inflate performance on this set. Therefore, for the three remaining indication sets, we removed any observations that were positives in this set.</li><li><strong>DrugCentral</strong> &#8212; We discovered the <a href=\"https://github.com/olegursu/drugtarget\">DrugCentral database</a> after completing our physician curation for PharmacotherapyDB. This database contained 210 additional indications <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d186\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d186\">92</a>]</span>. While we didn't curate these indications, we observed a high proportion of disease modifying therapy.</li><li><strong>Clinical Trial</strong> &#8212; We compiled indications that have been investigated by clinical trial from <a href=\"https://clinicaltrials.gov/\">ClinicalTrials.gov</a> <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d212\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d212\">216</a>]</span>. This set contains 5,594 indications. Since these indications were not manually curated and clinical trials often show a lack of efficacy, we expected lower performance on this set.</li><li><strong>Symptomatic</strong> &#8212; 390 symptomatic indications from PharacotherapyDB. These edges are included in the hetnet as <em>palliates</em> edges.</li></ul>\r\n\r\n<p>Only the Clinical Trial and DrugCentral indication sets were used for external validation, since the Disease Modifying and Symptomatic indications were included in the hetnet.</p>\r\n\r\n<h2 id=\"realtime-open-science-thinklab\">Realtime open science &amp; Thinklab</h2>\r\n\r\n<p>We conducted our study using Thinklab &#8212; a platform for realtime open collaborative science &#8212; on which this study was the first project. We began the study by publicly proposing the idea and inviting discussion <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.a5\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.a5\">217</a>]</span>. We continued by chronicling our progress via discussions. We used Thinklab as the frontend to coordinate and report our analyses and GitHub as the backend to host our code, data, and notebooks. On top of our Thinklab team consisting of core contributors, we welcomed community contribution and review. In areas where our expertise was lacking or advice would be helpful, we sought input from domain experts and encouraged them to respond on Thinklab where their comments would be CC BY licensed and their contribution rated and rewarded.</p>\r\n\r\n<p>In total, 40 non-team members commented across 86 discussions, which generated 607 comments and 190 notes (<a href=\"#contribution_figure\">Figure 6</a>). Thinklab content for this project totaled 143,056 words or 901,672 characters <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d200\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d200\">218</a>]</span>. Using an estimated 7,000 words per academic publication as a benchmark, Project Rephetio generated written content comparable in volume to 20.4 publications prior to its completion. We noticed several other benefits from using Thinklab including forging a community of contributors <span class=\"citation\">[<a href=\"https://doi.org/10.1242/dmm.003285\" class=\"citation \" data-key=\"10.1242/dmm.003285\">219</a>]</span>; receiving feedback during the early stages when feedback was most actionable <span class=\"citation\">[<a href=\"https://doi.org/10.3897/rio.1.e7547\" class=\"citation \" data-key=\"10.3897/rio.1.e7547\">220</a>]</span>; disseminating our research without delay <span class=\"citation\">[<a href=\"https://doi.org/10.1038/530148a\" class=\"citation \" data-key=\"10.1038/530148a\">221</a>, <a href=\"https://doi.org/10.1073/pnas.1511912112\" class=\"citation \" data-key=\"10.1073/pnas.1511912112\">222</a>]</span>; opening avenues for external input <span class=\"citation\">[<a href=\"https://doi.org/10.1038/530027a\" class=\"citation \" data-key=\"10.1038/530027a\">223</a>]</span>; facilitating problem-oriented teaching <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d181\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d181\">224</a>, <a href=\"https://doi.org/10.1038/523272a\" class=\"citation \" data-key=\"10.1038/523272a\">225</a>]</span>; and improving our documentation by maintaining a publication-grade digital lab notebook <span class=\"citation\">[<a href=\"https://doi.org/10.1038/481430a\" class=\"citation \" data-key=\"10.1038/481430a\">226</a>]</span>.</p>\r\n\r\n<a name=\"contribution_figure\"></a><div class=\"figure\" figure-id=\"contribution_figure\"><div class=\"figure-content\"><img src=\"https://think-lab.s3.amazonaws.com/m/figures/30.png\"></div>\n            <div class=\"signature-1\">\n                <div class=\"figure-title\">Figure 6. The growth the Project Rephetio corpus on Thinklab over time</div>\n                <div class=\"figure-description\"><p>This figure shows Project Rephetio contributions by user over time. Each band represented the cumulative contribution of a Thinklab user to <a href=\"http://thinklab.com/p/rephetio/discussion\">discussions</a> in the Rephetio project <span class=\"citation\">[<a href=\"https://doi.org/10.15363/thinklab.d200\" class=\"citation citation-self\" data-key=\"10.15363/thinklab.d200\">218</a>]</span>. Users are ordered by date of first contribution. Users who contributed over 4,500 characters are named. The square root transformation of characters written per user accentuates the activity of new contributors, thereby emphasizing collaboration and diverse input.</p></div>\n            </div>\n        </div>\r\n\r\n<h1 id=\"acknowledgements\">Acknowledgements</h1>\r\n\r\n<p>We are immensely grateful to our <a href=\"https://thinklab.com/p/rephetio/leaderboard\" title=\"Rephetio Project Thinklab Leaderboard\">Thinklab contributors</a> who joined us in our experiment of radically open science. The following non-team members provided contributions that received 5 or more Thinklab points: Lars Juhl Jensen, Frederic Bastian, Alexander Pico, Casey Greene, Benjamin Good, Craig Knox, Mike Gilson, Chris Mungall, Katie Fortney, Venkat Malladi, Tudor Oprea, MacKenzie Smith, Caty Chung, Allison McCoy, Alexey Strokach, Ritu Khare, Greg Way, Marina Sirota, Raghavendran Partha, Oleg Ursu, Jesse Spaulding, Gaya Nadarajan, Alex Ratner, Scooter Morris, Alessandro Didonna, Alex Pankov, Tong Shu Li, and Janet Pi&#241;ero. Additionally, the founder of Thinklab, Jesse Spaulding, supported community contributions and developed the platform with Project Rephetio's needs in mind. Finally, we would like to thank Neo Technology, whose staff provided excellent technical support.</p>\r\n\r\n<p>This material is based upon work supported by the National Science Foundation Graduate Research Fellowship under Grant No. 1144247 to DSH. SEB is supported by the Heidrich Family and Friends Foundation.</p>",
      "body_md": "# Abstract\r\n\r\nThe ability to computationally predict whether a compound treats a disease would improve the economy and success rate of drug approval. This study describes Project Rephetio to systematically model drug efficacy based on 755 existing treatments. First, we constructed Hetionet ([neo4j.het.io](https://neo4j.het.io \"Neo4j Hetionet Browser\")), an integrative network encoding knowledge from millions of biomedical studies. Hetionet v1.0 consists of 47,031 nodes of 11 types and 2,250,197 relationships of 24 types. Data was integrated from 29 public resources to connect compounds, diseases, genes, anatomies, pathways, biological processes, molecular functions, cellular components, pharmacologic classes, side effects, and symptoms. Next, we identified network patterns that distinguish treatments from non-treatments. Then we predicted the probability of treatment for 209,168 compound–disease pairs ([het.io/repurpose](http://het.io/repurpose/ \"Project Rephetio Prediction Browser\")). Our predictions validated on two external sets of treatment and provided pharmacological insights on epilepsy, suggesting they will help prioritize drug repurposing candidates. This study was entirely open and received realtime feedback from 40 community members.\r\n\r\n# Introduction\r\n\r\nThe cost of developing a new therapeutic drug has been estimated at 1.4 billion dollars [@10.1016/j.jhealeco.2016.01.012], the process typically takes 15 years from lead compound to market [@10.1038/nrd1178], and the likelihood of success is stunningly low [@10.1038/nbt.2786]. Strikingly, the costs have been doubling every 9 years since 1970, a sort of inverse Moore's law, which is far from an optimal strategy from both a business and public health perspective [@10.1038/nrd3681]. Drug repurposing — identifying novel uses for existing therapeutics — can drastically reduce the duration, failure rates, and costs of approval [@10.1038/nrd1468]. These benefits stem from the rich preexisting information on approved drugs, including extensive toxicology profiling performed during development, preclinical models, clinical trials, and postmarketing surveillance.\r\n\r\nDrug repurposing is poised to become more efficient as mining of electronic health records (EHRs) to retrospectively assess the effect of drugs gains feasibility [@10.1093/jamia/ocv102 @10.1136/amiajnl-2014-002649 @10.1016/j.amjmed.2015.10.015 @10.1126/scitranslmed.3003377]. However, systematic approaches to repurpose drugs based on mining EHRs alone will likely lack power due to multiple testing. Similar to the approach followed to increase the power of genome-wide association studies (GWAS) [@10.1038/nrg2615 @10.1093/brain/awn081], integration of biological knowledge to prioritize drug repurposing will help overcome limited EHR sample size and data quality.\r\n\r\nIn addition to repurposing, several other paradigm shifts in drug development have been proposed to improve efficiency. Since small molecules tend to bind to many targets, polypharmacology aims to find synergy in the multiple effects of a drug [@10.1038/nrd1346]. Network pharmacology assumes diseases consist of a multitude of molecular alterations resulting in a robust disease state. Network pharmacology seeks to uncover multiple points of intervention into a specific pathophysiological state that together rehabilitate an otherwise resilient disease process [@10.1038/nchembio.118 @10.1038/nbt1007-1110]. Although target-centric drug discovery has dominated the field for decades, phenotypic screens have more recently resulted in a comparatively higher number of first-in-class small molecules [@10.1038/nrd3480]. Recent technological advances have enabled a new paradigm in which mid- to high-throughput assessment of intermediate phenotypes, such as the molecular response to drugs, is replacing the classic target discovery approach [@10.1016/j.copbio.2011.11.010 @10.1038/nrc2044 @10.1016/j.drudis.2012.07.017]. Furthermore, integration of multiple channels of evidence, particularly diverse types of data, can overcome the limitations and weak performance inherent to data of a single domain [@10.1002/wsbm.1337]. Modern computational approaches offer a convenient platform to tie these developments together as the reduced cost and increased velocity of _in silico_ experimentation massively lowers the barriers to entry and price of failure [@10.1038/clpt.2013.1 @10.1016/j.drudis.2012.08.005].\r\n\r\nHetnets (short for heterogeneous networks) are networks with multiple types of nodes and relationships. They offer an intuitive, versatile and powerful structure for data integration. In this study, we developed a hetnet (Hetionet v1.0) by integrating knowledge and experimental findings from decades of biomedical research spanning millions of publications. We adapted an algorithm originally developed for social network analysis and applied it to Hetionet v1.0 to identify patterns of efficacy and predict new uses for drugs. The algorithm performs edge prediction through a machine learning framework that accommodates the breadth and depth of information contained in Hetionet v1.0 [@10.1371/journal.pcbi.1004259 @10.1109/ASONAM.2011.112]. Our approach represents an _in silico_ implementation of network pharmacology that natively incorporates polypharmacology and high-throughput phenotypic screening.\r\n\r\nOne fundamental characteristic of our method is that it learns and evaluates itself on existing medical indications (i.e. a \"gold standard\"). Next, we introduce previous approaches that also performed comprehensive evaluation on existing treatments. A 2011 study, named PREDICT, compiled 1,933 treatments between 593 drugs and 313 diseases [@10.1038/msb.2011.26]. Starting from the premise that similar drugs treat similar diseases, PREDICT trained a classifier that incorporates 5 types of drug-drug and 2 types of disease-disease similarity. A 2014 study compiled 890 treatments between 152 drugs and 145 diseases with transcriptional signatures [@10.1186/s13073-014-0095-1]. The authors found that compounds triggering an opposing transcriptional response to the disease were more likely to be treatments, although this effect was weak and limited to cancers. A 2016 study compiled 402 treatments between 238 drugs and 78 diseases and used a single proximity score — the average shortest path distance between a drug's targets and disease's associated proteins on the interactome — as a classifier [@10.1038/ncomms10331].\r\n\r\nWe build on these successes by creating a framework for incorporating the effects of any biological relationship into the prediction of whether a drug treats a disease. By doing this, we were able to capture a multitude of effects that have been suggested as influential for drug repurposing including drug-drug similarity [@10.1038/msb.2011.26 @10.1109/BIBM.2012.6392722], disease-disease similarity [@10.1038/msb.2011.26 @10.1038/clpt.2009.103], transcriptional signatures [@10.1186/s13073-014-0095-1 @10.1126/science.1132939 @10.1038/nrc2044 @10.1016/j.drudis.2012.07.014 @10.1016/j.drudis.2012.07.017], protein interactions [@10.1038/ncomms10331], genetic association [@10.1038/ng.3314 @10.1038/nbt.2151], drug side effects [@10.1126/science.1158140 @10.7717/peerj-cs.46], disease symptoms [@10.1038/ncomms5212], and molecular pathways [@10.1039/C4MB00014E]. Our ability to create such an integrative model of drug efficacy relies on the hetnet data structure to unite diverse information. On Hetionet v1.0, our algorithm learns which types of compound–disease paths discriminate treatments from non-treatments in order to predict the probability that a compound treats a disease.\r\n\r\nWe refer to this study as Project Rephetio (pronounced as **rep**-*het*-*ee*-oh). Both Rephetio and Hetionet are portmanteaus combining the words **rep**urpose, **het**erogeneous, and **net**work with the URL [het.**io**](http://het.io).\r\n\r\n# Results\r\n\r\n## Hetionet v1.0\r\n\r\nWe obtained and integrated data from 29 publicly available resources to create Hetionet v1.0 ([Figure 1](#hetionet_figure)). The hetnet contains 47,031 nodes of 11 types ([Table 1](#metanode_table)) and 2,250,197 relationships of 24 types ([Table 2](#metaedge_table)). The nodes consist of 1,552 small molecule compounds and 137 complex diseases, as well as genes, anatomies, pathways, biological processes, molecular functions, cellular components, perturbations, pharmacologic classes, drug side effects, and disease symptoms. The edges represent relationships between these nodes and encompass the collective knowledge produced by millions of studies over the last half century.\r\n\r\n[:figure](hetionet_figure)\r\n\r\nFor example, _Compound–binds–Gene_ edges represent when a compound binds to a protein encoded by a gene. This information has been extracted from the literature by human curators and compiled into databases such as DrugBank, ChEMBL, DrugCentral, and BindingDB. We combined these databases to create 11,571 binding edges between 1,389 compounds and 1,689 genes. These edges were compiled from 10,646 distinct publications, which Hetionet binding edges reference as an attribute. Binding edges represent a comprehensive catalog constructed from low throughput experimentation. However, we also integrated findings from high throughput technologies — many of which have only recently become available. For example, we generated consensus transcriptional signatures for compounds in LINCS L1000 and diseases in STARGEO.\r\n\r\n[:table](metanode_table)\r\n\r\n[:table](metaedge_table)\r\n\r\nWhile Hetionet v1.0 is ideally suited for drug repurposing, the network has broader biological applicability. For example, we have prototyped queries for a) identifying drugs that target a specific pathway, b) identifying biological processes involved in a specific disease, c) identifying the drug targets responsible for causing a specific side effect, and d) identifying anatomies with transcriptional relevance for a specific disease [@10.15363/thinklab.d220]. Each of these queries was simple to write and took less than a second to run on our publicly available Hetionet Browser. While it is possible that existing services provide much of the aforementioned functionality, they offer less versatility. Hetionet differentiates itself in its ability to flexibly query across multiple domains of information. As a proof of concept, we enhanced the biological process query (b), which identified processes that were enriched for disease-associated genes, using multiple sclerosis (MS) as an example disease. The enhanced query identified genes that interact with MS GWAS-genes. However, interacting genes were discarded unless they were upregulated in an MS-related anatomy (i.e. anatomical structure, e.g. organ or tissue). Then relevant biological processes were identified. Thus, the single query spanned 4 node and 5 relationship types. Furthermore, the portion of the query to identify paths meeting the above specification required only four lines of Cypher code.\r\n\r\nThe integrative potential of Hetionet v1.0 is reflected by its connectivity. Among the 11 metanodes, there are 66 possible source–target pairs. However, only 11 of them have at least one direct connection. In contrast, for paths of length 2, 50 pairs have connectivity (paths types that start on the source node type and end on the target node type, see [Figure 1C](#hetionet_figure)). At length 3, all 66 pairs are connected. At length 4, the source–target pair with the fewest types of connectivity (Side Effect to Symptom) has 13 metapaths, while the pair with the most connectivity types (Gene to Gene) has 3,542 pairs. This high level of connectivity across a diversity of biomedical entities forms the foundation for automated translation of knowledge into biomedical insight.\r\n\r\nHetionet v1.0 is accessible via a Neo4j Browser at https://neo4j.het.io. This public Neo4j instance provides users an installation-free method to query and visualize the network. The Browser contains a tutorial guide as well as guides with the details of each Project Rephetio prediction. Hetionet v1.0 is also [available for download](https://github.com/dhimmel/hetionet \"Hetionet on GitHub\") in JSON, Neo4j, and TSV formats [@10.5281/zenodo.268568]. The JSON and Neo4j database formats include node and edge properties — such as URLs, source and license information, and confidence scores — and are thus recommended.\r\n\r\n## Systematic mechanisms of efficacy\r\n\r\nOne aim of Project Rephetio was to systematically evaluate how drugs exert their therapeutic potential. To address this question, we compiled a gold standard of 755 disease-modifying indications, which form the _Compound–treats–Disease_ edges in Hetionet v1.0. Next, we identified types of paths (metapaths) that occurred more frequently between treatments than non-treatments (any compound–disease pair that is not a treatment). The advantage of this approach is that metapaths naturally correspond to mechanisms of pharmacological efficacy. For example, the _Compound–binds–Gene–associates–Disease_ (_CbGaD_) metapath identifies when a drug binds  to a protein corresponding to a gene involved in the disease.\r\n\r\nWe evaluated all 1,206 metapaths that traverse from compound to disease and have length of 2–4 ([Figure 2A](#feature_figure)). To control for the different degrees of nodes, we used the degree-weighted path count (_DWPC_) — which downweights paths going through highly-connected nodes [@10.1371/journal.pcbi.1004259] — to assess path prevalence. In addition, we compared the performance of each metapath to a baseline computed from permuted networks. Hetnet permutation preserves node degree while eliminating edge specificity, allowing us to isolate the portion of unpermuted metapath performance resulting from actual network paths. We refer to the permutation-adjusted performance measure as Δ AUROC.\r\n\r\n[:figure](feature_figure)\r\n\r\nOverall, 709 of the 1,206 metapaths exhibited a statistically significant Δ AUROC at a false discovery rate cutoff of 5%. These 709 metapaths included all 24 metaedges, suggesting that each type of relationship we integrated provided at least some therapeutic utility. However, not all metaedges were equally present in significant metapaths: 259 significant metapaths included a _Compound–binds–Gene_ metaedge, whereas only 4 included a _Gene–participates–Cellular Component_ metaedge. [Table 3](#metapath_table) lists the predictiveness of several metapaths of interest. Refer to the [Discussion](#discussion) for our interpretation of these findings.\r\n\r\n[:table](metapath_table)\r\n\r\n## Predictions of drug efficacy\r\n\r\nWe implemented a machine learning approach to translate the network connectivity between a compound and a disease into a probability of treatment [@10.15363/thinklab.d210 @10.5281/zenodo.268654]. The approach relies on the 755 known treatments as positives and 29,044 non-treatments as negatives to train a logistic regression model. The features consisted of a prior probability of treatment, node degrees for 14 metaedges, and DWPCs for 123 metapaths that were well suited for modeling. A cross-validated elastic net was used to minimize overfitting, yielding a model with 31 features ([Figure 2B](#feature_figure)). The DWPC features with negative coefficients appear to be included as node-degree-capturing covariates, i.e. they reflect the general connectivity of the compound and disease rather than specific paths between them. However, the 11 DWPC features with non-negligible positive coefficients represent the most salient types of connectivity for systematically modeling drug efficacy. See the metapaths with positive coefficients in [Table 3](#metapath_table) for unabbreviated names. As an example, the _CcSEcCtD_ feature assesses whether the compound causes the same side effects as compounds that treat the disease. Alternatively, the _CbGeAlD_ feature assesses whether the compound binds to genes that are expressed in the anatomies affected by the disease.\r\n\r\nWe applied this model to predict the probability of treatment between each of 1,538 connected compounds and each of 136 connected diseases, resulting in predictions for 209,168 compound–disease pairs [@10.15363/thinklab.d203], available at http://het.io/repurpose/. The 755 known disease-modifying indications were highly ranked (AUROC = 97.4%, [Figure 3](#performance_figure)). The predictions also successfully prioritized two external validation sets: novel indications from DrugCentral (AUROC = 85.5%) and novel indications in clinical trial (AUROC = 70.0%). Together, these findings indicate that Project Rephetio has the ability to recognize efficacious compound–disease pairs.\r\n\r\n[:figure](performance_figure)\r\n\r\nPredictions were scaled to the overall prevalence of treatments (0.36%). Hence a compound–disease pair that received a prediction of 1% represents a 2-fold enrichment over the null probability. Of the 3,980 predictions with a probability exceeding 1%, 586 corresponded to known disease-modifying indications, leaving 3,394 repurposing candidates. For a given compound or disease, we provide the percentile rank of each prediction. Therefore, users can assess whether a given prediction is a top prediction for the compound or disease. In addition, our table-based prediction browser links to a custom guide for each prediction, which displays in the Neo4j Hetionet Browser. Each guide includes a query to display the top paths supporting the prediction and lists clinical trials investigating the indication.\r\n\r\n### Nicotine dependence case study\r\n\r\nThere are currently two FDA-approved medications for smoking cessation (varenicline and bupropion) that are not nicotine replacement therapies. PharmacotherapyDB v1.0 lists varenicline as a disease-modifying indication and nicotine itself as a symptomatic indication for nicotine dependence, but is missing bupropion. Bupropion was first approved for depression in 1985. Owing to the serendipitous observation that it decreased smoking in depressed patients taking this drug, Bupropion was approved for smoking cessation in 1997 [@10.1093/ntr/nts201]. Therefore we looked whether Project Rephetio could have predicted this repurposing. Bupropion was the 9th best [prediction for nicotine dependence](http://het.io/repurpose/browse.html?id=DOID_0050742 \"Project Rephetio predictions for nicotine dependence (DOID:0050742)\") (99.5th percentile) with a probability 2.50-fold greater than the null. [Figure 4](#bupropion_nicotine_figure) shows the top paths supporting the repurposing of bupropion.\r\n\r\n[:figure](bupropion_nicotine_figure)\r\n\r\nAtop the nicotine dependence predictions were nicotine (10.97-fold over null), cytisine (10.58-fold), and galantamine (9.50-fold). Cytisine is widely used in Eastern Europe for smoking cessation due to its availability at a fraction of the cost of other pharmaceutical options [@10.1002/14651858.CD006103.pub7]. In the last half decade, large scale clinical trials have confirmed cytisine's efficacy [@10.1056/NEJMoa1102035 @10.1056/NEJMoa1407764]. Galantamine, an approved Alzheimer's treatment, is currently in [Phase 2 trial](https://clinicaltrials.gov/ct2/show/NCT01669538 \"Effect of Galantamine on Short-term Abstinence (GAL-K)\") for smoking cessation and is showing promising results [@10.1038/tp.2015.209]. In summary, nicotine dependence illustrates Project Rephetio's ability to predict efficacious treatments and prioritize historic and contemporary repurposing opportunities.\r\n\r\n### Epilepsy case study\r\n\r\nSeveral factors make epilepsy an interesting disease for evaluating repurposing predictions [@10.15363/thinklab.d224]. Antiepileptic drugs work by increasing the seizure threshold — the amount of electric stimulation that is required to induce seizure. The effect of a drug on the seizure threshold can be cheaply and reliably tested in rodent models. As a result, the viability of most approved drugs in treating epilepsy is known.\r\n\r\nWe focused our evaluation on the top 100 scoring compounds — referred to as the epilepsy predictions in this section — after discarding a single combination drug. We classified each compound as anti-ictogenic (seizure suppressing), unknown (no established effect on the seizure threshold), or ictogenic (seizure generating) according to medical literature [@10.15363/thinklab.d224]. Of the top 100 epilepsy predictions, 77 were anti-ictogenic, 8 were unknown, and 15 were ictogenic ([Figure 5A](#epilepsy_figure)). Notably, the predictions contained 23 of the 25 disease-modifying antiepileptics in PharamcotherapyDB v1.0.\r\n\r\n[:figure](epilepsy_figure)\r\n\r\nMany of the 77 anti-ictogenic compounds were not first-line antiepileptic drugs. Instead, they were used as ancillary drugs in the treatment of status epilepticus. For example, we predicted four halogenated ethers, two of which (isoflurane and desflurane) are used clinically to treat life-threatening seizures that persist despite treatment [@10.1001/archneur.61.8.1254]. As inhaled anesthetics, these compounds are not appropriate as daily epilepsy medications, but are feasible for refractory status epilepticus where patients are intubated.\r\n\r\nGiven this high precision (77%), the 8 compounds of unknown effect are promising repurposing candidates. For example, acamprosate — whose top prediction was epilepsy — is a taurine analog that promotes alcohol abstinence. Support for this repurposing arose from acamprosate's inhibition of the glutamate receptor and positive modulation of the GABAᴀ receptor ([Figure 5C](#epilepsy_figure)). If effective against epilepsy, acamprosate could serve a dual benefit for recovering alcoholics who experience seizures from alcohol withdrawal.\r\n\r\nWhile certain classes of compounds were highly represented in our epilepsy predictions, such benzodiazepines and barbiturates, there was also considerable diversity [@10.15363/thinklab.d224]. The 100 predicted compounds encompassed 26 third-level ATC codes [@10.4135/9781483349985.n37], such as antiarrhythmics (quinidine, classified as anti-ictogenic) and urologicals (phenazopyridine, classified as unknown). Furthermore, 25 of the compounds were chemically distinct, i.e. they did not resemble any of the other epilepsy predictions ([Figure 5B](#epilepsy_figure)).\r\n\r\nNext, we investigated which components of Hetionet contributed to the epilepsy predictions [@10.15363/thinklab.d224]. In total, 392,956 paths of 12 types supported the predictions. Using several different methods for grouping paths, we were able to quantify the aggregate biological evidence. Our algorithm primarily drew on two aspects of epilepsy: its known treatments (76% of the total support) and its genetic associations (22% of support). In contrast, our algorithm drew heavily on several aspects of the predicted compounds: their targeted genes (44%), their chemically similar compounds (30%), their pharmacologic classes, their palliative indications (5%), and their side effects (4%).\r\n\r\nSpecifically, 266,192 supporting paths originated with a _Compound–binds–Gene_ relationship. Aggregating support by these genes shows the extent that 121 different drug targets contributed to the predictions [@10.15363/thinklab.d224]. In order of importance, the predictions targeted GABAᴀ receptors (15.3% of total support), cytochrome P450 enzymes (5.6%), the sodium channel (4.6%), glutamate receptors (3.8%), the calcium channel (2.7%), carbonic anhydrases (2.5%), cholinergic receptors (2.1%) and the potassium channel (1.4%). Besides cytochrome P450, which primarily influences pharmacokinetics [@10.2174/157015910792246254], our method detected and leveraged bonafide anti-ictogenic mechanisms [@10.1038/nrn1430]. [Figure 5C](#epilepsy_figure) shows drug target contributions per compound and illustrates the considerable mechanistic diversity among the predictions.\r\n\r\nAlso notable are the 15 ictogenic compounds in our top 100 predictions. Nine of the ictogenic compounds share a tricyclic structure ([Figure 5B](#epilepsy_figure)), five of which are tricyclic antidepressants. While the ictogenic mechanisms of these antidepressants are still unclear [@10.1016/j.yebeh.2016.01.029], [Figure 5C](#epilepsy_figure) suggests their anticholinergic effects may be responsible [@10.15363/thinklab.d231], in accordance with previous theories [@10.1016/s0006-2952(96)00509-6].\r\n\r\nWe also ranked the contribution of the 1,137 side effects that supported the epilepsy predictions through 117,720 _CcSEcCtD_ paths. The top five side effects — ataxia (0.069% of total support), nystagmus (0.049%), diplopia (0.045%), somnolence (0.044%), and vomiting (0.043%) — reflect established adverse effects of antiepileptic drugs [@10.1136/jnnp.2006.100222 @10.1016/j.ebcr.2015.07.003 @10.1016/S1059-1311(03)00082-7 @10.1016/S1388-2457(00)00411-9 @10.1016/j.seizure.2010.12.011]. In summary, our method simultaneously identified the hallmark side effects of antiepileptic drugs while incorporating this knowledge to prioritize 1,538 compounds for anti-ictogenic activity.\r\n\r\n# Discussion\r\n\r\nWe created Hetionet v1.0 by integrating 29 resources into a single data structure — the hetnet. Consisting of 11 types of nodes and 24 types of relationships, Hetionet v1.0 brings more types of information together than previous leading-studies in biological data integration [@10.1098/rsif.2015.0571]. Moreover, we strove to create a reusable, extensible, and property-rich network. While all of the resources we include are publicly available, their integration was a time-intensive undertaking. Hetionet allows researchers to begin answering integrative questions without having to first spend months processing data.\r\n\r\nOur public Neo4j instance allows users to immediately interact with Hetionet. Through the Cypher language, users can perform highly specialized graph queries with only a few lines of code. Queries can be executed in the web browser or programmatically from a language with a Neo4j driver. For users that are unfamiliar with Cypher, we include several example queries in a Browser guide. In contrast to traditional REST APIs, our public Neo4j instance provides users with maximal flexibility to construct custom queries by exposing the underlying database.\r\n\r\nAs data has grown more plentiful and diverse, so has the applicability of hetnets. Unfortunately, network science has been naturally fragmented by discipline resulting in relatively slow progress in integrating heterogeneous data. A 2014 analysis identified 78 studies using multilayer networks — a superset of hetnets with the potential for a time dimension. However, the studies relied on 26 different terms, 9 of which had multiple definitions [@10.1093/comnet/cnu016 @10.15363/thinklab.d104]. Nonetheless, core infrastructure and algorithms for hetnets are emerging. One goal of our project has been to unite hetnet research across disciplines. We approached this goal by making Project Rephetio entirely available online and inviting community feedback throughout the process [@10.15363/thinklab.4].\r\n\r\nIntegrating every resource into a single interconnected data structure allowed us to assess systematic mechanisms of drug efficacy. Using the max performing metapath to assess the pharmacological utility of a metaedge ([Figure 2A](#feature_figure)), we can divide our relationships into tiers of informativeness. The top tier consists of the types of information traditionally considered by pharmacology: _Compound–treats–Disease_, _Pharmacologic Class–includes–Compound_, _Compound–resembles–Compound_, _Disease–resembles–Disease_, and _Compound–binds–Gene_. The upper-middle tier consists of types of information that have been the focus of substantial medical study, but have only recently started to play a bigger role in drug development, namely the metaedges _Disease–associates–Gene_, _Compound–causes–Side Effect_, _Disease–presents–Symptom_, _Disease–localizes–Anatomy_, and _Gene–interacts–Gene_.\r\n\r\nThe lower-middle tier contains the transcriptomics metaedges such as _Compound–downregulates–Gene_, _Anatomy–expresses–Gene_, _Gene→regulates→Gene_, and _Disease–downregulates–Gene_. Much excitement surrounds these resources due to their high throughput and genome-wide scope, which offers a route to drug discovery that is less biased by existing knowledge. However, our findings suggest that these resources are only moderately informative of drug efficacy. Other lower-middle tier metaedges were the product of time-intensive biological experimentation, such as _Gene–participates–Pathway_,  _Gene–participates–Molecular Function_, and _Gene–participates–Biological Process_. Unlike the top tier resources, this knowledge has historically been pursued for basic science rather than primarily medical applications. The weak yet appreciable performance of the _Gene–covaries–Gene_ suggests the synergy between the fields of evolutionary genomics and disease biology. The lower tier included the _Gene–participates–Cellular Component_ metaedge, which may reflect that the relevance of cellular location to pharmacology is highly case dependent and not amenable to systematic profiling.\r\n\r\nThe performance of specific metapaths ([Table 3](#metapath_table)) provides further insight. For example, significant emphasis has been put on the use of transcriptional data for drug repurposing [@10.1016/j.drudis.2012.07.014]. One common approach has been to identify compounds with opposing transcriptional signatures to a disease [@10.1126/scitranslmed.3001318 @10.1016/j.drudis.2012.07.017]. However, several systematic studies report underwhelming performance of this approach [@10.1186/s13073-014-0095-1 @10.1038/msb.2011.26 @10.1038/ncomms10331] — a finding supported by the low performance of the _CuGdD_ and _CdGuD_ metapaths in Project Rephetio. Nonetheless, other transcription-based methods showed some promise. Compounds with similar transcriptional signatures were prone to treating the same disease (_CuGuCtD_ and _CdGdCtD_ metapaths), while compounds with opposing transcriptional signatures were slightly averse to treating the same disease (_CuGdCtD_ and _CdGuCtD_ metapaths). In contrast, diseases with similar transcriptional profiles were not prone to treatment by the same compound (_CtDdGuD_ and _CtDuGdD_).\r\n\r\nBy comparably assessing the informativeness of different metaedges and metapaths, Project Rephetio aims to guide future research towards promising data types and analyses. Encouragingly, most data types were at least weakly informative and hence suitable for further study. Ideally, different data types would provide orthogonal information. However, our model for whether a compound treats a disease focused on 11 metapaths — a small portion of the hundreds of metapaths available. While parsimony aids interpretation, our model did not draw on the weakly-predictive high-throughput data types — which are intriguing for their novelty, scalability, and cost-effectiveness — as much as we had hypothesized.\r\n\r\nInstead our model selected types of information traditionally considered in pharmacology. However unlike a pharmacologist whose area of expertise may be limited to a few drug classes, our model was able to predict probabilities of treatment for all 209,168 compound–disease pairs. Furthermore, our model systematically learned the importance of each type of network connectivity. For any compound–disease pair, we now can immediately provide the top network paths supporting its therapeutic efficacy. A traditional pharmacologist may be able to produce a similar explanation, but likely not until spending substantial time researching the compound's pharmacology, the disease's pathophysiology, and the molecular relationships in between. Accordingly, we hope certain predictions will spur further research, such as trials to investigate the off-label use of acamprosate for epilepsy, which is supported by one animal model [@10.1016/j.physbeh.2008.05.020].\r\n\r\nAs demonstrated by the 15 ictogenic compounds in our top 100 epilepsy predictions, Project Rephetio's predictions can include contraindications in addition to indications. Since many of Hetionet v1.0's relationship types are general (e.g. the _Compound–binds–Gene_ relationship type conflates antagonist with agonist effects), we expect some high scoring predictions to exacerbate rather than treat the disease. However, the predictions made by Hetionet v1.0 represent such substantial relative enrichment over the null that uncovering the correct directionality is a logical next step and worth undertaking. Going forward, advances in automated mining of the scientific literature could enable extraction of precise relationship types at omics scale [@10.1145/2939502.2939515 @10.15363/thinklab.d227].\r\n\r\nFuture research should focus on gleaning orthogonal information from data types that are so expansive that computational methods are the only option. Our _CuGuCtD_ feature — measuring whether a compound upregulates the same genes as compounds which treat the disease — is a good example. This metapath was informative by itself (Δ AUROC = 4.4%) but was not selected by the model, despite its orthogonal origin (gene expression) to selected metapaths. Using a more extensive catalog of treatments as the gold standard would be one possible approach to increase the power of feature selection.\r\n\r\nIntegrating more types of information into Hetionet should also be a future priority. The \"network effect\" phenomenon suggests that the addition of each new piece of information will enhance the value of Hetionet's existing information. We envision a future where all biological knowledge is encoded into a single hetnet. Hetionet v1.0 was an early attempt, and we hope the strong performance of Project Rephetio in repurposing drugs foreshadows the many applications that will thrive from encoding biology in hetnets.\r\n\r\n# Methods\r\n\r\nHetionet was built entirely from publicly available resources with the goal of integrating a broad diversity of information types of medical relevance, ranging in scale from molecular to organismal. Practical considerations such as data availability, licensing, reusability, documentation, throughput, and standardization informed our choice of resources. We abided by a simple litmus test for determining how to encode information in a hetnet: nodes represent nouns, relationships represent verbs [@10.1016/s0169-023x(97)00017-7 @10.15363/thinklab.d162].\r\n\r\nOur method for relationship prediction creates a strong incentive to avoid redundancy, which increases the computational burden without improving performance. In a previous study to predict disease–gene associations using a hetnet of pathophysiology [@10.1371/journal.pcbi.1004259], we found that different types of gene sets contributed highly redundant information. Therefore, in Hetionet v1.0 we reduced the number of gene set node types from 14 to 3 by omitting several gene set collections and aggregating all pathway nodes.\r\n\r\n## Nodes\r\n\r\nNodes encode entities. We extracted nodes from standard terminologies, which provide curated vocabularies to enable data integration and prevent concept duplication. The ease of mapping external vocabularies, adoption, and comprehensiveness were primary selection criteria. Hetionet v1.0 includes nodes from 5 ontologies — which provide hierarchy of entities for a specific domain — selected for their conformity to current best practices [@10.1371/journal.pcbi.1004743].\r\n\r\nWe selected 137 terms from the [Disease Ontology](http://disease-ontology.org/) [@10.1093/nar/gkr972 @10.1093/nar/gku1011] (which we refer to as DO Slim [@10.15363/thinklab.d44 @10.5281/zenodo.45584]) as our disease set. Our goal was to identify complex diseases that are distinct and specific enough to be clinically relevant yet general enough to be well annotated. To this end, we included diseases that have been studied by GWAS and cancer types from `TopNodes_DOcancerslim` [@10.1093/database/bav032]. We ensured that no DO Slim disease was a subtype of another DO Slim disease. Symptoms were extracted from [MeSH](http://www.ncbi.nlm.nih.gov/mesh) by taking the 438 descendants of _Signs and Symptoms_ [@10.15363/thinklab.d67 @10.5281/zenodo.45586].\r\n\r\nApproved small molecule compounds with documented chemical structures were extracted from [DrugBank](http://www.drugbank.ca/) version 4.2 [@10.1093/nar/gkt1068 @10.15363/thinklab.d40 @10.5281/zenodo.45579]. Unapproved compounds were excluded because our focus was repurposing. In addition, unapproved compounds tend to be less studied than approved compounds making them less attractive for our approach where robust network connectivity is critical. Finally, restricting to small molecules with known documented structures enabled us to map between compound vocabularies (see [Mappings](#mappings)).\r\n\r\nSide effects were extracted from [SIDER](http://sideeffects.embl.de/) version 4.1 [@10.1093/nar/gkv1075 @10.15363/thinklab.d97 @10.5281/zenodo.45521]. SIDER codes side effects using [UMLS](https://www.nlm.nih.gov/research/umls/) identifiers [@10.1093/nar/gkh061], which we also adopted. Pharmacologic Classes were extracted from the DrugCentral [data repository](https://github.com/olegursu/drugtarget \"DrugCentral data: olegursu/drugtarget on GitHub\") [@10.1093/nar/gkw993 @10.15363/thinklab.d186].\r\n\r\nProtein-coding human genes were extracted from [Entrez Gene](http://www.ncbi.nlm.nih.gov/gene) [@10.1093/nar/gkq1237 @10.15363/thinklab.d34 @10.5281/zenodo.45524]. Anatomical structures, which we refer to as anatomies, were extracted from [Uberon](http://uberon.org) [@10.1186/gb-2012-13-1-r5]. We selected a subset of 402 Uberon terms by excluding terms known not to exist in humans and terms that were overly broad or arcane [@10.15363/thinklab.d41 @10.5281/zenodo.45527].\r\n\r\nPathways were extracted by combining human pathways from [WikiPathways](http://www.wikipathways.org/) [@10.1093/nar/gkv1024 @10.1371/journal.pbio.0060184], [Reactome](http://www.reactome.org/) [@10.1093/nar/gkv1351], and the [Pathway Interaction Database](http://pid.nci.nih.gov/) [@10.1093/nar/gkn653]. The latter two resources were retrieved from [Pathway Commons](http://www.pathwaycommons.org/pc2/) [@10.1093/nar/gkq1039], which compiles pathways from several providers. Duplicate pathways and pathways without multiple participating genes were removed [@10.15363/thinklab.d72 @10.5281/zenodo.48810]. Biological processes, cellular components, and molecular functions were extracted from the [Gene Ontology](http://geneontology.org/) [@10.1038/75556]. Only terms with 2–1000 annotated genes were included.\r\n\r\n## Mappings\r\n\r\nBefore adding relationships, all identifiers needed to be converted into the vocabularies matching that of our nodes. Oftentimes, our node vocabularies included external mappings. For example, the Disease Ontology includes mappings to MeSH, UMLS, and the ICD, several of which we submitted during the course of this study [@10.15363/thinklab.d68]. In a few cases, the only option was to map using gene symbols, a disfavored method given that it can lead to ambiguities.\r\n\r\nWhen mapping external disease concepts onto DO Slim, we used transitive closure. For example, the UMLS concept for primary progressive multiple sclerosis ([`C0751964`](http://linkedlifedata.com/resource/umls-concept/C0751964)) was mapped to the DO Slim term for multiple sclerosis ([`DOID:2377`](http://purl.obolibrary.org/obo/DOID_2377)).\r\n\r\nChemical vocabularies presented the greatest mapping challenge [@10.15363/thinklab.d40], since these are poorly standardized [@10.1016/j.ddtec.2015.01.005]. UniChem's [@10.1186/1758-2946-5-3] Connectivity Search [@10.1186/s13321-014-0043-5] was used to map compounds, which maps by atomic connectivity (based on First InChIKey Hash Blocks [@10.1186/1758-2946-5-7]) and ignores small molecular differences.\r\n\r\n## Edges\r\n\r\n_Anatomy–downregulates–Gene_ and _Anatomy–upregulates–Gene_ edges [@10.5281/zenodo.47157 @10.15363/thinklab.d124 @10.15363/thinklab.d81] were extracted from  [Bgee](http://bgee.org/) [@10.1007/978-3-540-69828-9_12], which computes differentially expressed genes by anatomy in post-juvenile adult humans. _Anatomy–expresses–Gene_ edges were extracted from Bgee and [TISSUES](http://tissues.jensenlab.org/) [@10.7717/peerj.1054 @10.5281/zenodo.27244 @10.15363/thinklab.d91].\r\n\r\n_Compound–binds–Gene_ edges were aggregated from [BindingDB](https://bindingdb.org) [@10.2174/1386207013330670 @10.1093/nar/gkv1072], [DrugBank](http://www.drugbank.ca/) [@10.1093/nar/gkj067 @10.1093/nar/gkt1068], and [DrugCentral](http://drugcentral.org/) [@10.1093/nar/gkw993]. Only binding relationships to single proteins with affinities of at least 1 μM (as determined by Kd, Kᵢ, or IC₅₀) were selected from the October 2015 release of BindingDB [@10.15363/thinklab.d53 @10.5281/zenodo.33987]. Target, carrier, transporter, and enzyme interactions with single proteins (i.e. excluding protein groups) were extracted from DrugBank 4.2 [@10.15363/thinklab.d65 @10.5281/zenodo.45579]. In addition, all mapping DrugCentral target relationships were included [@10.15363/thinklab.d186].\r\n\r\n_Compound–treats–Disease_ (disease-modifying indications) and _Compound–palliates–Disease_ (symptomatic indications) edges are from PharmacotherapyDB as described in [Intermediate resources](#intermediate-resources). _Compound–causes–Side Effect_ edges were obtained from [SIDER](http://sideeffects.embl.de/) 4.1 [@10.1093/nar/gkv1075 @10.15363/thinklab.d97 @10.5281/zenodo.45521], which uses natural language processing to identify side effects in drug labels. _Compound–resembles–Compound_ relationships [@10.15363/thinklab.d70 @10.5281/zenodo.45579 @10.6084/m9.figshare.1418386] represent chemical similarity and correspond to a Dice coefficient ≥ 0.5 [@10.2307/1932409] between extended connectivity fingerprints [@10.1021/ci100050t @10.1021/c160017a018].  _Compound–downregulates–Gene_ and _Compound–upregulates–Gene_ relationships were computed from LINCS L1000 as described in [Intermediate resources](#intermediate-resources).\r\n\r\n_Disease–associates–Gene_ edges were extracted from the GWAS Catalog [@10.5281/zenodo.48428], DISEASES [@10.15363/thinklab.d106 @10.5281/zenodo.48425], DisGeNET [@10.15363/thinklab.d105 @10.5281/zenodo.48426], and DOAF [@10.15363/thinklab.d94 @10.5281/zenodo.48427]. The [GWAS Catalog](https://www.ebi.ac.uk/gwas/) compiles disease–SNP associations from published GWAS [@10.1093/nar/gkw1133]. We aggregated overlapping loci associated with each disease and identified the mode reported gene for each high confidence locus [@10.15363/thinklab.d80 @10.15363/thinklab.d71]. [DISEASES](http://diseases.jensenlab.org/Search) integrates evidence of association from text mining, curated catalogs, and experimental data [@10.1016/j.ymeth.2014.11.020]. Associations from DISEASES with integrated scores ≥ 2 were included after removing the contribution of DistiLD. [DisGeNET](http://www.disgenet.org) integrates evidence from over 10 sources and reports a single score for each association [@10.1093/database/bav028]. Associations with scores ≥ 0.06 were included. DOAF mines Entrez Gene GeneRIFs (textual annotations of gene function) for disease mentions [@10.1371/journal.pone.0049686]. Associations with 3 or more supporting GeneRIFs were included. _Disease–downregulates–Gene_ and _Disease–upregulates–Gene_ relationships [@10.15363/thinklab.d96 @10.5281/zenodo.46866] were computed using [STARGEO](http://stargeo.org/) as described in [Intermediate resources](#intermediate-resources).\r\n\r\n_Disease–localizes–Anatomy_, _Disease–presents–Symptom_, and _Disease–resembles–Disease_ edges were calculated from MEDLINE co-occurrence [@10.15363/thinklab.d67 @10.5281/zenodo.48445]. MEDLINE is a subset of 21 million PubMed articles for which designated human curators have assigned topics. When retrieving articles for a given topic (MeSH term), we activated two non-default search options as specified below: `majr` for selecting only articles where the topic is major and `noexp` for suppressing explosion (returning articles linked to MeSH subterms). We identified 4,161,769 articles with two or more disease topics; 696,252 articles with both a disease topic (`majr`) and an anatomy topic (`noexp`) [@10.15363/thinklab.d93]; and 363,928 articles with both a disease topic (`majr`) and a symptom topic (`noexp`). We used a Fisher's exact test [@10.2307/2340521] to identify pairs of terms that occurred together more than would be expected by chance in their respective corpus. We included co-occurring terms with _p_ < 0.005 in Hetionet v1.0.\r\n\r\n_Gene–covaries–Gene_ edges represent evolutionary rate covariation ≥ 0.75 [@10.1371/journal.pgen.1004967 @10.15363/thinklab.d57 @10.5281/zenodo.48444]. _Gene–interacts–Gene_ edges [@10.15363/thinklab.d85 @10.5281/zenodo.48443] represent when two genes produce physically-interacting proteins. We compiled these interactions from the Human Interactome Database [@10.1038/nature04209 @10.1038/nmeth.1280 @10.1038/nmeth.1597 @10.1016/j.cell.2014.10.050], the Incomplete Interactome [@10.1126/science.1257601], and our previous study [@10.1371/journal.pcbi.1004259]. _Gene–participates–Biological Process_, _Gene–participates–Cellular Component_, and _Gene–participates–Molecular Function_ edges are from Gene Ontology annotations [@10.1093/nar/gku1113]. As described in [Intermediate resources](#intermediate-resources), annotations were propagated [@10.15363/thinklab.d39 @10.5281/zenodo.21711].\r\n\r\n## Intermediate resources\r\n\r\nIn the process of creating Hetionet, we produced several datasets with broad applicability that extended beyond Project Rephetio. These resources are referred to as intermediate resources and described below.\r\n\r\n### Transcriptional signatures of disease using STARGEO\r\n\r\n[STARGEO](http://stargeo.org/) is a nascent platform for annotating and meta-analyzing differential gene expression experiments. The STAR acronym stands for Search-Tag-Analyze Resources, while GEO refers to the Gene Expression Omnibus [@10.1093/nar/30.1.207 @10.1093/nar/gks1193]. STARGEO is a layer on top of GEO that crowdsources sample annotation and automates meta-analysis.\r\n\r\nUsing STARGEO, we computed differentially expressed genes between healthy and diseased samples for 49 diseases [@10.15363/thinklab.d96 @10.5281/zenodo.46866]. First, we and others created case/control tags for 66 diseases. After combing through GEO series and tagging samples, 49 diseases had sufficient data for case-control meta-analysis: multiple series with at least 3 cases and 3 controls. For each disease, we performed a random effects meta-analysis on each gene to combine log2 fold-change across series. These analyses incorporated 27,019 unique samples from 460 series on 107 platforms.\r\n\r\nDifferentially expressed genes (false discovery rate ≤ 0.05) were identified for each disease. The median number of upregulated genes per disease was 351 and the median number of downregulated genes was 340. Endogenous depression was the only of the 49 diseases without any significantly dysregulated genes.\r\n\r\n### Transcriptional signatures of perturbation from LINCS L1000\r\n\r\n[LINCS L1000](http://www.lincscloud.org/l1000/) profiled the transcriptional response to small molecule and genetic interference perturbations. To increase throughput, expression was only measured for 978 genes, which were selected for their ability to impute expression of the remaining genes. A single perturbation was often assayed under a variety of conditions including cell types, dosages, timepoints, and concentrations. Each condition generates a single signature of dysregulation _z_-scores. We further processed these signatures to fit into our approach [@10.5281/zenodo.47223 @10.6084/m9.figshare.3085837.v1].\r\n\r\nFirst we computed consensus signatures — which meta-analyze multiple signatures to condense them into one — for DrugBank small molecules, Entrez genes, and all L1000 perturbations [@10.15363/thinklab.d43 @10.6084/m9.figshare.3085426.v1]. First, we discarded non-gold (non-replicating or indistinct) signatures. Then we meta-analyzed _z_-scores using Stouffer's method. Each signature was weighted by its average Spearman's correlation to other signatures, with a 0.05 minimum, to de-emphasize discordant signatures. Our signatures include the 978 measured genes and the 6,489 imputed genes from the \"best inferred gene subset\". To identify significantly dysregulated genes, we selected genes using a Bonferroni cutoff of _p_ = 0.05 and limited the number of imputed genes to 1,000.\r\n\r\nThe consensus signatures for genetic perturbations allowed us to assess various characteristics of the L1000 dataset. First, we looked at whether genetic interference dysregulated its target gene in the expected direction [@10.15363/thinklab.d185]. Looking at measured z-scores for target genes, we found that the knockdown perturbations were highly reliable, while the overexpression perturbations were only moderately reliable with 36% of overexpression perturbations downregulating their target. However, imputed z-scores for target genes barely exceeded chance at responding in the expected direction to interference. Hence, we concluded that the imputation quality of LINCS L1000 is poor. However, when restricting to significantly dyseregulated targets, 22 out of 29 imputed genes responded in the expected direction. This provides some evidence that the directional fidelity of imputation is higher for significantly dysregulated genes. Finally, we found that the transcriptional signatures of knocking down and overexpressing the same gene were positively correlated 65% of the time, suggesting the presence of a general stress response [@10.15363/thinklab.d171].\r\n\r\nBased on these findings, we performed additional filtering of signifcantly dysregulated genes when building Hetionet v1.0. _Compound–down/up-regulates–Gene_ relationships were restricted to the 125 most significant per compound-direction-status combination (status refers to measured versus imputed). For genetic interference perturbations, we restricted to the 50 most significant genes per gene-direction-status combination and merged the remaining edges into a single _Gene→regulates→Gene_ relationship type containing both knockdown and overexpression perturbations.\r\n\r\n### PharmacotherapyDB: physician curated indications\r\n\r\nWe created PharmacotherapyDB, an open catalog of drug therapies for disease [@10.15363/thinklab.d182 @10.6084/m9.figshare.3103054 @10.5281/zenodo.47664]. Version 1.0 contains 755 disease-modifying therapies and 390 symptomatic therapies between 97 diseases and 601 compounds.\r\n\r\nThis resource was motivated by the need for a gold standard of medical indications to train and evaluate our approach. Initially, we identified four existing indication catalogs [@10.15363/thinklab.d21]: MEDI-HPS which mined indications from RxNorm, SIDER 2, MedlinePlus, and Wikipedia [@10.1136/amiajnl-2012-001431]; LabeledIn which extracted indications from drug labels via human curation [@10.1016/j.jbi.2014.08.004 @10.1093/database/bav016 @10.15363/thinklab.d46]; EHRLink which identified medication–problem pairs that clinicians linked together in electronic health records [@10.1136/amiajnl-2012-000852 @10.15363/thinklab.d62]; and indications from PREDICT, which were compiled from UMLS relationships, drugs.com, and drug labels [@10.1038/msb.2011.26]. After mapping to DO Slim and DrugBank Slim, the four resources contained 1,388 distinct indications.\r\n\r\nHowever, we noticed that many indications were palliative and hence problematic as a gold standard of pharmacotherapy for our _in silico_ approach. Therefore, we recruited two practicing physicians to curate the 1,388 preliminary indications [@10.15363/thinklab.d95]. After a pilot on 50 indications, we defined three classifications: _disease modifying_ meaning a drug that therapeutically changes the underlying or downstream biology of the disease; _symptomatic_ meaning a drug that treats a significant symptom of the disease; and _non-indication_ meaning a drug that neither therapeutically changes the underlying or downstream biology nor treats a significant symptom of the disease. Both curators independently classified all 1,388 indications.\r\n\r\nThe two curators disagreed on 444 calls (Cohen's κ = 49.9%). We then recruited a third practicing physician, who reviewed all 1,388 calls and created a detailed explanation of his methodology [@10.15363/thinklab.d95]. We proceeded with the third curator's calls as the consensus curation. The first two curators did have reservations with classifying steroids as disease modifying for autoimmune diseases. We ultimately considered that these indications met our definition of disease modifying, which is based on a pathophysiological rather than clinical standard. Accordingly, therapies we consider disease modifying may not be used to alter long-term disease course in the modern clinic due to a poor risk–benefit ratio.\r\n\r\n### User-friendly Gene Ontology annotations\r\n\r\nWe created a browser (http://git.dhimmel.com/gene-ontology/) to provide straightforward access to Gene Ontology annotations [@10.5281/zenodo.21711 @10.15363/thinklab.d39]. Our service provides annotations between Gene Ontology terms and Entrez Genes. The user chooses propagated/direct annotation and all/experimental evidence. Annotations are currently available for 37 species and downloadable as user-friendly TSV files.\r\n\r\n## Data copyright and licensing\r\n\r\nWe committed to openly releasing our data and analyses from the origin of the project [@10.15363/thinklab.d23]. Our goals were to contribute to the advancement of science [@10.1629/2431 @10.1371/journal.pbio.1001195], maximize our impact [@10.7554/eLife.16800 @10.7717/peerj.175], and enable reproducibility [@10.1126/science.aah6168 @10.5334/jors.ay @10.1038/467401b]. These objectives required publicly distributing and openly licensing Hetionet and Project Rephetio data and analyses [@10.1186/1756-0500-5-494 @10.3897/zookeys.150.2189].\r\n\r\nSince we integrated only public resources, which were overwhelmingly funded by academic grants, we had assumed that our project and open sharing of our network would not be an issue. However, upon releasing a preliminary version of Hetionet [@10.15363/thinklab.d102], a community reviewer informed us of legal barriers to integrating public data. In essence, both copyright (rights of exclusivity automatically granted to original works) and terms of use (rules that users must agree to in order to use a resource) place legally-binding restrictions on data reuse. In short, public data is not by default open data.\r\n\r\nHetionet v1.0 integrates 29 resources, but two resources were removed prior to the v1.0 release. Of the total [31 resources](https://github.com/dhimmel/integrate/blob/725f4e4b4a737cfb15abe55ef36386c23e1c4f1f/licenses/README.md \"Source license table on GitHub\") [@10.15363/thinklab.d107], five were United States government works not subject to copyright, and twelve had licenses that met the [Open Definition](http://opendefinition.org/od/2.1/en/) of knowledge version 2.1. Four resources allowed only non-commercial reuse. Most problematic were the remaining nine resources that had no license — which equates to all rights reserved by default and forbids reuse [@10.1038/536016a] — and one resource that explicitly forbid redistribution.\r\n\r\nAdditional difficulty resulted from license incompatibles across resources, which was caused primarily by non-commercial and share-alike stipulations. Furthermore, it was often unclear who owned the data [@10.1087/0953151053584984]. Therefore, we sought input from legal experts and chronicled our progress [@10.15363/thinklab.d107 @10.15363/thinklab.d108 @10.15363/thinklab.d111 @10.15363/thinklab.d110 @10.15363/thinklab.d213].\r\n\r\nUltimately, we did not find an ideal solution. We had to choose between absolute compliance and Hetionet: strictly adhering to copyright and licensing arrangements would have decimated the network. On the other hand, in the United States, mere facts are not subject to copyright, and fair use doctrine helps protect reuse that is transformative and educational. Hence, we choose a path forward which balanced legal, normative, ethical, and scientific considerations.\r\n\r\nIf a resource was in the public domain, we licensed any derivatives as CC0 1.0. For resources licensed to allow reuse, redistribution, and modification, we transmitted their licenses as properties on the specific nodes and relationships in Hetionet v1.0. For all other resources — for example, resources without licenses or with licenses that forbid redistribution — we sent permission requests to their creators. The median time till first response to our permission requests was 16 days, with only 2 resources affirmatively granting us permission. We did not receive any responses asking us to remove a resource. However, we did voluntarily remove MSigDB [@10.1093/bioinformatics/btr260], since its license was highly problematic [@10.15363/thinklab.d108]. As a result of our experience, we recommend that publicly-funded data should be explicitly dedicated to the public domain whenever possible.\r\n\r\n\r\n## Permuted Hetnets\r\n\r\nFrom Hetionet, we derived five permuted hetnets [@10.15363/thinklab.d178]. The permutations preserve node degree but eliminate edge specificity by employing an algorithm called XSwap to randomly swap edges [@10.1137/1.9781611972795.67]. Permuted networks are useful for computing the baseline performance of meaningless edges while preserving node degree [@10.15363/thinklab.d136].\r\n\r\n## Neo4j\r\n\r\nGraph database adoption in bioinformatics has thus far been limited [@10.1093/bioinformatics/btt549]. We used the Neo4j graph database for storing and operating on Hetionet and noticed major benefits from tapping into this large open source ecosystem [@10.15363/thinklab.d112]. Persistent storage with immediate access and the Cypher query language — a sort of SQL for hetnets — were two of the biggest benefits. To facilitate our migration to Neo4j, we updated [`hetio`](https://github.com/dhimmel/hetio \"dhimmel/hetio on GitHub\") — our existing Python package for hetnets [@10.5281/zenodo.61571] — to export networks into Neo4j and DWPC queries to Cypher. In addition, we created an [interactive GraphGist](http://portal.graphgist.org/graph_gists/drug-repurposing-by-hetnet-relationship-prediction-a-new-hope \"Neo4j GraphGist: Drug repurposing by hetnet relationship prediction\") for Project Rephetio, which introduces our approach and showcases its Cypher queries. Finally, we created a [public Neo4j instance](https://neo4j.het.io \"Hetionet Neo4j Browser\") [@10.15363/thinklab.d216], which leverages several modern technologies such Neo4j Browser guides, cloud hosting with HTTPS, and Docker deployment [@10.1186/s13742-015-0087-0 @10.1101/056473].\r\n\r\n## Machine learning approach\r\n\r\nWe made several refinements to metapath-based hetnet edge prediction compared to previous studies [@10.1371/journal.pcbi.1004259 @10.1109/ASONAM.2011.112]. First, we transformed DWPCs by mean scaling and then taking the inverse hyperbolic sine [@10.2307/2288929] to make them more amenable to modeling [@10.15363/thinklab.d193]. Second, we bifurcated the workflow into an all-features stage and an all-observations stage [@10.15363/thinklab.d210]. The all-features stage assesses feature performance and does not require computing features for all negatives. Here we selected a random subset of 3,020 (4 × 755) negatives. Little error was introduced by this optimization, since the predominant limitation to performance assessment was the small number of positives (755) rather than negatives. Based on the all-features performance assessment [@10.15363/thinklab.d115], we selected 142 DWPCs to compute on all observations (all 209,168 compound–disease pairs). The feature selection was designed to remove uninformative features (according to permutation) and guard against edge-dropout contamination [@10.15363/thinklab.d215]. Third, we included 14 degree features, which assess the degree of a specific metaedge for either the source compound or target disease.\r\n\r\n### Network support of predictions\r\n\r\nTo improve the interpretability of the predictions, we developed a method for decomposing a prediction into its network support [@10.15363/thinklab.d229]. This information is deployed to our Neo4j Browser guides, allowing users to assess the biomedical evidence contributing to a given prediction. First, we used logistic regression terms to quantify the contribution of metapaths that positively support a prediction. Second, we decomposed a metapath's contribution, according to its DWPC, into specific paths contributions. Finally, we aggregated paths based on their source (first) or target (last) edge to quantify the contribution of specific edges of the source compound or target disease [@10.15363/thinklab.d228].\r\n\r\nUsing the [acamprosate–epilepsy prediction](https://neo4j.het.io/browser/?cmd=play&arg=https://neo4j.het.io/guides/rep/DB00659/DOID_1826.html \"Hetionet Neo4j Browser with the network evidence that acamprosate treats epilepsy syndrome\") as an example, we first quantified metapath contributions: 40% of the prediction was supported by _CbGbCtD_ paths, 36% by _CbGaD_ paths, 11% by _CcSEcCtD_ paths, 8% by _CbGpPWpGaD_ paths, and 5% by _CbGeAlD_ paths. Second, we calculated path contributions: _Acamprosate–binds–GRM5–associates–epilepsy syndrome_ was the most supportive path, contributing 11% of the prediction. Finally, we aggregated path contributions to calculate that the source edge of _Acamprosate—binds—GRM5_ contributed 23% of the prediction, while the target edge of _epilepsy syndrome–treats–Felbamate_ contributed 12%.\r\n\r\n### Prior probability of treatment\r\n\r\nThe 755 treatments in Hetionet v1.0 are not evenly distributed between all compounds and diseases. For example, methotrexate treats 19 diseases and hypertension is treated by 68 compounds. We estimated a prior probability of treatment — based only on the treatment degree of the source compound and target disease — on 744,975 permutations of the bipartite treatment network [@10.15363/thinklab.d201]. Methotrexate received a 79.6% prior probability of treating hypertension, whereas a compound and disease that both had only one treatment received a prior of 0.12%.\r\n\r\nAcross the 209,168 compound–disease pairs, the prior predicted the known treatments with AUROC = 97.9%. The strength of this association threatened to dominate our predictions. However, not modeling the prior can lead to omitted-variable bias and confounded proxy variables. To address the issue, we included the logit-transformed prior, without any regularization, as a term in the model. This restricted model fitting to the 29,799 observations with a nonzero prior — corresponding to the 387 compounds and 77 diseases with at least one treatment. To enable predictions for all 209,168 observations, we set the prior for each compound–disease pair to the overall prevalence of positives (0.36%).\r\n\r\nThis method succeeded at accommodating the treatment degrees. The prior probabilities performed poorly on the validation sets with AUROC = 54.1% on DrugCentral indications and AUROC = 62.5% on clinical trials. This performance dropoff compared to training shows the danger of encoding treatment degree into predictions. The benefits of our solution are highlighted by the superior validation performance of our predictions compared to the prior ([Figure 3](#performance_figure)).\r\n\r\n## Indication sets\r\n\r\nWe evaluated our predictions on four sets of indications as shown in [Figure 3](#performance_figure).\r\n\r\n+ **Disease Modifying** — the 755 disease modifying treatments in PharmacotherapyDB v1.0. These indications are included in the hetnet as _treats_ edges and used to train the logistic regression model. Due to edge dropout contamination and self-testing [@10.15363/thinklab.d215 @10.15363/thinklab.d194], overfitting could potentially inflate performance on this set. Therefore, for the three remaining indication sets, we removed any observations that were positives in this set.\r\n+ **DrugCentral** — We discovered the [DrugCentral database](https://github.com/olegursu/drugtarget) after completing our physician curation for PharmacotherapyDB. This database contained 210 additional indications [@10.15363/thinklab.d186]. While we didn't curate these indications, we observed a high proportion of disease modifying therapy.\r\n+ **Clinical Trial** — We compiled indications that have been investigated by clinical trial from [ClinicalTrials.gov](https://clinicaltrials.gov/) [@10.15363/thinklab.d212]. This set contains 5,594 indications. Since these indications were not manually curated and clinical trials often show a lack of efficacy, we expected lower performance on this set.\r\n+ **Symptomatic** — 390 symptomatic indications from PharacotherapyDB. These edges are included in the hetnet as _palliates_ edges.\r\n\r\nOnly the Clinical Trial and DrugCentral indication sets were used for external validation, since the Disease Modifying and Symptomatic indications were included in the hetnet.\r\n\r\n## Realtime open science & Thinklab\r\n\r\nWe conducted our study using Thinklab — a platform for realtime open collaborative science — on which this study was the first project. We began the study by publicly proposing the idea and inviting discussion [@10.15363/thinklab.a5]. We continued by chronicling our progress via discussions. We used Thinklab as the frontend to coordinate and report our analyses and GitHub as the backend to host our code, data, and notebooks. On top of our Thinklab team consisting of core contributors, we welcomed community contribution and review. In areas where our expertise was lacking or advice would be helpful, we sought input from domain experts and encouraged them to respond on Thinklab where their comments would be CC BY licensed and their contribution rated and rewarded.\r\n\r\nIn total, 40 non-team members commented across 86 discussions, which generated 607 comments and 190 notes ([Figure 6](#contribution_figure)). Thinklab content for this project totaled 143,056 words or 901,672 characters [@10.15363/thinklab.d200]. Using an estimated 7,000 words per academic publication as a benchmark, Project Rephetio generated written content comparable in volume to 20.4 publications prior to its completion. We noticed several other benefits from using Thinklab including forging a community of contributors [@10.1242/dmm.003285]; receiving feedback during the early stages when feedback was most actionable [@10.3897/rio.1.e7547]; disseminating our research without delay [@10.1038/530148a @10.1073/pnas.1511912112]; opening avenues for external input [@10.1038/530027a]; facilitating problem-oriented teaching [@10.15363/thinklab.d181 @10.1038/523272a]; and improving our documentation by maintaining a publication-grade digital lab notebook [@10.1038/481430a].\r\n\r\n[:figure](contribution_figure)\r\n\r\n# Acknowledgements\r\n\r\nWe are immensely grateful to our [Thinklab contributors](https://thinklab.com/p/rephetio/leaderboard \"Rephetio Project Thinklab Leaderboard\") who joined us in our experiment of radically open science. The following non-team members provided contributions that received 5 or more Thinklab points: Lars Juhl Jensen, Frederic Bastian, Alexander Pico, Casey Greene, Benjamin Good, Craig Knox, Mike Gilson, Chris Mungall, Katie Fortney, Venkat Malladi, Tudor Oprea, MacKenzie Smith, Caty Chung, Allison McCoy, Alexey Strokach, Ritu Khare, Greg Way, Marina Sirota, Raghavendran Partha, Oleg Ursu, Jesse Spaulding, Gaya Nadarajan, Alex Ratner, Scooter Morris, Alessandro Didonna, Alex Pankov, Tong Shu Li, and Janet Piñero. Additionally, the founder of Thinklab, Jesse Spaulding, supported community contributions and developed the platform with Project Rephetio's needs in mind. Finally, we would like to thank Neo Technology, whose staff provided excellent technical support.\r\n\r\nThis material is based upon work supported by the National Science Foundation Graduate Research Fellowship under Grant No. 1144247 to DSH. SEB is supported by the Heidrich Family and Friends Foundation.",
      "doc_published": "2016-11-14T04:59:23.821057Z",
      "document_id": 7,
      "doi": "10.15363/thinklab.a7",
      "intro_html": "<p>Welcome to the report describing Project Rephetio and Hetionet v1.0. The formal title of this study is <em><strong>Systematic integration of biomedical knowledge prioritizes drugs for repurposing</strong></em>. The shortDOI for this project is <a href=\"https://doi.org/bszr\">https://doi.org/bszr</a>. It's also available as a <a href=\"http://biorxiv.org/content/early/2016/11/14/087619\" title=\"Project Rephetio Preprint on bioRxiv: Systematic integration of biomedical knowledge prioritizes drugs for repurposing\">preprint on bioRxiv</a> <span class=\"citation\">[<a href=\"/doi/10.1101/087619\" class=\"citation\" data-key=\"10.1101/087619\">1</a>]</span>.</p>",
      "intro_md": "Welcome to the report describing Project Rephetio and Hetionet v1.0. The formal title of this study is _**Systematic integration of biomedical knowledge prioritizes drugs for repurposing**_. The shortDOI for this project is https://doi.org/bszr. It's also available as a [preprint on bioRxiv](http://biorxiv.org/content/early/2016/11/14/087619 \"Project Rephetio Preprint on bioRxiv: Systematic integration of biomedical knowledge prioritizes drugs for repurposing\") [@10.1101/087619].",
      "title": "",
      "topic_field": "",
      "url": "/p/rephetio/report",
      "views": 829
    },
    {
      "body_html": "<h1>Project components</h1>\r\n\r\n<h2>Hetnets</h2>\r\n\r\n<p>Hetnets are networks with multiple node and edge types <span class=\"citation\">[<a href=\"/discussion/renaming-heterogeneous-networks-to-a-more-concise-and-catchy-term/104\" class=\"citation\" data-key=\"10.15363/thinklab.d104\">1</a>]</span>. Hetnets excel at data integration and are a versatile and intuitive data structure. While specific incarnations of hetnets have long existed, such as bipartite or property graphs, general algorithms that accommodate the multiple types are a recent development <span class=\"citation\">[<a href=\"https://doi.org/10.2200/S00433ED1V01Y201207DMK005\" class=\"citation\" data-key=\"10.2200/S00433ED1V01Y201207DMK005\">2</a>]</span>. Our research tries to predict edges on hetnets, using an algorithm originally developed for social network analysis <span class=\"citation\">[<a href=\"https://doi.org/10.1109/ASONAM.2011.112\" class=\"citation\" data-key=\"10.1109/ASONAM.2011.112\">3</a>]</span>. Previously, we predicted disease–gene associations <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004259\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1004259\">4</a>]</span>. Here, we predict repurposing drugs.</p>\r\n\r\n<h2>Network construction</h2>\r\n\r\n<p>We've constructed a state of the art hetnet for drug repurposing called <a href=\"https://github.com/dhimmel/hetionet\">Hetionet</a>. The network contains 47,031 nodes of 11 types and 2,250,197 edges of 24 types. The schema is shown in the metagraph below:</p>\r\n\r\n<p><img src=\"https://github.com/dhimmel/rephetio/blob/103054a2bc3f86998fed6cb3753d1ecdb5cbe1e7/figure/metagraph.png?raw=true\" alt=\"\"></p>\r\n\r\n<p>Nodes are identified using standardized terminologies to facilitate integration and prevent duplication. Edges are integrated from high-throughput databases, which were chosen for their quality, reusability, throughput, and relevance to pharmacology. We thank the community for <a href=\"http://thinklab.com/d/22\">helping us</a> identify the most appropriate resources.</p>\r\n\r\n<p>In general, we've dedicated a single GitHub repository to each resource. Versioning is accomplished using commit specific URLs. We expect several of these repositories to be helpful outside of this project. Examples include our analysis of LINCS L1000 <span class=\"citation\">[<a href=\"/discussion/computing-consensus-transcriptional-profiles-for-lincs-l1000-perturbations/43\" class=\"citation\" data-key=\"10.15363/thinklab.d43\">5</a>]</span>.</p>\r\n\r\n<h2>Indications catalog</h2>\r\n\r\n<p>Our approach requires a catalog of indications (compound–diseases treatments) for training and testing. Unfortunately, there was no open and structured catalog of indications, so we <a href=\"http://thinklab.com/d/21#21\">created our own</a> by combining four resources. We are <a href=\"http://thinklab.com/d/95\">now having physicians</a> curate the automated compilation to separate disease-modifying indications from symptomatic and non indications.</p>\r\n\r\n<h2>Neo4j</h2>\r\n\r\n<p>We use neo4j to store and operate on our hetnet <span class=\"citation\">[<a href=\"/discussion/using-the-neo4j-graph-database-for-hetnets/112\" class=\"citation\" data-key=\"10.15363/thinklab.d112\">6</a>]</span>. Neo4j is a powerful graph database. In addition our <a href=\"https://github.com/dhimmel/hetio\">hetio</a> python package provides an additional layer of functionality. Our project has led to the first public examples of duplicate node exclusion <span class=\"citation\">[<a href=\"/discussion/path-exclusion-conditions/134\" class=\"citation\" data-key=\"10.15363/thinklab.d134\">7</a>]</span> and network permutation <span class=\"citation\">[<a href=\"/discussion/permuting-hetnets-and-implementing-randomized-edge-swaps-in-cypher/136\" class=\"citation\" data-key=\"10.15363/thinklab.d136\">8</a>]</span> in the cypher query language.</p>\r\n\r\n<h2>Open science</h2>\r\n\r\n<p>We're <a href=\"http://thinklab.com/d/23\">committed</a> to making this project as useful to the community as possible. Therefore, the project is entirely open notebook. We strive to share all outputs upon their creation, under permissive open licenses such as CC0 or CC-BY. Furthermore, we have devoted considerable effort to handling data copyright complications <span class=\"citation\">[<a href=\"/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107\" class=\"citation\" data-key=\"10.15363/thinklab.d107\">9</a>]</span>. Much of this effort has been to save our downstream users the hassle. In other words, were we not compiling an open resource our legal burden would have been much diminished.</p>\r\n\r\n<h2>Mechanisms of efficacy</h2>\r\n\r\n<p>Stay tuned for our investigation into which data sources are informative of drug efficacy.</p>\r\n\r\n<h2>Drug repurposing predictions</h2>\r\n\r\n<p>Stay tuned for our predictions of the probability that a given small molecule treats a given complex disease.</p>",
      "body_md": "# Project components\r\n\r\n## Hetnets\r\n\r\nHetnets are networks with multiple node and edge types [@10.15363/thinklab.d104]. Hetnets excel at data integration and are a versatile and intuitive data structure. While specific incarnations of hetnets have long existed, such as bipartite or property graphs, general algorithms that accommodate the multiple types are a recent development [@10.2200/S00433ED1V01Y201207DMK005]. Our research tries to predict edges on hetnets, using an algorithm originally developed for social network analysis [@10.1109/ASONAM.2011.112]. Previously, we predicted disease--gene associations [@10.1371/journal.pcbi.1004259]. Here, we predict repurposing drugs.\r\n\r\n## Network construction\r\n\r\nWe've constructed a state of the art hetnet for drug repurposing called [Hetionet](https://github.com/dhimmel/hetionet). The network contains 47,031 nodes of 11 types and 2,250,197 edges of 24 types. The schema is shown in the metagraph below:\r\n\r\n![](https://github.com/dhimmel/rephetio/blob/103054a2bc3f86998fed6cb3753d1ecdb5cbe1e7/figure/metagraph.png?raw=true)\r\n\r\nNodes are identified using standardized terminologies to facilitate integration and prevent duplication. Edges are integrated from high-throughput databases, which were chosen for their quality, reusability, throughput, and relevance to pharmacology. We thank the community for [helping us](http://thinklab.com/d/22) identify the most appropriate resources.\r\n\r\nIn general, we've dedicated a single GitHub repository to each resource. Versioning is accomplished using commit specific URLs. We expect several of these repositories to be helpful outside of this project. Examples include our analysis of LINCS L1000 [@10.15363/thinklab.d43].\r\n\r\n## Indications catalog\r\n\r\nOur approach requires a catalog of indications (compound--diseases treatments) for training and testing. Unfortunately, there was no open and structured catalog of indications, so we [created our own](http://thinklab.com/d/21#21) by combining four resources. We are [now having physicians](http://thinklab.com/d/95) curate the automated compilation to separate disease-modifying indications from symptomatic and non indications.\r\n\r\n## Neo4j\r\n\r\nWe use neo4j to store and operate on our hetnet [@10.15363/thinklab.d112]. Neo4j is a powerful graph database. In addition our [hetio](https://github.com/dhimmel/hetio) python package provides an additional layer of functionality. Our project has led to the first public examples of duplicate node exclusion [@10.15363/thinklab.d134] and network permutation [@10.15363/thinklab.d136] in the cypher query language.\r\n\r\n## Open science\r\n\r\nWe're [committed](http://thinklab.com/d/23) to making this project as useful to the community as possible. Therefore, the project is entirely open notebook. We strive to share all outputs upon their creation, under permissive open licenses such as CC0 or CC-BY. Furthermore, we have devoted considerable effort to handling data copyright complications [@10.15363/thinklab.d107]. Much of this effort has been to save our downstream users the hassle. In other words, were we not compiling an open resource our legal burden would have been much diminished.\r\n\r\n## Mechanisms of efficacy\r\n\r\nStay tuned for our investigation into which data sources are informative of drug efficacy.\r\n\r\n## Drug repurposing predictions\r\n\r\nStay tuned for our predictions of the probability that a given small molecule treats a given complex disease.",
      "doc_published": "2016-01-06T02:39:22.551877Z",
      "document_id": 9,
      "doi": "10.15363/thinklab.a9",
      "intro_html": "",
      "intro_md": "",
      "title": "",
      "topic_field": "",
      "url": "/p/rephetio",
      "views": 1
    }
  ],
  "notes": [
    {
      "added": "2015-01-23T05:05:37.375664Z",
      "body_html": "<p>I don't see the \"attached reference\". Can you link to it or add a citation? Check out the <a href=\"http://thinklab.com/help/writing-in-markdown\">markdown syntax</a> offered by ThinkLab.</p>",
      "body_md": "I don't see the \"attached reference\". Can you link to it or add a citation? Check out the [markdown syntax](http://thinklab.com/help/writing-in-markdown) offered by ThinkLab.",
      "comment_id": 38,
      "note_id": 15,
      "profile_id": 17,
      "url": "/discussion/seeking-an-open-source-implementation-of-the-gerstein-sonnhammer-chothia-algorithm/25#note-15"
    },
    {
      "added": "2015-01-23T19:27:36.905732Z",
      "body_html": "<p>I'm talking about the reference you provided, whose <a href=\"https://pdf.yt/d/Sx3jMbr8vANgxAej/download\">link</a> is in the code.</p>",
      "body_md": "I'm talking about the reference you provided, whose [link](https://pdf.yt/d/Sx3jMbr8vANgxAej/download) is in the code.",
      "comment_id": 38,
      "note_id": 21,
      "profile_id": 23,
      "url": "/discussion/seeking-an-open-source-implementation-of-the-gerstein-sonnhammer-chothia-algorithm/25#note-21"
    },
    {
      "added": "2015-01-25T17:28:47.470401Z",
      "body_html": "<p>Okay, I made some code organization and documentation changes. My first github fork and <a href=\"https://github.com/antoine-lizee/R-GSC/pull/1\">pull request</a> (:</p>",
      "body_md": "Okay, I made some code organization and documentation changes. My first github fork and [pull request](https://github.com/antoine-lizee/R-GSC/pull/1) (:",
      "comment_id": 45,
      "note_id": 26,
      "profile_id": 17,
      "url": "/discussion/seeking-an-open-source-implementation-of-the-gerstein-sonnhammer-chothia-algorithm/25#note-26"
    },
    {
      "added": "2015-01-26T23:18:48.088353Z",
      "body_html": "<p>Sorry, I saw your request too late to make a merge efficient, but I implemented your small formal changes that improve readability. Thanks!</p>",
      "body_md": "Sorry, I saw your request too late to make a merge efficient, but I implemented your small formal changes that improve readability. Thanks!",
      "comment_id": 45,
      "note_id": 30,
      "profile_id": 23,
      "url": "/discussion/seeking-an-open-source-implementation-of-the-gerstein-sonnhammer-chothia-algorithm/25#note-30"
    },
    {
      "added": "2015-02-11T03:49:38.622777Z",
      "body_html": "<p>It seems appropriate that some of these things be put in the research plan. For example, that you plan to follow the 10 rules of reproducible computational research.</p>",
      "body_md": "It seems appropriate that some of these things be put in the research plan. For example, that you plan to follow the 10 rules of reproducible computational research.",
      "comment_id": 49,
      "note_id": 31,
      "profile_id": 2,
      "url": "/discussion/enabling-reproducibility-and-reuse/23#note-31"
    },
    {
      "added": "2015-02-17T00:28:30.913847Z",
      "body_html": "<span><strong>markdown error</strong>: <a href=\"/u/jspauld\" class=\"username\">@jspauld</a>, give me my bold! See SPL-X bullet.</span>",
      "body_md": "**markdown error**: @jspauld, give me my bold! See SPL-X bullet.",
      "comment_id": 29,
      "note_id": 32,
      "profile_id": 17,
      "url": "/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#note-32"
    },
    {
      "added": "2015-02-17T00:57:39.879533Z",
      "body_html": "<p>Yep, will fix.</p>",
      "body_md": "Yep, will fix.",
      "comment_id": 29,
      "note_id": 33,
      "profile_id": 2,
      "url": "/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#note-33"
    },
    {
      "added": "2015-02-17T13:52:36.308343Z",
      "body_html": "<p>Thanks! For things that require significant cluster usage I haven't yet found a cost effective way to do this either outside of a grant from one of the cloud providers. I wonder if you could apply to amazon or google for access to compute instances for this purpose.</p>",
      "body_md": "Thanks! For things that require significant cluster usage I haven't yet found a cost effective way to do this either outside of a grant from one of the cloud providers. I wonder if you could apply to amazon or google for access to compute instances for this purpose.",
      "comment_id": 57,
      "note_id": 38,
      "profile_id": 22,
      "url": "/discussion/enabling-reproducibility-and-reuse/23#note-38"
    },
    {
      "added": "2015-02-27T22:53:29.690324Z",
      "body_html": "<p>The authors do not plan on releasing the resource-specific indication data for the current MEDI database. However, they will consider doing so for future releases.</p>",
      "body_md": "The authors do not plan on releasing the resource-specific indication data for the current MEDI database. However, they will consider doing so for future releases.",
      "comment_id": 63,
      "note_id": 54,
      "profile_id": 17,
      "url": "/discussion/medi-indications-data-discrepancy-in-resource-specific-counts/31#note-54"
    },
    {
      "added": "2015-03-18T22:52:13.592863Z",
      "body_html": "<span><a href=\"/u/b_good\" class=\"username\">@b_good</a>, thanks for the suggestion. I am excited about any venues where we can publish the data to increase its reuse. Once we complete the data integration stage, I will touch base with you — it's still not entirely clear to me what exactly we would upload.</span>",
      "body_md": "@b_good, thanks for the suggestion. I am excited about any venues where we can publish the data to increase its reuse. Once we complete the data integration stage, I will touch base with you -- it's still not entirely clear to me what exactly we would upload.",
      "comment_id": 82,
      "note_id": 57,
      "profile_id": 17,
      "url": "/discussion/enabling-reproducibility-and-reuse/23#note-57"
    },
    {
      "added": "2015-03-19T23:42:23.213598Z",
      "body_html": "<p>Here's a <a href=\"http://thinklab.com/discussion/tissue-node/41\">link to the new discussion</a> (Venkat, it might be a good idea to edit your post to add this link)</p>",
      "body_md": "Here's a [link to the new discussion](http://thinklab.com/discussion/tissue-node/41) (Venkat, it might be a good idea to edit your post to add this link)",
      "comment_id": 85,
      "note_id": 58,
      "profile_id": 2,
      "url": "/discussion/suggestions-for-additional-information-types/22#note-58"
    },
    {
      "added": "2015-03-20T02:37:46.580338Z",
      "body_html": "<span><a href=\"/u/vsmalladi\" class=\"username\">@vsmalladi</a>, you may consider switching the associated publication to the Uberon paper <span class=\"citation\">[<a href=\"https://doi.org/10.1186/gb-2012-13-1-r5\" class=\"citation\" data-key=\"10.1186/gb-2012-13-1-r5\">1</a>]</span> and move the ENCODE use-case paper <span class=\"citation\">[<a href=\"https://doi.org/10.1093/database/bav010\" class=\"citation\" data-key=\"10.1093/database/bav010\">2</a>]</span> as an <a href=\"http://thinklab.com/help/writing-in-markdown\">inline citation</a>.</span>",
      "body_md": "@vsmalladi, you may consider switching the associated publication to the Uberon paper [@10.1186/gb-2012-13-1-r5] and move the ENCODE use-case paper [@10.1093/database/bav010] as an [inline citation](http://thinklab.com/help/writing-in-markdown).",
      "comment_id": 84,
      "note_id": 59,
      "profile_id": 17,
      "url": "/discussion/tissue-node/41#note-59"
    },
    {
      "added": "2015-03-20T02:38:37.568436Z",
      "body_html": "<span><a href=\"/u/jspauld\" class=\"username\">@jspauld</a>, see the citation display failure in the previous note.</span>",
      "body_md": "@jspauld, see the citation display failure in the previous note.",
      "comment_id": 84,
      "note_id": 60,
      "profile_id": 17,
      "url": "/discussion/tissue-node/41#note-60"
    },
    {
      "added": "2015-03-20T04:07:52.432555Z",
      "body_html": "<span><a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a> Yeah, the inline citations don't work in the notes right now. I suspect it will be rare that people will try to use them in notes given that most of the substantive conversation is intended to take place in comments. So, for the time being I think I'll wait and see how much demand there will be. [<strong>Edit:</strong> After speaking with <a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a> offline he has convinced me this was a bug. Inline note citations now work!]</span>",
      "body_md": "@dhimmel Yeah, the inline citations don't work in the notes right now. I suspect it will be rare that people will try to use them in notes given that most of the substantive conversation is intended to take place in comments. So, for the time being I think I'll wait and see how much demand there will be. [**Edit:** After speaking with @dhimmel offline he has convinced me this was a bug. Inline note citations now work!]",
      "comment_id": 84,
      "note_id": 61,
      "profile_id": 2,
      "url": "/discussion/tissue-node/41#note-61"
    },
    {
      "added": "2015-03-20T04:09:55.058400Z",
      "body_html": "<p>In support of the semantic web, you should check out ThinkLab's awesome <a href=\"http://thinklab.com/help/writing-in-markdown\">markdown syntax</a>, which includes easy citation and hyperlink capabilities.</p>",
      "body_md": "In support of the semantic web, you should check out ThinkLab's awesome [markdown syntax](http://thinklab.com/help/writing-in-markdown), which includes easy citation and hyperlink capabilities.",
      "comment_id": 83,
      "note_id": 62,
      "profile_id": 17,
      "url": "/discussion/enabling-reproducibility-and-reuse/23#note-62"
    },
    {
      "added": "2015-03-20T04:11:01.433966Z",
      "body_html": "<p>With regard to the associated publication — at the present moment this cannot be changed by the user. <a href=\"/u/vsmalladi\" class=\"username\">@vsmalladi</a>, if you agree it makes sense to change it please just let me know and I'll take care of it.</p>",
      "body_md": "With regard to the associated publication -- at the present moment this cannot be changed by the user. @vsmalladi, if you agree it makes sense to change it please just let me know and I'll take care of it.",
      "comment_id": 84,
      "note_id": 63,
      "profile_id": 2,
      "url": "/discussion/tissue-node/41#note-63"
    },
    {
      "added": "2015-03-20T04:48:01.252427Z",
      "body_html": "<span><a href=\"/u/jspauld\" class=\"username\">@jspauld</a> yes please update the citation</span>",
      "body_md": "@jspauld yes please update the citation",
      "comment_id": 84,
      "note_id": 64,
      "profile_id": 35,
      "url": "/discussion/tissue-node/41#note-64"
    },
    {
      "added": "2015-03-20T05:47:50.995793Z",
      "body_html": "<p>Updated. If you'd like to do an inline citation to the original DOI you were referencing just insert the following in your markdown: <code>[@10.1093/database/bav010]</code></p>",
      "body_md": "Updated. If you'd like to do an inline citation to the original DOI you were referencing just insert the following in your markdown: `[@10.1093/database/bav010]`",
      "comment_id": 84,
      "note_id": 66,
      "profile_id": 2,
      "url": "/discussion/tissue-node/41#note-66"
    },
    {
      "added": "2015-03-20T06:31:04.885382Z",
      "body_html": "<p>FYI, it looks like you mentioned the wrong person here. I'm assuming you meant <a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a> .. Any idea how that happened?</p>",
      "body_md": "FYI, it looks like you mentioned the wrong person here. I'm assuming you meant @dhimmel .. Any idea how that happened?",
      "comment_id": 88,
      "note_id": 67,
      "profile_id": 2,
      "url": "/discussion/tissue-node/41#note-67"
    },
    {
      "added": "2015-03-20T15:39:36.836092Z",
      "body_html": "<span><a href=\"/u/jspauld\" class=\"username\">@jspauld</a> I believe this was just user error. </span>",
      "body_md": "@jspauld I believe this was just user error. ",
      "comment_id": 88,
      "note_id": 68,
      "profile_id": 35,
      "url": "/discussion/tissue-node/41#note-68"
    },
    {
      "added": "2015-03-29T19:04:10.713623Z",
      "body_html": "<p>Saw this paper <span class=\"citation\">[<a href=\"https://doi.org/10.1371/journal.pcbi.1004068\" class=\"citation\" data-key=\"10.1371/journal.pcbi.1004068\">1</a>]</span> which explores when disease/compound expression profiles are reliable therapeutic indicators, specifically with regards to lung cancer.</p>",
      "body_md": "Saw this paper [@10.1371/journal.pcbi.1004068] which explores when disease/compound expression profiles are reliable therapeutic indicators, specifically with regards to lung cancer.",
      "comment_id": 93,
      "note_id": 69,
      "profile_id": 17,
      "url": "/discussion/computing-consensus-transcriptional-profiles-for-lincs-l1000-perturbations/43#note-69"
    },
    {
      "added": "2015-04-02T01:20:01.294752Z",
      "body_html": "<p>The markdown error has been fixed.</p>",
      "body_md": "The markdown error has been fixed.",
      "comment_id": 29,
      "note_id": 71,
      "profile_id": 2,
      "url": "/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#note-71"
    },
    {
      "added": "2015-04-02T21:47:12.107325Z",
      "body_html": "<p>For future reference it's probably better to wait until you have more to say here before you post this. The project's followers probably don't need to know what you are planning to post here (until you actually post it!) What do you think? And yes, 'draft mode' is coming soon!</p>",
      "body_md": "For future reference it's probably better to wait until you have more to say here before you post this. The project's followers probably don't need to know what you are planning to post here (until you actually post it!) What do you think? And yes, 'draft mode' is coming soon!",
      "comment_id": 97,
      "note_id": 75,
      "profile_id": 2,
      "url": "/discussion/processing-labeledin-to-extract-indications/46#note-75"
    },
    {
      "added": "2015-04-02T21:59:36.572209Z",
      "body_html": "<p>Hey Jesse, I was making a stub because one project member may be interested in posting and I thought this would simplify the process.</p>",
      "body_md": "Hey Jesse, I was making a stub because one project member may be interested in posting and I thought this would simplify the process.",
      "comment_id": 97,
      "note_id": 76,
      "profile_id": 17,
      "url": "/discussion/processing-labeledin-to-extract-indications/46#note-76"
    },
    {
      "added": "2015-04-02T22:05:48.541871Z",
      "body_html": "<p>Oh alright, carry on then :)</p>",
      "body_md": "Oh alright, carry on then :)",
      "comment_id": 97,
      "note_id": 77,
      "profile_id": 2,
      "url": "/discussion/processing-labeledin-to-extract-indications/46#note-77"
    },
    {
      "added": "2015-04-03T05:28:22.756037Z",
      "body_html": "<p>Ah.. guessing this is the reason behind <a href=\"http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21\" target=\"_blank\">http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21</a> </p>",
      "body_md": "Ah.. guessing this is the reason behind http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21 ",
      "comment_id": 99,
      "note_id": 78,
      "profile_id": 48,
      "url": "/discussion/evaluation-framework/47#note-78"
    },
    {
      "added": "2015-04-03T18:01:46.261151Z",
      "body_html": "<span><a href=\"/u/ritukhare\" class=\"username\">@ritukhare</a>, if you have a readily-available and exhaustive mapping of ingredient and disease identifiers to names, I could update my analysis with those names.</span>",
      "body_md": "@ritukhare, if you have a readily-available and exhaustive mapping of ingredient and disease identifiers to names, I could update my analysis with those names.",
      "comment_id": 103,
      "note_id": 79,
      "profile_id": 17,
      "url": "/discussion/processing-labeledin-to-extract-indications/46#note-79"
    },
    {
      "added": "2015-04-08T02:11:06.726415Z",
      "body_html": "<p>Added the reference to my initial post. Given the quality issues, I do not plan to include this resource in our gold standard set of indications. It could be helpful later as a literature-derived set of <em>potential</em> indications.</p>",
      "body_md": "Added the reference to my initial post. Given the quality issues, I do not plan to include this resource in our gold standard set of indications. It could be helpful later as a literature-derived set of *potential* indications.",
      "comment_id": 110,
      "note_id": 82,
      "profile_id": 17,
      "url": "/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#note-82"
    },
    {
      "added": "2015-04-09T01:30:54.293110Z",
      "body_html": "<p>+1 for grant agencies to fund this type of activity</p>",
      "body_md": "+1 for grant agencies to fund this type of activity",
      "comment_id": 115,
      "note_id": 83,
      "profile_id": 17,
      "url": "/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#note-83"
    },
    {
      "added": "2015-04-09T02:27:27.578532Z",
      "body_html": "<p>Thanks for the clarification. We also plan to perform some indication propagation on the Disease Ontology hierarchy.</p>",
      "body_md": "Thanks for the clarification. We also plan to perform some indication propagation on the Disease Ontology hierarchy.",
      "comment_id": 128,
      "note_id": 84,
      "profile_id": 17,
      "url": "/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#note-84"
    },
    {
      "added": "2015-04-21T20:03:30.075789Z",
      "body_html": "<p>The 'notebook' link is broken here</p>",
      "body_md": "The 'notebook' link is broken here",
      "comment_id": 148,
      "note_id": 87,
      "profile_id": 2,
      "url": "/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#note-87"
    },
    {
      "added": "2015-04-21T20:50:45.888240Z",
      "body_html": "<p>Fixed, thanks</p>",
      "body_md": "Fixed, thanks",
      "comment_id": 148,
      "note_id": 88,
      "profile_id": 17,
      "url": "/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#note-88"
    },
    {
      "added": "2015-05-01T22:06:14.259531Z",
      "body_html": "<p>Looks like this is all term type definitions across the entire UMLS.</p>",
      "body_md": "Looks like this is all term type definitions across the entire UMLS.",
      "comment_id": 183,
      "note_id": 96,
      "profile_id": 17,
      "url": "/discussion/retrieving-the-ingredients-in-rxnorm-concepts/61#note-96"
    },
    {
      "added": "2015-05-01T22:27:00.760636Z",
      "body_html": "<p>Awesome, you have set the train in motion for us to include ehrlink indications. Let's move discussion to <a href=\"http://thinklab.com/discussion/extracting-indications-from-the-ehrlink-resource/62\">this new thread specifically for ehrlink analysis</a>.</p>",
      "body_md": "Awesome, you have set the train in motion for us to include ehrlink indications. Let's move discussion to [this new thread specifically for ehrlink analysis](http://thinklab.com/discussion/extracting-indications-from-the-ehrlink-resource/62).",
      "comment_id": 169,
      "note_id": 97,
      "profile_id": 17,
      "url": "/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#note-97"
    },
    {
      "added": "2015-05-02T20:23:23.972725Z",
      "body_html": "<p>Correct - that is why I thought it could be a useful ressource to share.</p>",
      "body_md": "Correct - that is why I thought it could be a useful ressource to share.",
      "comment_id": 183,
      "note_id": 98,
      "profile_id": 23,
      "url": "/discussion/retrieving-the-ingredients-in-rxnorm-concepts/61#note-98"
    },
    {
      "added": "2015-05-03T20:54:14.123111Z",
      "body_html": "<p>As a side-note, I removed all the row name columns in the csvs, because it was annoying for display in github. You might have to change slightly your code to understand the new format.</p>",
      "body_md": "As a side-note, I removed all the row name columns in the csvs, because it was annoying for display in github. You might have to change slightly your code to understand the new format.",
      "comment_id": 185,
      "note_id": 99,
      "profile_id": 23,
      "url": "/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#note-99"
    },
    {
      "added": "2015-05-03T20:57:42.872674Z",
      "body_html": "<p>You might want to update #7 with my latest results from <a href=\"http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#185\">#6</a></p>",
      "body_md": "You might want to update #7 with my latest results from [#6](http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#185)",
      "comment_id": 181,
      "note_id": 100,
      "profile_id": 23,
      "url": "/discussion/extracting-indications-from-the-ehrlink-resource/62#note-100"
    },
    {
      "added": "2015-05-04T19:19:49.666061Z",
      "body_html": "<p>For reference, <a href=\"/u/alizee\" class=\"username\">@alizee</a> <a href=\"https://github.com/antoine-lizee/RRxNorm/blob/master/RxNorm2.R#L67\">used</a> the following term type priority list (high to low):</p>\n\n<p><code>SCD</code>, <code>SBD</code>, <code>SCDF</code>, <code>SBDF</code>, <code>BN</code>, <code>SCDC</code>, <code>SBDC</code>, <code>IN</code>, <code>MIN</code>, <code>PIN</code>, <code>GPCK</code>, <code>BPCK</code>, <code>SCDG</code>, <code>SBDG</code>, <code>DF</code>, <code>DFG</code></p>",
      "body_md": "For reference, @alizee [used](https://github.com/antoine-lizee/RRxNorm/blob/master/RxNorm2.R#L67) the following term type priority list (high to low):\n\n`SCD`, `SBD`, `SCDF`, `SBDF`, `BN`, `SCDC`, `SBDC`, `IN`, `MIN`, `PIN`, `GPCK`, `BPCK`, `SCDG`, `SBDG`, `DF`, `DFG`",
      "comment_id": 185,
      "note_id": 103,
      "profile_id": 17,
      "url": "/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#note-103"
    },
    {
      "added": "2015-05-08T19:45:18.976113Z",
      "body_html": "<p>I should add that the full text search is basically a last ditch effort to find genes w/o any matching identifiers in the structured databases. We use this on the description and alias field, as well as all of the cross reference IDs. We use elasticsearch via django-haystack to power this. It's pretty easy to set this up on AWS or locally. We previously used solr, but the configuration headache didn't outweigh the benefits.</p>",
      "body_md": "I should add that the full text search is basically a last ditch effort to find genes w/o any matching identifiers in the structured databases. We use this on the description and alias field, as well as all of the cross reference IDs. We use elasticsearch via django-haystack to power this. It's pretty easy to set this up on AWS or locally. We previously used solr, but the configuration headache didn't outweigh the benefits.",
      "comment_id": 208,
      "note_id": 113,
      "profile_id": 22,
      "url": "/discussion/using-entrez-gene-as-our-gene-vocabulary/34#note-113"
    },
    {
      "added": "2015-05-10T18:49:08.949801Z",
      "body_html": "<p>A common source of detailed variation between compounds is stereochemistry. See <a href=\"https://youtu.be/457xnJv80O0\">this video</a> for an introduction and <a href=\"//www.ncbi.nlm.nih.gov/pmc/articles/PMC353039/\">this paper</a> <span class=\"citation\">[<a href=\"https://doi.org/10.4088/pcc.v05n0202\" class=\"citation\" data-key=\"10.4088/pcc.v05n0202\">1</a>]</span> for the relevance of stereochemistry in pharmacology.</p>",
      "body_md": "A common source of detailed variation between compounds is stereochemistry. See [this video](https://youtu.be/457xnJv80O0) for an introduction and [this paper](//www.ncbi.nlm.nih.gov/pmc/articles/PMC353039/) [@10.4088/pcc.v05n0202] for the relevance of stereochemistry in pharmacology.",
      "comment_id": 78,
      "note_id": 114,
      "profile_id": 17,
      "url": "/discussion/unifying-drug-vocabularies/40#note-114"
    },
    {
      "added": "2015-05-13T20:19:22.125336Z",
      "body_html": "<p>Elvira Mitraka <a href=\"http://sourceforge.net/p/diseaseontology/feature-requests/75/#5304\">added these cross-references</a> to revision 2815.</p>",
      "body_md": "Elvira Mitraka [added these cross-references](http://sourceforge.net/p/diseaseontology/feature-requests/75/#5304) to revision 2815.",
      "comment_id": 219,
      "note_id": 115,
      "profile_id": 17,
      "url": "/discussion/disease-ontology-feature-requests/68#note-115"
    },
    {
      "added": "2015-05-13T20:20:56.580678Z",
      "body_html": "<p>Elvira Mitraka <a href=\"http://sourceforge.net/p/diseaseontology/feature-requests/77/#a1e0\">fixed these typos and inconsistencies</a> in revision 2815.</p>",
      "body_md": "Elvira Mitraka [fixed these typos and inconsistencies](http://sourceforge.net/p/diseaseontology/feature-requests/77/#a1e0) in revision 2815.",
      "comment_id": 220,
      "note_id": 116,
      "profile_id": 17,
      "url": "/discussion/disease-ontology-feature-requests/68#note-116"
    },
    {
      "added": "2015-05-13T20:21:42.950370Z",
      "body_html": "<p>Elvira Mitraka <a href=\"//sourceforge.net/p/diseaseontology/feature-requests/76/#04c8\">added these cross-references</a> to revision 2815.</p>",
      "body_md": "Elvira Mitraka [added these cross-references](//sourceforge.net/p/diseaseontology/feature-requests/76/#04c8) to revision 2815.",
      "comment_id": 221,
      "note_id": 117,
      "profile_id": 17,
      "url": "/discussion/disease-ontology-feature-requests/68#note-117"
    },
    {
      "added": "2015-05-19T02:40:56.552657Z",
      "body_html": "<p>See this <a href=\"https://raw.githubusercontent.com/dhimmel/medline/2a427d37c4174e492873e2387c9b1d51236a4f7b/data/disease-symptom-cooccurrence.tsv\">newer symptom–disease pair tsv file</a> which has <a href=\"https://github.com/dhimmel/medline/commit/2a427d37c4174e492873e2387c9b1d51236a4f7b?diff=unified#diff-3417fe5acc9338308981e0e58eca0f11\">additional</a> DO slim diseases with MeSH mappings. </p>",
      "body_md": "See this [newer symptom–disease pair tsv file](https://raw.githubusercontent.com/dhimmel/medline/2a427d37c4174e492873e2387c9b1d51236a4f7b/data/disease-symptom-cooccurrence.tsv) which has [additional](https://github.com/dhimmel/medline/commit/2a427d37c4174e492873e2387c9b1d51236a4f7b?diff=unified#diff-3417fe5acc9338308981e0e58eca0f11) DO slim diseases with MeSH mappings. ",
      "comment_id": 224,
      "note_id": 123,
      "profile_id": 17,
      "url": "/discussion/mining-knowledge-from-medline-articles-and-their-indexed-mesh-terms/67#note-123"
    },
    {
      "added": "2015-05-28T00:07:51.486503Z",
      "body_html": "<a href=\"/u/allisonmccoy\" class=\"username\">@allisonmccoy</a>, thanks for following up and congratulations on your paper <span class=\"citation\">[<a href=\"https://doi.org/10.4338/ACI-2015-01-RA-0010\" class=\"citation\" data-key=\"10.4338/ACI-2015-01-RA-0010\">1</a>]</span>. I read the abstract, but could you <a href=\"mailto:daniel.himmelstein@gmail.com\">email me</a> the pdf?\n\n<p>Enjoy the travels, we would definitely appreciate the data!</p>",
      "body_md": "@allisonmccoy, thanks for following up and congratulations on your paper [@10.4338/ACI-2015-01-RA-0010]. I read the abstract, but could you [email me](mailto:daniel.himmelstein@gmail.com) the pdf?\n\nEnjoy the travels, we would definitely appreciate the data!",
      "comment_id": 236,
      "note_id": 124,
      "profile_id": 17,
      "url": "/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#note-124"
    },
    {
      "added": "2015-06-12T17:22:48.072707Z",
      "body_html": "<p>2015-06-12: I reassessed the implications of the centimorgan versus kilobase window span correlation. My current conclusion is that a single centimorgan threshold cannot be chosen that produces similar windows to the <em>r</em>-squared method.</p>",
      "body_md": "2015-06-12: I reassessed the implications of the centimorgan versus kilobase window span correlation. My current conclusion is that a single centimorgan threshold cannot be chosen that produces similar windows to the *r*-squared method.",
      "comment_id": 254,
      "note_id": 125,
      "profile_id": 17,
      "url": "/discussion/calculating-genomic-windows-for-gwas-lead-snps/71#note-125"
    },
    {
      "added": "2015-06-19T15:13:07.277483Z",
      "body_html": "<p>What does SRA stand for?</p>",
      "body_md": "What does SRA stand for?",
      "comment_id": 283,
      "note_id": 130,
      "profile_id": 17,
      "url": "/discussion/processing-gtex-for-tissue-specific-gene-expression/82#note-130"
    },
    {
      "added": "2015-06-19T15:24:56.910197Z",
      "body_html": "<p>Sequence Read Archive (http://www.ncbi.nlm.nih.gov/sra). This is where we usually download the raw data from. But I think GTEx keep them private, for their \"on demand\" data sharing policy...</p>",
      "body_md": "Sequence Read Archive (http://www.ncbi.nlm.nih.gov/sra). This is where we usually download the raw data from. But I think GTEx keep them private, for their \"on demand\" data sharing policy...",
      "comment_id": 283,
      "note_id": 131,
      "profile_id": 111,
      "url": "/discussion/processing-gtex-for-tissue-specific-gene-expression/82#note-131"
    },
    {
      "added": "2015-06-19T23:32:57.683419Z",
      "body_html": "<p>My mistake regarding \"transcript abundance\" — we actually only care about gene abundance.</p>",
      "body_md": "My mistake regarding \"transcript abundance\" -- we actually only care about gene abundance.",
      "comment_id": 284,
      "note_id": 132,
      "profile_id": 17,
      "url": "/discussion/tissue-specific-gene-expression-resources/81#note-132"
    },
    {
      "added": "2015-06-20T01:06:56.926835Z",
      "body_html": "<span><a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a>: OK, it should fit your needs then. Let me know if you have any other question.</span>",
      "body_md": "@dhimmel: OK, it should fit your needs then. Let me know if you have any other question.",
      "comment_id": 284,
      "note_id": 133,
      "profile_id": 111,
      "url": "/discussion/tissue-specific-gene-expression-resources/81#note-133"
    },
    {
      "added": "2015-06-20T22:30:37.369980Z",
      "body_html": "<p>Links are broken</p>",
      "body_md": "Links are broken",
      "comment_id": 287,
      "note_id": 134,
      "profile_id": 17,
      "url": "/discussion/tissue-node/41#note-134"
    },
    {
      "added": "2015-06-26T23:25:24.504790Z",
      "body_html": "<p>Thanks <a href=\"/u/akolow\" class=\"username\">@akolow</a>! Let us know if you experience any problems or have suggestions.</p>",
      "body_md": "Thanks @akolow! Let us know if you experience any problems or have suggestions.",
      "comment_id": 301,
      "note_id": 135,
      "profile_id": 17,
      "url": "/discussion/python-for-the-modern-biodata-scientist/84#note-135"
    },
    {
      "added": "2015-06-29T04:07:20.652862Z",
      "body_html": "<p>Much appreciated. Thanks!</p>",
      "body_md": "Much appreciated. Thanks!",
      "comment_id": 304,
      "note_id": 136,
      "profile_id": 17,
      "url": "/discussion/adding-pathway-resources-to-your-network/72#note-136"
    },
    {
      "added": "2015-08-09T04:06:47.324939Z",
      "body_html": "<p>No, the right person to contact is Michael Kuhn.</p>",
      "body_md": "No, the right person to contact is Michael Kuhn.",
      "comment_id": 368,
      "note_id": 140,
      "profile_id": 125,
      "url": "/discussion/extracting-side-effects-from-sider-4/97#note-140"
    },
    {
      "added": "2015-08-09T04:12:25.999935Z",
      "body_html": "<p>Please note that using only the experiments channel will not eliminate knowledge biases. In particular, the immunohistochemical staining data from the Human Protein Atlas are heavily biased, since it depends strongly on the number and quality of antibodies available for each protein. </p>",
      "body_md": "Please note that using only the experiments channel will not eliminate knowledge biases. In particular, the immunohistochemical staining data from the Human Protein Atlas are heavily biased, since it depends strongly on the number and quality of antibodies available for each protein. ",
      "comment_id": 366,
      "note_id": 141,
      "profile_id": 125,
      "url": "/discussion/the-tissues-resource-for-the-tissue-specificity-of-genes/91#note-141"
    },
    {
      "added": "2015-08-09T20:18:38.535913Z",
      "body_html": "<p>In <code>human_tissue_integrated_full.tsv</code> I treated <code>HPA</code> as referring to HPA-IHC. Is this correct?</p>",
      "body_md": "In `human_tissue_integrated_full.tsv` I treated `HPA` as referring to HPA-IHC. Is this correct?",
      "comment_id": 372,
      "note_id": 142,
      "profile_id": 17,
      "url": "/discussion/the-tissues-resource-for-the-tissue-specificity-of-genes/91#note-142"
    },
    {
      "added": "2015-08-10T04:11:26.832146Z",
      "body_html": "<p>If you meant experiments instead of integrated in that filename, then yes.</p>",
      "body_md": "If you meant experiments instead of integrated in that filename, then yes.",
      "comment_id": 372,
      "note_id": 143,
      "profile_id": 125,
      "url": "/discussion/the-tissues-resource-for-the-tissue-specificity-of-genes/91#note-143"
    },
    {
      "added": "2015-08-11T05:55:36.726672Z",
      "body_html": "<p>I contacted Michael Kuhn. <code>label_mapping.tsv.gz</code> was not essential and was removed. Documentation was added to the README for <code>meddra_all_indications.tsv.gz</code>.</p>",
      "body_md": "I contacted Michael Kuhn. `label_mapping.tsv.gz` was not essential and was removed. Documentation was added to the README for `meddra_all_indications.tsv.gz`.",
      "comment_id": 368,
      "note_id": 147,
      "profile_id": 17,
      "url": "/discussion/extracting-side-effects-from-sider-4/97#note-147"
    },
    {
      "added": "2015-08-12T16:48:08.890975Z",
      "body_html": "<p>Yes, I meant <code>human_tissue_experiments_full.tsv.gz</code>.</p>",
      "body_md": "Yes, I meant `human_tissue_experiments_full.tsv.gz`.",
      "comment_id": 372,
      "note_id": 150,
      "profile_id": 17,
      "url": "/discussion/the-tissues-resource-for-the-tissue-specificity-of-genes/91#note-150"
    },
    {
      "added": "2015-08-12T18:12:56.111600Z",
      "body_html": "<p>Your study alludes that it includes <a href=\"https://dx.doi.org/10.1038/ncomms5074#ref51\">citation 51</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1038/nature01156\" class=\"citation\" data-key=\"10.1038/nature01156\">1</a>]</span> as a human interactome dataset. I don't think we'll include this study as it's old and doesn't seem to be a PPI database.</p>",
      "body_md": "Your study alludes that it includes [citation 51](https://dx.doi.org/10.1038/ncomms5074#ref51) [@10.1038/nature01156] as a human interactome dataset. I don't think we'll include this study as it's old and doesn't seem to be a PPI database.",
      "comment_id": 336,
      "note_id": 151,
      "profile_id": 17,
      "url": "/discussion/creating-a-catalog-of-protein-interactions/85#note-151"
    },
    {
      "added": "2015-08-16T07:39:18.514235Z",
      "body_html": "<p>I forgot to mention explicitly that this obviously means that you cannot distribute your network file on GitHub under the CC0 waiver as you currently do.</p>",
      "body_md": "I forgot to mention explicitly that this obviously means that you cannot distribute your network file on GitHub under the CC0 waiver as you currently do.",
      "comment_id": 397,
      "note_id": 152,
      "profile_id": 125,
      "url": "/discussion/one-network-to-rule-them-all/102#note-152"
    },
    {
      "added": "2015-08-16T07:48:48.752425Z",
      "body_html": "<p>Redistribution of LINCS data is also problematic, unless you contacted them and got permission to do so (http://www.lincscloud.org/license/).</p>",
      "body_md": "Redistribution of LINCS data is also problematic, unless you contacted them and got permission to do so (http://www.lincscloud.org/license/).",
      "comment_id": 397,
      "note_id": 153,
      "profile_id": 125,
      "url": "/discussion/one-network-to-rule-them-all/102#note-153"
    },
    {
      "added": "2015-08-16T08:21:11.712548Z",
      "body_html": "<p>Okay, I will look into the copyright issues and make any necessary modifications. I like the idea of including source and license fields for each node and edge. My understanding is that CC licenses prior to 4.0 <a href=\"https://wiki.creativecommons.org/wiki/Data\">do not restrict</a> the underlying data when used in the United States. However, I will need to do more reading and solicit the advice of copyright experts.</p>",
      "body_md": "Okay, I will look into the copyright issues and make any necessary modifications. I like the idea of including source and license fields for each node and edge. My understanding is that CC licenses prior to 4.0 [do not restrict](https://wiki.creativecommons.org/wiki/Data) the underlying data when used in the United States. However, I will need to do more reading and solicit the advice of copyright experts.",
      "comment_id": 397,
      "note_id": 154,
      "profile_id": 17,
      "url": "/discussion/one-network-to-rule-them-all/102#note-154"
    },
    {
      "added": "2015-08-16T08:27:17.366674Z",
      "body_html": "<p>I updated the <a href=\"https://github.com/dhimmel/integrate/blob/950f26ddff83e17fa6e398e7ae66179d8b2638e3/LICENSE.md\">repository license</a> until we clarify these issues.</p>",
      "body_md": "I updated the [repository license](https://github.com/dhimmel/integrate/blob/950f26ddff83e17fa6e398e7ae66179d8b2638e3/LICENSE.md) until we clarify these issues.",
      "comment_id": 397,
      "note_id": 155,
      "profile_id": 17,
      "url": "/discussion/one-network-to-rule-them-all/102#note-155"
    },
    {
      "added": "2015-08-16T08:27:28.794088Z",
      "body_html": "<p>CC licenses prior to 4.0 were not very well suited for data. I only just noticed that the new SIDER still uses the old license, which I think should be changed. Not to make it more restrictive, but simply because the 4.0 license addresses a problem in the earlier license (i.e. the attribution stacking problem).</p>",
      "body_md": "CC licenses prior to 4.0 were not very well suited for data. I only just noticed that the new SIDER still uses the old license, which I think should be changed. Not to make it more restrictive, but simply because the 4.0 license addresses a problem in the earlier license (i.e. the attribution stacking problem).",
      "comment_id": 397,
      "note_id": 156,
      "profile_id": 125,
      "url": "/discussion/one-network-to-rule-them-all/102#note-156"
    },
    {
      "added": "2015-08-16T08:39:27.607342Z",
      "body_html": "<p>Unfortunately, as far as I know, it is not sufficient to consider US law when you distribute data to the whole world. Although the US does not have sui generis database right, other parts of the world do, including the EU. This means that databases created in the EU are protected by such laws. (Caveat: I am not a lawyer, this does not constitute legal advice, yada yada yada.)</p>",
      "body_md": "Unfortunately, as far as I know, it is not sufficient to consider US law when you distribute data to the whole world. Although the US does not have sui generis database right, other parts of the world do, including the EU. This means that databases created in the EU are protected by such laws. (Caveat: I am not a lawyer, this does not constitute legal advice, yada yada yada.)",
      "comment_id": 397,
      "note_id": 157,
      "profile_id": 125,
      "url": "/discussion/one-network-to-rule-them-all/102#note-157"
    },
    {
      "added": "2015-08-17T07:33:53.127174Z",
      "body_html": "<p>I think that for gene-disease associations you should check DisGeNET (www.disgenet.org). I would start by checking the disease list that you already have and query DisGeNET with it. Currently, DisGeNET may be searched using MeSH, OMIMs, and UMLS CUIs. You can download the data in tab files.</p>",
      "body_md": "I think that for gene-disease associations you should check DisGeNET (www.disgenet.org). I would start by checking the disease list that you already have and query DisGeNET with it. Currently, DisGeNET may be searched using MeSH, OMIMs, and UMLS CUIs. You can download the data in tab files.",
      "comment_id": 346,
      "note_id": 159,
      "profile_id": 129,
      "url": "/discussion/suggestions-for-additional-information-types/22#note-159"
    },
    {
      "added": "2015-08-18T03:56:41.965372Z",
      "body_html": "<p><a href=\"/u/janispi\" class=\"username\">@janispi</a>, thanks for the suggestion. We've <a href=\"http://thinklab.com/discussion/processing-disgenet-for-disease-gene-relationships/105\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d105\">begun</a> adding DisGeNET.</p>",
      "body_md": "@janispi, thanks for the suggestion. We've [begun](http://thinklab.com/discussion/processing-disgenet-for-disease-gene-relationships/105) adding DisGeNET.",
      "comment_id": 346,
      "note_id": 160,
      "profile_id": 17,
      "url": "/discussion/suggestions-for-additional-information-types/22#note-160"
    },
    {
      "added": "2015-08-19T09:03:54.261042Z",
      "body_html": "<p>you are absolutely right, I have removed the tar the files, and now I just gzip them. </p>",
      "body_md": "you are absolutely right, I have removed the tar the files, and now I just gzip them. ",
      "comment_id": 404,
      "note_id": 161,
      "profile_id": 129,
      "url": "/discussion/processing-disgenet-for-disease-gene-relationships/105#note-161"
    },
    {
      "added": "2015-08-19T09:19:03.563143Z",
      "body_html": "<p>I was waiting for this question. All GDAs have score &gt; 0. <br>If you choose score &gt;= 0.06, then you will be including associations reporting by curated sources, or having animal models supporting them, or being reported by several papers (20 -200). It will not be permissive, though (less than 10% of GDAs satisfies this criteria). MAybe you could start with this score, and see how it goes. </p>",
      "body_md": "I was waiting for this question. All GDAs have score > 0. \nIf you choose score >= 0.06, then you will be including associations reporting by curated sources, or having animal models supporting them, or being reported by several papers (20 -200). It will not be permissive, though (less than 10% of GDAs satisfies this criteria). MAybe you could start with this score, and see how it goes. ",
      "comment_id": 405,
      "note_id": 162,
      "profile_id": 129,
      "url": "/discussion/processing-disgenet-for-disease-gene-relationships/105#note-162"
    },
    {
      "added": "2015-08-19T18:26:50.742635Z",
      "body_html": "<p>I am not able to resolve <a href=\"http://dev.stargeo.org/\">http://dev.stargeo.org/</a></p>",
      "body_md": "I am not able to resolve http://dev.stargeo.org/",
      "comment_id": 410,
      "note_id": 163,
      "profile_id": 17,
      "url": "/discussion/stargeo-expression-signatures-for-disease-using-crowdsourced-geo-annotation/96#note-163"
    },
    {
      "added": "2015-08-19T18:33:23.335413Z",
      "body_html": "<p>Make that: <a href=\"http://dev.stargeo.io\">http://dev.stargeo.io</a>. But not live quite yet.  I'll get an update tonight on the UI.  Current only working from command line, but at least its working :)</p>",
      "body_md": "Make that: http://dev.stargeo.io. But not live quite yet.  I'll get an update tonight on the UI.  Current only working from command line, but at least its working :)",
      "comment_id": 410,
      "note_id": 164,
      "profile_id": 121,
      "url": "/discussion/stargeo-expression-signatures-for-disease-using-crowdsourced-geo-annotation/96#note-164"
    },
    {
      "added": "2015-08-19T18:55:47.985376Z",
      "body_html": "<p>Okay, I'll switch the hyperlinks on Thinklab over to <a href=\"http://dev.stargeo.io/\">http://dev.stargeo.io/</a></p>",
      "body_md": "Okay, I'll switch the hyperlinks on Thinklab over to http://dev.stargeo.io/",
      "comment_id": 410,
      "note_id": 165,
      "profile_id": 17,
      "url": "/discussion/stargeo-expression-signatures-for-disease-using-crowdsourced-geo-annotation/96#note-165"
    },
    {
      "added": "2015-08-20T00:30:41.694617Z",
      "body_html": "<p>I'm wondering about your relation ontology here.  Can you really distinguish a causal relation from co-occurrence information?  Do the names on these edges actually matter based on how you are using the network ?  If the meaning of the relations is really important, I think there are other text-mining approaches that you should look into.  If not, the co-occurrence stuff should be fine.  Really curious about this experiment..  Would also like to see how the result of other text-ming approaches would influence the outcome.  e.g. would it change things if you swapped in the relations from semmedDB ?</p>",
      "body_md": "I'm wondering about your relation ontology here.  Can you really distinguish a causal relation from co-occurrence information?  Do the names on these edges actually matter based on how you are using the network ?  If the meaning of the relations is really important, I think there are other text-mining approaches that you should look into.  If not, the co-occurrence stuff should be fine.  Really curious about this experiment..  Would also like to see how the result of other text-ming approaches would influence the outcome.  e.g. would it change things if you swapped in the relations from semmedDB ?",
      "comment_id": 365,
      "note_id": 166,
      "profile_id": 48,
      "url": "/discussion/text-as-a-resource-for-network-population/48#note-166"
    },
    {
      "added": "2015-08-20T17:05:36.232991Z",
      "body_html": "<p>I think whatever we do is ultimately arbitrary and will become our 'protocol'.  We can assume that tags reference the sample itself which probably is some type of tissue and applies to the individual.  Like diabetic pancreas tissue is from a diabetic individual.  But cancer is a \"mosaic\" disease which puts tissue vs individual out of sync.  I think eventually for every set of annotations made on a GSE, we can allow for qualifiers from EFO to be set.</p>",
      "body_md": "I think whatever we do is ultimately arbitrary and will become our 'protocol'.  We can assume that tags reference the sample itself which probably is some type of tissue and applies to the individual.  Like diabetic pancreas tissue is from a diabetic individual.  But cancer is a \"mosaic\" disease which puts tissue vs individual out of sync.  I think eventually for every set of annotations made on a GSE, we can allow for qualifiers from EFO to be set.",
      "comment_id": 411,
      "note_id": 167,
      "profile_id": 121,
      "url": "/discussion/stargeo-expression-signatures-for-disease-using-crowdsourced-geo-annotation/96#note-167"
    },
    {
      "added": "2015-08-20T17:07:20.448562Z",
      "body_html": "<p>I guess.  This is mainly for testing.  By the end of the month or soon thereafter it should revert back to .org (public marketed site) and .io will remain for testing among a chosen few (and relatively private)</p>",
      "body_md": "I guess.  This is mainly for testing.  By the end of the month or soon thereafter it should revert back to .org (public marketed site) and .io will remain for testing among a chosen few (and relatively private)",
      "comment_id": 410,
      "note_id": 168,
      "profile_id": 121,
      "url": "/discussion/stargeo-expression-signatures-for-disease-using-crowdsourced-geo-annotation/96#note-168"
    },
    {
      "added": "2015-08-20T17:12:12.642262Z",
      "body_html": "<p>I took a look at that but it doesn't look like it provides hooks to the underlying annotations. Are those going to be available? For the types of analyses that we work on, those are much more valuable than the profiles.</p>",
      "body_md": "I took a look at that but it doesn't look like it provides hooks to the underlying annotations. Are those going to be available? For the types of analyses that we work on, those are much more valuable than the profiles.",
      "comment_id": 414,
      "note_id": 169,
      "profile_id": 22,
      "url": "/discussion/stargeo-expression-signatures-for-disease-using-crowdsourced-geo-annotation/96#note-169"
    },
    {
      "added": "2015-08-20T17:12:47.779058Z",
      "body_html": "<p>1) Yes multi species are on the books.  But for now we are focusing on humans to get the site launched.<br>2) Lets get you an account which for now is through me.  I'm idrdex at both google hangouts and Skype. </p>\n\n<p>3) Everything for now is accessed through the site.  We are working on an API to serve the data for the computational folks.  Basically allow retrival of annotations and served matrices with matching gene ids.</p>",
      "body_md": "1) Yes multi species are on the books.  But for now we are focusing on humans to get the site launched.\n2) Lets get you an account which for now is through me.  I'm idrdex at both google hangouts and Skype. \n\n\n3) Everything for now is accessed through the site.  We are working on an API to serve the data for the computational folks.  Basically allow retrival of annotations and served matrices with matching gene ids.",
      "comment_id": 413,
      "note_id": 170,
      "profile_id": 121,
      "url": "/discussion/stargeo-expression-signatures-for-disease-using-crowdsourced-geo-annotation/96#note-170"
    },
    {
      "added": "2015-08-20T17:16:09.000238Z",
      "body_html": "<p>The \"annotations\" interface is not ready yet.  But imagine a searchable list where you could put GSEs in for instance and get all our annotations across GSMs.  For now I could probably generate a .csv for you.   We currently have 400K+ annotations  over 100+ tags.  Some GSEs have been done up to quadruplicate and ones with multiple annotations we have kappa inter-related sats calculated.</p>",
      "body_md": "The \"annotations\" interface is not ready yet.  But imagine a searchable list where you could put GSEs in for instance and get all our annotations across GSMs.  For now I could probably generate a .csv for you.   We currently have 400K+ annotations  over 100+ tags.  Some GSEs have been done up to quadruplicate and ones with multiple annotations we have kappa inter-related sats calculated.",
      "comment_id": 414,
      "note_id": 171,
      "profile_id": 121,
      "url": "/discussion/stargeo-expression-signatures-for-disease-using-crowdsourced-geo-annotation/96#note-171"
    },
    {
      "added": "2015-08-20T17:21:53.596924Z",
      "body_html": "<p>The annotations interface sounds very helpful! I'm looking forward to it! The analysis that we're doing right now isn't for human datasets, so if your curations are generally there we can't check the overlap with our own curations. We do a lot of human work though, so it'll be very helpful to us to have these annotations available.</p>",
      "body_md": "The annotations interface sounds very helpful! I'm looking forward to it! The analysis that we're doing right now isn't for human datasets, so if your curations are generally there we can't check the overlap with our own curations. We do a lot of human work though, so it'll be very helpful to us to have these annotations available.",
      "comment_id": 414,
      "note_id": 172,
      "profile_id": 22,
      "url": "/discussion/stargeo-expression-signatures-for-disease-using-crowdsourced-geo-annotation/96#note-172"
    },
    {
      "added": "2015-08-20T17:23:01.622176Z",
      "body_html": "<p>I've got a postgres table that you can query if you like.  Let's hangout and discuss :)</p>",
      "body_md": "I've got a postgres table that you can query if you like.  Let's hangout and discuss :)",
      "comment_id": 414,
      "note_id": 173,
      "profile_id": 121,
      "url": "/discussion/stargeo-expression-signatures-for-disease-using-crowdsourced-geo-annotation/96#note-173"
    },
    {
      "added": "2015-08-20T17:27:50.566684Z",
      "body_html": "<p>It would be useful to compare and contrast STARGEO with this ADEPTUS list.  To be clear the 400+ annotations cover about 200+ distinct tags made on samples —  i.e samples can be redundantly annotated to check for validity of the original annotations.  This validation on demand allows us to weed out problematic studies that poorly describe their samples and individual sample annotations whose semantics are imprecise.</p>",
      "body_md": "It would be useful to compare and contrast STARGEO with this ADEPTUS list.  To be clear the 400+ annotations cover about 200+ distinct tags made on samples --  i.e samples can be redundantly annotated to check for validity of the original annotations.  This validation on demand allows us to weed out problematic studies that poorly describe their samples and individual sample annotations whose semantics are imprecise.",
      "comment_id": 387,
      "note_id": 174,
      "profile_id": 121,
      "url": "/discussion/the-adeptus-resource-for-expression-signatures-of-disease/101#note-174"
    },
    {
      "added": "2015-08-20T22:32:29.292522Z",
      "body_html": "<p>Okay, we can change links to <a href=\"http://stargeo.org\">http://stargeo.org</a> now or once the public site goes live. Your call.</p>",
      "body_md": "Okay, we can change links to http://stargeo.org now or once the public site goes live. Your call.",
      "comment_id": 410,
      "note_id": 175,
      "profile_id": 17,
      "url": "/discussion/stargeo-expression-signatures-for-disease-using-crowdsourced-geo-annotation/96#note-175"
    },
    {
      "added": "2015-08-21T20:54:30.263301Z",
      "body_html": "<p>We don't include COSMIC anywhere else, so I would like to include it. <a href=\"/u/larsjuhljensen\" class=\"username\">@larsjuhljensen</a>, which literature corpus was used for text mining?</p>",
      "body_md": "We don't include COSMIC anywhere else, so I would like to include it. @larsjuhljensen, which literature corpus was used for text mining?",
      "comment_id": 418,
      "note_id": 176,
      "profile_id": 17,
      "url": "/discussion/processing-the-diseases-resource-for-diseasegene-relationships/106#note-176"
    },
    {
      "added": "2015-08-21T20:59:14.336769Z",
      "body_html": "<p>Just Medline so far.</p>",
      "body_md": "Just Medline so far.",
      "comment_id": 418,
      "note_id": 177,
      "profile_id": 125,
      "url": "/discussion/processing-the-diseases-resource-for-diseasegene-relationships/106#note-177"
    },
    {
      "added": "2015-08-28T20:38:08.534127Z",
      "body_html": "<p>Great suggestion. This way users can avoid having to subset the network and reconcile various licenses.</p>",
      "body_md": "Great suggestion. This way users can avoid having to subset the network and reconcile various licenses.",
      "comment_id": 420,
      "note_id": 178,
      "profile_id": 17,
      "url": "/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#note-178"
    },
    {
      "added": "2015-09-07T16:07:27.482234Z",
      "body_html": "<p>Exciting, thanks for the update. On another note, I wasn't able to find any licensing information on the Bgee website, which technically means <a href=\"http://choosealicense.com/no-license/\">all rights reserved</a>. We're <a href=\"http://thinklab.com/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#3\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d107\">tying to compile</a> licenses for each resource we use. It would be great if you could add a license.</p>",
      "body_md": "Exciting, thanks for the update. On another note, I wasn't able to find any licensing information on the Bgee website, which technically means [all rights reserved](http://choosealicense.com/no-license/). We're [tying to compile](http://thinklab.com/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#3) licenses for each resource we use. It would be great if you could add a license.",
      "comment_id": 426,
      "note_id": 179,
      "profile_id": 17,
      "url": "/discussion/processing-gtex-for-tissue-specific-gene-expression/82#note-179"
    },
    {
      "added": "2015-09-07T16:38:45.337493Z",
      "body_html": "<p>Yep, I wanted to reply to you after checking all our datasources. I think we are going to use a cc-by, but I'll contact you when I can confirm that for sure.</p>",
      "body_md": "Yep, I wanted to reply to you after checking all our datasources. I think we are going to use a cc-by, but I'll contact you when I can confirm that for sure.",
      "comment_id": 426,
      "note_id": 180,
      "profile_id": 111,
      "url": "/discussion/processing-gtex-for-tissue-specific-gene-expression/82#note-180"
    },
    {
      "added": "2015-09-10T10:52:06.035130Z",
      "body_html": "<p>The big problem I see here is the term \"results\". If the results are actually new results, then I agree that they can be released whichever way you like. But if your \"results\" are in fact other people's databases mapped to different identifiers, bundled, and reformatted in JSON format, then claiming fair use is in my opinion a very risky proposition.</p>",
      "body_md": "The big problem I see here is the term \"results\". If the results are actually new results, then I agree that they can be released whichever way you like. But if your \"results\" are in fact other people's databases mapped to different identifiers, bundled, and reformatted in JSON format, then claiming fair use is in my opinion a very risky proposition.",
      "comment_id": 431,
      "note_id": 181,
      "profile_id": 125,
      "url": "/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#note-181"
    },
    {
      "added": "2015-09-10T19:26:59.238966Z",
      "body_html": "<p><a href=\"/u/larsjuhljensen\" class=\"username\">@larsjuhljensen</a> and <a href=\"/u/mackenziesmith\" class=\"username\">@mackenziesmith</a>, I think we may all be on the same page. Results from <em>network analyses</em> are truly transformative and thus eligible for CC0 licensing due to fair use. However, the <em>resource processing</em> and <em>integrative network</em> <a href=\"#4\">steps</a>, which distribute unmodified downloads as well as network-coerced versions of databases, should generally transmit the source licensing.</p>",
      "body_md": "@larsjuhljensen and @mackenziesmith, I think we may all be on the same page. Results from *network analyses* are truly transformative and thus eligible for CC0 licensing due to fair use. However, the *resource processing* and *integrative network* [steps](#4), which distribute unmodified downloads as well as network-coerced versions of databases, should generally transmit the source licensing.",
      "comment_id": 431,
      "note_id": 182,
      "profile_id": 17,
      "url": "/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#note-182"
    },
    {
      "added": "2015-09-10T19:47:47.420275Z",
      "body_html": "<p><a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a>, we almost agree. The one point where I disagree is that, in my opinion, fair use has nothing to do with it. If you do a network analysis that truly produces new results (e.g. predicting new edges based on the imported ones), then those edges are yours. You are free to do with them whatever you want, not because of fair use, but simply because you are the original creator :-)</p>",
      "body_md": "@dhimmel, we almost agree. The one point where I disagree is that, in my opinion, fair use has nothing to do with it. If you do a network analysis that truly produces new results (e.g. predicting new edges based on the imported ones), then those edges are yours. You are free to do with them whatever you want, not because of fair use, but simply because you are the original creator :-)",
      "comment_id": 431,
      "note_id": 183,
      "profile_id": 125,
      "url": "/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#note-183"
    },
    {
      "added": "2015-09-10T20:17:01.002824Z",
      "body_html": "<p>I am interested in subnetworks for user convenience — if a user wants only CC-BY-SA content, then the subnetwork saves them time. However, I disagree that subnetworks are a substitute for a complete network with mixed licensing. Merging networks will be burdensome to my hypothetical user who is interested only in analyzing rather than redistributing the network. Additionally, I am not sure the entire network can be represented by copyright uniform subnetworks. For example, DrugBank <a href=\"https://github.com/dhimmel/integrate/blob/0e343d8745a98757c86e73f645b41353f52b82b5/licenses/custom/DrugBank.md\">forbids</a> commercial reuse. However, our drug–gene binding edges derive from the CC-BY-SA ChEMBL resource. Thus the CC-BY-SA subnetwork would contain edges whose nodes cannot be included.</p>",
      "body_md": "I am interested in subnetworks for user convenience -- if a user wants only CC-BY-SA content, then the subnetwork saves them time. However, I disagree that subnetworks are a substitute for a complete network with mixed licensing. Merging networks will be burdensome to my hypothetical user who is interested only in analyzing rather than redistributing the network. Additionally, I am not sure the entire network can be represented by copyright uniform subnetworks. For example, DrugBank [forbids](https://github.com/dhimmel/integrate/blob/0e343d8745a98757c86e73f645b41353f52b82b5/licenses/custom/DrugBank.md) commercial reuse. However, our drug--gene binding edges derive from the CC-BY-SA ChEMBL resource. Thus the CC-BY-SA subnetwork would contain edges whose nodes cannot be included.",
      "comment_id": 429,
      "note_id": 184,
      "profile_id": 17,
      "url": "/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#note-184"
    },
    {
      "added": "2015-09-14T22:38:05.507384Z",
      "body_html": "<p>Continuum <a href=\"http://continuum.io/blog/conda-jupyter-irkernel\">has created</a> an <code>r-essentials</code> bundle containing many of the most common R packages. Installing, <code>r-essentials</code> should also add the R kernel to your jupyter notebook.</p>",
      "body_md": "Continuum [has created](http://continuum.io/blog/conda-jupyter-irkernel) an `r-essentials` bundle containing many of the most common R packages. Installing, `r-essentials` should also add the R kernel to your jupyter notebook.",
      "comment_id": 422,
      "note_id": 185,
      "profile_id": 17,
      "url": "/discussion/r-best-practices/83#note-185"
    },
    {
      "added": "2015-09-23T05:43:28.403404Z",
      "body_html": "<p>Thanks a lot for also pointing out the politics aspect. In my opinion, the risk of actually getting sued in academia is probably fairly low. However, if you were to systematically take resources with restrictive licenses, integrate them, and redistribute the complete data under CC0, you would almost for sure be burning bridges.</p>",
      "body_md": "Thanks a lot for also pointing out the politics aspect. In my opinion, the risk of actually getting sued in academia is probably fairly low. However, if you were to systematically take resources with restrictive licenses, integrate them, and redistribute the complete data under CC0, you would almost for sure be burning bridges.",
      "comment_id": 438,
      "note_id": 186,
      "profile_id": 125,
      "url": "/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#note-186"
    },
    {
      "added": "2015-10-02T19:29:30.472824Z",
      "body_html": "<p>Yesterday, we <a href=\"http://thinklab.com/discussion/incomplete-interactome-licensing/111\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d111\">sent out</a> our first permission request for a publication <span class=\"citation\">[<a href=\"https://doi.org/10.1126/science.1257601\" class=\"citation\" data-key=\"10.1126/science.1257601\">1</a>]</span> supplement.</p>",
      "body_md": "Yesterday, we [sent out](http://thinklab.com/discussion/incomplete-interactome-licensing/111) our first permission request for a publication [@10.1126/science.1257601] supplement.",
      "comment_id": 445,
      "note_id": 187,
      "profile_id": 17,
      "url": "/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#note-187"
    },
    {
      "added": "2015-10-05T02:33:53.056678Z",
      "body_html": "<p>Just a small correction — Thinklab is tracking views independently of Google Analytics. Our figure attempts to track the total number of <em>humans</em> that have viewed the page. Our figure will be less than what Google Analytics has because for them a unique page view is really the number of <em>sessions</em> with at least one page view.</p>",
      "body_md": "Just a small correction -- Thinklab is tracking views independently of Google Analytics. Our figure attempts to track the total number of *humans* that have viewed the page. Our figure will be less than what Google Analytics has because for them a unique page view is really the number of *sessions* with at least one page view.",
      "comment_id": 451,
      "note_id": 188,
      "profile_id": 2,
      "url": "/discussion/tracking-project-reuse-citation-and-publicity/113#note-188"
    },
    {
      "added": "2015-10-05T02:44:07.397470Z",
      "body_html": "<p>I've emailed them and will report back</p>",
      "body_md": "I've emailed them and will report back",
      "comment_id": 454,
      "note_id": 189,
      "profile_id": 2,
      "url": "/discussion/tracking-project-reuse-citation-and-publicity/113#note-189"
    },
    {
      "added": "2015-10-06T15:55:53.335805Z",
      "body_html": "<p>2015-09-06: I updated this post to correct edge counts. Previously, I wrote the network contains \"5,998,711 edges (2,977,167 of which are unbiased)\". The issue was caused by counting single edges multiple times.</p>",
      "body_md": "2015-09-06: I updated this post to correct edge counts. Previously, I wrote the network contains \"5,998,711 edges (2,977,167 of which are unbiased)\". The issue was caused by counting single edges multiple times.",
      "comment_id": 396,
      "note_id": 190,
      "profile_id": 17,
      "url": "/discussion/one-network-to-rule-them-all/102#note-190"
    },
    {
      "added": "2015-10-09T16:11:40.411972Z",
      "body_html": "<p>I've <a href=\"https://github.com/dhimmel/integrate/blob/7ef64533f0822fb5728ab4c1d88dc39f3345dcc8/licenses/README.md\">added institutional affiliations</a>. I did not specify affiliations for community driven projects or multi-affiliated projects. In general, is funding information available? Where can I find it?</p>",
      "body_md": "I've [added institutional affiliations](https://github.com/dhimmel/integrate/blob/7ef64533f0822fb5728ab4c1d88dc39f3345dcc8/licenses/README.md). I did not specify affiliations for community driven projects or multi-affiliated projects. In general, is funding information available? Where can I find it?",
      "comment_id": 462,
      "note_id": 191,
      "profile_id": 17,
      "url": "/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#note-191"
    },
    {
      "added": "2015-10-13T18:05:23.266060Z",
      "body_html": "<p>Funding is available on the project site or the citation.  For example <a href=\"http://disease-ontology.org/about/\">DO</a>, their last <a href=\"http://nar.oxfordjournals.org/content/early/2014/10/27/nar.gku1011.full.pdf?keytype=ref&amp;ijkey=Ul8AlMyerFSf0rP\">publication</a>, the funding are from several grants from NIH, EMBL and the department of energy. </p>\n\n<p>When sources are looking into licensing or terms of use, do they bind to the affiliation, funding or make the best educated guess?</p>",
      "body_md": "Funding is available on the project site or the citation.  For example [DO] (http://disease-ontology.org/about/), their last [publication]\n(http://nar.oxfordjournals.org/content/early/2014/10/27/nar.gku1011.full.pdf?keytype=ref&ijkey=Ul8AlMyerFSf0rP), the funding are from several grants from NIH, EMBL and the department of energy. \n\nWhen sources are looking into licensing or terms of use, do they bind to the affiliation, funding or make the best educated guess?",
      "comment_id": 462,
      "note_id": 192,
      "profile_id": 79,
      "url": "/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#note-192"
    },
    {
      "added": "2015-10-14T23:09:31.462736Z",
      "body_html": "<p>Generally with a CC license you should say how the author wants to be credited - if not specific as to manner, than at least with a name of person or organization. That's all so far. I'll keep an eye out now that I'm back in the office...</p>",
      "body_md": "Generally with a CC license you should say how the author wants to be credited - if not specific as to manner, than at least with a name of person or organization. That's all so far. I'll keep an eye out now that I'm back in the office...",
      "comment_id": 440,
      "note_id": 193,
      "profile_id": 137,
      "url": "/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#note-193"
    },
    {
      "added": "2015-10-22T03:37:18.366074Z",
      "body_html": "<p>Neo4j 3.0 should be interesting. So far, what has mainly held me back was that I do not want to develop my bioinformatics software in Java and doing everything through Cypher was not sufficiently efficient to warrant migration from a PostgreSQL database.</p>",
      "body_md": "Neo4j 3.0 should be interesting. So far, what has mainly held me back was that I do not want to develop my bioinformatics software in Java and doing everything through Cypher was not sufficiently efficient to warrant migration from a PostgreSQL database.",
      "comment_id": 484,
      "note_id": 194,
      "profile_id": 125,
      "url": "/discussion/using-the-neo4j-graph-database-for-hetnets/112#note-194"
    },
    {
      "added": "2015-12-04T21:52:50.278510Z",
      "body_html": "<p>Milestone 1 of version 3.0 was <a href=\"http://neo4j.com/blog/neo4j-3-0-milestone-1-release/\">released today</a> with a <a href=\"https://github.com/neo4j/neo4j-python-driver\">python driver</a>. The update promises fast access from outside of java. However, you will still need to use Cypher (which I find easier and more powerful than SQL). <a href=\"/u/larsjuhljensen\" class=\"username\">@larsjuhljensen</a>, I would wait till the final 3.0 release for production use but wanted to give you a heads up of what lies ahead.</p>",
      "body_md": "Milestone 1 of version 3.0 was [released today](http://neo4j.com/blog/neo4j-3-0-milestone-1-release/) with a [python driver](https://github.com/neo4j/neo4j-python-driver). The update promises fast access from outside of java. However, you will still need to use Cypher (which I find easier and more powerful than SQL). @larsjuhljensen, I would wait till the final 3.0 release for production use but wanted to give you a heads up of what lies ahead.",
      "comment_id": 484,
      "note_id": 195,
      "profile_id": 17,
      "url": "/discussion/using-the-neo4j-graph-database-for-hetnets/112#note-195"
    },
    {
      "added": "2015-12-04T22:16:40.803100Z",
      "body_html": "<p>Thanks - my problem was, though, that my network queries could not be expressed efficiently in Cypher. Whereas shortest path could be done very efficiently, something as simple as shortest path in a weighted graph could not. Maybe Cypher has become more powerful since?</p>",
      "body_md": "Thanks - my problem was, though, that my network queries could not be expressed efficiently in Cypher. Whereas shortest path could be done very efficiently, something as simple as shortest path in a weighted graph could not. Maybe Cypher has become more powerful since?",
      "comment_id": 484,
      "note_id": 196,
      "profile_id": 125,
      "url": "/discussion/using-the-neo4j-graph-database-for-hetnets/112#note-196"
    },
    {
      "added": "2015-12-04T23:34:50.299760Z",
      "body_html": "<p>Cypher doesn't have great algorithm coverage. Shortest weighted path <a href=\"http://www.khalidabuhakmeh.com/finding-the-shortest-path-using-neo4j-graph-database\">isn't too hard</a> to implement, albeit inefficiently. However, if you're encoding anything that resembles a hetnet, cypher will beat SQL for data interactions.</p>",
      "body_md": "Cypher doesn't have great algorithm coverage. Shortest weighted path [isn't too hard](http://www.khalidabuhakmeh.com/finding-the-shortest-path-using-neo4j-graph-database) to implement, albeit inefficiently. However, if you're encoding anything that resembles a hetnet, cypher will beat SQL for data interactions.",
      "comment_id": 484,
      "note_id": 197,
      "profile_id": 17,
      "url": "/discussion/using-the-neo4j-graph-database-for-hetnets/112#note-197"
    },
    {
      "added": "2015-12-14T00:55:48.202064Z",
      "body_html": "<p>We've <a href=\"https://github.com/dhimmel/hetio/commit/0683f5fd43ff0ca51c0bd1de1217f589a8891274\">implemented</a> the <strong>labeled</strong> method, which can be used for our path traversal, since the metapath is known <em>a priori</em>.</p>",
      "body_md": "We've [implemented](https://github.com/dhimmel/hetio/commit/0683f5fd43ff0ca51c0bd1de1217f589a8891274) the **labeled** method, which can be used for our path traversal, since the metapath is known *a priori*.",
      "comment_id": 572,
      "note_id": 198,
      "profile_id": 17,
      "url": "/discussion/path-exclusion-conditions/134#note-198"
    },
    {
      "added": "2016-02-05T22:03:55.034805Z",
      "body_html": "<p>Noting another disease–phenotype approach <span class=\"citation\">[<a href=\"https://doi.org/10.1038/srep10888\" class=\"citation\" data-key=\"10.1038/srep10888\">1</a>]</span> titled \"Analysis of the human diseasome using phenotype similarity between common, genetic, and infectious diseases.\"</p>",
      "body_md": "Noting another disease--phenotype approach [@10.1038/srep10888] titled \"Analysis of the human diseasome using phenotype similarity between common, genetic, and infectious diseases.\"",
      "comment_id": 345,
      "note_id": 204,
      "profile_id": 17,
      "url": "/discussion/suggestions-for-additional-information-types/22#note-204"
    },
    {
      "added": "2016-02-20T06:23:56.287611Z",
      "body_html": "<p>Pouya's curations are available as a <a href=\"https://github.com/dhimmel/indications/blob/d3d57b07abcf8d7af55f8e42ef7c4c99acd87ca8/curation/pk/template-pk%20final.xlsx\" title=\"GitHub · `template-pk final.xlsx`\">spreadsheet</a> or <a href=\"https://github.com/dhimmel/indications/blob/49cf8e3858f124e552051fc1e8c1c229a43dadf6/curation/pk/curation-PK.tsv\" title=\"GitHub · `curation-PK.tsv`\">TSV file</a>.</p>",
      "body_md": "Pouya's curations are available as a [spreadsheet](https://github.com/dhimmel/indications/blob/d3d57b07abcf8d7af55f8e42ef7c4c99acd87ca8/curation/pk/template-pk%20final.xlsx \"GitHub · `template-pk final.xlsx`\") or [TSV file](https://github.com/dhimmel/indications/blob/49cf8e3858f124e552051fc1e8c1c229a43dadf6/curation/pk/curation-PK.tsv \"GitHub · `curation-PK.tsv`\").",
      "comment_id": 900,
      "note_id": 205,
      "profile_id": 17,
      "url": "/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95#note-205"
    },
    {
      "added": "2016-02-26T17:37:11.558424Z",
      "body_html": "<p>Exactly - we think alike. What I refer to as \"not a happy cell\" is usually some mix of stress response and reduced growth rate, which also results in a change in the distribution of cells across cell-cycle phases.</p>",
      "body_md": "Exactly - we think alike. What I refer to as \"not a happy cell\" is usually some mix of stress response and reduced growth rate, which also results in a change in the distribution of cells across cell-cycle phases.",
      "comment_id": 1137,
      "note_id": 207,
      "profile_id": 125,
      "url": "/discussion/positive-correlations-between-knockdown-and-overexpression-profiles-from-lincs-l1000/171#note-207"
    },
    {
      "added": "2016-02-26T17:42:00.179885Z",
      "body_html": "<p><a href=\"/u/larsjuhljensen\" class=\"username\">@larsjuhljensen</a> Indeed! My guess right now is that or no gene-wise normalization (e.g. the most highly expressed genes are still the most highly expressed).</p>",
      "body_md": "@larsjuhljensen Indeed! My guess right now is that or no gene-wise normalization (e.g. the most highly expressed genes are still the most highly expressed).",
      "comment_id": 1137,
      "note_id": 208,
      "profile_id": 22,
      "url": "/discussion/positive-correlations-between-knockdown-and-overexpression-profiles-from-lincs-l1000/171#note-208"
    },
    {
      "added": "2016-02-26T17:46:19.124138Z",
      "body_html": "<p>I assume that the expression values here are already ratios between perturbed and non-perturbed. Otherwise, I would put my money on it being a normalization artifact, but in that case I would expect a much stronger correlation than what is observed.</p>",
      "body_md": "I assume that the expression values here are already ratios between perturbed and non-perturbed. Otherwise, I would put my money on it being a normalization artifact, but in that case I would expect a much stronger correlation than what is observed.",
      "comment_id": 1137,
      "note_id": 209,
      "profile_id": 125,
      "url": "/discussion/positive-correlations-between-knockdown-and-overexpression-profiles-from-lincs-l1000/171#note-209"
    },
    {
      "added": "2016-03-08T06:25:39.678908Z",
      "body_html": "<p>I removed the following sentence, since it is not true:</p>\n\n<blockquote><p>Unfortunately, none of the perturbed genes were in the landmark set, so I can't detect whether the perturbations are actually affecting their target genes in the desired direction.</p></blockquote>",
      "body_md": "I removed the following sentence, since it is not true:\n\n> Unfortunately, none of the perturbed genes were in the landmark set, so I can't detect whether the perturbations are actually affecting their target genes in the desired direction.",
      "comment_id": 1051,
      "note_id": 210,
      "profile_id": 17,
      "url": "/discussion/positive-correlations-between-knockdown-and-overexpression-profiles-from-lincs-l1000/171#note-210"
    },
    {
      "added": "2016-03-09T06:46:22.029813Z",
      "body_html": "<p>Reassuring to see that things behave the way I would expect. This should make it fairly easy to derive a scoring scheme that extracts only associations that are specifically associated with a small number of perturbations, as opposed to associated with any perturbation.</p>",
      "body_md": "Reassuring to see that things behave the way I would expect. This should make it fairly easy to derive a scoring scheme that extracts only associations that are specifically associated with a small number of perturbations, as opposed to associated with any perturbation.",
      "comment_id": 1166,
      "note_id": 211,
      "profile_id": 125,
      "url": "/discussion/workshop-to-analyze-lincs-data-for-the-systems-pharmacology-course-at-ucsf/181#note-211"
    },
    {
      "added": "2016-03-09T06:47:25.413092Z",
      "body_html": "<p>The part about broad downregulation occurring in tandem with broad upregulation is almost a given. Even if it is not the case biologically, this will be the case after most normalization methods.</p>",
      "body_md": "The part about broad downregulation occurring in tandem with broad upregulation is almost a given. Even if it is not the case biologically, this will be the case after most normalization methods.",
      "comment_id": 1166,
      "note_id": 212,
      "profile_id": 125,
      "url": "/discussion/workshop-to-analyze-lincs-data-for-the-systems-pharmacology-course-at-ucsf/181#note-212"
    },
    {
      "added": "2016-03-15T03:00:45.439522Z",
      "body_html": "<p>I <a href=\"https://github.com/dhimmel/integrate/blob/145810796f0729d1ed5255bcb83c658490a198f9/licenses/README.md\">updated the table</a> to include funding information. Without seeing the specific contractual arrangements between funders and Universities and between Universities and their researchers, it's difficult to know whether there are any binding obligations regarding data licensing.</p>",
      "body_md": "I [updated the table](https://github.com/dhimmel/integrate/blob/145810796f0729d1ed5255bcb83c658490a198f9/licenses/README.md) to include funding information. Without seeing the specific contractual arrangements between funders and Universities and between Universities and their researchers, it's difficult to know whether there are any binding obligations regarding data licensing.",
      "comment_id": 462,
      "note_id": 214,
      "profile_id": 17,
      "url": "/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#note-214"
    },
    {
      "added": "2016-03-15T06:31:19.499600Z",
      "body_html": "<p>I get an error when trying to follow the figshare link. Looks like the DOI is either wrong or not registered correctly (yet).</p>",
      "body_md": "I get an error when trying to follow the figshare link. Looks like the DOI is either wrong or not registered correctly (yet).",
      "comment_id": 1170,
      "note_id": 215,
      "profile_id": 125,
      "url": "/discussion/announcing-pharmacotherapydb-the-open-catalog-of-drug-therapies-for-disease/182#note-215"
    },
    {
      "added": "2016-03-15T08:09:10.808485Z",
      "body_html": "<p>If I were you, I would just delete Human Interactome Database and ADEPTUS from the network, unless they are crucial. Considering that over half a year has gone by without them responding, it seems likely that you will get permission, so I would remove them to not have legally questionable data in my resource.</p>",
      "body_md": "If I were you, I would just delete Human Interactome Database and ADEPTUS from the network, unless they are crucial. Considering that over half a year has gone by without them responding, it seems likely that you will get permission, so I would remove them to not have legally questionable data in my resource.",
      "comment_id": 1176,
      "note_id": 216,
      "profile_id": 125,
      "url": "/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#note-216"
    },
    {
      "added": "2016-03-15T15:02:14.154216Z",
      "body_html": "<p>The figshare DOI link is <a href=\"https://doi.org/10.6084/m9.figshare.3103054\">now active</a>. The citation metadata <span class=\"citation\">[<a href=\"https://doi.org/10.6084/m9.figshare.3103054\" class=\"citation\" data-key=\"10.6084/m9.figshare.3103054\">1</a>]</span> should resolve with time.</p>",
      "body_md": "The figshare DOI link is [now active](https://doi.org/10.6084/m9.figshare.3103054). The citation metadata [@10.6084/m9.figshare.3103054] should resolve with time.",
      "comment_id": 1170,
      "note_id": 217,
      "profile_id": 17,
      "url": "/discussion/announcing-pharmacotherapydb-the-open-catalog-of-drug-therapies-for-disease/182#note-217"
    },
    {
      "added": "2016-03-15T16:36:03.799865Z",
      "body_html": "<p>ADEPTUS is no longer included (indicated by ‡ <a href=\"https://github.com/dhimmel/integrate/blob/145810796f0729d1ed5255bcb83c658490a198f9/licenses/README.md\">here</a>). The Human Interactome Database (<a href=\"http://interactome.dfci.harvard.edu/H_sapiens/index.php?page=download\">HID</a>) is important because it's the only <a href=\"http://thinklab.com/discussion/creating-a-catalog-of-protein-interactions/85#9\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d85\">resource we include</a> of systematic (unbiased by knowledge) interactions. The HID — having received many millions in NIH funding (see <a href=\"http://grantome.com/grant/NIH/U01-HG001715-16\">a</a>, <a href=\"http://grantome.com/grant/NIH/U41-HG001715-17\">b</a>, &amp; <a href=\"http://grantome.com/grant/NIH/R01-HG001715-13\">c</a>) to create its dataset — provides a unique resource that is commonly reused despite it's lack of a license. I will follow up on my initial emails to the HID.</p>",
      "body_md": "ADEPTUS is no longer included (indicated by ‡ [here](https://github.com/dhimmel/integrate/blob/145810796f0729d1ed5255bcb83c658490a198f9/licenses/README.md)). The Human Interactome Database ([HID](http://interactome.dfci.harvard.edu/H_sapiens/index.php?page=download)) is important because it's the only [resource we include](http://thinklab.com/discussion/creating-a-catalog-of-protein-interactions/85#9) of systematic (unbiased by knowledge) interactions. The HID -- having received many millions in NIH funding (see [a](http://grantome.com/grant/NIH/U01-HG001715-16), [b](http://grantome.com/grant/NIH/U41-HG001715-17), & [c](http://grantome.com/grant/NIH/R01-HG001715-13)) to create its dataset -- provides a unique resource that is commonly reused despite it's lack of a license. I will follow up on my initial emails to the HID.",
      "comment_id": 1176,
      "note_id": 218,
      "profile_id": 17,
      "url": "/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#note-218"
    },
    {
      "added": "2016-03-17T04:22:20.379990Z",
      "body_html": "<p>Lars, you should have mentioned your article on whether graph databases are ready for bioinformatics <span class=\"citation\">[<a href=\"https://doi.org/10.1093/bioinformatics/btt549\" class=\"citation\" data-key=\"10.1093/bioinformatics/btt549\">1</a>]</span>! This is a citation that belongs in this discussion.</p>",
      "body_md": "Lars, you should have mentioned your article on whether graph databases are ready for bioinformatics [@10.1093/bioinformatics/btt549]! This is a citation that belongs in this discussion.",
      "comment_id": 484,
      "note_id": 219,
      "profile_id": 17,
      "url": "/discussion/using-the-neo4j-graph-database-for-hetnets/112#note-219"
    },
    {
      "added": "2016-03-21T13:29:59.475518Z",
      "body_html": "<p>I'm up for it. I should have some time either late this week or early next week. </p>",
      "body_md": "I'm up for it. I should have some time either late this week or early next week. ",
      "comment_id": 1184,
      "note_id": 220,
      "profile_id": 188,
      "url": "/discussion/incorporating-drugcentral-data-in-our-network/186#note-220"
    },
    {
      "added": "2016-03-31T05:00:22.399653Z",
      "body_html": "<p>We <a href=\"http://thinklab.com/discussion/the-adeptus-resource-for-expression-signatures-of-disease/101#2\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d101\">received permission</a> to use ADEPTUS. The ADEPTUS row in the permission request table now becomes PERM after 213 days.</p>",
      "body_md": "We [received permission](http://thinklab.com/discussion/the-adeptus-resource-for-expression-signatures-of-disease/101#2) to use ADEPTUS. The ADEPTUS row in the permission request table now becomes PERM after 213 days.",
      "comment_id": 1176,
      "note_id": 221,
      "profile_id": 17,
      "url": "/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#note-221"
    },
    {
      "added": "2016-03-31T05:10:48.632581Z",
      "body_html": "<p>I know it's dangerous to make pre-morning coffee comments on a mathematical proof, but didn't you get N_START and N_END swapped in the last formula? In the formula just above, I thought N_A was the number of start nodes and N_D the number of end nodes.</p>\n\n<p>It would also make more sense intuitively, since it implies that N_START⋅FC = N_END⋅BC. In other words, it doesn't matter whether you start from every start node and do forward traversal or start from every end node and do backward traversal. Both involve that you traverse all possible paths between all start nodes and all end nodes and have the same complexity.</p>",
      "body_md": "I know it's dangerous to make pre-morning coffee comments on a mathematical proof, but didn't you get N_START and N_END swapped in the last formula? In the formula just above, I thought N_A was the number of start nodes and N_D the number of end nodes.\n\nIt would also make more sense intuitively, since it implies that N_START⋅FC = N_END⋅BC. In other words, it doesn't matter whether you start from every start node and do forward traversal or start from every end node and do backward traversal. Both involve that you traverse all possible paths between all start nodes and all end nodes and have the same complexity.",
      "comment_id": 1191,
      "note_id": 222,
      "profile_id": 125,
      "url": "/discussion/estimating-the-complexity-of-hetnet-traversal/187#note-222"
    },
    {
      "added": "2016-04-01T01:47:55.441382Z",
      "body_html": "<p>Just came across this publication <span class=\"citation\">[<a href=\"https://doi.org/10.1002/psp4.12009\" class=\"citation\" data-key=\"10.1002/psp4.12009\">1</a>]</span>, which analyzed how chemical similarity correlated with transcriptional similarity in LINCS L1000.</p>",
      "body_md": "Just came across this publication [@10.1002/psp4.12009], which analyzed how chemical similarity correlated with transcriptional similarity in LINCS L1000.",
      "comment_id": 350,
      "note_id": 223,
      "profile_id": 17,
      "url": "/discussion/calculating-molecular-similarities-between-drugbank-compounds/70#note-223"
    },
    {
      "added": "2016-04-02T20:22:56.180964Z",
      "body_html": "<p>Noting an updated WikiPathways citation <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkv1024\" class=\"citation\" data-key=\"10.1093/nar/gkv1024\">1</a>]</span> in 2016 <em>NAR</em> Database Issue.</p>",
      "body_md": "Noting an updated WikiPathways citation [@10.1093/nar/gkv1024] in 2016 _NAR_ Database Issue.",
      "comment_id": 244,
      "note_id": 224,
      "profile_id": 17,
      "url": "/discussion/adding-pathway-resources-to-your-network/72#note-224"
    },
    {
      "added": "2016-04-03T04:21:04.803273Z",
      "body_html": "<p>MSigDB — the only remaining category 3 resource — has now <a href=\"http://thinklab.com/discussion/msigdb-licensing/108#3\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d108\">been removed</a>.</p>",
      "body_md": "MSigDB -- the only remaining category 3 resource -- has now [been removed](http://thinklab.com/discussion/msigdb-licensing/108#3).",
      "comment_id": 1176,
      "note_id": 225,
      "profile_id": 17,
      "url": "/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#note-225"
    },
    {
      "added": "2016-04-03T20:18:20.176280Z",
      "body_html": "<p><a href=\"/u/larsjuhljensen\" class=\"username\">@larsjuhljensen</a>: I wish I could say I let this one slip to test readership's attention, but it just seems that your pre-morning coffee brain is more awake than my post-lunch one. Well spotted - thank you.</p>",
      "body_md": "@larsjuhljensen: I wish I could say I let this one slip to test readership's attention, but it just seems that your pre-morning coffee brain is more awake than my post-lunch one. Well spotted - thank you.",
      "comment_id": 1191,
      "note_id": 226,
      "profile_id": 23,
      "url": "/discussion/estimating-the-complexity-of-hetnet-traversal/187#note-226"
    },
    {
      "added": "2016-04-03T20:19:09.802940Z",
      "body_html": "<p>Correct</p>",
      "body_md": "Correct",
      "comment_id": 1203,
      "note_id": 227,
      "profile_id": 23,
      "url": "/discussion/estimating-the-complexity-of-hetnet-traversal/187#note-227"
    },
    {
      "added": "2016-04-04T17:33:36.794753Z",
      "body_html": "<p><a href=\"/u/pouyakhankhanian\" class=\"username\">@pouyakhankhanian</a> I find your last remark interesting, but unfortunately not quite accurate. I'll try to show it below (notes are not good for math...)</p>",
      "body_md": "@pouyakhankhanian I find your last remark interesting, but unfortunately not quite accurate. I'll try to show it below (notes are not good for math...)",
      "comment_id": 1211,
      "note_id": 228,
      "profile_id": 23,
      "url": "/discussion/transforming-dwpcs-for-hetnet-edge-prediction/193#note-228"
    },
    {
      "added": "2016-04-04T18:19:03.130302Z",
      "body_html": "<p>To be clear, I didn't mean \"derivative\" in the strict mathematical definition (i.e. d/dx f(x)) .  I supposed a better word would be a \"relative\" or \"derivation\", so please excuse the language. And I do agree that both functions are very similar, that was the point I was trying to make. I think Daniel understood the spirit of my comment and has addressed it appropriately.</p>",
      "body_md": "To be clear, I didn't mean \"derivative\" in the strict mathematical definition (i.e. d/dx f(x)) .  I supposed a better word would be a \"relative\" or \"derivation\", so please excuse the language. And I do agree that both functions are very similar, that was the point I was trying to make. I think Daniel understood the spirit of my comment and has addressed it appropriately.",
      "comment_id": 1215,
      "note_id": 229,
      "profile_id": 188,
      "url": "/discussion/transforming-dwpcs-for-hetnet-edge-prediction/193#note-229"
    },
    {
      "added": "2016-04-04T18:29:09.339041Z",
      "body_html": "<p>I thought it was maybe the case, but also that clarification might be useful in general.</p>",
      "body_md": "I thought it was maybe the case, but also that clarification might be useful in general.",
      "comment_id": 1215,
      "note_id": 230,
      "profile_id": 23,
      "url": "/discussion/transforming-dwpcs-for-hetnet-edge-prediction/193#note-230"
    },
    {
      "added": "2016-04-04T18:37:42.089421Z",
      "body_html": "<p>RStudio is getting better with every iteration and has improved significantly since this post. Many features (smart completion, tight git integration, ...) make it a better IDE today than the Jupyter notebooks in my opinion.</p>",
      "body_md": "RStudio is getting better with every iteration and has improved significantly since this post. Many features (smart completion, tight git integration, ...) make it a better IDE today than the Jupyter notebooks in my opinion.",
      "comment_id": 277,
      "note_id": 231,
      "profile_id": 23,
      "url": "/discussion/r-best-practices/83#note-231"
    },
    {
      "added": "2016-04-05T17:39:22.111050Z",
      "body_html": "<p>I would love to see how sequential complexity predicts midpoint runtime when these results will be ready.</p>",
      "body_md": "I would love to see how sequential complexity predicts midpoint runtime when these results will be ready.",
      "comment_id": 1206,
      "note_id": 233,
      "profile_id": 23,
      "url": "/discussion/estimating-the-complexity-of-hetnet-traversal/187#note-233"
    },
    {
      "added": "2016-04-12T16:36:09.961963Z",
      "body_html": "<p>CHANGELOG: <br>- better counting of total number (relied on the cumulative density before)</p>",
      "body_md": "CHANGELOG: \n- better counting of total number (relied on the cumulative density before)",
      "comment_id": 1248,
      "note_id": 240,
      "profile_id": 23,
      "url": "/discussion/measuring-user-contribution-and-content-creation/200#note-240"
    },
    {
      "added": "2016-04-14T19:34:24.792264Z",
      "body_html": "<blockquote><p>Ultimately the predictions will be unaffected by whether we adopt a formal testing scheme.</p></blockquote>\n\n<p>I don't really agree with that, as the self-testing here also applies when fitting the model. Correctly incorporating the prior should nevertheless mitigate this issue.</p>",
      "body_md": "> Ultimately the predictions will be unaffected by whether we adopt a formal testing scheme.\n\nI don't really agree with that, as the self-testing here also applies when fitting the model. Correctly incorporating the prior should nevertheless mitigate this issue.\n",
      "comment_id": 1221,
      "note_id": 241,
      "profile_id": 23,
      "url": "/discussion/network-edge-prediction-how-to-deal-with-self-testing/194#note-241"
    },
    {
      "added": "2016-04-14T23:00:59.751005Z",
      "body_html": "<p>I was assuming an approach where you partition for assessing performance, but then refit on the entire dataset for your final predictions.</p>",
      "body_md": "I was assuming an approach where you partition for assessing performance, but then refit on the entire dataset for your final predictions.",
      "comment_id": 1221,
      "note_id": 242,
      "profile_id": 17,
      "url": "/discussion/network-edge-prediction-how-to-deal-with-self-testing/194#note-242"
    },
    {
      "added": "2016-04-18T17:37:29.490854Z",
      "body_html": "<p>We knew there would be a great deal of disparity, at least in the number of different values (hence the high auroc) - the surprise to me is the high value of the highest probability. Could we get the updated AUROC from this empiric prior? <br>Also, </p>\n\n<blockquote><p>The pseudo-linear relationship we see ... suggests an analytic solution may exist</p></blockquote>\n\n<p>I agree only approximately :-) The intricate relation that we see suggest on the contrary that there is no easy exact solution. We should focus on getting a good approximation.</p>",
      "body_md": "We knew there would be a great deal of disparity, at least in the number of different values (hence the high auroc) - the surprise to me is the high value of the highest probability. Could we get the updated AUROC from this empiric prior? \nAlso, \n\n>The pseudo-linear relationship we see ... suggests an analytic solution may exist\n\nI agree only approximately :-) The intricate relation that we see suggest on the contrary that there is no easy exact solution. We should focus on getting a good approximation.",
      "comment_id": 1267,
      "note_id": 244,
      "profile_id": 23,
      "url": "/discussion/network-edge-prediction-estimating-the-prior/201#note-244"
    },
    {
      "added": "2016-04-18T17:41:43.533656Z",
      "body_html": "<p>Beautiful - why not the complete square? I find it easier to read and the remaining space is left blank here anyway.</p>",
      "body_md": "Beautiful - why not the complete square? I find it easier to read and the remaining space is left blank here anyway.",
      "comment_id": 1276,
      "note_id": 245,
      "profile_id": 23,
      "url": "/discussion/describing-hetionet-v10-through-visualization-and-statistics/202#note-245"
    },
    {
      "added": "2016-04-18T17:47:20.553457Z",
      "body_html": "<p>Thanks for the reference - great read. It seems hard to implement without easy-to-use tools. Will you give it a try?</p>",
      "body_md": "Thanks for the reference - great read. It seems hard to implement without easy-to-use tools. Will you give it a try?",
      "comment_id": 1278,
      "note_id": 246,
      "profile_id": 23,
      "url": "/discussion/describing-hetionet-v10-through-visualization-and-statistics/202#note-246"
    },
    {
      "added": "2016-04-18T18:00:49.040466Z",
      "body_html": "<p>EDIT: removed because unnecessarily complicated while wrong.</p>",
      "body_md": "EDIT: removed because unnecessarily complicated while wrong.",
      "comment_id": 1269,
      "note_id": 247,
      "profile_id": 23,
      "url": "/discussion/estimating-the-complexity-of-hetnet-traversal/187#note-247"
    },
    {
      "added": "2016-04-18T18:55:45.079216Z",
      "body_html": "<p>EDIT: removed in response to the removal of <a href=\"/u/alizee\" class=\"username\">@alizee</a>'s preceding note.</p>",
      "body_md": "EDIT: removed in response to the removal of @alizee's preceding note.",
      "comment_id": 1269,
      "note_id": 248,
      "profile_id": 17,
      "url": "/discussion/estimating-the-complexity-of-hetnet-traversal/187#note-248"
    },
    {
      "added": "2016-04-19T16:28:06.987841Z",
      "body_html": "<p>I created a <a href=\"https://github.com/dhimmel/integrate/blob/e8406a94e6388ce5d5c3e136b508a1219c4fab64/viz/auto/data/hetionet-v1.0-simple.dot\" title=\"hetionet-v1.0-simple.dot\">DOT file</a> for a subnetwork of 1000 random nodes. I struggled with the <code>jhive v0.2.7</code> GUI — I couldn't figure out how to assign each node type to its own axis. The next steps would be to look into the Python hive plots packages <a href=\"https://github.com/CSB-IG/pyveplot\"><code>pyveplot</code></a> and <a href=\"https://github.com/ericmjl/hiveplot\"><code>hiveplot</code></a>. However, I'm suspicious whether hive plots will be able to handle the complexity of our hetnet. The <code>jhive</code> implementation seems to be limited to three axes.</p>",
      "body_md": "I created a [DOT file](https://github.com/dhimmel/integrate/blob/e8406a94e6388ce5d5c3e136b508a1219c4fab64/viz/auto/data/hetionet-v1.0-simple.dot \"hetionet-v1.0-simple.dot\") for a subnetwork of 1000 random nodes. I struggled with the `jhive v0.2.7` GUI -- I couldn't figure out how to assign each node type to its own axis. The next steps would be to look into the Python hive plots packages [`pyveplot`](https://github.com/CSB-IG/pyveplot) and [`hiveplot`](https://github.com/ericmjl/hiveplot). However, I'm suspicious whether hive plots will be able to handle the complexity of our hetnet. The `jhive` implementation seems to be limited to three axes.",
      "comment_id": 1278,
      "note_id": 253,
      "profile_id": 17,
      "url": "/discussion/describing-hetionet-v10-through-visualization-and-statistics/202#note-253"
    },
    {
      "added": "2016-04-19T16:36:09.973865Z",
      "body_html": "<p>I think we'd need at least 7 axes: SE + PC, C, G, A, D, S, BP + CC + MF + PW. Ideally, we could break from the polar coordinate system, so not all node-alignment-axes have to start from the same origin.</p>",
      "body_md": "I think we'd need at least 7 axes: SE + PC, C, G, A, D, S, BP + CC + MF + PW. Ideally, we could break from the polar coordinate system, so not all node-alignment-axes have to start from the same origin.",
      "comment_id": 1278,
      "note_id": 254,
      "profile_id": 17,
      "url": "/discussion/describing-hetionet-v10-through-visualization-and-statistics/202#note-254"
    },
    {
      "added": "2016-04-24T17:49:50.704531Z",
      "body_html": "<p>See the <a href=\"http://nbviewer.jupyter.org/github/dhimmel/learn/blob/f8f41e7e024733f443817c2a0353bc711bfa879e/optimize/time.ipynb\">updated notebook</a> where the silent timeout issue has been fixed. Now all queries count towards average time.</p>",
      "body_md": "See the [updated notebook](http://nbviewer.jupyter.org/github/dhimmel/learn/blob/f8f41e7e024733f443817c2a0353bc711bfa879e/optimize/time.ipynb) where the silent timeout issue has been fixed. Now all queries count towards average time.",
      "comment_id": 1269,
      "note_id": 255,
      "profile_id": 17,
      "url": "/discussion/estimating-the-complexity-of-hetnet-traversal/187#note-255"
    },
    {
      "added": "2016-05-02T17:33:02.574555Z",
      "body_html": "<p>For the intercept, it depends on the way you transform your variables to reflect the changes in the standardized coefficient. For instance, if you center your variable in addition to scaling it by the standard deviation, as your previous post suggest, you get:<br><span class=\"math\">$$ x^* = (x - \\mu_x) / \\sigma_x $$</span><br>and, <span class=\"math\">$$\\mu_x$$</span> referring to the centering parameter (here the mean):<br><span class=\"math\">$$ b_0^* = b_0 + \\sum b_x \\cdot \\mu_x $$</span></p>",
      "body_md": "For the intercept, it depends on the way you transform your variables to reflect the changes in the standardized coefficient. For instance, if you center your variable in addition to scaling it by the standard deviation, as your previous post suggest, you get:\n$$ x^* = (x - \\mu_x) / \\sigma_x $$\nand, $$\\mu_x$$ referring to the centering parameter (here the mean):\n$$ b_0^* = b_0 + \\sum b_x \\cdot \\mu_x $$",
      "comment_id": 1289,
      "note_id": 256,
      "profile_id": 23,
      "url": "/discussion/computing-standardized-logistic-regression-coefficients/205#note-256"
    },
    {
      "added": "2016-05-09T04:36:22.193390Z",
      "body_html": "<p>As far as I know, the \"freely available to all\" is not about data download. By having their current web interface, which allows anyone to freely search DrugBank, they are in compliance with the NAR Database Issue rules. You are right that the bulk download option should be disregarded by the next reviewers.</p>",
      "body_md": "As far as I know, the \"freely available to all\" is not about data download. By having their current web interface, which allows anyone to freely search DrugBank, they are in compliance with the NAR Database Issue rules. You are right that the bulk download option should be disregarded by the next reviewers.",
      "comment_id": 1303,
      "note_id": 260,
      "profile_id": 125,
      "url": "/discussion/sounding-the-alarm-on-drugbanks-new-license-and-terms-of-use/213#note-260"
    },
    {
      "added": "2016-05-09T15:45:22.914339Z",
      "body_html": "<p><a href=\"/u/larsjuhljensen\" class=\"username\">@larsjuhljensen</a>, assuming users abide by the Terms of Use, the current web interface now forbids anyone under 18 from freely searching DrugBank.</p>",
      "body_md": "@larsjuhljensen, assuming users abide by the Terms of Use, the current web interface now forbids anyone under 18 from freely searching DrugBank.",
      "comment_id": 1303,
      "note_id": 261,
      "profile_id": 17,
      "url": "/discussion/sounding-the-alarm-on-drugbanks-new-license-and-terms-of-use/213#note-261"
    },
    {
      "added": "2016-05-09T17:06:47.264543Z",
      "body_html": "<p>The 2013 paper mentions a Data Extractor <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkt1068\" class=\"citation\" data-key=\"10.1093/nar/gkt1068\">1</a>]</span>:</p>\n\n<blockquote><p>The new Data Extractor appears in all of DrugBank’s standard browse and search windows, allowing users to easily extract, download and save their current data view at any point.</p></blockquote>\n\n<p>The current <a href=\"http://www.drugbank.ca/about\">about page</a> on the website says:</p>\n\n<blockquote><p>The Data Extractor is the most sophisticated search tool for DrugBank. Users may download selected text components and sequence data from DrugBank and track the latest DrugBank statistics by clicking on the <a href=\"http://www.drugbank.ca/downloads\">Download</a> button.</p></blockquote>\n\n<p>I don't really understand what features the Data Extractor is referring to. However, if the Data Extractor includes the download functionality, I interpret the <em>NAR</em> policies to preclude password-protecting the version 4.0 download until 2018.</p>",
      "body_md": "The 2013 paper mentions a Data Extractor [@10.1093/nar/gkt1068]:\n\n> The new Data Extractor appears in all of DrugBank’s standard browse and search windows, allowing users to easily extract, download and save their current data view at any point.\n\nThe current [about page](http://www.drugbank.ca/about) on the website says:\n\n> The Data Extractor is the most sophisticated search tool for DrugBank. Users may download selected text components and sequence data from DrugBank and track the latest DrugBank statistics by clicking on the [Download](http://www.drugbank.ca/downloads) button.\n\nI don't really understand what features the Data Extractor is referring to. However, if the Data Extractor includes the download functionality, I interpret the _NAR_ policies to preclude password-protecting the version 4.0 download until 2018.",
      "comment_id": 1303,
      "note_id": 262,
      "profile_id": 17,
      "url": "/discussion/sounding-the-alarm-on-drugbanks-new-license-and-terms-of-use/213#note-262"
    },
    {
      "added": "2016-05-09T17:56:05.729356Z",
      "body_html": "<p>I completely agree with you that it seems like the people who drafted this license don't understand CC licenses. The license is either CC-BY-NC-SA 4.0 or it is not. The moment you change it in any way, such as adding additional usage restrictions, it is no longer a CC license.</p>",
      "body_md": "I completely agree with you that it seems like the people who drafted this license don't understand CC licenses. The license is either CC-BY-NC-SA 4.0 or it is not. The moment you change it in any way, such as adding additional usage restrictions, it is no longer a CC license.",
      "comment_id": 1304,
      "note_id": 263,
      "profile_id": 125,
      "url": "/discussion/sounding-the-alarm-on-drugbanks-new-license-and-terms-of-use/213#note-263"
    },
    {
      "added": "2016-05-09T17:57:55.097476Z",
      "body_html": "<p>You may be right or you may be wrong. You're only asked to accept the terms of use if you sign up for an account to download the files. It is thus unclear to me if the terms of use apply to the download files only or also to the website.</p>",
      "body_md": "You may be right or you may be wrong. You're only asked to accept the terms of use if you sign up for an account to download the files. It is thus unclear to me if the terms of use apply to the download files only or also to the website.",
      "comment_id": 1303,
      "note_id": 264,
      "profile_id": 125,
      "url": "/discussion/sounding-the-alarm-on-drugbanks-new-license-and-terms-of-use/213#note-264"
    },
    {
      "added": "2016-05-10T22:31:31.236675Z",
      "body_html": "<p>Hi Daniel, some excellent ideas here. I think the idea of an open vocabulary makes sense, and we are looking at other data sets as well that would make sense to have under an open license. We are working on improving the website terms of use as well, however keep in mind we are bound by local Alberta privacy laws (this is the origin of the requirement that users are over 18; I believe we'll be able to relax this one with some additional terms regarding consent). </p>\n\n<p>We really appreciate the time and effort you are putting into this. Thanks for that. Just a heads up that it will take us a few more days to get revised versions of our documents up for review.</p>",
      "body_md": "Hi Daniel, some excellent ideas here. I think the idea of an open vocabulary makes sense, and we are looking at other data sets as well that would make sense to have under an open license. We are working on improving the website terms of use as well, however keep in mind we are bound by local Alberta privacy laws (this is the origin of the requirement that users are over 18; I believe we'll be able to relax this one with some additional terms regarding consent). \n\nWe really appreciate the time and effort you are putting into this. Thanks for that. Just a heads up that it will take us a few more days to get revised versions of our documents up for review.",
      "comment_id": 1309,
      "note_id": 265,
      "profile_id": 241,
      "url": "/discussion/sounding-the-alarm-on-drugbanks-new-license-and-terms-of-use/213#note-265"
    },
    {
      "added": "2016-05-11T05:54:15.871325Z",
      "body_html": "<p>Noting the <a href=\"http://mycircos.iric.ca/\">myCircos webapp</a> to make circos plots online <span class=\"citation\">[<a href=\"https://doi.org/10.1101/052605\" class=\"citation\" data-key=\"10.1101/052605\">1</a>]</span>.</p>",
      "body_md": "Noting the [myCircos webapp](http://mycircos.iric.ca/) to make circos plots online [@10.1101/052605].",
      "comment_id": 1277,
      "note_id": 266,
      "profile_id": 17,
      "url": "/discussion/describing-hetionet-v10-through-visualization-and-statistics/202#note-266"
    },
    {
      "added": "2016-06-25T17:47:10.298339Z",
      "body_html": "<p>The review was published on June 23, 2016 in <em>Human Molecular Genetics</em> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/hmg/ddw160\" class=\"citation\" data-key=\"10.1093/hmg/ddw160\">1</a>]</span>.</p>",
      "body_md": "The review was published on June 23, 2016 in _Human Molecular Genetics_ [@10.1093/hmg/ddw160].",
      "comment_id": 1295,
      "note_id": 267,
      "profile_id": 17,
      "url": "/discussion/tracking-project-reuse-citation-and-publicity/113#note-267"
    },
    {
      "added": "2016-10-12T17:51:57.825721Z",
      "body_html": "<p><a href=\"/u/larsjuhljensen\" class=\"username\">@larsjuhljensen</a>, I just saw that APOC — a Neo4j plugin for \"Awesome Procedures On Cypher\" — contains <a href=\"https://neo4j-contrib.github.io/neo4j-apoc-procedures/#_graph_algorithms\">several graph algorithms</a>. Installing APOC <a href=\"https://github.com/dhimmel/hetionet/commit/687d2e22bf40f5244adeaac49724502f40b45302\">is easy</a>. It looks like <a href=\"https://neo4j-contrib.github.io/neo4j-apoc-procedures/#_graph_algorithms_work_in_progress\">some but not all algorithms</a> have edge weight support.</p>",
      "body_md": "@larsjuhljensen, I just saw that APOC -- a Neo4j plugin for \"Awesome Procedures On Cypher\" -- contains [several graph algorithms](https://neo4j-contrib.github.io/neo4j-apoc-procedures/#_graph_algorithms). Installing APOC [is easy](https://github.com/dhimmel/hetionet/commit/687d2e22bf40f5244adeaac49724502f40b45302). It looks like [some but not all algorithms](https://neo4j-contrib.github.io/neo4j-apoc-procedures/#_graph_algorithms_work_in_progress) have edge weight support.",
      "comment_id": 484,
      "note_id": 271,
      "profile_id": 17,
      "url": "/discussion/using-the-neo4j-graph-database-for-hetnets/112#note-271"
    },
    {
      "added": "2016-10-18T12:23:42.994110Z",
      "body_html": "<p>The axes in this figure are unnatural to me. If you rotated this it would be much easier for me to naturally interpret.</p>",
      "body_md": "The axes in this figure are unnatural to me. If you rotated this it would be much easier for me to naturally interpret.",
      "comment_id": 1367,
      "note_id": 272,
      "profile_id": 22,
      "url": "/discussion/prediction-in-epilepsy/224#note-272"
    },
    {
      "added": "2016-10-18T13:43:00.390257Z",
      "body_html": "<p><a href=\"/u/caseygreene\" class=\"username\">@caseygreene</a> we've been using a bit of a hack to host images for discussions. We use GitHub's drag-and-drop <a href=\"https://github.com/dhimmel/rephetio/issues/1\">image hosting in this issue</a>. Then you just take the markdown embed code that's generated and use it here.</p>",
      "body_md": "@caseygreene we've been using a bit of a hack to host images for discussions. We use GitHub's drag-and-drop [image hosting in this issue](https://github.com/dhimmel/rephetio/issues/1). Then you just take the markdown embed code that's generated and use it here.",
      "comment_id": 1371,
      "note_id": 273,
      "profile_id": 17,
      "url": "/discussion/describing-hetionet-v10-through-visualization-and-statistics/202#note-273"
    },
    {
      "added": "2016-10-18T13:46:35.362256Z",
      "body_html": "<p><a href=\"/u/caseygreene\" class=\"username\">@caseygreene</a>, I suspect you're talking about the second (two panel) figure. I agree. Additionally, the second figure adds great complexity with no more information compared to the first. I posted it here, but plan to proceed with only a <a href=\"https://github.com/dhimmel/rephetio/blob/127b094076684b40ea35f6e42aca8967afdb9f56/epilepsy/figure/epilepsy.png\" title=\"epilepsy.png on dhimmel/rephetio\">version of the first image</a> with compound labels removed..</p>",
      "body_md": "@caseygreene, I suspect you're talking about the second (two panel) figure. I agree. Additionally, the second figure adds great complexity with no more information compared to the first. I posted it here, but plan to proceed with only a [version of the first image](https://github.com/dhimmel/rephetio/blob/127b094076684b40ea35f6e42aca8967afdb9f56/epilepsy/figure/epilepsy.png \"epilepsy.png on dhimmel/rephetio\") with compound labels removed..",
      "comment_id": 1367,
      "note_id": 274,
      "profile_id": 17,
      "url": "/discussion/prediction-in-epilepsy/224#note-274"
    },
    {
      "added": "2016-10-18T13:57:16.253106Z",
      "body_html": "<p>Yes - the second portion. I think that it could be interpretable with predicted prob on the y-axis. I do agree that the first is much clearer.</p>",
      "body_md": "Yes - the second portion. I think that it could be interpretable with predicted prob on the y-axis. I do agree that the first is much clearer.",
      "comment_id": 1367,
      "note_id": 275,
      "profile_id": 22,
      "url": "/discussion/prediction-in-epilepsy/224#note-275"
    },
    {
      "added": "2016-10-18T13:59:29.861861Z",
      "body_html": "<p><a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a> : Gotcha! Edited post.</p>",
      "body_md": "@dhimmel : Gotcha! Edited post.",
      "comment_id": 1371,
      "note_id": 276,
      "profile_id": 22,
      "url": "/discussion/describing-hetionet-v10-through-visualization-and-statistics/202#note-276"
    },
    {
      "added": "2016-10-18T16:28:03.598817Z",
      "body_html": "<p>I like the black background!<br>Actually, this was the original color, but we decided to make it white for the paper. </p>",
      "body_md": "I like the black background!\nActually, this was the original color, but we decided to make it white for the paper. ",
      "comment_id": 1371,
      "note_id": 277,
      "profile_id": 20,
      "url": "/discussion/describing-hetionet-v10-through-visualization-and-statistics/202#note-277"
    },
    {
      "added": "2016-10-18T22:40:41.435714Z",
      "body_html": "<p><a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a> I would still classify as unknown because there is conflicting data. For example, it is exhibits periods of suppression with paroxysmal epileptiform discharges in cats and rats, so suppression (anti-epileptic activity) is the norm and the epileptiform discharges (ictogenic activity) is sporadic.</p>",
      "body_md": "@dhimmel I would still classify as unknown because there is conflicting data. For example, it is exhibits periods of suppression with paroxysmal epileptiform discharges in cats and rats, so suppression (anti-epileptic activity) is the norm and the epileptiform discharges (ictogenic activity) is sporadic.",
      "comment_id": 1369,
      "note_id": 278,
      "profile_id": 188,
      "url": "/discussion/prediction-in-epilepsy/224#note-278"
    },
    {
      "added": "2016-11-30T20:09:58.118792Z",
      "body_html": "<p>I'm generally happy to contribute - let me know if there are any holes that need to be plugged, and I'll let you know if I have anything or know who does. Also, whereas I'm not part of the NCATS Biomedical Translator, I am part of the NIH funded IDG Knowledge Management Central, which would be another public source of already integrated data.</p>",
      "body_md": "I'm generally happy to contribute - let me know if there are any holes that need to be plugged, and I'll let you know if I have anything or know who does. Also, whereas I'm not part of the NCATS Biomedical Translator, I am part of the NIH funded IDG Knowledge Management Central, which would be another public source of already integrated data.",
      "comment_id": 1392,
      "note_id": 279,
      "profile_id": 125,
      "url": "/discussion/brainstorming-future-directions-for-hetionet/227#note-279"
    },
    {
      "added": "2016-12-01T04:19:07.256915Z",
      "body_html": "<p>Our lab is part of the NCATS Translator program.  On a technical level, our team (led by OHSU) will mainly be extending the scigraph system mentioned above.  We will be supporting/using/building this knowledge graph with the Wikidata and BioThings projects.  More to follow on that as things take shape (just got started).  </p>\n\n<p>I've posed the question of how to organize a collaboration here to our group and will also circle back on that front - I hope that they will chime in individually here as I invited them to do.  I think github pull request structure makes sense in general.  Would like to see what specific projects would make sense to take on as a first step though.  If we are serious here, a periodic shared  virtual lab meeting would be a good step forward.  </p>\n\n<p>In terms of context, the wikidata qualifier structure is a pretty lightweight approach that suits a graph db and can be pretty expressive.  I wouldn't limit things to neo4j - there more and more solif competitors out there with different optimal uses.  e.g. I am personally quite impressed with BlazeGraph performance and its ability to host a SPARQL endpoint is compelling from the standpoint of encouraging interoperability on the Web.  </p>",
      "body_md": "Our lab is part of the NCATS Translator program.  On a technical level, our team (led by OHSU) will mainly be extending the scigraph system mentioned above.  We will be supporting/using/building this knowledge graph with the Wikidata and BioThings projects.  More to follow on that as things take shape (just got started).  \n\nI've posed the question of how to organize a collaboration here to our group and will also circle back on that front - I hope that they will chime in individually here as I invited them to do.  I think github pull request structure makes sense in general.  Would like to see what specific projects would make sense to take on as a first step though.  If we are serious here, a periodic shared  virtual lab meeting would be a good step forward.  \n\nIn terms of context, the wikidata qualifier structure is a pretty lightweight approach that suits a graph db and can be pretty expressive.  I wouldn't limit things to neo4j - there more and more solif competitors out there with different optimal uses.  e.g. I am personally quite impressed with BlazeGraph performance and its ability to host a SPARQL endpoint is compelling from the standpoint of encouraging interoperability on the Web.  ",
      "comment_id": 1392,
      "note_id": 280,
      "profile_id": 48,
      "url": "/discussion/brainstorming-future-directions-for-hetionet/227#note-280"
    },
    {
      "added": "2016-12-01T04:27:45.739328Z",
      "body_html": "<p>SemMedDB (created using <a href=\"https://semrep.nlm.nih.gov\">SemRep</a> which you can install locally) is a good general purpose starting point.  It certainly has a lot of good content in it, but it also has a pretty high false positive rate at both the concept tagging and relation prediction levels.  I think for any given entity type, say genes, you could make or find a better tagger (e.g. BANNER) and that the same could be said for most of the relations.  Getting all those different systems running at PubMed scale would be hard but could be worthwhile..  Though the license isn't perfect, the intent is very clearly along the lines of what we hope to see: \"SKR resources are available to all requesters, both within and outside the United States, at no charge. \"  and I doubt very much there would be any real legal ramifications of using the tools or their outputs.  </p>\n\n<p>Improving the quality of SemMedDB is something I've been hoping to work on with a crowdsourcing/machine learning angle for some time.  One of the main ideas behind knowledge.bio and the reason we seeded it at first with Semmed content was to attract expert users to flag correct and incorrect assertions..  </p>",
      "body_md": "SemMedDB (created using [SemRep](https://semrep.nlm.nih.gov) which you can install locally) is a good general purpose starting point.  It certainly has a lot of good content in it, but it also has a pretty high false positive rate at both the concept tagging and relation prediction levels.  I think for any given entity type, say genes, you could make or find a better tagger (e.g. BANNER) and that the same could be said for most of the relations.  Getting all those different systems running at PubMed scale would be hard but could be worthwhile..  Though the license isn't perfect, the intent is very clearly along the lines of what we hope to see: \"SKR resources are available to all requesters, both within and outside the United States, at no charge. \"  and I doubt very much there would be any real legal ramifications of using the tools or their outputs.  \n\nImproving the quality of SemMedDB is something I've been hoping to work on with a crowdsourcing/machine learning angle for some time.  One of the main ideas behind knowledge.bio and the reason we seeded it at first with Semmed content was to attract expert users to flag correct and incorrect assertions..  ",
      "comment_id": 1393,
      "note_id": 281,
      "profile_id": 48,
      "url": "/discussion/brainstorming-future-directions-for-hetionet/227#note-281"
    },
    {
      "added": "2016-12-01T04:30:59.429008Z",
      "body_html": "<p>We have had several folks attempt to Snorkel and before that to use raw DeepDive with very limited success so far.  Conceptually it seems completely awesome and exactly the right way to go.  The implementation(s) have been in a serious state of flux and that has made it a challenge to use.  I still like it and and I know Chris Re is keen to get more use in the biomedical space.  Perhaps this is an area where joining forces would help tip the balance.  </p>",
      "body_md": "We have had several folks attempt to Snorkel and before that to use raw DeepDive with very limited success so far.  Conceptually it seems completely awesome and exactly the right way to go.  The implementation(s) have been in a serious state of flux and that has made it a challenge to use.  I still like it and and I know Chris Re is keen to get more use in the biomedical space.  Perhaps this is an area where joining forces would help tip the balance.  ",
      "comment_id": 1397,
      "note_id": 282,
      "profile_id": 48,
      "url": "/discussion/brainstorming-future-directions-for-hetionet/227#note-282"
    },
    {
      "added": "2016-12-02T17:10:07.621062Z",
      "body_html": "<p>But I don't think hypercholesterolemia is an independent risk factor for hypertension...</p>",
      "body_md": "But I don't think hypercholesterolemia is an independent risk factor for hypertension...",
      "comment_id": 1403,
      "note_id": 283,
      "profile_id": 80,
      "url": "/discussion/incorporating-drugcentral-data-in-our-network/186#note-283"
    },
    {
      "added": "2016-12-03T18:44:44.741804Z",
      "body_html": "<p><a href=\"/u/b_good\" class=\"username\">@b_good</a> I think this is a very fair take, and we're excited to tip that balance!  Working with a bunch of our \"local\" colaborators at Stanford, we've been having a lot of success using Snorkel.  However, it's certainly still at a stage where our active involvement–both for help/bugfixes and active collaboration on code development–seems to be a big help, in part since the code is evolving so rapidly in response to feedback.  We're hoping that it will begin to increasingly stabilize soon; and any feedback you have for us on how we could make it easier to use would be greatly appreciated, either via github issues, a skype call, or on this platform!</p>\n\n<p><a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a> A few quick notes on your notes:</p>\n\n<ul><li><p>Regarding your point about not having to create an entirely new pipeline for each relation (edge) type: This is indeed an area we're very excited about!  To clarify: in a standard ML approach to relation extraction, you would indeed have to set up a new pipeline for each relation type- most annoyingly, you'd have to hand label training data for each one.  In our approach, you have to write labeling functions (LFs)–just python fns in Snorkel–but then you can potentially share some of these across multiple relation types.  And as I was getting excited about on our call, we're starting to work on automating this \"sharing\" of supervision signal within a multi-relation extraction project...</p></li><li><p>Re: Data processing &amp; test set curation: To reiterate what we discussed, we'd love to get more of this data out in the open &amp; shared!  To that end, we're currently preprocessing a lot of the data (PubMed abstracts to start) and plan to post this.  This preprocessing (e.g.: running through NLP pipelines to split sentences, tokenize words, parse linguistic signals &amp; grammatical structure, and then aligning with external entity annotations) is often very messy and time consuming, even though it's not part of what we'd consider Snorkel's \"core task\".  So we're hoping to get it out of the way for people.  Any pooling of efforts here would be awesome!</p></li><li><p>Re: Error analysis: Just to be clear, I would consider error analysis as one component of the broader process of \"developing the extractor\", or more specifically for Snorkel, developing labeling functions.  And this would still not be \"direct supervision\", because you're still not hand-labeling individual examples (although you always could)</p></li></ul>\n\n<p>Anyway, very excited to chat further with everyone here!</p>\n\n<p>-Alex</p>",
      "body_md": "@b_good I think this is a very fair take, and we're excited to tip that balance!  Working with a bunch of our \"local\" colaborators at Stanford, we've been having a lot of success using Snorkel.  However, it's certainly still at a stage where our active involvement--both for help/bugfixes and active collaboration on code development--seems to be a big help, in part since the code is evolving so rapidly in response to feedback.  We're hoping that it will begin to increasingly stabilize soon; and any feedback you have for us on how we could make it easier to use would be greatly appreciated, either via github issues, a skype call, or on this platform!\n\n@dhimmel A few quick notes on your notes:\n\n- Regarding your point about not having to create an entirely new pipeline for each relation (edge) type: This is indeed an area we're very excited about!  To clarify: in a standard ML approach to relation extraction, you would indeed have to set up a new pipeline for each relation type- most annoyingly, you'd have to hand label training data for each one.  In our approach, you have to write labeling functions (LFs)--just python fns in Snorkel--but then you can potentially share some of these across multiple relation types.  And as I was getting excited about on our call, we're starting to work on automating this \"sharing\" of supervision signal within a multi-relation extraction project...\n\n- Re: Data processing & test set curation: To reiterate what we discussed, we'd love to get more of this data out in the open & shared!  To that end, we're currently preprocessing a lot of the data (PubMed abstracts to start) and plan to post this.  This preprocessing (e.g.: running through NLP pipelines to split sentences, tokenize words, parse linguistic signals & grammatical structure, and then aligning with external entity annotations) is often very messy and time consuming, even though it's not part of what we'd consider Snorkel's \"core task\".  So we're hoping to get it out of the way for people.  Any pooling of efforts here would be awesome!\n\n- Re: Error analysis: Just to be clear, I would consider error analysis as one component of the broader process of \"developing the extractor\", or more specifically for Snorkel, developing labeling functions.  And this would still not be \"direct supervision\", because you're still not hand-labeling individual examples (although you always could)\n\nAnyway, very excited to chat further with everyone here!\n\n-Alex",
      "comment_id": 1397,
      "note_id": 284,
      "profile_id": 313,
      "url": "/discussion/brainstorming-future-directions-for-hetionet/227#note-284"
    },
    {
      "added": "2016-12-04T16:46:01.268531Z",
      "body_html": "<p>answer in post below</p>",
      "body_md": "answer in post below",
      "comment_id": 1400,
      "note_id": 285,
      "profile_id": 188,
      "url": "/discussion/incorporating-drugcentral-data-in-our-network/186#note-285"
    },
    {
      "added": "2016-12-04T17:45:31.609180Z",
      "body_html": "<p>agree that this is not a rationale for saying atorva it is indicated in htn. i present this as a rationale for why we may never know the true answer.</p>\n\n<p>i also wholly agree that physicians do not regard HTN as an off-label indication for a statin. (note that this is not how \"DM\" was defined).</p>",
      "body_md": "agree that this is not a rationale for saying atorva it is indicated in htn. i present this as a rationale for why we may never know the true answer.\n\ni also wholly agree that physicians do not regard HTN as an off-label indication for a statin. (note that this is not how \"DM\" was defined).",
      "comment_id": 1407,
      "note_id": 286,
      "profile_id": 188,
      "url": "/discussion/incorporating-drugcentral-data-in-our-network/186#note-286"
    },
    {
      "added": "2016-12-04T17:53:24.376376Z",
      "body_html": "<p>It's a shorthand for disease-modifying indication. In <a href=\"https://thinklab.com/discussion/announcing-pharmacotherapydb-the-open-catalog-of-drug-therapies-for-disease/182\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d182\">PharmacotherapyDB</a>, the three physicians classified each indication as disease modifying (DM), symptomatic (SYM), or non-indication (NOT).</p>",
      "body_md": "It's a shorthand for disease-modifying indication. In [PharmacotherapyDB](https://thinklab.com/discussion/announcing-pharmacotherapydb-the-open-catalog-of-drug-therapies-for-disease/182), the three physicians classified each indication as disease modifying (DM), symptomatic (SYM), or non-indication (NOT).",
      "comment_id": 1408,
      "note_id": 287,
      "profile_id": 17,
      "url": "/discussion/incorporating-drugcentral-data-in-our-network/186#note-287"
    },
    {
      "added": "2016-12-04T17:55:33.124230Z",
      "body_html": "<p><a href=\"/u/mkgilson\" class=\"username\">@mkgilson</a> Would you be interested in doing a case study of hypertension predictions by this algorithm? For example, a case study similar to the case study done for epilepsy here (https://thinklab.com/p/rephetio). The algorithm made a great number of high probability predictions for hypertension (there can be a link to a file in thinklab here), as it did for epilepsy. We chose to do a case study of epilepsy in part because our three physician curators were all neurologists. It would be great to get input from someone who is more experienced in general internal medicine to evaluate the predictions for hypertension.</p>",
      "body_md": "@mkgilson Would you be interested in doing a case study of hypertension predictions by this algorithm? For example, a case study similar to the case study done for epilepsy here (https://thinklab.com/p/rephetio). The algorithm made a great number of high probability predictions for hypertension (there can be a link to a file in thinklab here), as it did for epilepsy. We chose to do a case study of epilepsy in part because our three physician curators were all neurologists. It would be great to get input from someone who is more experienced in general internal medicine to evaluate the predictions for hypertension.",
      "comment_id": 1399,
      "note_id": 288,
      "profile_id": 188,
      "url": "/discussion/incorporating-drugcentral-data-in-our-network/186#note-288"
    },
    {
      "added": "2016-12-04T17:56:49.030240Z",
      "body_html": "<p>note, my filter above also included pentostatin as a statin. I manually removed this in a re-post</p>",
      "body_md": "note, my filter above also included pentostatin as a statin. I manually removed this in a re-post",
      "comment_id": 1406,
      "note_id": 289,
      "profile_id": 188,
      "url": "/discussion/incorporating-drugcentral-data-in-our-network/186#note-289"
    },
    {
      "added": "2016-12-04T18:03:04.659493Z",
      "body_html": "<p>The definition of DM was a subject of great debate, and was finally defined in <a href=\"https://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95\" class=\"citation thread-citation\" data-key=\"10.15363/thinklab.d95\">this discussion</a></p>\n\n<p>Abstracted from that discussion:<br>Definitions:</p>\n\n<p>disease modifying (DM) — a drug that therapeutically changes the underlying or downstream biology of the disease<br>symptomatic (SYM) — a drug that treats a significant symptom of the disease<br>non-indication (NOT) — a drug that neither therapeutically changes the underlying or downstream biology nor treats a significant symptom of the disease<br>Guidelines:</p>\n\n<p>reasonable evidence of efficacy is required to be classified as disease modifying or symptomatic. This includes off-label use.<br>if no classification accurately describes an indication, the most appropriate (although imperfect) classification should be chosen</p>\n\n<p>Amendment 1: if a drug was previously indicated, but is no longer used due to side effects, or because there are better drugs, it is still considered DM<br>Amendment 2: it doesn't matter whether it is first line or fifth line, it's still considered DM<br>Assumptions:</p>\n\n<p>Assumption 1: DM trumps SYM. If a drug is clearly both disease modifying and also treats symptoms, then I will call it disease modifying. This is because most disease modifying drugs also treat symptoms.</p>\n\n<p>Assumption 2: SYM trumps NOT. If a drug is clearly symptomatic treatment, but can actually exacerbate the downstream biology of disease, then I chose SYM. I made this choice because this was the choice I saw most often made by AJG and CSH</p>",
      "body_md": "The definition of DM was a subject of great debate, and was finally defined in [this discussion] (https://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95)\n\nAbstracted from that discussion:\nDefinitions:\n\ndisease modifying (DM) — a drug that therapeutically changes the underlying or downstream biology of the disease\nsymptomatic (SYM) — a drug that treats a significant symptom of the disease\nnon-indication (NOT) — a drug that neither therapeutically changes the underlying or downstream biology nor treats a significant symptom of the disease\nGuidelines:\n\nreasonable evidence of efficacy is required to be classified as disease modifying or symptomatic. This includes off-label use.\nif no classification accurately describes an indication, the most appropriate (although imperfect) classification should be chosen\n\nAmendment 1: if a drug was previously indicated, but is no longer used due to side effects, or because there are better drugs, it is still considered DM\nAmendment 2: it doesn't matter whether it is first line or fifth line, it's still considered DM\nAssumptions:\n\nAssumption 1: DM trumps SYM. If a drug is clearly both disease modifying and also treats symptoms, then I will call it disease modifying. This is because most disease modifying drugs also treat symptoms.\n\nAssumption 2: SYM trumps NOT. If a drug is clearly symptomatic treatment, but can actually exacerbate the downstream biology of disease, then I chose SYM. I made this choice because this was the choice I saw most often made by AJG and CSH",
      "comment_id": 1408,
      "note_id": 290,
      "profile_id": 188,
      "url": "/discussion/incorporating-drugcentral-data-in-our-network/186#note-290"
    },
    {
      "added": "2016-12-04T19:43:02.610909Z",
      "body_html": "<p>I'd love to contribute, but don't have time, and also am probably too far from clinical practice these days. I'll bet someone at Stanford could look at this with you, though!</p>",
      "body_md": "I'd love to contribute, but don't have time, and also am probably too far from clinical practice these days. I'll bet someone at Stanford could look at this with you, though!",
      "comment_id": 1399,
      "note_id": 291,
      "profile_id": 80,
      "url": "/discussion/incorporating-drugcentral-data-in-our-network/186#note-291"
    },
    {
      "added": "2016-12-05T02:19:27.535451Z",
      "body_html": "<p>Great points. Just wanted to clarify that symptomatic treatments were not used as positives to train the model. Only disease-modifying (DM) treatments were. In fact, symptomatic treatments were considered negatives, but excluding them all together wouldn't have made a big difference (since there were 29,044 negatives, of which only 390 were symptomatic treatments).</p>",
      "body_md": "Great points. Just wanted to clarify that symptomatic treatments were not used as positives to train the model. Only disease-modifying (DM) treatments were. In fact, symptomatic treatments were considered negatives, but excluding them all together wouldn't have made a big difference (since there were 29,044 negatives, of which only 390 were symptomatic treatments).",
      "comment_id": 1413,
      "note_id": 292,
      "profile_id": 17,
      "url": "/discussion/incorporating-drugcentral-data-in-our-network/186#note-292"
    },
    {
      "added": "2016-12-06T05:58:44.881807Z",
      "body_html": "<p>see my post below about CADUET and the most likely (Occam's razor) explanation for how Atorvastatin got annotated as anti-hypertensive. I remain skeptical that this is the case, speaking from a molecular interactions perspective. the algorithm may be biased by the mixtures that feed into the system confounding factors. </p>",
      "body_md": "see my post below about CADUET and the most likely (Occam's razor) explanation for how Atorvastatin got annotated as anti-hypertensive. I remain skeptical that this is the case, speaking from a molecular interactions perspective. the algorithm may be biased by the mixtures that feed into the system confounding factors. ",
      "comment_id": 1405,
      "note_id": 293,
      "profile_id": 75,
      "url": "/discussion/incorporating-drugcentral-data-in-our-network/186#note-293"
    },
    {
      "added": "2016-12-06T22:51:41.383626Z",
      "body_html": "<p>quite nice. thank you.</p>",
      "body_md": "quite nice. thank you.",
      "comment_id": 1417,
      "note_id": 294,
      "profile_id": 188,
      "url": "/discussion/incorporating-drugcentral-data-in-our-network/186#note-294"
    },
    {
      "added": "2016-12-13T21:24:42.168929Z",
      "body_html": "<p><a href=\"/u/mkgilson\" class=\"username\">@mkgilson</a> Just to clear things up. Three different resources have been discussed for whether a drug treats a disease. First, <a href=\"http://drugcentral.org/\">DrugCentral</a> — a resource created by <a href=\"/u/TIOprea\" class=\"username\">@TIOprea</a> and <a href=\"/u/olegursu\" class=\"username\">@olegursu</a> <span class=\"citation\">[<a href=\"https://doi.org/10.1093/nar/gkw993\" class=\"citation\" data-key=\"10.1093/nar/gkw993\">1</a>]</span> — which is the main topic of this thread. Second, PharmacotherapyDB <span class=\"citation\">[<a href=\"/discussion/announcing-pharmacotherapydb-the-open-catalog-of-drug-therapies-for-disease/182\" class=\"citation\" data-key=\"10.15363/thinklab.d182\">2</a>, <a href=\"https://doi.org/10.6084/m9.figshare.3103054\" class=\"citation\" data-key=\"10.6084/m9.figshare.3103054\">3</a>]</span>, which is a catalog of physician curated indications that <a href=\"/u/pouyakhankhanian\" class=\"username\">@pouyakhankhanian</a> helped create for this study (Project Rephetio). Third, the Project Rephetio predictions available at <a href=\"http://het.io/repurpose/\">http://het.io/repurpose/</a> <span class=\"citation\">[<a href=\"/p/rephetio/report\" class=\"citation\" data-key=\"10.15363/thinklab.a7\">4</a>, <a href=\"/discussion/predictions-of-whether-a-compound-treats-a-disease/203\" class=\"citation\" data-key=\"10.15363/thinklab.d203\">5</a>]</span>. DrugCentral and PharmacotherapyDB both compiled known indications and both considered atorvastatin as a treatment for hypertension. I <a href=\"https://github.com/dhimmel/indications/issues/1\">opened an issue</a> on the PharmacotherapyDB GitHub repository, so future versions will correct this. The Project Rephetio predictions are the result of an algorithm, but are not themselves just probabilities of treatment, not definitive evidence of drug efficacy.</p>",
      "body_md": "@mkgilson Just to clear things up. Three different resources have been discussed for whether a drug treats a disease. First, [DrugCentral](http://drugcentral.org/) -- a resource created by @TIOprea and @olegursu [@10.1093/nar/gkw993] -- which is the main topic of this thread. Second, PharmacotherapyDB [@10.15363/thinklab.d182 @10.6084/m9.figshare.3103054], which is a catalog of physician curated indications that @pouyakhankhanian helped create for this study (Project Rephetio). Third, the Project Rephetio predictions available at http://het.io/repurpose/ [@10.15363/thinklab.a7 @10.15363/thinklab.d203]. DrugCentral and PharmacotherapyDB both compiled known indications and both considered atorvastatin as a treatment for hypertension. I [opened an issue](https://github.com/dhimmel/indications/issues/1) on the PharmacotherapyDB GitHub repository, so future versions will correct this. The Project Rephetio predictions are the result of an algorithm, but are not themselves just probabilities of treatment, not definitive evidence of drug efficacy.",
      "comment_id": 1414,
      "note_id": 295,
      "profile_id": 17,
      "url": "/discussion/incorporating-drugcentral-data-in-our-network/186#note-295"
    },
    {
      "added": "2016-12-14T19:47:16.203247Z",
      "body_html": "<p>Here are two references for publishing hashes of academic content to the bitcoin blockchain: a <a href=\"http://www.bgcarlisle.com/blog/2014/08/25/proof-of-prespecified-endpoints-in-medical-research-with-the-bitcoin-blockchain/\" title=\"Proof of prespecified endpoints in medical research with the bitcoin blockchain\">2014 blog post</a> and a <a href=\"https://doi.org/10.12688/f1000research.8114.2\">2016 paper</a> <span class=\"citation\">[<a href=\"https://doi.org/10.12688/f1000research.8114.2\" class=\"citation\" data-key=\"10.12688/f1000research.8114.2\">1</a>]</span>.</p>",
      "body_md": "Here are two references for publishing hashes of academic content to the bitcoin blockchain: a [2014 blog post](http://www.bgcarlisle.com/blog/2014/08/25/proof-of-prespecified-endpoints-in-medical-research-with-the-bitcoin-blockchain/ \"Proof of prespecified endpoints in medical research with the bitcoin blockchain\") and a [2016 paper](https://doi.org/10.12688/f1000research.8114.2) [@10.12688/f1000research.8114.2].",
      "comment_id": 396,
      "note_id": 296,
      "profile_id": 17,
      "url": "/discussion/one-network-to-rule-them-all/102#note-296"
    },
    {
      "added": "2016-12-16T01:19:59.886382Z",
      "body_html": "<p>Agree with \"I think it's useful for following up on specific predictions and highlighting mechanisms of drug efficacy\". Especially if the function to display this result is embedded in a button on the neo4j interface.</p>\n\n<p>I'd love to see the weight given to various nodes in the top predictions for epilepsy, especially the ones in the top 100 which were not classified as AEDs. </p>",
      "body_md": "Agree with \"I think it's useful for following up on specific predictions and highlighting mechanisms of drug efficacy\". Especially if the function to display this result is embedded in a button on the neo4j interface.\n\nI'd love to see the weight given to various nodes in the top predictions for epilepsy, especially the ones in the top 100 which were not classified as AEDs. ",
      "comment_id": 1446,
      "note_id": 297,
      "profile_id": 188,
      "url": "/discussion/decomposing-the-dwpc-to-assess-intermediate-node-or-edge-contributions/228#note-297"
    },
    {
      "added": "2017-01-04T17:06:48.460957Z",
      "body_html": "<p>Thanks <a href=\"/u/b_good\" class=\"username\">@b_good</a> and <a href=\"/u/alexratner\" class=\"username\">@alexratner</a> for weighing in. The Greene Lab has got a new rotation  student, David Nicholson, who is interesting in piloting Snorkel. We <a href=\"https://github.com/greenelab/snorkeling/issues/1\">were thinking</a> of starting with <em>Compound–treats–Disease</em> relationships. The project is on GitHub at <a href=\"https://github.com/greenelab/snorkeling\"><code>greenelab/snorkeling</code></a>. Your time permitting, <a href=\"/u/b_good\" class=\"username\">@b_good</a> we'd love your involvement, especially in the early stages where your feedback will lead us down the right path. <a href=\"/u/b_good\" class=\"username\">@b_good</a>, do you have a GitHub handle?</p>",
      "body_md": "Thanks @b_good and @alexratner for weighing in. The Greene Lab has got a new rotation  student, David Nicholson, who is interesting in piloting Snorkel. We [were thinking](https://github.com/greenelab/snorkeling/issues/1) of starting with _Compound–treats–Disease_ relationships. The project is on GitHub at [`greenelab/snorkeling`](https://github.com/greenelab/snorkeling). Your time permitting, @b_good we'd love your involvement, especially in the early stages where your feedback will lead us down the right path. @b_good, do you have a GitHub handle?",
      "comment_id": 1397,
      "note_id": 298,
      "profile_id": 17,
      "url": "/discussion/brainstorming-future-directions-for-hetionet/227#note-298"
    },
    {
      "added": "2017-01-05T06:30:59.637206Z",
      "body_html": "<p><a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a> would love to be involved but am currently on family leave.  (Back in February).  Suggest engaging with <a href=\"/u/tongli\" class=\"username\">@tongli</a> from our lab.  I believe he has the most relevant  experience to offer and can connect you to other lab members (active and departed) that have worked with it.  Obviously <a href=\"/u/alexratner\" class=\"username\">@alexratner</a> is probably your best resource here :)..</p>",
      "body_md": "@dhimmel would love to be involved but am currently on family leave.  (Back in February).  Suggest engaging with @tongli from our lab.  I believe he has the most relevant  experience to offer and can connect you to other lab members (active and departed) that have worked with it.  Obviously @alexratner is probably your best resource here :)..",
      "comment_id": 1397,
      "note_id": 299,
      "profile_id": 48,
      "url": "/discussion/brainstorming-future-directions-for-hetionet/227#note-299"
    },
    {
      "added": "2017-01-05T15:24:49.803241Z",
      "body_html": "<p><a href=\"/u/b_good\" class=\"username\">@b_good</a> ah yes, congrats on <a href=\"https://twitter.com/bgood/status/808069248543096832\">Version 3.0</a>. Enjoy the time away — will try not to bother you.</p>\n\n<p><a href=\"/u/tongli\" class=\"username\">@tongli</a> (<a href=\"https://github.com/veleritas\"><code>veleritas</code></a> on GitHub) — feel free to get involved on <code>greenelab/snorkeling</code> as little or much as you want. If interested, I can mention you for pull request review or issues where I think your input may be helpful.</p>",
      "body_md": "@b_good ah yes, congrats on [Version 3.0](https://twitter.com/bgood/status/808069248543096832). Enjoy the time away -- will try not to bother you.\n\n@tongli ([`veleritas`](https://github.com/veleritas) on GitHub) -- feel free to get involved on `greenelab/snorkeling` as little or much as you want. If interested, I can mention you for pull request review or issues where I think your input may be helpful.",
      "comment_id": 1397,
      "note_id": 300,
      "profile_id": 17,
      "url": "/discussion/brainstorming-future-directions-for-hetionet/227#note-300"
    },
    {
      "added": "2017-01-06T23:39:32.161403Z",
      "body_html": "<p><a href=\"/u/dhimmel\" class=\"username\">@dhimmel</a> quick note that you might consider starting with a relation type (or 2) that are less semantically complex and more plentiful in the research literature than 'treats'.  As you  and others have demonstrated, potential new 'treats' relations can be inferred based on specific constellations of other relations (e.g. genetic interaction, physical interaction etc).  Even if DeepDive magic can eventually start figuring out those deeper signatures automatically, its probably worth a look as a starting point..   </p>",
      "body_md": "@dhimmel quick note that you might consider starting with a relation type (or 2) that are less semantically complex and more plentiful in the research literature than 'treats'.  As you  and others have demonstrated, potential new 'treats' relations can be inferred based on specific constellations of other relations (e.g. genetic interaction, physical interaction etc).  Even if DeepDive magic can eventually start figuring out those deeper signatures automatically, its probably worth a look as a starting point..   ",
      "comment_id": 1397,
      "note_id": 301,
      "profile_id": 48,
      "url": "/discussion/brainstorming-future-directions-for-hetionet/227#note-301"
    },
    {
      "added": "2017-01-26T22:39:49.856391Z",
      "body_html": "<p>Unfortunate that the links and pie charts don't work. Still I think the links you provide to cytoscape and neo4j allow quite a bit of interaction. It is not ideal but it is better than what we've had for a lot of projects.</p>",
      "body_md": "Unfortunate that the links and pie charts don't work. Still I think the links you provide to cytoscape and neo4j allow quite a bit of interaction. It is not ideal but it is better than what we've had for a lot of projects.",
      "comment_id": 1478,
      "note_id": 302,
      "profile_id": 188,
      "url": "/discussion/visualizing-the-top-epilepsy-predictions-in-cytoscape/230#note-302"
    },
    {
      "added": "2017-01-27T06:55:36.065352Z",
      "body_html": "<p>With all due respect, I think you have overloaded your visualization with properties. By having so many different properties visualized in a single figure, it is near impossible to spot any patterns. The art of visualization is to highlight what is important; the way to do that is by not showing what is not important.</p>",
      "body_md": "With all due respect, I think you have overloaded your visualization with properties. By having so many different properties visualized in a single figure, it is near impossible to spot any patterns. The art of visualization is to highlight what is important; the way to do that is by not showing what is not important.",
      "comment_id": 1477,
      "note_id": 303,
      "profile_id": 125,
      "url": "/discussion/visualizing-the-top-epilepsy-predictions-in-cytoscape/230#note-303"
    },
    {
      "added": "2017-01-28T06:18:41.034496Z",
      "body_html": "",
      "body_md": "",
      "comment_id": 1482,
      "note_id": 304,
      "profile_id": 125,
      "url": "/discussion/visualizing-the-top-epilepsy-predictions-in-cytoscape/230#note-304"
    },
    {
      "added": "2017-01-28T06:22:12.394443Z",
      "body_html": "",
      "body_md": "",
      "comment_id": 1482,
      "note_id": 305,
      "profile_id": 125,
      "url": "/discussion/visualizing-the-top-epilepsy-predictions-in-cytoscape/230#note-305"
    },
    {
      "added": "2017-02-01T17:22:13.408727Z",
      "body_html": "<p>Care should be taken against over-interpreting the \"clusters\" in your visualization.  In particular, if you look at the drugs listed closely, you'll see that there are actually two groups with only cyproheptadine and clozapine showing any similarity that crosses the groups.  The fact that the two groups are next to each other is a simple artifact of the layout.</p>",
      "body_md": "Care should be taken against over-interpreting the \"clusters\" in your visualization.  In particular, if you look at the drugs listed closely, you'll see that there are actually two groups with only cyproheptadine and clozapine showing any similarity that crosses the groups.  The fact that the two groups are next to each other is a simple artifact of the layout.",
      "comment_id": 1486,
      "note_id": 306,
      "profile_id": 323,
      "url": "/discussion/why-we-predicted-ictogenic-tricyclic-compounds-treat-epilepsy/231#note-306"
    },
    {
      "added": "2017-02-01T18:16:15.886770Z",
      "body_html": "<p><a href=\"/u/scootermorris\" class=\"username\">@scootermorris</a> great point. The 9 ictogenic tricyclic compounds can be broken into two groups based on their structures. First the <a href=\"https://en.wikipedia.org/wiki/Tricyclic_antidepressant\">tricyclic antidepressants</a> — amitriptyline, imipramine, nortriptyline, clomipramine, and desipramine — have the three connected rings with a tail. Second there's cyproheptadine, loxapine, clozapine, and amoxapine, which all have a fourth ring that is not directly touching the tricyclic structure. These four compounds seem to have diverse therapeutic applications: cyproheptadine is a first-generation antihistamine, loxapine is a typical antipsychotic, clozapine is an atypical antipsychotic, and amoxapine is a tetracyclic antidepressant. So <a href=\"/u/scootermorris\" class=\"username\">@scootermorris</a> I think you're right that the small chemical differences may actual be quite meaningful.</p>",
      "body_md": "@scootermorris great point. The 9 ictogenic tricyclic compounds can be broken into two groups based on their structures. First the [tricyclic antidepressants](https://en.wikipedia.org/wiki/Tricyclic_antidepressant) -- amitriptyline, imipramine, nortriptyline, clomipramine, and desipramine -- have the three connected rings with a tail. Second there's cyproheptadine, loxapine, clozapine, and amoxapine, which all have a fourth ring that is not directly touching the tricyclic structure. These four compounds seem to have diverse therapeutic applications: cyproheptadine is a first-generation antihistamine, loxapine is a typical antipsychotic, clozapine is an atypical antipsychotic, and amoxapine is a tetracyclic antidepressant. So @scootermorris I think you're right that the small chemical differences may actual be quite meaningful.",
      "comment_id": 1486,
      "note_id": 307,
      "profile_id": 17,
      "url": "/discussion/why-we-predicted-ictogenic-tricyclic-compounds-treat-epilepsy/231#note-307"
    },
    {
      "added": "2017-03-17T16:11:32.677847Z",
      "body_html": "<p>On March 10, 2017, we posted <a href=\"http://biorxiv.org/content/early/2017/03/10/087619\" title=\"Systematic integration of biomedical knowledge prioritizes drugs for repurposing [version 2]. bioRxiv\">version 2</a> of the preprint on bioRxiv <span class=\"citation\">[<a href=\"https://doi.org/10.1101/087619\" class=\"citation \" data-key=\"10.1101/087619\">1</a>]</span>.</p>",
      "body_md": "On March 10, 2017, we posted [version 2](http://biorxiv.org/content/early/2017/03/10/087619 \"Systematic integration of biomedical knowledge prioritizes drugs for repurposing [version 2]. bioRxiv\") of the preprint on bioRxiv [@10.1101/087619].",
      "comment_id": 1376,
      "note_id": 308,
      "profile_id": 17,
      "url": "/discussion/tracking-project-reuse-citation-and-publicity/113#note-308"
    }
  ],
  "profiles": [
    {
      "first_name": "Jesse",
      "last_name": "Spaulding",
      "profile_id": 2,
      "url": "/u/jspauld",
      "username": "jspauld"
    },
    {
      "first_name": "Daniel",
      "last_name": "Himmelstein",
      "profile_id": 17,
      "url": "/u/dhimmel",
      "username": "dhimmel"
    },
    {
      "first_name": "Sergio",
      "last_name": "Baranzini",
      "profile_id": 20,
      "url": "/u/sergiobaranzini",
      "username": "sergiobaranzini"
    },
    {
      "first_name": "Leo",
      "last_name": "Brueggeman",
      "profile_id": 21,
      "url": "/u/leobrueggeman",
      "username": "leobrueggeman"
    },
    {
      "first_name": "Casey",
      "last_name": "Greene",
      "profile_id": 22,
      "url": "/u/caseygreene",
      "username": "caseygreene"
    },
    {
      "first_name": "Antoine",
      "last_name": "Lizee",
      "profile_id": 23,
      "url": "/u/alizee",
      "username": "alizee"
    },
    {
      "first_name": "Venkat",
      "last_name": "Malladi",
      "profile_id": 35,
      "url": "/u/vsmalladi",
      "username": "vsmalladi"
    },
    {
      "first_name": "Benjamin",
      "last_name": "Good",
      "profile_id": 48,
      "url": "/u/b_good",
      "username": "b_good"
    },
    {
      "first_name": "Ritu ",
      "last_name": "Khare",
      "profile_id": 72,
      "url": "/u/ritukhare",
      "username": "ritukhare"
    },
    {
      "first_name": "Tudor",
      "last_name": "Oprea",
      "profile_id": 75,
      "url": "/u/TIOprea",
      "username": "TIOprea"
    },
    {
      "first_name": "Allison",
      "last_name": "McCoy",
      "profile_id": 77,
      "url": "/u/allisonmccoy",
      "username": "allisonmccoy"
    },
    {
      "first_name": "Caty",
      "last_name": "Chung",
      "profile_id": 79,
      "url": "/u/cchung",
      "username": "cchung"
    },
    {
      "first_name": "Mike",
      "last_name": "Gilson",
      "profile_id": 80,
      "url": "/u/mkgilson",
      "username": "mkgilson"
    },
    {
      "first_name": "Alessandro",
      "last_name": "Didonna",
      "profile_id": 82,
      "url": "/u/alessandrodidonna",
      "username": "alessandrodidonna"
    },
    {
      "first_name": "Alex",
      "last_name": "Pankov",
      "profile_id": 84,
      "url": "/u/apankov",
      "username": "apankov"
    },
    {
      "first_name": "Marina",
      "last_name": "Sirota",
      "profile_id": 103,
      "url": "/u/marinasirota",
      "username": "marinasirota"
    },
    {
      "first_name": "Alexander",
      "last_name": "Pico",
      "profile_id": 104,
      "url": "/u/alexanderpico",
      "username": "alexanderpico"
    },
    {
      "first_name": "Raghavendran",
      "last_name": "Partha",
      "profile_id": 107,
      "url": "/u/raghavpartha",
      "username": "raghavpartha"
    },
    {
      "first_name": "Chris",
      "last_name": "Mungall",
      "profile_id": 109,
      "url": "/u/chrismungall",
      "username": "chrismungall"
    },
    {
      "first_name": "Frederic",
      "last_name": "Bastian",
      "profile_id": 111,
      "url": "/u/fbastian",
      "username": "fbastian"
    },
    {
      "first_name": "Sabrina",
      "last_name": "Chen",
      "profile_id": 112,
      "url": "/u/sabrinachen",
      "username": "sabrinachen"
    },
    {
      "first_name": "Ola",
      "last_name": "O",
      "profile_id": 113,
      "url": "/u/akolow",
      "username": "akolow"
    },
    {
      "first_name": "Dexter",
      "last_name": "Hadley",
      "profile_id": 121,
      "url": "/u/idrdex",
      "username": "idrdex"
    },
    {
      "first_name": "Lars Juhl",
      "last_name": "Jensen",
      "profile_id": 125,
      "url": "/u/larsjuhljensen",
      "username": "larsjuhljensen"
    },
    {
      "first_name": "janet",
      "last_name": "piñero",
      "profile_id": 129,
      "url": "/u/janispi",
      "username": "janispi"
    },
    {
      "first_name": "MacKenzie",
      "last_name": "Smith",
      "profile_id": 135,
      "url": "/u/mackenziesmith",
      "username": "mackenziesmith"
    },
    {
      "first_name": "Katie",
      "last_name": "Fortney",
      "profile_id": 137,
      "url": "/u/katiefortney",
      "username": "katiefortney"
    },
    {
      "first_name": "Chrissy",
      "last_name": "Hessler",
      "profile_id": 172,
      "url": "/u/chrissyhessler",
      "username": "chrissyhessler"
    },
    {
      "first_name": "Tong Shu",
      "last_name": "Li",
      "profile_id": 176,
      "url": "/u/tongli",
      "username": "tongli"
    },
    {
      "first_name": "Pouya",
      "last_name": "Khankhanian",
      "profile_id": 188,
      "url": "/u/pouyakhankhanian",
      "username": "pouyakhankhanian"
    },
    {
      "first_name": "Kathleen",
      "last_name": "Keough",
      "profile_id": 203,
      "url": "/u/kathleenk",
      "username": "kathleenk"
    },
    {
      "first_name": "Beau",
      "last_name": "Norgeot",
      "profile_id": 204,
      "url": "/u/beaunorgeot",
      "username": "beaunorgeot"
    },
    {
      "first_name": "Misha",
      "last_name": "Vysotskiy",
      "profile_id": 205,
      "url": "/u/mishavysotskiy",
      "username": "mishavysotskiy"
    },
    {
      "first_name": "Jeffrey",
      "last_name": "Kim",
      "profile_id": 206,
      "url": "/u/jeffreykim",
      "username": "jeffreykim"
    },
    {
      "first_name": "Julia",
      "last_name": "Cluceru",
      "profile_id": 208,
      "url": "/u/juliacluceru",
      "username": "juliacluceru"
    },
    {
      "first_name": "Marjorie",
      "last_name": "Imperial",
      "profile_id": 209,
      "url": "/u/marjorieimperial",
      "username": "marjorieimperial"
    },
    {
      "first_name": "Emmalyn",
      "last_name": "Chen",
      "profile_id": 210,
      "url": "/u/emmalynchen",
      "username": "emmalynchen"
    },
    {
      "first_name": "Jasleen",
      "last_name": "Sodhi",
      "profile_id": 211,
      "url": "/u/jasleensodhi",
      "username": "jasleensodhi"
    },
    {
      "first_name": "Elizabeth",
      "last_name": "Levy",
      "profile_id": 213,
      "url": "/u/elizabethlevy1",
      "username": "elizabethlevy1"
    },
    {
      "first_name": "Greg",
      "last_name": "Way",
      "profile_id": 224,
      "url": "/u/gregway",
      "username": "gregway"
    },
    {
      "first_name": "Alexey",
      "last_name": "Strokach",
      "profile_id": 226,
      "url": "/u/ostrokach",
      "username": "ostrokach"
    },
    {
      "first_name": "Craig",
      "last_name": "Knox",
      "profile_id": 241,
      "url": "/u/cknoxrun",
      "username": "cknoxrun"
    },
    {
      "first_name": "Oleg",
      "last_name": "Ursu",
      "profile_id": 242,
      "url": "/u/olegursu",
      "username": "olegursu"
    },
    {
      "first_name": "Christopher",
      "last_name": "Southan",
      "profile_id": 248,
      "url": "/u/christophersouthan",
      "username": "christophersouthan"
    },
    {
      "first_name": "Alex",
      "last_name": "Ratner",
      "profile_id": 313,
      "url": "/u/alexratner",
      "username": "alexratner"
    },
    {
      "first_name": "Gaya",
      "last_name": "Nadarajan",
      "profile_id": 315,
      "url": "/u/gaya_n",
      "username": "gaya_n"
    },
    {
      "first_name": "Hanock",
      "last_name": "Kwak",
      "profile_id": 319,
      "url": "/u/hanockkwak",
      "username": "hanockkwak"
    },
    {
      "first_name": "Scooter",
      "last_name": "Morris",
      "profile_id": 323,
      "url": "/u/scootermorris",
      "username": "scootermorris"
    }
  ],
  "retrieved": "2017-05-29T22:38:54.612793Z",
  "threads": [
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d21",
      "doi_field": null,
      "profile_id": 17,
      "published": "2015-01-14T05:55:24.808111Z",
      "subject": "How should we construct a catalog of drug indications?",
      "thread_id": 21,
      "topic_field": "Bioinformatics,Natural Language Processing,Indications,Pharmacology,Text Mining,Pubchem,Informatics,Disease Ontology",
      "url": "/discussion/how-should-we-construct-a-catalog-of-drug-indications/21",
      "views": 842
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d22",
      "doi_field": null,
      "profile_id": 17,
      "published": "2015-01-16T00:46:28.770398Z",
      "subject": "Suggestions for additional information types?",
      "thread_id": 22,
      "topic_field": "Bioinformatics,Chemoinformatics,Databases",
      "url": "/discussion/suggestions-for-additional-information-types/22",
      "views": 164
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d23",
      "doi_field": null,
      "profile_id": 2,
      "published": "2015-01-16T10:18:57.231835Z",
      "subject": "Enabling reproducibility and reuse",
      "thread_id": 23,
      "topic_field": "Reproducibility",
      "url": "/discussion/enabling-reproducibility-and-reuse/23",
      "views": 137
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d25",
      "doi_field": null,
      "profile_id": 17,
      "published": "2015-01-22T18:14:09.267876Z",
      "subject": "Seeking an open source implementation of the Gerstein-Sonnhammer-Chothia Algorithm",
      "thread_id": 25,
      "topic_field": "Python,R,Algorithms,Computer Science,SIDER,GSC Weighting,Gerstein-Sonnhammer-Chothia,Julia,Open Source Software",
      "url": "/discussion/seeking-an-open-source-implementation-of-the-gerstein-sonnhammer-chothia-algorithm/25",
      "views": 173
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d30",
      "doi_field": "10.1038/msb.2009.98",
      "profile_id": 17,
      "published": "2015-02-13T02:25:05.517557Z",
      "subject": "Assessing the quality and applicability of the SIDER 2 resource",
      "thread_id": 30,
      "topic_field": "SIDER,Indications,NLP,Drugs,Side Effects,Drug Labels",
      "url": "/discussion/assessing-the-quality-and-applicability-of-the-sider-2-resource/30",
      "views": 172
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d31",
      "doi_field": "10.1136/amiajnl-2012-001431",
      "profile_id": 17,
      "published": "2015-02-17T02:21:47.729396Z",
      "subject": "MEDI indications data — discrepancy in resource-specific counts",
      "thread_id": 31,
      "topic_field": "SIDER,Indications,NLP,MEDI,Wikipedia,MedlinePlus,ICD9,UMLS,RxNorm",
      "url": "/discussion/medi-indications-data-discrepancy-in-resource-specific-counts/31",
      "views": 106
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d34",
      "doi_field": null,
      "profile_id": 17,
      "published": "2015-02-27T19:35:36.720301Z",
      "subject": "Using Entrez Gene as our gene vocabulary",
      "thread_id": 34,
      "topic_field": "Databases,HGNC,Genes,Entrez Gene",
      "url": "/discussion/using-entrez-gene-as-our-gene-vocabulary/34",
      "views": 257
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d39",
      "doi_field": "10.1038/75556",
      "profile_id": 17,
      "published": "2015-03-12T16:26:39.575818Z",
      "subject": "Compiling Gene Ontology annotations into an easy-to-use format",
      "thread_id": 39,
      "topic_field": "GO,Propagation,Gene Ontology",
      "url": "/discussion/compiling-gene-ontology-annotations-into-an-easy-to-use-format/39",
      "views": 339
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d40",
      "doi_field": null,
      "profile_id": 17,
      "published": "2015-03-16T23:22:11.497921Z",
      "subject": "Unifying drug vocabularies",
      "thread_id": 40,
      "topic_field": "Drugs,Small Molecules,Compounds,Terminologies,Standards,Mapping,DrugBank,UniChem,InChI",
      "url": "/discussion/unifying-drug-vocabularies/40",
      "views": 408
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d41",
      "doi_field": "10.1186/gb-2012-13-1-r5",
      "profile_id": 35,
      "published": "2015-03-19T19:15:53.241554Z",
      "subject": "Tissue Node",
      "thread_id": 41,
      "topic_field": "Ontologies",
      "url": "/discussion/tissue-node/41",
      "views": 176
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d42",
      "doi_field": "10.1126/science.1257601",
      "profile_id": 21,
      "published": "2015-03-25T21:20:49.503543Z",
      "subject": "Mapping Incomplete Interactome disease names to MeSH",
      "thread_id": 42,
      "topic_field": "Terminologies,Mapping,Incomplete Interactome,MeSH",
      "url": "/discussion/mapping-incomplete-interactome-disease-names-to-mesh/42",
      "views": 72
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d43",
      "doi_field": "",
      "profile_id": 17,
      "published": "2015-03-27T02:43:44.010612Z",
      "subject": "Computing consensus transcriptional profiles for LINCS L1000 perturbations",
      "thread_id": 43,
      "topic_field": "LINCS,Expression Signatures,Transcriptional Profiles",
      "url": "/discussion/computing-consensus-transcriptional-profiles-for-lincs-l1000-perturbations/43",
      "views": 653
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d44",
      "doi_field": null,
      "profile_id": 17,
      "published": "2015-03-31T00:16:47.505964Z",
      "subject": "Unifying disease vocabularies",
      "thread_id": 44,
      "topic_field": "UMLS,Terminologies,Mapping,Disease Ontology,Vocabularies,Diseases,MeSH,DO",
      "url": "/discussion/unifying-disease-vocabularies/44",
      "views": 302
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d46",
      "doi_field": "10.1016/j.jbi.2014.08.004",
      "profile_id": 17,
      "published": "2015-04-02T17:16:17.459590Z",
      "subject": "Processing LabeledIn to extract indications",
      "thread_id": 46,
      "topic_field": "Indications,LabeledIn,Data Processing,Crowdsourcing",
      "url": "/discussion/processing-labeledin-to-extract-indications/46",
      "views": 139
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d47",
      "doi_field": null,
      "profile_id": 48,
      "published": "2015-04-03T04:43:56.722211Z",
      "subject": "Evaluation framework",
      "thread_id": 47,
      "topic_field": "Validation,Evalauation",
      "url": "/discussion/evaluation-framework/47",
      "views": 72
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d48",
      "doi_field": null,
      "profile_id": 48,
      "published": "2015-04-03T04:53:35.463502Z",
      "subject": "Text as a resource for network population?",
      "thread_id": 48,
      "topic_field": "Natural Language Processing,Relation Extraction,Bias,Prior Knowledge",
      "url": "/discussion/text-as-a-resource-for-network-population/48",
      "views": 100
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d51",
      "doi_field": null,
      "profile_id": 21,
      "published": "2015-04-09T00:53:23.860871Z",
      "subject": "UniChem Mapping to LINCS Small Molecules",
      "thread_id": 51,
      "topic_field": "Mapping,UniChem,LINCS",
      "url": "/discussion/unichem-mapping-to-lincs-small-molecules/51",
      "views": 431
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d52",
      "doi_field": "10.1038/ncomms5212",
      "profile_id": 21,
      "published": "2015-04-09T17:39:42.860225Z",
      "subject": "Human Symptom Disease Network-MeSH ID Matching",
      "thread_id": 52,
      "topic_field": "HSDN",
      "url": "/discussion/human-symptom-disease-network-mesh-id-matching/52",
      "views": 371
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d53",
      "doi_field": "10.1093/nar/gkl999",
      "profile_id": 17,
      "published": "2015-04-13T20:32:22.752831Z",
      "subject": "Integrating drug target information from BindingDB",
      "thread_id": 53,
      "topic_field": "Databases,Compounds,BindingDB,PubChem BioAssay,Affinity,Binding Affinity,Drug Targets,ChEMBL",
      "url": "/discussion/integrating-drug-target-information-from-bindingdb/53",
      "views": 284
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d57",
      "doi_field": "10.1371/journal.pgen.1004967",
      "profile_id": 17,
      "published": "2015-04-23T03:38:31.895356Z",
      "subject": "Selecting informative ERC (evolutionary rate covariation) values between genes",
      "thread_id": 57,
      "topic_field": "Evolution,Entrez Gene,ERC,UCSC Genome Browser,Evolutionary Rate Covariation",
      "url": "/discussion/selecting-informative-erc-evolutionary-rate-covariation-values-between-genes/57",
      "views": 100
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d61",
      "doi_field": null,
      "profile_id": 17,
      "published": "2015-04-30T22:03:36.172813Z",
      "subject": "Retrieving the ingredients in RxNorm concepts",
      "thread_id": 61,
      "topic_field": "Drugs,RxNorm,Compounds,Terminologies,Ontologies,Mapping",
      "url": "/discussion/retrieving-the-ingredients-in-rxnorm-concepts/61",
      "views": 651
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d62",
      "doi_field": "10.1136/amiajnl-2012-000852",
      "profile_id": 17,
      "published": "2015-05-01T14:51:24.521647Z",
      "subject": "Extracting indications from the ehrlink resource",
      "thread_id": 62,
      "topic_field": "Databases,Indications,Clinical Informatics,EHR,Ehrlink,Medications,Health Records",
      "url": "/discussion/extracting-indications-from-the-ehrlink-resource/62",
      "views": 110
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d65",
      "doi_field": "10.1093/nar/gkt1068",
      "profile_id": 17,
      "published": "2015-05-09T06:26:06.835470Z",
      "subject": "Protein (target, carrier, transporter, and enzyme) interactions in DrugBank",
      "thread_id": 65,
      "topic_field": "Databases,DrugBank,Drug Targets",
      "url": "/discussion/protein-target-carrier-transporter-and-enzyme-interactions-in-drugbank/65",
      "views": 902
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d66",
      "doi_field": "10.1186/s12859-015-0559-3",
      "profile_id": 22,
      "published": "2015-05-09T13:55:34.587997Z",
      "subject": "KaBOB Knowledgebase",
      "thread_id": 66,
      "topic_field": "",
      "url": "/discussion/kabob-knowledgebase/66",
      "views": 130
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d67",
      "doi_field": "",
      "profile_id": 17,
      "published": "2015-05-10T21:10:43.786973Z",
      "subject": "Mining knowledge from MEDLINE articles and their indexed MeSH terms",
      "thread_id": 67,
      "topic_field": "Text Mining,MEDLINE,Pubmed,Literature Mining,MeSH",
      "url": "/discussion/mining-knowledge-from-medline-articles-and-their-indexed-mesh-terms/67",
      "views": 267
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d68",
      "doi_field": null,
      "profile_id": 17,
      "published": "2015-05-12T02:41:44.048927Z",
      "subject": "Disease Ontology feature requests",
      "thread_id": 68,
      "topic_field": "Open Source,Ontologies,Disease Ontology",
      "url": "/discussion/disease-ontology-feature-requests/68",
      "views": 140
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d70",
      "doi_field": "",
      "profile_id": 17,
      "published": "2015-05-19T02:56:31.048772Z",
      "subject": "Calculating molecular similarities between DrugBank compounds",
      "thread_id": 70,
      "topic_field": "DrugBank,Structural Similarity,Molecular Similarity,Fingerprint,Dice coefficient,Similarity,Chemical Similarity",
      "url": "/discussion/calculating-molecular-similarities-between-drugbank-compounds/70",
      "views": 219
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d71",
      "doi_field": null,
      "profile_id": 17,
      "published": "2015-06-08T18:54:53.831578Z",
      "subject": "Calculating genomic windows for GWAS lead SNPs",
      "thread_id": 71,
      "topic_field": "Genomics,Genetics,LD,Loci,HapMap,Linkage Disequilibrium,Recombination Hotspots,GWAS Catalog,1000 Genomes",
      "url": "/discussion/calculating-genomic-windows-for-gwas-lead-snps/71",
      "views": 664
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d72",
      "doi_field": null,
      "profile_id": 104,
      "published": "2015-06-09T01:15:52.882392Z",
      "subject": "Adding pathway resources to your network",
      "thread_id": 72,
      "topic_field": "Databases,Networks,Pathways",
      "url": "/discussion/adding-pathway-resources-to-your-network/72",
      "views": 148
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d80",
      "doi_field": null,
      "profile_id": 17,
      "published": "2015-06-16T20:43:50.470993Z",
      "subject": "Extracting disease-gene associations from the GWAS Catalog",
      "thread_id": 80,
      "topic_field": "DO,Disease Etiology,EFO,Association Studies,EBI,GWAS,GWAS Catalog,NHGRI,Associations",
      "url": "/discussion/extracting-disease-gene-associations-from-the-gwas-catalog/80",
      "views": 293
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d81",
      "doi_field": null,
      "profile_id": 17,
      "published": "2015-06-17T18:56:26.645203Z",
      "subject": "Tissue-specific gene expression resources",
      "thread_id": 81,
      "topic_field": "Transcription,RNASeq,Gene Expression,Tissue Specificity,Microarrays",
      "url": "/discussion/tissue-specific-gene-expression-resources/81",
      "views": 784
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d82",
      "doi_field": "10.1126/science.aaa0355",
      "profile_id": 17,
      "published": "2015-06-17T20:51:35.121449Z",
      "subject": "Processing GTEx for tissue-specific gene expression",
      "thread_id": 82,
      "topic_field": "Transcription,Gene Expression,GTEx,RNA-Seq",
      "url": "/discussion/processing-gtex-for-tissue-specific-gene-expression/82",
      "views": 644
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d83",
      "doi_field": "",
      "profile_id": 17,
      "published": "2015-06-18T04:18:56.839367Z",
      "subject": "R best practices",
      "thread_id": 83,
      "topic_field": "R,Rstats,Programming,Coding,Hadley Wickham,Style,Hadleyverse",
      "url": "/discussion/r-best-practices/83",
      "views": 1084
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d84",
      "doi_field": null,
      "profile_id": 17,
      "published": "2015-06-24T05:08:18.194553Z",
      "subject": "Python for the modern biodata scientist",
      "thread_id": 84,
      "topic_field": "Python,Computer Science,Programming,Jupyter,Coding,IPython,Notebooks",
      "url": "/discussion/python-for-the-modern-biodata-scientist/84",
      "views": 969
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d85",
      "doi_field": null,
      "profile_id": 17,
      "published": "2015-07-02T00:44:39.833696Z",
      "subject": "Creating a catalog of protein interactions",
      "thread_id": 85,
      "topic_field": "Protein Interactions,Interactions,PPI",
      "url": "/discussion/creating-a-catalog-of-protein-interactions/85",
      "views": 177
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d91",
      "doi_field": "",
      "profile_id": 17,
      "published": "2015-07-10T18:15:03.705673Z",
      "subject": "The TISSUES resource for the tissue-specificity of genes",
      "thread_id": 91,
      "topic_field": "TISSUES,Proteome,UniProtKB,Tissue Specificity,Transcriptome",
      "url": "/discussion/the-tissues-resource-for-the-tissue-specificity-of-genes/91",
      "views": 120
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d93",
      "doi_field": "",
      "profile_id": 17,
      "published": "2015-07-14T19:30:52.136138Z",
      "subject": "Disease similarity from MEDLINE topic cooccurrence",
      "thread_id": 93,
      "topic_field": "MEDLINE,Literature Mining,MeSH,Cooccurrence,Disease Similarity",
      "url": "/discussion/disease-similarity-from-medline-topic-cooccurrence/93",
      "views": 87
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d94",
      "doi_field": "10.1371/journal.pone.0049686",
      "profile_id": 17,
      "published": "2015-07-14T19:55:24.432032Z",
      "subject": "Functional disease annotations for genes using DOAF",
      "thread_id": 94,
      "topic_field": "Entrez Gene,Disease Ontology,DO,DOAF,GeneRIF,Gene Annotations",
      "url": "/discussion/functional-disease-annotations-for-genes-using-doaf/94",
      "views": 84
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d95",
      "doi_field": null,
      "profile_id": 17,
      "published": "2015-07-14T21:45:53.200462Z",
      "subject": "Expert curation of our indication catalog for disease-modifying treatments",
      "thread_id": 95,
      "topic_field": "Indications,Symptomatic Treatment,Disease-Modifying Therapy,Expert Curation",
      "url": "/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95",
      "views": 259
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d96",
      "doi_field": "",
      "profile_id": 17,
      "published": "2015-07-28T21:14:07.053888Z",
      "subject": "STARGEO: expression signatures for disease using crowdsourced GEO annotation",
      "thread_id": 96,
      "topic_field": "Gene Expression,Gene Expression Omnibus,STARGEO,GEO,STAR-GEO,Transcriptome",
      "url": "/discussion/stargeo-expression-signatures-for-disease-using-crowdsourced-geo-annotation/96",
      "views": 347
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d97",
      "doi_field": "10.1093/nar/gkv1075",
      "profile_id": 17,
      "published": "2015-08-08T23:36:57.800091Z",
      "subject": "Extracting side effects from SIDER 4",
      "thread_id": 97,
      "topic_field": "SIDER,NLP,Drugs,Side Effects,Drug Labels,Text Mining,SIDER4",
      "url": "/discussion/extracting-side-effects-from-sider-4/97",
      "views": 175
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d101",
      "doi_field": "10.1093/nar/gkv810",
      "profile_id": 17,
      "published": "2015-08-12T23:40:14.796814Z",
      "subject": "The ADEPTUS resource for expression signatures of disease",
      "thread_id": 101,
      "topic_field": "Transcription,Expression Signatures,STARGEO,ADEPTUS,Transcriptome",
      "url": "/discussion/the-adeptus-resource-for-expression-signatures-of-disease/101",
      "views": 130
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d102",
      "doi_field": null,
      "profile_id": 17,
      "published": "2015-08-14T22:24:08.006792Z",
      "subject": "One network to rule them all",
      "thread_id": 102,
      "topic_field": "Networks,Drug Repurposing,Network Biology,Dataset,Heterogeneous Network",
      "url": "/discussion/one-network-to-rule-them-all/102",
      "views": 316
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d104",
      "doi_field": null,
      "profile_id": 17,
      "published": "2015-08-17T02:56:46.304997Z",
      "subject": "Renaming ‘heterogeneous networks’ to a more concise and catchy term",
      "thread_id": 104,
      "topic_field": "Heterogeneous Networks,Heterogeneous Information Networks,Nomenclature",
      "url": "/discussion/renaming-heterogeneous-networks-to-a-more-concise-and-catchy-term/104",
      "views": 194
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d105",
      "doi_field": "10.1093/database/bav028",
      "profile_id": 17,
      "published": "2015-08-18T03:46:32.961745Z",
      "subject": "Processing DisGeNET for disease-gene relationships",
      "thread_id": 105,
      "topic_field": "Genes,Diseases,DisGeNET,Associations",
      "url": "/discussion/processing-disgenet-for-disease-gene-relationships/105",
      "views": 148
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d106",
      "doi_field": "10.1016/j.ymeth.2014.11.020",
      "profile_id": 17,
      "published": "2015-08-20T21:45:22.187428Z",
      "subject": "Processing the DISEASES resource for disease–gene relationships",
      "thread_id": 106,
      "topic_field": "Databases,Diseases,Associations",
      "url": "/discussion/processing-the-diseases-resource-for-diseasegene-relationships/106",
      "views": 78
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d107",
      "doi_field": null,
      "profile_id": 17,
      "published": "2015-08-28T19:10:38.805491Z",
      "subject": "Integrating resources with disparate licensing into an open network",
      "thread_id": 107,
      "topic_field": "Open science,Open Data,Copyright,License,Permission,Licensing,Intellectual Property,Creative Commons",
      "url": "/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107",
      "views": 494
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d108",
      "doi_field": null,
      "profile_id": 17,
      "published": "2015-09-28T18:33:52.774845Z",
      "subject": "MSigDB licensing",
      "thread_id": 108,
      "topic_field": "Copyright,Permission,Licensing,MSigDB,MIT",
      "url": "/discussion/msigdb-licensing/108",
      "views": 188
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d110",
      "doi_field": null,
      "profile_id": 17,
      "published": "2015-09-28T22:59:26.327280Z",
      "subject": "LINCS L1000 licensing",
      "thread_id": 110,
      "topic_field": "LINCS,Copyright,Licensing,MIT,L1000,Permissions",
      "url": "/discussion/lincs-l1000-licensing/110",
      "views": 375
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d111",
      "doi_field": "10.1126/science.1257601",
      "profile_id": 17,
      "published": "2015-10-02T01:58:42.504714Z",
      "subject": "Incomplete Interactome licensing",
      "thread_id": 111,
      "topic_field": "Incomplete Interactome,Permission,Licensing,Copyright Transfer,Supplement,AAAS",
      "url": "/discussion/incomplete-interactome-licensing/111",
      "views": 118
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d112",
      "doi_field": null,
      "profile_id": 17,
      "published": "2015-10-02T22:20:16.807633Z",
      "subject": "Using the neo4j graph database for hetnets",
      "thread_id": 112,
      "topic_field": "Database,Neo4J,Graphs,Graph Database,NoSQL",
      "url": "/discussion/using-the-neo4j-graph-database-for-hetnets/112",
      "views": 625
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d113",
      "doi_field": null,
      "profile_id": 17,
      "published": "2015-10-03T20:51:26.506341Z",
      "subject": "Tracking project reuse, citation, and publicity",
      "thread_id": 113,
      "topic_field": "Citations,Publicity,Media Coverage,Reuse,Attention",
      "url": "/discussion/tracking-project-reuse-citation-and-publicity/113",
      "views": 202
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d115",
      "doi_field": "",
      "profile_id": 17,
      "published": "2015-10-04T18:59:31.943591Z",
      "subject": "Assessing the informativeness of features",
      "thread_id": 115,
      "topic_field": "HNEP,Hetnets,Features,Metapaths",
      "url": "/discussion/assessing-the-informativeness-of-features/115",
      "views": 106
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d124",
      "doi_field": "10.1007/978-3-540-69828-9_12",
      "profile_id": 17,
      "published": "2015-11-04T02:25:25.390587Z",
      "subject": "Processing Bgee for tissue-specific gene presence and over/under-expression",
      "thread_id": 124,
      "topic_field": "Gene Expression,Over-Expression,Under-Expression,Bgee,Transcriptome",
      "url": "/discussion/processing-bgee-for-tissue-specific-gene-presence-and-overunder-expression/124",
      "views": 133
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d130",
      "doi_field": null,
      "profile_id": 17,
      "published": "2015-11-30T20:04:57.637787Z",
      "subject": "Licensing neo4j",
      "thread_id": 130,
      "topic_field": "Open Source,Licensing,Neo4J,GPLv3,AGPLv3",
      "url": "/discussion/licensing-neo4j/130",
      "views": 291
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d134",
      "doi_field": null,
      "profile_id": 17,
      "published": "2015-12-09T02:51:40.846273Z",
      "subject": "Path exclusion conditions",
      "thread_id": 134,
      "topic_field": "HNEP,Network Theory,Graph Theory,Hetnets,Paths",
      "url": "/discussion/path-exclusion-conditions/134",
      "views": 319
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d136",
      "doi_field": null,
      "profile_id": 17,
      "published": "2015-12-22T01:25:50.912906Z",
      "subject": "Permuting hetnets and implementing randomized edge swaps in cypher",
      "thread_id": 136,
      "topic_field": "Neo4J,Edge Swaps,Cypher,XSwap,Permutation,Hetnets",
      "url": "/discussion/permuting-hetnets-and-implementing-randomized-edge-swaps-in-cypher/136",
      "views": 105
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d162",
      "doi_field": "",
      "profile_id": 17,
      "published": "2016-02-17T19:43:44.509494Z",
      "subject": "Data nomenclature: naming and abbreviating our network types",
      "thread_id": 162,
      "topic_field": "Drug Repurposing,Nomenclature,Hetnets",
      "url": "/discussion/data-nomenclature-naming-and-abbreviating-our-network-types/162",
      "views": 158
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d171",
      "doi_field": "",
      "profile_id": 17,
      "published": "2016-02-26T17:17:30.782382Z",
      "subject": "Positive correlations between knockdown and overexpression profiles from LINCS L1000",
      "thread_id": 171,
      "topic_field": "LINCS,L1000,shRNAs,overexpression,knockdown,upregulation,downregulation",
      "url": "/discussion/positive-correlations-between-knockdown-and-overexpression-profiles-from-lincs-l1000/171",
      "views": 257
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d178",
      "doi_field": "",
      "profile_id": 17,
      "published": "2016-02-25T22:56:18.276962Z",
      "subject": "Assessing the effectiveness of our hetnet permutations",
      "thread_id": 178,
      "topic_field": "permutation,XSwap,network randomization,hetnets,hetio",
      "url": "/discussion/assessing-the-effectiveness-of-our-hetnet-permutations/178",
      "views": 71
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d181",
      "doi_field": "",
      "profile_id": 17,
      "published": "2016-03-08T20:48:53.483423Z",
      "subject": "Workshop to analyze LINCS data for the Systems Pharmacology course at UCSF",
      "thread_id": 181,
      "topic_field": "LINCS,L1000,Systems Pharmacology,UCSF,open education",
      "url": "/discussion/workshop-to-analyze-lincs-data-for-the-systems-pharmacology-course-at-ucsf/181",
      "views": 182
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d182",
      "doi_field": "",
      "profile_id": 17,
      "published": "2016-03-15T05:24:35.059545Z",
      "subject": "Announcing PharmacotherapyDB: the Open Catalog of Drug Therapies for Disease",
      "thread_id": 182,
      "topic_field": "Pharmacotherapy,Indications,PharmacotherapyDB,curation",
      "url": "/discussion/announcing-pharmacotherapydb-the-open-catalog-of-drug-therapies-for-disease/182",
      "views": 301
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d185",
      "doi_field": "",
      "profile_id": 17,
      "published": "2016-03-11T22:41:36.229906Z",
      "subject": "Assessing the imputation quality of gene expression in LINCS L1000",
      "thread_id": 185,
      "topic_field": "LINCS,L1000,gene expression,imputation,genetic perturbation,knockdown,BING,overepression,downregulation,upregulation",
      "url": "/discussion/assessing-the-imputation-quality-of-gene-expression-in-lincs-l1000/185",
      "views": 194
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d186",
      "doi_field": "",
      "profile_id": 17,
      "published": "2016-03-20T16:41:10.657363Z",
      "subject": "Incorporating DrugCentral data in our network",
      "thread_id": 186,
      "topic_field": "DrugCentral,pharmacology,Database",
      "url": "/discussion/incorporating-drugcentral-data-in-our-network/186",
      "views": 168
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d187",
      "doi_field": "",
      "profile_id": 17,
      "published": "2016-03-22T17:03:53.346144Z",
      "subject": "Estimating the complexity of hetnet traversal",
      "thread_id": 187,
      "topic_field": "complexity,runtime,optimization,Neo4J,join hints",
      "url": "/discussion/estimating-the-complexity-of-hetnet-traversal/187",
      "views": 67
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d193",
      "doi_field": "",
      "profile_id": 17,
      "published": "2016-04-01T21:13:21.069496Z",
      "subject": "Transforming DWPCs for hetnet edge prediction",
      "thread_id": 193,
      "topic_field": "IHS,transformation,DWPC,regression",
      "url": "/discussion/transforming-dwpcs-for-hetnet-edge-prediction/193",
      "views": 73
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d194",
      "doi_field": "",
      "profile_id": 23,
      "published": "2016-04-05T22:49:42.877538Z",
      "subject": "Network Edge Prediction: how to deal with self-testing",
      "thread_id": 194,
      "topic_field": "HNEP,Hetnets,Machine learning,self-testing",
      "url": "/discussion/network-edge-prediction-how-to-deal-with-self-testing/194",
      "views": 76
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d200",
      "doi_field": "",
      "profile_id": 17,
      "published": "2016-04-11T22:43:07.306129Z",
      "subject": "Measuring user contribution and content creation",
      "thread_id": 200,
      "topic_field": "analytics,contribution,content",
      "url": "/discussion/measuring-user-contribution-and-content-creation/200",
      "views": 83
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d201",
      "doi_field": "",
      "profile_id": 23,
      "published": "2016-04-15T01:44:45.372095Z",
      "subject": "Network Edge Prediction: Estimating the prior",
      "thread_id": 201,
      "topic_field": "Machine learning,Heterogeneous Networks,Hetnets,HNEP,Prior Knowledge",
      "url": "/discussion/network-edge-prediction-estimating-the-prior/201",
      "views": 76
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d202",
      "doi_field": "",
      "profile_id": 17,
      "published": "2016-04-16T21:39:16.671437Z",
      "subject": "Describing Hetionet v1.0 through visualization and statistics",
      "thread_id": 202,
      "topic_field": "hetnets,Data Visualization,Hetionet",
      "url": "/discussion/describing-hetionet-v10-through-visualization-and-statistics/202",
      "views": 220
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d203",
      "doi_field": "",
      "profile_id": 17,
      "published": "2016-05-17T18:29:23.449241Z",
      "subject": "Predictions of whether a compound treats a disease",
      "thread_id": 203,
      "topic_field": "hetnet,HNEP,pharmacology,predictions",
      "url": "/discussion/predictions-of-whether-a-compound-treats-a-disease/203",
      "views": 321
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d205",
      "doi_field": "",
      "profile_id": 17,
      "published": "2016-04-21T19:42:43.182591Z",
      "subject": "Computing standardized logistic regression coefficients",
      "thread_id": 205,
      "topic_field": "logistic regression,GLM,coefficients,statistics,regression",
      "url": "/discussion/computing-standardized-logistic-regression-coefficients/205",
      "views": 1361
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d210",
      "doi_field": "",
      "profile_id": 17,
      "published": "2016-05-04T05:28:16.441526Z",
      "subject": "Our hetnet edge prediction methodology: the modeling framework for Project Rephetio",
      "thread_id": 210,
      "topic_field": "HNEP,machine learning",
      "url": "/discussion/our-hetnet-edge-prediction-methodology-the-modeling-framework-for-project-rephetio/210",
      "views": 123
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d212",
      "doi_field": "",
      "profile_id": 17,
      "published": "2016-05-08T05:00:23.976320Z",
      "subject": "Cataloging drug–disease therapies in the ClinicalTrials.gov database",
      "thread_id": 212,
      "topic_field": "clinical trials,ClinicalTrials.gov",
      "url": "/discussion/cataloging-drugdisease-therapies-in-the-clinicaltrialsgov-database/212",
      "views": 114
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d213",
      "doi_field": "",
      "profile_id": 17,
      "published": "2016-05-08T21:35:21.435199Z",
      "subject": "Sounding the alarm on DrugBank’s new license and terms of use",
      "thread_id": 213,
      "topic_field": "DrugBank,licensing,legal",
      "url": "/discussion/sounding-the-alarm-on-drugbanks-new-license-and-terms-of-use/213",
      "views": 546
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d214",
      "doi_field": "",
      "profile_id": 17,
      "published": "2016-05-16T18:32:57.157163Z",
      "subject": "Introducing the Residual Degree Weighted Path Count (R-DWPC)",
      "thread_id": 214,
      "topic_field": "DWPC,HNEP,Residual DWPC,R-DWPC,permutation,hetnet,algorithms",
      "url": "/discussion/introducing-the-residual-degree-weighted-path-count-r-dwpc/214",
      "views": 65
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d215",
      "doi_field": "",
      "profile_id": 17,
      "published": "2016-05-16T20:03:59.544024Z",
      "subject": "Edge dropout contamination in hetnet edge prediction",
      "thread_id": 215,
      "topic_field": "HNEP,dropout contamination,overfitting",
      "url": "/discussion/edge-dropout-contamination-in-hetnet-edge-prediction/215",
      "views": 36
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d216",
      "doi_field": "",
      "profile_id": 17,
      "published": "2016-06-23T23:20:21.033963Z",
      "subject": "Hosting Hetionet in the cloud: creating a public Neo4j instance",
      "thread_id": 216,
      "topic_field": "neo4j,Neo4j Browser,Cloud,Cloud Computing,Docker",
      "url": "/discussion/hosting-hetionet-in-the-cloud-creating-a-public-neo4j-instance/216",
      "views": 262
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d220",
      "doi_field": "",
      "profile_id": 17,
      "published": "2016-06-25T18:21:47.830304Z",
      "subject": "Exploring the power of Hetionet: a Cypher query depot",
      "thread_id": 220,
      "topic_field": "Hetionet,Neo4j,Cypher,Network Biology",
      "url": "/discussion/exploring-the-power-of-hetionet-a-cypher-query-depot/220",
      "views": 144
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d224",
      "doi_field": "",
      "profile_id": 188,
      "published": "2016-09-19T04:35:42.315453Z",
      "subject": "Prediction in epilepsy",
      "thread_id": 224,
      "topic_field": "epilepsy,Hetionet",
      "url": "/discussion/prediction-in-epilepsy/224",
      "views": 123
    },
    {
      "document_id": 7,
      "doi": "10.15363/thinklab.d226",
      "doi_field": null,
      "profile_id": null,
      "published": "2017-03-10T18:32:32.758831Z",
      "subject": "",
      "thread_id": 226,
      "topic_field": "",
      "url": "/doc/7/review",
      "views": 123
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d227",
      "doi_field": "",
      "profile_id": 17,
      "published": "2016-11-19T22:35:43.933077Z",
      "subject": "Brainstorming future directions for Hetionet",
      "thread_id": 227,
      "topic_field": "applied imagination,Hetionet,hetnets,future,planning",
      "url": "/discussion/brainstorming-future-directions-for-hetionet/227",
      "views": 140
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d228",
      "doi_field": "",
      "profile_id": 17,
      "published": "2016-12-15T21:16:12.334875Z",
      "subject": "Decomposing the DWPC to assess intermediate node or edge contributions",
      "thread_id": 228,
      "topic_field": "HNEP,DWPC,algorithms,hetnet,metapath,cypher",
      "url": "/discussion/decomposing-the-dwpc-to-assess-intermediate-node-or-edge-contributions/228",
      "views": 18
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d229",
      "doi_field": "",
      "profile_id": 17,
      "published": "2016-12-21T22:32:27.980844Z",
      "subject": "Decomposing predictions into their network support",
      "thread_id": 229,
      "topic_field": "DWPC,hetnet,paths,metapaths,machine learning,algorithms",
      "url": "/discussion/decomposing-predictions-into-their-network-support/229",
      "views": 26
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d230",
      "doi_field": "",
      "profile_id": 17,
      "published": "2017-01-24T17:23:18.186900Z",
      "subject": "Visualizing the top epilepsy predictions in Cytoscape",
      "thread_id": 230,
      "topic_field": "Cytoscape,networks,compounds,visualization,epilepsy",
      "url": "/discussion/visualizing-the-top-epilepsy-predictions-in-cytoscape/230",
      "views": 70
    },
    {
      "document_id": null,
      "doi": "10.15363/thinklab.d231",
      "doi_field": "",
      "profile_id": 17,
      "published": "2017-03-10T18:32:33.097951Z",
      "subject": "Why we predicted ictogenic tricyclic compounds treat epilepsy?",
      "thread_id": 231,
      "topic_field": "epilepsy,tricyclic antidepressants,pharmacology",
      "url": "/discussion/why-we-predicted-ictogenic-tricyclic-compounds-treat-epilepsy/231",
      "views": 26
    }
  ]
}