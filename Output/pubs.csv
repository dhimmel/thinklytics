"","type","project","fields.published","fields.profile","fields.body_md","profile","time","date","weight","N","model","fn","ln","un"
"1","comments","dFoxPoperant","2015-11-25T14:23:50.156Z",157,"Below one anonymous reviewer's comments.

In humans, the transcription factor FoxP2 gene is necessary for normal development of speech and language. In flies, the only ortholog FoxP has been recently analyzed in several studies. In a report by the Miesenb6ck lab published last year in Science, a transposon induced mutant affecting one of the two (or three) isoforms of the FoxP gene was used to show a requirement of FoxP in decision making processes. In a later report by the Brembs lab published in PLOSone the very same insertion mutant was used to demonstrate a requirement of FoxP in operant self learning. One of the problems in all these studies is that no ""clean"" FoxP mutants are available and that the expression pattern of FoxP is still elusive as no antibodies work and several FoxP Gal4 lines all show different expression patterns.

The present proposal of B. Brembs aims to clarify these issues by
a) the generation of additional strains allowing the expression of shRNA,
b) generation of an Anti-FoxP monoclonal antibody
c) generation of specific mutants and Gal4 strains by RMCE complemented
d) by a behavioral analysis of the generated lines.


In principle, this proposal addresses important and highly relevant questions but unfortunately there are many (!) problems with this application which make it rather weak and in no case fundable. The preliminary work mentioned in this proposal is odd. Basically we learn that there are many RNAi lines available in the stock centers, which have a phenotype when used to silence FoxP expression but strangely do not affect FoxP expression. What does this mean? I have seen no arguments why the generation of additional RNAi strains is now all the sudden expected to yield a breakthrough result.

Quite similar we learn in the preliminary result section that many attempts to generate specific antibodies failed and yet the generation of mAbs is proposed. Again, it is unclear what we will learn and alternative strategies are not even discussed. The authors could consider the generation of HA-tagged Fosmids /I minigenes or could use homologous recombination to manipulate the gene locus accordingly.

One page 2 of the application it is stated that ""It is a technical hurdle for further mechanistic study of operant self-learning that the currently available FoxP mutant lines are insertion lines, which only affect the expression level of some of the isoforms. "" This is not true! and the applicant himself states on page 11: 

""However, as the Mi{MIC} insertion is contained within a coding exon which is spliced into all FoxP isoforms, it is likely that this insertion alone already leads to a null mutation at the FoxP locus.""

Yes, by all means the insertion of a large transposon into the open reading frame of a gene causes a mutation!!!! Why this allele, which is available in the stock centers, has not yet been analyzed so far remains mysterious. Moreover, reading the entire third section of this application ""genome editing using MiMIC"" reveals that the applicant has not understood the rational behind the MiMIC technique at all. Venken et al clearly published that ""Insertions (of the Minos-based MiMIC transposon) in coding introns can be exchanged with protein-tag cassettes to create fusion proteins to follow protein expression and perform biochemical experiments."" Importantly, insertions have to be in an intron!!!! The entire paragraph demonstrates the careless generation of this application. ""we will characterize the expression of eGFP in the MiMIC transposen"". Again, a short look into the Venken et aI., paper demonstrates the uselessness of this approach. The application requests two students. Although the entire application is far from being fundable, this request adds the dot on the i. The student is planned for the characterization of lines that are not available, characterization of antibodies that likely will not be on hand in the next two years and so on. 

In summary, this is a not well prepared application, full of mistakes and lacking some necessary preliminary data. Not at all fundable.","157",2015-11-25,2015-11-25,2,4120,"base.profile","Björn","Brembs","brembs"
"2","comments","dFoxPoperant","2015-12-01T17:15:46.913Z",157,"My reply to reviewer #1:

http://bjoern.brembs.net/2015/12/why-cutting-down-on-peer-review-will-improve-it/","157",2015-12-01,2015-12-01,2,109,"base.profile","Björn","Brembs","brembs"
"3","comments","dFoxPoperant","2015-12-01T20:33:03.696Z",2,"In @brembs's [response](http://bjoern.brembs.net/2015/12/why-cutting-down-on-peer-review-will-improve-it/) to reviewer 1's [feedback](http://thinklab.com/discussion/reviewer-1/129) he's clearly frustrated that the reviewer did not have the proper expertise to review his proposal.

And I would definitely agree that in an ideal world, reviewers would only make comments in areas where they have expertise. But here's my question: in today's world, as a practical, strategic matter, how much expertise is it realistic to expect grant reviewers to have?

The same question occurred to me as I was reviewing @alexanderpico's [Pathways4Life proposal](http://thinklab.com/p/pathways4life/proposal/1). The proposal went into quite a bit of detail about gamification strategies and software implementation. And these were things I definitely appreciated -- but was it wise to assume that the real reviewers at the NIH would have expertise in those areas? I'm asking the question because I don't know the answer.

And a final note: Thinklab aims to move us towards a world where grant writers can always expect experts in the field reviewing their proposals! We want experts involved because they can help grant writers actually improve the science! But given the world we live, I think there's another valuable service Thinklab can provide. We can help grant writers make their proposals more appealing to a broader audience -- appealing to people with a level of expertise that we would expect the real reviewers to have. 

Maybe it's a common problem that grant writers assume too much expertise from reviewers? What does everyone think?","2",2015-12-01,2015-12-01,2,1640,"base.profile","Jesse","Spaulding","jspauld"
"4","comments","dFoxPoperant","2015-12-01T21:45:44.099Z",2,"Thanks for sharing Bjoern. I really hope it was cathartic writing that response! ;) Moving ahead I'd just like to make sure everyone is on a positive, constructive footing. As I see it there's two things we can help you with:

1. We can help you improve the research plan to create the most impact in the field
2. We can help you improve the proposal to help you get funded!

So I'd like to invite everyone to join in that effort. To respond to an issues raised by reviewer #1 you can [start a new discussion](http://thinklab.com/p/dFoxPoperant/discussion) or simply reply in this thread. I've started a discussion posing the following question: [How much expertise is it realistic to expect grant reviewers to have?](http://thinklab.com/discussion/how-much-expertise-is-it-realistic-to-expect-grant-reviewers-to-have/133)

For anyone who wants to be extra helpful, I invite you to [start a full review](http://thinklab.com/p/dFoxPoperant/proposal/3/annotate) of Bjoern's proposal. ","2",2015-12-01,2015-12-01,2,989,"base.profile","Jesse","Spaulding","jspauld"
"5","comments","dFoxPoperant","2015-12-02T08:29:38.091Z",157,"Those are good and relevant questions that all of us have to consider when writing an application. In the end, it is hard to know who will receive the proposal, but this kind of proposal usually has a track record of being reviewed by experts in the field.

In Reviewer #1's comments were two main themes which I would expect anybody with at least postdoctoral experience in the broad field of neurogenetics to have heard about:
1) The issue of mRNA degradation vs. sequestration in the RNAi process is so basic and well-known that it is even covered in Wikipedia (besides our paper and my blog post). So it would have been both very easy and very quick to look it up in case it wasn't clear (it should have been clear!).
2) The distinction between polyclonal and monoclonal antibodies is not only basic undergraduate biology, their use in biomedical science generally is also currently hotly debated in very broad and prominent forums. You'd have to have slept through undergraduate classes *and* spent the last year or two in a cave, not to be aware of the differences and why monoclonal ABs are superior to polyclonal ABs.

Finally, the last major issue of Reviewer #1 was a suggestion that we had already covered in the grant, even with a figure and using different (more recent and refined) references than the one they cited. Reviewer #1 probably doesn't necessarily have to be aware of these two latest techniques we propose - that's why we mention them in the proposal and illustrate them with a figure.","157",2015-12-02,2015-12-02,2,1517,"base.profile","Björn","Brembs","brembs"
"6","comments","EdgeProject","2016-02-23T23:33:01.306Z",48,"Not sure if this discussion fits here or should wait for the larger, technical part of the proposal, but we will need to explain why we think we should do this in a dynamic manner (query the web on demand) rather than building an all-encompassing data warehouse as the first step and how we are realistically going to make this happen.

Why: The Web evolves constantly, keeping a warehouse in sync is very difficult and maintaining a very large knowledge graph (e.g. a SPARQL server) is expensive.  If answers could be gathered automatically via a distributed services that could go up and and come down, it would be more sustainable and more extensible.  

How: The workflows would be constrained according to a set of important semantic types (genes, drugs, diseases).  Based on these constraints, we would map out paths (stories) to compose the workflows.  A plugin/registry system such as BioCatalogue would be used to identify functional services that would meet the requests.  The outputs would be modeled in nanopublication RDF, integrated, and delivered to the client for rendering.  Note this would probably not be instantaneous..","48",2016-02-23,2016-02-23,2,1143,"base.profile","Benjamin","Good","b_good"
"7","comments","EdgeProject","2016-02-24T02:08:25.831Z",2,"I think if this is intended to be beneficial to the general public, there needs to be sections of the proposal that explain the value in terms the general public will understand. I would give clear examples that describe the users need, what they do in the app/website, what information is returned to them, and how it works on the backend technically.

Unfortunately I don't have the expertise to comment on the viability of the approach itself.","2",2016-02-24,2016-02-24,2,448,"base.profile","Jesse","Spaulding","jspauld"
"8","comments","EdgeProject","2016-02-24T02:08:37.415Z",2,"Seems very vague ","2",2016-02-24,2016-02-24,2,17,"base.profile","Jesse","Spaulding","jspauld"
"9","comments","EdgeProject","2016-02-24T02:08:41.227Z",2,"Maybe you should/could use some language that would be compelling to the user you are targeting?  I really couldn't make much sense of this sentence upon first reading. And maybe give an example of what a user might enter and what information they might bet back. ","2",2016-02-24,2016-02-24,2,264,"base.profile","Jesse","Spaulding","jspauld"
"10","comments","EdgeProject","2016-02-24T02:08:45.833Z",2,"It's actually not that clear to me what ""why"" means here. The question for me might be ""what is the relationship between them?"" ","2",2016-02-24,2016-02-24,2,128,"base.profile","Jesse","Spaulding","jspauld"
"11","comments","EdgeProject","2016-02-24T02:08:51.591Z",2,"Do you mean by looking at nano-publications? If so, do enough of them exist for this to be useful? ","2",2016-02-24,2016-02-24,2,99,"base.profile","Jesse","Spaulding","jspauld"
"12","comments","EdgeProject","2016-02-24T02:08:55.835Z",2,"Building a mobile application seems like a totally separate challenge that you don't necessarily need to embark upon. Why not just create a simple web interface that proves the technology and let others build a mobile app or website? Isn't creating the core technology challenging enough? ","2",2016-02-24,2016-02-24,2,289,"base.profile","Jesse","Spaulding","jspauld"
"13","comments","EdgeProject","2016-02-24T07:33:46.523Z",48,"Agreed and in the works.  Maybe, as usual, a better more specific example would help explain things better in the short space of a 1 page idea.","48",2016-02-24,2016-02-24,2,143,"base.profile","Benjamin","Good","b_good"
"14","comments","EdgeProject","2016-02-24T09:47:44.538Z",196,"Another point that we need to address is the data cleaning. One reason for the warehouse approach is that testing procedures can be built in efficiently in order to clean the data. This is much more challenging in a dynamic approach. We can argue that we make use of sources with at least some level of data cleaning in place already and that we leave the rest to the user. By suppling the user with tools to annotate and even change links themselves we give them power.","196",2016-02-24,2016-02-24,2,470,"base.profile","Kristina","Hettne","kristinahettne"
"15","comments","EdgeProject","2016-02-25T21:20:10.304Z",48,"Based on the quick, early feedback received here and on twitter we are re-writing this proposal from the ground up.  This is taking place in a google document: 
https://docs.google.com/document/d/1VoObxwVDtjHDenGpQLFNK4UCuZxuT3-RY7mDnYjLd00/edit
Not sure how best to integrate that process (rewriting) with the ThinkLab process?  Especially in an extremely small window of time..","48",2016-02-25,2016-02-25,2,381,"base.profile","Benjamin","Good","b_good"
"16","comments","EdgeProject","2016-02-26T07:00:14.080Z",2,"We've just updated the site so you can now ""End Review of Version"" from the ""Manage"" page of the proposal. I went ahead and did this for you. Thinklab is not the really intended as a tool for collaborative writing, so it makes sense that you're doing that in Google Docs. Thinklab would come back into play if you had a more complete version that you wanted to have reviewed. (There's an ""Open for Review"") button. I guess there's not a lot of time left now :)","2",2016-02-26,2016-02-26,2,460,"base.profile","Jesse","Spaulding","jspauld"
"17","comments","EdgeProject","2016-02-26T17:27:13.491Z",48,"As you can see, this is a bit of a challenge.  Typically we end up writing in Google docs until the last possible moment.  To use ThinkLab effectively would require a lot of discipline in terms of self-imposed deadlines that were sufficiently in advance of actual hard deadlines to allow for the process to unfold.  No one would argue that such discipline would improve the end-product, ThinkLab or not.  I can tell you from my personal situation over the past 2 months leading up to this particular proposal that the delay was not for lack of trying..  Just too many things to do that are all top priority.  

I think its worth thinking hard about the relationship between ThinkLab and real collaborative editing.  If you could embed a live Google doc as an entity in this framework, you might make more progress in opening up the entire process.  I'm not sure if the citable, frozen versions are the best things during the creative process.  In cases like this proposal and Toby's earlier one, I think it would be better if things could be adapted quickly in response to feedback.

Now if you could make it such that the agencies that hand out the money made ThinkLab a necessary stop on the way to submission, you would get the missing 'real' deadline that would be needed to make this really work.","48",2016-02-26,2016-02-26,2,1305,"base.profile","Benjamin","Good","b_good"
"18","comments","HHMI_Bcr_Abl","2016-01-18T23:39:45.695Z",48,"CML causes Bcr-Abl ?   Don't you mean that a  chromosomal translocation results in the fusion of Bcr and Abl which results in the new gene Bcr-Abl, whose constitutive expression produces CML?  A small figure might be nice to explain the biology. ","48",2016-01-18,2016-01-18,2,246,"base.profile","Benjamin","Good","b_good"
"19","comments","HHMI_Bcr_Abl","2016-01-18T23:40:00.075Z",48,"The figure should not come before its mention in the text.  You should not state your hypothesis a figure caption.   ","48",2016-01-18,2016-01-18,2,117,"base.profile","Benjamin","Good","b_good"
"20","comments","HHMI_Bcr_Abl","2016-01-18T23:40:12.678Z",48,"Would be better to introduce the concept first before you use it.  A knowledge network is ...   Don't depend on the figure to do that for you.   ","48",2016-01-18,2016-01-18,2,145,"base.profile","Benjamin","Good","b_good"
"21","comments","HHMI_Bcr_Abl","2016-01-18T23:40:30.706Z",48,"either drop this or expand and be specific.  The sentence limitation does not apply to all techniques. ","48",2016-01-18,2016-01-18,2,103,"base.profile","Benjamin","Good","b_good"
"22","comments","HHMI_Bcr_Abl","2016-01-18T23:40:39.684Z",48,"Not seeing how this follows from the sentence before it.  

I would take this out.   ","48",2016-01-18,2016-01-18,2,85,"base.profile","Benjamin","Good","b_good"
"23","comments","HHMI_Bcr_Abl","2016-01-18T23:41:02.461Z",48,"Seems like the first step would be to benchmark a fully automated approach to the specific task you had in mind.  (And before that, to define the specific task and why it is going to solve the biological problem) ","48",2016-01-18,2016-01-18,2,213,"base.profile","Benjamin","Good","b_good"
"24","comments","HHMI_Bcr_Abl","2016-01-18T23:41:15.576Z",48,"If this were required as written, I would not believe that this would work.  You need to show the ability to divide and conquer the problem and not depend on individuals really deeply understanding scientific literature on their own. ","48",2016-01-18,2016-01-18,2,234,"base.profile","Benjamin","Good","b_good"
"25","comments","HHMI_Bcr_Abl","2016-01-18T23:41:23.257Z",48,"Accuracy of the system is fundamental.  I don't believe the previous sentence is enough to 'ensure' it. ","48",2016-01-18,2016-01-18,2,104,"base.profile","Benjamin","Good","b_good"
"26","comments","HHMI_Bcr_Abl","2016-01-18T23:41:28.448Z",48,"You need to have a specific plan ","48",2016-01-18,2016-01-18,2,33,"base.profile","Benjamin","Good","b_good"
"27","comments","HHMI_Bcr_Abl","2016-01-18T23:41:37.712Z",48,"This section is really not very clear.   ","48",2016-01-18,2016-01-18,2,41,"base.profile","Benjamin","Good","b_good"
"28","comments","HHMI_Bcr_Abl","2016-01-18T23:41:52.907Z",48,"Up until now I was assuming the ML had something to do with the target identification step.   ","48",2016-01-18,2016-01-18,2,94,"base.profile","Benjamin","Good","b_good"
"29","comments","HHMI_Bcr_Abl","2016-01-18T23:51:24.094Z",48,"How have others previously applied machine learning or other algorithmic techniques to convert collections of non-expert judgments into high-quality, expert-level judgments ?  For example [@citation_key]:  ""Raykar, Vikas C., et al. ""Learning From Crowds."" Journal of Machine Learning Research 11 (2010): 1297-1322.""","48",2016-01-18,2016-01-18,2,315,"base.profile","Benjamin","Good","b_good"
"30","comments","HHMI_Bcr_Abl","2016-01-18T23:52:09.574Z",48,"This should remain the focus.  You should be composing the other aims much more specifically to get to here. ","48",2016-01-18,2016-01-18,2,109,"base.profile","Benjamin","Good","b_good"
"31","comments","HHMI_Bcr_Abl","2016-01-18T23:52:31.026Z",48,"these are your controls.  Can your method predict them? ","48",2016-01-18,2016-01-18,2,56,"base.profile","Benjamin","Good","b_good"
"32","comments","HHMI_Bcr_Abl","2016-01-18T23:53:00.383Z",48,"Clinicians are the wrong judges of these predictions.  (Should be scientists)  What does blinded mean here?  Do they get both predicted and known?  You are missing the computational validation step before this. ","48",2016-01-18,2016-01-18,2,211,"base.profile","Benjamin","Good","b_good"
"33","comments","HHMI_Bcr_Abl","2016-01-18T23:55:37.075Z",48,"You need stronger evidence than the one reference regarding prostate cancer to get here.  As it stands, I would not be convinced.  Further, since that work did not use crowdsourcing, why do you need to ?  If you just did exactly what they did, but enhanced their workflow through crowdsourcing, could you identify better drugs than they did?  WHy do you think so?  How similar is that to what you are planning to do here?","48",2016-01-18,2016-01-18,2,421,"base.profile","Benjamin","Good","b_good"
"34","comments","HHMI_Bcr_Abl","2016-01-18T23:56:10.300Z",48,"Seems easily estimated.   If you can predict it clearly, than its not a potential pitfall, its part of the plan.","48",2016-01-18,2016-01-18,2,112,"base.profile","Benjamin","Good","b_good"
"35","comments","HHMI_Bcr_Abl","2016-01-18T23:57:00.147Z",48,"What about using a crowd-trained machine learning model ? 

This is what I thought you were going for.  (Personally I would be much more excited about this as a direction for integration)","48",2016-01-18,2016-01-18,2,187,"base.profile","Benjamin","Good","b_good"
"36","comments","HHMI_Bcr_Abl","2016-01-18T23:57:10.478Z",48,"the significance is the medical impact ","48",2016-01-18,2016-01-18,2,39,"base.profile","Benjamin","Good","b_good"
"37","comments","HHMI_Bcr_Abl","2016-01-19T16:59:17.918Z",48,"What would be a good place to start looking for proteins impacted by the expression of Bcr-Abl ?  For example, would https://www.pharmgkb.org/pathway/PA164713427 ""Imatinib pathway"" be a good place to start?","48",2016-01-19,2016-01-19,2,206,"base.profile","Benjamin","Good","b_good"
"38","comments","HHMI_Bcr_Abl","2016-01-19T18:59:40.666Z",180,"I was under the impression that the untrained folk would be doing simple tasks. ","180",2016-01-19,2016-01-19,2,80,"base.profile","Tim","Putman","timputman"
"39","comments","HHMI_Bcr_Abl","2016-01-19T19:00:00.326Z",180,"A little redundant to use ""than what is...""  twice here ","180",2016-01-19,2016-01-19,2,56,"base.profile","Tim","Putman","timputman"
"40","comments","HHMI_Bcr_Abl","2016-01-19T19:00:28.262Z",180,"I know you mention it a few paragraphs back, but maybe a little refresher or more description on what a classifier is. ","180",2016-01-19,2016-01-19,2,119,"base.profile","Tim","Putman","timputman"
"41","comments","HHMI_Bcr_Abl","2016-01-19T19:00:55.494Z",180,"This could be expanded on.  That doesn't necessarily sound like an unfortunate thing.   ","180",2016-01-19,2016-01-19,2,88,"base.profile","Tim","Putman","timputman"
"42","comments","HHMI_Bcr_Abl","2016-01-19T19:02:19.451Z",180,"I agree that specific steps need to be added ","180",2016-01-19,2016-01-19,2,45,"base.profile","Tim","Putman","timputman"
"43","comments","HHMI_Bcr_Abl","2016-01-19T19:03:45.507Z",180,"I think that this should be expanded on.  The knowledge network is key.  By making the connections through unbiased observations, the answer will come.  Very important to make it clear what this means.","180",2016-01-19,2016-01-19,2,201,"base.profile","Tim","Putman","timputman"
"44","comments","HHMI_Bcr_Abl","2016-01-19T19:04:49.312Z",180,"I completely agree.  The free option is always more attractive","180",2016-01-19,2016-01-19,2,62,"base.profile","Tim","Putman","timputman"
"45","comments","HHMI_Bcr_Abl","2016-01-20T06:35:43.945Z",181,"This is a key motivating principle for your proposal, so would be best to find a stronger citation and/or more citations. ","181",2016-01-20,2016-01-20,2,122,"base.profile","Andrew","Su","andrewsu"
"46","comments","HHMI_Bcr_Abl","2016-01-20T06:36:11.668Z",181,"You might consider briefly relating the story of Swanson / Reynaud / fish oil here instead of these refs.  It has the advantage of saying *how* information extraction can lead to testable hypotheses in an intuitively understandable way. ","181",2016-01-20,2016-01-20,2,237,"base.profile","Andrew","Su","andrewsu"
"47","comments","HHMI_Bcr_Abl","2016-01-20T06:36:17.651Z",181,"If crowdsourcing is a central theme, then devote a paragraph to it.  Here, it's buried and easily missed. ","181",2016-01-20,2016-01-20,2,106,"base.profile","Andrew","Su","andrewsu"
"48","comments","HHMI_Bcr_Abl","2016-01-20T06:36:24.398Z",181,"will you mention feedback between crowdsourcing and text mining later?  I think this is an attractive point... ","181",2016-01-20,2016-01-20,2,111,"base.profile","Andrew","Su","andrewsu"
"49","comments","HHMI_Bcr_Abl","2016-01-20T06:36:29.701Z",181,"I'm assuming the glucose, g6p, f6p example is merely an example of a larger knowledge network.  If so, I think this is too specific -- better generalize into a schematic network. ","181",2016-01-20,2016-01-20,2,179,"base.profile","Andrew","Su","andrewsu"
"50","comments","HHMI_Bcr_Abl","2016-01-20T06:36:36.240Z",181,"Is this from Ben's PSB paper?  How do you define ""performance""?  Surprised that experts achieve 100%... ","181",2016-01-20,2016-01-20,2,104,"base.profile","Andrew","Su","andrewsu"
"51","comments","HHMI_Bcr_Abl","2016-01-20T06:36:42.030Z",181,"I don't think the figure illustrates well what the text says. ","181",2016-01-20,2016-01-20,2,62,"base.profile","Andrew","Su","andrewsu"
"52","comments","HHMI_Bcr_Abl","2016-01-20T06:36:49.644Z",181,"based on what corpus? ","181",2016-01-20,2016-01-20,2,22,"base.profile","Andrew","Su","andrewsu"
"53","comments","HHMI_Bcr_Abl","2016-01-20T06:36:56.212Z",181,"Clinicians I don't think are the target audience (nor the best people to evaluate). You need either experts in Bcr-Abl, or ideally an experimental system to evaluate your predictions.   ","181",2016-01-20,2016-01-20,2,186,"base.profile","Andrew","Su","andrewsu"
"54","comments","HHMI_Bcr_Abl","2016-01-20T06:37:23.142Z",181,"agree, turn it into a positive...","181",2016-01-20,2016-01-20,2,33,"base.profile","Andrew","Su","andrewsu"
"55","comments","HHMI_Bcr_Abl","2016-01-20T06:41:05.486Z",181,"... though also agree with Toby that the generalizability of the significant too...","181",2016-01-20,2016-01-20,2,83,"base.profile","Andrew","Su","andrewsu"
"56","comments","HHMI_Bcr_Abl","2016-01-31T05:17:47.722Z",187,"I found this figure a little too general for its ambitious goals. It feels a bit naive. I don't think glucose metabolism is a good example of a part of the knowledge network that is likely to contribute to knowledge of Bcr-Abl targets. ","187",2016-01-31,2016-01-31,2,236,"base.profile","Obi","Griffith","obigriffith"
"57","comments","HHMI_Bcr_Abl","2016-01-31T05:18:05.468Z",187,"awkward wording ","187",2016-01-31,2016-01-31,2,16,"base.profile","Obi","Griffith","obigriffith"
"58","comments","HHMI_Bcr_Abl","2016-01-31T05:18:15.719Z",187,"you haven't explained/introduced why cytoplasmic targets are of particular interest ","187",2016-01-31,2016-01-31,2,84,"base.profile","Obi","Griffith","obigriffith"
"59","comments","HHMI_Bcr_Abl","2016-01-31T05:18:26.232Z",187,"The novelty of the hybrid method is a strength of this proposal ","187",2016-01-31,2016-01-31,2,64,"base.profile","Obi","Griffith","obigriffith"
"60","comments","HHMI_Bcr_Abl","2016-01-31T05:18:35.606Z",187,"This is a bit bold. It remains to be seen whether the proposed approach will identify ANY previously unidentified targets ","187",2016-01-31,2016-01-31,2,122,"base.profile","Obi","Griffith","obigriffith"
"61","comments","HHMI_Bcr_Abl","2016-01-31T05:18:54.986Z",187,"I think you should be specific here in the sentence about what type of biological concept. Say that you have shown that groups of non-experts can identify biological concepts such as diseases, genes, etc with high accuracy. If you just say ""biological concepts"" a reader might imagine something more complex and get riled up by this statement. ","187",2016-01-31,2016-01-31,2,344,"base.profile","Obi","Griffith","obigriffith"
"62","comments","HHMI_Bcr_Abl","2016-01-31T05:20:17.819Z",187,"For the ","187",2016-01-31,2016-01-31,2,8,"base.profile","Obi","Griffith","obigriffith"
"63","comments","HHMI_Bcr_Abl","2016-01-31T05:20:24.978Z",187,"Provide an example of what you mean here ","187",2016-01-31,2016-01-31,2,41,"base.profile","Obi","Griffith","obigriffith"
"64","comments","HHMI_Bcr_Abl","2016-01-31T05:20:31.412Z",187,"It would be helpful to explain the source of these non-experts ","187",2016-01-31,2016-01-31,2,63,"base.profile","Obi","Griffith","obigriffith"
"65","comments","HHMI_Bcr_Abl","2016-01-31T05:20:38.302Z",187,"word not necessary and repeats recent use ","187",2016-01-31,2016-01-31,2,42,"base.profile","Obi","Griffith","obigriffith"
"66","comments","HHMI_Bcr_Abl","2016-01-31T05:21:08.316Z",187,"an ","187",2016-01-31,2016-01-31,2,3,"base.profile","Obi","Griffith","obigriffith"
"67","comments","HHMI_Bcr_Abl","2016-01-31T05:21:27.151Z",187,"combine ","187",2016-01-31,2016-01-31,2,8,"base.profile","Obi","Griffith","obigriffith"
"68","comments","HHMI_Bcr_Abl","2016-01-31T05:21:34.656Z",187,"This is a good opportunity for a specific hypothesis (always needed/expected in NIH-style grant applications). Rephrase as a hypothesis ","187",2016-01-31,2016-01-31,2,136,"base.profile","Obi","Griffith","obigriffith"
"69","comments","HHMI_Bcr_Abl","2016-01-31T05:21:42.031Z",187,"Again, rephrase this as specific hypothesis ","187",2016-01-31,2016-01-31,2,44,"base.profile","Obi","Griffith","obigriffith"
"70","comments","HHMI_Bcr_Abl","2016-01-31T05:21:49.012Z",187,"This is the first mention of paid online crowdsourcing platforms. It should be introduced as an approach before it can become a potential pitfall ","187",2016-01-31,2016-01-31,2,146,"base.profile","Obi","Griffith","obigriffith"
"71","comments","HHMI_Bcr_Abl","2016-01-31T05:21:54.998Z",187,"delete for redundancy ","187",2016-01-31,2016-01-31,2,22,"base.profile","Obi","Griffith","obigriffith"
"72","comments","HHMI_Bcr_Abl","2016-01-31T05:22:03.115Z",187,"emphasize the hybrid approach here ","187",2016-01-31,2016-01-31,2,35,"base.profile","Obi","Griffith","obigriffith"
"73","comments","HHMI_Bcr_Abl","2016-01-31T05:22:18.102Z",187,"This is an awkward tautology. If everyone's path is different then by saying your is no exception you mean that yours is also different?  What if your path wasn't the exception then it would be the same? Impossible.  I suggest you drop this first sentence and just begin the story of your unique journey to comp biol. ","187",2016-01-31,2016-01-31,2,318,"base.profile","Obi","Griffith","obigriffith"
"74","comments","HHMI_Bcr_Abl","2016-01-31T05:22:28.449Z",187,"explored ","187",2016-01-31,2016-01-31,2,9,"base.profile","Obi","Griffith","obigriffith"
"75","comments","HHMI_Bcr_Abl","2016-01-31T05:22:34.330Z",187,"delete ","187",2016-01-31,2016-01-31,2,7,"base.profile","Obi","Griffith","obigriffith"
"76","comments","HHMI_Bcr_Abl","2016-01-31T05:22:38.899Z",187,"field? ","187",2016-01-31,2016-01-31,2,7,"base.profile","Obi","Griffith","obigriffith"
"77","comments","HHMI_Bcr_Abl","2016-01-31T05:22:43.692Z",187,"that most inspired me ","187",2016-01-31,2016-01-31,2,22,"base.profile","Obi","Griffith","obigriffith"
"78","comments","HHMI_Bcr_Abl","2016-01-31T05:22:48.656Z",187,"delete ","187",2016-01-31,2016-01-31,2,7,"base.profile","Obi","Griffith","obigriffith"
"79","comments","HHMI_Bcr_Abl","2016-01-31T05:22:53.375Z",187,"it was biology that  ","187",2016-01-31,2016-01-31,2,21,"base.profile","Obi","Griffith","obigriffith"
"80","comments","HHMI_Bcr_Abl","2016-01-31T05:22:57.714Z",187,"Make this its own sentence. it will have greater impact that way. ","187",2016-01-31,2016-01-31,2,66,"base.profile","Obi","Griffith","obigriffith"
"81","comments","HHMI_Bcr_Abl","2016-01-31T05:23:02.119Z",187,"I think you need a comma after this ","187",2016-01-31,2016-01-31,2,36,"base.profile","Obi","Griffith","obigriffith"
"82","comments","HHMI_Bcr_Abl","2016-01-31T05:23:06.556Z",187,"This feels redundant with above. Maybe just start with ""In high school, I was ..."" ","187",2016-01-31,2016-01-31,2,83,"base.profile","Obi","Griffith","obigriffith"
"83","comments","HHMI_Bcr_Abl","2016-01-31T05:23:11.655Z",187,"Sounds better as either ""I relished the logical rigor of"" or ""I thrived on the logical rigor"" or ""I flourished in the logical rigor"" ","187",2016-01-31,2016-01-31,2,133,"base.profile","Obi","Griffith","obigriffith"
"84","comments","HHMI_Bcr_Abl","2016-01-31T05:23:16.224Z",187,"Explain just a little more what this means ","187",2016-01-31,2016-01-31,2,43,"base.profile","Obi","Griffith","obigriffith"
"85","comments","HHMI_Bcr_Abl","2016-01-31T05:23:20.993Z",187,"rephrase ","187",2016-01-31,2016-01-31,2,9,"base.profile","Obi","Griffith","obigriffith"
"86","comments","HHMI_Bcr_Abl","2016-01-31T05:23:26.084Z",187,"italicize ","187",2016-01-31,2016-01-31,2,10,"base.profile","Obi","Griffith","obigriffith"
"87","comments","HHMI_Bcr_Abl","2016-01-31T05:23:31.882Z",187,"Why raise this as a negative?  Introduce your experience studying abroad as a separate positive growth experience. ","187",2016-01-31,2016-01-31,2,115,"base.profile","Obi","Griffith","obigriffith"
"88","comments","HHMI_Bcr_Abl","2016-01-31T05:23:44.981Z",187,"further pursue my passion for? ","187",2016-01-31,2016-01-31,2,31,"base.profile","Obi","Griffith","obigriffith"
"89","comments","HHMI_Bcr_Abl","2016-01-31T05:23:53.765Z",187,"delete ","187",2016-01-31,2016-01-31,2,7,"base.profile","Obi","Griffith","obigriffith"
"90","comments","HHMI_Bcr_Abl","2016-01-31T05:23:58.051Z",187,"focused on utilizing and verifying ","187",2016-01-31,2016-01-31,2,35,"base.profile","Obi","Griffith","obigriffith"
"91","comments","HHMI_Bcr_Abl","2016-01-31T05:24:02.543Z",187,"improve outcomes ","187",2016-01-31,2016-01-31,2,17,"base.profile","Obi","Griffith","obigriffith"
"92","comments","HHMI_Bcr_Abl","2016-01-31T05:30:14.256Z",187,"I consider myself sufficiently expert on the topic to review. I really like the idea of the proposal but think it needs more polishing before it would be worthy of funding. A challenge is that I am sympathetic to the approach being proposed but a typical HHMI reviewer may not be. More work is needed to get across a strong message of how novel, ambitious, and game-changing this approach can be. You need to explain the problem that you are trying to solve (identifying potential new drug targets for bcr-abl inhibitor resistant disease from the vast knowledge trapped and unsynthesized in the biomedical literature). Then convince the reviewer that your hybrid crowd-sourcing + ML approach is an exciting and novel new way to potentially solve this problem.","187",2016-01-31,2016-01-31,2,759,"base.profile","Obi","Griffith","obigriffith"
"93","comments","HHMI_Bcr_Abl","2016-02-01T22:06:38.038Z",176,"Hi Obi,

Thanks for your feedback. I found it difficult to balance the need to provide background information for the reviewers with the need to explain why the technique is novel. The strict three page word limit is preventing me from going into the detail I would ideally want.

Did you have any general recommendations? I also agree that the proposal needs more polishing.

Best,
Toby","176",2016-02-01,2016-02-01,2,394,"base.profile","Tong Shu","Li","tongli"
"94","comments","HHMI_Bcr_Abl","2016-02-01T22:41:26.957Z",187,"I don't have any additional recommendations beyond the general comments I outline above and the specific/detailed notes I provided in my review.","187",2016-02-01,2016-02-01,2,144,"base.profile","Obi","Griffith","obigriffith"
"95","comments","HHMI_Bcr_Abl","2016-02-02T00:12:12.367Z",176,"Ok, thank you very much for reviewing my proposal.","176",2016-02-02,2016-02-02,2,50,"base.profile","Tong Shu","Li","tongli"
"96","comments","HHMI_Bcr_Abl","2016-02-05T04:47:32.837Z",17,"I had similar thoughts (written before reading Dr. Good's comment):

I am not a biologist. I have no idea what Bcr-Abl is. I am guessing it is a protein because of ""constitutively active tyrosine kinase"" but I don't fully grasp what is going on with the chromosome translocation. Without the translocation, are humans devoid of Bcr-Abl? Also searching for ""Bcr-Abl"" hasn't been helpful because ""BCR-ABL"" is a gene name. Is all CML caused by Bcr-Abl? Is all Bcr-Abl bad? ","17",2016-02-05,2016-02-05,2,470,"base.profile","Daniel","Himmelstein","dhimmel"
"97","comments","HHMI_Bcr_Abl","2016-02-05T04:50:17.185Z",17,"More Bcr-Abl confusion: are you considering a downstream protein a ""Bcr-Abl target""?","17",2016-02-05,2016-02-05,2,84,"base.profile","Daniel","Himmelstein","dhimmel"
"98","comments","HHMI_Bcr_Abl","2016-02-05T04:51:25.960Z",17,"I have a hard time understanding the ""Knowledge Network"" from Figure 1. Drawing node borders in addition to edge arrows may help. My current understanding of your network at this point in reading is that you are using text mining + crowdsourcing to construct a metabolite network.","17",2016-02-05,2016-02-05,2,280,"base.profile","Daniel","Himmelstein","dhimmel"
"99","comments","HHMI_Bcr_Abl","2016-02-05T04:52:23.718Z",17,"The paragraph up till the end of this sentence has primed me: you've led me to believe that NLP programs need to span multiple sentences. The rest of the paragraph is a complete non-sequitur. I finish the paragraph confused, having just read a list of definition with no cohesive connection. ","17",2016-02-05,2016-02-05,2,292,"base.profile","Daniel","Himmelstein","dhimmel"
"100","comments","HHMI_Bcr_Abl","2016-02-05T04:53:12.853Z",17,"Don't be vague. I would get more out of: 

> I propose combining crowdsourcing and automated text mining to identify cytoplasmic Bcr-Abl targets ","17",2016-02-05,2016-02-05,2,145,"base.profile","Daniel","Himmelstein","dhimmel"
"101","comments","HHMI_Bcr_Abl","2016-02-05T04:54:03.291Z",17,"My comment on this phrase:

I feel that this is a precondition for funding you. If in general it is unknown whether non-experts can read science publications, I don't see the point of exploring such a specific application of crowdsourcing.

Now I agree that you should evaluate whether non-experts succeed on your specific problem, but you should have examples of where non-experts read science successfully. Here is one example that non-experts understood drug labels [@10.1093/database/bav016].

Update: your next sentences answer the point, so you should assert that non-experts can from the start. ","17",2016-02-05,2016-02-05,2,602,"base.profile","Daniel","Himmelstein","dhimmel"
"102","comments","HHMI_Bcr_Abl","2016-02-05T04:54:55.389Z",17,"y-axis labels are unreadable. Either make them larger or remove them ","17",2016-02-05,2016-02-05,2,69,"base.profile","Daniel","Himmelstein","dhimmel"
"103","comments","HHMI_Bcr_Abl","2016-02-05T04:55:03.817Z",17,"Move the circles closer to increase the overlap size. The visual elicits the opposite response as the numbers. ","17",2016-02-05,2016-02-05,2,111,"base.profile","Daniel","Himmelstein","dhimmel"
"104","comments","HHMI_Bcr_Abl","2016-02-05T04:57:11.079Z",17,"What is a ""known non-targets"" and where does that knowledge come from?","17",2016-02-05,2016-02-05,2,70,"base.profile","Daniel","Himmelstein","dhimmel"
"105","comments","HHMI_Bcr_Abl","2016-02-05T04:58:10.518Z",17,"Move this citation to the first part of the sentence? ","17",2016-02-05,2016-02-05,2,54,"base.profile","Daniel","Himmelstein","dhimmel"
"106","comments","HHMI_Bcr_Abl","2016-02-05T04:59:06.171Z",17,"Details please! What are your positives and negatives? What are your predictors? All this talk of machine learning and I can't figure out what your models will predict and what datasets they will be trained and tested on. ","17",2016-02-05,2016-02-05,2,222,"base.profile","Daniel","Himmelstein","dhimmel"
"107","comments","HHMI_Bcr_Abl","2016-02-05T05:00:00.260Z",17,"A little more background is needed in the caption to appreciate Figure 3A -- performance of what? ","17",2016-02-05,2016-02-05,2,98,"base.profile","Daniel","Himmelstein","dhimmel"
"108","comments","HHMI_Bcr_Abl","2016-02-05T05:01:23.133Z",17,"The expense issue should be worked out beforehand. Given that you haven't explained the ""concept similarity method"", what's the point of introducing an alternative? You could just say we will use A if the network is sparse and B if the network is dense. ","17",2016-02-05,2016-02-05,2,254,"base.profile","Daniel","Himmelstein","dhimmel"
"109","comments","HHMI_Bcr_Abl","2016-02-05T05:01:45.740Z",17,"Is Bcr-Abl a small molecule, target, or protein therapeutic? ","17",2016-02-05,2016-02-05,2,61,"base.profile","Daniel","Himmelstein","dhimmel"
"110","comments","HHMI_Bcr_Abl","2016-02-05T05:19:40.806Z",17,"The proposal lacks a cohesive flow. I don't know how all the pieces (Bcr-Abl, CML, crowdsourcing, machine learning, NLP) fit together. I recommend telling a story. Here's an off-the-cuff example:

+ CML is a big problem.
+ The solution lies in Bcr-Abl.
+ Lot's of research has been done about Bcr-Abl, so much that no one expert can know it all.
+ In fact you couldn't even get many experts to write down all the knowledge on Brc-Abl.
+ The easiest/cheapest/fastest/most-scalable method for retrieving all the knowledge on Brc-Abl is to use automated text mining.
+ However automated text mining alone is unreliable.
+ Crowdsourcing (getting non-experts who are cheap to read through literature) allows us to evaluate and improve on the NLP. Crowdsourcing provides the necessary feedback to learn how to do the automated text mining.
+ The literature mined information fits into a network.
+ There is a network algorithm that uses the network topology to predict the solution to CML.
 
You need to present each stage as the most logical next step. Additionally, it would be nice to address the shortcomings of alternatives. For example, what is deficient about current text mining networks relating to Bcr-Abl? Shouldn't you try those first? Preferably, you can answer these questions about alternatives as part of the story.

Best of luck -- I think the proposal combines a bunch of cool and cutting edge techniques. Now you just need to communicate the logic of the approach in a clear and accessible way.","17",2016-02-05,2016-02-05,2,1521,"base.profile","Daniel","Himmelstein","dhimmel"
"111","comments","HHMI_Bcr_Abl","2016-02-05T21:36:54.786Z",176,"Hi Daniel,

Thanks for the helpful review. I agree that the proposal lacked cohesiveness and am working on a revised version now.","176",2016-02-05,2016-02-05,2,131,"base.profile","Tong Shu","Li","tongli"
"112","comments","HHMI_Bcr_Abl","2016-02-05T21:55:26.689Z",17,"> I agree that the proposal lacked cohesiveness and am working on a revised version now.

Awesome, can't wait to see the next draft. You're the first person to receive in depth proposal review on *Thinklab*, so I'm excited to see how helpful you find it. I can imagine so much feedback (currently four detailed reviews) can be a bit overwhelming, but I suspect the proposal will strengthen as a result. Consider posting your experience when done: what worked, what didn't work, and whether you'd recommend public proposal review to others.

One further piece of feedback: the techniques you propose implementing, specifically crowdsourcing and machine learning, have high upfront costs. Therefore, I feel that it's especially important to justify that they're essential to solving the problem. Otherwise, the grant reviewers may hesitate. Instead you want the reviewers to ""hesitate not, fund or fund not"".","17",2016-02-05,2016-02-05,2,910,"base.profile","Daniel","Himmelstein","dhimmel"
"113","comments","HHMI_Bcr_Abl","2016-02-05T23:19:52.284Z",176,"I would be more than happy to write up my thoughts about the review process and Thinklab itself after I submit the proposal. I will also be providing a reference to these discussions in the application itself, so maybe the HHMI reviewers will visit the site.

As for the proposal itself, I will work to have a revised version posted before the application deadline, but don't know if I will be successful. I've decided to alter the direction slightly to go after why CML stem cells are not killed by Bcr-Abl inhibitors, since after a further review of the literature it seems that this is where the field is going.","176",2016-02-05,2016-02-05,2,616,"base.profile","Tong Shu","Li","tongli"
"114","comments","HHMI_Bcr_Abl","2016-02-05T23:24:56.574Z",17,"> I will also be providing a reference to these discussions in the application itself, so maybe the HHMI reviewers will visit the site.

Great idea. I think it will impress the reviewers that the proposal has already been publicly vetted by peers.

Best of luck with the new direction!","17",2016-02-05,2016-02-05,2,289,"base.profile","Daniel","Himmelstein","dhimmel"
"115","comments","meta","2015-01-15T23:27:18.340Z",2,"Hi folks,

I'm writing this comment in [Meta](http://thinklab.com/p/meta), an area of the site where community members can discuss ThinkLab itself. If you have any feedback, questions, or suggestions this is where you should post them.

Posting publicly will give others the chance to weigh in. (And that's kind of the point of this site.) However, if you'd prefer to give feedback privately, that's also encouraged. You may email me at jesse@thinklab.com","2",2015-01-15,2015-01-15,2,459,"base.profile","Jesse","Spaulding","jspauld"
"116","comments","meta","2015-01-23T01:59:47.859Z",23,"Hi all,

I'm not fond of how are treated the output links, for the references in particular. I find it a bit frustrating to arrive on a page with only the title and Disccusion/Followers. I wondered if it was broken at first. Now I get it, you can click on the doi to get to the destination, but I think the UX is a bit puzzling. 
I'd rather have on the page itself a preview of the ressource. If it's an image, let's get it, if it's a paper, the abstract... Something.
Another solution would be to ask if I want to go directly to the link at the moment I click on it.

Best,
Antoine","23",2015-01-23,2015-01-23,2,589,"base.profile","Antoine","Lizee","alizee"
"117","comments","meta","2015-01-23T02:02:46.776Z",23,"More a silly question than constructive feedback: can we change our handle after creation of the profile? I somewhat screwed up the profile creation part, and I've been told I could have during these steps, but I can't find the functionality anywhere now. 

Thanks,
Antoine
","23",2015-01-23,2015-01-23,2,278,"base.profile","Antoine","Lizee","alizee"
"118","comments","meta","2015-01-23T04:30:13.620Z",23,"In the ""It breaks"" section,

I cannot change my profile image. I get a page with just written in plain text ""server error"".
I managed to find one image that went through, but I have no idea why.

Best,
Antoine","23",2015-01-23,2015-01-23,2,215,"base.profile","Antoine","Lizee","alizee"
"119","comments","meta","2015-01-23T22:35:21.831Z",17,"I'm imagining projects will accumulate quite a few discussions. Some will warrant continued attention and thus visibility. However, many discussions will be resolved and should remain as part of the scientific record and as a resource, but do not require the same prominence in the discussion page.

Perhaps an archive feature. It's unclear to me whose decision it should be to archive (perhaps the initial poster) and whether this feature will be needed. An alternative would be a star feature, so extremely pertinent discussions will have enhanced visibility. With starring you could imagine a consensus algorithm determining the degree of sparkle (corresponding to the crowd's decision on the importance of the issues within).","17",2015-01-23,2015-01-23,2,731,"base.profile","Daniel","Himmelstein","dhimmel"
"120","comments","meta","2015-01-23T22:36:28.023Z",17,"As I've discussed with @jspauld, I think a ThinkLab hosted storage solution would be really nice to ensure files are persistent. Each file could even be reachable as a subdomain of the master doi. However, I also see a potential overstretch problem when other players already may provide good storage and embedding solutions.

I would like people's advice on good places to host different types of content. Ideally, the hosting would be free, allow commercial reuse/embedding, and persistent.","17",2015-01-23,2015-01-23,2,494,"base.profile","Daniel","Himmelstein","dhimmel"
"121","comments","meta","2015-01-25T19:21:08.287Z",2,"I completely agree that a feature as you describe will be needed and will be very valuable. 

An alternative to an archive/star feature would be to have a scale of Importance/Visibility/Attention. Perhaps we'd have 4 buttons:

- Closed/Resolved
- Moderate visibility
- High visibility
- Very high visibility

Something like that. I would think that for the most part the project leaders could determine the importance of each thread. On the other hand it might be nice to be able to have the community weigh in on what they think is important. 

@dhimmel do you feel like this feature would be valuable right away? Right now I'm thinking to wait until there is more activity on the site.

If anyone has additional thoughts on such a feature let us know.","2",2015-01-25,2015-01-25,2,766,"base.profile","Jesse","Spaulding","jspauld"
"122","comments","meta","2015-01-25T20:47:34.190Z",2,"ThinkLab definitely *could* host files. And it may be that we need to do so in order to allow users to embed figures and make them look pretty. That said, its my strong intention to have ThinkLab play nice with as many third party services as possible. 

[Figshare](http://figshare.com/) seems to be the go-to site for hosting of scientific files. There is some question as to whether or not they will allow their users to embed content on ThinkLab. But I guess worst case scenario you can just link people to view the content directly on Figshare.","2",2015-01-25,2015-01-25,2,550,"base.profile","Jesse","Spaulding","jspauld"
"123","comments","meta","2015-01-26T14:17:01.070Z",17,"One possibility is to start off using figshare. The embed markdown could mirror the current [youtube and vimeo syntax](http://thinklab.com/help/writing-in-markdown): `![:figshare](937004)`

Since the content users upload to figshare should be CC-BY or CC-0, it could always just be copied and stored locally by ThinkLab, if figshare tries to charge an exorbitant fee.","17",2015-01-26,2015-01-26,2,369,"base.profile","Daniel","Himmelstein","dhimmel"
"124","comments","meta","2015-01-26T15:08:52.599Z",17,"People minimize signup time by not customizing their user handle. However, if they continue using ThinkLab, they may want to change their handle. Also, someone's preferred handle often changes over time.

Once, It would be great if all handles (example: @jspauld) in text fields became dynamic upon submission. So if Jesse changed his handle to @jpaul, because he thought it sounded cooler, the previous sentence would update. #betterthantwitter

Finally, mentions should hyperlink to the corresponding user's profile.","17",2015-01-26,2015-01-26,2,522,"base.profile","Daniel","Himmelstein","dhimmel"
"125","comments","meta","2015-01-26T17:51:01.558Z",2,"Great. I'll put this on the backlog of things to do. I don't think there's a particularly elegant solution to do this on our backend but certainly it can be done.","2",2015-01-26,2015-01-26,2,162,"base.profile","Jesse","Spaulding","jspauld"
"126","comments","meta","2015-02-17T03:13:40.458Z",17,"I will use this thread for feedback related to [ThinkLab flavored markdown](http://thinklab.com/help/writing-in-markdown) (TLFM).","17",2015-02-17,2015-02-17,2,129,"base.profile","Daniel","Himmelstein","dhimmel"
"127","comments","meta","2015-02-17T03:20:19.941Z",17,"# Smart Punctuation

Many markdown parsers have implemented smart punctuation, which includes en and em dashes, curly quotes, and ellipsis. Here are a few examples:

+ Daring Fireball's [smartypants](http://daringfireball.net/projects/smartypants/)
+ Python's [mdx_smartypants](https://pypi.python.org/pypi/mdx_smartypants)
+ `smart=TRUE` in [R Markdown](http://rmarkdown.rstudio.com/html_document_format.html)

Hopefully, this can also apply to titles where I have been using lots of en dashes.","17",2015-02-17,2015-02-17,2,503,"base.profile","Daniel","Himmelstein","dhimmel"
"128","comments","meta","2015-02-17T05:23:14.593Z",2,"Smart Punctuation does not appear to be something Discourse, Stackoverflow, or GitHub have implemented. Perhaps there's a reason they haven't? Jeff Atwood [seems to think its better to only use it in titles](https://meta.discourse.org/t/should-smartypants-be-implemented-in-the-body-of-a-post/10086/2). But on the other hand that might screw up something [like this](http://stackoverflow.com/questions/28555062/can-i-use-git-checkout-on-two-files).","2",2015-02-17,2015-02-17,2,448,"base.profile","Jesse","Spaulding","jspauld"
"129","comments","meta","2015-02-17T17:01:07.218Z",17,"After submitting a discussion by pressing 'Save', I would like to be redirected to that specific discussion rather than the listing of all project discussions.","17",2015-02-17,2015-02-17,2,159,"base.profile","Daniel","Himmelstein","dhimmel"
"130","comments","meta","2015-02-22T05:42:25.344Z",17,"I'm migrating my websites from Google Analytics to [Piwik](http://piwik.org/) and thought I would share my experience, in case its relevant to ThinkLab or any ThinkLab users.

## Google Analytics

[Google Analytics](https://en.wikipedia.org/wiki/Google_Analytics) is the most popular platform used by webmasters to analyze traffic to their sites. However, since it's a closed source and third party solution, the feature set is predetermined/inflexible and users must rely on Google to provide the service and manage user data. The advantages are easy setup and an impressive feature set that integrates with the larger Google knowledgebase.

## Piwik

[Piwik](https://en.wikipedia.org/wiki/Piwik) is an open source analytics platform. Piwik can provide more detailed user information, such as IP addresses, and is extensible and modifiable. If you host your own Piwik instance on a server you control, user data is not shared with a third party and there are fewer potentially problematic dependencies (for example, some counties block Google services). The downside is greater setup, maintenance, and cost compared to Google Analytics, as well as lack of integration to the Google knowledgebase. The main benefits are complete control, data ownership, and user privacy.

## User Privacy

Regarding user privacy, Piwik may not necessarily be preferable to Google Analytics. For example, Google's expertise and size could allow them to implement superior penetration resistance than a single webmaster. The privacy and security issue centers around whether Google or a website's private webmaster is more likely to accidentally leak or misuse user data. This is a complex issue and likely situation dependent.

Ultimately, I think its the user's responsibility to protect their own privacy. Concerned users should check out the [Disconnect browser plugin](https://disconnect.me/disconnect), which blocks many online tracking requests, such as Google Analytics. The Piwik javascript can also be blocked client-side and it may be possible to opt out of on [specific sites](http://piwik.org/docs/privacy/).

## My Personal Experience

Personally, I have mostly migrated my sites to Piwik from Google Analytics and prefer the interface and additional details. I used the [Bitnami Image](https://bitnami.com/stack/piwik/cloud/amazon) to quickly get Piwik running on an Amazon Web Services' [EC2 Cloud](https://aws.amazon.com/ec2/) instance. To get a free SSL certificate to secure communications with my AWS instance, I used [StartSSL](https://www.startssl.com/).

## ThinkLab

ThinkLab currently uses Google Analytics, along with most other sites I've investigated. Given the complex set of drawbacks and advantages, it's difficult to say which service is superior, but I wanted to throw out the idea of Piwik.

/cc @caseygreene @alizee ","17",2015-02-22,2015-02-22,2,2857,"base.profile","Daniel","Himmelstein","dhimmel"
"131","comments","meta","2015-02-25T18:48:00.560Z",22,"We use Google Analytics on our sites because of the convenient interface and ease of use. I also use Disconnect to block trackers though, so I'm not sure what that says.","22",2015-02-25,2015-02-25,2,169,"base.profile","Casey","Greene","caseygreene"
"132","comments","meta","2015-02-25T19:02:52.169Z",22,"Are e-mails being evaluated during login in a case sensitive manner? It seems like I have to remember the precise capitalization that I used when I signed up. Case sensitive e-mail systems are discouraged but allowed by RFC2821, but I don't know if they are prevalent enough (I haven't encountered one) to matter for the convenience trade-off.

Edit: Link to RFC (second paragraph of 2.4): http://www.faqs.org/rfcs/rfc2821.html","22",2015-02-25,2015-02-25,2,429,"base.profile","Casey","Greene","caseygreene"
"133","comments","meta","2015-02-25T20:05:17.399Z",2,"@dhimmel Thanks for the idea. I'm pretty comfortable with using Google Analytics for now. As far as privacy, I don't really have any concerns about using GA.","2",2015-02-25,2015-02-25,2,157,"base.profile","Jesse","Spaulding","jspauld"
"134","comments","meta","2015-03-12T02:27:34.802Z",17,"Writing the introductory post for discussions can be time consuming and sometimes requires multiple sessions. A draft mode would be nice, where a discussion remains private to a user (or members of a project team?) until the user decides to publish.","17",2015-03-12,2015-03-12,2,249,"base.profile","Daniel","Himmelstein","dhimmel"
"135","comments","meta","2015-03-12T04:51:13.963Z",2,"Agreed. Have added this to the to do list. Will be private to just the user for now.","2",2015-03-12,2015-03-12,2,84,"base.profile","Jesse","Spaulding","jspauld"
"136","comments","meta","2015-03-17T18:30:24.403Z",17,"# Author order in crossref

Our project is now citable with a doi [@10.15363/thinklab.4]!

However, the current [author order in crossref](http://search.crossref.org/?q=10.15363%2Fthinklab.4) is incorrect.","17",2015-03-17,2015-03-17,2,209,"base.profile","Daniel","Himmelstein","dhimmel"
"137","comments","meta","2015-03-31T23:05:03.054Z",2,"We've extended our citation feature thanks to [a suggestion](http://thinklab.com/discussion/add-your-thinklab-feedback-here-in-meta/2#note-53) from @dhimmel.

Up until now users have been able cite external publications (anything that has a DOI) by inserting some custom [markdown](http://thinklab.com/help/writing-in-markdown) like so: `[@10.1136/amiajnl-2012-001431]`. This results in a citation that appears like this: [@10.1136/amiajnl-2012-001431]. Building upon this we were able to add two new features:

1. Users can now look up a publication and view all ThinkLab content that cites it. ([Example](http://thinklab.com/doi/10.1136/amiajnl-2012-001431))
2. Users can now follow a publication, and their ThinkLab inbox will surface any new content that cites it. This should be particularly useful for tracking citations of your own work.

Any suggestions are welcome!","2",2015-03-31,2015-03-31,2,881,"base.profile","Jesse","Spaulding","jspauld"
"138","comments","meta","2015-04-03T21:04:07.219Z",17,"I would like more options when valuing contributions. Ideally, I would like to be able to manually enter an integer dollar amount.","17",2015-04-03,2015-04-03,2,130,"base.profile","Daniel","Himmelstein","dhimmel"
"139","comments","meta","2015-04-04T03:44:40.416Z",2,"If we were to keep the fixed valuation options how many more options do you feel we should have? They are currently:

0, 5, 10, 20, 40, 70, 100, 150, 250, 400

I think there may be some benefit to having these distinct levels, although I'm not sure about that. The other option is to have a one-click sliding scale that goes from 0-500. Basically, as you mouse-over it would show you the amount you're valuing the comment at. This scale could be logarithmic if it helps ease of use.","2",2015-04-04,2015-04-04,2,486,"base.profile","Jesse","Spaulding","jspauld"
"140","comments","meta","2015-04-04T08:45:58.368Z",2,"Draft mode has now been implemented.","2",2015-04-04,2015-04-04,2,36,"base.profile","Jesse","Spaulding","jspauld"
"141","comments","meta","2015-04-13T23:18:18.948Z",17,"There are some options I would like for individual comments in a discussion:

+ comment permalink
+ see raw markdown -- this may also be helpful for all markdown content. The benefits will be 1) a way for new markdown users to learn syntax and 2) a way for people to copy unformatted comments to other *media* (plural of medium).","17",2015-04-13,2015-04-13,2,332,"base.profile","Daniel","Himmelstein","dhimmel"
"142","comments","meta","2015-04-20T19:50:11.897Z",84,"I would like to receive project updates directly on [feedly](http://www.feedly.com). Could you create an RSS feed option to track projects.
 ","84",2015-04-20,2015-04-20,2,142,"base.profile","Alex","Pankov","apankov"
"143","comments","meta","2015-04-21T01:16:04.645Z",2,"ThinkLab has built a platform that financially rewards scientists for sharing feedback on open research projects. And I'm happy to report that one of our first projects, [Repurposing drugs on a heterogeneous network](http://thinklab.com/p/rephetio), has now generated ~$600 in such rewards! We expect this open feedback and discussion to be extremely valuable to science.

But research projects aren't the only thing that benefit from feedback. User feedback will be critically important to the growth and success of ThinkLab itself. That's why we're using our own platform to solicit, and now, reward user feedback. Comments you make in [ThinkLab Meta](http://thinklab.com/p/meta) will now be payment eligible just like any other (funded) project on the platform.

**Please help us improve by sharing your feedback in [ThinkLab Meta](http://thinklab.com/p/meta)!** 

- What features would you like to see? 
- Which parts of the site need improvement, are confusing, or unclear?
- How can we do a better job growing the ThinkLab community? 
- How can we help science become more open, collaborative, and efficient?

Please note: critical feedback is highly encouraged — it's the only way we're going to get better!","2",2015-04-21,2015-04-21,2,1225,"base.profile","Jesse","Spaulding","jspauld"
"144","comments","meta","2015-04-22T21:02:49.828Z",17,"Another option to consider is an [Atom feed](https://en.wikipedia.org/wiki/Atom_%28standard%29), which is a newer standard than RSS. Feedly can also import Atoms, which are more feature rich and may be better at handling updates to feeds.","17",2015-04-22,2015-04-22,2,238,"base.profile","Daniel","Himmelstein","dhimmel"
"145","comments","meta","2015-04-23T03:45:34.617Z",48,"Most (90%) proposals submitted to the NIH and elsewhere are not funded.  This is an enormous waste of time and energy.  Can ThinkLab be used to improve these large grants before they are submitted to increase their chances of getting funded, perhaps to filter out those that have no chance earlier in the process or to redirect the applicant to a more appropriate funder (such as a thinklab sponsor)?  It seems the system as it stands could be used for that, very important, purpose.  What other new mechanisms would be needed to make that specific process more effective?

As an example, here is what a twice-failed R21 NIH grant looks like, along with the rejection letter (called the Summary Statement).  http://sulab.org/2014/03/nih-grant-proposal-for-sale/ Could ThinkLab have helped this one?  Is it salvageable?  Would it make sense to resubmit it for this new call?  http://grants.nih.gov/grants/guide/rfa-files/RFA-CA-15-006.html

","48",2015-04-23,2015-04-23,2,944,"base.profile","Benjamin","Good","b_good"
"146","comments","meta","2015-04-23T18:53:53.880Z",17,"I thought we could use this thread for discussion related to ThinkLab Flavored Markdown (TLFM) and the ThinkLab post editor. I have a few suggestions:

1. The [markdown help page](http://thinklab.com/help/writing-in-markdown) should provide a tutorial of all markdown features. It's fine if the TLFM-specific features are detailed first, but I've always found it annoying to track down markdown syntax through nested help docs.
2. I have noticed an omitted space following some inline urls. See [this example](http://thinklab.com/discussion/enabling-reproducibility-and-reuse/23#83).
3. In the preview mode, it is easy to inadvertently navigate away from the unsaved post when clicking a link. Perhaps all links in the preview window should set `target=""_blank""`.
4. More broadly, perhaps all links to outside resources should open in new tabs/windows. Currently, I believe only inline urls trigger a new window.","17",2015-04-23,2015-04-23,2,917,"base.profile","Daniel","Himmelstein","dhimmel"
"147","comments","meta","2015-04-23T21:53:56.984Z",2,"Just FYI — you already created [a thread](http://thinklab.com/discussion/markdown-feedback-bugs-and-suggestions/32) that was intended to be for markdown related discussion. But in all honesty I don't think there is a particular reason to try and keep everything in the same thread. We're still working on the previous issues you posted BTW.

> The markdown help page should provide a tutorial of all markdown features. It's fine if the TLFM-specific features are detailed first, but I've always found it annoying to track down markdown syntax through nested help docs.

Makes sense. We'll try to just put all of this on one page. 

BTW, I'm a little bit hesitant to endorse the term ""ThinkLab flavored markdown"". I think this term implies we are changing something from other flavors. The intent is to only be adding things (where necessary).

> I have noticed an omitted space following some inline urls. See this example.

Yes, I noticed this too. It's been flagged to fix, thanks.

> In the preview mode, it is easy to inadvertently navigate away from the unsaved post when clicking a link. Perhaps all links in the preview window should set target=""_blank"".

Are you clicking the links on purpose to test if they're working or just inadvertently clicking the links? We could also just disable the links in preview.

> More broadly, perhaps all links to outside resources should open in new tabs/windows. Currently, I believe only inline urls trigger a new window.

I'm generally against this. It should be up to the user to decide if they want to open something in a new tab or not. I think you'd find it irritating to have links opened in new windows when you didn't want that to happen.","2",2015-04-23,2015-04-23,2,1710,"base.profile","Jesse","Spaulding","jspauld"
"148","comments","meta","2015-04-23T22:10:12.897Z",2,"Thanks for making the request Alex.

At this moment I'm not familiar with what the implications will be for creating RSS feeds. So I can't promise it will get done. However we will definitely look into it. A few things I'm concerned about:

- Will this make it harder for us to make changes to the site in the future? ThinkLab is brand new and we need to maintain flexibility to be able to change things.
- Are there extra performance issues we need to worry about with this?
- Will this negatively affect our comment peer assessment system? People need to be on ThinkLab to be able to rate comments.

Not saying we won't do it — just that we need to look into it further. In the meantime if you click to ""Follow"" the project you will receive updates on the project daily. Or if you want real-time notifications there is a setting for that in Notification settings.","2",2015-04-23,2015-04-23,2,873,"base.profile","Jesse","Spaulding","jspauld"
"149","comments","meta","2015-04-23T22:49:14.139Z",17,"> Just FYI — you already created [a thread](http://thinklab.com/discussion/markdown-feedback-bugs-and-suggestions/32) that was intended to be for markdown related discussion

Yes, I looked through the abbreviated discussion list on the [meta project page](http://thinklab.com/p/meta) and didn't see the old thread. Consider adding a footer row that shows the number of non-displayed discussions -- just to make it clear that the table is not exhaustive.

> It should be up to the user to decide if they want to open something in a new tab or not.

You have convinced me, except for the specific case of the preview window where data loss is a concern.

> Are you clicking the links on purpose to test if they're working or just inadvertently clicking the links? We could also just disable the links in preview.

I was with @apankov when he composed his first post and this situation arose. I personally like to make sure my links resolve from the preview window.","17",2015-04-23,2015-04-23,2,972,"base.profile","Daniel","Himmelstein","dhimmel"
"150","comments","meta","2015-04-23T22:53:41.941Z",2,"> Yes, I looked through the abbreviated discussion list on the meta project page and didn't see the old thread. Consider adding a footer row that shows the number of non-displayed discussions -- just to make it clear that the table is not exhaustive.

Yes, I actually ran into the same problem :) Will do something about it.

> I was with @apankov when he composed his first post and this situation arose. I personally like to make sure my links resolve from the preview window.

Okay, we will see if we can get them to open in a new tab.","2",2015-04-23,2015-04-23,2,544,"base.profile","Jesse","Spaulding","jspauld"
"151","comments","meta","2015-04-23T23:05:07.907Z",2,"Thanks for the great idea Ben. This was also suggested to me in an offline conversation with @newyorklenny.

I think this very well could be the idea that can really help ThinkLab turn the corner! It seems like it might really hit a pain point. And the great thing is, anybody who sees the benefit of ThinkLab in improving their proposal can easily just decide to continue their research as an open project like @dhimmel is doing.

That's what I'm thinking but I'd really appreciate getting feedback from others here. What do people think? Will researchers openly post their proposals in order to get feedback and increase their odds of getting funded?

Lenny, you're welcome to reiterate what you've said. Would also love to hear from @jonathaneisen and @hollyganz (who I worked with to put up the [first ThinkLab proposal](http://thinklab.com/p/MicrobeResist)). What do you guys think?","2",2015-04-23,2015-04-23,2,893,"base.profile","Jesse","Spaulding","jspauld"
"152","comments","meta","2015-04-24T01:11:30.949Z",17,"# Hosting content with GitHub

`git` is a distributed version control system that stores files and tracks their changes over time. While primarily designed for code, git repositories can contain any type of files, including binaries (an area where the main competing project, mercurial, struggles). This [cheat sheet](https://training.github.com/kit/downloads/github-git-cheat-sheet.pdf) goes over the commands for initializing and updating a repository.

[GitHub](https://github.com/) is an online host for git repositories with a nice user interface to browse and inspect the contents. I have started hosting [our project](//thinklab.com/p/rephetio) analyses using [GitHub](https://github.com/) and find that it solves many of the file hosting issues that I was experiencing.

First you must create a repository, add your files, commit, and push to GitHub. For this post, I'll use my [`erc` repository](https://github.com/dhimmel/erc) as an example. Below I show how to use GitHub for cloud-based file storage.

## Retrieving the most recent version of a file
format: `https://raw.githubusercontent.com/[user]/[repo]/[branch]/[path_to_file]` 
example: `https://raw.githubusercontent.com/dhimmel/erc/gh-pages/entrez-group.R`

Linking to the most recent version of a file makes sense for a research plan or project summary, where the updated file is desired. For example, you may have a figure that should be updated as you modify your analysis.

## Retrieving a specific version of a file
format: `https://raw.githubusercontent.com/[user]/[repo]/[commit_hash]/[path_to_file]` 

By linking to a specific file in a specific commit, you don't have to worry about file updates or deletion interfering with the content of an old post. This makes sense for discussions where posts are often chronological. In these instances, updated external resources could degrade the scientific record.

## Advantages

The main benefits of this system are tracked-changes, versioning, and that code, data, and results are all coupled.

## Drawbacks

+ file sizes are limited to 100 MB
+ requires `git` expertise, but the GitHub applications for [windows](https://windows.github.com/) and [mac](https://mac.github.com/) reduce the barrier","17",2015-04-24,2015-04-24,2,2245,"base.profile","Daniel","Himmelstein","dhimmel"
"153","comments","meta","2015-04-24T03:04:58.418Z",5,"I think in general it is a good idea.  Though I note - in my experience most people put together grant proposals at the last minute so this might only help after one round of rejection ","5",2015-04-24,2015-04-24,2,185,"base.profile","Jonathan","Eisen","jonathaneisen"
"154","comments","meta","2015-04-24T03:43:32.443Z",48,"The last minute point is totally valid.  Actually one of my concerns about putting something up here is that the attention required to develop it and monitor it would take away too much time from meeting the next deadline.  (e.g. the letter of intent for that crowdsourcing call is one week away).  Ideas:

(1) It should be encouraged to post less-than-fully-baked concepts here.  Daniel's proposal was well thought out and pretty complete when I saw it.  Very close to a state that would be ready for a typical grant.  It would be cool if you supported ""1 pagers"" to gauge community feeling for the idea and to quickly get feedback on major direction changes.  Basically much like the letter of intent process.

(2) If you do this, go whole-hog on a pattern for it.  Support the whole process - idea, opportunity discovery, letter of intent, drafting, letters of support, personal statement...   Get them all out in the open here.   Importantly, add a timeline feature so that people could see deadlines that would need to be met.  

(3) Catalogue success rates..  Follow up with people that try this to see how it impacted them.  Many people will hesitate to share early stage ideas openly.  You will need to get evidence that it really does produce better outcomes for their selfish interests to gain a lot of momentum.  

(4) Phil Bourne (bioinformatics director at NIH) would likely be very supportive of something like this..  It fits his philosophy very well from what I can tell..   

(5) I've had discussions about something like this with Jonathan Wren.  Would be good to get his feedback as well..
","48",2015-04-24,2015-04-24,2,1620,"base.profile","Benjamin","Good","b_good"
"155","comments","meta","2015-04-24T17:42:13.136Z",2,"Thanks Ben, this is great.

1. Very much agree on the ""1 pagers"". This will be easy to do. Although in the beginning I'm suspecting the primary interest may be from people who have already had a proposal rejected?

2. I don't personally have experience with submitting NIH/NSF proposals so I'll be relying on learning everything I can from others. Would you mind going into more detail here? Are you essentially suggesting that ThinkLab be not just a place to get feedback and improve proposals but basically an entire front-end to the NIH proposal process? 

3. Agree

4. I'm in touch with Daniel Mietchen ( @daniel_mietchen ) who works with Phil now. I believe Daniel has spent considerable time thinking about this idea of opening up research proposals. In fact, he's put up a [proposal for exactly that](https://www.newschallenge.org/challenge/2014/submissions/opening-up-research-proposals). There's a lot of great ideas in there. And the fact that we can benefit from them now actually demonstrates part of the value of open proposals!

5. Thanks, I've emailed him :)","2",2015-04-24,2015-04-24,2,1083,"base.profile","Jesse","Spaulding","jspauld"
"156","comments","meta","2015-04-25T14:13:02.138Z",5,"Another person to contact is Titus Brown at UC Davis, who has been posting his grant proposals on his blog and getting feedback on them there.","5",2015-04-25,2015-04-25,2,142,"base.profile","Jonathan","Eisen","jonathaneisen"
"157","comments","meta","2015-04-25T15:07:05.737Z",55,"Titus Brown's blog: http://ivory.idyll.org/blog/","55",2015-04-25,2015-04-25,2,48,"base.profile","Jack","Park","jackpark"
"158","comments","meta","2015-04-26T04:16:33.114Z",48,"The key, as usual, is where the money is and this seems to be a problem with the current content on ThinkLab - there is not nearly enough of it.  The ""small"" award I am looking to apply for right now is $400,000.   That is the underlying reason for the suggestion to orient a ThinkLab process around getting participants access to the large pots of research money that do exist (at the NIH and similar places).  Increasing chances of gaining such funding is definitely a value proposition for ThinkLab participation.  If you achieve a flow of researchers here that way, it should increase your chances of diverting them towards other resources as they arise.

As a very junior grant writer, I find the structures provided by [this book] (http://www.amazon.com/Writing-Grant-Proposal-Step-Step/dp/1412975166) extremely helpful in preparing my applications.  It goes into great detail about the various kinds of NIH grants and what elements they are composed of.   If you are keen on this direction, its worth a look.  If ThinkLab took something like the process suggested in that book and translated it into software modules imbued with the collaborative features of ThinkLab it would be very interesting.  I would be happy to test it.  Our lab also has a habit of posting our proposals e.g. http://sulab.org/category/GeneWikiRenewal/ though it does seem time to start opening things up earlier.

Note that you wouldn't need to have things as tightly laid out as they do in that (200+ page) book.  Just having the core structures defined and attached to timelines would be great...  Though the more utility you put in, the more attractive it becomes.","48",2015-04-26,2015-04-26,2,1653,"base.profile","Benjamin","Good","b_good"
"159","comments","meta","2015-04-28T08:12:38.181Z",25,"I agree it would be good to have mechanisms to develop research ideas into grant proposals in the open, and that an iterative approach (perhaps starting with a one-pager or even shorter, as per http://beta.briefideas.org/ ) seems most promising, especially since feedback is badly broken in many funding schemes. ThinkLab can be of help here, keeping in mind that features like automated generation of PERT and Gantt charts as well as budget overviews are amongst the major reasons why people often resort to dedicated grant-writing environments.

Yes, timing (especially distance to deadlines) is crucial and will likely have a strong influence on the amount of attention people can devote to such open drafting. On the other hand, by drafting in the open, you can get help that would otherwise be hard to get - our H2020 proposal at http://dx.doi.org/10.5281/zenodo.13906 was written in five weeks around Christmas, with significant contributions from multiple people outside the consortium (which itself was only formed on the basis of the published idea - with most of the partners, I have had no prior interaction).

As for my work with Phil at NIH, my notes are at https://github.com/Daniel-Mietchen/datascience , and exploring openness in funding contexts tops the list. I would thus welcome it very much if you (or others) were to step forward to draft NIH proposals in the open and to keep track of any red tape that stands in the way. I will work on trimming the red tape and combine that with creating incentives for sharing proposals. We try to be attentive to demands from the community, so suggestions, pull requests etc. are most welcome.

Independent of these NIH activities, I am pursuing the idea of publishing research proposals and associated materials more formally, as sketched out in the News Challenge proposal that Jesse mentioned above as well as in http://dx.doi.org/10.1371/journal.pbio.1002027 . Nothing more specific to show here yet, but I expect this to be operational before the end of the year. Ping me if you would like to be involved.
","25",2015-04-28,2015-04-28,2,2078,"base.profile","Daniel","Mietchen","daniel_mietchen"
"160","comments","meta","2015-04-29T17:38:02.237Z",23,"Just ran into a *potential* issue yesterday as I wrongly copy-pasted my whole console output into the editor and saved. 
There was no warnings, no errors and the whole thing ended up in a *very* long message. Should we have a limit?

I am concerned by:
- usability: in this very small use-case, I would have loved a warning box!
- security/reliability: it seems brittle to accept any size of comment from the engineering side.

PS: I tried with messages with up to 8K lines. Still works :-)
","23",2015-04-29,2015-04-29,2,499,"base.profile","Antoine","Lizee","alizee"
"161","comments","meta","2015-04-29T17:38:09.076Z",23,"This was a test message with 8041 lines which made the thread unreadable and the website slow for a while. 

Have we discussed the fact that there is no way to delete a message?","23",2015-04-29,2015-04-29,2,179,"base.profile","Antoine","Lizee","alizee"
"162","comments","meta","2015-04-29T17:52:20.334Z",23,"It seems that a few things around the way people interact with comments and notes could change for better. Here is a thread to discuss it.

I'll begin with a couple of suggestions:

* I might have missed something, but it seems that there is no way to delete a comment. As the user base of the platform grows, it might be useful to add this feature, at least for a certain amount of time after posting. Especially since full editing is available without time limit.

* Notes should be ""upvotable"". As SO and other knowledge crowd-sharing platforms have shown (and I understand we might want to do things differently), the key information is sometimes better placed in a note of an existing comment. I am not sure how this should work, but it seems that something similar to comments with smaller values should be enough to give the *opportunity* of rewarding important notes.","23",2015-04-29,2015-04-29,2,881,"base.profile","Antoine","Lizee","alizee"
"163","comments","meta","2015-04-30T16:32:04.367Z",86,"The idea I proposed to Ben was essentially ""gamifying"" grant reviews. It would basically work something like this:

1) A grant writer would submit key concepts (overview/aims) for review, fitting it in one page maximum to keep it brief.
2) Competitors would try to identify both strong and weak points of the grant by highlighting text and categorizing it as minor/major weak or strong points
3) Points are scored by guessing - as accurately as possible - which areas are considered by others as strong and weak points (which likely reflects how the real grant reviewers will feel)
4) The more text highlighted, the fewer points a reviewer is likely to get, as the score would be a function of how specifically their own weak points aligned with others, with what frequency and what severity. I haven't worked out the cost function yet, but have a general idea in mind.
5) Badges mark specific milestones and leaderboards track people best able to guess points of criticism/praise
6) There are 3 points of value in this: 
      a) Grant writers: Obviously, they get strategic feedback before it actually gets sent to real reviewers
      b) For casual reviewers: They will write their own grants and would like to think they can identify strong/weak areas in their own work. If they're not good at it, then the game offers them a way to get better. 
      c) For serious reviewers: People on the leaderboard become eligible to accept pay-for-review offers to review the entire grant. They can set their price - if it's too high, then they price themselves out of the market and get no offers. An average fee (based on past fees) will display at the top of the leaderboard to guide both writers & reviewers.
7) Submitting grants can be done either by pay-to-play or by earning enough points as a reviewer. If you don't want to help the system by reviewing, then you need to ante up some cash.

Surely, there will be kinks to iron out, but what do you guys think of this idea?","86",2015-04-30,2015-04-30,2,1987,"base.profile","Jonathan","Wren","jonathanwren"
"164","comments","meta","2015-04-30T18:52:01.580Z",17,"> To be noted: there is a utility to visualize html files from github repositories: http://htmlpreview.github.io/ I found it very useful to share reports that are compiled directly in the projects (using R Markdown for instance).

@alizee, I have been using https://rawgit.com to display webpages corresponding to a past commit, since the `gh-pages` [branch method](https://pages.github.com/) only displays the current version.

I like the idea of `htmlpreview.github.io` because it is itself a github page, meaning GitHub remains the only dependency. However, I cannot get this site to work:

See: [htmlpreview](https://htmlpreview.github.io/?https://raw.githubusercontent.com/dhimmel/bindingdb/6bd29c55ec6d7dcdf699a39e9621df45a76619c7/collapse.html) hangs while [rawgit](https://rawgit.com/dhimmel/bindingdb/6bd29c55ec6d7dcdf699a39e9621df45a76619c7/collapse.html) delivers.","17",2015-04-30,2015-04-30,2,881,"base.profile","Daniel","Himmelstein","dhimmel"
"165","comments","meta","2015-04-30T19:56:58.409Z",17,"> it seems that there is no way to delete a comment

I would support comment deletion once/if version history of discussions are tracked. I also encourage a mandatory ""justification"" field when deleting a comment.

> Notes should be ""upvotable""

At this stage with limited examples of note usage on ThinkLab, I have difficulty assessing whether voting would be a worthwhile feature. I'm still new to the whole comment versus note distinction, so it may take me a long time to develop an opinion here.","17",2015-04-30,2015-04-30,2,506,"base.profile","Daniel","Himmelstein","dhimmel"
"166","comments","meta","2015-05-01T14:29:44.366Z",55,"In relation to comments, it seems to me that there is an opportunity to bring structure to them.  If bringing structure to, let's call them ""threads"", then there are further comments (other topics) to add.","55",2015-05-01,2015-05-01,2,205,"base.profile","Jack","Park","jackpark"
"167","comments","meta","2015-05-01T18:35:42.271Z",55," Structure other than linear lists, I believe, offers opportunities to render our conversations more useful along these dimensions: Ability to isolate questions and their responses and any pro or con arguments from other questions in a visual sense; that isolation raises the opportunity to maintain an improved ""signal to noise"" ratio.
Structure, in my view, entails two opportunities:
1) make use of natural outline structures to as many depth levels as required
2) provide some form of node type identifier, which would include these types (drawn from the Issue-based Information Systems vocabulary first isolated by Jeff Conklin and implemented in http://compendium.open.ac.uk/ and, in part, at http://debategraph.org/): question (issue), answer (position), pro or con arguments, reference, decision, and note.
3) restrict each node in such a conversation to *one topic*. That is because each topic should carry its own ""thread"".","55",2015-05-01,2015-05-01,2,937,"base.profile","Jack","Park","jackpark"
"168","comments","meta","2015-05-04T19:25:04.056Z",2,"In [another thread](http://thinklab.com/discussion/comments-notes-interface-and-behaviour-suggestions/60#180) @jackpark suggested there may be benefits to bringing more structure to the ThinkLab commenting system. I believe one of his points raised the idea of structuring ThinkLab comments more like [Slashdot](http://science.slashdot.org/story/15/05/03/2042231/empty-landscape-looms-if-large-herbivores-continue-to-die-out) or [Reddit](http://www.reddit.com/r/science/comments/34q1v9/who_keeps_track_if_your_surgery_goes_well_or_fails/):

> 1) make use of natural outline structures to as many depth levels as required

There's been a debate about [flat vs threaded](http://blog.codinghorror.com/discussions-flat-or-threaded/) commenting systems for a long time. For our use case I'm pretty firmly in the camp that says flat is better. Here's why:

* Whenever someone posts a comment we want it to be a well thought out comment in consideration of all the comments that have already been made in the discussion. A flat structure supports this.
* We want to keep discussions focused on one subject. This increases the signal-to-noise for anyone who is looking at the discussion because of an interest in the subject. A threaded discussion structure tends to encourage conversation to go all over the place. If people have an important point to make on a new topic we'd like them to post a new discussion with a new subject.
* When people are following a discussion we want to be able to quickly point them to the new comments they haven't seen yet. This just gets really complicated in a threaded view.","2",2015-05-04,2015-05-04,2,1611,"base.profile","Jesse","Spaulding","jspauld"
"169","comments","meta","2015-05-04T21:42:22.437Z",55,"I think that I did a rather poor job of explaining my thesis; I was certainly not advocating mimicking slashdot or reddit. Rather, I had in mind something closer to what Jeff Conklin has to say about the matter: https://www.youtube.com/watch?v=pxS5wUljfjE

Clearly, keeping dialogue focused on one subject is a useful goal. Let me build on that for a moment: A particular thread is about a single topic; this thread is about the difference between flat and structured dialogue. It necessarily entails, at the very least, two distinct subjects: flat dialogue, and structured dialogue. 

But those topics, as indicated in the bullets, entail signal-to-noise ratio, and findability.

Point of interest: a claim was made in this ""flat"" thread; it stands out as if it needs its own specific let's call it ""sub-thread"": ""A threaded discussion structure tends to encourage conversation to go all over the place.""

When one makes such a claim, it is considered good form to offer citations, or at least some level of evidence; a conversation about the conversation platform is no-less important than conversations about, say, hemochromatosis and leukemia. 

My inclination, were this to be a threaded conversation, would be to launch a ""con"" node, that is, an argument node which, by its node type, signals disagreement with that claim. I would do so from the observation that a single thread always entails other subjects, and that a proper structure keeps those subjects bound to their context.  To do that in a flat thread, as here, requires a lot of verbiage to keep things flowing, lowering, I would argue, the SNR, forcing others to read more prose than could otherwise be signaled by structure and typed nodes.

The specific vocabulary of such a structure is one created by Jeff Conklin for what is known as IBIS conversations.  Neither Slashdot nor Reddit use anything like that.","55",2015-05-04,2015-05-04,2,1891,"base.profile","Jack","Park","jackpark"
"170","comments","meta","2015-05-04T23:00:24.433Z",2,"I watched the linked video and I get it. I can see that regardless of how we display the conversation (flat or threaded), behind the scenes there could always be some structure extracted and mapped. I also get the discussions could be broken down into node types of ideas, questions, supporting arguments, disagreements, etc. But the question is so what? The question is not whether a structure exists, but what user interface best works to accomplish our goals?

> My inclination, were this to be a threaded conversation, would be to launch a ""con"" node, that is, an argument node which, by its node type, signals disagreement with that claim.

Right, I get the concept but what do you mean by ""threaded conversation""? Reddit and Slashdot have threaded conversations. 

In ThinkLab's current flat structure you could signal disagreement like so:

>> A threaded discussion structure tends to encourage conversation to go all over the place.

> I disagree, ...

I'm not saying there won't be some benefits to structuring things more. I would just ask you to try to think about what *specific* user interface changes you would suggest. And it would really help if you can point me to some other popular and easy to use sites that have implemented them. I've taken a look at [DebateGraph](http://debategraph.org/) and I must say this interface seems far from user-friendly. 

ThinkLab already has a huge challenge ahead of us. We're basically trying to reinvent science. Reinventing how comments work on the internet is really asking too much. But if you have any specific ideas that would improve the site right now let me know! We are currently in the process of adding a discussion labelling system which will work very similarly to what has been implemented for [GitHub issues](https://github.com/OpenSourceMalaria/OSM_To_Do_List/issues?q=is%3Aopen+is%3Aissue). There will be a separate post about that.","2",2015-05-04,2015-05-04,2,1918,"base.profile","Jesse","Spaulding","jspauld"
"171","comments","meta","2015-05-05T00:04:22.808Z",2,"**Re: deletion of comments**

I don't really have a good sense of what the best thing to do here is yet. So I think it's best just to hold off on doing anything for now. For the time being users can just edit their comment and type in `[deleted]` or something like that (possibly giving a reason). Over time I think we'll have a better understanding of the type of scenarios people are deleting comments in and if this is causing any problems. In general I don't think we want people deleting comments.

**Re: notes being ""upvotable""**

I agree that it's premature given that even I'm not sure what role the notes feature should play yet.","2",2015-05-05,2015-05-05,2,644,"base.profile","Jesse","Spaulding","jspauld"
"172","comments","meta","2015-05-05T18:13:49.092Z",2,"I'd like to know if people agree with my assessments below:

# Benefits

It seems to me there are several good reasons to keep discussions narrowly focused. 

1. **Better signal-to-noise ratio**. People will be attracted to reading a discussion based on the subject written for it. If they encounter conversation that doesn't match the subject this will likely lower the perceived signal-to-noise ratio of the thread.

2. **Minimizes confusion in thread**. The introduction of multiple ideas within a thread is more likely to lead to confusion as a result of parallel conversations happening at the same time. This is one of the downsides of a flat (vs threaded) discussion structure. But there are [reasons ThinkLab uses a flat discussion structure](http://thinklab.com/discussion/why-thinklab-uses-a-flat-discussion-structure-not-threaded/63).

3. **Prevents ideas getting lost**. Potentially high value ideas can get ""lost"" if they are posted in a discussion with a subject that doesn't capture the idea. (Potentially interested users won't see the idea when it's posted and future users won't find the idea when they search for related keywords.)

# Implications for user behavior

1. If someone has multiple points of feedback that could each lead to substantial discussion then they should post each point of feedback individually so that we can have a separate discussion thread for each. For example, it may have been better for @alizee's post [here](http://thinklab.com/discussion/comments-notes-interface-and-behaviour-suggestions/60) to have been separated into two.

2. If someone has multiple minor points of feedback that are unlikely to lead to much discussion they should go ahead and post them together. An example would be @dhimmel's post [here](http://thinklab.com/discussion/thinklab-editor-and-markdown-suggestions/59) perhaps.

3. If someone is introducing a new idea to an existing thread that is likely to lead to substantial parallel discussion they should post this idea in a new thread (and perhaps link to to the new thread from the thread they were going to post in). An example is @jonathanwren's comment [here](http://thinklab.com/discussion/thinklab-as-a-vetting-system-for-traditional-grants/58#173).

# Possible ThinkLab changes

1. When people click to post a new discussion we can offer some advice regarding keeping discussions narrowly focused.

2. We can offer a ""reply as new discussion"" feature which will create a new thread and automatically add a link to it from the current one.

What does everyone think? @dhimmel have you had any such thoughts in relation to the discussions in your project?

Also, just FYI — I don't want to stress anyone out about how to use the site. This is all an experiment and everyone is figuring it out as we go!","2",2015-05-05,2015-05-05,2,2813,"base.profile","Jesse","Spaulding","jspauld"
"173","comments","meta","2015-05-05T18:19:07.280Z",2,"**Re: adding more structure to comments**

I've addressed this in two posts: 

* [Why ThinkLab uses a flat discussion structure (not threaded)](http://thinklab.com/discussion/why-thinklab-uses-a-flat-discussion-structure-not-threaded/63)
* [Should we aim to keep discussions narrowly focused?](http://thinklab.com/discussion/should-we-aim-to-keep-discussions-narrowly-focused/64)","2",2015-05-05,2015-05-05,2,384,"base.profile","Jesse","Spaulding","jspauld"
"174","comments","meta","2015-05-05T18:56:52.934Z",2,"@jonathanwren the idea sounds genius to me. Presumably you wouldn't be posting it if you didn't want someone to take it and implement it? Few questions:

1. For an initial one page proposal how useful would it be to see a heat map of the perceived strong and weak points within a proposal? Presumably you would also want to know *why* something is seen as weak? 

2. Do you see a reason to allow free-form highlighting? Why not just do this sentence by sentence? Perhaps free form would be more fun?

3. What percentage of researchers do you think would pay for an open peer review (the serious review)? How much would they pay? Where is the money coming from? And how much time would we expect the average reviewer to spend reviewing?","2",2015-05-05,2015-05-05,2,741,"base.profile","Jesse","Spaulding","jspauld"
"175","comments","meta","2015-05-05T19:10:02.381Z",86,"@jspauld ,

1) Although it is definitely what people want to know, I think it will increase the complexity to try to synthesize the ""why"" of it from multiple responses. Presumably, the sentence itself would tell the writer what people may have a problem with, but I guess allowing (rather than requiring) commentary would be a plus

2) Free-form, yes - people choose whatever they want to highlight. Single word, phrase, sentence, etc.

3) I think that's going to depend on what they get out of it. The nice thing about the proposed system is they can evaluate how many grants the leaders have reviewed and how well they did. In other words, they don't have to guess as to whether or not it would be useful - they have data for that. I don't know how much they would pay. I don't know how much time reviewers would spend, but the leaderboards and badges would distinguish the serious from the casual reviewers.

The more time someone *has* to spend on the grant review, the less incentivized they will be. The incentive structure has to be set up so that, if they do spend more time, they gain something. Points, status, recognition, ranking, etc. There's no need to worry about individual reviewers - they will come in all forms, sizes, degrees of interest, etc, and the ranking system will segregate them accordingly.","86",2015-05-05,2015-05-05,2,1327,"base.profile","Jonathan","Wren","jonathanwren"
"176","comments","meta","2015-05-05T22:17:45.418Z",2,"Working on some copy for the homepage. This wouldn't be specifically for @jonathanwren's idea, but I wouldn't expect the selling points to be too different anyway.

-----------------

# Crowdsourced feedback for NIH grant proposals

(and any other research proposal)

## Benefits

- Receive $1000 to support crowdsourced feedback on your proposal
- Improve your odds of NIH/NSF funding
- Establish provenance over your research ideas
- Increase the visibility and impact of your work
- Connect with new potential collaborators

-----------

This seems pretty compelling to me. What does everyone think? Keep in mind I'm trying to create selling points for a potential proposal poster. (Not necessarily selling the benefits to science/society, of which I believe there are many.) Am I missing anything?","2",2015-05-05,2015-05-05,2,819,"base.profile","Jesse","Spaulding","jspauld"
"177","comments","meta","2015-05-05T22:21:52.373Z",55,"NIH is already showing specific interest in such matters:
http://grants.nih.gov/grants/guide/rfa-files/RFA-CA-15-006.html

I think others following this thread are well aware of that.","55",2015-05-05,2015-05-05,2,186,"base.profile","Jack","Park","jackpark"
"178","comments","meta","2015-05-06T17:18:24.925Z",23,">@alizee, I have been using https://rawgit.com to display webpages corresponding to a past commit, since the gh-pages branch method only displays the current version.

I'm not sure I understand, since as you said:
>https://raw.githubusercontent.com/[user]/[repo]/[commit_hash]/[path_to_file]

...lets you get the file at a certain point in history. So you can preview an html file through https://htmlpreview.github.io/?https://raw.githubusercontent.com/[user]/[repo]/[commit]/[path]

I just wanted to add that if you're not creating these pages or links programmatically, the easiest way to get the link pointing to the raw content (eg: html) is to navigate to your file/commit on github and click on the ""Raw"" button on the top right corner. You can then grab the link and copy/paste it directly into https://htmlpreview.github.io/ for instance. I found it less error prone than trying to construct the link itself.","23",2015-05-06,2015-05-06,2,924,"base.profile","Antoine","Lizee","alizee"
"179","comments","meta","2015-05-06T20:46:16.973Z",17,"The `raw.githubusercontent.com` method can retrieve an html file from a previous commit ([example](https://raw.githubusercontent.com/dhimmel/indications/36f0c5f143618abbbf8c9eb94b7318cb5936fd61/merge.html)). Although the html file is retrieved, it is not displayed as a webpage (at least in chrome). Therefore, I have been using `rawgit.com` ([example](https://rawgit.com/dhimmel/indications/36f0c5f143618abbbf8c9eb94b7318cb5936fd61/merge.html)) but may switch to `htmlpreview.github.io` ([example](https://htmlpreview.github.io/?https://raw.githubusercontent.com/dhimmel/indications/36f0c5f143618abbbf8c9eb94b7318cb5936fd61/merge.html)) now that the mixed content bug has been fixed.","17",2015-05-06,2015-05-06,2,684,"base.profile","Daniel","Himmelstein","dhimmel"
"180","comments","meta","2015-05-07T05:11:38.596Z",17,"I see both sides of the issue. Our most valuable [discussion thus far](http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21) includes 21 posts from 5 users. The initial topic was general and recruited important suggestions, however specific conversations arose where separate discussions would have provided a clearer picture. However, I'm not sure these divergent topics could have been anticipated beforehand.

## Specificity trade-off

I see a specificity trade-off that:

1.  If discussions are general, the posts within need organization -- I have been using headings and user mentions as a partial solution.
2. If discussions are specific, the discussion list can become unwieldy. A search/filter feature as well as tags in the [discussion menu](http://thinklab.com/p/rephetio/discussion) could help.

I have found extensively hyperlinking topics in my posts helps to alleviate both these issues ([example](http://thinklab.com/discussion/extracting-indications-from-the-ehrlink-resource/62#181)).

## Post dependency proposal

If discussions stay general, I can imagine a dependency linking feature between posts could be helpful. For example, an option would enable me to add your initial post as a dependency to this present post. In other words, to understand my post, one should first read it's dependencies. When viewing a post, a user could ask to collapse all previous posts in the discussion that are not part of the dependency chain. The [benefits of flat discussion](http://thinklab.com/discussion/why-thinklab-uses-a-flat-discussion-structure-not-threaded/63) would be maintained, while incorporating advantages of a threaded model.

## Reply as new discussion

The *reply as new discussion* feature is a great idea. We have already manually taken advantage of an analogous feature by hyperlinking. See @jspauld's [post here](http://thinklab.com/discussion/comments-notes-interface-and-behaviour-suggestions/60#194). Therefore unless you see a great user experience benefit to the dedicated feature, I think it's a community standards and education issue mostly.","17",2015-05-07,2015-05-07,2,2131,"base.profile","Daniel","Himmelstein","dhimmel"
"181","comments","meta","2015-05-07T05:27:18.069Z",17,"# Markdown tables tip

I have found [tablesgenerator.com](http://www.tablesgenerator.com/markdown_tables) extremely helpful for generating markdown tables to input into thinklab posts. You can paste in tab delimited text and automatically generate the markdown format.","17",2015-05-07,2015-05-07,2,270,"base.profile","Daniel","Himmelstein","dhimmel"
"182","comments","meta","2015-05-08T00:09:21.365Z",23,">The markdown help page should provide a tutorial of all markdown features. It's fine if the TLFM-specific features are detailed first, but I've always found it annoying to track down markdown syntax through nested help docs.

I think the most useful thing (at least for me) would be to have a small javascript popup with a ""cheat sheet"" with summary information about the 80% of MD features that everybody uses. Not a guide (that could be linked to in the popup) but a set of short reminders.

Something like this (and this obviously doesn't fully work because of markdown interpretation!):

`````

# Header 1
## Header 2
### Header 3

*emphasized*
**bold**
~~StrikeThrough~~

[link text](http://linkaddress.com)

>You are quoting me right now,
and you still are.

Citations:
[@10.1002]
[@10.1002 @10.1002/aris.202 @10.1002/aris.203]
[@citation_key]: 10.1002/aris.201
[@citation_key]: http://www.optional-url.com ""Citation text in quotes""

`\``
function codeBlock() {print ""yes!""}
`\``
Some `inline code` might be the answer.

...
**Full mark down ressource**

`````


","23",2015-05-08,2015-05-08,2,1108,"base.profile","Antoine","Lizee","alizee"
"183","comments","meta","2015-05-08T00:35:02.081Z",23,"There might be pitfalls that we are overlooking, but I think the extra discussion structure is a great idea. We might fulfill the needed behavior with a simple structural design:

# Proposal:
- Any comment can have many children discussions.
- Any discussion can have one parent post.

## Pros:
- Simple. 
- Encourages flatter discussion by letting people track the proper background needed to understand what is going on for a given discussion.
- Lets an OP structure off the bat a subject (s)he wants to tackle, by having one ""general"" discussion whose first post spawns out several ""sub""-discussions.

## Cons:
It doesn't implement the comment dependency feature that @dhimmel is mentioning above, which I think is a good idea in general but an overkill for now. Especially, as a result of this proposal, the discussions should be pretty self-contained and dependencies of a post should be in the discussion itself, above the post of interest - or else mentioned in the body of the post.

## Challenges:
- Engineering: the simple dependency structure [discussion -hasOne-> parent post || post -hasMany-> children discussion] should be pretty straightforward to implement.
- Design: having a small UI per post, linking to the children discussions, and another UI per discussion, linking back to the parent post should be sufficient. Creation of the post/discussion links could be done in the edit view of a post, after the discussion is created, or in the edit view of the first post of a discussion (back to the parent comment). The bigger challenge is how to display this inter-discussion dependency when browsing discussions. We might want to hold off on thisvisualization for now.","23",2015-05-08,2015-05-08,2,1702,"base.profile","Antoine","Lizee","alizee"
"184","comments","meta","2015-05-08T20:33:02.298Z",22,"Hypothes.is gives a nice mechanism for markup of individual sentences or parts. I'd also be happy to pilot something like this with an R01(either A0 or A1) at some point if you want a test case for either a new submission or a revision of a larger grant. I'd like a system that is web based but that can output to an NIH style, that shows the grant as it would exist (e.g. with page marks, etc), that allows inline commenting, that works for the component documents that make up a grant.

I've used sharelatex but it didn't previously work with github for version control, though I think that was one of their requested features. Google docs is ok, but I'd like something that has the idea of a ""commit"" instead of live editing.","22",2015-05-08,2015-05-08,2,730,"base.profile","Casey","Greene","caseygreene"
"185","comments","meta","2015-05-09T00:17:29.525Z",2,"@caseygreene thanks for expressing an interest in this.

We're currently preparing a new version of the site with a focus on crowdsourced feedback for grant proposals so I would love to have you try it out!

I just want to clarify what you see as the primary benefits and the reason for your interest in piloting this. From my perspective the primary benefit is that we are creating an incentive for people to review your proposal. (By having feedback posted publicly and recognizing and *paying* people based on the value of their feedback.)

Are we on the same page there? Beyond this, what would be the requirements for trying this? You mentioned:

- Output to NIH style — You want to be able to output to PDF documents that can be directly attached to your proposal correct? This should be doable. 
- Inline commenting — Is your interest in this that you want people to be able to *make* comments inline or *view* comments inline? Do you basically want Google docs inline commenting feature reproduced? Making comments inline (by selecting text to quote) should be quite doable and seems like a good idea, however, viewing comments inline could be quite tricky. Consider that this discussion thread (that you're reading) might be a discussion thread on your proposal.
- The idea of a ""commit"" — Could you describe what you're looking for here and why? Currently, ThinkLab creates a commit with each ""save"" of the proposal. There's no integration with GitHub but there is a revision history page.

Any further information would be very helpful. Thanks!","2",2015-05-09,2015-05-09,2,1567,"base.profile","Jesse","Spaulding","jspauld"
"186","comments","meta","2015-05-09T13:49:58.397Z",22,"@jspauld -- here are my current thoughts:


Output: Yes. PDF documents with appropriate margins, size 11 arial, figures + legends that meet the requirements of an NIH grant. It could also just output to plain text that could be incorporated quickly into a word processor template. Accurate length estimates (""~11 formatted pages"") are critical though if it doesn't handle the output.


Inline commenting: I'd like to see people be able to make comments inline. On the view front, that could be configured on a proposal by proposal or even comment by comment basis. Something double-opt-in for public comments would be great. (author either pre or post commenting clicks a button to flag a comment as visible, comment contributor can mark as allowing a comment to be made visible). I can definitely imagine cases where someone comments:

CX: Commenter X
A: Author

C1: Have you thought about XYZ?
A: Yes, due to ABC we didn't talk about them here but we could add Z, would that be more clear?
C1: I think you really need X and Y as well.
C2: What about Q which shows that Z depends on X and Y?
A: @C2 @C1 -- Thanks! This really helped me clarify this. Take a look at the next commit and let me know if you think it helped.

I like the way that medium does inline comments (essentially on a paragraph by paragraph basis):
https://medium.com/@greenescientist/why-do-you-want-to-be-a-scientist-e4a94a93af78


The idea of a commit: essentially labeled savepoints. More like a tag if you're already essentially versioning each save. I think that by default it'd be nice to have only tagged versions be visible (or even only specific tagged versions). There are times where feedback is helpful, and other times where I'm trying to figure out how to best structure something and feedback at that point can just be more time consuming.

This might be something that I'd have to try, see how it works, and then see how my opinion changes during the process.","22",2015-05-09,2015-05-09,2,1970,"base.profile","Casey","Greene","caseygreene"
"187","comments","meta","2015-05-19T00:36:31.026Z",2,"We are now registering DOIs for ThinkLab discussions (excluding discussions in Meta) and we've created a suggested citation format that displays in the sidebar. For example [this thread](http://thinklab.com/discussion/mining-knowledge-from-medline-articles-and-their-indexed-mesh-terms/67) could be cited as follows:

> Daniel Himmelstein, Alex Pankov (2015) Mining knowledge from MEDLINE articles and their indexed MeSH terms. ThinkLab. doi:10.15363/thinklab.d67

Note that comment authors appear in the order in which they appear in the thread. If this creates an incentive to add low value comments to the discussion, we could make sure only to include authors of comments that have been rated as valuable.

# Citation of individual comments 

We could also create a suggested citation format for each individual comment. Is this worthwhile? Perhaps in one of these three ways:

> Alex Pankov (2015) Comment #3 in discussion ""Mining knowledge from MEDLINE articles and their indexed MeSH terms"". ThinkLab. doi:10.15363/thinklab.d67

> Alex Pankov (2015) Comment #3 in discussion ""Mining knowledge from MEDLINE articles and their indexed MeSH terms"". ThinkLab. http://thinklab.com/d/67#223

> Alex Pankov (2015) Comment #3 in discussion ""Mining knowledge from MEDLINE articles and their indexed MeSH terms"". ThinkLab. http://dx.doi.org/10.15363/thinklab.d67#223

Please note that the comment doesn't actually have it's own unique DOI. The last option here only works because ""#223"" gets passed along to the URL redirect.

# Citing discussions from within ThinkLab

Discussions may be cited using DOIs in the same way [any DOI can be cited](http://thinklab.com/help/writing-in-markdown). However, we'd also like people to be able to cite discussions with a normal link. (This will enable them to link to a specific comment -- those links can now be obtained by clicking the comment time/date.)

The plan is to have a discussion's sidebar display all ThinkLab pages that are citing it.

This raises a few questions:

1. If people link to a discussion from a proposal should that discussion be listed as a reference at the bottom of the page? I'm thinking no because if it was wanted to be an official reference it could be included using the DOI citation feature.

2. Should we have some visual cue that tells people a link goes to another discussion page? I'm thinking perhaps an icon or a different background color behind the text.

3. Should people be able to hover over the link and see a preview in the same way they can for a DOI citation?

Any other feedback is welcome!","2",2015-05-19,2015-05-19,2,2610,"base.profile","Jesse","Spaulding","jspauld"
"188","comments","meta","2015-05-19T03:29:51.714Z",17,"> authors appear in the order in which they appear in the thread

This makes sense to me. Another option would be to order by rated contribution. However, I am not sure how you could account for project members who don't get comment ratings. Author order conventions vary by field, so any automated ordering scheme will be inherently limited. One fallback option would be alphabetical, if problems arise.

> We could also create a suggested citation format for each individual comment. Is this worthwhile?

I believe so and think citers will lead the way here in determining the desired citation granularities -- might as well provide them flexibility.

Regarding the format, I think it is important to hyperlink to the specific comment. Perhaps we could get someone from the International DOI Foundation to advise on the durability of the hashtag passthrough method.

Regarding your three questions, my opinion is (1) no, (2) yes, (2) yes.","17",2015-05-19,2015-05-19,2,950,"base.profile","Daniel","Himmelstein","dhimmel"
"189","comments","meta","2015-06-15T06:31:09.395Z",2,"We've been using the term ""contributor"" to refer to Thinklab participants because it seems to make the most sense for projects that have been funded and are in the research phase.

However, given that [we're changing the focus of the site](http://thinklab.com/discussion/thinklab-as-a-vetting-system-for-traditional-grants/58) from ""leading an open research project"" to ""helping grant writers improve their research proposals"", it seems that the better term for ThinkLab participants is now ""reviewers"". When looking at the [homepage](http://thinklab.com/home) you can now see we have ""benefits for grant writers"" and ""benefits for reviewers"". I think this language will make the most sense for new users.

At this moment, the site is using both terms depending on whether the project is in the proposal stage or the research stage. However, I feel this is simply too confusing.  I feel we need to pick one term. I'm leaning towards ""reviewers"", because it makes the most sense for the first part of the project.  And that's where I think we're going to attract new users of the site. And at this point in time, that needs to be the primary goal.

@dhimmel and @alexanderpico do you have any thoughts on this?","2",2015-06-15,2015-06-15,2,1215,"base.profile","Jesse","Spaulding","jspauld"
"190","comments","meta","2015-06-15T06:53:37.988Z",2,"Using pure markdown for including figures and tables in ThinkLab proposals and project reports has seemed to be less than ideal. Sure you can include an image or markdown table and type in ""figure 1"" or ""table 1"" underneath it, but then that's all you've got.

Our new figures feature offers the following:

- Figures and tables just look prettier. See the [Pathways4Life  proposal](http://thinklab.com/p/pathways4life/proposal).
- Figures and tables can be moved around and we automatically update its position (ie. we'll change ""Figure 1"" to ""Figure 2"" for you.)
- We'll be able to add click-to-zoom and download features. (Coming soon)
- We'll be able to register a DOI if that's something people want?

@dhimmel do you want to try this out on your proposal? Let me know if you have any feedback.","2",2015-06-15,2015-06-15,2,808,"base.profile","Jesse","Spaulding","jspauld"
"191","comments","meta","2015-06-15T16:15:31.906Z",17,"Great implementation.

@jspauld, I added the tables and figures using markdown, i.e. `[:figure](metagraph)`. However, the figure description prints as `None`. When I changed the caption alignment, the description started properly displaying. I didn't resolve the error for the two tables, if this will help you diagnose.","17",2015-06-15,2015-06-15,2,322,"base.profile","Daniel","Himmelstein","dhimmel"
"192","comments","meta","2015-06-15T22:11:20.528Z",17,"I do not have a strong opinion here. Contributor is a broader term that fits well for the research stage, but less well for the proposal stage.

Users will be more familiar with the term reviewer. Do you want users to behave as reviewers (in the context of traditional peer review) or do you want to differentiate Thinklab participation from traditional review?","17",2015-06-15,2015-06-15,2,363,"base.profile","Daniel","Himmelstein","dhimmel"
"193","comments","meta","2015-06-16T07:32:27.961Z",2,"It's a bit hard to say how we want users to behave. Ultimately, the guiding principle is that we want users to behave in a way that results in the most efficient creation of value for society.

I think there are 4 general categories of contribution that could be given:

1. Evaluating proposals and other content
- Giving feedback on proposals and other things
- Contributing ideas
- Actually doing small amounts of work (perhaps writing some code or doing some statistical analysis)

I think the first points fall more into the category of review while the second fall more into the category of contribution. I do think review could be considered a form of contribution -- but not necessarily the other way around. So that argument would suggest ""contributor"" is the better term.

However, I feel the argument that the term reviewer will make ThinkLab more approachable and understandable for new users trumps the other argument.

At the end of the day this is something we'll be able to easily change in the future so it's really not that big of a deal.","2",2015-06-16,2015-06-16,2,1068,"base.profile","Jesse","Spaulding","jspauld"
"194","comments","meta","2015-06-16T08:01:12.394Z",2,"@dhimmel in my estimation it makes more sense for table titles and descriptions to appear above the tables not below. This is because as readers I think people will want to first understand what the table is by reading the title and description. On the other hand for figures I think it's more reasonable people would want to scan the figure before reading about it.

I guess it's a standard to always have the descriptions below is it? But do you have any idea why? Do you think below is better?","2",2015-06-16,2015-06-16,2,498,"base.profile","Jesse","Spaulding","jspauld"
"195","comments","meta","2015-06-16T18:44:34.245Z",17,"I am slightly embarrassed that I had yet to develop an opinion on caption placement.

Captions above tables and below figures is used by [PeerJ](https://peerj.com/) -- a publisher that scrutinizes over design decisions. I switched my proposal to this layout and prefer the new aesthetic. At first it seemed incongruous to place the caption differently for figures versus tables, but on closer examination I don't sense incongruity.

I'm interested in @ksimeonov's judgement on this matter.","17",2015-06-16,2015-06-16,2,493,"base.profile","Daniel","Himmelstein","dhimmel"
"196","comments","meta","2015-07-07T18:55:08.081Z",17,"How frequently do citations update their metadata in the Thinklab database?

I occasionally run into the problem where a DOI reference isn't in CrossRef, primarily because the article was just published. Therefore when I add the citation to a discussion, the citations displays as ""Citation not found"" ([example](http://thinklab.com/doi/10.7717/peerj.1054)). Eventually, the metadata is populated in CrossRef, but Thinklab does not update.

For cases where ""citation not found"", frequent automatic updates should be occurring in the background. A manual refresh button on a paper's page would be one approach. However, I think automatically updating metadata for all papers on a schedule is a good idea.","17",2015-07-07,2015-07-07,2,707,"base.profile","Daniel","Himmelstein","dhimmel"
"197","comments","meta","2015-07-08T04:08:49.097Z",17,"When replacing a figure with a newer version there should be better feedback that the replacement succeeded. Currently the preview image doesn't update after choosing a new file and the proposal only updated in my browser after a refresh.","17",2015-07-08,2015-07-08,2,238,"base.profile","Daniel","Himmelstein","dhimmel"
"198","comments","meta","2015-07-12T03:40:55.082Z",17,"I experienced this issue again when adding my recently publication [@10.1371/journal.pcbi.1004259]. Interestingly, the record was returned by the [online crossref search](http://search.crossref.org/?q=10.1371%2Fjournal.pcbi.1004259) prior to me adding the DOI citation in Thinklab. However, the citation still failed. Is crossref's API database that Thinklab uses different than the crossref online search database?","17",2015-07-12,2015-07-12,2,415,"base.profile","Daniel","Himmelstein","dhimmel"
"199","comments","meta","2015-07-12T04:36:12.686Z",2,"I have a ticket open with Crossref regarding this exact issue. Will post here when it's resolved.","2",2015-07-12,2015-07-12,2,97,"base.profile","Jesse","Spaulding","jspauld"
"200","comments","meta","2015-07-28T21:47:40.290Z",17,"While not found citations have appeared to update in the Thinklab database, they still render as not found on proposal and discussion pages. I am not sure whether this only applies to references entered before the metadata resolved. The next paragraph will diagnose.

See these two studies with the issue: [@10.1371/journal.pcbi.1004259 @10.7717/peerj.1054]

","17",2015-07-28,2015-07-28,2,363,"base.profile","Daniel","Himmelstein","dhimmel"
"201","comments","meta","2015-08-09T05:54:31.288Z",125,"The idea of having impact points and a leaderboard is no doubt to gamify the work.

However, for that to work, it has to actually motivate participants. Spending a couple of hours writing multiple comments to give thought-through input to people and seeing your impact points staying at a solid 0, unfortunately achieves the exact opposite.

I am mystified as to what does give impact points, if giving scientific feedback and answers to questions does not.","125",2015-08-09,2015-08-09,2,461,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"202","comments","meta","2015-08-09T08:02:49.274Z",2,"Thanks for the feedback Lars. It is really helpful to understand the experience of a new user.

Points are accumulated in relation to to peer ratings of your comments. By giving well thought out, useful comments you're doing exactly the right thing! Your points have stayed at zero because our system only updates them daily. I will try and make this more clear. I assume that if you had have known this, everything would be cool right?

Your comments have been rated and I expect that in a few hours from now that will be reflected on the site. When this occurs, please let me know if things are motivational (as intended).

Thanks for trying out ThinkLab!","2",2015-08-09,2015-08-09,2,663,"base.profile","Jesse","Spaulding","jspauld"
"203","comments","meta","2015-08-09T08:12:22.110Z",125,"And now I see points - thanks :-)

A few suggestions for improvements:
- Update points and leaderboard realtime instead of daily. Successfully gamifying something is all about instant gratification.
- Related to this, give maybe 1 impact point before peer rating as immediate reward for doing something. This does not necessarily need to give any money - it is just an immediate pat on the back.
- Money and more points can come later as comments get rated.","125",2015-08-09,2015-08-09,2,462,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"204","comments","meta","2015-08-09T15:49:40.333Z",17,"I agree that realtime updates are desirable for the reward system. Several people who have contributed think they've earned zero, since all their contributions were in a single day and they never saw an update.

Perhaps the mouseover on the impact points could also indicate the user's number of payment eligible unrated comments. This way users know points are on the way, just that rating must happen first.","17",2015-08-09,2015-08-09,2,411,"base.profile","Daniel","Himmelstein","dhimmel"
"205","comments","meta","2015-08-09T22:01:21.603Z",2,"# New mechanisms for instant gratification

Great feedback guys. I agree with you both on the desirability of instant gratification. For this reason I've made the following changes:

1. Rating a comment will now instantly give you 1 point
2. Adding a comment will also instantly give you 1 point. This point will not affect your earnings but it will influence the leaderboard (and hopefully make your life just that much better, lol). Thanks for this idea Lars -- I had not even thought of the possibility.

# Arguments against real-time updates of peer assessed points

A few arguments against this:

1. I think it's better to have comment scores be secret (or at least hard to guess). If we give real-time updates it would be quite easy to guess who rated your comment and what score they gave you in some scenarios. For example, if you saw that they made a comment in the same discussion at the same time.
2. One interesting aspect of the current system is that it's possible for a user's impact points and *unconfirmed* earnings to go *down*. This would happen when a rating is given that is lower than the comment's average rating. I suspect from a gamification perspective this is quite bad. One way we can mitigate this is to put a damper on points earned when just one or two people have submitted ratings. So two ratings of 10 would result in more points than just one rating of 10. And a rating of 10 followed by a rating of 5 would result in less of a reduction of points than it would otherwise. Combining this functionality with daily updates should significantly reduce the likelihood of a users's impact points  progressing backwards. The reason is that the effect of any one rating will be averaged in with the effects of all other ratings that occur in that 24 hour period. And any rating should, on average, increase points scored (because of the damper I mentioned).
3. Finally, since peer ratings will not provide ""instant"" gratification anyway, it's probably not that big of a deal to just do the updates daily.

# Inspiring confidence in new users

> Several people who have contributed think they've earned zero, since all their contributions were in a single day and they never saw an update.

To address the issues brought up by @dhimmel I propose the following:

1. When a user posts a comment we will make it more clear that it is 'payment eligible' (right now it is stated in small gray text), and perhaps provide a link to more information on what that means.
2. The first time a user has a payment eligible comment that has been rated positively we will send them an email saying something like ""Congratulations, one of your ThinkLab comments has been rated positively and you've begun earning money!"" (I feel this is a great idea!)
3. I've gone ahead and updated the ""[your points](http://thinklab.com/account/your-points)"" and ""[your comments](http://thinklab.com/account/your-comments)"" pages to try and clarify things and show the user if they have payment eligible comments.","2",2015-08-09,2015-08-09,2,3032,"base.profile","Jesse","Spaulding","jspauld"
"206","comments","meta","2015-08-09T23:36:47.951Z",2,"@larsjuhljensen I was just thinking -- it seems you were particularly put off by the fact that your score remained at zero despite the fact that you took the time to make some thoughtful comments. Well, let's just say you spent 30 minutes making your first comment -- would it really be that much better if your impact score said just ""1""? Maybe a little better, but I'm thinking we should detect this situation and put something like ""Updating.."" instead of ""1"", and if the user hovers over it it will say something like ""This user's impact score will display after their first comments have been rated"". What do you think? I think it is worth optimizing for first impressions","2",2015-08-09,2015-08-09,2,677,"base.profile","Jesse","Spaulding","jspauld"
"207","comments","meta","2015-08-10T04:27:32.523Z",125,"Thanks @jspauld - I think your ideas are very good. I especially like the idea about putting a damper on the rating.

Having your earnings possibly go down due to later ratings that lower the average, would indeed seem bad from a gamification viewpoint. Viewing ratings a bit more like votes on stackoverflow makes sense to me: one person liking something a lot and nobody else bothering to even rate it is clearly not as good as several people liking it a lot. So calculating the simple average seems suboptimal.

Regarding getting 1 point versus staying at 0, I think it makes a big difference. If nothing else, it makes it clear to the user that making comments is indeed how you earn points. This is also why I think real-time updating is important: the first day I was baffled and beginning to wonder how one even earns points in this place. Because it was apparently not by making comments, since I had made several and still had 0 points.

","125",2015-08-10,2015-08-10,2,953,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"208","comments","meta","2015-08-10T08:28:24.395Z",2,"> one person liking something a lot and nobody else bothering to even rate it is clearly not as good as several people liking it a lot

Agree. I think a simple average is suboptimal, and I also think a simple sum (like stack overflow) is suboptimal -- so somewhere in the middle.

I'm thinking that with only 1 vote there is a damper that results in the user receiving just 30-50% of the points scored, while if there were 5 votes it might be 90%. The difference between 5 votes and say 50 votes would then be quite small. But this is just one way of doing it. We could make it so there is a substantial difference between 5 and 50. I think the effect would be to reward participation in ""popular"" discussion threads and my current thinking this is not a particularly good idea. But I'm open to arguments for it.

Of course, we don't have any comments that have been voted on 50 times yet so it's a little premature to be thinking too much about this!","2",2015-08-10,2015-08-10,2,957,"base.profile","Jesse","Spaulding","jspauld"
"209","comments","meta","2015-08-11T04:08:51.773Z",17,"While I understand that a decrease in unconfirmed earnings may pester users, I am worried about the flip side. Currently, posts receive very few ratings and it's unclear when a cultural shift will occur towards more widespread rating. When a new user contributes, I lean on the generous side to reward them for their sunk time investment in setting up an account and learning how to use Thinklab. I think it's important for users to see that their work is being valued highly. Therefore, I think whatever downweighting scheme is adopted, the full rating of their contributions should also be made apparent.

Overall, I am not convinced a dampening scheme is needed. This seems more like an education issue. For example, I personally am not bothered by diminishing unconfirmed earnings because I understand the mechanism and believe it to be fair. However, I am far from the target audience, which at this point is new users, so take my opinion with a grain of salt.","17",2015-08-11,2015-08-11,2,967,"base.profile","Daniel","Himmelstein","dhimmel"
"210","comments","meta","2015-08-11T05:02:30.287Z",17,"Thinklab takes a bold and unprecedented approach to rewarding scientific contribution. The mechanisms of this system are in their infancy and would benefit from an analysis of existing rating data. And the [meta project](http://thinklab.com/p/meta) is an ideal forum to have this discussion.

For example, @larsjuhljensen -- a recent community addition -- rated 55 comments on [our project](http://thinklab.com/p/rephetio/leaderboard) which I have also rated. Analyzing the concordance of our ratings and drawing insights from the differences would be [instructive for the platform](http://thinklab.com/discussion/impact-points-and-leaderboard-demotivating/98). I envision a @dhimmel by @larsjuhljensen scatterplot of comment ratings, colored by comment author and outlined by per-author chronology.

However, rater identities are currently private. Since there are presently few ratings, privacy is easily unmasked by a diligent party. Nonetheless, I think it's important that privacy be maintained. One potential workaround to enable analytics is that **raters choose to make their identity public**. Fundamentally its a user's own prerogative to publicize their ratings.

Since any meaningful analysis of the current rating database will compromise rater identities, I think consented transparency is a must. Therefore if @larsjuhljensen is willing to make his ratings up till now public, so am I, and we could proceed with the aforementioned analysis.

Of course, the desire to remain private is *no questions asked* affair. However, if all concerned parties (@larsjuhljensen, @jspauld, and I) are okay with the proposed analysis, I will happily proceed.

Finally, I think there is a longer term potential for optional public rating. Perhaps this could be implemented as a non-default option on the rating bar. Not that public rating identities need to be immediately visible, but that when analysis comes knocking data will be available. In many instances, I think it will be instructive to know who rated what how. And leaving that choice up to the rater should avoid any nasty consequences.","17",2015-08-11,2015-08-11,2,2107,"base.profile","Daniel","Himmelstein","dhimmel"
"211","comments","meta","2015-08-11T05:19:12.125Z",125,"I think the big issue with averaging is that different users will use the scoring schemes completely differently.

Some will only vote if they think a comment actually contributes something substantial (as opposed to, e.g., stating the obvious). Others, like myself, try to remember to rate everything that I've read. The vast majority of comments was in my opinion not worth $5, and I thus rated them $0.

The problem here is that numerically it makes a huge difference if I rate something $0 or if I do not rate it. However, to me it means exactly the same thing.","125",2015-08-11,2015-08-11,2,569,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"212","comments","meta","2015-08-11T16:29:41.212Z",2,"> While I understand that a decrease in unconfirmed earnings may pester users, I am worried about the flip side.

@dhimmel I just want to clarify that this down weighting will NOT mean that everyone in your project will suddenly be receiving 50% less payment. If I implement this (which I was always planning to do), I'll do it in such a way that considers the relative amount of voting that is occurring in the project, and perhaps instead of just dampening scores when there's less votes it can actually increase scores with more votes.

Having said that -- you probably shouldn't think about the exact rating you give as some kind of ""full rating"" that should be exposed. The reason is there will be many things that can affect the actual number of points given. For example, one of them will be the relative stinginess/generousness of whoever is doing the rating. There's also factors that affect the weight of each rating, such as if the rater is on the project research team (weighted higher) or if the rater is from the same institution (weighted lower).

> I think the big issue with averaging is that different users will use the scoring schemes completely differently.

@larsjuhljensen I take your point that some people may simply not rate a comment rather than rate it at $0 and that these same people when they encounter a more valuable comment may take the time to score it. 

I'm not terribly concerned about this. Firstly, it will be a consistent phenomenon that will affect all users equally. So the question is -- does it create any bad incentives? And you could say it would encourage shorter less well thought out comments because they're more likely to get paid out $3-5 instead of the $1-3 they might deserve. This is a fair concern. But the reality is there will be ways we can tackle this. The dampening will help. But as @dhimmel mentioned -- we can explicitly state that a requirement for a good [participation score](http://thinklab.com/how-it-works/earnings) is that you rate comments 0 when appropriate. Theoretically we could also detect such cases of scrolling past comments without bothering to vote on them.

And I'll just mention an idea I've had. We could give comment posters the option to click a button that says ""This comment is not a significant contribution"". And for these comments we wouldn't even ask people to rate them. Would save people the trouble of having to rate every single comment. And when there is a trivial comment that someone failed to click the checkbox for -- well people will feel more motivation to click 0.","2",2015-08-11,2015-08-11,2,2582,"base.profile","Jesse","Spaulding","jspauld"
"213","comments","meta","2015-08-14T09:55:53.393Z",2,"Good ideas. However, I have significant concerns.

> if all concerned parties (@larsjuhljensen, @jspauld, and I) are okay with the proposed analysis

This is something that probably should have been suggested privately. I think suggesting it publicly puts unfair pressure on @larsjuhljensen. In any case, I'm not sure it's something we should do right now -- I think this would create a mistaken impression that rating data is public information. Of course, I'm not saying your proposed analysis wouldn't be interesting or potentially useful. And I'm also not saying that we wouldn't do such analysis *internally* at ThinkLab.

> Finally, I think there is a longer term potential for optional public rating.

At this point I'm skeptical that this is a good idea. Even if people are choosing to make their ratings public I imagine this could still easily create bias. For example, will people feel comfortable rating a colleague or respected scientist with a low score? And if someone sees they've been rated high/low will they feel compelled to return the favor/non-favor?

How about we revisit this idea at some point in the future when there is a lot more ratings data? Perhaps you can suggest some analysis that we can do internally, and we can publish the results in a blog post.","2",2015-08-14,2015-08-14,2,1293,"base.profile","Jesse","Spaulding","jspauld"
"214","comments","meta","2015-09-28T22:44:54.794Z",17,"DOI resolution no longer requires the `dx` subdomain. For example, `http://dx.doi.org/10.15363/thinklab.4` can be shortened to `http://doi.org/10.15363/thinklab.4`. The [DOI documentation](http://www.doi.org/factsheets/DOIProxy.html) indicates the short method is preferred:

> Users may resolve DOI names that are structured to use the DOI system Proxy Server (http://doi.org (preferred) or http://dx.doi.org). The resolution of the DOI name in this case depends on the use of URL syntax: the example DOI name doi:10.10.123/456 would be resolved from the address: ""http://doi.org/10.123/456"". Any standard browser encountering a DOI name in this form will be able to resolve it. The proxy service (both doi.org and dx.doi.org) is accessible over IPv6, and supports DNSSEC. The proxy servers respond to HTTPS as well as HTTP requests.

I have begun switching to the short format and suggest Thinklab does as well. Some community projects such as [`PeerJ/paper-now`](https://github.com/PeerJ/paper-now) have [already](https://github.com/PeerJ/paper-now/commit/e9ea8bb2c21287ff8f77c8f17e9d9a30c1a20816) migrated.","17",2015-09-28,2015-09-28,2,1114,"base.profile","Daniel","Himmelstein","dhimmel"
"215","comments","meta","2015-09-30T04:58:39.289Z",2,"Thanks Daniel. We've updated things to use the shorter URL. Please keep the feedback coming..","2",2015-09-30,2015-09-30,2,93,"base.profile","Jesse","Spaulding","jspauld"
"216","comments","meta","2015-10-04T17:23:14.048Z",17,"Currently, Thinklab's [markdown engine](http://thinklab.com/help/writing-in-markdown) does not properly format inline code or math in headings, i.e. the heading style isn't applied. Neither of these are major issues for me, but I would use the inline code in headings if fixed. GitHub [for example](https://github.com/dhimmel/elevcan/issues/1#issuecomment-138615325) properly formats code in headings.

***
## Code

Paragraph with  `code`

> blockquote with `code`

# Heading with `code`

> # blockquote heading with `code`

***
## Math

Paragraph with $$1+1=2$$

> blockquote with $$1+1=2$$

# Heading with $$1+1=2$$

> # blockquote heading with $$1+1=2$$
","17",2015-10-04,2015-10-04,2,680,"base.profile","Daniel","Himmelstein","dhimmel"
"217","comments","meta","2015-10-19T21:09:21.631Z",2,"Thanks I've put this on the to do list","2",2015-10-19,2015-10-19,2,38,"base.profile","Jesse","Spaulding","jspauld"
"218","comments","meta","2015-12-01T07:14:28.008Z",2,"As you can see above this has been corrected","2",2015-12-01,2015-12-01,2,44,"base.profile","Jesse","Spaulding","jspauld"
"219","comments","meta","2015-12-01T15:24:27.175Z",159,"First off, let me just say how generally well designed the ThinkLab site is. Really slick design and a lot of functionality. 

That said, it all feels a bit static. A sense of momentum is important! One thing that immediately strikes me about the site is that there is an absence of story, either about ThinkLab as a project (how did it start, how long has it been around ext) or about the proposals/users themselves (have they been funded, what was the use of thinklab to the researcher). 
","159",2015-12-01,2015-12-01,2,494,"base.profile","Joseph","McArthur","josephmcarthur"
"220","comments","meta","2015-12-01T15:59:40.257Z",17,"```
I think the correction has messed up text in code blocks.
Code no longer has a fixed width font.
```
I think the correction has messed up text in code blocks.
Code no longer has a fixed width font.","17",2015-12-01,2015-12-01,2,206,"base.profile","Daniel","Himmelstein","dhimmel"
"221","comments","meta","2015-12-02T10:00:51.426Z",2,"Hi Joe. I really appreciate the feedback. Storytelling has never been my strength so it doesn't surprise me if the site is weak in that regard.

To start to address this I've made a couple changes already. We're now displaying the 'Blog' and 'About' sections more prominently in the header (for users not logged in already).

![image](https://cloud.githubusercontent.com/assets/1437696/11527424/e433e21e-991b-11e5-81d5-d0e4b69bd39b.png)

In the [about section](http://thinklab.com/about) it now starts with a page called 'Our story'. Here's what I think might potentially be interesting about the story. (And I haven't actually included these on the story page but let me know if you think I should.)

- I have no background in academia which gives me a fresh perspective
- I've taken a very [first principles](https://www.youtube.com/watch?v=NV3sBlRgzTI) approach to understanding the problem and what kind of solution might fix the underlying systemic issues and create good incentives going forward
- I want to avoid taking investment money from anyone not bought into the mission as the primary objective
- I could talk about how [I conceived of the idea while thinking about how the internet could be used to reimagine democracy](http://jspauld.com/post/93322268131/thinklab-building-a-startup-team-to-fix-science) -- but that might muddle the message?

Anyway I would appreciate any further details on how we can tell a better story. And more broadly, the question I'm concerned with is how can we make people *really want* to support Thinklab? 

Any further suggestions would be very much appreciated!","2",2015-12-02,2015-12-02,2,1623,"base.profile","Jesse","Spaulding","jspauld"
"222","comments","meta","2015-12-03T19:32:29.688Z",161,"I think that it would help to know the background. I really like the layout but I am still not sure how to best use thinklab. ","161",2015-12-03,2015-12-03,2,126,"base.profile","Shelley","Mason","shelleymason"
"223","comments","meta","2015-12-16T06:08:50.992Z",2,"Thanks for your feedback everyone. We've announced this feature here: [Thinklab open grant proposal review has arrived!](http://thinklab.com/blog/thinklab-open-grant-proposal-review-has-arrived/125)","2",2015-12-16,2015-12-16,2,198,"base.profile","Jesse","Spaulding","jspauld"
"224","comments","meta","2016-01-13T18:36:02.608Z",176,"While I really like the intuitive Markdown format for authoring proposals and including figures, I found that I would have really liked a PDF upload option for creating new ideas and proposals. Before I was referred to this site by a colleague, I had already used LaTeX to create a PDF of my proposal and sent it out for a first round of institutional review. I found that having to rewrite everything in Markdown was off-putting because I already had a properly formatted PDF that was ready to go. Having things in a PDF was also important for me personally since I had a strict page limitation.

Therefore, I propose adding a PDF upload or document upload button for the idea/proposal creation process. I do not yet know how the annotation phase would work with PDFs, since that might be more complicated, but I think including the upload function as an option would lower the barrier of entry for new users of the site.","176",2016-01-13,2016-01-13,2,924,"base.profile","Tong Shu","Li","tongli"
"225","comments","meta","2016-01-13T18:59:33.889Z",176,"I found the process of converting my LaTeX formatted proposal into the Markdown format to be manual busywork that could have been better done by a program. Having an automatic LaTeX to Markdown conversion button would greatly reduce the workload of the proposal author.

I found that this conversion process consisted of a few separate tasks:

1. Remove any LaTeX specific code (e.g. `\documentclass{}`) and convert special characters (e.g. `\%`) to their regular counterparts.
2. Format LaTeX control sequences to the Markdown equivalent (e.g. changing `\section` to `#`).
3. Uploading figures and porting the labels and references (e.g. `\label{}` to `[:figure](metanodes)`).
4. Converting the Bibtex reference file to DOIs.

Of the above tasks, I found the Bibtex to DOI conversion the most annoying, since there were many references and the automatic export function of most websites do not include the DOI in the auto-generated Bibtex files.

If a fully automated LaTeX to Markdown converter is too difficult to write, then I would be more than satisfied to see a Bibtex to DOI converter, since that represented perhaps the task which took the longest.","176",2016-01-13,2016-01-13,2,1168,"base.profile","Tong Shu","Li","tongli"
"226","comments","meta","2016-01-13T19:21:25.503Z",17,"[Pandoc](http://pandoc.org/), the universal document converter, should be able to handle most of the conversion besides images and citations. Math will be trivial.

I generally lookup DOIs manually using [crossref](http://search.crossref.org/), although the lookup could presumably be mostly automated.","17",2016-01-13,2016-01-13,2,304,"base.profile","Daniel","Himmelstein","dhimmel"
"227","comments","meta","2016-01-13T21:44:02.865Z",176,"Cool, thanks for the tip!","176",2016-01-13,2016-01-13,2,25,"base.profile","Tong Shu","Li","tongli"
"228","comments","meta","2016-01-14T04:28:09.070Z",2,"Thanks for the great suggestion.

I suspect if we have a LaTeX file we could do most, if not all, conversion automatically. Perhaps with the help of Pandoc. Crossref has an API we are working with for DOI lookup so that shouldn't be a problem.

That said, I'm putting this as ""deferred"" for now because we're just going to provide a service where users can email us their proposal and we'll enter it for them. See new instructions for publishing a proposal:

![image](https://cloud.githubusercontent.com/assets/1437696/12315749/8ce0a8a2-bab9-11e5-9171-c3bf367bd880.png)

As soon as this becomes too much of a hassle we'll implement a more automated solution.

@tongli sorry you weren't made aware of this possibility sooner. But thank you for taking the time to enter your proposal -- your feedback has been very valuable.","2",2016-01-14,2016-01-14,2,832,"base.profile","Jesse","Spaulding","jspauld"
"229","comments","meta","2016-01-14T04:41:58.150Z",2,"Thanks Tong.

For the time being we've made it so users can simply email us support@thinklab.com and we will convert their proposal from whatever format they have it in. A docx or LaTeX file is preferred over PDF, however.

We will revisit this when things pick up, and we'll post in your thread regarding [conversion of LaTeX proposals](http://thinklab.com/discussion/latex-integration/139).","2",2016-01-14,2016-01-14,2,396,"base.profile","Jesse","Spaulding","jspauld"
"230","comments","meta","2016-01-14T18:09:44.813Z",176,"Ah, I wasn't aware of that option. That seems like a good way to attract new users and users who are not familiar with Markdown.","176",2016-01-14,2016-01-14,2,128,"base.profile","Tong Shu","Li","tongli"
"231","comments","meta","2016-01-20T16:32:42.905Z",48,"When a reviewer completes the review of a proposal, it might be useful to encourage them to synthesize their most cogent feedback over the whole thing as a comment - as if it were a blog post with a comment section.  When you get to the bottom, the system could ask for those more general thoughts, perhaps with a specific prompt of: **""would you fund this as it stands, why or why not?""**  That would help encourage the reviewer to crystalize their most important advice.","48",2016-01-20,2016-01-20,2,472,"base.profile","Benjamin","Good","b_good"
"232","comments","meta","2016-01-23T07:06:30.760Z",2,"Great feedback Ben! This clearly seems to be a missing feature.

I think what we'll do is add a 3rd step in the review process. For now this will just have a text entry field, but in the future this could have various ratings fields depending on the situation. I think it's best to have this review summary posted as a new discussion thread. This will allow people to reply to it and proceed with a discussion if they want. 

The alternative would be to post all the summaries in the same thread, or just have them as a separate thing that cannot be directly replied to.","2",2016-01-23,2016-01-23,2,574,"base.profile","Jesse","Spaulding","jspauld"
"233","comments","meta","2016-01-28T07:37:08.098Z",2,"@b_good @timputman @andrewsu if you guys would like to provide a review summary for @tongli's proposal [you can now do so](http://thinklab.com/doc/11/review). 

For now we've added this as a last step in the review process. Let me know what you think. My apologies for the slowness on getting this done.

![image](https://cloud.githubusercontent.com/assets/1437696/12637785/def1907e-c5d2-11e5-9150-8021f47557e0.png)","2",2016-01-28,2016-01-28,2,419,"base.profile","Jesse","Spaulding","jspauld"
"234","comments","meta","2016-02-01T22:14:00.660Z",176,"@jspauld 
I think some sort of final conclusion panel would also be really helpful. Ideally the ratings assigned by each reviewer for the various categories would be presented in a table format, so that the reviewers' responses can be compared to one another. Some more general comments about the changes which need to be made would also be helpful.","176",2016-02-01,2016-02-01,2,350,"base.profile","Tong Shu","Li","tongli"
"235","comments","meta","2016-02-17T22:56:27.741Z",17,"There's a bug where, on occasion, a link with title attribute causes some text to be excised.

For example, the following markdown:

```markdown
Switching relationship types to verbs also makes sense as part of our [migration to neo4j](http://thinklab.com/discussion/using-the-neo4j-graph-database-for-hetnets/112). The neo4j convention is to use verbs for relationship types. In fact, a neo4j company [explains relationships](https://www.graphstory.com/elements-of-a-graph-database ""Elements of a Graph Database · Graph Story"") by saying:
```

Renders as:

Switching relationship types to verbs also makes sense as part of our [migration to neo4j](http://thinklab.com/discussion/using-the-neo4j-graph-database-for-hetnets/112). The neo4j convention is to use verbs for relationship types. In fact, a neo4j company [explains relationships](https://www.graphstory.com/elements-of-a-graph-database ""Elements of a Graph Database · Graph Story"") by saying:","17",2016-02-17,2016-02-17,2,962,"base.profile","Daniel","Himmelstein","dhimmel"
"236","comments","meta","2016-02-18T01:32:35.265Z",2,"Good find! The source of the bug may be in the original markdown parser we used. This may take a while for us to resolve and we'd like to ask that you just avoid using titles in links for now. Removing the following will solve the problem:

```""Elements of a Graph Database · Graph Story""```","2",2016-02-18,2016-02-18,2,293,"base.profile","Jesse","Spaulding","jspauld"
"237","comments","meta","2016-02-18T01:41:26.381Z",17,"Okay, I suspect the bug has to do with the preceding internal Thinklab link. Check out the malformed popup when you hover over ""migration to neo4j"" [above](#1).","17",2016-02-18,2016-02-18,2,160,"base.profile","Daniel","Himmelstein","dhimmel"
"238","comments","meta","2016-02-18T04:36:28.738Z",2,"We were able to track down and correct the bug. 

The bug had been reported here: https://github.com/evilstreak/markdown-js/issues/162

And corrected by Discourse here: https://meta.discourse.org/t/weird-markdown-bug-when-using-inline-links-with-title/16926","2",2016-02-18,2016-02-18,2,261,"base.profile","Jesse","Spaulding","jspauld"
"239","comments","meta","2016-02-19T07:12:29.826Z",2,"Thanks great feedback. We will try to add ratings that replicate the criteria that the actual reviewers will be considering.","2",2016-02-19,2016-02-19,2,124,"base.profile","Jesse","Spaulding","jspauld"
"240","comments","meta","2016-02-22T02:03:39.176Z",17,"Doing open science, especially via _Thinklab_, requires writing lots of content. Given the fast pace, it's easy to make errors or typos. Yet, we would like our content to be part of permanent scientific record and hence adhere to a high literary standard.

Oftentimes readers will pick up on errors. Replying to a comment to point out typos or miswordings isn't ideal, because it distracts from topical discussion. A service called Hypothesis, which allows annotations of any webpage, may be a solution.

I first heard of [Hypothesis](https://hypothes.is/ ""The Internet, peer reviewed"") when @caseygreene mentioned it [here](http://thinklab.com/discussion/thinklab-as-a-vetting-system-for-traditional-grants/58#15) and [on twitter](https://twitter.com/GreeneScientist/status/690218330603556864). The service is gaining adoption in academia [@10.1038/528153a].

I gave Hypothesis a try on @pouyakhankhanian's [recent post](http://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95#7). His post was a doozy -- 2763 words (16645 characters) on his curation of our indication catalog -- and I anticipate it to become one of the most influential comments of our project. I [annotated writing errors](https://via.hypothes.is/http://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95#7) that Pouya was then able to fix by editing his post. I emailed Pouya to alert him of my annotations, but perhaps _Thinklab_ could auto-notify authors of annotated content down the road.

You can annotate with Hypothesis by going to `https://via.hypothes.is/` + `URL` where `URL` is the page you would like to annotate.","17",2016-02-22,2016-02-22,2,1708,"base.profile","Daniel","Himmelstein","dhimmel"
"241","comments","meta","2016-02-22T03:19:30.263Z",188,"To comment on my experience: 
I found Hypothesis to be relatively easy to use; the interface was quite intuitive. It took only moments to identify the mistakes. It was not just limited to typographic errors, but there were two sentences that were missing several words. It was certainly better for the readability of the discussion thread to make the corrections to the original post, rather than give minor corrections as a response to a response on the thread.","188",2016-02-22,2016-02-22,2,463,"base.profile","Pouya","Khankhanian","pouyakhankhanian"
"242","comments","meta","2016-02-22T15:53:04.686Z",2,"Sounds like a great solution guys. At some point in the future we should be able to setup automatic notifications of Hypothesis annotations.","2",2016-02-22,2016-02-22,2,140,"base.profile","Jesse","Spaulding","jspauld"
"243","comments","meta","2016-02-24T02:59:42.868Z",17,"I'd consider removing the current prompt and replacing it with either:

+ provide your general feedback on the proposal here
+ a prompt which is created by the proposal authors

In particular, I would remove ""would you fund this proposal as it stands?"" Since the reviewer is not in a position to actually fund the project, it's a moot point. I think the feedback is the valuable aspect of a review, and it's best to avoid forcing reviewers into making a subjective judgement that could have unintended or negative consequences. I believe the current standard for journal peer review is to omit your recommendation to the editor from the review body. I think it's fine to have reviewers score proposals based on metrics, but I see less benefit to the fund/no-fund prompt.","17",2016-02-24,2016-02-24,2,775,"base.profile","Daniel","Himmelstein","dhimmel"
"244","comments","meta","2016-02-24T17:52:25.333Z",2,"I think I agree with you. The intention was to get the reviewer in a frame of mind that the actual reviewers will be in -- get them thinking about any major flaws that would prevent it being funded.","2",2016-02-24,2016-02-24,2,198,"base.profile","Jesse","Spaulding","jspauld"
"245","comments","meta","2016-03-22T20:54:30.599Z",17,"# Outdated citation metadata persists

It appears that when a citation's metadata is not found, the process is repeated in the future until the metadata resolves. However, there is still an issue with citations that originally contained metadata but are now outdated.

For example, the [citation](http://thinklab.com/doi/10.15363/thinklab.4) to my project [@10.15363/thinklab.4] is very outdated. While the metadata for most DOIs, especially for traditional journal articles, will be more stable than evolving Thinklab projects, there will still be this problem.

I think it makes sense to:

+ periodically refresh citations with existing metadata
+ add a control on each citation page, to allow a logged-in user to request a metadata refresh.

One or both of these solutions would help address the problem.","17",2016-03-22,2016-03-22,2,818,"base.profile","Daniel","Himmelstein","dhimmel"
"246","comments","meta","2016-03-22T21:26:45.225Z",17,"When interacting with citations on _Thinklab_, the breakdown of my needs are as follows:

1. Go directly to the article on the publisher's website (55% of the time)
2. Copy the article's DOI for use elsewhere (40% of the time)
3. Copy a textual version of the citations including authors, title, journal, and year (4% of the time)
4. Go to the _Thinklab_ page for the article (1% of the time)

However, currently option 4 is most accessible and option 1 is quite difficult. Option 1 used to be easier when the citation popover could be interacted with. One easy fix would be to make the popover toggle on click rather than (or in addition to) hover.

As example citations, here are two papers that I find to be on the weak side [@10.1371/journal.pmed.0030190 @10.1098/rsos.150266].","17",2016-03-22,2016-03-22,2,790,"base.profile","Daniel","Himmelstein","dhimmel"
"247","comments","meta","2016-03-23T17:29:50.630Z",23,"I would just add a small note in the markdown guide (http://thinklab.com/help/writing-in-markdown) that returns are needed before and after the three dollars signs to insert a block. It took me a while to figure out.","23",2016-03-23,2016-03-23,2,216,"base.profile","Antoine","Lizee","alizee"
"248","comments","meta","2016-03-23T17:50:42.016Z",17,"Here's an example of what Antoine is talking about

## One newline -- does not work

```
Text
$$$
This + is = a \times math block
$$$
Text
```

Text
$$$
This + is = a \times math block
$$$
Text

## Two newlines -- does work

```
Text

$$$
This + is = a \times math block
$$$

Text
```

Text

$$$
This + is = a \times math block
$$$

Text

**Other issue:** Math should probably be disabled inside code blocks. Until then this example will be weird.","17",2016-03-23,2016-03-23,2,485,"base.profile","Daniel","Himmelstein","dhimmel"
"249","comments","meta","2016-03-24T18:39:42.422Z",2,"@alizee thanks for pointing this out. I removed the requirement for having any line breaks before or after the three dollar signs. You might have to refresh the page to get that to work.

@dhimmel you are correct -- Mathjax should be disabled within code blocks. I think we'll save this one for later.","2",2016-03-24,2016-03-24,2,303,"base.profile","Jesse","Spaulding","jspauld"
"250","comments","meta","2016-03-24T20:33:36.645Z",2,"All Thinklab DOIs will no longer need metadata refreshes from Crossref. We are the source of this metadata so we don't need to query Crossref for it. You can see the metadata for your project is now correct above.

Non-Thinklab DOIs can now have their metadata updated by clicking the More > Update Metadata from the publication's Thinklab page.

For now we haven't added the periodic metadata refresh, but this could be considered later.","2",2016-03-24,2016-03-24,2,442,"base.profile","Jesse","Spaulding","jspauld"
"251","comments","meta","2016-03-24T21:49:40.575Z",2,"I've made it so the popover remains visible if you hover over it. This allows you to copy the citation or click the DOI. 

We could make the main link go directly to the external page instead of a Thinklab discussion page. The reasons we haven't done this are A) For SEO purposes we expect having contextual links to our publication pages is a very good thing and B) We want to make people aware that they can discuss publications on Thinklab. I think this last point could be accomplished by making some references to discussions in the popup box. And with regard to the SEO benefits: I think they can be sacrificed if it improves the user experience.","2",2016-03-24,2016-03-24,2,654,"base.profile","Jesse","Spaulding","jspauld"
"252","comments","meta","2016-03-24T23:33:38.763Z",17,"> For SEO purposes we expect having contextual links to our publication pages is a very good thing

This is an interesting point. However, it may not be bad -- now when I search for Thinklab content via google, I receive publication and tag pages. But, I'm almost always looking for the discussion pages which are home to the actual content rather than the aggregation pages.

> B) We want to make people aware that they can discuss publications on Thinklab. I think this last point could be accomplished by making some references to discussions in the popup box.

Definitely, and the popover could more clearly state which link brings you to Thinklab content and which link brings you to the paper. In the future, I image more links could even be added such as links to citation databases, Altmetrics, and PubMed.","17",2016-03-24,2016-03-24,2,820,"base.profile","Daniel","Himmelstein","dhimmel"
"253","comments","meta","2016-03-24T23:36:11.622Z",17,"> For now we haven't added the periodic metadata refresh, but this could be considered later.

With the manual refresh, this probably isn't super necessary. In fact you could imagine some instances where metadata was originally correct, but it somehow gets corrupted or deleted from crossref. In these cases, auto-refresh would be undesirable.","17",2016-03-24,2016-03-24,2,345,"base.profile","Daniel","Himmelstein","dhimmel"
"254","comments","meta","2016-03-25T22:16:02.845Z",17,"When I try to print out Thinklab pages, URLs get inserted after hyperlinks and result in an unaesthetic typesetting.

For example, the title of the composition window becomes:

#### New discussion in project: Thinklab Meta (/p/meta)

I assume this is due to a [default bootstrap behavior](http://drupal.stackexchange.com/a/59908 ""How to get rid of added URLs when printing a Bootstrap-themed page?""), and I find it highly undesirable.","17",2016-03-25,2016-03-25,2,440,"base.profile","Daniel","Himmelstein","dhimmel"
"255","comments","meta","2016-03-26T06:01:08.751Z",17,"I'm currently writing up a first draft of our project report. Yay! I currently have a sentence:

> In total, XX non-team member commented across the 65 discussions, which generated XX comments totaling XX words and XX characters.

Essentially, I want to summarize how much content, participation, and viewership [our project](http://thinklab.com/p/rephetio) has generated. @jspauld, what's the best way to go about computing these numbers (I can do it manually but is there an easier way)?

Does it make sense to add these summary statistics somewhere on the project page?

And is it possible to get a total count of all views/unique viewers to any page in the project?","17",2016-03-26,2016-03-26,2,677,"base.profile","Daniel","Himmelstein","dhimmel"
"256","comments","meta","2016-03-26T21:12:55.157Z",17,"Currently it seems that proposals and reports receive the same title as the project. This leads to 3 DOIs (proposal, report, and project) with the same title.

One option would be to automatically (pre/a)ppend the category. For example, see how F1000 appends version info to titles [@10.12688/f1000research.6836.1 @10.12688/f1000research.6836.2]. Perhaps something similar, but for titles, could be done for Thinklab?

**Update**: It looks like F1000Research doesn't include their version stamps in DOI metadata, but does so on their website. For example [@10.12688/f1000research.6836.2]:

> iCTNet2: integrating heterogeneous biological interactions to understand complex traits [version 2; referees: 2 approved].","17",2016-03-26,2016-03-26,2,720,"base.profile","Daniel","Himmelstein","dhimmel"
"257","comments","meta","2016-03-26T21:20:31.008Z",17,"For example, our project [@10.15363/thinklab.4] is titled ""Repurposing drugs on a hetnet"" and hence so is the proposal [@10.15363/thinklab.a5]. You could imagine:

+ Repurposing drugs on a hetnet [project]
+ Repurposing drugs on a hetnet [proposal]
+ Repurposing drugs on a hetnet [report]

And if versioned citation gets enabled for reports and proposals, which I think is an important feature, you could have:

+ Repurposing drugs on a hetnet [proposal version 1]
+ Repurposing drugs on a hetnet [report version 2]","17",2016-03-26,2016-03-26,2,525,"base.profile","Daniel","Himmelstein","dhimmel"
"258","comments","meta","2016-04-01T22:50:21.101Z",17,"One way to proceed would be to create a feature for exporting a Thinklab project. From the export, I could calculate all the stats I want.

For example, I'm imagining a JSON export (or XML) that contains:

+ the markdown content for discussions and documents
+ the HTML-formatted content for discussions and documents
+ user info for the subset of users who contributed, i.e. the project leaderboard

Potentially, the export could contain multiple files that get zipped into a single download. Then the export could include figures and potentially each discussion would be in its own file in a `discussion` directory.","17",2016-04-01,2016-04-01,2,625,"base.profile","Daniel","Himmelstein","dhimmel"
"259","comments","meta","2016-04-05T02:17:50.005Z",23,"That would be extremely useful indeed, and I side with Daniel on getting raw data.

From an engineering point-of-view - because it makes explaining easier - it would be a good start in my opinion to get JSON or tabular format of a subset of fields for the 'comments', 'discussions', and 'users' collections. 
Scoping per project would be great. HTML formatted content seems non-necessary for descriptive stats and potentially harder to get, and even the actual contents for each object could be skipped to start with. Date, user, number of views, and the few foreign & primary keys would be a great start!","23",2016-04-05,2016-04-05,2,608,"base.profile","Antoine","Lizee","alizee"
"260","comments","meta","2016-04-05T06:40:59.683Z",23,"@dhimmel and myself have recently gone through the traumatic experience of losing two hours worth of pristine, beautiful brain juice. 

Poor habits, forged in a world where auto-saving is the norm (Evernote, Gmail, BS Word...), led us to blissfully write long comments and start discussions but without actively using the ""Save as Draft"" feature - mainly because the piece was intended to be posted. Of course, the wonders of modern technology sometimes result in random crashes and reboots, or wild logging out (by Thinklab systems, with irrefutable legitimacy). No drawing is needed - catastrophes ensued.

The proposition here is to mitigate these issues by automatically 'saving the draft' at regular intervals, whatever option is finally chosen. Like normal drafts, these 'background drafts' will either be deleted over posting or overwritten if saved again. 
The only foreseeable problem with this strategy is automatic overwriting of an existing 'voluntary' draft, but use-cases that would be affected by such a behavior are hard to think of.

Thanks to @jspauld for giving us an open space to Think.","23",2016-04-05,2016-04-05,2,1114,"base.profile","Antoine","Lizee","alizee"
"261","comments","meta","2016-04-05T22:43:06.954Z",17,"Auto-save could be helpful. There are three situations to consider here:

1. When Thinklab eats the content (posting while logged out or before having a verified account).
2. Client-side crashes or user errors that lead to an open composition getting lost.
3. Accidental deletion where a use removes all text from a composition. In this case, autosave could lead to content loss.

> Poor habits, forged in a world where auto-saving is the norm (Evernote, Gmail, BS Word...), led us to blissfully write long comments and start discussions but without actively using the ""Save as Draft""

My issue is that I only save when I have writer's block. When I'm on a writing spurt, I don't to deviate from content creation.","17",2016-04-05,2016-04-05,2,721,"base.profile","Daniel","Himmelstein","dhimmel"
"262","comments","meta","2016-04-07T22:38:17.812Z",2,"Fixed. Don't know why Bootstrap is doing that. Apparently they are removing that ""feature"" in version 4.","2",2016-04-07,2016-04-07,2,104,"base.profile","Jesse","Spaulding","jspauld"
"263","comments","meta","2016-04-07T22:44:14.055Z",2,"We've appended [idea], [proposal], [report], or [project] as you suggested.","2",2016-04-07,2016-04-07,2,75,"base.profile","Jesse","Spaulding","jspauld"
"264","comments","meta","2016-04-07T23:03:45.794Z",23,"I fell in love with Github's feature that supports direct copy pasting or dragging of images into the comment edition pane.

I don't know how much work this would entail, but it would be a great addition, especially if there is a place where I could see all the hosted pictures of a specific project.","23",2016-04-07,2016-04-07,2,302,"base.profile","Antoine","Lizee","alizee"
"265","comments","meta","2016-04-07T23:09:02.081Z",2,"I setup a project export. It is available here: http://thinklab.com/p/rephetio/export. Note number of views is a calculated field and thus I prefer not to add it to the export for now. 

It currently contains the following tables and fields for each project:

- **documents** -- title, intro_md, intro_html, body_md, body_html, doc_published, topic_field
- **threads** -- profile, document, subject, published, topic_field, doi_field
- **comments** -- profile, thread, body_md, body_html, published
- **notes** -- profile, comment, body_md, body_html, added
- **profiles** -- username, first_name, last_name","2",2016-04-07,2016-04-07,2,615,"base.profile","Jesse","Spaulding","jspauld"
"266","comments","meta","2016-04-07T23:44:17.150Z",2,"Yes, that is a nice feature. However, given the amount of work it would likely take to implement, I'm going to defer this until Thinklab has more usage/momentum.","2",2016-04-07,2016-04-07,2,161,"base.profile","Jesse","Spaulding","jspauld"
"267","comments","meta","2016-04-08T00:56:55.884Z",17,"Fantastic -- can't wait to play with the content.

I'm having a bit of trouble reading the file. The two methods that I usually use to download and load a JSON from Python are not working (`JSONDecodeError`):

```python
url = 'http://thinklab.com/p/rephetio/export'

# Method 1 (Python 3)
import urllib.request
urllib.request.urlretrieve(url)
with open('export') as fp:
    export = json.load(fp)

# Method 2 (requests dependency)
import requests
export = json.loads(requests.get(url).text)
```

I think it's because they are retrieving an HTTPMessage rather than a JSON text file. Also, when I view the project export in my browser, I'm noticing some escaping that I don't think is standard JSON. Here's an example URL that does work https://pages.github.com/versions.json. @jspauld any ideas?

Two other points -- if this is a JSON file, then adding a `.json` extension may be helpful. Second, I think newlines make working with JSON files easier. Setting `indent=2` in Python's [`json.dump`](https://docs.python.org/3.5/library/json.html#json.dump) will enable newlines. Newlines often make the difference because a frozen and responsive text editor.","17",2016-04-08,2016-04-08,2,1173,"base.profile","Daniel","Himmelstein","dhimmel"
"268","comments","meta","2016-04-08T01:46:20.559Z",17,"# Workaround using GitHub Issues

@alizee, I created a [GitHub Issue](https://github.com/dhimmel/rephetio/issues/1) that we can use to get this functionality without too much hassle.

As [an example](https://github.com/dhimmel/rephetio/issues/1#issue-146788031), I uploaded an image to the Issue and will now include it on Thinklab using:

```
![Rephetio metagraph and visualization](https://cloud.githubusercontent.com/assets/1117703/14371774/aff6b0de-fcef-11e5-9e4b-341b385abcdd.png ""This is hosted on GitHub"")
```

Which displays as:

![Rephetio metagraph and visualization](https://cloud.githubusercontent.com/assets/1117703/14371774/aff6b0de-fcef-11e5-9e4b-341b385abcdd.png ""This is hosted on GitHub"")","17",2016-04-08,2016-04-08,2,718,"base.profile","Daniel","Himmelstein","dhimmel"
"269","comments","meta","2016-04-08T03:43:48.051Z",2,"Yes, I thought something looked off. I was serializing things twice. Try again with:

http://thinklab.com/p/rephetio/export.json","2",2016-04-08,2016-04-08,2,130,"base.profile","Jesse","Spaulding","jspauld"
"270","comments","meta","2016-04-08T18:57:15.904Z",23,"Works for me - awesome!

We were thinking of potentially applying the simple analytics we're doing to the whole thinklab dataset. Would there be a way to get the data for all projects?

Also, even if calculated, hence dynamic and potentially unreliable, the 'views' field would be a great addition for marketing purposes of our projects. We can issue a disclaimer next to the related data.

Best,
Antoine","23",2016-04-08,2016-04-08,2,411,"base.profile","Antoine","Lizee","alizee"
"271","comments","meta","2016-04-08T19:08:44.038Z",17,"# Automatically retrieving the Thinklab JSON export

Here's a Python script to retrieve, parse, and save the JSON export. You need to define the `email` and `password` variables for your Thinklab account.

```python
import json
import datetime
import requests

with requests.Session() as session:
    login_url = 'http://thinklab.com/login'
    session.get(login_url)
    csrf_token = session.cookies['csrftoken']
    payload = {
        'email': email,
        'password': password,
        'csrfmiddlewaretoken': csrf_token,
    }
    session.post(login_url, data=payload)
    
    export_url = 'http://thinklab.com/p/rephetio/export.json'
    response = session.get(export_url)
    export = response.json()

export['retrieved'] = datetime.datetime.utcnow().isoformat() + 'Z'

with open('export.json', 'wt') as write_file:
    json.dump(export, write_file, ensure_ascii=False, indent=2, sort_keys=True)
```

I added a `retrieved` property with the date/time the export was retrieved. I'd like to acknowledge these two stack overflow answers for help with [logging in](http://stackoverflow.com/a/17633072/4651668 ""How to log in to a website using Python's Requests module?"") and [CSRF tokens](http://stackoverflow.com/a/13569789 ""Passing csrftoken with python Requests"") in [`requests`](http://docs.python-requests.org/en/master/ ""Python Requests Package: HTTP for Humans"").","17",2016-04-08,2016-04-08,2,1405,"base.profile","Daniel","Himmelstein","dhimmel"
"272","comments","meta","2016-04-08T20:10:47.969Z",17,"# A repository for project analytics

I created a repository ([`thinklytics`](https://github.com/dhimmel/thinklytics ""dhimmel/thinklytics on GitHub"")) for exporting and analyzing Thinklab content.

@alizee, I think [you want](http://thinklab.com/discussion/discussion-summary-statistics-for-illustrating-project-impact/191#7) data for all [projects](http://thinklab.com/projects) and [proposals](http://thinklab.com/proposals) using my [`export.py`](https://github.com/dhimmel/thinklytics/blob/e6c64cf1a709653032605e008fcc828f6e4f0d0f/export.py). The only missing piece to programmatic retrieval of all content is a complete list of proposal and project IDs. For now this can be compiled manually, but it would be nice to have a `thinklab.com/projects.json` for getting this list. Consider forking `thinklytics`.","17",2016-04-08,2016-04-08,2,816,"base.profile","Daniel","Himmelstein","dhimmel"
"273","comments","MicrobeResist","2014-06-02T18:11:29.355Z",2,"Great job so far Holly.

May I suggest that for the Team & Resources section you play up the fact that your lab has been a leader in the open science movement? If you look at the [peer review form](http://thinklab.com/preview_review/1) for the initial proposal you'll see one of the rating criteria is ""Open Collaboration"". If ThinkLab is successful, the fact that Jonathan and the rest of your team have made a proactive effort supporting open science will definitely be a huge advantage for you.

Also, feel free to add links to the proposal. (For example you might add a link so people can see all the awesome open science related stuff your lab is involved with.) Remember, this system is web-native. Let's take advantage of the medium. Links can be added using [markdown](http://thinklab.com/help/writing-in-markdown). I might create another post with some markdown suggestions.","2",2014-06-02,2014-06-02,2,887,"base.profile","Jesse","Spaulding","jspauld"
"274","comments","MicrobeResist","2014-06-02T18:41:14.957Z",5,"I tried to use markdown in my profile but it did not seem to work ...","5",2014-06-02,2014-06-02,2,69,"base.profile","Jonathan","Eisen","jonathaneisen"
"275","comments","MicrobeResist","2014-06-03T19:42:05.963Z",4,"As Rachel has mentioned, there are some issues with using ITS primers for fungal characterization. One is that the ITS region does not provide phylogenetic information. As a result analyses need to use other approaches. Another problem is that the PCR products for different taxa differ dramatically in size and will not be sequenced uniformly. Does anyone have any thoughts about this? ","4",2014-06-03,2014-06-03,2,387,"base.profile","Holly","Ganz","hollyganz"
"276","comments","MicrobeResist","2014-06-03T19:55:45.644Z",6,"From the little data I've seen recently on the size variation in ITS, I can't see how it can work to provide any information about relative abundance if using Illumina sequencing.   Those taxa with small ITS regions will take over the entire flowcell and you'll never even see the taxa with large ITS regions.   This should be fairly easy to confirm however, by size selecting pools of different ITS sizes (on say a Pippin) and then confirming the existence of taxa that don't appear in a pooled run.","6",2014-06-03,2014-06-03,2,500,"base.profile","David","Coil","davidcoil"
"277","comments","MicrobeResist","2014-06-03T22:08:34.061Z",4,"Maybe other people aren't finding the same size variation in ITS amplicons?","4",2014-06-03,2014-06-03,2,75,"base.profile","Holly","Ganz","hollyganz"
"278","comments","MicrobeResist","2014-06-03T23:01:17.524Z",2,"I'd just like to give a brief introduction to ThinkLab and the pilot that is taking place.

### ThinkLab introduction

I created ThinkLab with the mission to bring about a world in which scientists share their research openly, in real-time, while collaborating with peers worldwide. ThinkLab is an open collaboration platform and it's also a funding platform. It's a funding platform because I believe it had to be in order [provide incentives](http://thinklab.com/how-it-works/incentives) for the broader scientific community to participate fully.

As a starting point I reached out to Jonathan due to his advocacy and involvement with open science. We agreed to do a small-scale pilot. That pilot is Holly's project: [Microbial resistance to disinfectants in animal shelters](http://thinklab.com/MicrobeResist). 

My hope is that we'll be able to get some good conversation happening on the platform and this project can serve as an example for when we launch publicly. All of your comments will remain public and it's very possible the site could receive significant traffic. (At least that will be the idea)

### Notes on the pilot

#### Your imagination is required

Because this is a pilot there are a few things that make this not quite real. Normally getting funded on the platform is a competitive process. That's why there is a proposal and that's why there is [peer review](http://thinklab.com/how-it-works/peer_review). In this case it's kind of understood that the project will get funded. However, I ask that you please try to imagine that you are competing against other possible projects and that therefore peer review is important.

#### Feel free to invite others

If you think of someone that might like to follow along and contribute anything to the project please feel free to invite them. Just send them the URL and username and password:

user: eisen
pass: pilot

#### But, please don't share this publicly

As ThinkLab has not launched publicly yet I'd like to ask that everyone please refrain from tweeting/blogging about us. The site is only accessible if you have the password.","2",2014-06-03,2014-06-03,2,2129,"base.profile","Jesse","Spaulding","jspauld"
"279","comments","MicrobeResist","2014-06-09T21:29:24.997Z",2,"@jackgilbert & @adamsri --

Please note that because there will only be a few of us submitting reviews in the pilot the scores you submit will be *a lot less* secret. This is due to the fact that ThinkLab will publicly display the *average* scores that the proposal receives.

This shouldn't be a big deal because for the pilot your scores are inconsequential anyway!

However, any feedback you have for the team definitely *is* consequential! Just please note if you have feedback on the research plan it might make sense to wait until [phase 2 of the project](http://thinklab.com/how-it-works/projects). That's when the project will be funded such that collaborators (you) earn money. I'm not sure whether you care about that at all but thought I'd point it out.","2",2014-06-09,2014-06-09,2,770,"base.profile","Jesse","Spaulding","jspauld"
"280","comments","MicrobeResist","2014-06-10T22:45:40.761Z",4,"Thanks for the suggestion. I will add some links to our open science effort.","4",2014-06-10,2014-06-10,2,76,"base.profile","Holly","Ganz","hollyganz"
"281","comments","MicrobeResist","2014-06-10T23:08:38.912Z",4,"I asked a couple of people for feedback on the proposal. Because they didn't post their comments on the site, I thought that I would share what they said here.  

Colleague 1 (building scientist):

I took a quick look at the proposal (don't have a ton of time to edit until mid-Jul, unfortunately).  The antibiotic and disinfectant resistance genes are interesting.

Are there any factors you can think of that you can measure regarding the animals, that could help explain any variability in the data?  Will you focus on animals that have just arrived, or that have been there for a while?  I think there may be a difference…Should document the cleaning practices, how often chemicals are used, how much, what are the ventilation rates, probably best to measure RH near surface and in middle of room after cleaning, what are the exercise practices for the animals?

That's all I can think of at the moment!  Looks great :-)

Colleague 2 (veterinarian and expert in shelter animal medicine):

Suggests change in title to: Characterization of the microbial communities occurring on surfaces in an animal shelter

Comment 1: Would love to see this take on the additional angle of building/housing design differences.  It's been our experience that once the basics of vaccination and a decent cleaning/disinfection protocol is in place then the greatest differences in population health/ animal well being in animal shelters are due to LOS and housing (housing type and environment (noise/hvac, etc)). 

Comment 2: Disease transmission is a concern more because of the demographics of the population served (naive population etc)  

Comment 3: Not sure how in depth you want/need  to go on the intro for this pilot project seems broad in scope. 

Comment 4: This is a good descriptive paragraph (final paragraph in introduction).  I don’t know anything about genes that promote persistence in the environment- perhaps more info there. Do you have hypotheses?

Comment 5 in response to ""This study will help in the development of strategies to manage the development of antimicrobial and antibiotic resistance in an intensive housing environment."" How?  Unless you were comparing differing strategies- cleaning methods, disinfectant use, housing type etc within the same environment.  This study will help understand the presence or absence  and quantitative information of whatever you are looking for but not sure how much further you can go with this project.","4",2014-06-10,2014-06-10,2,2480,"base.profile","Holly","Ganz","hollyganz"
"282","comments","MicrobeResist","2014-06-11T00:02:50.667Z",4,"How can I notify our collaborators?","4",2014-06-11,2014-06-11,2,35,"base.profile","Holly","Ganz","hollyganz"
"283","comments","MicrobeResist","2014-06-11T00:51:46.141Z",2,"For the time being we can notify them like so:

 @adamsri @jackgilbert @jarradmarcell 

Could you guys reply to this so we know that you saw this?","2",2014-06-11,2014-06-11,2,150,"base.profile","Jesse","Spaulding","jspauld"
"284","comments","MicrobeResist","2014-06-11T01:03:09.290Z",10,"I saw it","10",2014-06-11,2014-06-11,2,8,"base.profile","Jack","Gilbert","jackgilbert"
"285","comments","MicrobeResist","2014-06-11T19:20:09.613Z",9,"I saw it, too. ","9",2014-06-11,2014-06-11,2,15,"base.profile","Rachel","Adams","adamsri"
"286","comments","MicrobeResist","2014-06-11T23:59:22.929Z",2,"I had similar concerns as offline colleague #2 [noted here](http://thinklab.com/projects/MicrobeResist/discussion/6) with regard to the projected outcomes of the project:

> in response to ""This study will help in the development of strategies to manage the development of antimicrobial and antibiotic resistance in an intensive housing environment."" How? Unless you were comparing differing strategies- cleaning methods, disinfectant use, housing type etc within the same environment. This study will help understand the presence or absence and quantitative information of whatever you are looking for but not sure how much further you can go with this project.

I really want us to be clear about exactly what are the positive outcomes (or potential outcomes) of the project and what are not. In addition to the comments above I'll make my own. The proposal says:

> By identifying what bacteria and fungi occur here, we can begin to understand sources for these communities (such as animal host, soil, air, water) 

I can see that this research will help us understand what microbes are found in an animal shelter versus what microbes are not. But, how does it allow you to tell if the source is animal host, soil, air, or water? Furthermore, why is this useful to know?

> and identify potential effects that different environmental factors may have on microbial persistence in these building reservoirs (such as use of disinfectants, proximity to windows, moisture, sunlight). These findings can help to inform practices within animal shelters such as the use of ventilation and disinfectants to protect animal health.

Will there really be a meaningful differentiation between samples in the amount of disinfectants that were used? Wouldn't each kennel basically have the same profile as far as disinfectants, moisture, light, etc? And even if they didn't -- do the microbes not move around, from one kennel to another?

If we were really going to help inform animal shelters on the use of ventilation and disinfectants I'd think we'd have to to characterize the microbial communities across multiple shelters that had varying practices. Either that or setup controlled experiments within one shelter. Right?

This also implies that certain microbial communities are ""bad"" and certain communities are ""good"". I just want to confirm that there could in fact be a set of results where we could definitively recommend to shelters that they change their practices to X. If that outcome is not possible I don't think it can be claimed that we are helping inform practices within animal shelters.","2",2014-06-11,2014-06-11,2,2612,"base.profile","Jesse","Spaulding","jspauld"
"287","comments","MicrobeResist","2014-06-12T18:16:30.042Z",4,"Hi Jesse,

Thanks for reading the proposal and taking the time to comment on it. 

I provided the two offline reviewers' comments in the spirit of openness. Typically I will have several people read a proposal before it is submitted as I did here. In this case, I have provided the initial first draft of the proposal, so there are some simple things that should be corrected. In fact, I have already started to revise the proposal based on these comments. But I'm not sure how to revise it online without changing the original document. It seems like it would be useful to have different versions of the proposal to see how it changes in response to these discussions. Or maybe I am missing how to do this? Also I wasn't sure if I should change it while some of you are reading the current version. So for now I have let the first draft online as it is.

When I wrote the somewhat careless statement that ""This study will help in the development of strategies to manage the development of antimicrobial and antibiotic resistance in an intensive housing environment,"" this is what I was thinking about. If we find evidence for resistance genes that are associated with disinfectants that are commonly used in the animal shelter environment (and also genes for antibiotic resistance), this background information will be very informative in guiding future studies to develop specific strategies to manage the development of such resistance in bacterial communities that reside on surfaces in animal shelters. I have some specific ideas for this but they are a bit beyond the scope of this project. In any case, I have already revised this statement (and the similar one later in the proposal) offline but await further input before I upload a revised version of the proposal. In addition, it is clarifying for me to see how different people respond to it.

We can use bacterial source tracking to identify potential sources for some of the surface communities based on the many available reference collections for soil, air, water, human and animal associated communities. I did not propose collecting additional samples for that purpose here due to the limited level of funding for this project. But we can use publicly available data to begin to address potential sources. 

Why do we want to identify the biogeography of bacteria in buildings? This is something that is not always clear to people who are not ecologists. Microbial ecologists believe that we need to understand what is there and how diversity varies across these environments before we can understand how such communities might change in response to environmental variation or potential interventions, such as a new approach to ventilation or disinfection. In addition to who is there, the traits exhibited by these communities can be of interest, i.e., resistance genes.

This study is not designed to compare different disinfection strategies in the different kennels. Instead it is designed to characterize the communities found living on surfaces in the dog housing area. It is designed to capture the range of variation in the dog kennels, which do differ in amount of light, humidity and proximity to windows and exits. I would also like to use data loggers to measure the amount of variation in temperature and humidity in the kennels.

This pilot study is not funded at a level to allow for comparisons of multiple shelters with different strategies. It would take something like $25,000 to do such a study (without including salaries). The project proposed here will already cost about twice as much as the current budget so I will probably drop the fungal characterization, depending on the feedback that we get from the community here.

I didn't mean to imply anything about good or bad microbial communities. What I am thinking about here is managing for the evolution and spread of antibiotic and disinfectant resistance genes in bacterial communities found on surfaces in animal shelters. First we have to start by characterizing who is there and whether they have the traits of interest. 

Thanks for the constructive feedback. I will modify the proposal accordingly. 


","4",2014-06-12,2014-06-12,2,4175,"base.profile","Holly","Ganz","hollyganz"
"288","comments","MicrobeResist","2014-06-12T18:21:48.619Z",4,"Hi @adamsri @jackgilbert @jarradmarcell 
This discussion might be of interest to you as reviewers.
Thanks for your help with this project.","4",2014-06-12,2014-06-12,2,140,"base.profile","Holly","Ganz","hollyganz"
"289","comments","MicrobeResist","2014-06-12T20:57:58.714Z",14,"I think this is a really interesting proposal, and well thought out. It's great to see the inclusion of metagenomics and antibiotic-resistance targeting. I think this will yield insights about our management of these facilities the way it is designed. Since you have already answered the broader concerns in another comment ([Concerns with projected outcomes](http://thinklab.com/MicrobeResist/discussion/7)), I'll focus on a few methods issues that can be clarified or improved.

*  You are targeting the 16S V4 region, but with the newest round of Illumina amplicon sequencing, we've begun extending primers from F515-R806 to F319-R806. This still allows some overlap between paired ends and gives a potentially more informative amplicon length. And I might recommend looking into the [Fadrosh et al. 2014](http://www.microbiomejournal.com/content/2/1/6) method for adding a spacer to the beginning of the primers - this avoids the wasteful phiX spike necessitated by Illumina clustering algorithms. We've been experimenting with a version of this, and results are good so far. However, if you plan to run the amplicons and metagenomes in the same run, then nevermind - that probably fixes the same problem. 
* You are going to use UniFrac for beta-diversity analysis. This is a great idea, and should certainly be part of the workflow. However, keep in mind that UniFrac excels at finding broad, phylogenetically-relevant habitat differences (e.g., acidic vs basic, or gut vs skin). 
But quite often microbial ecologists miss out on really interesting *subtle* habitat or source differences by eschewing traditional ecological beta-diversity metrics simply because they are not based in phylogeny. For example, when looking at skin samples from men and women, UniFrac sees very little difference because the same clades are represented in both sets. However, we keep seeing that minor taxonomic swaps hold the key to distinguishing between groups. Men might have one type of *Corynebacterium* enriched on their skin and women have another *Corynebacterium*. UniFrac overlooks this (by design, and for good reason), while another metric, like Canberra, will emphasize this difference. That is not to say that you should use one over another, but choose metrics carefully based on the differences you expect to see, or else risk missing out on interesting results. 
* Minor point - QIIME is now up to version 1.8 and will likely change again before your sequences come out, so it is probably sufficient to just cite Caporaso et al. 2010, instead of version number. 
* Aesthetic markdown point: The markdown editor seems to have hijacked your underscores in the `pick_otus_through_otu_table.py` description. Put backticks around it to avoid the italics. 

This is a very cool idea, and I'm happy to help out where I can, or review a future version. 

","14",2014-06-12,2014-06-12,2,2861,"base.profile","James","Meadow","JamesMeadow"
"290","comments","MicrobeResist","2014-06-12T22:06:33.148Z",2,"> I have already started to revise the proposal based on these comments. But I'm not sure how to revise it online without changing the original document. It seems like it would be useful to have different versions of the proposal to see how it changes in response to these discussions.

Thanks. Yes I agree having multiple versions would be useful. We will work on adding it before public launch. For now you'll just have to use whatever strategy you think is best given the limitations of the system.

With regard to the rest of the comments. I've probably reached my limit in being able to make any useful response without understanding the science.

I would just say that if any of the outcomes you are talking about refer to future studies that could be based on yours then we should probably describe them as such. We don't want people thinking they are *direct* outcomes from your study if they are not.



","2",2014-06-12,2014-06-12,2,923,"base.profile","Jesse","Spaulding","jspauld"
"291","comments","MicrobeResist","2014-09-10T20:33:29.494Z",2,"All of the proposal sections except for the abstract allow you to write text in markdown. This allows simple formatting such as creating bulleted lists, numbered lists, headings, bold, italics, etc. I suggest you check out [Markdown Basics on GitHub](https://help.github.com/articles/markdown-basics) as a guide. Note, that I created that text link using markdown!

I would suggest that the items under 'Team & Resources' can be converted to lists. I'd also suggest that you add section headings to the research plan. Use your own judgement of course.","2",2014-09-10,2014-09-10,2,553,"base.profile","Jesse","Spaulding","jspauld"
"292","comments","MicrobeResist","2014-09-10T22:10:22.538Z",4,"It is interesting  to get to practice writing in markdown. I wasn't sure how useful it would be but I can see that it would be useful to add some structure to the proposal. Thanks!","4",2014-09-10,2014-09-10,2,180,"base.profile","Holly","Ganz","hollyganz"
"293","comments","MicrobeResist","2014-09-11T16:31:11.521Z",6,"We've been using Markdown in our various Authorea-created publications and while it takes a bit of getting used to, I think it's worth it in the end.","6",2014-09-11,2014-09-11,2,149,"base.profile","David","Coil","davidcoil"
"294","comments","pathways4life","2015-06-09T02:28:14.517Z",104,"We just submitted this proposal in response to an NIH UH2 funding opportunity announcement for [Advancing Biomedical Science Using Crowdsourcing and Interactive Digital Media](http://grants.nih.gov/grants/guide/rfa-files/RFA-CA-15-006.html). We love to get general feedback that we could use to improve upon the proposal if/when we need to resubmit or even if accepted. In particular, we are interested in resources and technologies we could use in this work, as well as collaborators who are independently working in areas of science game design and platform development.
","104",2015-06-09,2015-06-09,2,574,"base.profile","Alexander","Pico","alexanderpico"
"295","comments","pathways4life","2015-06-10T23:17:15.345Z",17,"The proposal primarily measures the novelty of the 3,985 pilot pathway images based on unique genes -- genes not currently in any WikiPathway pathways. While this is the simplest measure and therefore a good starting point, I think unique edges are a better assessment of novelty than unique genes. For example, a pathway could be composed of genes that are all already present elsewhere but are not connected anywhere else. This distinction is mentioned in the proposal:

> Thus, even the 28% of symbols that overlap with current human pathways (Fig. 2, blue) may provide new interaction content.

While the initial OCR implementation does not appear to extract edges, each pathway could be represented as a gene set. Then novelty could be measured as:

+ whether any other pathways are a superset or subset of the query pathway
+ the max [Jaccard index](https://en.wikipedia.org/wiki/Jaccard_index) of the query pathway with all other pathways

An edge-based conception of novelty will provide greater recall of novel pathways. At the current stage, where plentiful novel information exists, node-based novelty will definitely work. I agree that expanding the number of genes in at least one pathway should be a primary goal but think that your current node-based metrics may undersell the extent of novel pathways.","17",2015-06-10,2015-06-10,2,1326,"base.profile","Daniel","Himmelstein","dhimmel"
"296","comments","pathways4life","2015-06-10T23:23:57.888Z",17,"How do you plan to handle when the same pathway is represented in multiple images? For example, one publication may add an additional gene to a pathway first put forward by a previous publication. Is merging duplicated pathways outside the scope of this proposal?

I don't think that consolidating duplicates needs to be a focus of this project, but am intrigued by the difficulty of this problem and curious as to your insights. Does WikiPathways currently rely on users to merge duplicates?","17",2015-06-10,2015-06-10,2,494,"base.profile","Daniel","Himmelstein","dhimmel"
"297","comments","pathways4life","2015-06-10T23:34:36.687Z",17,"I will provide my comments related to formatting and visual improvements here -- feedback that is unrelated to any substantial aspect of the proposal.

1. Misspelling of most:
> **mosst** pathway information is still published solely as static

+ I would use the markdown list feature for the paragraph beginning with
> Several caveats to this survey ...

+ Figure 3 is too low resolution -- specific gene names are not visible. The human/machine difficultly aspect of the image is discernible, but I would like to see the actual images, especially to gain familiarity with examples of pathway figures.
  
+ Thinklab citations would improve online readability. Minimal extra work would be needed if you use the [Citation Key method](http://thinklab.com/help/writing-in-markdown). I would use [crossref](http://crossref.org/) for doi lookup when needed. The intelligent citations will help with readability and hopefully spur discussions on referenced works.","17",2015-06-10,2015-06-10,2,967,"base.profile","Daniel","Himmelstein","dhimmel"
"298","comments","pathways4life","2015-06-10T23:48:36.579Z",17,"What a fantastic proposal! The contribution is immense -- unlocking decades of knowledge residing in raster images. The proposal combines many state of the art tools and methodologies. It builds off of important open science resources, such as PubMed Central and wikis. Not only is the idea exceptional, the technical details of the implementation appear sound and current. The team has proven their technical expertise through their creation of [WikiPathways](http://www.wikipathways.org/index.php/WikiPathways).

As a scientist who relies on open data as the input to my research [@10.15363/thinklab.4], I can attest to the importance of literature-derived informatics resources. The compound-target databases such as BindingDB, ChEMBL, PubChem Assay, and DrugBank have been exceptionally helpful. MEDLINE topic annotations and curated protein interaction databases have also been crucial. I wholeheartedly agree that pathway images are a fruitful information hive in need of a skilled investigator.","17",2015-06-10,2015-06-10,2,1003,"base.profile","Daniel","Himmelstein","dhimmel"
"299","comments","pathways4life","2015-06-11T04:08:54.782Z",2,"> Figure 3 is too low resolution

Just FYI, people will soon be able to insert figures and have them appear somewhat like they do on PLOS and other websites. There will be an option to insert figures at a smaller size that can be clicked to zoom, and an option to have the figure full width. There will also be a button to download the original. This should help things.

> Thinklab citations would improve online readability

@alexanderpico we'd be happy to take care of this for you.
","2",2015-06-11,2015-06-11,2,493,"base.profile","Jesse","Spaulding","jspauld"
"300","comments","pathways4life","2015-06-12T01:49:50.154Z",104,"I'm most excited about the novel edges as well, but this is simply impossible to estimate from the current OCR results on our sample set. Realize that on average one gene is recognized per image... The distribution of recognized genes is heavily skewed, however (Fig 2). But even if we consider the 1104 pathways were 5 or more genes were recognized, how could we honestly estimate edges. We can't assume that the detected nodes are connected to each other.

Likewise, the other novelty measures you suggest would be great to apply to complete gene sets from a sample set of pathways. Unfortunately, we just aren't even close to getting that from the current OCR results.

Of course, after we actually model a few hundred of these images, we will be able to start estimating novel nodes, novel sets and novel edges more reliably. Between now and the NIH reviews, perhaps we'll try to brute force a set of these to get at these numbers.","104",2015-06-12,2015-06-12,2,939,"base.profile","Alexander","Pico","alexanderpico"
"301","comments","pathways4life","2015-06-12T02:00:25.184Z",104,"Contrary to the strategy of most pathway archive that strive for a single set of canonical pathways, WikiPathways loves redundancy... because, well, that's how biology actually works :)  

For example, instead of 1 Apoptosis pathway, we'd like to see 50+ Apoptosis pathways, depending on cell type, tissue type, conditions, developmental stages, disease states, etc. These might have a lot of redundancy, but the typical pathway analysis methods can already handle that. They typically provide a rank order of overrepresented pathways, for example, and being able to see exactly *which* Apoptosis version is most like your dataset would be very useful.

So, this is predicated on having ontology-based tags for the sources of variation. We've started with 3 standard ontologies, but this can expand by demand.  And, if two pathways are 100% identical in all ways, well then, yes, we should merge them. This will be rare (hasn't happened yet) and the bulk of the work will be on providing good search, browse and grouping tools in our UI.

For this project, I left out these details because I'm just focusing on nodes and edges (for simplicity), but you can easily imagine taking the same products from this first round and doing another cycle where the focus is capturing biological context.  The issue of redundancy is also address by our simple approach of prioritizing (and providing point bonuses for) novel genes. This alone will drive focus to less redundant pathway first... though we still want all variants in the end.","104",2015-06-12,2015-06-12,2,1533,"base.profile","Alexander","Pico","alexanderpico"
"302","comments","pathways4life","2015-06-12T02:10:38.420Z",104,"1. Fixed
2. I think I prefer the paragraph form here.
3. Looking forward to the PLoS-like feature. The goal of this figure, though, isn't really to inspect the details of the image. Honestly, I'd simply recommend searching pubmed central for ""signaling pathway"" and you'll see exactly what we're working with.
4. Thanks Jesse. The help with formatting would be appreciated. I'm going to stick with Endnote in Word for the final version, so I'm not too motivated to markdown all the refs...","104",2015-06-12,2015-06-12,2,492,"base.profile","Alexander","Pico","alexanderpico"
"303","comments","pathways4life","2015-06-15T05:27:53.605Z",2,"I've gone ahead and converted the references in your proposal to a native ThinkLab format.  In the future we may actually be able to automate this process.

I also took the liberty to convert your figures to use [our new figures feature](http://thinklab.com/discussion/we-now-have-a-figures-feature/79). If you'd like to edit the figures, you can find them by clicking ""edit figures"" from the project manager page. If you'd like to go ahead and upload a higher resolution version of the figure that @dhimmel commented on I think that would be a good idea. We currently don't have a click to zoom or download feature but those will be added soon.","2",2015-06-15,2015-06-15,2,647,"base.profile","Jesse","Spaulding","jspauld"
"304","comments","pathways4life","2015-08-06T15:03:09.615Z",35,"This is great. I am currently trying to integrate Pathway data into my analysis. So I will try to help as much as I can. ","35",2015-08-06,2015-08-06,2,121,"base.profile","Venkat","Malladi","vsmalladi"
"305","comments","pathways4life","2015-10-30T22:07:19.360Z",2,"At this point it was unclear to me what an internal curation team was","2",2015-10-30,2015-10-30,2,69,"base.profile","Jesse","Spaulding","jspauld"
"306","comments","pathways4life","2015-10-30T22:23:55.572Z",2,"I like that you are highlighting your efforts to correct the problem at its source","2",2015-10-30,2015-10-30,2,82,"base.profile","Jesse","Spaulding","jspauld"
"307","comments","pathways4life","2015-10-30T22:24:33.963Z",2,"It is unclear to me what I am supposed to learn from this graph. Does it aide in understanding something? ","2",2015-10-30,2015-10-30,2,106,"base.profile","Jesse","Spaulding","jspauld"
"308","comments","pathways4life","2015-10-30T22:28:02.164Z",2,"Is it safe to assume that people already know what tunable game mechanics are?","2",2015-10-30,2015-10-30,2,78,"base.profile","Jesse","Spaulding","jspauld"
"309","comments","pathways4life","2015-10-30T22:28:31.521Z",2,"It's unclear to me what aggregation and valuation mean here.","2",2015-10-30,2015-10-30,2,60,"base.profile","Jesse","Spaulding","jspauld"
"310","comments","pathways4life","2015-10-30T22:29:40.919Z",2,"Great, but this seems weak without explanation. Perhaps mention you'll get into the detail later?","2",2015-10-30,2015-10-30,2,97,"base.profile","Jesse","Spaulding","jspauld"
"311","comments","pathways4life","2015-10-30T22:30:19.549Z",2,"I find drawing this analogy just makes things harder to read. I also don't think it adds much value. ","2",2015-10-30,2015-10-30,2,101,"base.profile","Jesse","Spaulding","jspauld"
"312","comments","pathways4life","2015-10-30T22:35:41.703Z",2,"Why not just say something like ""Engaging the general public will accelerate pathway modeling""? Are you trying to match the language of the FOA?","2",2015-10-30,2015-10-30,2,144,"base.profile","Jesse","Spaulding","jspauld"
"313","comments","pathways4life","2015-10-30T22:37:59.785Z",2,"Is it worth saying this here if you're not going to explain how it does this?","2",2015-10-30,2015-10-30,2,77,"base.profile","Jesse","Spaulding","jspauld"
"314","comments","pathways4life","2015-10-30T22:43:42.562Z",2,"If points calculations are done in the browser it seems like a user could cheat and artificially inflate their score. If we are talking about simple calculations it is hard to imagine there is a real need to have these done client side.","2",2015-10-30,2015-10-30,2,236,"base.profile","Jesse","Spaulding","jspauld"
"315","comments","pathways4life","2015-10-30T22:44:03.539Z",2,"Looks good ","2",2015-10-30,2015-10-30,2,11,"base.profile","Jesse","Spaulding","jspauld"
"316","comments","pathways4life","2015-10-30T22:44:58.727Z",2,"Perhaps you should say that you are in fact *designing* it for others to extend -- not just anticipating. You could also mention other open source projects that were successfully extended in the manner you imagine for Pathways4Life. ","2",2015-10-30,2015-10-30,2,233,"base.profile","Jesse","Spaulding","jspauld"
"317","comments","pathways4life","2015-10-30T22:45:59.353Z",2,"I suggest a points system and leaderboard specific to each disease. I suspect there are people motivated to help out and be acknowledged within the scope of a particular disease.","2",2015-10-30,2015-10-30,2,178,"base.profile","Jesse","Spaulding","jspauld"
"318","comments","pathways4life","2015-10-30T23:15:04.371Z",2,"> The equation for calculating confidence scores will be the sum of observations (+1 for confirmation, –1 for rejection, o), weighted by the relative skill level of the participant (0–1, w). We can include a multiplier for negative observations to convey the extra effort in making a negative call (e.g., 2, m), and assess this sum against a threshold (e.g., 10, T) to ultimately mark a snippet as confirmed (e.g., S≥1).

Once you have a decent amount of data accumulated, and assuming you've marked a decent number of pathways as officially confirmed, I expect that you could use machine learning to optimize confidence score equations.

You could start by optimizing the equation for calculating how much trust the system should have in any given user. You might look at how new the user is, how many of their edits turned out to be correct, and what was the difficulty level associated with those edits. You would then probably want to optimize the equation for confidence in a particular snippet, as well as confidence in an entire pathway being correct.","2",2015-10-30,2015-10-30,2,1062,"base.profile","Jesse","Spaulding","jspauld"
"319","comments","pathways4life","2015-10-30T23:20:37.694Z",2,"The word 'curate' is used a lot. I personally find this word vague. It may be helpful to be more specific about what you're doing.","2",2015-10-30,2015-10-30,2,130,"base.profile","Jesse","Spaulding","jspauld"
"320","comments","pathways4life","2015-10-30T23:49:10.464Z",2,"A not insignificant part of the proposal seems to be gamification based on users leveling up to tackle more challenging pathways, while scoring more points.

This is great but it seems to me this presumes that there are in fact noticeable differences in difficulty between tasks. As someone who is not familiar with modeling pathways, I wonder what makes one harder than another? Aren't users essentially just copying the nodes, arrows, and relationships they see in the image? Couldn't most users do all of them with relative ease? It might be worthwhile addressing this.

The [difficulty matrix figure](http://thinklab.com/p/pathways4life/proposal/1/review#section-19) only specifies a set of easy pathways for humans (90% of them) and a set of hard ones (9%).","2",2015-10-30,2015-10-30,2,766,"base.profile","Jesse","Spaulding","jspauld"
"321","comments","pathways4life","2015-10-31T00:11:28.660Z",2,"> Pathway information is immensely useful for analyzing and interpreting large-scale omics data

Does this proposal assume that the reader is already aware of how valuable it would be to have pathways modeled and machine readable? As someone who is not familiar with this, I didn't come away with a great appreciation of the value of this proposal.

How about listing all the awesome science that your project will enable? I think we want readers thinking, ""Damn, we need all pathways modeled ASAP -- how can we build upon WikiPathways and accelerate this progress?""","2",2015-10-31,2015-10-31,2,570,"base.profile","Jesse","Spaulding","jspauld"
"322","comments","pathways4life","2015-10-31T00:29:30.955Z",2,"While there is [a section](http://thinklab.com/p/pathways4life/proposal/1/review#section-7) of the  proposal addressing this, I feel the scope of the challenge could be clarified. 

Here's what I'd like to know:

- How many total pathways do you expect users to model throughout the lifetime of the platform? (Presuming the project is successful and users do in fact use it)
- How many man-hours do you expect it to take, on average, to model each pathway?

With these two pieces of data we can think clearly about whether it's worth the time investment of creating a crowdsourcing platform and gamifying the experience. As the [proposal mentioned](http://thinklab.com/p/pathways4life/proposal/1/review#section-42), you could just pay people to do this through Amazon Mechanical Turk.

Now I think there's likely a lot of value to getting real science do-gooders involved, creating a platform that may be reusable, etc. However, I think there should be more clarity about the scope of what you're proposing.","2",2015-10-31,2015-10-31,2,1016,"base.profile","Jesse","Spaulding","jspauld"
"323","comments","pathways4life","2015-10-31T00:48:03.323Z",2,"If I was considering funding this proposal one of the big questions I would be asking myself is: will users use the platform? Sometimes you build it and they don't come.

As you'll see from my annotations I think you've got a great [plan for gamifying the experience](http://thinklab.com/p/pathways4life/proposal/1/review#section-36) -- and it sounds like you've got good [networks for reaching out to people](http://thinklab.com/p/pathways4life/proposal/1/review#section-41) as well. However, one of the things I'd really like to know is do you know exactly what made other platforms successful? I think it would be useful to do an analysis and have the summary in the proposal. What can you learn from those that have succeeded, and what can you learn from those that failed? Have you learned those lessons?

It would also be great to get those that have been involved in previous efforts commenting here on Thinklab as well!","2",2015-10-31,2015-10-31,2,931,"base.profile","Jesse","Spaulding","jspauld"
"324","comments","pathways4life","2015-10-31T01:50:26.212Z",2,"How about a link?","2",2015-10-31,2015-10-31,2,17,"base.profile","Jesse","Spaulding","jspauld"
"325","comments","pathways4life","2015-11-09T19:59:52.874Z",48,"This is a word that is used frequently and pretty well understood within the community of folks that build and maintain biological databases.  e.g. an important annual conference is run by the 'biocuration' society.  http://www.biocurator.org  From my viewpoint the use is pretty clear.  Perhaps a definition early on would clarify this for folks a little farther outside this community though.","48",2015-11-09,2015-11-09,2,394,"base.profile","Benjamin","Good","b_good"
"326","comments","pathways4life","2015-11-09T20:01:48.772Z",48,"Scanning the proposal without reading deeply, I would concur with your confusion.  The point of the figure and its relevance could be more clear.","48",2015-11-09,2015-11-09,2,145,"base.profile","Benjamin","Good","b_good"
"327","comments","pathways4life","2015-11-09T20:42:12.361Z",48,"Some thoughts on this.  The biggest successes so far (Foldit, EteRNA, Eyewire, MalariaSpot, Galaxy Zoo) in this genre have focused on problems that are almost entirely visual.  The work that has so far been done on non-visual problems (our lab: Dizeez, The Cure, mark2cure, VU Amsterdam/IBM: Dr. Detective, CMU: Verbosity, MIT/ISI: Learner) have met with less success - though haven't been total flops either.  However, far less money and time have gone into the development of games for the non-visual problems which creates a chicken and egg problem.  Have people not invested in other problem classes because its really just a bad a idea or have we just not seen the success because we haven't made the investment yet?  

The wikipathways proposal is interesting in this sense because, though it does have a strong visual appeal, the tasks involved (e.g. making sure a node is correctly marked with the right gene identifier) are mainly linguistic in nature.   ","48",2015-11-09,2015-11-09,2,966,"base.profile","Benjamin","Good","b_good"
"328","comments","pathways4life","2015-12-16T02:14:56.590Z",104,"Possibly. Given that this was for a 2-year grant, however, I think dedicating machine learning to the tuning of a simple scoring mechanism would be outside the scope of the project.  ","104",2015-12-16,2015-12-16,2,183,"base.profile","Alexander","Pico","alexanderpico"
"329","comments","pathways4life","2015-12-16T02:16:35.842Z",104,"Thanks!  You can edit and add pathways of interest today at WikiPathways.org. This grant proposal was rejected, but was for *additional* mechanisms of curation. The basics are already in place and ready for your participation.","104",2015-12-16,2015-12-16,2,226,"base.profile","Alexander","Pico","alexanderpico"
"330","comments","pathways4life","2015-12-16T02:23:21.634Z",104,"I was surprised by this as well. In our preliminary look at 40k images, we found the difficulty range to be huge. I tried to express this in the matrix figure, but really didn't have the space to include a sampling of images at sufficient resolution. There's wide range and a spectrum of levels between.

The easy ones are really easy. The harder ones would actually be hard for an expert biologist. In fact, I suspect there are many that are NOT possible to model. We would filter out as many of these as we could ahead of time, but we could also detect these by ""skip"" event and lack of consensus.  It comes down to the fact that researchers literally makeup their own unique formats and conventions almost every time a pathway drawing is made outside of a dedicated modeling tool.  It's a big problem.","104",2015-12-16,2015-12-16,2,806,"base.profile","Alexander","Pico","alexanderpico"
"331","comments","pathways4life","2015-12-16T02:32:04.037Z",104,"Right. This is written to a fairly specific target audience of reviewers. The assumption is safe that with the initial paragraph they'd connect the value of the modeling to major questions being asked across almost all fields of biomedical research.

In fact, now that I've got the Summary Statement back from the review committee, I can confirm that our ""significance"" score was one of the best overall. The only critique in this category was from one reviewer regarding the lack of ""advancing the science of crowdsourcing""...  That indeed was not an aim of this proposal, but it was important to this reviewer :)","104",2015-12-16,2015-12-16,2,616,"base.profile","Alexander","Pico","alexanderpico"
"332","comments","pathways4life","2015-12-16T02:42:32.907Z",104,"I'd like to know that too! :)

This funding mechanism is explicitly billed as ""exploratory."" It's two years of initialization funding to see if there is something worth *really* investing in, especially in terms of gamification.  So, I don't have real answers to those questions because it's never been done before... the platform doesn't exist in any form currently. 

My goal with this project was to build and organize biomedical knowledge. So, I focused on how there is definitely knowledge out there waiting to be curated and a few ways to go about curating it, the primary way being gamification with some backup plans.

Based on the NIH reviewer statements, however, there was no critique of the biomedical aims and value, nor on the approach towards those aims, but rather on the fact that the approach itself wasn't a new way to crowdsource and the aims didn't advance crowdsourcing science itself.","104",2015-12-16,2015-12-16,2,913,"base.profile","Alexander","Pico","alexanderpico"
"333","comments","rephetio","2015-01-14T05:55:24.832Z",17,"We are looking to construct a catalog of [indications](https://en.wikipedia.org/wiki/Indication_%28medicine%29) (efficacious drug-disease pairs) with the following attributes (ordered by importance):

1. automated and high-throughput construction
+ high-quality, or varying levels of quality as long as quality level is annotated
+ comprehensive
+ disease modifying rather than symptomatic
+ compounds which map to pubchem
+ [contraindications](https://en.wikipedia.org/wiki/Contraindication) and adverse effects are excluded and cataloged separately
+ diseases which map to the disease ontology
+ source is retrievable

A few options we can consider:

+ [**LabeledIn**](http://ftp.ncbi.nlm.nih.gov/pub/lu/LabeledIn/) -- Curators manually identified indications from drug labels for 250 human prescription ingredients (drugs) [@10.1016/j.jbi.2014.08.004].
+ [**MEDI**](http://knowledgemap.mc.vanderbilt.edu/research/content/MEDI) -- Indications extracted from RxNorm, SIDER 2, MedlinePlus, and Wikipedia were integrated into a single resource. The high-precision subset (indications in RxNorm or two other resources) includes 13,304 unique indications for 2,136 medications [@10.1136/amiajnl-2012-001431]. Further work added indication prevalence information [@MediPrev]. MEDI compares favorably to SemRep for extracting indications from clinical text [@10.1136/amiajnl-2014-002954].
+ **SemRep** -- ""[SemRep](http://semrep.nlm.nih.gov/) is a program that extracts semantic predications (subject-relation-object triples) from biomedical free text"" [@10.1016/j.jbi.2003.11.003]. SemRep has been used to extract *TREAT* relations from MeSH scope notes, Daily Med, DrugBank, and [AHFS Consumer Medication Information](http://www.ahfsdruginformation.com/product-consumer-info.aspx) [@10.1145/1882992.1883096]. SemRep has also been used to identify *TREAT* relations from Medline abstracts [@LiuSemRep]. A project called [SemMedDB](//skr3.nlm.nih.gov/SemMedDB/) provides the SemRep results from mining PubMed [@10.1093/bioinformatics/bts591]. 
+ **SPL-X** -- **S**tructured **P**roduct **L**abels e**X**tractor -- Using MetaMap, this project extracted indications from DailyMed drug labels that were available as XML [@10.1136/amiajnl-2012-001291]. Data does not appear to be available.
+ **[Comparative Toxicogenomics Database](http://ctdbase.org/)** [@10.1093/nar/gku935] -- Manual literature curators annotated drug-disease pairs as 'therapeutic'. The resource is extensive (the 'therapeutic' threshold was low) but incomplete.
+ **[SIDER 2](http://sideeffects.embl.de/)** -- In addition to extracting side effects from drug labels, SIDER also extracts indications [@10.1038/msb.2009.98]. Since the approach is automated, some side effects may be extracted as indications and *vice versa*. This approach would only provide information for drugs with labels from the US FDA or Canada.

Any additional resources or suggestions?

[@LiuSemRep]: http://www.d.umn.edu/~tpederse/Pubs/amia2012-liu.pdf ""Liu, Ying, et al. 'Using SemRep to label semantic relations extracted from clinical text.' AMIA annual symposium proceedings. Vol. 2012. American Medical Informatics Association, 2012.""

[@MediPrev]: http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3900157/ ""Wei W-Q, Mosley JD, Bastarache L, Denny JC (2013) Validation and enhancement of a Computable Medication Indication Resource (MEDI) using a large practice-based dataset. AMIA Annual Symposium Proceedings.""","17",2015-01-14,2015-01-14,2,3475,"base.profile","Daniel","Himmelstein","dhimmel"
"334","comments","rephetio","2015-01-16T00:46:28.796Z",17,"Are there any types of nodes or edges that you think we should include? Or do you think there is a superior resource for an information type than the one proposed?

When constructing edges, we prefer data that is:

+ systematic, without knowledge bias
+ extensive in coverage
+ easy to process
+ without prohibitive reuse restrictions

For node suggestions, we prefer controlled vocabularies so annotating the nodes with new edge types in the future is possible.","17",2015-01-16,2015-01-16,2,471,"base.profile","Daniel","Himmelstein","dhimmel"
"335","comments","rephetio","2015-01-16T10:18:57.266Z",2,"Daniel -- we talked a bit about how you'll be constructing this resource in a manner that is automated and reproducible. I think it would be good to put these details in the research plan -- it will give people more opportunities to make suggestions. And if you'll be using techniques that you've used before it's probably a good idea to link people to that work.

I want people to be able to share their opinion on how you can create the most value from this project. I'm sure you'll agree that enabling reproducibility and reuse is a big part of that.

What do you think?","2",2015-01-16,2015-01-16,2,577,"base.profile","Jesse","Spaulding","jspauld"
"336","comments","rephetio","2015-01-16T19:49:29.082Z",17,"> I think it would be good to put these details in the research plan -- it will give people more opportunities to make suggestions.

Perhaps, we should discuss here what formats of data and types of services would be most valuable to the community. Then once we reach some consensus, I will update the proposal.

Currently, I was planning on releasing the network in a few file formats:

+ as a single JSON text file based on a [specification we've developed](https://github.com/dhimmel/hetio/blob/master/hetio/readwrite.py).
+ as a [SIF file](http://wiki.cytoscape.org/Cytoscape_User_Manual/Network_Formats) which is a text file of all edges. We will also provide an accompanying node table, with node attributes. This format is ideal for [Cytoscape](http://www.cytoscape.org/) users.
+ as a [GML file](https://en.wikipedia.org/wiki/Graph_Modelling_Language) -- a poorly documented and varyingly implemented format for storing graphs. Despite it's problems, this format is widely supported.
+ as separate files for each metanode and metaedge. This will help users who are only interested in a single part of the network, bypass having to process the rest of the network.
+ as matrices for edge types that were constructed from continuous pairwise scores.

An online tool for browsing the network would also be nice. I will look into options here.","17",2015-01-16,2015-01-16,2,1359,"base.profile","Daniel","Himmelstein","dhimmel"
"337","comments","rephetio","2015-01-22T18:14:09.286Z",17,"I am looking for a method to weight features based on their uniqueness: I want to downweight redundant features and upweight distinct features.

The specific problem is weighting side effects when calculating side effect similarity between two drugs. The initial implementation of this analysis [@10.1126/science.1158140] used the Gerstein-Sonnhammer-Chothia Algorithm [@10.1016/0022-2836(94)90012-4]. The initial implementation [describes their method](http://www.sciencemag.org/content/suppl/2008/07/10/321.5886.263.DC1/Campillos.SOM.pdf):

> Not all side effects are independent of each other; for example, 90% of drugs that cause nausea also cause vomiting. We correct for this redundancy by weighting side effects in a manner analogous to the down-weighting of similar protein sequences within multiple alignments [@10.1016/0022-2836(94)90012-4] (Fig. S1C). In order to determine the correlation weight, the correlation of side effects was determined by clustering all side effects according to their assigned drugs using a Tanimoto/Jacquard score to compute a distance matrix: The distance between two drugs was calculated by dividing the number of drugs that feature both side effects by the number of drugs that have either side effect associated. **The Gerstein–Sonnhammer–Chothia algorithm [@10.1016/0022-2836(94)90012-4] was used to compute weights based on a hierarchal clustering with the aforementioned distance matrix [@10.1073/pnas.95.25.14863].**

I would like to perform an identical analysis, while making the code and results public. The analysis follows the following steps:

1. Calculating pairwise side effect correlations.
2. Performing hierarchical clustering of side effects to produce a dendrogram
3. Inputting the denrogram into the GSC algorithm to calculate side effect weights.

I am looking for an implementation of step 3, that it easy to integrate with implementations of steps 1 and 2. My preferred languages are *R*, *python*, and *julia* (in that order). The author should be willing to post the code publicly under an open source license.

An in detail description of the GSC algorithm can be found in the paper appendix titled, *[A Method to Weight Protein Sequences to Correct for Unequal Representation](https://pdf.yt/d/Sx3jMbr8vANgxAej/download)*.

Also, if you know of a simpler or superior method for accomplishing this weighting task, please suggest.","17",2015-01-22,2015-01-22,2,2412,"base.profile","Daniel","Himmelstein","dhimmel"
"338","comments","rephetio","2015-01-22T20:43:07.278Z",22,"As a follow-up to this, are you planning to make only the network available, or are you planning to release all of the code necessary to construct the network? If you release that code, will you use some testing and continuous integration process to evaluate regressions? Releasing the code would allow others in the future to assess the role that new experiments or new sources of information play in prediction quality. I agree with Jesse that more details on the overall development process would be great.","22",2015-01-22,2015-01-22,2,509,"base.profile","Casey","Greene","caseygreene"
"339","comments","rephetio","2015-01-23T04:11:25.882Z",23,"Hey Daniel,

This should do it:
https://github.com/antoine-lizee/R-GSC/blob/master/GSC.R

It uses dendrogram objects in R.

Once you get it, the implementation is quite straightforward and short, so it doesn't really justify creating a package. Everything in one file, you can just source it.
Have a go at it and tell me what you think.

Best,
Antoine

PS: the attached reference that explains the algorithm has its main example wrong because of the low (and surprisingly inconsistent) precision they use to do the maths.","23",2015-01-23,2015-01-23,2,534,"base.profile","Antoine","Lizee","alizee"
"340","comments","rephetio","2015-01-23T19:58:27.683Z",17,"@alizee, thanks for the [open source implementation](https://github.com/antoine-lizee/R-GSC/) -- you just spared scientists all over the pain of unnecessary reimplementation.

Here is the code I wrote, which calls your `GSC` function

```r
GitHubScript <- function(...) {
  # Source a script from GitHub
  library(RCurl)
  github.url <- file.path('https://raw.githubusercontent.com', ...)
  script <- RCurl::getURL(github.url)
  eval(parse(text = script), envir = .GlobalEnv)
}

UnderrepresentationWeight <- function(mat) {
  # Returns underrepresentation weight for each column
  col.dist <- stats::dist(t(mat), method = 'binary')
  col.clust <- hclust(col.dist, method = 'ward.D2')
  col.dendro <- as.dendrogram(col.clust)
  GitHubScript('antoine-lizee', 'R-GSC', 'master', 'GSC.R')
  GSC(col.dendro)
}
```
I have come accross two errors for my use cases

The following code (which computes only the first 100 side effects for time) returns a vector of only `NaN`:
```r
underrep.ind.vec <- UnderrepresentationWeight(se.mat[, 1:100])
```
On a slightly larger matrix, I also got a maximum recursion depth error.

`se.mat` is a matrix where rows are compounds and columns are side effects. An element is `0` for no relationship and `1` for side effect. You can [load](http://stat.ethz.ch/R-manual/R-devel/library/base/html/load.html) `se.mat` from [this file](https://www.dropbox.com/s/8e12q0gkmxs54b6/se.mat.RData?raw=1).","17",2015-01-23,2015-01-23,2,1451,"base.profile","Daniel","Himmelstein","dhimmel"
"341","comments","rephetio","2015-01-25T03:22:18.788Z",23,"Hi Daniel,

Thank you for your feedback. 
I solved your first ""Nan"" problem. Below is a short explanation, and on the repository I added a [file](https://github.com/antoine-lizee/R-GSC/blob/master/dhimmel_bugs_test.R) in which I investigate the problem.

The problem came from the fact that some of your vectors of features in your original matrix were **exactly the same**, i.e. some of your compounds have the exact same side effects. This resulted in a computed distance of zero between these two objects, and the clustering is putting them at the bottom of the dendrogram, at height 0. The algorithm wasn't designed for such an edge case and a division by 0 was giving you the NaN. I slightly changed the algorithm to work even with this edge case.
I quickly tested that the coefficients at this edge case were roughly the limit of the coefficients when the two vectors are getting similar, which shows that the handling of this edge case is appropriate. 

I am looking into some profiling and making it work for bigger matrices, so I'll update you regarding your other problem soon.

Best,
Antoine","23",2015-01-25,2015-01-25,2,1113,"base.profile","Antoine","Lizee","alizee"
"342","comments","rephetio","2015-01-26T15:00:59.175Z",17,"I plan to follow the 10 rules of reproducible computational research [@10.1371/journal.pcbi.1003285].

@caseygreene, I would like to release all of the code. I plan on doing a lot of the work in notebooks (of the [R](http://rmarkdown.rstudio.com/) and [python](http://ipython.org/notebook.html) varieties). However, my current plan lacks the level of automation that you are suggesting.

Testing whether a new source of information has improved prediction should be straightforward. I am not sure exactly what you mean by ""continuous integration process"".

I would like to provide a single script that performs the entire analysis, but this may be difficult because the computation will be performed in different venues and locations.","17",2015-01-26,2015-01-26,2,740,"base.profile","Daniel","Himmelstein","dhimmel"
"343","comments","rephetio","2015-01-26T15:14:48.758Z",22,"If you get the entire analysis boiled down a one-step build process, there are services that can monitor your github repository, look for commits, and then kick off a build. You'd need to define test cases that determine that something looks different than you expect. Maybe you have a set of positive controls (known multi-use drugs?) and you evaluate the extent to which they are accurately predicted. Depending on how long the entire process takes, these services might be enough to monitor and identify any commits that produce large changes in your overall results. You could also use some sort of correlation measure to previous runs to look for any commits that produce abnormally large changes in the output.","22",2015-01-26,2015-01-26,2,716,"base.profile","Casey","Greene","caseygreene"
"344","comments","rephetio","2015-01-26T23:25:48.859Z",23,"Hey,

I think the code is ready now. 

In addition to the fix above that let the algorithm run on datasets with objects that have the same representation, I added some routine check to increase the maximum recursive depth of R when calling the function. I used a robust adaptive approach to increase this recursion limit based on the estimated number of elements in the dendrogram, see the [code](https://github.com/antoine-lizee/R-GSC/blob/master/GSC.R#L47).

I also did some extensive testing and profiling in the [dhimmel file] (https://github.com/antoine-lizee/R-GSC/blob/master/dhimmel_bugs_test.R) mentioned earlier. As expected, the algorithm is very cheap: execution time is linear in the number of elements of the dendrogram, with roughly [10ms / kElements] (https://github.com/antoine-lizee/R-GSC/blob/master/test/profiling.pdf). I tried to half the stack depth by writing a [more verbose](https://github.com/antoine-lizee/R-GSC/blob/master/test/GSC2.R) version of the GSC algorithm, but it didn't change performance, so I kept the first more elegant version.

Enjoy!","23",2015-01-26,2015-01-26,2,1085,"base.profile","Antoine","Lizee","alizee"
"345","comments","rephetio","2015-02-13T02:25:05.540Z",17,"SIDER is a [resource](http://sideeffects.embl.de/) which automatically parsed labels for approved drugs and annotated side effects and indications [@10.1038/msb.2009.98].

We [performed an analysis](http://git.dhimmel.com/SIDER2/) using the [raw SIDER data](http://sideeffects.embl.de/download/), to evaluate the accuracy, quality, and usefulness of this resource. In addition to using the indications, we are interested in adding side effects as a separate node and edge type in our network.

After quality control to resolve conflicts (cases where a concept was annotated to a compound as both a side effect and indication), we found indications for 1005 drugs. @leobrueggeman, manually classified 101 random indications and found a precision of 63.4% [95% CI: 53.1--72.6%]. We browsed the indications for multiple sclerosis and found that many symptomatic treatments were included while many of the disease-modifying small molecules were absent. Overall the SIDER indications alone will be a rather *poor* resource. One possibility is combining [SIDER indications](http://git.dhimmel.com/SIDER2/data/sider2-processed.txt) with orthogonal methods.

The precision of side effects was considerably better at 92.0% [95% CI: 84.4--96.2%]. However, despite being largely accurate, not all side effects are of the same relevance (frequencies vary and placebo levels of occurrence are frequently lacking). @leobrueggeman, could you provide some additional information on the deficiencies or strengths of the SIDER approach?","17",2015-02-13,2015-02-13,2,1524,"base.profile","Daniel","Himmelstein","dhimmel"
"346","comments","rephetio","2015-02-16T22:41:28.927Z",17,"@caseygreene and @jspauld, thanks for the suggestions. I've [added](http://thinklab.com/p/rephetio/plan/compare/0ed4f4242ca776e6460be3f24e9e7e4d3a5c6ad3/2f775f436f7c99413a195f729ae9a20bfc25e6c5) an [open science section](http://thinklab.com/p/rephetio/plan#open-science) to the proposal where I make commitments to:

+ the 10 simple rules for reproducible research in computational biology [@10.1371/journal.pcbi.1003285]
+ releasing all code on [GitHub](https://github.com/dhimmel)
+ releasing all data
+ CC-BY or CC-0 licensing

I also mention R Markdown and IPython notebooks, which I've been using extensively thus far -- for example, when [analyzing SIDER 2 data](http://git.dhimmel.com/SIDER2/).

***

@caseygreene, I think your suggestion of implementing a continuous integration process is fantastic. I am hesitant to commit on this issue for a few reasons:

+ In the past, the computations have been extreme (requiring cluster usage) and this may be unwieldy to execute after every commit. I hope to optimize the algorithm, which may help in this regard.
+ I need to investigate these services more.
+ Our heterogeneous network framework and analyses are still rapidly evolving, so I don't want to invest lot's of time in code or methods that will soon be replaced.
+ I need to start writing unit tests for my programs. This seems like a more immediate issue that I will prioritize. Once I create proper unit tests, I will enable them as [pre-commit hooks](http://git-scm.com/book/en/v2/Customizing-Git-Git-Hooks#Client-Side-Hooks).

That being said, your suggestion is in line with the philosophy of ThinkLab and I will keep it in mind.","17",2015-02-16,2015-02-16,2,1664,"base.profile","Daniel","Himmelstein","dhimmel"
"347","comments","rephetio","2015-02-17T02:21:47.753Z",17,"**Update: See reply -- this issue has been resolved. Links to our analyses and code have been changed to archived versions in this post.**

***

MEDI is a [publicly-available indication resource](http://knowledgemap.mc.vanderbilt.edu/research/content/MEDI) standardized to ICD9/UMLS concepts for diseases and RxNorm ingredients for drugs. The accompanying publication clearly and concisely presents the analysis, which follows a rational, resourceful, and thorough methodology [@10.1136/amiajnl-2012-001431].

The data is also already online, which [is not the case](http://thinklab.com/p/rephetio/how-should-we-construct-a-catalog-of-drug-indications/21) with some other indication resources we've evaluated. However, when [processing the data](http://cdn.rawgit.com/dhimmel/indications/65dbe8ec52c1c882cecb4451f5bcf433d5b189c7/medi/index.html) ([source on github](https://github.com/dhimmel/indications/tree/65dbe8ec52c1c882cecb4451f5bcf433d5b189c7/medi)), we came across a potential discrepancy between [Table 2 of the manuscript](http://dx.doi.org/10.1136/amiajnl-2012-001431#T1) and the [statistics we generated](http://cdn.rawgit.com/dhimmel/indications/65dbe8ec52c1c882cecb4451f5bcf433d5b189c7/medi/index.html#resource-counts). The problem could have arisen from a mistake in our data processing or in MEDI's data export.

Specifically, from the [manuscript](http://dx.doi.org/10.1136/amiajnl-2012-001431#T1) [@10.1136/amiajnl-2012-001431]:
> **Table 2**: Number of unique medications, ICD9 codes, and indication pairs extracted from each resource
>
| Resource               | Medications (% of total) | ICD9 codes (% of total) | Indication pairs (% of total) |
|------------------------|--------------------------|-------------------------|-------------------------------|
| RxNorm                 | 1,726 (56)                | 999 (33)                | 8,040 (13)                     |
| SIDER 2                | 1,554 (50)                | 1,703 (57)               | 17,702 (28)                    |
| MedlinePlus            | 1,629 (52)                | 869 (29)                | 16,581(26)                     |
| Wikipedia              | 2,608 (84)                | 2,624 (87)               | 34,911 (55)                    |
| Union of all resources | 3,112                     | 3,009                    | 63,343                         |

[Our analysis](http://cdn.rawgit.com/dhimmel/indications/65dbe8ec52c1c882cecb4451f5bcf433d5b189c7/medi/index.html#resource-counts) found different resource-specific counts. The comparison is complicated since the resource to numeric identifier mapping is unknown:

| resource | medications | diseases | indications |
|----------|-------------|----------|-------------|
| 1        | 3,091        | 2,985     | 53,615       |
| 2        | 1,648        | 1,075     | 6,279        |
| 3        | 984         | 551      | 2,497        |
| 4        | 447         | 222      | 952         |
| all      | 3,112        | 3,009     | 63,343       |
| hps      | 2,139        | 1,345     | 13,379       |

We will reach out to the MEDI authors for assistance. Currently the discrepancy seems to have a negligible effect on the high-precision subset.","17",2015-02-17,2015-02-17,2,3223,"base.profile","Daniel","Himmelstein","dhimmel"
"348","comments","rephetio","2015-02-17T17:26:17.673Z",17,"After contacting [Dr. Wei-Qi Wei](http://knowledgemap.mc.vanderbilt.edu/research/content/wei-qi-wei-mmed-phd), we located the cause of the discrepancy. The integer values in the `MENTIONEDBYRESOURCES` column of `MEDI_01212013_0.csv` and `MEDI_01212013_UMLS.csv` refer to *how many* resources reported the indication. We had incorrectly assumed that this column referred to *which* resources reported the indication. Therefore, it appeared that each indication was only reported by a single resource.

Resource-specific indications data is not available from the [MEDI website](http://knowledgemap.mc.vanderbilt.edu/research/content/MEDI). However, the true counts for each resource combination are provided in [manuscript Figure 2](http://dx.doi.org/10.1136/amiajnl-2012-001431#sec-8) [@10.1136/amiajnl-2012-001431]:

![Weighted Venn diagram of the distribution of medications and indication pairs within the four resources](http://jamia.oxfordjournals.org/content/jaminfo/20/5/954/F2.large.jpg)

We would like to thank the authors for their prompt response and clarification.","17",2015-02-17,2015-02-17,2,1082,"base.profile","Daniel","Himmelstein","dhimmel"
"349","comments","rephetio","2015-02-17T19:20:28.273Z",21,"@dhimmel 
From what I observed it seems that there are a few types of mistakes which, when combined, lead to a significant drop in the precision of indications. The biggest problem I saw in the SIDER data, and perhaps the easiest to fix, was that there were several ""indications"" which were not actually diseases (e.g. ""progression"", ""adverse reactions"", ""interactions""). It should be possible to filter out these artifacts of text mining via reference to a disease ontology.

The second repeated mistake I saw was that SIDER would on occasion mark a symptom of a real indication as an indication (e.g. agoraphobia, which sometimes accompanies panic disorder, was marked as an indication).

Probably the hardest problem to sort out would be the cases where a disease is mentioned in the ""Indications and Usage"" section of a label, but is not actually treated by the drug (e.g. drug x treats disease y, in the case that patient has disease z, administer drug x at a slower rate). This is less common, but happened a few times in the random sample of 100 indications I analyzed.

Lastly, an update to the drug list would be appropriate. There are only 888 drugs listed for SIDER, while the total number of FDA approved drugs is significantly higher. This difference could explain some of the gaps for indications.

Hope this helps give context to some of the issues within the indications.
Leo","21",2015-02-17,2015-02-17,2,1401,"base.profile","Leo","Brueggeman","leobrueggeman"
"350","comments","rephetio","2015-02-27T19:35:36.741Z",17,"In our previous project to [predict disease-associated](http://het.io/diease-genes) genes from a heterogeneous network [@10.1371/journal.pcbi.1004259], we used the [HGNC (HUGO Gene Nomenclature Committee) database](http://www.genenames.org) to encode genes [@10.1007/s00439-001-0615-0 @10.1093/nar/gku1071]. This resource, ""based at the European Bioinformatics Institute (EMBL-EBI), assigns unique symbols and names to human genes [@10.1093/nar/gku1071].""

For this project, we are considering switching to NCBI's [Entrez Gene](http://www.ncbi.nlm.nih.gov/gene) and would like feedback. ""The primary goals of Entrez Gene are to provide tracked, unique identifiers for genes and to report information associated with those identifiers for unrestricted public use. The identifier that is assigned (GeneID) is an integer, and is species specific [@10.1093/nar/gki031].""

The main advantages of Entrez versus HGNC for gene identification include:

+ more species than human
+ GeneIDs which are less error prone than ambiguous gene symbols
+ integration with many other NCBI services such as [HomoloGene](http://www.ncbi.nlm.nih.gov/homologene), which can relate orthologous genes across species

The main disadvantage is familiarity, as most biologists conceive human genes in terms of their HGNC symbols. Although symbol information is available in Entrez Gene, there is no guarantee that each Entrez Gene record has a single corresponding, current HGNC symbol.

I am interested in:

+ the best way to retrieve, store, parse, and map to Entrez Gene records
+ how stable Entrez Gene identifiers are for protein-coding genes in humans
+ the difficulty of updating to new versions of the Entrez Gene database

Any advice or information would be appreciated!","17",2015-02-27,2015-02-27,2,1769,"base.profile","Daniel","Himmelstein","dhimmel"
"351","comments","rephetio","2015-02-28T12:50:57.554Z",22,"We use Entrez internally in our lab at the moment. We store them in a SQL database with their associated features. We've started using ElasticSearch to perform mapping from sources that use multiple alternative identifiers or that also include aliases, but in general we try to convert to Entrez.

There are some problems with Entrez <-> HGNC, but they are relatively minor -- especially for protein coding genes. IMP, GIANT, Tribe, and our other servers use entrez internally and map to symbol for display purposes.

I have talked to people who are discussing more sophisticated systems to generate identifiers that unify the databases through an automated process capable of resolving ambiguities, and I am hopeful that some of those projects will come to fruition.","22",2015-02-28,2015-02-28,2,771,"base.profile","Casey","Greene","caseygreene"
"352","comments","rephetio","2015-03-12T16:26:39.610Z",17,"We have previously retrieved our human [Gene Ontology](//geneontology.org/) (GO) [@10.1038/75556] annotations from [MSigDB](//www.broadinstitute.org/gsea/msigdb/collections.jsp#C5). MSigDB was designed for gene set enrichment analyses and therefore GO terms with fewer than 10 annotations are excluded. Additionally, MSigDB is infrequently updated and only contains human gene sets.

Therefore, we created a [utility to provide GO annotations](//git.dhimmel.com/gene-ontology/) for a variety of species using the most recent annotation data. The resource relies on Entrez Gene as the [main gene vocabulary](//thinklab.com/discussion/using-entrez-gene-as-our-gene-vocabulary/34). The utility's [source code is online](https://github.com/dhimmel/gene-ontology), but briefly, annotations are retrieved from the Entrez `gene2go.gz` file and the python [goatools package](https://github.com/tanghaibao/goatools) is used to parse `go-basic.obo` and propagate annotations.

Propagating annotations refers to transferring annotations from a more specific GO term to its broader parent terms. The theoretical justification is described [@10.1038/nrg2363]:

> When a gene is annotated to a term, associations between the gene and the terms' parents are implicitly inferred. Because GO annotations to a term inherit all the properties of the ancestors of those terms, every path from any term back to its root(s) must be biologically accurate or the ontology must be revised.

We allow the user to choose propagated or unpropagated annotations, gene identifiers as Entrez IDs or symbols, and protein-coding or all genes. Since this resource is meant to be maximally useful, any suggestions or feature requests are welcome.","17",2015-03-12,2015-03-12,2,1719,"base.profile","Daniel","Himmelstein","dhimmel"
"353","comments","rephetio","2015-03-16T23:22:11.518Z",17,"Currently, we would like to integrate several drug resources that rely on different compound vocabularies. These resources include

| type | resource | vocabulary |
| - | - | - |
| indication | [MEDI](http://knowledgemap.mc.vanderbilt.edu/research/content/MEDI) [@10.1136/amiajnl-2012-001431] | [RxNorm](http://www.nlm.nih.gov/research/umls/rxnorm/) [@10.1136/amiajnl-2011-000116] |
| indication | [LabeledIn](http://ftp.ncbi.nlm.nih.gov/pub/lu/LabeledIn/) [@10.1016/j.jbi.2014.08.004 @10.1093/database/bav016] | [RxNorm](http://www.nlm.nih.gov/research/umls/rxnorm/) [@10.1136/amiajnl-2011-000116] |
| transcriptional signatures | [LINCS](http://www.lincscloud.org/) | LINCS & PubChem |
| target binding | [ChEMBL](https://www.ebi.ac.uk/chembl/) [@10.1093/nar/gkt1031] | ChEMBL |
| side effects | [SIDER 2](http://sideeffects.embl.de/download/) [@10.1038/msb.2009.98] | [STITCH](http://stitch.embl.de/) [@10.1093/nar/gkt1207] |
| side effects | [OFFSIDES](https://www.pharmgkb.org/downloads/) [@10.1126/scitranslmed.3003377] | [STITCH](http://stitch.embl.de/) [@10.1093/nar/gkt1207] |

We are planning on using [DrugBank](http://www.drugbank.ca/) [@10.1093/nar/gkt1068] as the primary vocabulary for compounds. While the [coverage of DrugBank](http://www.drugbank.ca/stats) is limited, DrugBank includes FDA-approved compounds and likely covers the majority of compounds that would be well-connected in the network. The main benefits of DrugBank are extensive information per compound and a level of granularity that matches our needs.

We plan to use [UniChem](https://www.ebi.ac.uk/unichem/ucquery/listSources) [@10.1186/1758-2946-5-3] to map resources with available structures. Importantly, we will likely benefit from a permissive matching algorithm that ignores small structural variations [@10.1016/j.ddtec.2015.01.005]. UniChem has a connectivity mapping feature to perform fuzzy matching [@10.1186/s13321-014-0043-5].","17",2015-03-16,2015-03-16,2,1940,"base.profile","Daniel","Himmelstein","dhimmel"
"354","comments","rephetio","2015-03-17T17:52:01.860Z",17,"This paper [@10.1016/j.jbi.2012.06.005] discusses the problem of mapping between medication vocabularies. They identify several major difficulties:

>
1. the availability of up-to-date information to assess the suitability of a given terminological system for a particular use case, and to assess the quality and completeness of cross-terminology links
2. the difficulty of correctly using complex, rapidly evolving, modern terminologies
3. the time and effort required to complete and evaluate the mapping
4. the need to address differences in granularity between the source and target terminologies
5. the need to continuously update the mapping as terminological systems evolve

They provide a helpful diagram (manuscript Fig. 2) that illustrates the connections between terminologies:
> ![](http://www.j-biomed-inform.com/cms/attachment/2022323725/2041973432/gr2_lrg.jpg)

Since most of our resources include structural information, we will likely face a slightly different and more computationally-amenable set of mapping challenges. Nonetheless, the ""differences in granularity between the source and target terminologies"" will be an important consideration.","17",2015-03-17,2015-03-17,2,1176,"base.profile","Daniel","Himmelstein","dhimmel"
"355","comments","rephetio","2015-03-17T19:40:52.373Z",17,"# Integrating RxNorm ingredients

The [RxNorm terminology](http://www.nlm.nih.gov/research/umls/rxnorm/) [@10.1136/amiajnl-2011-000116] does not contain chemical structures for ingredients. However, the terminology does cross-reference the NDF-RT and FDA-SRS. The FDA-SRS identifiers, called UNIIs (Unique Ingredient Identifiers), are [included in UniChem](https://www.ebi.ac.uk/unichem/ucquery/listSources). Therefore to map RxNorm ingredients to other vocabularies, we will first convert RXCUIs to UNIIs.

We downloaded the RxNorm data release and [loaded it into a MySQL database](http://www.nlm.nih.gov/research/umls/rxnorm/docs/2015/rxnorm_doco_full_2015-1.html). We used the following query to produce a RXCUI--UNII mapping:

```sql
SELECT DISTINCT RXCUI, CODE
FROM rxnorm.RXNCONSO
WHERE SAB = 'MTHSPL' AND TTY = 'SU' AND CODE != 'NOCODE';
```","17",2015-03-17,2015-03-17,2,859,"base.profile","Daniel","Himmelstein","dhimmel"
"356","comments","rephetio","2015-03-18T22:23:07.532Z",48,"Would you consider hosting your knowledge network on WikiData ? https://www.wikidata.org/.  WikiData is a new freebase-like open knowledge base being constructed by the Wikimedia Foundation.

A couple reasons to think about this:
1) Our group has NIH funding to build many of the nodes and edges you need there and we have already started.
2) By working in WikiData, your project can benefit from an existing, large user/contributor community and from the WMF computational resources.
3) WikiData is fundamentally about open knowledge exchange.  Working in its context will ensure the greatest visibility and re-use for your network.  

You probably wouldn't want to store computed probabilities there, but qualitative relationships would work well I think.  This would be a great use case for our own efforts..
","48",2015-03-18,2015-03-18,2,820,"base.profile","Benjamin","Good","b_good"
"357","comments","rephetio","2015-03-19T17:54:50.896Z",48,"Daniel,  
Regarding what to upload.  The figure you presented in your research plan sums this up nicely https://dl.dropboxusercontent.com/s/yp0gjh1v3329xji/metagraph.png
Aside from perhaps the MSigDB collection (which could be added), those are exactly the nodes and edges that we hope to see in WikiData.  

To use WikiData to its full power, you would actually use it within your own application in the same way that you would use your own internal relational database.  Rather than thinking of it only as a repository to export to, you could think of it as the central staging area for the data that you (and the rest of the community) want to compute with.  

For more about how we are working with wikidata, you can check out the series of blog posts that describes the funded grant here starting here:  http://sulab.org/2013/07/the-future-of-the-gene-wiki/  ","48",2015-03-19,2015-03-19,2,870,"base.profile","Benjamin","Good","b_good"
"358","comments","rephetio","2015-03-19T19:15:53.264Z",35,"Instead of using [Brenda Tissue Ontology](http://www.brenda-enzymes.info/ontology.php?ontology_id=3), I would suggest using [Uberon](http://uberon.org) for anatomy which incorporates [CL](http://cellontology.org/).These ontologies provide greater breadth of anatomy and cell types for various species. In addition, I think that with integration with Disease Ontology into [EFO](http://www.ebi.ac.uk/efo) you can add more data sources to this network as well as links to further experiments. 

ENCODE makes use of Uberon, you can read more  [@10.1093/database/bav010]","35",2015-03-19,2015-03-19,2,568,"base.profile","Venkat","Malladi","vsmalladi"
"359","comments","rephetio","2015-03-19T19:17:04.573Z",35,"Started discussion on changing ontology used for Tissue node. [Discussion is here](http://thinklab.com/discussion/tissue-node/41)","35",2015-03-19,2015-03-19,2,129,"base.profile","Venkat","Malladi","vsmalladi"
"360","comments","rephetio","2015-03-20T02:35:04.095Z",17,"Hi @vsmalladi, thanks for the [Uberon](https://uberon.github.io/) [@10.1186/gb-2012-13-1-r5] suggestion.

The project has good documentation, a nice user interface, and is [actively maintained](https://github.com/obophenotype/uberon/commits/master) -- three important features when choosing an ontology (and areas where the [BRENDA Tissue Ontology](http://www.brenda-enzymes.info/ontology.php?ontology_id=3) (BTO) [@10.1093/nar/gkq968] sometimes lags behind.

In our previous network [@10.1371/journal.pcbi.1004259], we had under 100 tissues and only used BTO as a common vocabulary. Since the current project is in an early stage, it is difficult to know whether we will take full advantage of the rich structure and cross-referencing provided by next-generation ontologies. However, I agree it makes sense to build an extensible and forward-thinking network and Uberon will assist in these pursuits. We also prefer ontologies that will have the widest adoption and are free of restrictive licensing. Do you know Uberon's license?

I noticed Uberon includes [mappings to other ontologies](https://github.com/obophenotype/uberon/wiki/inter-anatomy-ontology-bridge-ontologies), called *bridges*. A BTO bridge doesn't currently exist, but perhaps we could contribute one for the 77 BTO terms ([download link](http://het.io/disease-genes/downloads/files/expression.txt.gz)) used in our disease network.","17",2015-03-20,2015-03-20,2,1405,"base.profile","Daniel","Himmelstein","dhimmel"
"361","comments","rephetio","2015-03-20T04:06:29.499Z",17,"Hi @b_good, fascinating work. I was amazed that the [Gene Wiki](https://en.wikipedia.org/wiki/Gene_Wiki) [@10.1371/journal.pbio.0060175] [averages](http://sulab.org/2013/07/gene-wiki-progress-report/) ""two page views every single second"". This amazing traffic, and return on investement from the perspective of funders, illustrates the potential of open, crowdsourced, and collaborative undertakings.

I think your wiki work capitalizes on a larger trend of computing moving to the web and browser. I recently made my [first html presentation](http://slides.com/dhimmel/elevcan); my coding is now largely browser based thanks to [Jupyter](http://jupyter.org/) and [RStudio](http://www.rstudio.com/) and [hosted](https://github.com/dhimmel) online; API web-queries are now fundamental for information retrieval. It only makes sense that we adopt a information commons like Wikidata to integrate knowledge. The video below really sold me on the concept:

![:youtube](Rww2dA-1Cqc)

Since the initial stage of this project is highly prototypical, I am hesitant to immediately switch to Wikidata as our backend. However, I would love to work with you and your team to upload as much content as possible. Then for subsequent analyses, we could potentially pull from Wikidata.","17",2015-03-20,2015-03-20,2,1275,"base.profile","Daniel","Himmelstein","dhimmel"
"362","comments","rephetio","2015-03-20T06:13:53.412Z",35,"Hi @dantericci, I believe there is no restrictive licensing and is open to use. 

As for adpotion, they have many big projects and consotrium adopting use of Uberon. Such as EBI, [other adoptors](http://uberon.github.io/about/adopters.html).

Uberon does have cross-references to BTO, so I don't think we need to make a bridge. ","35",2015-03-20,2015-03-20,2,332,"base.profile","Venkat","Malladi","vsmalladi"
"363","comments","rephetio","2015-03-20T06:41:44.409Z",17,"I [updated the proposal](http://thinklab.com/p/rephetio/plan/compare/cf0af88368d84640e6face839932af64a0963f5f/438864fde53c372dfa654dd59674f4bfc6cf249c) to replace BTO with Uberon.

As for the BTO mapping, I didn't see [any bridges on the GitHub](https://github.com/obophenotype/uberon/tree/master/bridge) and the [BTO bridge download](http://purl.obolibrary.org/obo/uberon/bridge/uberon-bridge-to-bto.owl) produces an error. Am I looking in the wrong place or are the BTO mappings not populated yet?","17",2015-03-20,2015-03-20,2,501,"base.profile","Daniel","Himmelstein","dhimmel"
"364","comments","rephetio","2015-03-20T15:44:19.979Z",35,"@dhimmel Within the [Uberon file](http://berkeleybop.org/ontologies/uberon.owl) there are DbXref's. An example is for 

    <owl:Class rdf:about=""http://purl.obolibrary.org/obo/UBERON_0000002"">
        <rdfs:label rdf:datatype=""http://www.w3.org/2001/XMLSchema#string"">uterine cervix</rdfs:label>
        <oboInOwl:hasDbXref rdf:datatype=""http://www.w3.org/2001/XMLSchema#string"">BTO:0001421</oboInOwl:hasDbXref>
        <oboInOwl:hasDbXref rdf:datatype=""http://www.w3.org/2001/XMLSchema#string"">BTO:0002249</oboInOwl:hasDbXref>","35",2015-03-20,2015-03-20,2,533,"base.profile","Venkat","Malladi","vsmalladi"
"365","comments","rephetio","2015-03-20T21:37:04.117Z",17,"# The UniChem Connectivity Search

UniChem is a structure-centric search engine (based on InChI identifiers [@10.1186/1758-2946-5-7]) for compound unification [@10.1186/1758-2946-5-3]. UniChem includes a widesearch mode that matches compounds based on common connectivity [@10.1186/s13321-014-0043-5]. We speculate that fuzzy matching will outperform a strict structural identity matching [@10.1016/j.ddtec.2015.01.005] because:

+ we will retain more information by integrating greater percentages of external databases
+ small chemical variations may have a minimal pharmacodynamic impact
+ many resources and pharmacologists conceptualize compounds with less granularity than exact chemical structure

# Mapping external resrouces to DrugBank

We would like to standardize all compound resources using DrugBank [@10.1093/nar/gkt1068]. To accomplish this task, we first [parsed the DrugBank xml download](//nbviewer.ipython.org/url/git.dhimmel.com/drugbank/parse.ipynb) to extract basic compound information. Second, we [mapped DrugBank compounds to each resource in UniChem](//nbviewer.ipython.org/url/git.dhimmel.com/drugbank/unichem-map.ipynb) using the connectivity search [[docs](https://www.ebi.ac.uk/unichem/info/widesearchInfo)]. Third, we [assessed the mappings using a variety of metrics](//git.dhimmel.com/drugbank/unichem-map.html). For this third step, we concentrated only on approved small molecules as these will be the most essential and connected in our network.

The following findings were aparent:

+ DrugBank contained 1,600 approved small molecules, 51 of which were lacking structural information and could not be mapped.
+ 108 DrugBank compounds mapped to multiple DrugBank compounds indicating the granularity of our connectivity search is not equivalent to the granularity of the DrugBank inclusion criteria.
+ 93% of DrugBank compounds had atleast one match in ChEMBL, 77% matched FDA SRS (UNII), 95% matched PubChem, 57% matched LINCS
+ Zolmitriptan (DB00315) matched 768 PubChem compounds

Given these findings, we have the following **questions for a chemist or cheminformaticist**:

1. Given our focus on pharmacodynamics rather than pharmacokinetics and our desire to avoid duplicate entities in the network, did we [properly construct our UniChem query](//nbviewer.ipython.org/url/git.dhimmel.com/drugbank/unichem-map.ipynb)? 
2. Given that some DrugBank compounds matched multiple DrugBank compounds ([see histograms](//git.dhimmel.com/drugbank/unichem-map.html)), should we instead use the First InChIKey Hash Block (FIKHB) as the primary compound identifier?
3. ~20% of approved small molecules in DrugBank did not match a FDA-SRS (UNII) compound, which is troubling. Many of these unmatched compounds would have matched by name matching. We would like an explanation for this discrepency and will look into the issue further ourselves.
4. Should we use a tiered matching system, where we take only exact matches when available and then expand to connecitivity matches if necessary?
5. Should we adopt an even more permissive (or alternative) mapping strategy for LINCS to annotate more compounds with transcriptomic profiles?
6. Is the excessive number of PubChem matches for some DrugBank compounds indicative of a larger problem? The full mapping can be [downloaded here](//git.dhimmel.com/drugbank/data/mapping.tsv.gz).","17",2015-03-20,2015-03-20,2,3388,"base.profile","Daniel","Himmelstein","dhimmel"
"366","comments","rephetio","2015-03-25T21:20:49.529Z",21,"In order to make the disease data within the *Incomplete Interactome* easier to manipulate we have mapped the MeSH disease names used within the paper to their corresponding MeSH IDs. The outcome ([here](https://raw.githubusercontent.com/LABrueggs/incomplete-interactome/master/disease_output.tsv)) should make integrating data from this study simpler. The [python program](http://nbviewer.ipython.org/github/LABrueggs/incomplete-interactome/blob/master/SciencetoMESHterm.ipynb) and its associated input and output files can be found [here](https://github.com/LABrueggs/incomplete-interactome).","21",2015-03-25,2015-03-25,2,594,"base.profile","Leo","Brueggeman","leobrueggeman"
"367","comments","rephetio","2015-03-27T02:43:44.027Z",17,"[LINCS](//www.lincscloud.org/) (Library of Integrated Cellular Signatures) provided ""perturbational profiles across multiple cell and perturbation types, as well as read-outs, at a massive scale."" We plan to compute transcriptional profiles, i.e. expression signatures -- sets of up and down-regulated genes -- for the compounds in our network. We will be following a workflow suggested to us by Ted Natoli during the [online office hours](//www.lincscloud.org/training/).

For a given compound in our network, there may be multiple matched LINCS compounds. Additionally, each LINCS compound may have been assayed across multiple cell lines, dosages, and replicates. To calculate a single consensus transcriptional profile across multiple signatures we will

1. calculate pairwise correlations between signatures
+ calculate mean correlation with other signatures for each signature
+ scale similarities to sum to 1
+ multiply z-score signature vectors by their similarity weights
+ sum weighted z-score signature vectors

The z-score signature vectors are retrieved from the `/xchip/cogs/data/build/a2y13q1/modzs.gctx` file on the [C3 cloud](http://c3.lincscloud.org/).","17",2015-03-27,2015-03-27,2,1180,"base.profile","Daniel","Himmelstein","dhimmel"
"368","comments","rephetio","2015-03-31T00:16:47.526Z",17,"This discussion will explore how to unify the variety of disease vocabularies used by our resources. These resources are listed below:

| type | resource | vocabulary |
| - | - | - |
| indications | MEDI [@10.1136/amiajnl-2012-001431] | ICD-9 |
| indications | LabeledIn [@10.1016/j.jbi.2014.08.004 @10.1093/database/bav016] | UMLS [@10.1093/nar/gkh061] |
| transcriptional signatures | [STAR-GEO](http://dev.stargeo.io/) | custom |
| symptoms | HSDN [@10.1038/ncomms5212] | [MeSH](//www.nlm.nih.gov/mesh/filelist.html) [@10.1001/jama.271.14.1103] (2011 release) |
| gene associations | [het.io](//het.io/disease-genes/downloads/) [@10.1101/011569] | [Disease Ontology](//disease-ontology.org/) [@10.1093/nar/gkr972 @10.1093/nar/gku1011] |
| pathophysiology | [het.io](//het.io/disease-genes/downloads/) [@10.1101/011569] | [Disease Ontology](//disease-ontology.org/) [@10.1093/nar/gkr972 @10.1093/nar/gku1011] |
| tissue localization | [het.io](//het.io/disease-genes/downloads/) [@10.1101/011569] | [Disease Ontology](//disease-ontology.org/) [@10.1093/nar/gkr972 @10.1093/nar/gku1011] |

Our current plan is to use the Disease Ontology (DO) as our primary vocabulary. Therefore, we will have to map resources to DO terms.","17",2015-03-31,2015-03-31,2,1236,"base.profile","Daniel","Himmelstein","dhimmel"
"369","comments","rephetio","2015-04-01T21:45:15.517Z",17,"The initial LabeledIn [@10.1016/j.jbi.2014.08.004] resource used expert curators. The team behind this project tested crowdsourced curation using Amazon Mechanical Turk workers [@10.1093/database/bav016]. They found the majority vote of workers on whether a disease within a label was an indication had a high accuracy (96%).

They [assessed](ftp://ftp.ncbi.nlm.nih.gov/pub/lu/LabeledIn/Crowdsourcing/) 3004 indications not already in LabeledIn corresponding to 706 new drug labels. We are looking to increase the coverage of the initial LabeledIn dataset by adding these crowdsourced indications.","17",2015-04-01,2015-04-01,2,599,"base.profile","Daniel","Himmelstein","dhimmel"
"370","comments","rephetio","2015-04-02T17:16:17.491Z",17,"The [LabeledIn](http://ftp.ncbi.nlm.nih.gov/pub/lu/LabeledIn/) resource consists of an expert curated [@10.1016/j.jbi.2014.08.004] and crowdsourced [@10.1093/database/bav016] components. Here we will discuss parsing these resources to extract indications.","17",2015-04-02,2015-04-02,2,255,"base.profile","Daniel","Himmelstein","dhimmel"
"371","comments","rephetio","2015-04-02T22:13:31.868Z",17,"# Disease Ontology Resources

Since we plan to use the DO as our primary disease vocabulary, I thought I would keep track of related papers and projects here. These may be slightly off-topic but valuable to keep track of.

| name | description | cite |
| - | - | - |
| [Disease Ontology](//disease-ontology.org) | Main resource | [@10.1093/nar/gkr972 @10.1093/nar/gku1011] |
| [DOLite](http://django.nubic.northwestern.edu/fundo/) | DO terms are grouped using associated-gene similarity to produce a simplified vocabulary with little redundancy. | [@10.1093/bioinformatics/btp193] |
| DO_cancer_slim | Created a DO subset named `TOPNodes_DOcancerslim` composed of 63 non-redundant upper-level cancer terms | [@10.1093/database/bav032] |
| [DOAF](http://doa.nubic.northwestern.edu/pages/search.php) | Provides gene annotations (extracted from GeneRIF) to the Disease Ontology. | [@10.1371/journal.pone.0049686] |
| [FunDO](http://django.nubic.northwestern.edu/fundo/) | Provides gene annotations (extracted from GeneRIF) to the Disease Ontology. Uses diseases from DOLite. Potentially outdated. | [@10.1186/1471-2164-10-S1-S6] |
| [DOSE](https://github.com/GuangchuangYu/DOSE) | DOSE is an R package to compute semantic similarity between DO terms. The result is pairwise similarities between DO terms based only on the ontology structure.| [@10.1093/bioinformatics/btu684] |
| [DOsim](http://cran.r-project.org/web/packages/DOSim/index.html) | Similar to DOSE but allegedly unmaintained or outdated | [@10.1186/1471-2105-12-266] |
","17",2015-04-02,2015-04-02,2,1544,"base.profile","Daniel","Himmelstein","dhimmel"
"372","comments","rephetio","2015-04-03T04:43:56.743Z",48,"What data are you planning to use to validate your framework?  E.g. what are the positive controls?  Presumably you would have some collection of drug-disease pairs that would be divided into development, training, and testing sets? ","48",2015-04-03,2015-04-03,2,233,"base.profile","Benjamin","Good","b_good"
"373","comments","rephetio","2015-04-03T04:53:35.489Z",48,"You say elsewhere that you want to avoid bias - that you want to work basically form experimental measurements as much as possible.  This has some merit, but it also seems like there must be quite a lot of value out there in the space of biased knowledge.. Some of that bias will be real signal.  Would be great to execute an experiment to empirically test the impact of bringing in prior knowledge (e.g. via text mining techniques for relation extraction).  Does it make it better or worse at the task at hand?","48",2015-04-03,2015-04-03,2,511,"base.profile","Benjamin","Good","b_good"
"374","comments","rephetio","2015-04-03T05:35:58.188Z",48,"This dataset might be worth looking into.  Drug-indication links captured from physicians in an EHR system [@10.1136/amiajnl-2012-000852] .  Data appears to be available - though its in a 200+ page PDF!  http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3422843/bin/amiajnl-2012-000852-s1.pdf
(I'm sure that was a journal requirement).
","48",2015-04-03,2015-04-03,2,332,"base.profile","Benjamin","Good","b_good"
"375","comments","rephetio","2015-04-03T17:19:55.617Z",72,"Question: I was under the impression that the workers assessed individual indications rather than all indications within a specific label. Therefore each drug--disease (RxNORM--UMLS) pair should have it's own majority vote. However, the data release appears to be listed in terms of labels rather than indications. Some labels have multiple UMLS diseases but only report the outcome of a single vote. Majority votes should be in terms of indications rather than labels, right?
 
Answer: You are right: each drug--disease (RxNORM--UMLS) pair should have it's own majority vote and majority votes should be in terms of indications rather than labels. The data is organized in this manner only (one entry = one drug-label/UMLSCUI pair). Each entry in the text file corresponds to one indication candidate (i.e. one disease UMLS-CUI) in a given drug label. The disease CUI is specified in the third field of the file. Also, as you have already noted that there for some entries with two CUIs in the third field. These correspond to composite mentions (e.g.""Moderate to severe pain""). Our [disease NER module](http://metamap.nlm.nih.gov/) detects two concepts for this phrase (""moderate +pain"" and ""severe pain"") but we present this phrase as a single disease mention to the turkers and hence a single majority vote was computed for both UMLS-CUIs.

We are happy to answer more questions! - LabeledIn Team","72",2015-04-03,2015-04-03,2,1404,"base.profile","Ritu ","Khare","ritukhare"
"376","comments","rephetio","2015-04-03T17:59:14.506Z",17,"Thanks @ritukhare, we've [processed your datasets](//git.dhimmel.com/indications/labeledin/) and combined the expert [@10.1016/j.jbi.2014.08.004] and crowdsourced [@10.1093/database/bav016] indications. The [resulting .tsv file is available for download](//git.dhimmel.com/indications/labeledin/data/indications.tsv). We provide ingredient and disease names here *only for convenience*, since our simplistic lookup methodology left many identifiers unnamed. 

Specifically, we extracted 1,335 indications from the [expert data release](//ftp.ncbi.nlm.nih.gov/pub/lu/LabeledIn/LabeledIn_Structured_Results.txt) and 1,516 indications from the [crowdsourced data release](//ftp.ncbi.nlm.nih.gov/pub/lu/LabeledIn/Crowdsourcing/Crowdsourced_Results.txt). The two sets shared one indication, so merging the two resources resulted in `2850 = 1335 + 1516 - 1` indications.

We calculated the total number of labels reporting each indication. For this task, we assumed `study_drug_label_ID` was consistent across the expert and crowdsourced datasets. If this assumption is wrong, the effect would be minimal, since the two releases report almost entirely disjoint sets of indications.","17",2015-04-03,2015-04-03,2,1179,"base.profile","Daniel","Himmelstein","dhimmel"
"377","comments","rephetio","2015-04-03T20:10:47.043Z",17,"Hey @b_good, thanks for the suggestion [@10.1136/amiajnl-2012-000852] and tracking down the data supplement, which I cannot find on the [article's JAMIA page](http://dx.doi.org/10.1136/amiajnl-2012-000852). Hereon, I will refer to this resource as `ehrlink`, unless anyone can find a previously-used or author-preferred nickname.

This resource is noteworthy because it will capture off-label usages better than LabeledIn (which is explicitly on-label) and MEDI (whose inclusion criteria likely favor on-label indications)

I [converted the pdf file into a tsv file](http://nbviewer.ipython.org/github/dhimmel/indications/blob/gh-pages/ehrlink/convert-to-text.ipynb), which can be downloaded [here](//git.dhimmel.com/indications/ehrlink/download/amiajnl-2012-000852-s1.tsv).","17",2015-04-03,2015-04-03,2,778,"base.profile","Daniel","Himmelstein","dhimmel"
"378","comments","rephetio","2015-04-07T17:58:47.060Z",17,"# Evaluation with known indications

@b_good, the primary means of evaluation will be assessing performance on a masked subset of indications. Previously [@10.1371/journal.pcbi.1004259], we withheld 25% of observations for testing. During training (on the remaining 75% of observations), we can use cross-validation to identify optimal parameter values. We plan to measure performance using area under the ROC curve (AUROC). We will also consider using condensed-ROC curves [@10.1093/bioinformatics/btq140], which emphasize top predictions.

The [discussion you noted](http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21) discusses how to construct a catalog of high-confidence indications, also known as a *gold standard*. What we haven't discussed thus far is how to create a negative set, which is a necessary input for our classification approaches. The simplest way to generate negatives is to treat all non-positives as negatives: if a compound is not indicated for a disease, the compound-disease pair is considered a negative. Since our positive set is incomplete, some true but unknown indications will be considered negatives. Given that the overwhelming majority of negatives will truly be negatives, I expect the impact of improper negatives to be minimal. However, our past experiences show many people find this response unsatisfactory and would prefer us to exclude potential positives from the negative set. We will probably do that for this project, for example by omitting compound-disease pairs that are in the low-precision subset of MEDI [@10.1136/amiajnl-2014-002954].

In our previous project [@10.1371/journal.pcbi.1004259], we found that our classification approach was resistant to overfitting. In other words, our training and testing AUROCs were comparable. We should still continue a formal testing paradigm as good practice, but there is a larger issue that I will discuss in my next post.","17",2015-04-07,2015-04-07,2,1961,"base.profile","Daniel","Himmelstein","dhimmel"
"379","comments","rephetio","2015-04-07T19:33:29.194Z",48,"You can access SemRep extracted semantic relations (e.g. treats, causes) based on all PubMed abstracts (updated bi-annually) via the semantic medline database.  With a UMLS login, you can get the complete MySQL dump via http://skr3.nlm.nih.gov/SemMedDB/ .  Main challenge here is in ensuring quality (as with any NLP output).","48",2015-04-07,2015-04-07,2,325,"base.profile","Benjamin","Good","b_good"
"380","comments","rephetio","2015-04-08T01:53:46.278Z",17,"# ehrlink problem and medication vocabularies

We have extracted the ehrlink [@10.1136/amiajnl-2012-000852] indication data ([see above](#104)). Unfortunately, I am unfamiliar with the identifiers used for problems (diseases) and medications (drugs). I've posted a sampling below in case anyone can figure out.

| problem_definition_id | problem                                         |
|-----------------------|-------------------------------------------------|
| 63645                 | Complete D-transposition Of The Great Vessels   |
| 258894                | Acromegaly                                      |
| 275590                | Organic REM Sleep Behavior Disorder             |
| 62983                 | Arteriosclerotic Cardiovascular Disease (ASCVD) |
| 75090                 | Cerebral Palsy                                  |

| medication_definition_id | medication                                     |
|--------------------------|------------------------------------------------|
| 17938                    | Sodium Polystyrene Sulfonate Oral Powder       |
| 21707                    | Clotrimazole Anti-Fungal 1 % External Cream    |
| 18805                    | Niacin CR 1000 MG Oral Tablet Extended Release |
| 19598                    | ClonazePAM 0.5 MG Oral Tablet                  |
| 136143                   | AmLODIPine Besylate 2.5 MG Oral Tablet         |

My worry is that these identifiers may not correspond to a standardized vocabulary that we can access and easily map to. I will contact the authors for clarification.","17",2015-04-08,2015-04-08,2,1578,"base.profile","Daniel","Himmelstein","dhimmel"
"381","comments","rephetio","2015-04-06T18:57:35.693Z",72,"This is great. Thanks @dhimmel. There should be no confusion with the study_drug_label_ID between the two datasets: In expert-LabeledIn, the values are numbers and in crowd-LabeledIn, the values are concatenation of drug type and a number.

I don't have a readily available mapping of ingredient and disease identifiers to names. Please note that the it would be more appropriate to use the title of drug label (SPL) instead of ingredient name as the title will also contain the dose form information of the drug (and we found that indications may be different between two drugs having same ingredient but different dose form). However, it's your decision.","72",2015-04-06,2015-04-06,2,658,"base.profile","Ritu ","Khare","ritukhare"
"382","comments","rephetio","2015-04-08T05:15:41.083Z",17,"# Evaluation with novel indications

Experienced chemoinformaticians stress that impressive testing performance on known positives does not always translate to predicting *novel* positives. The causes are several fold:

+ the patterns behind established positives are not generative -- those patterns do not translate to unknown positives.
+ predictions are made for instances that are not well-represented in the training set. Understanding the applicability domain of your model is crucial here.
+ the current set of positives is synchronous with the current state of knowledge. If the method does not incorporate untapped knowledge, novel predictions may not be possible.

These issues are one reason why the community places such emphasis on novel discovery when appraising new methods. Absent experimental verification of our top predicted indications, there are a few approaches we could consider that begin to assess our ability to predict the ""unkown"". Several potential approaches were explored by a past repurposing study [@10.1038/msb.2011.26]:

+ Predicting indications currently undergoing clinical trials
+ Predicting potential indications that were not in our gold standard. For example, those indications in the MEDI low-precision subset or those identified using literature mining. 

These approaches are both imperfect, but they are a start. Ideally, we could experimentally evaluate several predictions. This work could potentially be [outsourced](https://www.scienceexchange.com/) and thus parallelized. ","17",2015-04-08,2015-04-08,2,1537,"base.profile","Daniel","Himmelstein","dhimmel"
"383","comments","rephetio","2015-04-08T05:23:57.025Z",17,"> we found that indications may different between two drugs having same ingredient but different dose form

@ritukhare, interesting to hear that examples of repurposing frequently relied on different dose forms (and perhaps dosage levels as well). I think we would like to ignore this complexity. In other words, our predicted indications will not include dosage or dose form recommendations. I am comfortable leaving these details for the end users to investigate.","17",2015-04-08,2015-04-08,2,467,"base.profile","Daniel","Himmelstein","dhimmel"
"384","comments","rephetio","2015-04-08T14:53:34.682Z",75,"Just to let you guys know that, at UNM, Oleg Ursu and I have been constructing such a catalog for nearly eight years. 
Unfortunately, nobody funds this type of activity - or at least nobody has funded it so far - thus resources are somewhat limited.
Briefly, we manually curated all the active pharmaceutical ingredients APIs (over 4400; includes biologics), and mapped them to FDA approved drug labels (over 50000 ADLs). 
From the ADLs one can extract/map indications, contra-indications, off-label indications... and to each API we mapped RxNorm [CUI], NPC, ATC, INN, plus targets, including numeric bioactivity & type [MoA related; non-MoA assigned; as well as non-human targets]. We also mapped all our diseases to DOIDs - however, there are about 800 or so left that will take us a while to map.
A few pointers: 
1) if you want to extract the data yourselves, you're in for a treat. There are diseases in ""indications"" that do NOT exist anywhere else [e.g., cancer XYZ with mutation A3999B, in other words it's not enough to have the disease, you need the right genotype!]; 
2) you also have to deal with indications that are ""fringe"" (pregnancy is not a disease; neither is contraception)
3) indications etc. are not from PubMed - so please pay attention to approved labels
4) disease modifying is far from trivial - you need epi to show you that, X years after the Dx/Rx event, there was no recurrence [are steroids in anti-allergy disease modifying? probably not; are antibiotics in sinusitis disease-modifying? yes and no [if it's chronic!]
","75",2015-04-08,2015-04-08,2,1559,"base.profile","Tudor","Oprea","TIOprea"
"385","comments","rephetio","2015-04-08T17:40:12.289Z",77,"My colleagues and I have worked on multiple approaches to create this knowledge in the papers below:

1. Wright A, Chen ES, Maloney FL. An automated technique for identifying associations between medications, laboratory results and problems. J Biomed Inform. 2010 Dec;43(6):891–901. http://www.ncbi.nlm.nih.gov/pubmed/20884377
2. McCoy AB, Wright A, Laxmisan A, Singh H, Sittig DF. A prototype knowledge base and SMART app to facilitate organization of patient medications by clinical problems. AMIA Annu Symp Proc. 2011;2011:888–94. http://www.ncbi.nlm.nih.gov/pubmed/22195147
3. McCoy AB, Wright A, Laxmisan A, Ottosen MJ, McCoy JA, Butten D, et al. Development and evaluation of a crowdsourcing methodology for knowledge base construction: identifying relationships between clinical problems and medications. J Am Med Inform Assoc. 2012 Oct;19(5):713–8. http://www.ncbi.nlm.nih.gov/pubmed/22582202
4. McCoy AB, Wright A, Rogith D, Fathiamini S, Ottenbacher AJ, Sittig DF. Development of a clinician reputation metric to identify appropriate problem-medication pairs in a crowdsourced knowledge base. J Biomed Inform. 2014 Apr;48:66–72. http://www.ncbi.nlm.nih.gov/pubmed/24321170

In the JAMIA paper mentioned above, we used what we called a crowdsourcing approach to get this data. We have recently validated that approach at another site, and that publication is coming out in ACI soon. Unfortunately, in the original version, as you suspected, our medications and problems not mapped to any standardized terminology. The identifiers are local to the EHR, and while we have made some attempts to map them to RxNorm and SNOMED-CT, we were never able to get a really accurate set. However, the validation uses data from a different EHR, which I believe can be more easily mapped. Once the paper is out, I'll see if I can share that data.","77",2015-04-08,2015-04-08,2,1847,"base.profile","Allison","McCoy","allisonmccoy"
"386","comments","rephetio","2015-04-08T18:05:35.112Z",75,"I find crowdsourcing useful when you use a team of experts. So, for example, a carefully selected team of experts, when working on the same problem, can give surprisingly interesting feedback on an otherwise difficult problem.
http://www.nature.com/nchembio/journal/v5/n7/abs/nchembio0709-441.html
Please note that this paper is not about data entry, but about polling experts for their opinion.

I professionally supervised data entry for chemical structures, chemical bioactivities, as well as controlled vocabulary descriptions for assays, indexing medicinal chemistry literature. The average *trained* person loading data had an error rate of 5-10% - errors varied with period (e.g., the closer to the deadline, usually Christmas, the worse the quality). We used a 3-layer quality control system. And even so, we had a 1-2% error in our database, as revealed by comparison with two other systems. 
See this paper http://pubs.acs.org/doi/abs/10.1021/ci400099q for details (mine is the WOMBAT database).

With this in mid, I want to point out that crowdsourcing problem medication pairs by clinicians is an intriguing effort, and if the data is publicly available I would like to learn more. There are risks because a) verification of data entry was probably not done at the entry level (was the clinician familiar with both the drug and the disease?); b) the person determining the problem would require training in pharmacovigilance, understanding of known side-effects, etc. I assume you have done that, and that you compared the sets? I apologize that I do not have time to access your papers right now. ","75",2015-04-08,2015-04-08,2,1617,"base.profile","Tudor","Oprea","TIOprea"
"387","comments","rephetio","2015-04-08T18:16:23.522Z",77,"To clarify the crowdsourcing approach, in our study the clinicians are completing the task because it is required during routine care, not solely for the purpose of creating a knowledge base. They are entering the data into the EHR because they are prescribing a medication to a patient and are often required to link it to one or more of the patient's problems for billing purposes. We did not ask them to do any additional work outside of their own routine clinical practice.","77",2015-04-08,2015-04-08,2,477,"base.profile","Allison","McCoy","allisonmccoy"
"388","comments","rephetio","2015-04-08T19:29:35.198Z",75,"thank you - was wondering about that. this does make their work more reliable.","75",2015-04-08,2015-04-08,2,78,"base.profile","Tudor","Oprea","TIOprea"
"389","comments","rephetio","2015-04-08T22:22:49.866Z",17,"> there must be quite a lot of value out there in the space of biased knowledge

You are correct. In our current proposal, we do use text mining for the symptom-disease edges and tissue-disease edges. We also rely on literature curation for compound-target binding and protein interactions.

> Would be great to execute an experiment to empirically test the impact of bringing in prior knowledge

I agree, we should fit a model that excludes all knowledge-biased domains. I reckon this model's performance on known indications will be drastically inferior. The worry with predicting known indications with known biology is that your testing performance becomes nearly perfect. However, your novel predictions are not interesting -- they would be readily apparent to a pharmacologist.

The more text mining data you include the larger your gap between testing performance and generative performance (see our [discussion on evaluation](http://thinklab.com/discussion/evaluation-framework/47#113)). Therefore, I like the following workflow:

1. Start with high-throughput resources that are not affected by knowledge bias (a.k.a. study bias)
2. If the algorithm performs significantly better than random, explore the top predictions.
3. If performance is mediocre, add a biased resource that provides orthogonal information (information not already included from a systematic resource)
4. Repeat.

One final note to help explain the insidiousness of the knowledge bias. In [CTD](http://ctdbase.org/) [@10.1093/nar/gku935], curators may read that `compound_X` treats `disease_X` and also targets `gene_X` and therefore add interactions between all three entities to their knowledgebase. In reality the study hasn't proven that `gene_X` is associated with `disease_X` but this relationship was still extracted. This happens on a macro-scale across the entire compendium of published literature: specific network vicinities become well studied and the resulting disease-gene-compound triangles are more a result of attention rather than noteworthy biology.","17",2015-04-08,2015-04-08,2,2065,"base.profile","Daniel","Himmelstein","dhimmel"
"390","comments","rephetio","2015-04-09T00:05:43.325Z",17,"# Seeking a Slim DO with distinct terms.

The Disease Ontology is a hierarchy of human diseases. However, our current method has been designed for *distinct* nodes (especially with respect to diseases and compounds, since we will be predicting indications). By distinct we mean non-redundant -- in a non-redundant set of terms, no terms should be an ancestor or descendant of any other term. 

Additionally, we would like to pick terms at an appropriate level of specificity. Below, I show lineages of DO terms and bold the term whose specificity I prefer:

+ cancer > organ system cancer > respiratory system cancer > **lung cancer** > Pancoast tumor > lung superior sulcus carcinoma
+ neurodegenerative disease > demyelinating disease > **multiple sclerosis** > relapsing-remitting multiple sclerosis
+ glucose metabolism disease > diabetes mellitus > **type 2 diabetes mellitus** > diabetic peripheral angiopathy

Ideally, we chose a level of specificity such that:

+ a term and its descendants form a cohesive and differentiated disease concept
+ disease data is collected at a similar level of specificity
+ sufficient data exists for the term, after propagating data annotated to more specific terms

These are competing aims and we will most likely have to make difficult subjective decisions. In the past [@10.1101/011569], we identified [108 distinct, complex diseases](http://het.io/disease-genes/downloads/files/diseases.txt) by investigating only diseases with GWAS. However, GWAS may be too restrictive of a filter for the present study. We are more concerned with omitting diseases that would be poorly connected in the network. Some diseases may be well connected but lacking GWAS. We also would prefer to focus on diseases with indications as indications are needed to train our model.

Two previous DO studies may be helpful here:

1. **DOLite** took a data-driven approach to selecting a consolidated set of DO terms [@10.1093/bioinformatics/btp193]. I have not been able to locate the list of DO identifiers composing DOLite. These terms may also be obsolete as the project is dated. _**Any information regarding DOLite would be appreciated.**_
+ **DO_cancer_slim** created a DO subset named `TOPNodes_DOcancerslim` composed of 63 non-redundant upper-level cancer terms [@10.1093/database/bav032]. _**We would like a similar term list but encompassing all diseases, not just cancers.**_","17",2015-04-09,2015-04-09,2,2427,"base.profile","Daniel","Himmelstein","dhimmel"
"391","comments","rephetio","2015-04-09T00:53:23.882Z",21,"While [mapping](http://nbviewer.ipython.org/url/git.dhimmel.com/drugbank/unichem-map.ipynb) DrugBank compounds to LINCS, we have noticed that UniChem's mapping is potentially outdated. UniChem maps to LINCS compound identifiers that begin with `LSM-` while the current LINCS small molecule identifiers (called `pert_id`) begin with `BRD-`.

UniChem searches that match to LINCS, hyperlink to the [LIFE resource](http://life.ccs.miami.edu/life/), which is not up to date with the released LINCS data ([example search](https://www.ebi.ac.uk/unichem/frontpage/results?queryText=ULSMZGGENQYXHL-UHFFFAOYSA-N&kind=InChIKey&sources=&incl=exclude) and [example link](http://life.ccs.miami.edu/life/summary?mode=SmallMolecule&source=LINCS&input=LSM-3295)).

LIFE contains ~9000 small molecules versus >20000 at LINCS and also does not consistently supply the main pert_id used by LINCS. The `LINCS ID` used by LIFE doesn't appear in the compound information that is currently obtainable from the LINCS API, so it may be an obsolete ID system replaced by pert_id.

We will contact UniChem to alert them and will solicit feedback from the LINCS team regarding the ID confusion.","21",2015-04-09,2015-04-09,2,1172,"base.profile","Leo","Brueggeman","leobrueggeman"
"392","comments","rephetio","2015-04-09T01:14:34.957Z",17,"Perhaps this explains why 39% of DrugBank approved small molecules [did not map](http://git.dhimmel.com/drugbank/unichem-map.html) to a single LINCS compound: the LINCS resource was half it's current size.

Until this issue is resolved, we have two workarounds:

1. Identify LINCS small molecules with their PubChem identifiers, which are provided for most compounds.
2. Match LINCS compounds to DrugBank using the provided InChIKeys and UniChem.","17",2015-04-09,2015-04-09,2,451,"base.profile","Daniel","Himmelstein","dhimmel"
"393","comments","rephetio","2015-04-09T01:28:15.012Z",17,"> My colleagues and I have worked on multiple approaches to create this knowledge in the papers [@10.1016/j.jbi.2010.09.009 @10.1136/amiajnl-2012-000852 @10.1016/j.jbi.2013.11.010]

@allisonmccoy, thanks for the references. I like your approach because it captures what clinicians are actually using to treat diseases (and can provide indication prevalence -- what percent of patients with problem X receive medication X). Too bad that the identifiers are local. We would definitely appreciate the validation data when available, especially if it can be mapped to standard terminologies.

In terms of the mappings from the [aforementioned](#104) study [@10.1136/amiajnl-2012-000852], we still may be able to extract some utility: for example, we could manually map indications for diseases where our indications were lacking. @allisonmccoy, did any of the other papers you highlighted release data that could add value here?

@TIOprea mentioned the difficulty of identifying disease-modifying indications, even in a carefully hand-curated database. @allisonmccoy, does your method favor disease-modifying links? For example, if modafinil were prescribed to treat MS-induced fatigue, would the clinicians link modafinil to multiple sclerosis or fatigue?","17",2015-04-09,2015-04-09,2,1258,"base.profile","Daniel","Himmelstein","dhimmel"
"394","comments","rephetio","2015-04-09T01:43:12.201Z",77,"> Did any of the other papers you highlighted release data that could add value here?

I don't believe so. I also omitted one more paper that validated the approach in Wright, et al.:

5. Wright A, McCoy A, Henkin S, Flaherty M, Sittig D. Validation of an association rule mining-based method to infer associations between medications and problems. Appl Clin Inform. 2013;4(1):100–9. 

The 2nd reference uses RxNorm, SNOMED-CT, and NDF-RT, all of which is freely available, so that knowledge base could easily be regenerated by another party.

> Does your method favor disease-modifying links? For example, if modafinil were prescribed to treat MS-induced fatigue, would the clinicians link modafinil to multiple sclerosis or fatigue?

It could be either, but more than likely it would be linked to MS, because that's what would be on the problem list already and easily linked during e-prescribing, but in our evaluation, we would have counted either as correct. We actually had a lot of discussion about this while doing the evaluations, because it did occur frequently.","77",2015-04-09,2015-04-09,2,1082,"base.profile","Allison","McCoy","allisonmccoy"
"395","comments","rephetio","2015-04-09T01:53:53.624Z",17,"@TIOprea, thanks for your insights. You touch on important points. In general our method may not require a perfect indication catalog to succeed, so I am hopeful despite the difficulties you mention. Specifically,

> There are diseases in ""indications"" that do NOT exist anywhere else [e.g., cancer XYZ with mutation A3999B, in other words it's not enough to have the disease, you need the right genotype!]

In this case, ""cancer XYZ with mutation A3999B"" would likely not be in the Disease Ontology and if it were would probably lack cross-references. However, if the disease did map to the DO, we would [propagate the indication](http://thinklab.com/discussion/unifying-disease-vocabularies/44#121) to ""cancer XYZ"".

> you also have to deal with indications that are ""fringe"" (pregnancy is not a disease; neither is contraception)

These indications would not make it into the network because they do not relate to an included disease term. Information loss is ); but we'll get over it (;

> indications etc. are not from PubMed - so please pay attention to approved labels

Thanks for the perspective. We won't include these as part of our gold standard.

> disease modifying is far from trivial - you need epi to show you that

This I think will be the biggest difficulty. One option could be to exclude drugs that mostly treat symptoms. We noticed that drugs with many indications tended to be of this category. For multiple sclerosis, disease modifying is an [established concept with currently 12 drugs](http://www.nationalmssociety.org/Treating-MS/Medications). Unfortunately, the MS indications we've [extracted from MEDI](http://git.dhimmel.com/indications/medi/) and [LabeledIn](http://git.dhimmel.com/indications/labeledin/) are predominantly symptomatic. And to make matters worse, for most other diseases the DM status seems much more poorly defined.","17",2015-04-09,2015-04-09,2,1880,"base.profile","Daniel","Himmelstein","dhimmel"
"396","comments","rephetio","2015-04-09T02:14:45.918Z",17,"> The 2nd reference [@McCoy_2011] uses RxNorm, SNOMED-CT, and NDF-RT, all of which is freely available, so that knowledge base could easily be regenerated by another party.

@allisonmccoy, I believe when MEDI [@10.1136/amiajnl-2012-001431] extracts RxNorm indications, they are taking information from the NDF-RT. My belief is based on that in the introduction they state:

> The integration of RxNorm with the National Drug File–Reference Terminology (NDF-RT) from the Veterans Health Administration has added significant indication information between single-ingredient medications and diseases through ‘may_treat’ and ‘may_prevent’ therapeutic relationships. NDF-RT includes both on-label and off-label indications, but its performance on indications has not been previously reported. Preliminary work with earlier versions of RxNorm and NDF-RT demonstrated that a number of medications were lacking indications.

Then in the methods they state:

> To obtain indications of a medication from RxNorm, we retrieved all diseases that connect with the medication through either ‘may_be_treated_by’ or ‘may_be_prevented_by’ relationships.

Do you know whether the RxNorm portion of MEDI relied on the same underlying NDF-RT data that you collected for the 2011 AMIA Proceedings Paper [@McCoy_2011]? 

[@McCoy_2011]: http://www.ncbi.nlm.nih.gov/pubmed/22195147 ""McCoy AB, Wright A, Laxmisan A, Singh H, Sittig DF. A prototype knowledge base and SMART app to facilitate organization of patient medications by clinical problems. AMIA Annu Symp Proc. 2011;2011:888–94.""","17",2015-04-09,2015-04-09,2,1575,"base.profile","Daniel","Himmelstein","dhimmel"
"397","comments","rephetio","2015-04-09T02:18:37.037Z",77,"> Do you know whether the RxNorm portion of MEDI relied on the same underlying NDF-RT data that you collected for the 2011 AMIA Proceedings Paper [1]?

@dhimmel We only used the may_treat relationship, but we also took advantage of the is_a hierarchy for problems and ingredient_of relationships between medications and expanded the original set of pairs. So there is some overlap between the two, but likely some pairs that exist in only one or the other.","77",2015-04-09,2015-04-09,2,458,"base.profile","Allison","McCoy","allisonmccoy"
"398","comments","rephetio","2015-04-09T17:39:42.896Z",21,"One of the edge types we plan to incorporate in our network is that between diseases and symptoms. This data will come from the work of *Zhou et al.* in their [""Human symptoms–disease network""](https://dx.doi.org/10.1038/ncomms5212) paper. The supplementary data released by *Zhou et al.* identifies diseases and symptoms by their MeSH names, but does not include the associated MeSH IDs. To ease interoperability we have performed the minor task of appending the relevant MeSH IDs to these files. The result can be found [here](https://github.com/LABrueggs/HSDN).","21",2015-04-09,2015-04-09,2,564,"base.profile","Leo","Brueggeman","leobrueggeman"
"399","comments","rephetio","2015-04-10T00:30:43.175Z",17,"# Selecting the top nodes from DO Cancer Slim

I emailed [Lynn Schriml](http://medschool.umaryland.edu/FACULTYRESEARCHPROFILE/viewprofile.aspx?id=20337), a lead investigator for the DO, asking about the creation of a consolidated and distinct set of high-level cancer terms. This work was [recently published](https://dx.doi.org/10.1093/database/bav032) in *Database* [@10.1093/database/bav032]. I wrote:

> My main question is how did you decide which terms should be included in TopNodes_DOcancerslim? I want to generate a similar top-level term set but for all diseases. Was this a very difficult task that required medical expertise? Do you have any plans to create a DO-wide slim set? (Ideally, I would prefer to rely on an existing effort than to recreate the wheel).

**Response by Lynn Schriml** (posted with permission):

We are not planning on creating a DO wide slim at this time.

Creating the DO cancer slim and the TOP nodes slim was a couple of months work by a team, including MDs, cancer and disease experts.

We started with a set of terms from multiple cancer sources that we wanted align. We worked to identify how each term mapped to the current nomenclature of disease (disease names change over time), we then worked to define each term, figure out if the term was represented in DO, and where to place the term in DO, then we added the terms, creating DO definitions. We also reviewed and edited related terms. Once we had the larger set of terms defined, we looked at their parent nodes up to the top node for cancer. 

We wanted to identify body system level parents that reflected both the most specific we could be (not mapping the new TOP node parent all the way up to cancer), and for the TOP node to be biologically informative. There was also much discussion in our work group to finalize these choices. When that was done, we then edited the DO file, adding the new subtypes (slims) and adding each term in (one at a time).","17",2015-04-10,2015-04-10,2,1970,"base.profile","Daniel","Himmelstein","dhimmel"
"400","comments","rephetio","2015-04-10T03:45:06.006Z",17,"# Reconstructing DO Lite

DO Lite is an outdated project which provided a consolidated disease terminology [@10.1093/bioinformatics/btp193]. The only data release we could find is a mapping of disease names to implicated genes. Unfortunately, [this dataset](http://django.nubic.northwestern.edu/fundo/media/data/do_lite.txt) omits the actual DO identifiers.

We extracted these disease names found 561 different terms. We [used a text matching paradigm to match](http://nbviewer.ipython.org/github/dhimmel/disease-ontology/blob/gh-pages/dolite/dolite.ipynb) these disease names to current DO terms. The paradigm consisted of the following steps:

1. creating a mapping of names (including synonyms) to DO identifiers [[tsv](http://git.dhimmel.com/disease-ontology/data/term-names.tsv)]
2. mapping DOLite names to current DO names (via exact lowercase match) [[tsv](http://git.dhimmel.com/disease-ontology/dolite/dolite_to_doid.tsv)]

A majority (`66.3% =  372 / 561`) of DOLite terms were matched to a current DO identifier. We may consider using these terms as a reference when manually constructing a DO Slim.","17",2015-04-10,2015-04-10,2,1120,"base.profile","Daniel","Himmelstein","dhimmel"
"401","comments","rephetio","2015-04-13T18:44:55.931Z",79,"The [BD2K-LINCS Data Coordination and Integration Center](http://lincs-dcic.org/)  is part of the Big Data to Knowledge (BD2K) NIH initiative, and it is the data coordination center for the NIH Common Fund's Library of Integrated Network-based Cellular Signatures (LINCS) program, which aims to characterize how a variety of human cells, tissues and the entire organism respond to perturbations by drugs and other molecular factors. 
  

The [BD2K- LINCS DCIC](http://www.lincsproject.org/centers/bd2k-lincs-dcic/) works closely with each [LINCS Data and Signature Generation Centers (DSGC)](http://www.lincsproject.org/centers/data-and-signature-generating-centers/). The DCIC also collaborates with other other organizations and projects like EBI (UniChem, ChEMBL, ChEBI), PubChem.
The LINCS Production Phase (LP2) DSGC's are:
-  Drug Toxicity Signature Generation Center (Icahn School of Medicine at Mount Sinai)
-  HMS LINCS Center (Harvard Medical School)
-  LINCS Center for Transcriptomics (Broad Institute)
-  LINCS Proteomic Characterization Center for Signaling and Epigenetics (Broad Institute)
-  Microenvironment Perturbagen (MEP) LINCS Center (Oregon Health and Science University)
-  NeuroLINCS Center (University of California, Irvine)

The UniChem chemical structure cross-reference is mapped against the standardized LINCS small molecule (LSM).  The DCIC uses a simple schema to combine LINCS and other data into a coherent and computable knowledge framework. The Center develops meta-data standards that enable data integration and representation across the data and signature generation centers (DGSCs). Members of the DCIC are actively developing a next generation integrated web-based platform for the LINCS project that will serve as the foundation for LINCS activities and federate LINCS data, signatures, analysis algorithms, pipelines, APIs and web tools.  

UniChem cross-references the standardized LINCS Small Molecule ID (LSM ID).  The LSM IDs are mapped to each center's compound and / or sample identifiers.  One example of such Center-specific IDs are identifier with the prefix ""BRD"", which correspond to small molecule compound IDs from the LINCS Center for Transcriptomics (Broad Institute).","79",2015-04-13,2015-04-13,2,2241,"base.profile","Caty","Chung","cchung"
"402","comments","rephetio","2015-04-13T20:32:22.786Z",17,"We have chosen to rely on [BindingDB](http://www.bindingdb.org/bind/index.jsp) [@10.1093/nar/gkl999 @10.2174/1386207013330670] for compound--protein binding (ligand--target affinity) information. Their website provides a [nice background on this topic](http://www.bindingdb.org/bind/BindingDB-Intro2a.pdf). BindingDB includes several other databases including ChEMBL [@10.1093/nar/gkr777 @10.1093/nar/gkt1031] and PubChem BioAssay [@10.1093/nar/gkp965 @10.1093/nar/gkr1132 @10.1093/nar/gkt978] and [provides](https://www.bindingdb.org/bind/chemsearch/marvin/SDFdownload.jsp?all_download=yes) well-annotated data in convenient formats.

We have [begun our parsing of BindingDB](http://nbviewer.ipython.org/github/dhimmel/bindingdb/blob/gh-pages/process.ipynb) from the `BindingDB_All_2015m3` release. We have taken the following steps:

1. Some binding experiments refer to multichain protein complexes. However, `96% = 1073428 / 1115639` of experiments assayed a single chain protein. For simplicity, we decided to omit binding to complexes.
+ Of the remaining interactions, the protein targets for `20% = 215107 / 1073428 ` did not map to a SwissProt identifier and were excluded.
+ Of the remaining interactions `78% = 673750 / 858321` were curated with `Homo sapiens` as the organism. While we will most likely only end up using the human targets, this filtering should naturally occur at a later stage.

The next step is translating BindingDB compounds to DrugBank compounds. Many BindingDB compounds may match a single DrugBank compound. Additionally multiple experiments may report affinities for the same compound--target pair. There are several affinity metrics (`Ki (nM)`, `IC50 (nM)`, `Kd (nM)`, `EC50 (nM)`) that are in nanomolar units. We would like to combine all affinities for a DrugBank--EntrezGene pair into a single molarity value (which can then be used as a network inclusion threshold).
 
We would like input on how to combine affinities across experiments. Are some molarity measurements more precise? Are certain source databases less error prone? We are looking for simple and rational rules and are willing to accept a healthy dose of reductionism.","17",2015-04-13,2015-04-13,2,2183,"base.profile","Daniel","Himmelstein","dhimmel"
"403","comments","rephetio","2015-04-14T00:34:03.123Z",80,"Hi Daniel,

Most of the data in bindingDB are 50% inhibitor concentrations (IC50s), inhibition constants (Kis), with occasional dissocation constants (Kds), all in default units of nanomolar (nM).  The IC50 values are regarded as less rigorous measures of binding affinity as they depend to some degree on the association constant of the enzyme substrate used in measuring the IC50 value. The Ki and Kd values should be somewhat more rigorous. If a given compound and protein target have multiple measurements of different types, I'd probably use them in the following order of preference: Kd over Ki over IC50.  That said, most of the data are IC50s, so this case won't arise all that often.  

Hope this helps!
Regards,
Mike","80",2015-04-14,2015-04-14,2,732,"base.profile","Mike","Gilson","mkgilson"
"404","comments","rephetio","2015-04-14T16:18:39.208Z",17,"The table below categorizes each binding by the affinity measures reported in bindingDB. Some reports include multiple measures. After filtering multichain and unmapped proteins, the number of bindings per category is reported:

| IC50 (nM) | Ki (nM) | Kd (nM) | EC50 (nM) | count |
| - | - | - | - | - |
| - | - | - | - | 881 |
| IC50 | - | - | - | 480,070 |
| - | Ki | - | - | 245,475 |
|- | - | Kd | - | 55,044 |
| - | - | - | EC50 | 74,549 |
| IC50 | Ki | - | - | 985 |
| IC50 | - | Kd | - | 76 |
| IC50 | - | - | EC50 | 631 |
| - | Ki | Kd | - | 4 |
| - | Ki | - | EC50 | 574 |
| - | - | Kd | EC50 | 8 |
| IC50 | Ki | Kd | - | 1 |
| IC50 | Ki | - | EC50 | 23 |

Definitions for reference:

+ IC50 - half maximal inhibitory concentration
+ Kd - dissociation constant
+ Ki - inhibitor constant
+ EC50 - half maximal effective concentration

@mkgilson, thanks! What about EC50s, of which there are 74,549 reports? Can we include this information, and if so where should EC50s fall in the preference order? 

Also is it possible to infer whether a ligand is an agonist or antagonist based on which measures are reported?","17",2015-04-14,2015-04-14,2,1148,"base.profile","Daniel","Himmelstein","dhimmel"
"405","comments","rephetio","2015-04-14T17:29:15.868Z",80,"Hi Dan,

I'd significantly downweight or ignore the EC50s, as these are at greatest risk of not corresponding to a confirmed binding reaction.  For example, there might be a compound which binds, or is expected to bind,  a particular protein target; but the measurement done is to expose cells to the compound and report the concentration at which it is ""50% effective"" (hence EC50) in producing a biological effect supposedly due to binding of the protein target.

Unfortunately, agonism/antagonism is not readily available.

Regards,
Mike","80",2015-04-14,2015-04-14,2,547,"base.profile","Mike","Gilson","mkgilson"
"406","comments","rephetio","2015-04-15T19:25:54.569Z",79,"The following tables will help you map between LINCS Centers to LINCS Small Molecule ID (LSM):
[mapping of LINCS Small Molecules to LINCS Facility ID](http://lincs-dcic.org/metadata/SmallMolecules/LincsID2FacilityID_LINCS_StandardizedCmpds_LSMIDs.txt)
[LINCS compound table](http://lincs-dcic.org/metadata/SmallMolecules/CompoundTable_LINCS_StandardizedCmpds_LSMIDs.txt)
[LINCS by SM_Center_Sample_ID](http://lincs-dcic.org/metadata/SmallMolecules/SampleTable_LincsID2FacilityID2CenterBatchID_LINCS_StandardizedCmpds_LSMIDs.txt)","79",2015-04-15,2015-04-15,2,531,"base.profile","Caty","Chung","cchung"
"407","comments","rephetio","2015-04-15T19:32:12.014Z",79,"The [BD2K LINCS Data Science Research webinars](https://sites.google.com/site/bd2klincsdatascience/) serve as a general forum to engage data scientists within and outside of LINCS project to work on problems related to LINCS data analysis and integration. 

The [BD2K-LINCS DCIC](http://lincs-dcic.org/) engages the research community by delivering high quality educational materials through the web as well as through mentoring, seminars and symposia. Also, Center investigators actively engage in the education of a new generation of Big Data Scientists by developing a graduate-level Big Data Science MOOC that will be delivered to graduate students in Big Data Biostatistics and other Biomedical Informatics graduate programs.

See [BD2K-LINCS DCIC Training and Outreach](http://lincs-dcic.org/#/training).
","79",2015-04-15,2015-04-15,2,816,"base.profile","Caty","Chung","cchung"
"408","comments","rephetio","2015-04-15T21:48:29.611Z",21,"@cchung, Thank you for the useful links. Looking into the file you linked to named [mapping of LINCS Small Molecules to LINCS Facility ID](http://lincs-dcic.org/metadata/SmallMolecules/LincsID2FacilityID_LINCS_StandardizedCmpds_LSMIDs.txt) (`LincsID2FacilityID_LINCS_StandardizedCmpds_LSMIDs.txt`), we found that it contained 35,305 `BRD-` small molecule perturbagen IDs. Separate from this, we have a smaller set of `BRD-` small molecule perturbagen IDs (20,413) extracted from the [LINCS L1000 API](http://api.lincscloud.org/). In comparing these two sets, we found only 13,796 common `BRD-` IDs.

This means that many of the `BRD-` small molecule perturbagen IDs mapped to `LSM` IDs do not have transcriptional profiles from Broad. Additionally many compounds that were transcriptionally profiled are not mapped to the `LSM` ID set.

Therefore, to integrate `BRD` compounds, we will rely on the supplied pubchem CIDs, which almost all compounds had.","21",2015-04-15,2015-04-15,2,956,"base.profile","Leo","Brueggeman","leobrueggeman"
"409","comments","rephetio","2015-04-16T13:55:58.879Z",79,"The count difference is because the [L1000 dataset contains  20,413 small-molecules](http://www.lincscloud.org/perturbagens/) profiled as part of the LINCS program, the Broad Connectivity Map, NIH efforts such as CDRP, and other projects.  We are standardizing the remaining - will keep you posted on the release!
","79",2015-04-16,2015-04-16,2,315,"base.profile","Caty","Chung","cchung"
"410","comments","rephetio","2015-04-16T18:56:14.776Z",17,"@leobrueggeman and I attended the online LINCS office hours today. We spoke primarily with Ted who provided some helpful insights and suggestions.

1. **Spearman's correlation** is preferred to the Pearson's correlation when calculating correlations between transcriptional profiles. Spearman's correlation is rank based and therefore less prone to excessive influence of extremes. We will switch from Pearson's to Spearman's correlation in step 2 [above](#).

2. **Gold signatures** -- Multiple replicates (often 3) are performed for each signature. Higher quality signatures are considered gold (`is_gold`) based on a heuristic that values reproducibility across replicates and distinctness of that signature. They require the aggregate correlation within replicates to exceed a threshold among other criteria. Around half of the dataset is gold. The informativeness of nongold signatures is dubious, thus Ted suggests restricting to gold signatures.

3. **Z-score threshold** -- when setting a DEG (deferentially expressed gene) threshold, the LINCS team uses `> 2.0` or `< -2.0` and is pleased with the results.

4. **Signature number bias in DEG counts** -- We found that some perturbagens had an extremely high number of DEGs. We speculate that this occurs for perturbagens with few signatures, since with many signatures across varying contexts, a large set of consistently dysregulated genes seems unlikely. Two possible corrections for this bias are: a) choose a constant number of signatures to include per perturbagen. However, this would lead to information loss, which is undesirable. b) develop an empirical method for adjusting for expected DEG numbers. We will explore option (b) in a future post.

5. **Best inferred gene set** -- (`is_bing`) refers to genes that are reliably imputed from the 1000 assayed genes (L1000). We plan to switch to only included the ~7,500 bing genes in our DEG analysis because we would like to avoid unreliable data. This may also help reduce the excess of DEG for certain perturbagens. Whether a gene is part of the bing subset can be retrieved through the `geneinfo` [API query](http://api.lincscloud.org/a2/docs/geneinfo). 
","17",2015-04-16,2015-04-16,2,2185,"base.profile","Daniel","Himmelstein","dhimmel"
"411","comments","rephetio","2015-04-16T21:16:29.833Z",17,"# BindingDB Processing

For our network, we desire binding edges between entrez genes and drugbank compounds. We coerced the bindingDB to conform to our desires using the following steps:

### [Dataset cleanup and tidying](https://github.com/dhimmel/bindingdb/blob/95aa588c6e553d85f7bd9030956297076f0df5e3/process.ipynb):

1. downloading and reading bindingDB
2. removing interactions with multichain complexes or without uniprot protein IDs
3. converting binding affinities to floats
4. retrieving entrez genes corresponding to uniprot proteins ([download mapping](http://git.dhimmel.com/uniprot/data/map/GeneID.tsv.gz))
5. gathering data so rows contain only a single affinity measurement, uniprot protein, and entrez gene ([download tidied data](https://github.com/dhimmel/bindingdb/blob/95aa588c6e553d85f7bd9030956297076f0df5e3/data/binding.tsv.gz))

### [Collapsing bindingDB into compound-gene relationships](https://htmlpreview.github.io/?https://github.com/dhimmel/bindingdb/blob/95aa588c6e553d85f7bd9030956297076f0df5e3/collapse.html):

1. restricting to human interactions
2. mapping bindingDB compounds to drugbank ([download fuzzy mapping](http://git.dhimmel.com/drugbank/data/mapping/bindingdb.tsv))
3. multiple affinities for the same bindingdb--uniprot pairs were resolved by preferentially selecting Kd over Ki over IC50 and taking a geometric mean when there were multiple measurements of the same measure ([download](https://github.com/dhimmel/bindingdb/blob/95aa588c6e553d85f7bd9030956297076f0df5e3/data/bindings-drugbank-collapsed.tsv))
4. collapsing into drugbank--gene pairs, taking the minimum affinity reported across grouped bindingdb--uniprot pairs ([download](https://github.com/dhimmel/bindingdb/blob/95aa588c6e553d85f7bd9030956297076f0df5e3/data/bindings-drugbank-gene.tsv))

The resulting drugbank--gene dataset contained 21,617 interactions. Setting an affinity threshold at 1 micromolar (1000 nanomolar) -- a threshold suggested by both @mkgilson and @alessandrodidonna in conversation -- retained ~20% of interactions. After thresholding at 1 micromolar, 890 genes and 1,634 drugbank compounds participated in 5,701 binding interactions.","17",2015-04-16,2015-04-16,2,2189,"base.profile","Daniel","Himmelstein","dhimmel"
"412","comments","rephetio","2015-04-17T18:45:07.422Z",17,"# Creating a slim DO

We created a slim DO with [137 terms](https://github.com/dhimmel/disease-ontology/blob/75050ea2d4f60e745d3f3578ae03560a2cc0e444/data/slim-terms.tsv ""TSV of DO Slim diseases"") where:

1. no terms were descendants/ancestors of other terms
2. terms were specific enough to be clinically relevant
3. terms were general enough to be well annotated

To create this slim term set, we combined the diseases from:

1. hetio [@10.1371/journal.pcbi.1004259] -- 108 complex diseases contained in the GWAS Catalog.
2. TOPNodes_DOcancerslim [@10.1093/database/bav032] -- a body system focused set of 63 cancer terms.

We found that both sources contained overlapping nodes, and we removed 34 nodes to create a non-overlapping term set. We chose the following rules to resolve overlapping nodes:

1. For cancers in TOPNodes_DOcancerslim, retain only the most specific cancer
2. Remove hetio terms that descend from TOPNodes_DOcancerslim terms
3. For the remaining overlapping hetio terms, choose the term with greater clinical interest or GWAS annotations. For 4 out of the 5 conflicts under this rule, we chose to retain the more general term.

### Other notes:

The repository with our DO analysis is [here](https://github.com/dhimmel/disease-ontology) and contains notebooks for [extracting xrefs](https://github.com/dhimmel/disease-ontology/blob/75050ea2d4f60e745d3f3578ae03560a2cc0e444/DO-xrefs.ipynb) and [evaluating our slim DO](https://github.com/dhimmel/disease-ontology/blob/75050ea2d4f60e745d3f3578ae03560a2cc0e444/slim.ipynb) [@10.5281/zenodo.45584].

We plan to propagate annotations from more specific terms to our slim terms. To facilitate this process, we created a [propagated DO slim xref mapping file](https://github.com/dhimmel/disease-ontology/blob/75050ea2d4f60e745d3f3578ae03560a2cc0e444/data/xrefs-prop-slim.tsv).

Pleural cancer (`DOID:9917`) was a TOPNodes_DOcancerslim term but was not found in the ontology version we downloaded (subversion revision 2810).","17",2015-04-17,2015-04-17,2,2016,"base.profile","Daniel","Himmelstein","dhimmel"
"413","comments","rephetio","2015-04-20T16:53:13.382Z",17,"We mapped the MeSH diseases from the HSDN [@10.1038/ncomms5212] to [our slim DO](http://thinklab.com/discussion/unifying-disease-vocabularies/44#144). See the [notebook](https://cdn.rawgit.com/dhimmel/hsdn/51d31d738fe3cad0a12c736b8def333729c3c7f4/index.html) for more info or download the [mapped data](https://raw.githubusercontent.com/dhimmel/hsdn/51d31d738fe3cad0a12c736b8def333729c3c7f4/data/symptoms-DO.tsv).

Each disease-symptom relationship includes a `tfidf_score` (term frequency-inverse document frequency). This score, $$w_{i,j}$$, between symptom *i* and disease *j* was calculated with:

$$$
w_{i,j} = W_{i,j} \times \log{\frac{N}{n_i}}
$$$

where $$W_{i,j}$$ is the number of co-occurrences in PubMed, *N* is the total number of diseases, and $$n_i$$ is the number of diseases where symptom *i* appears.

At some point we will set an inclusion threshold for symptom edges based on their `tfidf_score`.

We used a propagated slim DO mapping, so symptoms for MeSH term ""relapsing-remitting multiple sclerosis"" for example were included as symptoms for DO term ""multiple sclerosis"".","17",2015-04-20,2015-04-20,2,1106,"base.profile","Daniel","Himmelstein","dhimmel"
"414","comments","rephetio","2015-04-21T18:56:59.333Z",17,"# PREDICT Indications

An existing computational repurposing approach called PREDICT [@10.1038/msb.2011.26], compiled indications for their analysis. They describe their approach as:

> The associations between drugs and UMLS disease concepts were integrated from four different sources using three different methods: (i) direct mapping to drugs, exploiting embedded UMLS links between concepts and drugs; (ii) drug–condition associations downloaded from http://drugs.com, where conditions were mapped to UMLS concepts using MetaMap; and (iii) indication‐based mapping. For the latter, we extracted UMLS concepts using the MetaMap tool from textual drug indications downloaded from FDA package inserts (available in the DailyMed website, http://dailymed.nlm.nih.gov) and DrugBank. In addition, we manually added 44 associations occurring in phase IV (post‐marketing) clinical trials.

>... Finally, performing a manual curation of the extracted UMLS concepts from textual description of drug indications, we observed that they are more prone to false positives. We thus required that associations extracted from drug indications appear also in at least one more source.

Compounds are from DrugBank and diseases are from OMIM and the UMLS, which are both cross-referenced by the DO. The study does not report the precision of their indications making it difficult to assess how the quality compares with MEDI-HPS and LabeledIn.

We combined the supplementary datasets from the study to create a table of PREDICT indications ([notebook](http://git.dhimmel.com/indications/msb-predict/), [download](http://git.dhimmel.com/indications/msb-predict/data/indications-umls.tsv)). We will further investigate including these indications.","17",2015-04-21,2015-04-21,2,1739,"base.profile","Daniel","Himmelstein","dhimmel"
"415","comments","rephetio","2015-04-21T21:54:58.762Z",17,"# Indication Set

Now that we have decided which [diseases](http://thinklab.com/discussion/unifying-disease-vocabularies/44#144) and [compounds](http://thinklab.com/discussion/unifying-drug-vocabularies/40) to include in the network, we can map indications onto these nodes.

Our indication set contains four indication resources:

1. MEDI-HPS -- indications from the MEDI's high precision subset
2. MEDI-LPS -- indications from the MEDI's low precision subset
2. LabeledIn -- drug label indications extracted by experts or Mechanical Turks
3. PREDICT -- indications compiled by the PREDICT study

We anticipate constructing our gold standard of indications from MEDI-HPS, LabeledIn, and PREDICT while omitting MEDI-LPS, which has a lower precision. We did not include ehrlink [@10.1136/amiajnl-2012-000852] because the vocabularies were not mapped. However, we would happily reward anyone who contributes a mapping of [the problems](https://raw.githubusercontent.com/dhimmel/indications/f7ea9f9d932cf083c68cdb0395b474b215013280/ehrlink/data/problems.tsv) to the DO and [the medications](https://raw.githubusercontent.com/dhimmel/indications/f7ea9f9d932cf083c68cdb0395b474b215013280/ehrlink/data/medications.tsv) to DrugBank.

### Indication Links

+ [analysis notebook](https://cdn.rawgit.com/dhimmel/indications/f7ea9f9d932cf083c68cdb0395b474b215013280/merge.html) -- includes a searchable table
+ [data download](https://raw.githubusercontent.com/dhimmel/indications/f7ea9f9d932cf083c68cdb0395b474b215013280/data/indications.tsv) -- tsv file

We would still like a way to differentiate disease-modifying from symptomatic indications and will explore manually classifying a subset of indications and training a model.","17",2015-04-21,2015-04-21,2,1737,"base.profile","Daniel","Himmelstein","dhimmel"
"416","comments","rephetio","2015-04-23T03:38:31.939Z",17,"Evolutionary rate covariation (ERC) assesses whether two genes have a similar evolutionary history. A recent study computed ERC values in humans and found that genes associated with the same disease were often tied together by similar evolutionary histories [@10.1371/journal.pgen.1004967]. The study based their gene sets on [OMIM](http://www.omim.org/) [@10.1093/nar/gkn665], which focuses on Mendelian genetics, so whether ERC prioritizes disease-associated genes for complex diseases in unclear. However, this resource is attractive as an orthogonal, systematic, and unbiased indicator of common gene functionality.

We began working with the human data from the [website](http://csb.pitt.edu/erc_analysis/Methods.php). First, we parsed the data, converted from a matrix format to a tidy pairwise format, and mapped the UCSC gene ids to Entrez Gene ([notebook](http://nbviewer.ipython.org/github/dhimmel/erc/blob/c1f19cc70758a4d880881221697f49ab0f41ee10/erc.ipynb)). Next, we collapsed the values by Entrez Gene pairs ([code](https://github.com/dhimmel/erc/blob/c1f19cc70758a4d880881221697f49ab0f41ee10/entrez-group.R)). Almost all UCSC--Entrez mappings were one-to-one, but in the case of many-to-one, we took the average correlation value.

Our goal is to extract gene pairs that share an evolutionary history. ERC values are provided for all gene pairs with sufficient data, but we are only interested in the small subset of biologically-meaningful correlations. Here we consider using the ERC value as a threshold:

### Figure 1. Distribution of ERC values
![](https://raw.githubusercontent.com/dhimmel/erc/c1f19cc70758a4d880881221697f49ab0f41ee10/figure/erc-value-dist.png)

### Figure 2. Probability of positive or negative sign given absolute ERC value
![](https://raw.githubusercontent.com/dhimmel/erc/c1f19cc70758a4d880881221697f49ab0f41ee10/figure/erc-signed-dist.png)

Assuming that dissimilar evolutionary histories are not present, we can use Figure 2 to select an ERC threshold. Assuming a symmetric null distribution, selecting a threshold of `ERC > 0.75` would lead to a false discovery rate of approximately 10%. We can also take an empirical approach and optimize the threshold based on performance.

We would appreciate any community feedback on rational thresholding techniques. Additionally, we may want to consider a separate edge for dissimilar evolutionary history -- is that a meaningful concept?","17",2015-04-23,2015-04-23,2,2439,"base.profile","Daniel","Himmelstein","dhimmel"
"417","comments","rephetio","2015-04-28T22:43:19.909Z",17,"The above formula used to calculate `tfidf_score` adjusts for the frequency of the symptom, but not the frequency of disease. Therefore we speculate that the scores are comparable within but not across diseases. Since we want to adopt a single inclusion threshold for all symptom-disease pairs, we would like to reformulate the metric to adjust for disease frequency.

We added a [new visualization and table](https://cdn.rawgit.com/dhimmel/hsdn/af2237af712be4b5319fa3669527e3fa1dbdfe44/index.html) to investigate a disease-frequency bias. It appears that diseases that occur in more PubMed records have a higher number of symptoms exceeding a given `tfidf_score`.","17",2015-04-28,2015-04-28,2,666,"base.profile","Daniel","Himmelstein","dhimmel"
"418","comments","rephetio","2015-04-29T00:21:16.730Z",17,"Another paper by the same group [@10.1371/journal.pcbi.1004120] includes what I presume to be a subset of these diseases, so this mapping could be helpful there as well.
","17",2015-04-29,2015-04-29,2,171,"base.profile","Daniel","Himmelstein","dhimmel"
"419","comments","rephetio","2015-04-29T08:52:41.447Z",23,"Hi Daniel,

I spend some time solving your problem about mapping the drug names from one arbitrary system to a known ontology. As a matter of fact RxNorm proposes an [API](http://rxnav.nlm.nih.gov/RxNormAPIs.html#) which has an [endpoint](http://rxnav.nlm.nih.gov/RxNormAPIs.html#uLink=RxNorm_REST_getApproximateMatch) that can directly be queried for fuzzy matching - so that's useful. It will be helpful to look into the different endpoints of the API down the road, they provide many useful features (though poorly documented).

I [wrote a script (in R)](https://github.com/antoine-lizee/RRxNorm) to match all the medication names in your file and get the related properties of the retrieved Rx concepts. It took an hour + to run because of stalling to avoid going over API quotas. The fuzzy-matching API returns several rxcui matches for *each medication*. A score, ranging from 0 to 100, is attached to every match.

The main output file can have several concepts per medication names if (i) there is **ambiguity**, i.e. there is more than one best match for a medication or (ii) the best match is **imperfect**, i.e. the best score is not 100 (then the first three are reported).
The [final output](https://raw.githubusercontent.com/antoine-lizee/RRxNorm/master/Output/unambiguousMatches.csv) is a subset of this file with only the huge majority of unambiguous hits (and we thus have one concept per medication string).

Here are some numbers:
 1. Only 2353 medications got matched with a valid concept, out of 2537 initially. Some names don't correspond to any medication and are filtered out.
 2. From these 2353 matched medications, 2281 (97%) have an unambiguous first match. These are in the final output.
 3. These 2281 unambiguous hits match to a total of 2148 different rxcuis.
 4. 1490 (63%) medications have at least one perfect match, with 1471 (63%) being unambiguous.
 5. These 1471 unambiguous perfect hits match to a total of 1442 different rxcuis.

**QC** is straightforward by [comparing](https://github.com/antoine-lizee/RRxNorm/blob/master/Output/unambiguousMatchesForQC.csv) the original medication names and the retrieved name of each matched rxcui. I quickly checked and even the non-perfect matches (with a score different than 100) seems on point, at the exception of the ""therapies"" that have very few equivalents in RxNorm and definitely match to the wrong concept.

Potential future directions:
1. Assess the quality of the matches through a systematic check based on the [QC file](https://github.com/antoine-lizee/RRxNorm/blob/master/Output/unambiguousMatchesForQC.csv) mentioned above. 
2. Enrich the final dataset by resolving ambiguity from the term types reported in the rxcui properties.","23",2015-04-29,2015-04-29,2,2746,"base.profile","Antoine","Lizee","alizee"
"420","comments","rephetio","2015-04-30T20:51:53.215Z",17,"*Below, I've copied the [supplementary methods section](http://www.nature.com/ncomms/2014/140626/ncomms5212/extref/ncomms5212-s1.pdf) from the HSDN [@10.1038/ncomms5212] describing how the literature mining was accomplished. I think a similar method could help us if we choose to perform our own [text mining](http://thinklab.com/discussion/text-as-a-resource-for-network-population/48) for network population.*

We use the Medical Subject Headings (MeSH) [@10.1001/jama.1994.03510380059038] terminology to generate symptom-disease relationships from the metadata extracted from PubMed [@10.1093/nar/gkl1031] bibliographic records. PubMed is currently the most comprehensive literature database on biomedical sciences. It includes MEDLINE [@10.3163/1536-5050.95.4.416] and uses MeSH for each citation to facilitate information retrieval. MeSH is a controlled thesaurus that is used for the annotation of published articles, resulting in a high quality representation of their main topics and contributions. The MeSH terms are assigned manually by trained indexers and have been used in numerous biomedical text mining and literature-based discovery studies [@10.1038/ng895 @10.1093/bioinformatics/btr223 @10.1002/asi.20438 @10.1038/nrg1768].

We downloaded the [2011 ASCII version of MeSH](http://www.nlm.nih.gov/mesh/2011/download/termscon.html) that contains 26,142 distinct terms and their unified identifiers. The MeSH vocabulary is structured as a hierarchical tree with 16 top nodes, representing general categories, such as ‘Anatomy’, ‘Diseases’ and ‘Phenomena and Processes.’ The broad category ‘Diseases’ contains the sub-category ‘Symptoms and Signs’ (MeSH tree code C23.888) that incorporates terms related to clinical manifestations observed by physicians or perceived by patients. We used all terms contained in the ‘Disease’ category (Table S1), excluding ‘Animal diseases’, as well as twenty terms, which only represent unspecific disease information, such as ‘Diseases’ itself, ‘Syndrome’, ‘Chronic diseases’ and ‘Infection’. In total, we obtained 4,442 distinct MeSH disease terms and 327 distinct MeSH symptom terms to be used for the PubMed query. To ensure that we only retrieve records with the corresponding indexed disease terms as a major topic, we search MEDLINE with the constraint “[Majr:NoExp]”, which filters for bibliographic records with the study of a specific disease as a main contribution. Using the E-Utility API web service interface of the National Center for Biotechnology Information, we developed a JAVA program to automatically search all MEDLINE bibliographic records published between 1966 and October 2011 (Figure S4). The total number of corresponding PubMed records was 7,109,429, of which 6,553,494 included a disease and 1,405,038 a symptom term. The number of records that contain both a disease, as well as a symptom term was 849,103. They included all 4,442 MeSH disease terms and almost all (322, i.e. 98%) symptom terms.

![Figure S4 from the Human symptoms–disease network](https://raw.githubusercontent.com/dhimmel/hsdn/ca31229cf7174d8ee22567a455f386412a592144/figure/figS4.png)","17",2015-04-30,2015-04-30,2,3140,"base.profile","Daniel","Himmelstein","dhimmel"
"421","comments","rephetio","2015-04-30T22:03:36.193Z",17,"We would like to convert from RxNorm medications to their ingredients. RxNorm is an ontology, with terms connected by [relationship types](http://www.nlm.nih.gov/research/umls/rxnorm/docs/2015/appendix1.html), which can be traversed to map ingredients. This is necessary to [map RxNorm medications to DrugBank](http://thinklab.com/discussion/unifying-drug-vocabularies/40), enabling network inclusion. Additionally, we need to know when medications map to multiple ingredients as we are excluding combination therapies for the time being. Once the mapping is complete, we can proceed with [integrating the ehrlink resource](http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#169). This discussion will follow our attempts to map concepts to ingredients.","17",2015-04-30,2015-04-30,2,790,"base.profile","Daniel","Himmelstein","dhimmel"
"422","comments","rephetio","2015-04-30T22:04:16.067Z",17,"# RxNorm term types

RxNorm concepts each have a specified term type (`TTY`). RxNorm documentation is oftentimes difficult to navigate, so we provide definitions for [all term types](http://rxnav.nlm.nih.gov/RxNormAPIs.html#uLink=RxNorm_REST_getTermTypes) below. The descriptions are from [@10.1136/amiajnl-2011-000116], while definitions were found [here](http://rxnav.nlm.nih.gov/RxNavViews.html).

| `TTY` | Definition | Description |
|--------|----------|----------------|
| `BN` | brand name |  |
| `BPCK` | branded pack |  |
| `DF` | dose form |  |
| `DFG` | dose form group |  |
| `GPCK` | generic pack |  |
| `IN` | ingredient | The term type (TTY) indicating that this name is that of the substance represented in an RxNorm name responsible for the medicinal activity. Also, the name and the substance. |
| `MIN` | multiple ingredients | The TTY indicating that this name is that of the ingredients of a combination product represented in an RxNorm name, where those ingredients are responsible for the medicinal activity. Also, the name and the substances. |
| `PIN` | precise ingredient | The TTY indicating that this name is that of the substance, expressed more precisely as a salt or ester of the ingredient, represented in an RxNorm name. Also, the name and the substance expressed precisely. |
| `SBD` | branded drug | The TTY indicating that this name is the normalized name created for a branded clinical drug. The name consists of ingredient, strength, and dose form, followed by a brand name in square brackets. Also, the name and the product. |
| `SBDC` | branded drug component |  |
| `SBDF` | branded dose form |  |
| `SBDG` | branded dose form group |  |
| `SCD` | clinical drug |  |
| `SCDC` | clinical drug component |  |
| `SCDF` | clinical dose form |  |
| `SCDG` | clinical dose form group |  |","17",2015-04-30,2015-04-30,2,1844,"base.profile","Daniel","Himmelstein","dhimmel"
"423","comments","rephetio","2015-05-01T04:06:57.676Z",17,"# RxNorm API method

We found a method to retrieve ingredients using the `allrelated` [RxNorm API command](http://rxnav.nlm.nih.gov/RxNormAPIs.html#uLink=RxNorm_REST_getAllRelatedInfo). An example query for rxcui `198440` looks like:

`http://rxnav.nlm.nih.gov/REST/rxcui/198440/allrelated`

Ingredients can be extracted from the returned xml with the following XPath query:

`./allRelatedGroup/conceptGroup[tty='IN']/conceptProperties`

We wrote a [python script](http://nbviewer.ipython.org/github/dhimmel/indications/blob/aa2405b1015be580a5452d5e318f8d3e72468713/ehrlink/rxnorm-ingredient-map.ipynb) to perform this operation on the ehrlink [@10.1136/amiajnl-2012-000852] RxNorm medications [mapped](http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#169) by @alizee. The resulting ingredient map is available for [download](https://raw.githubusercontent.com/dhimmel/indications/aa2405b1015be580a5452d5e318f8d3e72468713/ehrlink/data/rxnorm-as-ingredient.tsv).","17",2015-05-01,2015-05-01,2,1009,"base.profile","Daniel","Himmelstein","dhimmel"
"424","comments","rephetio","2015-05-01T14:51:24.555Z",17,"ehrlink is our name for a study where an EHR system prompted clinicians to report the problem that a medication was prescribed for [@10.1136/amiajnl-2012-000852]. The resulting high-confidence set contained 11,166 problem-medication pairs with precision exceeding 95%. Thus far, the comments pertaining to ehrlink have been scattered, so this discussion is meant to consolidate and provide a home for further analysis.

Here is the history of this *collaborative integration effort*:

1. @b_good initially [suggested](//thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#101) the resource and located the data supplement.
+ @dhimmel converted the pdf data supplement to a tsv file ([comment](//thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#101), [notebook](http://nbviewer.ipython.org/github/dhimmel/indications/blob/gh-pages/ehrlink/convert-to-text.ipynb), [download](//git.dhimmel.com/indications/ehrlink/download/amiajnl-2012-000852-s1.tsv)).
+ @dhimmel [determined](http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#111) the identifiers were not from a standard terminology
+ @allisonmccoy [joined](http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#116) the discussion, confirming the proprietary identifiers and providing additional related studies.
+ @allisonmccoy and @TIOprea [discussed](http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#119) the reliability of the resource.
+ @alizee mapped the medication terms from ehrlink to RxNorm ([comment](http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#169), [repository](https://github.com/antoine-lizee/RRxNorm)).
+ @dhimmel mapped the RxNorm concepts matched by @alizee to RxNorm ingredients ([comment](//thinklab.com/discussion/retrieving-the-ingredients-in-rxnorm-concepts/61#179), [notebook](http://nbviewer.ipython.org/github/dhimmel/indications/blob/aa2405b1015be580a5452d5e318f8d3e72468713/ehrlink/rxnorm-ingredient-map.ipynb), [download](https://raw.githubusercontent.com/dhimmel/indications/aa2405b1015be580a5452d5e318f8d3e72468713/ehrlink/data/rxnorm-as-ingredient.tsv)).","17",2015-05-01,2015-05-01,2,2263,"base.profile","Daniel","Himmelstein","dhimmel"
"425","comments","rephetio","2015-05-01T20:00:14.399Z",23,"To go further on resolving ambiguities when retrieving concepts, I had to look up abbreviations of the TTY too. I had seen [the very useful link you mention above](http://rxnav.nlm.nih.gov/RxNavViews.html) from the RxNav documentation, but I finally used the more general ressource that is the MetaThesaurus of UMLS. [This page](http://www.nlm.nih.gov/research/umls/knowledge_sources/metathesaurus/release/abbreviations.html#mrdoc_TTY) lists all the abbreviations used in the Rx system.

I [extracted](https://github.com/antoine-lizee/RRxNorm/blob/master/getTTYs.R) from this page the table with all the TTY abbreviations into a reusable [csv file](https://github.com/antoine-lizee/RRxNorm/blob/master/Output/TTYInSourceAbbreviations.csv). It could be useful down the road to other people.","23",2015-05-01,2015-05-01,2,791,"base.profile","Antoine","Lizee","alizee"
"426","comments","rephetio","2015-05-01T22:18:31.017Z",17,"# Mapping ehrlink diseases to the DO

The ehrlink high-confidence set contains indications for 1,596 problems ([download](https://raw.githubusercontent.com/dhimmel/indications/968bd8c947fe045a56caefb9f08182dea6e20662/ehrlink/data/problems.tsv)). We used a simplistic string matching scheme to map these terms to the disease ontology. Lowercase ehrlink problem names were matched to lowercase DO names and synonyms ([notebook](http://nbviewer.ipython.org/github/dhimmel/indications/blob/968bd8c947fe045a56caefb9f08182dea6e20662/ehrlink/problem-map.ipynb), [results](https://raw.githubusercontent.com/dhimmel/indications/968bd8c947fe045a56caefb9f08182dea6e20662/ehrlink/data/problem-to-doid.tsv)).

`22.9% = 365 / 1596` of the ehrlink problems mapped to the disease ontology. Of the 137 DO slim terms, 50 had a matching ehrlink problem. When we include propagated matching to DO slim terms, 5 additional diseases get matched. While these recall numbers appear low, we do recover a decent extent of the major complex diseases with few to no false positives.","17",2015-05-01,2015-05-01,2,1058,"base.profile","Daniel","Himmelstein","dhimmel"
"427","comments","rephetio","2015-05-03T20:54:06.377Z",23,"UPDATE:
I went forward on resolving the ambiguity, using the term source in type, and then the number of ""atoms"" that matches each medication name. 

This brings down the number of remaining ambiguity from 72 to 11 medications (0.5%).

I understand you want to extract the ingredients from these concepts, so it doesn't necessarily matter that there are two ""top"" matches for one medication after trying to resolve ambiguity (both will likely lead to the same components). As a result I created both the file for the [successfully resolved matches](https://raw.githubusercontent.com/antoine-lizee/RRxNorm/master/Output/resolvedMatches.csv), and the [file for all the best matches after trying to resolve them](https://raw.githubusercontent.com/antoine-lizee/RRxNorm/master/Output/allResolvedMatches.csv). The latter has 100% of the medications, including the 11 ambiguous, for which I took arbitrarily one of the top concepts. This is the file you'll want to work off in the future.

I also created the [QC file](https://github.com/antoine-lizee/RRxNorm/blob/master/Output/resolvedMatchesForQC.csv) for the ambiguity resolution step.","23",2015-05-03,2015-05-03,2,1140,"base.profile","Antoine","Lizee","alizee"
"428","comments","rephetio","2015-05-05T01:11:23.690Z",17,"# Mapping ehrlink to DO and RxNorm ingredient terms

We created a version of ehrlink with the subset problem-medication pairs that mapped to standardized terminologies ([notebook](https://cdn.rawgit.com/dhimmel/indications/169dd2bb5f1a77f7cd54f1b7d6181f914f666e89/ehrlink/index.html), [download](https://raw.githubusercontent.com/dhimmel/indications/169dd2bb5f1a77f7cd54f1b7d6181f914f666e89/ehrlink/data/indications.tsv)). We converted problems to DO terms ([see above](#184)). Then we converted medications to RxNorm concepts, using the [mapping](http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#185) produced by @alizee. We excluded any RxNorm matches with `score < 55` as errors were observed below this threshold. Overall, the RxNorm `approximateTerm` [function of the API](http://rxnav.nlm.nih.gov/RxNormAPIs.html#uLink=RxNorm_REST_getApproximateMatch) performed impressively. Next we converted RxNorm concepts into their active ingredients and restricted to single-ingredient medications.

`33.3% = 3719 / 11166` of the original problem-medication pairs successfully mapped to an ingredient and DO term. Users should take note that our mapping procedure was motivated by precision and automation, rather than recall.","17",2015-05-05,2015-05-05,2,1265,"base.profile","Daniel","Himmelstein","dhimmel"
"429","comments","rephetio","2015-05-05T05:16:58.441Z",17,"# Revised indications which include ehrlink

We were able to [collaboratively map](//thinklab.com/discussion/extracting-indications-from-the-ehrlink-resource/62#190) ehrlink to RxNorm and the DO.

Our indication catalog, which only includes DO slim diseases and approved small molecules in DrugBank, now contains:

+ 1,386 high-confidence indications retrieved from MEDI-HPS [@10.1136/amiajnl-2012-001431], LabeledIn [@10.1016/j.jbi.2014.08.004 @10.1093/database/bav016], PREDICT [@10.1038/msb.2011.26], and ehrlink [@10.1136/amiajnl-2012-000852] covering 96 diseases and 602 compounds
+ 1,113 low-confidence indications retrieved from MEDI-LPS [@10.1136/amiajnl-2012-001431]

The combined high and low-confidence indication set covers 107 diseases and 744 compounds. For more information see the [notebook](https://cdn.rawgit.com/dhimmel/indications/36f0c5f143618abbbf8c9eb94b7318cb5936fd61/merge.html), table of [indications with resource info](https://github.com/dhimmel/indications/blob/36f0c5f143618abbbf8c9eb94b7318cb5936fd61/data/indications-with-source.tsv), or table of [collapsed indications](https://github.com/dhimmel/indications/blob/36f0c5f143618abbbf8c9eb94b7318cb5936fd61/data/indications.tsv).","17",2015-05-05,2015-05-05,2,1219,"base.profile","Daniel","Himmelstein","dhimmel"
"430","comments","rephetio","2015-05-05T05:23:16.481Z",17,"# Compound Vocabulary

We have proceeded with a subset of DrugBank [@10.1093/nar/gkt1068] as our compound vocabulary. [Included compounds](https://github.com/dhimmel/drugbank/blob/503968ed700257215f7c81137d29f86ab71e7ac4/data/drugbank-slim.tsv) meet the following criteria:

+ DrugBank type is `small molecule`
+ DrugBank groups includes `approved`
+ Have an InChI chemical structure

Other compound vocabularies are mapped to DrugBank with UniChem [@10.1186/s13321-014-0043-5] using the most permissive matching scheme [available](https://www.ebi.ac.uk/unichem/info/widesearchInfo) (`B = 0` and `C = 4`). `B = 0` matches compounds using the FIKHB (First InChIKey Hash Block) which is based on atomic connectivity [@10.1186/1758-2946-5-7]. `C = 4` matches compounds which share a component with a component of the DrugBank compound, in order to ignore differences based on salts and acids.","17",2015-05-05,2015-05-05,2,897,"base.profile","Daniel","Himmelstein","dhimmel"
"431","comments","rephetio","2015-05-07T18:39:43.748Z",17,"We talked to Dave and Ted at the LINCS office hours today. Here are the meeting notes:

## Probes and genes

There have been two versions of landmark genes (the genes that are measured by the L1000 platform). In the first version (`pr_pool_id = 'deltap'`), there were 979 landmark genes. In the current version (`pr_pool_id = 'epsilon'`), there are 978.

The L1000 platform is designed to imitate the Affymetrix HG-U133A array [@10.1186/gb-2006-7-7-r61], so L1000 output is in probe-space. The LINCS team performs their analyses in probe-space. For landmark genes, the probe-to-gene correspondence is one-to-one. However, other genes may consist of multiple probes. We plan to average z-scores across probes to convert our observations into gene-space.

## Computing consensus signatures

When drugs have multiple signatures, we find the average correlation value for each signature. We have noticed that some signatures have negative correlations and were thus contributing their inverse signature to the consensus. We are uncomfortable with negative weights and therefore plan to set a minimum correlation threshold for each signature. A minimum of `0` would exclude all negatively correlated signatures. Another option is `0.1`, which is used by the LINCS team when processing shRNA data.

# Miscellaneous

+ The API returns `-666` for missing values.
+ Instances refer to the replicates that compose a signature.
+ @leobrueggeman, will be presenting on LINCS at lab meeting today ([presentation](http://slides.com/leoo/lincs)).
+ `is_summly` refers to whether a perturbagen has been profiled across a broad range of cell lines.","17",2015-05-07,2015-05-07,2,1648,"base.profile","Daniel","Himmelstein","dhimmel"
"432","comments","rephetio","2015-05-08T18:06:54.819Z",17,"## Background reading on Gene Ontology annotations

1. Gene Ontology Annotations and Resources [@10.1093/nar/gks1050]
+ Use and misuse of the gene ontology annotations [@10.1038/nrg2363]
+ Understanding how and why the Gene Ontology and its annotations evolve: the GO within UniProt [@10.1186/2047-217X-3-4]
+ Quality of Computationally Inferred Gene Ontology Annotations [@10.1371/journal.pcbi.1002533]

### Updates

+ [Primer on the Gene Ontology](http://arxiv.org/abs/1602.01876 ""arXiv"")
+ [Gene Ontology: Pitfalls, Biases, Remedies](http://arxiv.org/abs/1602.01875 ""arXiv"")","17",2015-05-08,2015-05-08,2,587,"base.profile","Daniel","Himmelstein","dhimmel"
"433","comments","rephetio","2015-05-08T18:58:07.489Z",17,"We have proceeded with Entrez Gene for gene identification.

@caseygreene, do you have any advice or information on how to build the SQL database? I found [this site](http://jura.wi.mit.edu/entrez_gene/) which provides instructions and Perl scripts. Do you use the same [schema](http://jura.wi.mit.edu/entrez_gene/entrez_gene.pdf)?","17",2015-05-08,2015-05-08,2,333,"base.profile","Daniel","Himmelstein","dhimmel"
"434","comments","rephetio","2015-05-08T19:43:12.982Z",22,"We have done it a couple of ways. Currently we like to We have an EntrezID field that's an index, a systematic name that's an index (if you're human, this is HGNC identifiers), standard name (you won't need this for human only), the gene description, a foreign key to the organism (again, if only human, won't need this), the aliases (space separated list of previous/alternative names -- used only for full text search), whether or not the gene is now obsolete (used during updates), and a few other things that we use for search.

For other identifiers, we have a table of cross reference databases, which has a name (index) and a url. URL has characters in it that signify that the ID for the database is supposed to go there.

We then have a table of cross references, which has foreign keys to both the cross reference database and gene, as well as a cross reference id (also db index).

If you want python code to generate this and/or load identifiers using the Django ORM, we can supply it. We might also be able to open source it as part of a pip installable django app on pypi. This is on our to-do list, so we could potentially reprioritize if this is particularly useful to you.","22",2015-05-08,2015-05-08,2,1195,"base.profile","Casey","Greene","caseygreene"
"435","comments","rephetio","2015-05-08T19:46:56.057Z",22,"@dhimmel I'd add this as particularly important for GO as well: http://wiki.geneontology.org/index.php/Transitive_closure

People frequently overlook this.","22",2015-05-08,2015-05-08,2,157,"base.profile","Casey","Greene","caseygreene"
"436","comments","rephetio","2015-05-09T06:26:06.869Z",17,"DrugBank [contains](http://www.drugbank.ca/documentation) four types of drug-protein interactions:

+ **Target**: A protein, macromolecule, nucleic acid, or small molecule to which a given drug binds, resulting in an alteration of the normal function of the bound molecule anda desirable therapeutic effect. Drug targets are most commonly proteins such as enzymes, ion channels, and receptors.
+ **Enzyme**: A protein which catalyzes chemical reactions involving the a given drug (substrate). Most drugs are metabolized by the Cytochrome P450 enzymes.
+ **Transporter**: A membrane bound protein which shuttles ions, small molecules or macromolecules across membranes, into cells or out of cells.
+ **Carrier**: A secreted protein which binds to drugs, carrying them to cell transporters, where they are moved into the cell. Drug carriers may be used in drug design to increase the effectiveness of drug delivery to the target sites of pharmacological actions.

We extracted DrugBank-protein interactions ([notebook](http://nbviewer.ipython.org/github/dhimmel/drugbank/blob/22d835b3cd0ed421c18f855a85a183a9c1349e8f/parse.ipynb), [download](https://raw.githubusercontent.com/dhimmel/drugbank/22d835b3cd0ed421c18f855a85a183a9c1349e8f/data/proteins.tsv)). Our resource includes all DrugBank interactions that met the following criteria:

1. The interaction is between a drug and *single* protein. A target which is ""protein group"" and contains multiple uniprot proteins would be excluded. Examples include the [GABA-A receptor (anion channel)](//www.drugbank.ca/biodb/bio_entities/BE0004797) and [NMDA receptor](//www.drugbank.ca/biodb/bio_entities/BE0004956). Likewise, a target which is not a protein, such as [DNA](//www.drugbank.ca/biodb/bio_entities/BE0004796) or [Phosphate](//www.drugbank.ca/biodb/bio_entities/BE0004815), would be excluded.
2. The protein maps to an entrez gene. Some uniprot proteins did not such as [Q7ZJM1](//www.uniprot.org/uniprot/Q7ZJM1), [Q59GM9](//www.uniprot.org/uniprot/Q59GM9), and [Q53ET4](//www.uniprot.org/uniprot/Q53ET4) -- all TrEMBL (unreviewed) terms with low [annotation scores](http://www.uniprot.org/help/annotation_score).

In total, we extracted 19,906 interactions for 5,878 drugs and 3,757 genes.","17",2015-05-09,2015-05-09,2,2255,"base.profile","Daniel","Himmelstein","dhimmel"
"437","comments","rephetio","2015-05-09T13:55:34.618Z",22,"Larry Hunter just gave a talk here where he highlighted his group's work developing KaBOB:
http://www.biomedcentral.com/1471-2105/16/126/abstract

Some of the work that they've done may help with processing of external databases. They unify some of the drug/target concepts in DrugBank and PharmGCB, for example, by developing abstract representations of genes, gene products, variants, etc.","22",2015-05-09,2015-05-09,2,394,"base.profile","Casey","Greene","caseygreene"
"438","comments","rephetio","2015-05-09T19:44:06.933Z",17,"Thanks for the recommendation [@10.1186/s12859-015-0559-3]. Unless there is a specific contribution that this resource could immediately provide, I am wary to invest significant time in understanding and integrating it.

For example, do we want to introduce a dependency on a [1,665 line java package](https://github.com/UCDenver-ccp/datasource/blob/master/datasource-fileparsers/src/main/java/edu/ucdenver/ccp/datasource/fileparsers/drugbank/DrugBankDrugRecord.java) to parse a DrugBank record, when we can retrieve the small subset of information we require with [much simpler scripts](https://github.com/dhimmel/drugbank/blob/93d4974e05e238fc45d87e9a79d3f2b23cab58e1/parse.ipynb).

My initial sense is that while this study tackles some important problems in biodata integration, there isn't a readily available way to easily retrieve and incorporate the unified vocabularies. It would be great to get feedback from the authors, in case I am wrong.","17",2015-05-09,2015-05-09,2,955,"base.profile","Daniel","Himmelstein","dhimmel"
"439","comments","rephetio","2015-05-09T20:26:06.382Z",17,"# Transitive Closure

@caseygreene, our resource has an option to propagate annotations to account for transitive closure. Briefly, transitive closure is defined through example as:

> ‘every kidney is located in some body’ follows from ‘every kidney is located in some abdomen’ and ‘every abdomen is located in some body’ [@10.1093/bioinformatics/btr164]

Our current propagation method transfers annotations across `is_a` relationships between terms in the `go-basic.obo` ontology. We rely on the [goatools python package](https://github.com/tanghaibao/goatools) to process the gene ontology. This package [appears to discard all non-`is_a` relationships](https://github.com/tanghaibao/goatools/blob/b7aab4ee4d242d67aa7f4eba2bb5015238875a6b/goatools/obo_parser.py#L91). It sounds like our method would classify as the ""the old way"" according to [your link](http://wiki.geneontology.org/index.php/Transitive_closure).

Is there an easy way to retrieve a table of closure relationships that we should use for annotation propagation? The site mentions a ""pre-computed closure tsv"" but does not indicate whether it is currently available. If we do switch to a method that incorporates additional relationship types beyond `is_a`, which additional types do you recommend propagating on?","17",2015-05-09,2015-05-09,2,1291,"base.profile","Daniel","Himmelstein","dhimmel"
"440","comments","rephetio","2015-05-10T21:10:43.806Z",17,"## Background

The National Library of Medicine (NLM) produces a catalog of 23 million journal articles called PubMed. PubMed contains [two subsets](//www.nlm.nih.gov/pubs/factsheets/dif_med_pub.html) that are relevant for literature mining:

1. **PubMed Central (PMC)** -- 3.4 million articles that include full texts, rather than just abstracts.
2. **MEDLINE** -- 21 million articles that are manually annotated with their topics. Topics are chosen from the MeSH vocabulary. 5,594 journals are [currently indexed](http://www.ncbi.nlm.nih.gov/nlmcatalog/?term=currentlyindexed).

MeSH, which stands for Medical Subject Headings, is a broad terminology of ~27 thousand terms structured hierarchically to form an ontology. *Skilled subject analysts* at the NLM [typically assign](//www.ncbi.nlm.nih.gov/books/NBK3827/#pubmedhelp.MeSH_Terms_MH) 10--12 MeSH terms per article and denote a subset of these terms as *major topics*.

## Application

Text mining, as [suggested to us](//thinklab.com/discussion/text-as-a-resource-for-network-population/48) by @b_good, is an intriguing technique because it is widely-applicable and draws from a knowledge base of epic proportions [@10.1186/1742-5581-3-2].

We would like to infer relationships between nodes in our network based on MEDLINE cooccurrence. We will search for pairs of MeSH terms that are assigned to the same articles beyond what would be expected if the terms were unrelated. This approach has successfully identified disease symptoms [@10.1038/ncomms5212] ([browse results](https://cdn.rawgit.com/dhimmel/hsdn/51d31d738fe3cad0a12c736b8def333729c3c7f4/index.html)). The method is versatile and can be applied to any nodes which have been mapped to MeSH.","17",2015-05-10,2015-05-10,2,1724,"base.profile","Daniel","Himmelstein","dhimmel"
"441","comments","rephetio","2015-05-12T02:41:44.069Z",17,"The [Disease Ontology](//disease-ontology.org/) (DO) [@10.1093/nar/gkr972 @10.1093/nar/gku1011] is an open source ontology of human diseases. We are using a [subset of the DO](//thinklab.com/discussion/unifying-disease-vocabularies/44#144), which we refer to as DO slim, as our primary disease vocabulary.

We plan on using this discussion to document [DO feature requests](//sourceforge.net/p/diseaseontology/feature-requests/) related to our project. Individuals who contribute to the DO to assist our project should post here so their efforts can be rewarded.","17",2015-05-12,2015-05-12,2,564,"base.profile","Daniel","Himmelstein","dhimmel"
"442","comments","rephetio","2015-05-12T02:52:52.494Z",17,"# MeSH cross-reference additions

Of our 137 [DO slim](//thinklab.com/discussion/unifying-disease-vocabularies/44#144) terms, 19 did not contain a MeSH (`MSH`) xref. We manually mapped 16 of these terms ([tsv download](https://raw.githubusercontent.com/dhimmel/disease-ontology/89a4fa3e8eb4703d0d3f2c6001ff807876f8b045/requests/DO-slim-to-mesh.tsv)):

| doid_code | doid_name | mesh_id | mesh_name |
|--------------|---------------------------|---------|----------------------------------|
| DOID:0050741 | alcohol dependence | D000437 | Alcoholism |
| DOID:0050742 | nicotine dependence | D014029 | Tobacco Use Disorder |
| DOID:0060119 | pharynx cancer | D010610 | Pharyngeal Neoplasms |
| DOID:10021 | duodenum cancer | D004379 | Duodenal Neoplasms |
| DOID:10153 | ileum cancer | D007078 | Ileal Neoplasms |
| DOID:1115 | sarcoma | D012509 | Sarcoma |
| DOID:11615 | penile cancer | D010412 | Penile Neoplasms |
| DOID:11920 | tracheal cancer | D014134 | Tracheal Neoplasms |
| DOID:1324 | lung cancer | D008175 | Lung Neoplasms |
| DOID:1725 | peritoneum cancer | D010534 | Peritoneal Neoplasms |
| DOID:1781 | thyroid cancer | D013964 | Thyroid Neoplasms |
| DOID:4362 | cervical cancer | D002583 | Uterine Cervical Neoplasms |
| DOID:4481 | allergic rhinitis | D065631 | Rhinitis, Allergic |
| DOID:8398 | osteoarthritis | D010003 | Osteoarthritis |
| DOID:8893 | psoriasis | D011565 | Psoriasis |
| DOID:90 | degenerative disc disease | D055959 | Intervertebral Disc Degeneration |

Comprehensive MeSH cross-references will enable [literature mining through MEDLINE](http://thinklab.com/discussion/mining-knowledge-from-medline-articles-and-their-indexed-mesh-terms/67).","17",2015-05-12,2015-05-12,2,1701,"base.profile","Daniel","Himmelstein","dhimmel"
"443","comments","rephetio","2015-05-12T03:11:16.676Z",17,"# Mistakes in xref resource abbreviations

MedDRA cross-references are inconsistently denoted with `MedDRA` and `MEDDRA`.

The following examples include snippets from the `HumanDO.obo` (revision 2810). Unless otherwise noted, the errors are on the last copied line.

`IDC` should be `ICD` for the International Classification of Diseases (last two lines):
```
[Term]
id: DOID:0060236
name: xanthinuria
def: ""A purine-pyrimidine metabolic disorder characterized by deficiency of xanthine oxidase, resulting in excretion of large amounts of xanthine in the urine and the formation of xanthine stones."" [url:http\://en.wikipedia.org/wiki/Xanthinuria, url:http\://www.ncbi.nlm.nih.gov/pubmed/4369449]
comment: NT MGI.
subset: DO_MGI_slim
synonym: ""xanthine dehydrogenase deficiency"" EXACT []
synonym: ""xanthine oxidase deficiency"" EXACT []
xref: HP:0010934
xref: IDC10CM:E79.8
xref: IDC9CM:277.2
```
`IDC` should be `ICD`:
```
[Term]
id: DOID:0060332
name: mitochondrial complex V (ATP synthase) deficiency nuclear type 3
def: ""A mitochondrial metabolism disease that has material basis in mutation in the ATP5E gene on chromosome 20q13."" [url:http\://omim.org/entry/614053]
subset: DO_MGI_slim
synonym: ""MC5DN3"" EXACT []
xref: IDC10CM:E88.8
```
`IDC` should be `ICD`:
```
[Term]
id: DOID:5212
name: congenital disorder of glycosylation
def: ""A carbohydrate metabolic disorder that involves deficient or defective glycosylation of a variety of tissue proteins and/or lipids."" [url:http\://en.wikipedia.org/wiki/Congenital_disorder_of_glycosylation]
comment: Xref MGI.
subset: DO_MGI_slim
synonym: ""carbohydrate-deficient glycoprotein syndrome"" EXACT []
xref: ICD10CM:77.8
xref: IDC9CM:271.8
```
`UML_CUI` should be `UMLS_CUI` for the Unified Medical Language System:
```
[Term]
id: DOID:0060313
name: tracheomalacia
def: ""A tracheal disease characterized by flaccidity of the tracheal support cartilage."" [url:http\://en.wikipedia.org/wiki/Tracheomalacia]
comment: PRISM.
synonym: ""congenital tracheomalacia"" EXACT []
xref: HP:0002779
xref: ICD10CM:Q32.0
xref: MSH:C557675
xref: NCI:C98634
xref: ORDO:95430
xref: UML_CUI:C0392109
```
`UMLS` should be `UMLS_CUI` for consistency:
```
[Term]
id: DOID:0060217
name: Cogan-Reese syndrome
def: ""A rare eye disease characterized by variable iris atrophy, pigmented and pedunculated nodules located_in iris and attachment of the iris to the cornea (peripheral anterior synechiae) and characterized_by glaucoma."" [url:http\://en.wikipedia.org/wiki/Iridocorneal_endothelial_syndrome, url:http\://rarediseases.info.nih.gov/gard/6125/cogan-reese-syndrome/resources/1]
xref: ICD10CM:H21.1
xref: MEDDRA:10059200
xref: ORDO:98980
xref: UMLS:C1168173
```","17",2015-05-12,2015-05-12,2,2753,"base.profile","Daniel","Himmelstein","dhimmel"
"444","comments","rephetio","2015-05-12T03:37:08.730Z",17,"# UMLS cross-reference additions

Of our 137 DO slim terms, 6 did not contain a UMLS (`UMLS_CUI`) xref. We manually mapped 5 of these terms ([tsv download](https://raw.githubusercontent.com/dhimmel/disease-ontology/9fd75f14b17e01bebc97faf1bfa1b9025e9ce4de/requests/DO-slim-to-umls.tsv)):

| doid_code | doid_name | umls_cui | umls_name |
|--------------|-------------------------------|----------|---------------------------------|
| DOID:0050156 | idiopathic pulmonary fibrosis | C1800706 | Idiopathic Pulmonary Fibrosis |
| DOID:0050425 | restless legs syndrome | C0035258 | Restless Legs Syndrome |
| DOID:0050741 | alcohol dependence | C0001973 | Alcoholic Intoxication, Chronic |
| DOID:0050742 | nicotine dependence | C0028043 | Nicotine Dependence |
| DOID:0060119 | pharynx cancer | C0031347 | Pharyngeal Neoplasms |","17",2015-05-12,2015-05-12,2,834,"base.profile","Daniel","Himmelstein","dhimmel"
"445","comments","rephetio","2015-05-13T19:51:58.974Z",17,"# *Proof of concept* implementation

We implemented a topic cooccurrence calculator based on MEDLINE and used this method to identify **disease-symptom relationships** ([notebook](//nbviewer.ipython.org/github/dhimmel/medline/blob/61590a7007d282429694e52a3a6743af99c1ab12/symptoms.ipynb), [API query script](https://github.com/dhimmel/medline/blob/61590a7007d282429694e52a3a6743af99c1ab12/eutility.py), [tsv of results](https://raw.githubusercontent.com/dhimmel/medline/gh-pages/data/disease-symptom-cooccurrence.tsv)).

First we created a **disease set** of 119 MeSH terms that mapped to DO slim diseases ([tsv of diseases](https://github.com/dhimmel/medline/blob/61590a7007d282429694e52a3a6743af99c1ab12/data/DO-slim-to-mesh.tsv)). Next, we created a **symptom set** of 438 MeSH terms by finding all descendants of `D012816` (Signs and Symptoms) ([notebook](//nbviewer.ipython.org/github/dhimmel/mesh/blob/e561301360e6de2140dedeaa7c7e17ce4714eb7f/mesh.ipynb), [tsv of symptoms](https://github.com/dhimmel/mesh/blob/e561301360e6de2140dedeaa7c7e17ce4714eb7f/data/symptoms.tsv)).

For each disease, we identified the articles where that disease was a major topic. For each symptom, we identified the articles where that symptom was a topic. We then identified the articles that contained both a disease major topic and symptom topic. We based further analysis only on these 392,397 articles that contain at least one disease--symptom cooccurrence.

For each symptom--disease pair, we calculated:

+ `cooccurrence` -- the number of articles where the disease and symptom terms cooccurred.
+ `expected` -- the number of expected cooccurrences by chance based on each term's marginal frequency.
+ `enrichment` -- `cooccurrence` divided by `expected`.
+ `odds_ratio` -- the odds of `cooccurrence` divided by the odds of `expected`. This calculation appears to be slightly messed up due to non-integer expected counts.
+ `p_fisher` -- the p-value from Fisher's exact test evaluating whether the observed cooccurrence exceeded that expected by chance.

@apankov, can you comment on the Fisher's exact test and whether there is a superior way to identify terms that significantly cooccur?

@b_good or others: do you know of better metrics for literature mining? One issue is that our approach may miss common symptoms that are not greatly enriched for any particular disease. The HSDN study [@10.1038/ncomms5212] used a TF-IDF measure, but [we require](//thinklab.com/discussion/human-symptom-disease-network-mesh-id-matching/52#167) metrics that are comparable across diseases.","17",2015-05-13,2015-05-13,2,2588,"base.profile","Daniel","Himmelstein","dhimmel"
"446","comments","rephetio","2015-05-13T23:39:44.558Z",84,"I think the Fisher's exact test will be accepted well by reviewers, but Barnard's test could be a good alternative. Otherwise, if you can calculate a p-value based on permutation (or get a bootstrapped estimates for the variance of the number of expected cooccurrences) , that could be an easy, straightforward approach.

","84",2015-05-13,2015-05-13,2,324,"base.profile","Alex","Pankov","apankov"
"447","comments","rephetio","2015-05-15T22:54:27.488Z",17,"Thanks @apankov. I couldn't find a python implementation of [Barnard's test](https://en.wikipedia.org/wiki/Barnard%27s_test) [@10.1038/156177a0 @10.1093/biomet/34.1-2.123], so I think we'll stick with [Fisher's exact test](https://en.wikipedia.org/wiki/Fisher%27s_exact_test) [@10.2307/2340521] for simplicity. The fidelity of *p*-values is not a major concern here.

However, it has occurred to me that in our above post, we incorrectly created the contingency table for the exact test. We now [construct it](https://github.com/dhimmel/medline/blob/a3e35d7dd58fb64f4043247e661259c743dce7d5/cooccurrence.py#L44) similarly to [Table 1 of this paper](https://dx.doi.org/10.1016/j.jbi.2006.11.003#tbl1) [@10.1016/j.jbi.2006.11.003] so that the contingency table is:

$$$
\begin{bmatrix}
a & b\\
c & d
\end{bmatrix}
$$$

where

+ *a* is the number of studies with both the disease and the symptom (`cooccurrence`)
+ *b* is the number of studies with the disease and without the symptom
+ *c* is the number of studies without the disease and with the symptom
+ *d* is the number of studies without either the disease or symptom

The revised symptom--disease pair tsv file is [available here](https://raw.githubusercontent.com/dhimmel/medline/a3e35d7dd58fb64f4043247e661259c743dce7d5/data/disease-symptom-cooccurrence.tsv).","17",2015-05-15,2015-05-15,2,1335,"base.profile","Daniel","Himmelstein","dhimmel"
"448","comments","rephetio","2015-05-19T02:56:31.081Z",17,"We have calculated molecular (aka chemical/structural) similarities between DrugBank compounds. First, we retrieved the compound structures as an SDF file from the [download page](http://www.drugbank.ca/downloads#structures). Then we calculated extended connectivity fingerprints for each compound using the Morgan/circular method [@10.1021/ci100050t]. We chose a radius of 2, since ""Typically, two iterations is sufficient for fingerprints that will be used for similarity or clustering. [@10.1021/ci100050t]"" Finally, we computed all pairwise similarities [using] (http://www.rdkit.org/Python_Docs/rdkit.DataStructs.cDataStructs-module.html#DiceSimilarity) the [Dice coefficient](https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient) [@10.2307/1932409].

The similarities for the subset of DrugBank compounds included in our network is [available here](https://github.com/dhimmel/drugbank/blob/55587651ee9417e4621707dac559d84c984cf5fa/data/similarity-slim.tsv.gz). We posted the full set of similarities (for all DrugBank compounds with structures) on [figshare](https://dx.doi.org/10.6084/m9.figshare.1418386) [@10.6084/m9.figshare.1418386].

See the [notebook of the analysis](http://nbviewer.ipython.org/github/dhimmel/drugbank/blob/9eb1e15ada5e6579e5aea1cae784c10602037b05/similarity.ipynb) for more details.","17",2015-05-19,2015-05-19,2,1334,"base.profile","Daniel","Himmelstein","dhimmel"
"449","comments","rephetio","2015-05-20T11:23:17.925Z",17,"I came across the following paper that has useful information regarding the LINCS data integration standards:

> Metadata Standard and Data Exchange Specifications to Describe, Model, and Integrate Complex and Diverse High-Throughput Screening Data from the Library of Integrated Network-based Cellular Signatures (LINCS). [@10.1177/1087057114522514]","17",2015-05-20,2015-05-20,2,352,"base.profile","Daniel","Himmelstein","dhimmel"
"450","comments","rephetio","2015-05-21T03:35:08.975Z",17,"# Anatomy--Disease Relationships

The Uberon ontology [@10.1186/gb-2012-13-1-r5] of anatomical structures includes MeSH [cross-references](https://github.com/dhimmel/uberon/blob/0c50839eb3e58a89e81018978f269210d2212d58/data/mesh-map.tsv). Thus, we performed our MEDLINE cooccurrence analysis described above to find relationships between diseases and anatomical structures ([notebook](http://nbviewer.ipython.org/github/dhimmel/medline/blob/ef0aef8b9c4bfcaa4cf46f03efe6d0ea0dc5d13b/tissues.ipynb), [tsv download](https://raw.githubusercontent.com/dhimmel/medline/ef0aef8b9c4bfcaa4cf46f03efe6d0ea0dc5d13b/data/disease-uberon-cooccurrence.tsv)).

The ability of this method to capture disease localization was exceptional. For example, the top five terms by *p*-value for multiple sclerosis were:

| mesh_name | cooccurrence | expected | enrichment | odds_ratio | p_fisher |
|------------------------|--------------|----------|------------|------------|----------|
| Central Nervous System | 881 | 38.6 | 22.8 | 34.3 | 0.000 |
| Spinal Cord | 1492 | 80.8 | 18.5 | 27.5 | 0.000 |
| Myelin Sheath | 1006 | 19.9 | 50.5 | 146.8 | 0.000 |
| Brain | 4777 | 778.3 | 6.1 | 11.5 | 0.000 |
| Optic Nerve | 372 | 36.5 | 10.2 | 11.9 | 0.000 |

One improvement would be to exclude Uberon terms that don't exist in humans such as venom (`UBERON:0007113`). Additionally, there are some [Uberon--MeSH mapping issues](https://github.com/obophenotype/uberon/issues/698#issuecomment-104079963) that should get resolved soon allowing us to update the analysis.","17",2015-05-21,2015-05-21,2,1552,"base.profile","Daniel","Himmelstein","dhimmel"
"451","comments","rephetio","2015-05-21T03:46:33.583Z",17,"Hi @vsmalladi, we have proceeded with Uberon and incorporated the MeSH cross-references. Specifically, we [identified](http://thinklab.com/d/67#229) disease--anatomy localization using literature mining.

We would like a way to restrict terms to structures in humans. Does anyone know how to implement a species filter?

We would also like to incorporate the Cell Ontology (CL) for cell information [@10.1186/gb-2005-6-2-r21]. However, there is a [MeSH xref issue](https://code.google.com/p/cell-ontology/issues/detail?id=146#c2) that will need to be remedied first.","17",2015-05-21,2015-05-21,2,570,"base.profile","Daniel","Himmelstein","dhimmel"
"452","comments","rephetio","2015-05-21T05:04:41.405Z",17,"# Combining z-scores across multiple signatures

To create consensus signatures for a compound, we have been taking a weighted average of z-scores (steps 4--5 [above](#3)). It has occurred to us that this is an underpowered method, just as averaging p-values is a weak method of meta-analysis. 

Instead we can use [Stouffer's method](https://en.wikipedia.org/wiki/Fisher%27s_method#Relation_to_Stouffer.27s_Z-score_method) to meta-analyze z-scores [@stouffer]. This method accepts weights (calculated in steps 2--3 [above](#3)). The formula is below for weight vector *w* and z-score vector *Z*:

$$$
Z \sim \frac{\sum_{i=1}^k w_iZ_i}{\sqrt{\sum_{i=1}^k w_i^2}}
$$$

[@stouffer]: http://press.princeton.edu/titles/2692.html ""Stouffer SA, Suchman EA, DeVinney LC, Star SA, Williams RM. (1949) *The American Soldier, Vol.1: Adjustment during Army Life*. Princeton University Press""","17",2015-05-21,2015-05-21,2,890,"base.profile","Daniel","Himmelstein","dhimmel"
"453","comments","rephetio","2015-05-22T05:05:57.647Z",35,"@dhimmel You can restrict structures by NCBI taxon ID Human would be Taxon:9606

Can you elaborate on the MeSH issue? I might be able to help. ","35",2015-05-22,2015-05-22,2,145,"base.profile","Venkat","Malladi","vsmalladi"
"454","comments","rephetio","2015-05-22T21:39:45.073Z",35,"@dhimmel To understand what relationships you should compute closure on I recommend reading http://geneontology.org/page/ontology-relations

I would add ```part_of```` and maybe ```has_part``` first before exploring the other relationships. 

Another option for reasoning that can take advantage of the relationships is https://github.com/owlcollab/owltools","35",2015-05-22,2015-05-22,2,361,"base.profile","Venkat","Malladi","vsmalladi"
"455","comments","rephetio","2015-05-23T21:52:32.772Z",17,"# Restricting to human terms

@vsmalladi, thanks for the pointer. In the [obo](//berkeleybop.org/ontologies/uberon/ext.obo) header I see:
```
treat-xrefs-as-reverse-genus-differentia: DHBA part_of NCBITaxon:9606
treat-xrefs-as-reverse-genus-differentia: EHDAA2 part_of NCBITaxon:9606
treat-xrefs-as-reverse-genus-differentia: FMA part_of NCBITaxon:9606
treat-xrefs-as-reverse-genus-differentia: HBA part_of NCBITaxon:9606
treat-xrefs-as-reverse-genus-differentia: HsapDv part_of NCBITaxon:9606
```
Therefore I speculate the best way to identify human applicable terms would be to identify all terms with a cross-reference to the above resources and all broader terms in the hierarchy. Is that what you suggest?","17",2015-05-23,2015-05-23,2,720,"base.profile","Daniel","Himmelstein","dhimmel"
"456","comments","rephetio","2015-05-26T21:20:05.133Z",35,"@dhimmel 

Actually what you want to do is for each term filter on ```present_in_taxon```:

   property_value: present_in_taxon NCBITaxon:7777

","35",2015-05-26,2015-05-26,2,150,"base.profile","Venkat","Malladi","vsmalladi"
"457","comments","rephetio","2015-05-27T14:26:51.387Z",77,"Our validation manuscript has been published, @dhimmel: http://aci.schattauer.de/en/contents/current-issue/issue/special/manuscript/24377/show.html

I'll see what I can do about sharing the data, but unfortunately I've got travel coming up along with several deadlines, so it may be a little while longer before I'm able to do that.","77",2015-05-27,2015-05-27,2,334,"base.profile","Allison","McCoy","allisonmccoy"
"458","comments","rephetio","2015-06-02T18:51:21.520Z",17,"@vsmalladi, [the obo](http://berkeleybop.org/ontologies/uberon/ext.obo) only contains `relationship: present_in_taxon NCBITaxon:9606` for four terms. Is there a more extensive listing of `present_in_taxon` relationships that you are aware of?

Meanwhile the [results](https://github.com/dhimmel/uberon/blob/50c311f3d15744e8c559ea76178bdd7542f6d16b/data/mesh-map.tsv) of the `treat-xrefs-as-reverse-genus-differentia` method look satisfactory. Terms were annotated as human (`in_human = 1`) if they or any terms they subsumed (along `is_a`, `part_of`, and `develops_from` relationships) contained a cross-reference to any of the following resources: `DHBA`, `EHDAA2`, `FMA`, `HBA`, and `HsapDv` ([notebook](https://github.com/dhimmel/uberon/blob/50c311f3d15744e8c559ea76178bdd7542f6d16b/mesh-map.ipynb)). Most terms where `in_human = 0` are not appropriate for humans.


","17",2015-06-02,2015-06-02,2,875,"base.profile","Daniel","Himmelstein","dhimmel"
"459","comments","rephetio","2015-06-07T23:11:43.668Z",17,"@caseygreene, thanks for the description of your database setup. In the immediate term, I don't need any of the advanced features that your design accommodates such as elastic search and efficient lookup, so I just did a simple [parsing](//nbviewer.ipython.org/github/dhimmel/entrez-gene/blob/2208158e9e9691d54d48faf3b6b9c2c8f69d7914/retrieve.ipynb) of the human subset and exported three tsv files ([genes](https://github.com/dhimmel/entrez-gene/blob/2208158e9e9691d54d48faf3b6b9c2c8f69d7914/data/genes-human.tsv), [symbols](https://github.com/dhimmel/entrez-gene/blob/2208158e9e9691d54d48faf3b6b9c2c8f69d7914/data/symbols-human.tsv), [cross-references](https://github.com/dhimmel/entrez-gene/blob/2208158e9e9691d54d48faf3b6b9c2c8f69d7914/data/xrefs-human.tsv)).

Therefore, don't reprioritize for me, but I think the pypi package is a great idea. It looks like your [Tribe](//tribe.greenelab.com/) API already supports Entrez gene lookup. However, I'm confused about the usage, since the [demo code](//tribe.greenelab.com/#/demo/speak) is equivalent to:

```python
import requests
payload = {'show_tip': 'true'}
response = requests.get('http://tribe.greenelab.com/api/v1/geneset/', params=payload)
```

How do you specify the query string (the gene symbol/name for which you want the GeneID)? It may be the case that your API already provides most of the functionality a user may need. In that case, a local Entrez Gene database may not be needed at all.

Summary: my vote is for a powerful, well-documented API as a primary resource, with an open source codebase.","17",2015-06-07,2015-06-07,2,1578,"base.profile","Daniel","Himmelstein","dhimmel"
"460","comments","rephetio","2015-06-08T18:54:53.853Z",17,"## Background

GWAS uncover disease-associated loci, but due to sparse genotyping arrays and linkage disequilibrium (LD), identifying the specific SNP driving the association is difficult. Therefore, GWAS usually report the most significant hit as the single lead SNP for a loci, leaving the identification of a causal SNP for later research. Often multiple GWAS of the same disease will identify different lead SNPs in the same region, presumable all tagging the same causal variant. Therefore, around any lead SNP is a *region of indetermination*---a genomic window in which the SNP driving the association is likely to reside.

## Application

When extracting disease-gene associations from the [GWAS Catalog](//www.ebi.ac.uk/gwas/) [@10.1093/nar/gkt1229], we collapse multiple associations for the same disease into loci (regions) [@10.1371/journal.pcbi.1004259]. Starting with lead SNPs for each association, we find the corresponding windows and overlap them into genomically disjoint sets.

Previously, we retrieved windows for GWAS lead-SNPs from the [DAPPLE](https://www.broadinstitute.org/mpg/dapple/dappleTMP.php) [@10.1371/journal.pgen.1001273] wingspan files. DAPPLE windows ""were calculated for each lead-SNP by finding the furthest upstream and downstream SNPs where $$r^2 > 0.5$$ and extending outwards to the next recombination hotspot [@10.1371/journal.pcbi.1004259].""

However, DAPPLE relied on HapMap [@10.1038/nature04226] for LD data, which is now outdated. Many SNPs in the GWAS catalog are not in HapMap. Since HapMap is missing many SNPs, extending to the next recombination hotspot was necessary.

# Questions

1. **Given a lead SNP, how should we identify the furthest upstream and downstream SNPs with $$r^2$$ exceeding a given threshold?** Which data and tools should we use?
2. In the context of GWAS loci, is $$r^2 > 0.5$$ too low of a threshold for windows?
3. Is the recombination hotspot extension necessary?

We would like to identify windows for ~5000 SNPs which are identified in dbSNP build 142 rsids.","17",2015-06-08,2015-06-08,2,2057,"base.profile","Daniel","Himmelstein","dhimmel"
"461","comments","rephetio","2015-06-08T20:58:12.464Z",103,"I would suggest using 1000 genomes for the LD calculation here with a more stringent r^2 cutoff (maybe 0.8?). Some LD information is available through their browser

http://browser.1000genomes.org/Homo_sapiens/Location/Genome?db=core;r=2:31451742-31452000

Here is a thread discussing similar ideas:
https://www.biostars.org/p/2909/

The other resource of interest is the ExAC dataset: http://exac.broadinstitute.org/ I don't think the LD data is available, but it's worthwhile reaching out to them!","103",2015-06-08,2015-06-08,2,506,"base.profile","Marina","Sirota","marinasirota"
"462","comments","rephetio","2015-06-09T00:52:06.974Z",104,"For identifier mapping, you might want to check out [BridgeDb](http://bridgedb.org/), which provides both mapping databases and libraries to add identifier mapping functionality to any project. It's 100% free and [open source](https://github.com/bridgedb/BridgeDb).

There are many ways to integrate BridgeDb into your own tool or resource. The easiest is simply to make web service calls, like:

http://webservice.bridgedb.org/Human/xrefs/H/CCR5
(for all mappings connected to HGNC ""CCR5""), or

http://webservice.bridgedb.org/Human/xrefs/H/CCR5?dataSource=Entrez%20Gene
(to only retrieve the Entrez Gene for ""CCR5"")

Here are some docs for additional web service syntax: http://bridgedb.org/wiki/BridgeWebservice

If performance is an issue, e.g., you want to query 10,000 times a day, then you can install the databases locally and implement the libs provided by the project into your tool and have complete control over database versions, etc.","104",2015-06-09,2015-06-09,2,958,"base.profile","Alexander","Pico","alexanderpico"
"463","comments","rephetio","2015-06-09T01:15:52.903Z",104,"For Table 1, you might consider adding another Gene Set resource based on curated pathways.  These are analogous to GO-Biological Process terms, but are much more focused and constrained. In fact, they also include small molecules and drugs, so they can serve as more than just *gene* sets.

Likewise, for Table 2, you could add a number of interaction resources with pathway data.  As co-founder of [WikiPathways](http://wikipathways.org), I have to recommend that one in particular! :)  It's 100% free, open source and open access.  I can also recommend [Reactome](http://www.reactome.org) and [Pathway Commons](http://www.pathwaycommons.org/), the latter of which compiles pathway data from multiple sources into BioPAX data format.

Again, these would not only provide high-quality gene-gene interactions for your network, but also direct drug-gene interactions. And in relation to your Figure 1, they would also provide Disease and Tissue associations.

You can download all human pathways from WikiPathways [in multiple formats](http://wikipathways.org/index.php/Download_Pathways), or parse just the Entrez Genes in Human pathways from [this single dump file](http://www.pathvisio.org/data/bots/gmt/wikipathways.gmt). The advantage to the first option are that you are getting the original data, as curated by contributors; the disadvantage is that you have to perform the ID mapping to unify to Entrez and your preferred small molecule system. The advantage of the second option (the dump file) is that the Entrez ID unification has been done for you; the disadvantage is that anything that didn't map to Entrez is simply discarded (including drugs and small molecules!).
","104",2015-06-09,2015-06-09,2,1687,"base.profile","Alexander","Pico","alexanderpico"
"464","comments","rephetio","2015-06-10T18:22:49.540Z",17,"@alexanderpico, thanks for letting us know about the best current pathway resources.

## MSigDB Canonical Pathways

In the past, we used the versions of [Reactome](http://www.reactome.org/), [KEGG](http://www.genome.jp/kegg/pathway.html), and [BioCarta](http://www.biocarta.com/) provided by MSigDB [@10.1073/pnas.0506580102 @10.1093/bioinformatics/btr260]. MSigDB version 5.0 was [released in April](https://www.broadinstitute.org/cancer/software/gsea/wiki/index.php/MSigDB_v5.0_Release_Notes), but it's unclear whether the pathway resources were updated. However, the ""C2: Canonical Pathways"" (CP) collection [integrates 9](https://www.broadinstitute.org/gsea/msigdb/collection_details.jsp#CP) pathway resources, so I think we should create a *C2: CP* metanode with a node for each MSigDB CP gene set.

## WikiPathways

We can have a separate metanode for [WikiPathways](//www.wikipathways.org/) [@10.1371/journal.pbio.0060184 @10.1093/nar/gkr1074]. The open and crowdsourced nature of WikiPathways is ideal. The inclusion of compounds, tissues, diseases in addition to genes in these pathways could provide a major performance boost for our method. The benefit will depends on how frequently non-gene entities are included in these pathways. What percent of pathways include diseases, tissues, or drugs? Additionally, are non-gene entities identified as free text, or are they structured by a standardized vocabulary?

## Pathway Commons

I like how Pathway Commons [@10.1093/nar/gkq1039] brings a common format to [many resources](http://www.pathwaycommons.org/pc2/datasources). One worry is that Pathway Commons contains edges, such as those from DrugBank, which will be included elsewhere in the network. One solution would be to [pick and chose](http://www.pathwaycommons.org/pc2/downloads) which source databases to integrate from Pathway Commons. After including *MSigDB C2: CP* and *WikiPathways*, will Pathway Commons contain much information not already captured? If not, we may just stick with the above resources.

## General Questions

1. How much do these pathway resources overlap? Does WikiPathways include pathways directly taken from other databases?
+ Do databases differ greatly in quality or type of pathways encoded? If the databases do differ, it may make sense to give each a separate metanode. Otherwise, we will organize all pathways by 1 or 2 metanodes.","17",2015-06-10,2015-06-10,2,2399,"base.profile","Daniel","Himmelstein","dhimmel"
"465","comments","rephetio","2015-06-10T18:47:13.538Z",17,"@alexanderpico, thanks for the BridgeDB suggestion. It looks like [several transcript/gene/protein resources](http://webservice.bridgedb.org/Human/targetDataSources) are integrated including HGNC, Entrez Gene, Affy, Illumina, WikiGenes, UniGene, UCSC Genome Browser, Uniprot, RefSeq, miRBase, and Ensembl. That's great -- we may or may not need these mappings at this point.

One worry I have is that the resource is outdated. The build date for human gene products is 2013-07-01. However, on 2014-11-21 version 2.0.0 was released. Does this mean the database was also rebuilt? In either case, I would like more frequent updates. Do you know the status of the project and whether it is actively maintained?

One final note is that @caseygreene's Tribe service allows free-text gene lookup, through elasticsearch. Currently, we do not need this feature. However, perhaps @alexanderpico Pathways4Life project [@10.15363/thinklab.8] does. Also, perhaps [Tribe](http://tribe.greenelab.com/#/home)---a gene set wiki with a private option---would like to autopopulate [WikiPathways](//www.wikipathways.org/index.php/WikiPathways).","17",2015-06-10,2015-06-10,2,1128,"base.profile","Daniel","Himmelstein","dhimmel"
"466","comments","rephetio","2015-06-10T19:08:23.025Z",104,"Right. The database build system was recently updated from using Ensembl's Perl API to using BioMart. This will allow frequent updates; probably quarterly.","104",2015-06-10,2015-06-10,2,155,"base.profile","Alexander","Pico","alexanderpico"
"467","comments","rephetio","2015-06-10T19:12:41.943Z",104,"Figures 1 and 2 in [the Pathways4Life proposal](http://thinklab.com/p/pathways4life) will answer questions about overlap and frequency of updates.  Pathway Commons is not a primary source; their focus is on compiling from as many sources as possible. So, given their restriction to BioPAX, they definitely include more than any single resource.","104",2015-06-10,2015-06-10,2,344,"base.profile","Alexander","Pico","alexanderpico"
"468","comments","rephetio","2015-06-11T00:29:13.219Z",17,"@alexanderpico, thanks figures 1 and 2 do help, however I am more interested in [edge-based measures of overlap](http://thinklab.com/discussion/pathway-novelty-based-on-unique-relationships-rather-than-genes/75). Do you have a general sense of whether the same pathways are represented in multiple databases?

My interpretation of Figure 1 is that it provides a lower bound of uniqueness. The fact that there are many genes unique in KEGG, Reactome, and WikiPathways warrants the inclusion of all three resources. However, it doesn't answer whether the common genes are from duplicated pathways or not.","17",2015-06-11,2015-06-11,2,604,"base.profile","Daniel","Himmelstein","dhimmel"
"469","comments","rephetio","2015-06-11T22:14:15.659Z",17,"@marinasirota, thanks for the advice.

The [SNAP Proxy Search](https://www.broadinstitute.org/mpg/snap/ldsearch.php) [@10.1093/bioinformatics/btn564] allows us to find all SNPs within 500kb and with LD above a provided threshold for the query SNP, using 1000 Genomes (KG) pilot data.

One issue with KG is that the whole-genome sequencing was done at low depth (4x coverage) and that only 179 samples were sequenced: 60 CEU, 59 YRI, 30 CHB, and 30 JPT [@10.1038/nature09534]. Therefore many low frequency or technically difficult variants were likely missed. Since GWAS have mostly focused on common variants, the puniness of 1000 Genomes pilot data may be acceptable.

We went ahead and evaluated the SNAP LD information from KG for our GWAS lead SNPs. For each lead SNP, we found all SNPs in $$r^2 \geq 0.8$$ in the European subset of 60 individuals. The [findings are as follows](https://github.com/dhimmel/gwas-catalog/blob/568e063010d725c335a019ac20c2d023d000f5d4/windows.ipynb):

+ Of 5,255 GWAS lead SNPs, 517 were not found by SNAP
+ SNPs with lower minor allele frequencies were more likely to have large windows (kilobase spans). We speculate this results from greater noise in $$r^2$$ values when the number of minor alleles is low, enabling far away SNPs to appear in high LD by chance. 
+ 614 lead SNPs have a zero-length span -- no SNPs were found with LD exceeding the threshold. Most likely this is due to the incompleteness of KG.
+ Window spans measured in kilobases are highly, positively correlated with spans measured in centimorgans. Therefore, we cannot chose a single centimorgan threshold to approximate windows calculated using the $$r^2$$ method.

In conclusion, the KG data retrieved from SNAP is feasible but not ideal. We will look into larger datasets and have [reached out to the ExAC team](https://github.com/konradjk/exac_browser/issues/189).","17",2015-06-11,2015-06-11,2,1889,"base.profile","Daniel","Himmelstein","dhimmel"
"470","comments","rephetio","2015-06-12T02:05:40.666Z",104,"That measure of overlap is fraught with caveats relating to exactly how edges are modeled. When each of the three resource mentioned here converts to a single exchange format, like BioPAX, for example, we each make a unique set of mapping decisions and compromises. Nevertheless, you're absolutely right that node overlap is a lower bound, but I don't have a good estimate for edge overlap. Just browsing the pathway titles is the most convincing way to see that we cover much of the same ground: metabolism, signaling and gene regulation.","104",2015-06-12,2015-06-12,2,539,"base.profile","Alexander","Pico","alexanderpico"
"471","comments","rephetio","2015-06-12T18:15:23.590Z",17,"# Permissive $$r^2$$ threshold when relying on low-powered LD data

@marinasirota, I intuitively agree that for the modern GWAS assaying and imputing millions of SNPs, lead SNPs are likely be in $$r^2 \geq 0.8$$ with the SNPs driving the association. However, when using the 1000 Genomes Pilot data for LD, I think we should use a more permissive threshold of $$r^2 \geq 0.5$$. The 0.8 threshold produces [614](https://github.com/dhimmel/gwas-catalog/blob/568e063010d725c335a019ac20c2d023d000f5d4/windows.ipynb) windows with zero-length spans compared to [149](https://github.com/dhimmel/gwas-catalog/blob/cbc30cbe88bda38c7ebe9c32802b051436431065/windows.ipynb) for the 0.5 threshold. Zero-length spans are equivalent to declaring that the lead SNP is the only SNP capable of creating the association. I would prefer to minimize these instances when we have such incomplete LD information.","17",2015-06-12,2015-06-12,2,891,"base.profile","Daniel","Himmelstein","dhimmel"
"472","comments","rephetio","2015-06-12T20:00:07.588Z",103,"@dhimmel - that makes sense.  ","103",2015-06-12,2015-06-12,2,30,"base.profile","Marina","Sirota","marinasirota"
"473","comments","rephetio","2015-06-16T18:28:41.237Z",107,"We recently worked on a (mini-)study to investigate the relationship between the ERC values of gene-pairs and the extent to which they share their interacting partners. The Jaccard coefficient was used to quantify the extent to which genes share interacting partners (higher the Jaccard, more the fraction of interacting partners shared). We used the yeast ERC dataset, and interestingly found that there is a weak, but significant positive correlation between ERC values of gene pairs and Jaccard coefficient (JC) of the interacting partners of the two genes. We additionally saw that using JC in conjunction with ERC has potential to reduce the number of false discoveries in interaction prediction. I could attach the full report of our investigation if it interests you.

I think it would be interesting to refine the approach further, and apply the same in the human context as well - it may very well turn out to be more powerful than thresholding based on ERC values.","107",2015-06-16,2015-06-16,2,976,"base.profile","Raghavendran","Partha","raghavpartha"
"474","comments","rephetio","2015-06-16T18:47:14.342Z",17,"The protein interaction project sounds interesting. Have you considered using a random walk with restart on the protein interaction network for PPI-similarity? I think you will find it preferable to the Jaccard coefficient, since it considers more than just first degree neighbors. I have some python code for the random walk that I can open source, if you can't find an implementation. What protein interaction network are you using? I think a systematic PPI network (that isn't ridden with knowledge bias) would be especially interesting. I suggest the HI-II-14 network from [here](http://interactome.dfci.harvard.edu/H_sapiens/index.php?page=download).

In terms of this project, we would like to keep the ERC edges independent of the PPI edges. The ERC values are attractive to us as a completely orthogonal resource to the protein interactions.","17",2015-06-16,2015-06-16,2,851,"base.profile","Daniel","Himmelstein","dhimmel"
"475","comments","rephetio","2015-06-16T20:43:50.492Z",17,"The [GWAS Catalog](https://www.ebi.ac.uk/gwas/) [@10.1093/nar/gkt1229] compiles SNP associations from published genome-wide studies. We converted the catalog from SNP associations to gene associations. We classify each gene association as high or low confidence and as primary or secondary (based on whether the gene is assumed to drive the signal at a loci).

We only extracted associations for diseases in [DO Slim](http://thinklab.com/discussion/unifying-disease-vocabularies/44#144), which should cover most diseases in the catalog while excluding traits. Genes are restricted to protein-coding.

## External resources

+ [**compiled gene associations**](https://github.com/dhimmel/gwas-catalog/blob/0617ea7ea8268f21f5ca1b8dbe487dd12671fc7b/data/gene-associations.tsv)
+ summary files with [associations per disease](https://github.com/dhimmel/gwas-catalog/blob/0617ea7ea8268f21f5ca1b8dbe487dd12671fc7b/data/diseases.tsv) and [associations per gene](https://github.com/dhimmel/gwas-catalog/blob/0617ea7ea8268f21f5ca1b8dbe487dd12671fc7b/data/genes.tsv)
+ [compiled SNP associations](https://github.com/dhimmel/gwas-catalog/blob/0617ea7ea8268f21f5ca1b8dbe487dd12671fc7b/data/snp-associations.tsv) -- a processed subset of the GWAS Catalog
+ [notebook](https://github.com/dhimmel/gwas-catalog/blob/0617ea7ea8268f21f5ca1b8dbe487dd12671fc7b/loci.ipynb) for processing loci
+ [discussion](http://thinklab.com/discussion/calculating-genomic-windows-for-gwas-lead-snps/71) and [notebook](https://github.com/dhimmel/gwas-catalog/blob/0617ea7ea8268f21f5ca1b8dbe487dd12671fc7b/windows.ipynb) for calculating lead-SNP windows

## Method

The method for processing associations was taken from our previous work [@10.1371/journal.pcbi.1004259], which describes it as follows (modifications afterwards):

> Disease-gene associations were extracted from the GWAS Catalog [@10.1093/nar/gkt1229], a compilation of GWAS associations where $$p < 10^{−5}$$. First, associations were segregated by disease. GWAS Catalog phenotypes were converted to Experimental Factor Ontology (EFO) terms using mappings produced by the European Bioinformatics Institute. Associations mapping to multiple EFO terms were excluded to eliminate cross-phenotype studies. We manually mapped EFO to DO terms (now included in the DO as cross-references) and annotated each DO term with its associations.

> Associations were classified as either high or low-confidence, where exceeding two thresholds granted high-confidence status. First, $$p \leq 5 × 10^{-8}$$ corresponding to  $$p \leq 0.05$$ after Bonferroni adjustment for one million comparisons (an approximate upper bound for the number of independent SNPs evaluated by most GWAS). Second, a minimum sample size (counting both cases and controls) of 1,000 was required, since studies below this size are underpowered [@10.1093/brain/awn081]---i.e. any discovered associations are more likely than not to be false---for the majority of true effect size distributions commonly assumed to underlie complex disease etiology [@10.1038/nrg2615].

> Lead-SNPs were assigned windows—regions wherein the causal SNPs are assumed to lie—retrieved from the DAPPLE server [@10.1371/journal.pgen.1001273]. Windows were calculated for each lead-SNP by finding the furthest upstream and downstream SNPs where $$r^2 > 0.5$$ and extending outwards to the next recombination hotspot. Associations were ordered by confidence, sorting on following criteria: high/low confidence, p-value (low to high), and recency. In order of confidence, associations were overlapped by their windows into disease-specific loci. By organizing associations into loci, associations from multiple studies tagging the same underlying signal were condensed. A locus was classified as high-confidence if any of its composite associations were high-confidence and low-confidence otherwise.

> For each disease-specific loci, we attempted to identify a primary gene. The primary gene was resolved in the following order:
>
1. the mode author-reported gene
2. the containing gene for an intragenic lead-SNP
3. the mode author-reported gene for an intragenic lead-SNP (in the case of overlapping genes)
4. the mode author-reported gene of the most proximal up and downstream genes.

> Steps 2–4 were repeated on each association composing the loci, in order of confidence, until a single gene resolved as primary. Loci where ambiguity was unresolvable or where no genes were returned did not receive a primary gene. All non-primary genes—genes that were author-reported, overlapping the lead-SNP, or immediately up or downstream from the lead-SNP—were considered secondary.

> Accordingly, four categories of processed associations were created: high-confidence primary, high-confidence secondary, low-confidence primary, and low-confidence secondary. We assume that our primary gene annotation for each loci represents the single causal gene responsible for the association.

## Method modifications

We [switched](http://thinklab.com/discussion/calculating-genomic-windows-for-gwas-lead-snps/71) from HapMap LD data provided by DAPPLE to 1000 Genomes LD data provided by SNAP and removed the recombination hotspot extensions. ","17",2015-06-16,2015-06-16,2,5234,"base.profile","Daniel","Himmelstein","dhimmel"
"476","comments","rephetio","2015-06-17T18:56:26.669Z",17,"We would to know the expression level of each gene in as many tissues and cell types as possible. Humans only for now. What are the best resources and methods to go about this?

Here are some relevant resources we compiled (in order of preference):

1. The Genotype-Tissue Expression project ([GTEx](http://www.gtexportal.org/home/)) [@10.1126/science.aaa0355]
+ Baseline Expression Atlas ([BEA](//www.ebi.ac.uk/gxa/help/baseline-atlas.html)) [@10.1093/nar/gkt1270]
+ Human Protein Atlas ([HPA](//www.proteinatlas.org/)) [@10.1126/science.1260419]
+ GNF Gene Expression Atlas ([BodyMap](http://biogps.org/dataset/1/geneatlas-u133a-gcrma/)) [@10.1073/pnas.0400782101]
+ Human Proteome Map ([HPM](http://www.humanproteomemap.org/)) [@10.1038/nature13302]
+ Gene Enrichment Profiler ([GEP](//xavierlab2.mgh.harvard.edu/EnrichmentProfiler/)) [@10.1182/blood-2010-01-263855]
+ A global map of human gene expression ([E-MTAB-62](https://www.ebi.ac.uk/arrayexpress/experiments/E-MTAB-62/)) [@10.1038/nbt0410-322]
+ Unveiling RNA Sample Annotation ([USRA](//ursa.princeton.edu/)) [@10.1093/bioinformatics/btt529]
+ RNA-Seq Atlas [@10.1093/bioinformatics/bts084]

**Additional resources found since initial post**:

+ [Bgee](http://bgee.unil.ch/) [@10.1007/978-3-540-69828-9_12]
+ [TISSUES](http://tissues.jensenlab.org/About) [@10.7717/peerj.1054]","17",2015-06-17,2015-06-17,2,1356,"base.profile","Daniel","Himmelstein","dhimmel"
"477","comments","rephetio","2015-06-17T18:56:34.553Z",17,"@marinasirota recommended GTEx because of the large number samples per tissue and the use of RNA-seq.","17",2015-06-17,2015-06-17,2,101,"base.profile","Daniel","Himmelstein","dhimmel"
"478","comments","rephetio","2015-06-17T20:51:35.154Z",17,"The Genotype-Tissue Expression project ([GTEx](http://www.gtexportal.org/home/)) RNA-sequenced [@10.1126/science.aaa0355]:

> 1641 samples from 175 individuals representing 43 sites: 29 solid organ tissues, 11 brain subregions, whole blood, and two cell lines: Epstein-Barr virus–transformed lymphocytes (LCL) and cultured fibroblasts from skin.

The data is [available online](http://www.gtexportal.org/home/datasets2). Specifically, we are interested in the `GTEx_Analysis_V4_RNA-seq_RNA-SeQCv1.1.8_gene_rpkm.gct.gz` file that contains RPKM expression values for each sample. We would like to calculate a single expression value for each gene-tissue pair. Expression values should be comparable across tissues, not just within tissues.

We will post our questions here. Advice appreciated.","17",2015-06-17,2015-06-17,2,797,"base.profile","Daniel","Himmelstein","dhimmel"
"479","comments","rephetio","2015-06-17T21:22:53.938Z",17,"# Mapping GTEx sites to Uberon and CL

We [are using](//thinklab.com/discussion/tissue-node/41) [Uberon](https://uberon.github.io/) [@10.1186/gb-2012-13-1-r5] terms to identify anatomical structures and [Cell Ontology](https://github.com/obophenotype/cell-ontology) (CL) [@10.1186/gb-2005-6-2-r21] terms to identify cell types. Thus, we need to map GTEx sites to their corresponding ontology terms.

From the sample attribute documentation (`GTEx_Data_V4_Annotations_SampleAttributesDS.txt`), we [identified](https://github.com/dhimmel/gtex/blob/8acb90fea2613f8b27814401e361bb6ae4b29078/gtex.ipynb) 54 sites using the `SMTSD` attribute. I have mapped about half of the sites to Uberon. The remainder would benefit from a skilled anatomist or GTEx consortium member.

**Bounty:** Add or correct [our mappings using this spreadsheet](https://docs.google.com/spreadsheets/d/1aXm_RvD4aywXRpQdxVxjBxwPAR_YBBq9f3xkHQaLZXo/edit?usp=sharing) and put your Thinklab username. Then leave a comment in this discussion, and we will rate its value $$\geq $4 \times n$$, where *n* is the number of mappings provided.

Some additional sample site information is available in Table S1 (p. 58) of the [supplement](//www.sciencemag.org/content/suppl/2015/05/06/348.6235.660.DC1/Mele.SM.pdf).","17",2015-06-17,2015-06-17,2,1280,"base.profile","Daniel","Himmelstein","dhimmel"
"480","comments","rephetio","2015-06-17T23:55:39.120Z",109,"So you probably don't want structures that are *uniquely* human or that evolved after the human-chimp common ancestor - there are probably only a handful of these, e.g. certain minor glands and brain regions.

You probably want structures that are typically present in humans but not necessarily absent from other species. There are two ways to go about answering this, based on your tolerance for accidentally including a non-human structure vs accidentally excluding a human structure.

 1. List structures that exclude those that are known not to be found in human
 2. List structures for which there is evidence that the structure is found in humans.

Currently we are well geared up for answering (1), but you have to tolerate the occasional inclusion of some obscure brain region that was only actually observed in macaques or mice. We call these 'taxon modules'. We are not well geared up for (2) but this could be prioritized. Using cross-references to DHBA, EHDAA2, FMA, HBA, and HsapDv is a good start but you may still miss some things.

Either way, you need to do something more specific than just look up the direct properties of the class. You need inference over both the anatomical graph, and the taxonomy graph. For (1) you need to make use of negative evidence, which intuitively 'reverses the flow' of inference. So if a larval stage is never found in amniotes, then any structure that necessarily exists at the larval stage is never found in any descendant of amniotes.

You'd be better using an owl reasoner or some existing tooling for this.



Some background on the taxon axioms:
https://github.com/obophenotype/uberon/wiki/Taxon-constraints

Hmm the taxon subsets files could do with better documentation:

http://uberon.github.io/downloads.html#subsets

(these follow (1) above) 

We should really make a ready-made human subset here. It would probably be more popular than the Aves one.

These are built using [owltools](https://github.com/owlcollab/owltools)

```
owltools --use-catalog ext.owl--reasoner elk --make-species-subset -t NCBITaxon:9606 --remove-dangling --assert-inferred-subclass-axioms --useIsInferred --remove-dangling --set-ontology-id $(OBO)/uberon/subsets/human.owl -o human.owl
```
","109",2015-06-17,2015-06-17,2,2261,"base.profile","Chris","Mungall","chrismungall"
"481","comments","rephetio","2015-06-18T04:18:56.860Z",17,"*R is a data scientist's dream but a programmer's nightmare.*

Here I'll describe the R programming principles and practices that @leobrueggeman and I will try to adhere to for this project. We are big believers in the [Hadleyverse](https://barryrowlingson.github.io/hadleyverse) -- a philosophy of R programming, data analysis, and visualization -- spearheaded by [Hadley Wickham](http://had.co.nz/). I'll describe the basics as well as our modifications below.

# Style

We follow the [Hadley style guide](http://adv-r.had.co.nz/Style.html), which builds off the older [Google style guide](https://google-styleguide.googlecode.com/svn/trunk/Rguide.xml). When calling functions from a package (any non-base function), use double colons to clarify function provenance (i.e. `dplyr::filter()` rather than just `filter()`).

# Data format

The preferred storage format for tabular data is tab-separated with the `.tsv` function. Column names should always be included. For compression, use gzip with a `.gz` extension.

Tabular data in R should be in data frames. Avoid relying on row names by making a dedicated column for the attribute. `options(stringsAsFactors = FALSE)` is imperative but may not need to be explicitly called if reading data with [`readr`](https://github.com/hadley/readr) and manipulating data with [`dplyr`](http://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html) and [`tidyr`](https://github.com/hadley/tidyr). Create data frames using `dplyr::data_frame()`.

Tables should be [tidy](http://www.jstatsoft.org/v59/i10/paper):

1. Each variable forms a column.
2. Each observation forms a row.
3. Each type of observational unit forms a table.

# Piping

Consecutive commands should be chained together using the [`magrittr`](https://github.com/smbache/magrittr) pipe (`%>%`) when possible. Piping improves readability and avoids unnecessary variables cluttering the workspace.

# Visualization

[`ggplot2`](http://docs.ggplot2.org/current/) is the preferred plotting package. Avoid the shortcut function `ggplot2::qplot()`. Consider [`cowplot`](http://cran.r-project.org/web/packages/cowplot/vignettes/introduction.html) or `ggplot2::theme_bw()` to avoid the ugly default theme. Make sure all text is readable. If text is too small to read, remove it. Exporting to vector images (pdfs and svgs) is preferred unless intensive rendering requires png.

# Development environment

[RStudio](http://www.rstudio.com/products/RStudio/) is a mediocre mature development environment. For most prototyping work, notebooks are more powerful and straightforward. Consider using [Jupyter (IPython) notebooks](https://jupyter.org/) with [IRKernel](https://irkernel.github.io/).

# Version control

All code should be version controlled. We use [git](https://git-scm.com/) hosted on [GitHub](https://github.com/). [These short videos](https://git-scm.com/videos) are recommended for inexperienced git users.

Link to specific files on GitHub with the commit hash for immutability and durability.

# Additional materials

Check out the rstudio [webinars](https://github.com/rstudio/webinars) as well as [cheatsheets](http://www.rstudio.com/resources/cheatsheets/).","17",2015-06-18,2015-06-18,2,3225,"base.profile","Daniel","Himmelstein","dhimmel"
"482","comments","rephetio","2015-06-18T16:33:27.976Z",17,"# Bgee

On a GitHub issues discussion on mapping GTEx data to Uberon, [Frederic Bastian suggested Bgee](https://github.com/obophenotype/uberon/issues/704#issuecomment-113134400) as a database for human tissue-specific expression measurements under normal conditions -- exactly what we're looking for.

[Bgee](http://bgee.unil.ch/) was designed for comparative genomics [@10.1007/978-3-540-69828-9_12] and therefore maps sample sites to standard vocabularies (like Uberon) and contains data for many species (not needed now but may be in the future).

Genes are in Ensembl identifiers which we can easily convert to Entrez GeneIDs. Highly processed and relevant datasets [appear to be available](http://bgee.unil.ch/?page=doc&action=call_files#single_expr):

+ Presence/absence of expression
+ Over-/under-expression across anatomy or life stages

Specifically, we want to create three matrices with Entrez GeneID columns and Uberon/CL rows. We are interested in the adult development stage. The values should binary or continuous allowing us to pick an inclusion threshold later. The three desired matrices of tissue-specific expression are:

1. Transcript presence in adult 
2. Transcript over-expression compared to other adult human sites
3. Transcript under-expression compared to other adult human sites

Bgee does not yet include GTEx RNA-Seq data but will integrate this data in the coming months. **Question for Bgee team:** do you compute transcript abundance from raw data? I am not stoked about the Flux Capacitor software used by GTEx for [reasons pointed out by others](https://liorpachter.wordpress.com/2013/10/21/gtex/).","17",2015-06-18,2015-06-18,2,1652,"base.profile","Daniel","Himmelstein","dhimmel"
"483","comments","rephetio","2015-06-18T21:09:23.190Z",17,"# Human constraint: *positive* versus *no negative* evidence

@chrismungall, could not have hoped for a more informative response!

I am going to refer to your two methods as:

1. no negative evidence, which should include all human structures and some non-human structures
2. positive evidence, which should include some human structures and exclude all non-human structures

I created a comparison of the two methods for Uberon terms, using @fbastian's [implementation](https://github.com/obophenotype/uberon/issues/703#issuecomment-113131156) of @chrismungall's owltools command [above](#276) for (1) and my [implementation](https://github.com/dhimmel/uberon/blob/08cbf5beef80a68cf880a459a49097e39afade08/human-constraint.ipynb) of *positive evidence* for (2). My implementation has not been vetted, and if there is an owltools command for this functionality, we should switch. 

I created two tsv files: one with [all uberon terms](https://github.com/dhimmel/uberon/blob/08cbf5beef80a68cf880a459a49097e39afade08/data/human-constraint.tsv) and another with only [MeSH-mapping uberon terms](https://github.com/dhimmel/uberon/blob/08cbf5beef80a68cf880a459a49097e39afade08/data/mesh-map.tsv).

Since I'm primarily concerned with terms in MeSH, I looked through MeSH-mapping uberon terms with no positive evidence (`positive_evidence == 0`) and also no negative evidence (`no_negative_evidence == 1`). Looking through this subset, there were a few notable terms where we would like negative evidence to exist:

| uberon_id | uberon_name |
|----------------|-------------------------|
| UBERON:0013196 | strand of wool |
| UBERON:0002415 | tail |
| UBERON:0007113 | venom |
| UBERON:0005079 | eggshell |
| UBERON:0001011 | hemolymph |
| UBERON:0006378 | strand of vibrissa hair |
| UBERON:0004758 | salt gland |
| UBERON:0011123 | stifle joint |

However, overall the *no negative evidence* method appeared to have higher accuracy than the *positive evidence* method. Therefore, we will proceed using *no negative evidence*, which should improve over time as Uberon matures.","17",2015-06-18,2015-06-18,2,2098,"base.profile","Daniel","Himmelstein","dhimmel"
"484","comments","rephetio","2015-06-18T23:49:43.252Z",17,"# Bgee parameters

The [Bgee human downloads](http://bgee.unil.ch/?page=download&action=expr_calls#id9606) are user-friendly and should be easy to process. We just have a few questions:

## Transcript presence

For determining expression presence, we want to pick a single and broad **developmental stage**, such as adult. The [propagation](http://bgee.unil.ch/?page=doc&action=call_files#single_expr) up the developmental ontology means we don't need to pick a stage that has been directly assayed by many studies. Post-juvenile adult stage (`UBERON:0000113`) is used for the differential expression analysis. Which stage should we choose?

Next, what **evidence threshold** should we require to consider a gene expressed I was thinking requiring `call_quality == 'high quality'` and `expression in {'present', 'low ambiguity'}`. We could also use a more complex metric on the [complete file](http://bgee.unil.ch/?page=doc&action=call_files#single_expr). 

## Differential expression

We would like to include two differential expression edges in our network: one for under-expression and one for over-expression. For the over-expression dataset, is `call_quality == 'high quality'` and `differential_expression  == 'over-expression'` the right filter?","17",2015-06-18,2015-06-18,2,1265,"base.profile","Daniel","Himmelstein","dhimmel"
"485","comments","rephetio","2015-06-19T00:00:40.757Z",17,"# Handing over GTEx processing responsibility to Bgee

We have [decided to use Bgee](http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#278) for tissue-specific transcript presence, over-, and under-expression. Bgee doesn't currently include GTEx data but [will soon](https://github.com/obophenotype/uberon/issues/704#issuecomment-113134400).

Therefore, we are not going to proceed with GTEx data directly for this project. However, we did already process the data into a usable gene × site format ([notebook](https://github.com/dhimmel/gtex/blob/93c3800cef1ced48b100d57b8d6efab831f8533b/gtex.ipynb), [download](https://github.com/dhimmel/gtex/blob/93c3800cef1ced48b100d57b8d6efab831f8533b/data/expression-SMTSD.tsv.gz)). We converted genes to Entrez GeneIDs. The sites are still in GTEx strings rather than Uberon terms. Expression values are log-transformed. Check out the notebook for a visualization of tissue-specific transcript abundance distributions.

**Bounty:** we will keep the GTEx--Uberon mapping bounty going until June 25, 2015 because these mappings will help the Bgee team and eventually us. @chrismungall, do you want to add a comment here, so you can get rewarded for your 3 mappings?","17",2015-06-19,2015-06-19,2,1235,"base.profile","Daniel","Himmelstein","dhimmel"
"486","comments","rephetio","2015-06-19T00:12:47.995Z",109,"I think the Bgee team will do a great job. Just a few general comments:

most of the GTEx terms correspond to 'wild-type' structures as can be found in uberon/cl. There are however, two subclasses of skin: exposed and unexposed. We *could* add these as subclasses in uberon, but this would be unusual. It would be better to either post-compose these, or to have some kind of ancillary 'sample' ontology where this is composed.

For 'hippocampus', the safest option is to map to the broadest term, 'hippocampal formation', but if it can be shown than the GTEx sample excludes bits of the dentate gyrus then the more specific 'ammons horn' can be used.

Finally, it's always best when ontologies are used prospectively rather than retrospectively, maybe future rounds of GTEx will follow the lead of FANTOM5 and ENCODE in doing this.","109",2015-06-19,2015-06-19,2,837,"base.profile","Chris","Mungall","chrismungall"
"487","comments","rephetio","2015-06-19T12:48:14.856Z",111,"IMO, the ""exposed/unexposed"" state is an experimental factor, and should not be annotated using a new anatomical term, it should be an additional ""column"" in an annotation (using, e.g., EFO).

Daniel, we will discuss next week during our lab meeting the timescale to annotate GTEx data, but as you said, it should be fast. Our problem is that we requested access to the data, and are waiting for an answer. 

We could start working on the mapping you have, but we'd rather go through the information for each sample, to check for normality, etc. This is how we usually do. 
(do they provide GEO or SRA identifiers for the samples BTW?)","111",2015-06-19,2015-06-19,2,640,"base.profile","Frederic","Bastian","fbastian"
"488","comments","rephetio","2015-06-19T12:52:20.262Z",111,"> do you compute transcript abundance from raw data? I am not stoked about the Flux Capacitor software used by GTEx for reasons pointed out by others.

Yes, we do. We map reads to transcriptome using TopHat2; read counts extracted using HTseq; length of longest annotated transcript used.
(edit: woops, you said transcript abundance. We only provide expression data ""per gene"")

Currently, we do not use TMM normalization between samples for the RPKM values we provide, but we will in the next release. We also want to get away from RPKM values, and provide TPM values (for motivation, see [@10.1007/s12064-012-0162-3]).

To generate differential expression calls, we use TMM normalization, then voom + limma. This has been shown to perform well (see [@10.1093/bib/bbt086]). 

We will provide complete documentation by July. 

> The values should binary or continuous allowing us to pick an inclusion threshold later.

So have you noticed that we also provide RPKM values, not only the qualitative ""calls""?

> Post-juvenile adult stage (UBERON:0000113) is used for the differential expression analysis. Which stage should we choose?

Post-juvenile in human also includes 13-18 yo, so I don't know if you want to include those. HsapDv:0000087 ""human adult stage"" would be a ""true"" adult stage. But I think we don't use it for ""differential expression across anatomy"", we could correct that if you need it. It should be correctly used for ""differential expression across development"", if we have the data. And of course it is correctly used for the ""presence/absence"" calls.

Note that ""differential expression"" calls are not propagated, so you might still need to examine all stages for ""differential expression across development"". But for ""presence/absence"", you can safely rely on the propagation, and only retrieve results for your stage of interest. 

You might want to use the ""complete"" file, you will have more data propagated. Also, if you use the ""complete"" file, you might decide to rely only on RNA-Seq data, and avoid the ""ambiguity"" states.

> what evidence threshold should we require to consider a gene expressed I was thinking requiring call_quality == 'high quality' and expression in {'present', 'low ambiguity'}. We could also use a more complex metric on the complete file. 

Presence low quality seems also to give good results, but here it is up to you to decide whether you want to be more on the false negative side, or more on the false positive side.

> For the over-expression dataset, is call_quality == 'high quality' and differential_expression == 'over-expression' the right filter?

I would definitely use the ""low quality"" as well here. Because the overall call generated is based on a voting system weighted by p-values, so even if it is ""low quality"" because of conflicting analyses, the best p-value has won anyway. 
Again, if you use the ""complete"" file, you might decide to rely only on RNA-Seq data, and avoid the ""ambiguity"" states.

Edit: oh, I didn't notice you where mentioning ""transcript abundance"". We only provide expression data ""per gene"", not ""per transcript"".","111",2015-06-19,2015-06-19,2,3142,"base.profile","Frederic","Bastian","fbastian"
"489","comments","rephetio","2015-06-19T18:00:24.304Z",17,"> do they provide GEO or SRA identifiers for the samples BTW?

@fbastian, I do not see any other sample identifiers than `SAMPID` (GTEx Public Sample ID) in the [sample attributes documentation spreadsheet](http://www.gtexportal.org/static/datasets/gtex_analysis_v4/annotations/GTEx_Data_V4_Annotations_SampleAttributesDD.xlsx). The IDs are formatted like `GTEX-N7MS-0007-SM-2D7W1` -- not sure whether that corresponds with other databases.

> We could start working on the mapping you have, but we'd rather go through the information for each sample, to check for normality, etc.

@fbastian, do whatever is best for you! And let it be known that your painstaking and thorough integration efforts are appreciated.

> There are however, two subclasses of skin: exposed and unexposed.

@chrismungall, by post-compose do you mean contacting GTEx and asking for more details on the skin sample sites? That seems the best to me as I assume the sample collectors had specific instructions. The skin sites are specified as *suprapubic* for sun unexposed and *lower leg* for sun exposed.","17",2015-06-19,2015-06-19,2,1089,"base.profile","Daniel","Himmelstein","dhimmel"
"490","comments","rephetio","2015-06-19T18:37:26.847Z",17,"# Nomenclature

We have been referring to the metanode (node type) for uberon as Tissue. Is Tissue a misnomer? Does Tissue encompass all uberon nodes? If we add CL terms under the same metanode, what term can we use that encompass uberon terms and cell types?

A single word is preferred to a compound term. Some options I can think of are

+ Tissue
+ Anatomy
+ Structure
+ Anatomical Structure

@chrismungall, do you have an inclination?","17",2015-06-19,2015-06-19,2,449,"base.profile","Daniel","Himmelstein","dhimmel"
"491","comments","rephetio","2015-06-19T19:07:48.480Z",109,"tissue is too specific, but people will still know what you mean. Uberon follows the CARO upper level ontology:

 *  [CARO:0030000](http://purl.obolibrary.org/obo/CARO_0030000) ! biological entity
    *  [CARO:0000000](http://purl.obolibrary.org/obo/CARO_0000000) ! anatomical entity
       *  [CARO:0000006](http://purl.obolibrary.org/obo/CARO_0000006) ! material anatomical entity
          *  [CARO:0000003](http://purl.obolibrary.org/obo/CARO_0000003) ! connected anatomical structure (aka anatomical structure)
              *  [CARO:0000013](http://purl.obolibrary.org/obo/CARO_0000013) ! cell 
              *  [CARO:0010000](http://purl.obolibrary.org/obo/CARO_0010000) ! multicellular anatomical structure
                 *  [CARO:0000043](http://purl.obolibrary.org/obo/CARO_0000043) ! tissue  
                 *  [CARO:0020004](http://purl.obolibrary.org/obo/CARO_0020004) ! organ  
                 *  [CARO:0000043](http://purl.obolibrary.org/obo/CARO_0000043) ! tissue  

So formally speaking 'anatomical structure' would exclude non-material entities such as lumens, 2D boundaries... but you should never have gene expression in any of these sites","109",2015-06-19,2015-06-19,2,1176,"base.profile","Chris","Mungall","chrismungall"
"492","comments","rephetio","2015-06-20T01:04:36.970Z",111,"@dhimmel, thanks for the information. Did your lab formally request access to the data to get the actual annotations? (GTEx_Data_V4_Annotations_SampleAttributesDS.txt in your notebook)

Otherwise, Chris is speaking about ontology term post-composition, a way of creating a new ontology concept on-the-fly, that doesn't have any identifier or IRI (""anonymous class expression""), and that is made of the ""composition"" of several other terms. That would allow you to create on the fly a new concept for ""exposed skin"".

See for instance, in zebrafish ontology: https://zfin.org/action/ontology/post-composed-term-detail?superTermID=ZFA:0001117&subTermID=ZFA:0000155
There is no term ""post-vent region somite"" in the ontology, but the concept is represented by using the existing terms ""post-vent region"" and ""somite"".","111",2015-06-20,2015-06-20,2,819,"base.profile","Frederic","Bastian","fbastian"
"493","comments","rephetio","2015-06-20T03:01:42.139Z",17,"We have done some initial analyses on the Bgee data ([notebook](http://nbviewer.ipython.org/github/dhimmel/bgee/blob/b26d396bbe6b137372731f031f544c7da47e314c/bgee.ipynb)). We stuck with the simple files because:

+ we would like to outsource as much of the difficult decision-making as possible.
+ we want a method that is resilient to changing technologies and Bgee revisions -- not a method that is only optimal for a specific Bgee release.

Here are our initial findings.

## Gene presence

We chose the filter:

```python
call_quality in {'high quality', 'low quality'} and expression in {'present', 'low ambiguity'}
```

We chose a permissive filter that is not limited to RNA-Seq. In the future, when Bgee contains more sources, we could increase these thresholds.

The developmental stage ""25-44 year-old human stage"" (`HsapDv:0000090`) has the most present genes. ""Human adult stage"" (`HsapDv:0000087`) is comparatively quite underpopulated with major organs like heart having no present genes ([Figure 1](http://nbviewer.ipython.org/github/dhimmel/bgee/blob/b26d396bbe6b137372731f031f544c7da47e314c/bgee.ipynb#Figure-1:-Number-of-genes-present-by-developmental-stage-and-anatomical-entity)). I was surprised because I thought adult would subsume 25-44 and the expression data would be propagated. @fbastian, any idea what is going on? Should we take 25-44 as our developmental context or should we collapse data across adult developmental stages. Is the differential-expression data lacking if it's only calculated on ""post-juvenile adult stage""?

Compared to the distribution of expressed genes in the GNF Expression Atlas ([Figure 3](http://nbviewer.ipython.org/github/dhimmel/bgee/blob/b26d396bbe6b137372731f031f544c7da47e314c/bgee.ipynb#Figure-3:-Distibution-of-genes-present-per-tissue-in-GNF-Expression-Atlas)), Bgee had much more variation by tissue. This is expected since Bgee integrates diverse data of varied throughput and a is an acceptable sacrifice for broader input data.

## Differential expression

We identified differential expression with `call_quality in {'low quality', 'high quality'}`. [Figure 2](http://nbviewer.ipython.org/github/dhimmel/bgee/blob/b26d396bbe6b137372731f031f544c7da47e314c/bgee.ipynb#Figure-2:-Number-of-differntially-expressed-genes-present-by-anatomical-entity) shows that we identified a large number of DE-genes across a variety of anatomical entities. Some tissues or cell types, such as leukocytes and testis, have over 10,000 under/over-expressed genes (almost every gene). Is this biologically meaningful or the result of data coverage or other experimental artifacts?","17",2015-06-20,2015-06-20,2,2651,"base.profile","Daniel","Himmelstein","dhimmel"
"494","comments","rephetio","2015-06-20T03:14:11.820Z",17,"@fbastian, `GTEx_Data_V4_Annotations_SampleAttributesDS.txt` is available from the GTEx [download page](http://www.gtexportal.org/home/datasets2) which requires an account. However, [this direct link](http://www.gtexportal.org/static/datasets/gtex_analysis_v4/annotations/GTEx_Data_V4_Annotations_SampleAttributesDS.txt) circumvents the login page. How long has it been since you submitted the data access request?","17",2015-06-20,2015-06-20,2,414,"base.profile","Daniel","Himmelstein","dhimmel"
"495","comments","rephetio","2015-06-20T11:51:59.295Z",111,"Not very long, a week or so.

Just to anticipate, do they provide more detailed information somewhere else, like, e.g., http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM81022 ? (extraction protocols, detailed information about the anatomical structure, etc)","111",2015-06-20,2015-06-20,2,263,"base.profile","Frederic","Bastian","fbastian"
"496","comments","rephetio","2015-06-20T12:36:57.943Z",111,"(on a side note, I didn't know IPython/Jupyter, I discovered it thanks to you and I fell in love with it, this is amazing; also, it's great to have other people to investigate our data, and check their quality)

> I was surprised because I thought adult would subsume 25-44 and the expression data would be propagated

So, we propagate the data, but in the simple file we only display conditions that were actually observed in experimental data (no conditions appearing from propagation only). It means that we never had an experiment studying ""heart"" at stage ""human adult stage"". Which makes sense, because annotating experimental data with such a broad term basically mean ""we know it was a heart from an adult, but no idea which age""; we often have more detailed information.

This is why the complete file would work better for you, as we also display conditions from ""propagation only""; you should see lots of data for ""heart"" at ""human adult stage"". Of note, even in the complete file you get the ""global"" call generated by us, see column 7 and 8: http://bgee.org/?page=doc&action=call_files#single_expr_complete
So you wouldn't have to do the decision-making, even when using the complete file.

But your problem is interesting, maybe we should ""relax"" the filtering of conditions in the simple file, I will think about it.
This difference in filtering was explained in the documentation, should we clarify it?

> Some tissues or cell types, such as leukocytes and testis, have over 10,000 under/over-expressed genes (almost every gene). Is this biologically meaningful or the result of data coverage or other experimental artifacts?

I think it is meaningful. First, it is not almost every gene, from the complete file (where you can also find genes never shown to have differential expression) you can see that we have about 20,000 genes tested for differential expression; so, in the majority of tissues you get a reasonable percentage of genes differentially expressed. Second, I'm not surprised by the outlier tissues you found, for instance we know that testis and brain have very specific expression. Third, you almost always found more genes under-expressed than over-expressed, and this is actually an interesting pattern, that we have observed by other methods.

I will discuss this with my colleagues to be sure they get to the same conclusion, and will get back to you. But I think everything looks good. ","111",2015-06-20,2015-06-20,2,2441,"base.profile","Frederic","Bastian","fbastian"
"497","comments","rephetio","2015-06-20T20:46:05.585Z",17,"# Completed Bgee analysis -- version 0

## Tissue-specific gene presence

> we propagate the data, but in the simple file we only display conditions that were actually observed in experimental data (no conditions appearing from propagation only)

Okay I switched to the complete file for presence/absence. The updated [Figure 1](http://nbviewer.ipython.org/github/dhimmel/bgee/blob/bd50da6c931675a0316a71ab5c6d7d1bbd35f8bd/bgee.ipynb#Figure-1:-Number-of-genes-present-by-developmental-stage-and-anatomical-entity) makes much more sense now. We chose to go with ""human adult stage"" (`HsapDv:0000087`) as the developmental stage, which now has broad coverage across tissues, however with fewer present genes than ""life cycle"" as expected. We converted to entrez genes and ended up with a matrix of 18,997 genes (16,278 coding) × 666 anatomical entities ([download](https://github.com/dhimmel/bgee/blob/bd50da6c931675a0316a71ab5c6d7d1bbd35f8bd/data/present-in-adult.tsv.gz)). On average, 41.1% of genes were expressed in a given anatomical entity.

> But your problem is interesting, maybe we should ""relax"" the filtering of conditions in the simple file, I will think about it. This difference in filtering was explained in the documentation, should we clarify it?

I misinterpreted the [documentation](http://bgee.unil.ch/?page=doc&action=call_files#single_expr) by assuming that if a developmental stage had any annotations, propagated values would be provided for all anatomies of that stage. Instead, propagated values are only included for stage--anatomy combinations with annotations. Perhaps the documentation should make it more clear that many use cases will require the complete file due to this issue. Another consideration is that processing the complete file was consuming up to 80 GB of RAM at points -- not an issue *personally* but could be for others.

## Tissue-specific differential expression

We converted the differential expression to entrez genes and ended up with a matrix of 18,620 genes (16,184 coding) × 98 anatomical entities ([notebook](http://nbviewer.ipython.org/github/dhimmel/bgee/blob/bd50da6c931675a0316a71ab5c6d7d1bbd35f8bd/bgee.ipynb#Read-and-process-differential-expression-data), [download](https://github.com/dhimmel/bgee/blob/bd50da6c931675a0316a71ab5c6d7d1bbd35f8bd/data/diffex.tsv.gz)).

# General Bgee feedback

@fbastian, in the presence download, for a given gene--stage--anatomy combination is there at most one row? For the anatomy-based differential expression download, for a given gene--anatomy combination is there at most one row? Better documentation of what uniquely defines an observation (row) would be helpful.

Since the downloaded zip files only contain a single file, I think gzip compression makes more sense.

Finally, I prefer lowercase column names with underscores rather than spaces. This naming convention avoids frustrating [R munging](https://github.com/hadley/readr/blob/efd422504762d703bc8c67a40c36e52466e275b3/README.md#output) and enables unquoted variable reference in R and python. Understandably, you may not want to change for compatibility issues.","17",2015-06-20,2015-06-20,2,3147,"base.profile","Daniel","Himmelstein","dhimmel"
"498","comments","rephetio","2015-06-20T22:26:16.860Z",17,"> do they provide more detailed information somewhere else

No idea, I did email the GTEx support with a link to this thread, so perhaps they'll provide some clarification.","17",2015-06-20,2015-06-20,2,174,"base.profile","Daniel","Himmelstein","dhimmel"
"499","comments","rephetio","2015-06-20T23:02:20.747Z",17,"> formally speaking 'anatomical structure' would exclude non-material entities such as lumens, 2D boundaries

Nodes that don't have expression may still be connected via a disease localization edge. These edges are currently [created via MEDLINE cooccurrence](http://thinklab.com/discussion/mining-knowledge-from-medline-articles-and-their-indexed-mesh-terms/67#229) and can connect any uberon or CL terms that map to MeSH.

I am leaning towards calling the metanode *Anatomy*. We would end up with metapaths (path types) like: **C**ompound--**t**arget--**G**ene--**e**xpression--**A**natomy--**l**ocalization--**D**isease (abbreviated as *CtGeAlD*). This metapath refers to when a compound targets a gene that is expressed in an anatomy/tissue/cell-type where the disease is localized. Does that seem like a misuse of the word Anatomy?","17",2015-06-20,2015-06-20,2,840,"base.profile","Daniel","Himmelstein","dhimmel"
"500","comments","rephetio","2015-06-22T11:50:04.721Z",111,"FYI, our curator Anne Niknejad has started editing your mapping, she will also create the issues on the Uberon tracker to request new terms.","111",2015-06-22,2015-06-22,2,140,"base.profile","Frederic","Bastian","fbastian"
"501","comments","rephetio","2015-06-22T15:16:41.680Z",111,"> Some tissues or cell types, such as leukocytes and testis, have over 10,000 under/over-expressed genes (almost every gene). Is this biologically meaningful or the result of data coverage or other experimental artifacts?

I discussed this with my colleagues as promised, they agree that everything looks fine. We just get to the conclusion that maybe we could use a FDR correction over all analyses (currently, p-values are corrected on a ""per analysis"" basis), to decrease the number of differentially expressed genes in the most studied organs. 

> matrix of 18,997 genes (16,278 coding) × 666 anatomical entities

Great, I just want to warn you that lots of these structures are not independent (e.g., ""cerebellum"" is not independent from ""brain""). I don't know what type of analyses you plan, but this can sometimes be problematic. If you need it, I can provide you a script accepting a list of organs as argument, and returning only the most-precise ""independent"" organs.

> in the presence download, for a given gene–stage–anatomy combination is there at most one row

Yes.

> For the anatomy-based differential expression download, for a given gene–anatomy combination is there at most one row?

No, because an analysis could compare organ A, B, C at stage embryo, another one compare the organs A, B, C at stage adult. So, for a given gene, you would have two entries for organ A: one at stage embryo, another one at stage adult.
So, it is as for presence download, it is at most one row for a given gene–stage–anatomy combination.

> I think gzip compression makes more sense.

Not for Windows users (yes, it exists :p)

Thank you for your feedback, we will take it into account, it is much appreciated. Notably we will remove the spaces in header, will update the documentation, and will change the filtering in simple files.","111",2015-06-22,2015-06-22,2,1857,"base.profile","Frederic","Bastian","fbastian"
"502","comments","rephetio","2015-06-23T18:26:55.244Z",17,"# 1000 Genomes Phase 3 data

We have [become aware](http://www.1000genomes.org/announcements/phase-3-variant-set-additional-allele-frequencies-functional-annotation-and-other-data) that more recent and comprehensive 1000 Genomes data exists, it's just not included in SNAP. The phase 3 dataset contains ~2500 individuals with whole-genome sequencing.

The phase 3 data was [recently added](http://www.ensembl.info/blog/2015/06/18/1000-genomes-phase-3-frequencies-genotypes-and-ld-data/#comments) to the Ensembl database. Ensembl has a [perl API](http://uswest.ensembl.org/info/docs/api/variation/true), which should be able to find all SNPs in LD with a lead SNP.

We found [example code](https://www.biostars.org/p/109785/#110102) and have [reached out](https://www.biostars.org/p/109785/#147784) for advice because our implementation is [currently failing](http://nbviewer.ipython.org/github/dhimmel/ensembl-api/blob/5ee80e036a8dd4e5416c2af6ddd5ae7a1a9c5a44/linkage.ipynb).","17",2015-06-23,2015-06-23,2,981,"base.profile","Daniel","Himmelstein","dhimmel"
"503","comments","rephetio","2015-06-23T19:29:01.737Z",17,"> we could use a FDR correction over all analyses

I support the correction for multiple testing.

> So, it is as for presence download, it is at most one row for a given gene–stage–anatomy combination.

I thought all rows in the ""Over-/Under-expression across anatomy"" download were for ""post-juvenile adult stage"", so row uniqueness depends only on gene and anatomy?

> lots of these structures are not independent (e.g., ""cerebellum"" is not independent from ""brain""). I don't know what type of analyses you plan, but this can sometimes be problematic.

We enforce uniqueness for the metanodes where we are predicting edges ([compounds](http://thinklab.com/discussion/unifying-drug-vocabularies/40#192) and [diseases](http://thinklab.com/discussion/unifying-disease-vocabularies/44#144)). We are not planning on eradicating term overlap for other metanodes such as [GO Domains](http://thinklab.com/discussion/compiling-gene-ontology-annotations-into-an-easy-to-use-format/39), [Anatomy](http://thinklab.com/discussion/tissue-node/41#286), and [Symptom](http://thinklab.com/discussion/mining-knowledge-from-medline-articles-and-their-indexed-mesh-terms/67#222). The consequence of this duplicity is unknown and something that [HNEP](http://het.io/hnep/) researchers should eventually confront.

Our method downweights paths through high-degree nodes, which reduces the impact of highly-redundant supernodes such as ""anatomical entity"", ""anatomical structure"", and ""anatomical system"". However, our implementation has not been optimized and may get bogged down by all these expression edges. Therefore we may consider removing anatomies that are too broad to be meaningful. We could also consider pruning for independence.

> If you need it, I can provide you a script accepting a list of organs as argument, and returning only the most-precise ""independent"" organs.

Yes, I don't *need* it but *want* to see the script out of interest. Primarily, I am curious about how your algorithm, since I often encounter these problems.","17",2015-06-23,2015-06-23,2,2042,"base.profile","Daniel","Himmelstein","dhimmel"
"504","comments","rephetio","2015-06-24T05:08:18.216Z",17,"Python is our first-line language because it is powerful, elegant, and widely adopted. In combination with [Jupyter notebooks](https://jupyter.org/), python is a data science jackhammer, while also being general purpose.

Python 3 was released in 2008 and contains small incompatibilities with Python 2. 3 is [superior](https://youtu.be/f_6vDi7ywuA) to 2. Many training resources and codebases are still in 2, but new users should begin with 3.

## Installation

We will use Anaconda for package management. Anaconda makes installing packages easier and includes most important ones by default. It also supports environments -- distinct and independent installations -- which allow specific installations for specific purposes. Anaconda creates a default environment (root) that becomes your primary python distribution. Here, we create a root python 3 environment and an elective python 2 environment that can be activated when needed. 

Download [anaconda for python 3](http://continuum.io/downloads). Avoid the graphical installer which installs unneeded GUI programs. Install according to the defaults. Once installed run the following terminal command for updates:

```sh
conda update --all
```

When needed, additional packages should be installed like `conda install seaborn`, which installs the [seaborn](https://web.stanford.edu/~mwaskom/software/seaborn/) visualization package.

To install python 2.7, we will create a new environment called `py27` with the following command:

```sh
conda create -n py27 python=2.7 anaconda
```

Activate the python 2 environment with `source activate py27` on linux or mac and `activate py27` on windows. Once activated, run `conda update --all` to update packages and `jupyter kernelspec install-self --user` to make the Python 2 kernel available in Jupyter. Then run `source deactivate` (or `deactivate` on windows) to return to the default python 3 environment.

Python 2 should only be used when necessitated by legacy codebases. Otherwise, we use Python 3.

If you need [rdkit](http://www.rdkit.org/) for chemoinformatics, you should follow the installation [instructions here](https://github.com/rdkit/conda-rdkit), which creates a dedicated rdkit environment with InChI support.

## Usage

We recommend using Jupyter notebooks for most analyses. Launch jupyter by running `jupyter notebook` in the terminal. Dedicated .py files can be edited using the Jupyter text editor or [atom](https://atom.io/).

Familiarize yourself with the [PEP 0008](https://www.python.org/dev/peps/pep-0008/) style guide.

## Local development

When developing a package locally, run `pip install -e .` from the package's root directory. The package will then be importable from within your conda environment. The `-e` flag specifies editable mode and makes the package automatically update when you modify the source.

## Packages

+ [`pandas`](http://pandas.pydata.org/) for dataframes -- important functions include [`DataFrame.merge`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.merge.html), [`melt`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.melt.html), [`DataFrame.pivot_table`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.pivot_table.html), [`DataFrame.groupby`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.groupby.html), [`pandas.read_table`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_table.html), [`DataFrame.to_csv(path, sep='\t', index=False)`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_csv.html), [`pandas.isnull`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.isnull.html), and [`DataFrame.head`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.head.html). Be forewarned of [the horrors](http://pandas.pydata.org/pandas-docs/stable/gotchas.html#support-for-integer-na) of int to float conversion when missing values are present.

+ [`seaborn`](https://web.stanford.edu/~mwaskom/software/seaborn/) for data visualization.

+ [`numpy`](http://www.numpy.org/) for arrays and linear algebra.

+ [`requests`](http://docs.python-requests.org/en/latest/) for http calls.

+ [`sklearn`](http://scikit-learn.org/stable/) for machine learning and classification.

For example code, [check out](https://github.com/search?l=&o=desc&q=user%3Adhimmel+extension%3Aipynb&ref=advsearch&s=indexed&type=Code&utf8=%E2%9C%93) my notebooks.","17",2015-06-24,2015-06-24,2,4505,"base.profile","Daniel","Himmelstein","dhimmel"
"505","comments","rephetio","2015-06-25T04:17:27.147Z",113,"Thank you. This is very helpful.","113",2015-06-25,2015-06-25,2,32,"base.profile","Ola","O","akolow"
"506","comments","rephetio","2015-06-26T21:40:14.598Z",17,"# Initial human pathway collection

We have downloaded, parsing, and combined MSigDB and WikiPathways ([notebook](https://github.com/dhimmel/pathways/blob/5eb835b33629ffed4e22978e98a702e30ebd7076/merge-resources.ipynb), [tsv results](https://github.com/dhimmel/pathways/blob/5eb835b33629ffed4e22978e98a702e30ebd7076/data/pathways.tsv)). In total we identified, 1,516 human pathways after removing a single duplicated pathway. Most pathways have below 100 genes but some have up to 1,000.

## WikiPathways Method

We extracted pathways from the previously-suggested [dump file](http://www.pathvisio.org/data/bots/gmt/wikipathways.gmt). We removed pathways without any human genes. From a total of 669 wikipathways, 187 were human. @alexanderpico, can you confirm that these are the expected numbers?

Above I asked:

> Additionally, are non-gene entities identified as free text, or are they structured by a standardized vocabulary?

It appears that other entities besides genes are unstandardized in WikiPathway models. Therefore, we chose to not connect pathways to diseases, drugs, and tissues.

## MSigDB Method

We used the *C2: CP* collection from MSigDB 5.0 which yielded 1,330 pathways. The sources and counts of these pathways are below:

| MsigDB ID | Name | Pathways |
|---------------------|--------------------------------------|----------|
| REACTOME | [Reactome](http://www.reactome.org/) | 674 |
| BIOCARTA | [BioCarta](http://www.biocarta.com/) | 217 |
| PID | [Pathway Interaction Database](http://pid.nci.nih.gov/) | 196 |
| KEGG | [KEGG](http://www.genome.jp/kegg/) | 186 |
| ST | [Signaling Transduction KE](http://stke.sciencemag.org/) | 28 |
| SA | [SigmaAldrich](http://www.sigmaaldrich.com/life-science.html) | 10 |
| NABA | [Matrisome](http://matrisomeproject.mit.edu/) | 10 |
| SIG | [Signaling Gateway](http://www.signaling-gateway.org/molecule/) | 8 |
| WNT | [SuperArray](http://superarray.com/) | 1 |","17",2015-06-26,2015-06-26,2,1958,"base.profile","Daniel","Himmelstein","dhimmel"
"507","comments","rephetio","2015-06-27T17:57:03.429Z",104,"> We extracted pathways from the previously-suggested dump file. We removed pathways without any human genes. From a total of 669 wikipathways, 187 were human. @alexanderpico, can you confirm that these are the expected numbers?

Hmm... You are correct that the dump file contains 187 human pathways (just did a browser FIND on the page for 'homo sapiens'), but there are ~293 human pathways in the standard collection. You can access these on the [bulk download page](http://wikipathways.org/index.php/Download_Pathways) in multiple formats, including plain text lists of (non-unified) datanode identifiers.  This number is climbing as folks continue to add new content. For example, we have over 300 additional human pathways that are in the works at various stages of completion (or disrepair) that are not included in these bulk downloads.

Sorry for suggesting the dump file. I thought that would make it easier since the identifiers are unified to Entrez, but it's apparently incomplete. I'm not sure why...
","104",2015-06-27,2015-06-27,2,1019,"base.profile","Alexander","Pico","alexanderpico"
"508","comments","rephetio","2015-06-29T01:34:02.291Z",104,"The WikiPathways team found the error, corrected it and updated the dump file, which now contains 290 human pathways with gene identifiers unified to Entrez. Same location: http://www.pathvisio.org/data/bots/gmt/wikipathways.gmt

","104",2015-06-29,2015-06-29,2,232,"base.profile","Alexander","Pico","alexanderpico"
"509","comments","rephetio","2015-06-29T17:19:07.142Z",17,"# Human pathway collection revision

We updated our pathway resource with the updated WikiPathways data ([notebook](https://github.com/dhimmel/pathways/blob/032036f91a8395eabd0dab2d9d1ee3252ba140f8/merge-resources.ipynb), [tsv results](https://github.com/dhimmel/pathways/blob/032036f91a8395eabd0dab2d9d1ee3252ba140f8/data/pathways.tsv)). The new total for human pathways is 1,619 with 289 of those from WikiPathways.","17",2015-06-29,2015-06-29,2,419,"base.profile","Daniel","Himmelstein","dhimmel"
"510","comments","rephetio","2015-06-30T19:15:05.994Z",17,"@fbastian and Anne Niknejad.

On June 17th I emailed `gtex-help@broadinstitute.org` asking for a GTEX--Uberon mapping. Today, Tim Sullivan responded and attached [this mapping file](https://github.com/dhimmel/gtex/blob/30096fb519efba939eeb0c5681ba20ad8d43660a/download/GTEx_Uberon_Terms.xlsx).

He didn't mention the methodology used, but you may want to crosscheck your work.

I've reproduced Tim's mapping below for quick reference:

| Tissue Site Detail | Uberon Code | Uberon Term |
|-------------------------------------------|-------------|------------------------------------|
| Adipose - Subcutaneous | 0002190 | subcutaneous adipose tissue |
| Adipose - Visceral (Omentum) | 0010414 | omental fat pad |
| Adrenal Gland | 0002369 | adrenal gland |
| Artery - Aorta | 0001496 | ascending aorta |
| Artery - Coronary | 0001621 | coronary artery |
| Artery - Tibial | 0001323 | tibial nerve |
| Artery - Tibial | 0007610 | tibial artery |
| Bladder | 0001255 | urinary bladder |
| Brain - Amygdala | 0001876 | amygdala |
| Brain - Anterior cingulate cortex (BA24) | 0009835 | anterior cingulate cortex |
| Brain - Caudate (basal ganglia) | 0001873 | caudate nucleus |
| Brain - Cerebellar Hemisphere | 0002037 | cerebellum |
| Brain - Cerebellum | 0002037 | cerebellum |
| Brain - Cortex | 0001870 | frontal cortex |
| Brain - Frontal Cortex (BA9) | 0009834 | dorsolateral prefrontal cortex |
| Brain - Hippocampus | 0001954 | Ammon's horn |
| Brain - Hypothalamus | 0001898 | hypothalamus |
| Brain - Nucleus accumbens (basal ganglia) | 0001882 | nucleus accumbens |
| Brain - Putamen (basal ganglia) | 0001874 | putamen |
| Brain - Spinal cord (cervical c-1) | 0006469 | first cervical spinal cord segment |
| Brain - Substantia nigra | 0002038 | substantia nigra |
| Breast - Mammary Tissue | 0008367 | breast epithelium |
| Cells - EBV-transformed lymphocytes | EFO_0000572 | lymphoblast |
| Cells - Leukemia cell line (CML) | EFO_0002067 | K562 |
| Cells - Transformed fibroblasts | EFO_0000496 | fibroblast |
| Cervix - Ectocervix | 0012249 | ectocervix |
| Cervix - Endocervix | 0000458 | endocervix |
| Colon - Sigmoid | 0001159 | sigmoid colon |
| Colon - Transverse | 0001157 | transverse colon |
| Esophagus - Gastroesophageal Junction | 0004550 | gastroesophageal sphincter |
| Esophagus - Mucosa | 0006920 | esophagus squamous epithelium |
| Esophagus - Muscularis | 0004648 | esophagus muscularis mucosa |
| Fallopian Tube | 0003889 | fallopian tube |
| Heart - Atrial Appendage | 0006631 | right atrium auricular region |
| Heart - Left Ventricle | 0006566 | left ventricle myocardium |
| Kidney - Cortex | 0001225 | cortex of kidney |
| Liver | 0001114 | right lobe of liver |
| Lung | 0008952 | upper lobe of left lung |
| Minor Salivary Gland | 0006330 | anterior lingual gland |
| Muscle - Skeletal | 0011907 | gastrocnemius medialis |
| Nerve - Tibial | 0001323 | tibial nerve |
| Nerve - Tibial | 0007610 | tibial artery |
| Ovary | 0002119 | left ovary |
| Pancreas | 0001150 | body of pancreas |
| Pituitary | 0000007 | pituitary gland |
| Prostate | 0002367 | prostate gland |
| Skin - Not Sun Exposed (Suprapubic) | 0001416 | skin of abdomen |
| Skin - Sun Exposed (Lower leg) | 0001511 | skin of leg |
| Small Intestine - Terminal Ileum | 0001211 | Peyer's patch |
| Spleen | 0002106 | spleen |
| Stomach | 0000945 | stomach |
| Testis | 0000473 | testis |
| Thyroid | 0002046 | thyroid gland |
| Uterus | 0000995 | uterus |
| Vagina | 0000996 | vagina |
| Whole Blood | 0013756 | venous blood |","17",2015-06-30,2015-06-30,2,3591,"base.profile","Daniel","Himmelstein","dhimmel"
"511","comments","rephetio","2015-06-30T20:00:13.809Z",35,"This is very helpful and something I can use to improve my python workflow. ","35",2015-06-30,2015-06-30,2,76,"base.profile","Venkat","Malladi","vsmalladi"
"512","comments","rephetio","2015-07-01T14:32:41.223Z",109,"Some seem slightly more specific than the label suggests - sometimes the increased specificity is trivial (ie their ovary sample was from a left ovary), sometimes relevant (their representative skeletal muscle sample was from gastrocnemius medialis, the esophagus mucosa sample was taken from the epithelium rather than lamina propria).","109",2015-07-01,2015-07-01,2,336,"base.profile","Chris","Mungall","chrismungall"
"513","comments","rephetio","2015-07-02T00:44:39.854Z",17,"We would like to create a catalog of interactions between proteins (PPIs). I am currently leaning towards focusing on physical interactions, since other types of interactions will be captured by other metanodes and metaedges. If some non-physical interactions are included that is acceptable but not the goal.

Some previous studies have compiled PPI catalogs:

+ the Incomplete Interactome (II) [@10.1126/science.1257601] --- compiled protein interactions of seven types

+ the Human Interaction Database ([HID](http://interactome.dfci.harvard.edu/H_sapiens/index.php?page=download)) [@10.1016/j.cell.2014.10.050] --- systematic experimental approach for identifying PPIs

+ our disease-gene association study ([hetio](http://het.io/disease-genes/downloads/)) [@10.1371/journal.pcbi.1004259] -- interactions from [iRefIndex](http://irefindex.org/wiki/index.php?title=iRefIndex), which compiles records from primary databases, processed using [ppiTrim](http://www.ncbi.nlm.nih.gov/CBBresearch/Yu/downloads/ppiTrim.html) [@10.1093/database/bar036].

Suggestions for other resources are welcome.","17",2015-07-02,2015-07-02,2,1103,"base.profile","Daniel","Himmelstein","dhimmel"
"514","comments","rephetio","2015-07-02T00:47:21.811Z",17,"# Methods for the *Incomplete Interactome* PPI catalog

*Here, we reproduce the methods section from the [supplement](http://www.sciencemag.org/content/suppl/2015/02/18/347.6224.1257601.DC1/Menche_SM.pdf) of the Incomplete Interactome publication [@10.1126/science.1257601] describing how their PPI catalog was constructed:*

In building the interactome, we rely only physical protein interactions with experimental support, hence we do not include interactions extracted from gene expression data or evolutionary considerations. In order to obtain an interactome as complete as currently feasible, we combine several databases with various kinds of physical interactions:

1. **Regulatory interactions**: We use the TRANSFAC database [@10.1093/nar/gkg108] that lists interactions derived from the presence of a transcription factor binding site in the promoter region of a certain gene. The resulting network consists of 271 transcription factors regulating 564 genes via 1,335 interactions.
+ **Binary interactions**: We combine several yeast-two-hybrid high-throughput datasets [@10.1016/j.cell.2014.10.050 @10.1038/nmeth.1280 @10.1016/j.cell.2005.08.029 @10.1038/nmeth.1597 @10.1038/nature04209 @55] with binary interactions from IntAct [@10.1093/nar/gkp878] and MINT databases [@10.1093/nar/gkp983]. The sum of these data sources yields 28,653 interactions between 8,120 proteins. Note that IntAct and MINT provide interactions derived from both literature curation and direct submissions. 
+ **Literature curated interactions**: These interactions, typically obtained by low throughput experiments, are manually curated from the literature. We use IntAct [@10.1093/nar/gkp878], MINT [@10.1093/nar/gkp983], BioGRID [@10.1093/nar/gkq1116] and HPRD [@10.1093/nar/gkn892], resulting in 88,349 interactions between 11,798 proteins.
+ **Metabolic enzyme-coupled interactions**: Two enzymes are assumed to be coupled if they share adjacent reactions in the KEGG and BIGG databases. In total, we use 5,325 such metabolic links between 921 enzymes from [@10.1073/pnas.0802208105].
+ **Protein complexes**: Protein complexes are single molecular units that integrate multiple gene products. The CORUM database [@10.1093/nar/gkp914] is a collection of mammalian complexes derived from a variety of experimental tools, from co-immunoprecipitation to co-sedimentation and ion exchange chromatography. In total, CORUM yields 2,837 complexes with 2,069 proteins connected by 31,276 links.
+ **Kinase network (kinase-substrate pairs)**: Protein kinases are important regulators in different biological processes, such as signal transduction. PhosphositePlus [@10.1093/nar/gkr1122] provides a network of peptides that can be bound by kinases, yielding in total 6,066 interactions between 1,843 proteins.
+ **Signaling interactions**: The dataset from [@10.1126/scisignal.2001699] provides 32,706 interactions between 6,339 proteins that integrate several sources, both high-throughput and literature curation, into a directed network in which cellular signals are transmitted by proteins-protein interactions.

The union of all interactions obtained from (i)-(vii) yields a network of 13,460 proteins that are interconnected by 141,296 physical interactions. Note that we treat the interactome as an undirected network (see Section 2.3 for a discussion of the impact of directionality). The interactome is approximately scale-free (Figure S1a) and shows other typical characteristics as observed previously in many other biological networks [@10.1103/RevModPhys.74.47 @10.1137/S003614450342480], such as high clustering and short pathlengths (Figure S1c)

[@55]: ""Center for Cancer Systems Biology, Hi-2012 prepublication""","17",2015-07-02,2015-07-02,2,3727,"base.profile","Daniel","Himmelstein","dhimmel"
"515","comments","rephetio","2015-07-09T20:59:26.433Z",17,"# GWAS associations for all DO diseases

We repeated the above analysis for all diseases, not just DO slim diseases. The EFO terms added to the GWAS Catalog by the EBI are still converted to DO terms: therefore, associations whose EFO terms are not cross-referenced in the DO are omitted.

In total, the dataset contains 1447 high-confidence primary gene-disease associations. Counting both confidence levels, associations exist for 124 diseases and 4142 genes.

Download the [compiled gene associations](https://github.com/dhimmel/gwas-catalog/blob/a5aa4910708a3995501ebe4136d8b9d601463fa1/data/gene-associations.tsv) or see the [repository](https://github.com/dhimmel/gwas-catalog/tree/a5aa4910708a3995501ebe4136d8b9d601463fa1) for more information.","17",2015-07-09,2015-07-09,2,757,"base.profile","Daniel","Himmelstein","dhimmel"
"516","comments","rephetio","2015-07-10T18:15:03.724Z",17,"Last week a seminal paper on tissue-specificity of the transciptome, proteome, knowledgeome, and literome was published [@10.7717/peerj.1054], along with an [accompanying webapp](http://tissues.jensenlab.org/). This study is notable for intelligently merging expression studies and performing informative comparisons between studies and data types.

We have already [processed Bgee](http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#8) for anatomy-specific transcription. Compared to Bgee, the anatomical coverage of TISSUES is much lower, but edges are likely of higher quality. Therefore I think Bgee and TISSUES will be complimentary. Additionally, TISSUES contains other measures of tissue-specific gene expression such as UniProtKB, proteomics, and literature mining. We are particularly interested in including these data sources.

Our first step is to retrieve the data for each of the four methods. We want entities encoded using identifiers rather than names or symbols. We will need to pick a confidence threshold. And for each method, we would like the broadest tissue coverage permitted by that method. Advice appreciated!","17",2015-07-10,2015-07-10,2,1164,"base.profile","Daniel","Himmelstein","dhimmel"
"517","comments","rephetio","2015-07-10T19:06:19.048Z",17,"# SciPy 2015

Some incredible presentations and materials are being unleashed at the [SciPy 2015 conference](http://scipy2015.scipy.org/) as I type. The full [playlist of presentations](https://www.youtube.com/playlist?list=PLYx7XA2nY5Gcpabmu61kKcToLz0FapmHu) is on YouTube.

One excellent presentation is *State of the Stack* ([video](https://youtu.be/5GlNDD7qbP4), [slides](https://speakerdeck.com/jakevdp/the-state-of-the-stack-scipy-2015-keynote)) by Jake Vanderplas, which details the latest developments in python tools for data science.

Some additional projects of interest are:

+ [xray](https://youtu.be/X0pAhJgySxk)
+ [beaker notebook](https://youtu.be/iMPfLz6kKv8)","17",2015-07-10,2015-07-10,2,685,"base.profile","Daniel","Himmelstein","dhimmel"
"518","comments","rephetio","2015-07-13T21:36:11.923Z",17,"# Human Interaction Database

The Human Interaction Database (HID) 2014 [release](http://interactome.dfci.harvard.edu/H_sapiens/index.php?page=download) [@10.1016/j.cell.2014.10.050] contained two PPI datasets:

+ `HI-II-14` -- 13,944 interactions -- proteome-scale map of the human binary interactome network generated by systematically screening Space-II
+ `Lit-BM-13` -- 11,045 interactions -- high-quality recurated literature binary interactions extracted from 7 public repository in 2013

We [compared](https://github.com/dhimmel/ppi/blob/77862798448c4272c55e9c718323a3ec5d8db571/compile-PPIs.ipynb) interactions from HID to interactions from the Incomplete Interactome (II). We found that `HI-II-14` was a subset of `II_binary`. However, only 78.2% of `Lit-BM-13` was included in `II_literature`.

*To better understand `Lit-BM-13`, we have added the relevant sections of the paper [supplement](http://www.sciencedirect.com/science/MiamiMultiMediaURL/1-s2.0-S0092867414014226/1-s2.0-S0092867414014226-mmc1.pdf/272196/html/S0092867414014226/2b892ecda8f249667d75023be6d13c7b/mmc1.pdf) below, omitting the ""assignment of experimental method"" sections [@10.1016/j.cell.2014.10.050]:*

**Literature datasets:** We generated two datasets from literature-curated protein-protein interactions. A first dataset was generated in 2010 and used for all experiments, concomitantly with our mapping experiment, and a second dataset was extracted in 2013 to provide an updated version for all computational analyses.

**Obtaining the Lit-2010 dataset:** The Lit-2010 dataset extracts human protein-protein interactions (PPIs), annotated through December 2010, from seven primary source databases: BIND [@10.1093/nar/gkg056], BioGRID [@10.1093/nar/gks1158], DIP [@10.1093/nar/gkh086], HPRD [@10.1093/nar/gkn892], MINT [@10.1093/nar/gkr930], IntAct [@10.1093/nar/gkr1088] and PDB [@10.1093/nar/28.1.235]. For each reported PPI the interacting proteins were mapped to UniProt protein identifiers and then converted to NCBI Entrez gene ID pairs using an ID mapping table downloaded on January 12, 2012 from uniprot.org. Information about the specific publications reporting each interaction was retained and reported interactions that did not have an associated PubMed ID (PMID) were not included in the Lit-2010 dataset.

**Identification of binary interactions:** We divided Lit-2010 into the PPIs reported by
systematic high-throughput binary human interactome mapping efforts [@10.1038/nature04209 @10.1016/j.cell.2005.08.029 @10.1038/nmeth.1280] and those detected in small- or medium-scale experiments. A small number of PPIs that had been detected in both systematic and other studies could appear in both datasets. Removing the PPIs only seen in systematic studies resulted in a dataset of 56,743 human PPIs.

Next we attempted to distinguish binary interactions (direct biophysical contact between two proteins) [@10.1002/pmic.201100598 @10.1002/pmic.201100563] from indirect associations (associations between two proteins that are in the same complex, but may or may not directly interact) [@10.1016/j.sbi.2013.02.008]. We evaluated each experimental interaction detection method in the PSI-MI 2.5 and classified them as binary, that is, primarily detects binary interactions, versus indirect, that is, primarily detects association of proteins within a complex (Table S1C). Where an experimental method could be viewed as either, depending on the specific experimental implementation then the method was conservatively classified as indirect. Fewer methods were classified as binary here than in previous [@10.1038/nmeth.1284 @10.1126/science.1158684] or parallel [@10.1186/1752-0509-6-92] efforts to ensure the highest confidence binary Lit dataset possible.

After parsing all PPI data from the source databases we obtained a binary human
dataset of 13,962 PPIs that contained at least one piece of binary evidence supporting each PPI (there could be other pieces of experimental evidences that were either binary or indirect) and a non-binary dataset containing 42,781 PPIs for which none of the experimental methods are binary (Lit-NB-10).

A paper curated independently by two or more different PPI databases is commonly annotated to different PSI-MI terms, generally to terms of different depth on the same branch of the PSI-MI ontology tree [@10.1093/database/baq026 @10.1038/nbt.1867]. If not corrected for, these annotations would count as two or more pieces of evidence for the PPI, when actually there is only one piece of supporting evidence. For example, a yeast two-hybrid experiment might be annotated to the deeper term “two hybrid prey pooling approach” (MI:1112) by one PPI database but to the parent term “two hybrid” (MI:0018) by another database; a coimmunoprecipitation (co-IP) experiment might be annotated to the deeper term “anti-tag coimmunoprecipitation” (MI:0007) by one database but to the parent term “affinity chromatography technology” (MI:0004) by another. To compensate for variability in the annotated methods, when the same paper with the same PMID had different MI terms in two databases, we reassigned the deeper term “up” to the corresponding parent binary or nonbinary term on the same PSI-MI branch. In the examples given, the two Y2H annotations collapse to the single ID MI:0018, while the two co-IP annotations collapse to the single ID MI:0004.

The binary human dataset was next separated into “binary multiple” (Lit-BM-10) (Table S1A), containing all interactions supported by two or more pieces of experimental evidence, at least one of which was binary (4,906 PPIs); versus “binary single”, containing all interactions supported by exactly one piece of binary experimental evidence (Lit-BS-10) (9,056 PPIs).

**Updating the Lit dataset to 2013:** To construct Lit-2013 (Figure S1B and Table S1B) we downloaded, on August 5, 2013, the updated curated PPI content of the same seven PPI databases used for Lit-2010.","17",2015-07-13,2015-07-13,2,5988,"base.profile","Daniel","Himmelstein","dhimmel"
"519","comments","rephetio","2015-07-13T23:21:46.024Z",17,"# *hetio* interactions

Previously, we used the following method to catalog protein interactions [@10.1371/journal.pcbi.1004259]:

> Physical protein-protein interactions ([S8 Data](http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004259#pcbi.1004259.s020)) were extracted from iRefIndex 12.0, a compilation of 15 primary interaction databases [@10.1186/1471-2105-9-405]. The iRefIndex was processed with ppiTrim to convert proteins to genes, remove protein complexes, and condense duplicated entries [@10.1093/database/bar036].

The method contributed 97,938 interactions to our network of protein-coding genes. For this project, we converted these interactions to entrez genes. Prior to filtering for coding genes, 98,119 interactions were in the hetio dataset.

The hetio interactions overlapped most with `Lit-BM-13`, `II_literature`, and `II_signaling` ([notebook](https://github.com/dhimmel/ppi/blob/919264e834a95bf8724c7177b8657af9de8622fd/compile-PPIs.ipynb)).","17",2015-07-13,2015-07-13,2,998,"base.profile","Daniel","Himmelstein","dhimmel"
"520","comments","rephetio","2015-07-14T19:30:52.174Z",17,"We have [adopted a literature mining scheme](http://thinklab.com/d/67) for term relations based on cooccurrence of MeSH topics in MEDLINE. Of [DO Slim](http://thinklab.com/discussion/unifying-disease-vocabularies/44#144) diseases, 133 out of 137 have a MeSH cross-reference. For each disease, we identified all studies assigned that topic and then computed pairwise cooccurrences ([notebook](https://github.com/dhimmel/medline/blob/54a621d7fc360a2ad623d2cb3180f60485aff37f/diseases.ipynb), [tsv](https://github.com/dhimmel/medline/blob/54a621d7fc360a2ad623d2cb3180f60485aff37f/data/disease-disease-cooccurrence.tsv)).

Since disease topics seemed averse to cooccurrence, we did not enforce the major topic filter. Even so, diseases cooccurred less than would be expected by chance. This makes sense given that papers often focus on a single disease only but means that our p-values are likely conservative.","17",2015-07-14,2015-07-14,2,908,"base.profile","Daniel","Himmelstein","dhimmel"
"521","comments","rephetio","2015-07-14T19:32:41.490Z",17,"# Disease--Disease Relationships

We computed disease similarities based on MEDLINE cooccurrences. Refer to [this discussion](http://thinklab.com/discussion/disease-similarity-from-medline-topic-cooccurrence/93) for more information.","17",2015-07-14,2015-07-14,2,235,"base.profile","Daniel","Himmelstein","dhimmel"
"522","comments","rephetio","2015-07-14T19:55:24.483Z",17,"[DOAF](http://doa.nubic.northwestern.edu/pages/search.php), the Disease Ontology Annotation Framework [@10.1371/journal.pone.0049686], provides gene--disease relationships extracted from GeneRIF. [GeneRIF](http://www.ncbi.nlm.nih.gov/gene/about-generif) is a crowdsourced database of functional gene annotations that is integrated into NCBI's Entrez Gene. DOAF describes the resources [@10.1371/journal.pone.0049686]:

> GeneRIF contains brief textual descriptions of genes (up to 250 characters) and are available from the NCBI [@10.1186/1471-2105-9-s3-s9], [@10.1142/9789812772435_0026]. Every GeneRIF entry is associated with a PubMed ID, providing published evidence for each description.

## Processing

We converted the `IDMappings.txt` [data release](http://doa.nubic.northwestern.edu/pages/download.php) into a tsv with a single row per disease--gene pair ([notebook](https://github.com/dhimmel/doaf/blob/bbe1c326aa385416e36d02b144e89e2b99e700b6/doaf.ipynb), [tsv](https://github.com/dhimmel/doaf/blob/bbe1c326aa385416e36d02b144e89e2b99e700b6/data/doaf.tsv)). Genes are in entrez identifiers and diseases are DO terms.

Overall, we identified 50,863 gene--disease functional annotations.","17",2015-07-14,2015-07-14,2,1203,"base.profile","Daniel","Himmelstein","dhimmel"
"523","comments","rephetio","2015-07-14T21:45:53.225Z",17,"## Latest indication catalog

We have [completed](http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#191) a first-draft of our indication catalog. Recently, we updated the catalog with some [fresh](http://thinklab.com/discussion/disease-ontology-feature-requests/68#221) disease cross-references. The latest catalog is now online ([webpage](https://cdn.rawgit.com/dhimmel/indications/7c2b17f463babafcf4ec441e720b831340b186fe/merge.html#indication-table), [tsv](https://github.com/dhimmel/indications/blob/7c2b17f463babafcf4ec441e720b831340b186fe/data/indications.tsv), [repository](https://github.com/dhimmel/indications/tree/7c2b17f463babafcf4ec441e720b831340b186fe)).

The catalog includes 1,388 high-confidence indications from four resources -- MEDI-HPS [@10.1136/amiajnl-2012-001431], ehrlink [@10.1136/amiajnl-2012-000852], LabeledIn [@10.1016/j.jbi.2014.08.004 @10.1093/database/bav016], and PREDICT [@10.1038/msb.2011.26] -- and 1,114 low-confidence indications from MEDI-LPS [@10.1136/amiajnl-2012-001431]. We are primarily concerned about the high-confidence associations which connect 108 diseases from [DO Slim](http://thinklab.com/discussion/unifying-disease-vocabularies/44#144) and 744 small molecules from [Drugbank Slim](http://thinklab.com/discussion/unifying-drug-vocabularies/40#192).

## Problematic indications

The source databases have a loose definition of indication -- symptomatic treatments are often considered indications. For example, a narcolepsy drug approved for MS-induced fatigue is indicated for MS in our catalog. However, we are primarily interested in disease-modifying therapies. Since our method trains itself from this catalog, our predictions will recapitulate the types of indications included.

## Seeking an expert

We are **seeking an expert physician** to manually review our 1,388 high-confidence indications and identify the disease-modifying subset. Since the classification is *unlikely* to be straightforward, we are looking for someone who can conceptualize the task from a high-throughput systems pharmacology perspective. We are happy to offer project authorship for a job well done.","17",2015-07-14,2015-07-14,2,2189,"base.profile","Daniel","Himmelstein","dhimmel"
"524","comments","rephetio","2015-07-14T21:55:43.335Z",17,"# Expert curation of the indication catalog

We have decided to filter our catalog for disease-modifying indications and are seeking an expert curator to assist with this task. We [started a new discussion](http://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95) for this next step.

@allisonmccoy, have you thought more about releasing the data from your recent publication [@10.4338/ACI-2015-01-RA-0010]? If you can do this in the next week or two, we would be thrilled to include this data. Otherwise we will have to move ahead with only the [ehrlink data](http://thinklab.com/discussion/extracting-indications-from-the-ehrlink-resource/62) from your initial study [@10.1136/amiajnl-2012-000852].","17",2015-07-14,2015-07-14,2,757,"base.profile","Daniel","Himmelstein","dhimmel"
"525","comments","rephetio","2015-07-15T00:58:47.066Z",17,"# Signaling PPI

*The incomplete interactome paper includes interactions from a signaling study [@10.1126/scisignal.2001699]. We report the sources of this `HPPI1` network from the original paper's [supplement](http://stke.sciencemag.org/content/sigtrans/suppl/2011/09/01/4.189.rs8.DC1/4_rs8_SM.pdf):*


**Table S3**: Human PPI interaction data sets used to construct the HPPI1 network. A comprehensive HPPI1 network was created by unifying the data sets listed. Name of the data set, publication reference, number of proteins and number of interactions in the data set (after mapping to NCBI Entrez GeneID) are given. 

| PPI Data sets | Reference | Proteins | Interactions |
|--------------------|---------------|----------|--------------|
| Human Protein Reference Database V7.0 | [@10.1007/978-1-60761-232-2_6] | 9305 | 35021 |
| Genome-wide Y2H screen and literature-derived PPI data | [@10.1038/nature04209] | 3024 | 6221 |
| Y2H screen for inherited ataxia and literature-derived PPI data | [@10.1016/j.cell.2006.03.032] | 2909 | 5440 |
| Genome-wide Y2H screen | [@10.1016/j.cell.2005.08.029] | 1699 | 3150 |
| Y2H PPIs | This study | 1126 | 2626 |
| Mouse signaling PPI data from AfCS | http://www.signalinggateway.org/ | 857 | 1004 |
| Network for Smad signaling | [@10.1101/gr.2334104] | 623 | 874 |
| PPIs of proteins in MHC class III region and mRNA decay | [@10.1101/gr.2122004 @10.1016/S0888-7543(03)00235-0] | 300 | 376 |
| Network of nuclear receptors | [@10.1074/mcp.M400169-MCP200] | 134 | 288 |
| Huntingtin’s disease PPI network | [@10.1016/j.molcel.2004.09.016] | 64 | 156 |
| PPIs between KIAA proteins | [@10.1101/gr.406902] | 94 | 84 |
| Total |  | 9832 | 39641 |","17",2015-07-15,2015-07-15,2,1708,"base.profile","Daniel","Himmelstein","dhimmel"
"526","comments","rephetio","2015-07-15T18:31:30.951Z",17,"# Migrating to owltools

We are in the decade of the ontology: the pace of development and growth of this field is incredible. Therefore, I would like to outsource the ontology reasoning and inference to established software projects, namely [owltools](https://github.com/owlcollab/owltools).

The first step will be to load GO with `owltools http://purl.obolibrary.org/obo/go.owl`. Beyond this step I am stuck and haven't found sufficient documentation. @chrismungall or @fbastian perhaps you could help me with the below queries or point me to a good tutorial:

1. **Adding annotations**: we would like to add human gene annotations to GO terms.
2. **Propagating annotations**: we would like to propagate annotations up `is_a` and `part_of` edges. Negative (`NOT`) annotations should short-circuit annotation propagation. 
3. **Filter overly broad terms**: Remove the ""[do not annotate](http://geneontology.org/ontology/subsets/gocheck_do_not_annotate.obo)"" terms for GO.
4. **Output:** Write the propagated annotations to a text file

If it's not possible to perform all of these steps in one command, then we can work on a piecemeal approach.","17",2015-07-15,2015-07-15,2,1157,"base.profile","Daniel","Himmelstein","dhimmel"
"527","comments","rephetio","2015-07-17T00:15:58.471Z",111,"You should definitely check with Chris, GO annotation/propagation is not really my area of expertise. And it is indeed possible to do a lot of things in a single command using owltools. ","111",2015-07-17,2015-07-17,2,186,"base.profile","Frederic","Bastian","fbastian"
"528","comments","rephetio","2015-07-17T00:21:40.270Z",111,"Actually, for some mappings we needed to request for new terms in Uberon, e.g.: https://github.com/obophenotype/uberon/issues/725

Things will be slow until mid-August on our side. ","111",2015-07-17,2015-07-17,2,183,"base.profile","Frederic","Bastian","fbastian"
"529","comments","rephetio","2015-07-28T19:29:02.651Z",121,"Have you seen [Human Interactome](http://interactome.dfci.harvard.edu/H_sapiens/) out of Harvard.  I used them for my [PPI work for CNVs in GWAS for Autism](http://www.nature.com/ncomms/2014/140606/ncomms5074/full/ncomms5074.html) and worked out quite well.  They seem to have at least some of the ones you have already listed, although I think your list looks more extensive.  You want to be careful of integrating genome-wide PPI (i.e. Y2H) vs targeted PPI datasets.  It may mess up interpreting the statistics if the evidence for PPI is biased vs genome-wide.","121",2015-07-28,2015-07-28,2,562,"base.profile","Dexter","Hadley","idrdex"
"530","comments","rephetio","2015-07-28T21:14:07.077Z",17,"A 2011 study [@10.1126/scitranslmed.3001318] introduced the idea of large-scale drug repurposing based disease expression profiles. However, the field has faced a great impediment: results from differential expression experiments are only available on a *per study* basis. Our project requires a consensus signature (that aggregates many experiments) for *each of 137* diseases.

A forthcoming project called [STARGEO](http://dev.stargeo.io/) aims to provide disease-specific expression signatures on a broad scale. The webapp crowdsources [GEO](http://www.ncbi.nlm.nih.gov/geo/) [@10.1093/nar/gks1193 @10.1093/nar/30.1.207] annotation and performs case-control analyses based on user queries. The following video introduces the project:

![:youtube](61lw_d6Eoik)

We now join forces with STARGEO and welcome its creator @idrdex to the team! The first stage will be tagging all GEO datasets containing [DO Slim](http://thinklab.com/discussion/unifying-disease-vocabularies/44#144) diseases. STARGEO's current DO Slim coverage is [available here](https://github.com/dhimmel/stargeo/blob/master/data/DO-tag-mapping.tsv).","17",2015-07-28,2015-07-28,2,1124,"base.profile","Daniel","Himmelstein","dhimmel"
"531","comments","rephetio","2015-07-28T21:32:56.762Z",17,"@idrdex, we're referring to this data as the Human Interaction Database (HID) and found that the systematic datasets were wholly included in the Incomplete Interactome (`II`) data ([comment](#323), [notebook](https://github.com/dhimmel/ppi/blob/77862798448c4272c55e9c718323a3ec5d8db571/compile-PPIs.ipynb)).

You are right that once we introduce PPIs from targeted or curated analyses, we have introduce knowledge bias. While we prefer systematic data, we [decided to incorporate](http://thinklab.com/discussion/text-as-a-resource-for-network-population/48#120) biased knowledge. We will likely perform a parallel analysis on an network built from only unbiased data sources. For this analysis, we'll use the Y2H datasets used in your autism study [@10.1038/ncomms5074].","17",2015-07-28,2015-07-28,2,772,"base.profile","Daniel","Himmelstein","dhimmel"
"532","comments","rephetio","2015-07-28T22:03:29.420Z",112,"#Similarities between associated genes in drug compounds

[Notebook](https://github.com/sabrinalchen/drugbank-similarity/blob/912848e1d13fc0648ae33e022308d1da719f5a1a/similarities.ipynb)

##Objective: 
We wanted to visualize the similarities among the associated genes for drug pairs in each of the four types of drug-bank interaction categories. To do so we extracted data from various sources to compile drugs with associated genes and the compound similarities between pairs of drugs compounds. 

##The Data: 
We extracted [DrugBank-protein relationships](https://raw.githubusercontent.com/dhimmel/drugbank/3e87872db5fca5ac427ce27464ab945c0ceb4ec6/data/proteins.tsv) which lists drug types and associated genes, as well as [compound similarity data](http://nbviewer.ipython.org/github/dhimmel/drugbank/blob/9eb1e15ada5e6579e5aea1cae784c10602037b05/similarity.ipynb) which gives a value between zero and one based on the chemical similarity of a pair of drugs. 

##Jaccard Values and Initial Visualization:
Our first step was to create a dataframe with combination of compound pairs. Each compound is associated with a certain number of genes and we were able to define a Jaccard function to calculate the Jaccard value of the overlapping genes in each compound pair. It was noted – as expected -- that the wide majority of the compound pairs had no similar genes, with a Jaccard value of zero. The drug-protein interactions were then categorized into four subgroups: carrier, enzyme, target and transporter. The similarity data was added for each compound pair. All five categories were graphed on a Seaborn PairGrid using a histogram on the univariate level and a hexbin scatterplot on the bivariate level.

##Analysis of PairGrid Jaccard Value Visualization:
The data for each of the graphs did indeed center around zero, meaning that most compounds had no genes in common. In fact, the data was so skewed in the histogram that we needed to use logarithmic bins. Though the data was skewed right towards zero and dipped around 0.9 for each category, the histograms showed that there was also significant data for the Jaccard value of one, so that the graphs had U-shaped figures. This means that there are some compound pairs with all genes in common. In terms of the hexbin scatterplots, the darkest areas were zero and one, which reflected what was observed in the histograms. One other interesting trend to note are that for carrier and transporter, the data also concentrated around 0.5 and 0.33. 

![](https://raw.githubusercontent.com/sabrinalchen/drugbank-similarity/ad3edac94b5c8d00e81395095468c7cce621e9d6/figure/similarity.png)
#####Figure 1: Compares Jaccard values for each drug-protein interaction category and chemical similarity

##Mean Jaccard Pointplot:
We used the Seaborn [Pointplot](https://github.com/sabrinalchen/drugbank-similarity/blob/22bf54916d14b933be846bf52ad93237d54394c9/figure/similarity_mean.png) to visualize the data in a different way. The means of Jaccard values were calculated for each of the four protein-interaction categories. With the similarity on the x-axis and the mean of Jaccard on the y-axis, it was concluded that the mean Jaccard peaked when the similarity was about 0.8 to 0.9. The general upwards trend was expected, as increased compound similarity should indicate an increase of gene overlap. By far, the target category had the most dramatic increase in mean Jaccard value. Though it started with a pretty flat mean Jaccard value at zero, it increased rapidly to hit a mean Jaccard value of nearly 0.5 at similarity=0.8. 

![](https://raw.githubusercontent.com/sabrinalchen/drugbank-similarity/912848e1d13fc0648ae33e022308d1da719f5a1a/figure/similarity_mean.png)
#####Figure 2: Demonstrates relationship between chemical similarity of compounds and the mean Jaccard values

##Similarity Threshold:
The final visualization we created was a series of complex barplots to compare a similarity threshold among the four category groups. The similarity values were replaced with zero or one depending on whether the original value was greater or less than 0.5. Next, contingency tables were created for each category so that relative frequencies could be calculated. 

The visualization showed that similar compounds are likely to have common targets. For example, if two compounds shared a transporter, they also shared a carrier 25% of the time, compared to 5% of the time if they did not.  This trend continued throughout each of the bar graphs and was particularly notable in the comparisons with similarity. Note that the y-axis’s are labeled differently for easier reading. 

![](https://raw.githubusercontent.com/sabrinalchen/drugbank-similarity/ad3edac94b5c8d00e81395095468c7cce621e9d6/figure/output.png)
#####Figure 3: Illustrates similarity threshold among the drug-protein interaction categories and chemical similarity","112",2015-07-28,2015-07-28,2,4915,"base.profile","Sabrina","Chen","sabrinachen"
"533","comments","rephetio","2015-07-29T17:06:14.274Z",17,"# Migration cancelled

In the interest of time, we did not switch to owltools. The OWL ecosystem codebases rely on a completely different stack than our current python workflow, and the documentation is often incomplete. We [asked](https://github.com/owlcollab/owltools/issues/129) our usage questions on GitHub and will consider migrating in the future with clearer guidance.

# Updated annotations framework

We revamped the analysis behind our [user-friendly GO annotation utility](http://git.dhimmel.com/gene-ontology/) [@10.5281/zenodo.21711].

We made the following changes:

+ an option to discard annotations without experimental evidence
+ propagation along `part_of` (as well as `is_a`) relationships
+ direct annotations short-circuit the propagation of conflicting annotations. This occurs only when negative (`NOT`) and positive annotations conflict.
+ exclude terms in the `goantislim_grouping`, `gocheck_do_not_annotate`, or `gocheck_do_not_manually_annotate` subsets

We removed the ""protein-coding genes only"" option and made a single download with gene identifiers and symbols.","17",2015-07-29,2015-07-29,2,1110,"base.profile","Daniel","Himmelstein","dhimmel"
"534","comments","rephetio","2015-07-30T20:42:18.764Z",17,"# Phenotype--Disease Associations

A recent paper titled ""The Human Phenotype Ontology: Semantic Unification of Common and Rare Disease"" [@10.1016/j.ajhg.2015.05.020] constructed a catalog of 132,006 phenotypic annotations for common diseases.

The approach relied on text mining of PubMed abstracts. Abstracts were annotated with diseases using MEDLINE topics. Phenotype annotation, however, relied on concept recognition. Thus the method appears to produce similar results to our [disease--symptom MEDLINE approach](http://thinklab.com/discussion/mining-knowledge-from-medline-articles-and-their-indexed-mesh-terms/67#2). The difference being that their approach achieves greater phenotype/symptom coverage by substituting manual topic annotation with concept recognition.

The data is [online](http://pubmed-browser.human-phenotype-ontology.org/hp_common_annotations_all.tab). The column names for the dataset, provided by Tudor Groza in personal communication, are:

* MeSH ID
* MeSH descriptor
* Disease Ontology ID
* HPO ID
* HPO label
* Ranking score of the HPO concept in the context of the MeSH term - this is a modified version of TF-IDF (as per the paper)
* Number of Publications containing this association
* 5 PMIDs (of the total number listed above) referring to this association

I am still slightly unclear on what a phenotype means in the context of human disease, but we will keep this dataset on hand.","17",2015-07-30,2015-07-30,2,1438,"base.profile","Daniel","Himmelstein","dhimmel"
"535","comments","rephetio","2015-07-31T18:00:29.433Z",17,"A recent study [@10.1038/ng.3314] found disease-associated genes are mildly predictive of effective drug targets, which is in line with the findings of a preceding but less rigorous study [@10.1038/nbt.3183].

The data supplement for  ""The support of human genetic evidence for approved drug indications"" contains two potentially useful resources:

**Gene-disease associations** from GWAS and OMIM. Compared to [our approach](http://dx.doi.org/10.15363/thinklab.d80) for converting from SNP to gene, their method incorporates experimental genomic evidence.

**Disease-target combinations** extracted from [Pharmaprojects](https://citeline.com/products/pharmaprojects/), a commercial database. As per the paper: 
> A target was defined as successful in treating an indication if a drug targeting that gene product was approved for the corresponding indication in the United States or the European Union, as annotated in Pharmaprojects.

Unfortunately, this dataset is a step abstracted from the *real deal* (separate databases of drug targets and drug indications).

We performed some basic manipulation of their data, which is [available here](https://github.com/dhimmel/nelson/blob/af1066df8f8d2b599869864a2a5d7935cf67c1ba/process.ipynb).","17",2015-07-31,2015-07-31,2,1250,"base.profile","Daniel","Himmelstein","dhimmel"
"536","comments","rephetio","2015-07-31T20:43:01.711Z",82,"What do you think about implementing high-throughput data from RNA interference screenings? RNAi is an alternative, more precise way to control gene expression and it should have less off-target effects compared to pharmacological inhibition.","82",2015-07-31,2015-07-31,2,242,"base.profile","Alessandro","Didonna","alessandrodidonna"
"537","comments","rephetio","2015-08-03T23:26:00.170Z",17,"# Set of anatomy nodes

We have settled on 402 Uberon terms to use as our anatomy vocabulary ([tsv](https://github.com/dhimmel/uberon/blob/134f23479186abba03ba340fc6dc90e16c781920/data/hetio-slim.tsv), [notebook](https://github.com/dhimmel/uberon/blob/134f23479186abba03ba340fc6dc90e16c781920/process.ipynb)).

We included terms that met the following conditions:

+ were in the `uberon_slim` subset.
+ were not in the `non_informative`, `upper_level`, or `grouping_class` subsets. See this related [GitHub issue](https://github.com/obophenotype/uberon/issues/1133).
+ contained a MeSH cross-reference
+ were human-relevant based on the [no negative evidence](#12) standard.

We chose a restrictive subset of Uberon terms because the vast extent of tissue-specific gene expression edges can become computationally troubling. We did not include cell types from the Cell Ontology because this ontology lags behind Uberon in terms of subset assignments, cross-references, and documentation.","17",2015-08-03,2015-08-03,2,998,"base.profile","Daniel","Himmelstein","dhimmel"
"538","comments","rephetio","2015-08-03T23:33:50.805Z",112,"#Relationship between transcriptional and chemical similarity

[Notebook](https://github.com/sabrinalchen/drugbank-similarity/blob/master/L1000.ipynb)

##Objective:
Determine the correlation and visualize the relationship between L1000 transcriptional and chemical compound similarity.

##The data:
We extracted [L1000 perturbation data](
http://files.figshare.com/2166122/consensus_drugbank.tsv.gz) which lists drug types with perturbation IDs and [similarity data](http://nbviewer.ipython.org/github/dhimmel/drugbank/blob/9eb1e15ada5e6579e5aea1cae784c10602037b05/similarity.ipynb) which gives a value between zero and one based on the chemical similarity of a pair of drugs. 

##Jointplot comparing chemical and transcriptional similarities:
From the imported L1000 perturbation data, we calculated the spearman correlation values for each combination of pair of drugs. This correlation value was labeled as the ""transcriptional similarity."" This value was graphed against the imported similarity data for each drug pair. From the Jointplot, (which plots both bivariate data on a hexbin plot and univariate data on a histogram,) we concluded that there was no strong correlation visually. The darkest parts of the hexbin graph were grouped at the bottom left of the grid and the graph showed no real positive pattern. Nevertheless, the graph had an extremely small p-value, indicating significance, and leading to a small effect. 

![](https://raw.githubusercontent.com/sabrinalchen/drugbank-similarity/master/figure/similarity2.png)
#####Figure 1: Compares transcriptional similarity for each drug pair and chemical similarity

##Rounded chemical similarity pointplot:
To visualize the correlation a different way, the chemical similarity data was rounded off to the nearest tenth and the mean transcriptional value was found for each subset. This data was graphed on a pointplot which demonstrated a clear positive correlation, especially when the chemical similarity reached 0.5. After this point, the correlation was even stronger, increasing steadily as the chemical similarity reached 1.0. It should be noted that as the chemical similarity increased, there were less and less data points to be used in graphing. In fact, the last data point where chemical similarity was 1.0 had only a single data point (as seen in the table of rounded values shown in the cell before the pointplot.)

![](https://raw.githubusercontent.com/sabrinalchen/drugbank-similarity/master/figure/similarity_mean2.png)
#####Figure 2: Demonstrates relationship between chemical similarity of compounds and the mean transcriptional similarity values","112",2015-08-03,2015-08-03,2,2651,"base.profile","Sabrina","Chen","sabrinachen"
"539","comments","rephetio","2015-08-04T18:40:15.210Z",17,"Great work @sabrinachen! Your analysis reveals many interesting findings.

First, chemical similarity is a strong indicator that two compounds share a target (Figure 2). One of the most successful target prediction algorithms, named the Similarity Ensemble Approach (SEA) [@10.1038/nature08506], is based on this very observation. Our data shows an enrichment of shared protein interactions above a chemical similarity threshold of 0.5. Interestingly, when binarizing chemical similarity scores, SEA also chose a cutoff of 0.5 ([source](http://salilab.org/~nkhuri/files/systems-pharmacology-lecture4-01262015.pdf#page=19)).

Second, when two proteins share proteins of a specific category, they are more likely to share proteins of other categories (Figure 3). For example, when two compounds share a transporter, they have a 14% chance of sharing an enzyme, compared to 3% otherwise. This trend applies to all categories but is most pronounced between chemical similarity and target similarity.

Finally, it would be interesting to know how many compound pairs were included for each chemical similarity bin in Figure 2.","17",2015-08-04,2015-08-04,2,1127,"base.profile","Daniel","Himmelstein","dhimmel"
"540","comments","rephetio","2015-08-04T19:13:17.098Z",17,"Nice analysis. Chemical similarity appears to be a *weak* predictor of transcriptional similarity (Figure 1, $$\rho = 0.02, p = 10 ^ {-66}$$). However, this correlation is highly influenced by the majority of compound pairs where chemical similarity is less than 0.5. As we have [previously noticed](http://thinklab.com/discussion/protein-target-carrier-transporter-and-enzyme-interactions-in-drugbank/65#3), chemical similarity becomes predictive of other types of similarity above 0.5. As seen in Figure 2, the same trend applies to transcriptional similarity. Therefore, within the meaningful range of chemical similarity values, the association looks stronger.

Nice catch that the highest bin (chemical similarity ≥ 0.95) only has a single compound pair. This is due to our [selection criteria](http://thinklab.com/discussion/unifying-drug-vocabularies/40#5) for compounds which aims to avoid redundancy. We have computed chemical similarities for the entire LINCS L1000 perturbation set, so we could rerun this analysis with all perturbagens.","17",2015-08-04,2015-08-04,2,1050,"base.profile","Daniel","Himmelstein","dhimmel"
"541","comments","rephetio","2015-08-04T21:19:36.253Z",112,"#Chemical similarity association with side effect and indication similarity

[Notebook](https://github.com/sabrinalchen/drugbank-similarity/blob/master/side-effect.ipynb)

##Objective:
To determine the relationship between side effect similarity and chemical similarity as well as drug indication and chemical similarity

##Data:
We extracted [side effect and indication similarity data](https://github.com/dhimmel/SIDER2/blob/9d585685dbeaba3bbac58024c814ac87521122ad/data/similarities.txt.gz) which lists drug pairs (pubchem ID,) and their associated side effect similarity and indication similarity. Side effect similarity deals with the similarity of the side effect when a drug is used to treat a protein. Indication is the term doctors use when a drug treats a disease.In addition, [drugbank data](https://github.com/dhimmel/drugbank/blob/e8567eed2dd48ae0694a0960c518763a777845ff/data/mapping/pubchem.tsv) was extracted to convert pubchem ID into drugbank ID. Finally, we extracted [chemical similarity data](http://nbviewer.ipython.org/github/dhimmel/drugbank/blob/9eb1e15ada5e6579e5aea1cae784c10602037b05/similarity.ipynb) which gives a value between zero and one based on the chemical similarity of a pair of drugs. 

##Chemical similarity vs substructure jointplot
As predicted, a positive correlation was found between these two variables. It seemed from the graph that the two were strongly correlated, especially since the p-value was zero. An interesting trend to note was that the data seemed to be banded and centered around certain values. The smaller bands could be due to the fact that substructure data was rounded off to the nearest hundredth place. However, we are not sure of what the large horizontal bands indicate. 

![](https://raw.githubusercontent.com/sabrinalchen/drugbank-similarity/master/figure/substructure.png)
#####Figure 1: Compares chemical similarity to substructure and demonstrates a positive correlation

##Chemical similarity vs side effect similarity jointplot
The graph demonstrated a positive correlation between chemical compound similarity and side effect similarity. To make it easier to read, we took the square root of side effect similarity values and also used logarithmic bins. With the data transformed this way, the correlation was clearer.  Though the correlation coefficient was less than that of the previous comparison, the p-value was zero. 

![](https://raw.githubusercontent.com/sabrinalchen/drugbank-similarity/master/figure/side_effect.png)
#####Figure 2: Compares chemical similarity to side effect similarity

##Chemical similarity vs indication similarity jointplot
Though this graph was slightly harder to read than the previous two because of the skewed indication similarity data, the zero p-value showed some degree of significance. Most of the indication values were zero, so even by taking the square root of the values, it was difficult to visualize the positive correlation. We decided to use a different visualization for clearer analysis (see pointplot below.)

![](https://raw.githubusercontent.com/sabrinalchen/drugbank-similarity/master/figure/indication.png)
#####Figure 3: Compares chemical similarity to indication similarity

##Pointplot 
Because the correlation was a bit difficult to read in previous graphs (especially in the indication jointplot,) we used a pointplot for a different visualization. The chemical similarity data was rounded off to the nearest tenth and the mean values for both side effect similarity and indication similarity was found for each subset. This data was graphed on a pointplot which demonstrated a clear positive correlation, especially when the chemical similarity passed 0.4. For the side effect similarity, it was easy to see a steady positive correlation, apart from the fall between 0.9 and 1.0 on the chemical similarity axis. This could be attributed to the small number of data points, however. For the indication similarity, the graph showed no real correlation between 0.0 and 0.3, but a steady upward trend began starting from 0.4. From our graphs we concluded that increased chemical compound similarity did indeed indicate an increase for side effect similarity and indication similarity.

![](https://raw.githubusercontent.com/sabrinalchen/drugbank-similarity/master/figure/combined_similarity_mean.png)
#####Figure 4: A clearer representation of the association between chemical compound similarity and side effect and indication similarity","112",2015-08-04,2015-08-04,2,4505,"base.profile","Sabrina","Chen","sabrinachen"
"542","comments","rephetio","2015-08-05T20:35:16.257Z",17,"I contacted Mike Keiser, the human intellect behind SEA, regarding chemical similarity thresholding. Below and with permission, I've posted his reply to our [above](#3) comment:

> The [0.5 measure](http://salilab.org/~nkhuri/files/systems-pharmacology-lecture4-01262015.pdf#page=19) refers to a tanimoto coefficient on daylight path-based fingerprints. It'd be in the supplemental materials and/or methods of Keiser et al, Nat Biotechnol, 2007 [@10.1038/nbt1284]. So I think the closest equivalent in rdkit would be tanimoto instead of dice coefficient, or rdkit-path fingerprints. Using ECFP4 (i.e., Morgan with radius 2 in rdkit) and a tanimoto coefficient, we found cutoffs more around 0.28 (the range can vary pretty substantially depending on fingerprint type used). In general, 0.5 is considered pretty high similarity for ECFP/Morgan fingerprints at least with tanimoto coefficients (I'm less sure of the Dice coefficient equivalents, off-hand).","17",2015-08-05,2015-08-05,2,955,"base.profile","Daniel","Himmelstein","dhimmel"
"543","comments","rephetio","2015-08-08T16:15:09.942Z",125,"Please note that [SIDER 4](http://sider-beta.embl.de/) has just been released.

Before anyone asks: no there has never been a SIDER 3. We decided to jump to version 4 to make SIDER version numbers consistent with STITCH. This means that compound IDs of SIDER 4 are consistent with those of STITCH 4, and that SIDER 5 will be consistent with STITCH 5 etc.

I am a bit surprised to see that you use SIDER as a source of drug indications. As is hopefully clear, the focus of SIDER is very much on side effect information. It should thus be no surprise that the quality of the drug indication information is presumably lower than the side effect information.","125",2015-08-08,2015-08-08,2,658,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"544","comments","rephetio","2015-08-08T16:18:22.874Z",125,"It may be worth noting that the work on SIDER actually started as part of a drug-repurposing / off-target-prediction project at EMBL [@10.1126/science.1158140].

I do not want to be overly negative, but there is a reason why we only made use of side effects and not indications to calculate drug similarity: it seems very unlikely to me that you would be able to make non-obvious predictions based on the known indications. If drug X is approved for indications A, B, C and D, and drug Y is approved for indications A, B and C, I would consider the prediction that drug Y might also work for indication D to be trivial. Especially if drugs X and Y are similar chemical compounds.

I believe this is the biggest challenge in computational drug repurposing: how do you predict something that is correct and not obvious? In my experience, this turns out to be much, much harder than to predict something that is just correct.","125",2015-08-08,2015-08-08,2,926,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"545","comments","rephetio","2015-08-08T16:28:14.150Z",125,"The TISSUES resource uses the proteins in the latest version of [STRING](http://string-db.org/) as baseline. If you need to map the [Ensembl](http://www.ensembl.org/) protein identifiers to other database identifiers, the best thing to do is thus to use either the [STRING alias file](http://string-db.org/newstring_download/protein.aliases.v10.txt.gz) or one of the specific mapping files available [here](ftp://string-db.org/STRING/10.0/mapping_files/).","125",2015-08-08,2015-08-08,2,455,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"546","comments","rephetio","2015-08-08T16:28:42.632Z",125,"Introducing a score cutoff does not sound like the right way to go about it to me. The problem is that there is no right cutoff; wherever you put it, what scores just above the cutoff is almost exactly as reliable as what scores just below the cutoff.

I know that life is much simpler if you do not have to deal with confidence scores. However, the moment you take associations with confidence scores and make them binary by applying an arbitrary cutoff, you are throwing away information. For this reason, you will almost always be better off having a method that can deal with confidence scores in a sensible manner and only apply a cutoff on your predictions in the very end after all available evidence has been combined.","125",2015-08-08,2015-08-08,2,728,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"547","comments","rephetio","2015-08-08T16:39:10.962Z",17,"@larsjuhljensen, great timing and thanks for the heads up!

> I am a bit surprised to see that you use SIDER as a source of drug indications.

SIDER was one of the first resources we played with for this project. At the time, we decided to investigate the indications because 1) they were there and 2) we were unaware of other indication databases.

Since then we've spent considerable time on [creating a catalog of indications](http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21). We ended up combining four indication databases, one of which ([MEDI](http://knowledgemap.mc.vanderbilt.edu/research/content/MEDI) [@10.1136/amiajnl-2014-002954]) uses SIDER 2 as an input. We have now moved on to a final stage of [expert curation](http://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95).

> it seems very unlikely to me that you would be able to make non-obvious predictions based on the known indications.

Our heterogeneous network edge prediction [method](http://het.io/hnep/) is a supervised method. Therefore, we need efficacious indications to train our model. However, I do have hope for some metapaths containing an indication metaedge to produce non-obvious predictions. For example, 

+ disease A has 3 indicated drugs (X, Y, Z)
+ X, Y, Z elicit similar transcriptional responses (in [LINCS L1000 data](http://thinklab.com/discussion/computing-consensus-transcriptional-profiles-for-compounds-using-lincs/43))
+ W elicits a similar transcriptional response to X, Y, and Z
+ drug W may treat disease A

I agree that repurposing using only the bipartite indication network will produce mostly obvious predictions. However, our approach is capable of much more!","17",2015-08-08,2015-08-08,2,1776,"base.profile","Daniel","Himmelstein","dhimmel"
"548","comments","rephetio","2015-08-08T17:15:00.985Z",17,"> Introducing a score cutoff does not sound like the right way to go about it to me.

I totally agree that cutoffs are suboptimal because they require arbitrary decision-making, conflate levels of confidence, and throw away information. In the long term, we hope to modify our method to enable weighted edge and to investigate other methods that allow weights (such as data fusion [@10.1109/TPAMI.2014.2343973 @10.1038/srep03202]). However, in the short term, I want to proceed with unweighted edges and understand the sacrifice.

@larsjuhljensen, you may disagree with implementing cutoffs, but by providing ""confidence scores that are comparable between datasets"" [@10.7717/peerj.1054], you have made the life of binners like me much more pleasant (:

For the experimental dataset from TISSUES, one cutoff I envision is 2 or more sources reporting scores ≥ 3 per gene--tissue relation. Does this sound reasonable?

> The TISSUES resource uses the proteins in the latest version of STRING as baseline.

We have begun processing the TISSUES datasets ([notebook](https://github.com/dhimmel/tissues/blob/b7711d18e51ff1a8e91837354415d271bf975907/tissues.ipynb)). I was mapping Ensembl proteins using [`pyensembl`](https://github.com/hammerlab/pyensembl), but will switch to the [mapping](ftp://string-db.org/STRING/10.0/mapping_files/entrez_mappings/) suggested by @larsjuhljensen.","17",2015-08-08,2015-08-08,2,1388,"base.profile","Daniel","Himmelstein","dhimmel"
"549","comments","rephetio","2015-08-08T17:41:25.920Z",125,"My gut feeling is that your cutoff is too stringent. If you want support from at least two different experimental datasets, I would not put the cutoff at 3. I would at most put it at 2.

However, I think there are more fundamental problems with that approach than just the numeric cutoff. Not all tissues were included in all datasets. This means that some tissues will be entirely lost if you require support from two datasets. Also, I do not understand why you would want to exclude the other channels (knowledge and text mining). Having, for example, text mining to support something that would otherwise be based on only a single dataset is very valuable.

If you want to enforce a hard cutoff to make things binary, I would urge you to at least take the integrated scores that takes everything into account and apply the cutoff to that. In this case a score of 3 might be appropriate. Applying cutoffs to the scores of individual datasets before combining them is in my opinion a fundamentally bad idea.","125",2015-08-08,2015-08-08,2,1012,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"550","comments","rephetio","2015-08-08T20:12:51.051Z",17,"# Initial release of consensus signatures

We have computed consensus transcriptional signatures for LINCS L1000 perturbations. We have released [datasets](https://github.com/dhimmel/lincs/tree/b36dfd82b6b1aa0b0c45ec905cb2548ddf7dc53e/data/consensi) [@10.5281/zenodo.27229] for the following pertubation sets:

+ LINCS pert_ids: 38,327 consensi ([download](https://github.com/dhimmel/lincs/blob/b36dfd82b6b1aa0b0c45ec905cb2548ddf7dc53e/data/consensi/consensi-pert_id.tsv.gz))
+ DrugBank compounds: 1,170 consensi ([download](https://github.com/dhimmel/lincs/blob/b36dfd82b6b1aa0b0c45ec905cb2548ddf7dc53e/data/consensi/consensi-drugbank.tsv.gz))
+ Gene knockdowns: 4,363 consensi ([download](https://github.com/dhimmel/lincs/blob/b36dfd82b6b1aa0b0c45ec905cb2548ddf7dc53e/data/consensi/consensi-knockdown.tsv.gz))
+ Gene over-expressions: 2,471 consensi ([download](https://github.com/dhimmel/lincs/blob/b36dfd82b6b1aa0b0c45ec905cb2548ddf7dc53e/data/consensi/consensi-overexpression.tsv.gz))

The datasets are tsv-formatted with perturbations as rows and genes as columns. We only report expression values for the 978 assayed genes. Non-gold signatures were omitted. We set a [minimum signature weight](#4) of 0.05 and combined z-scores using [Stouffer's method](#5).","17",2015-08-08,2015-08-08,2,1274,"base.profile","Daniel","Himmelstein","dhimmel"
"551","comments","rephetio","2015-08-08T20:37:06.568Z",17,"# Genetic perturbation edges

@alessandrodidonna, thanks for the recommendation. You have motivated to us to add four new gene--gene metaedges:

+ Gene → knockdown downregulates → Gene
+ Gene → knockdown upregulates → Gene
+ Gene → overexpression downregulates → Gene
+ Gene → overexpression upregulates → Gene

These will be our first directed edges, so it will be exciting to stress test our support for directed edges, a feature that we [designed](https://github.com/dhimmel/hetio/blob/340b5f3572e29a766cb103b0883796323f983e97/hetio/graph.py#L322) our implementation to support.

We'll be taking the data from [LINCS L1000](http://www.lincscloud.org/) which contains a large number of genetic perturbation experiments:

![](https://raw.githubusercontent.com/dhimmel/rephetio/b4ccfe08be839a4caa4b4a0e2b918b03d50cde65/figure/lincs-l1000-synopsys.png)

[Read more](http://thinklab.com/discussion/computing-consensus-transcriptional-profiles-for-compounds-using-lincs/43#6) about our consensus signatures for gene knockdowns (of 4,363 genes) and overexpressions (of 2,471 genes).","17",2015-08-08,2015-08-08,2,1093,"base.profile","Daniel","Himmelstein","dhimmel"
"552","comments","rephetio","2015-08-08T22:27:20.277Z",17,"# Knowledge biased and unbiased edges

Thanks to @b_good's suggestion for text mining and curated databases, we have incorporated several edges that are subject to knowledge bias.

Text mining edges include:

+ *Disease -- causation -- Symptom* edges from MEDLINE [topic cooccurrence](http://thinklab.com/discussion/mining-knowledge-from-medline-articles-and-their-indexed-mesh-terms/67#4)
+ *Disease -- similarity -- Disease* edges from MEDLINE [topic cooccurrence](http://thinklab.com/discussion/disease-similarity-from-medline-topic-cooccurrence/93)
+ *Disease -- localization -- Anatomy* edges from MEDLINE [topic cooccurrence](http://thinklab.com/discussion/mining-knowledge-from-medline-articles-and-their-indexed-mesh-terms/67#5)

Literature curation edges include:

+  *Compound -- target -- Gene* edges from [DrugBank](http://thinklab.com/discussion/protein-target-carrier-transporter-and-enzyme-interactions-in-drugbank/65) and [BindingDB](http://thinklab.com/discussion/integrating-drug-target-information-from-bindingdb/53)
+ *Gene -- interaction -- Gene* edges from [curated databases](http://thinklab.com/discussion/creating-a-catalog-of-protein-interactions/85)
+ *Gene -- membership -- Pathway* edges from [WikiPathways and MSigDB](http://thinklab.com/discussion/adding-pathway-resources-to-your-network/72)
+ *Gene -- membership -- GO Domain* edges from the [Gene Ontology](http://thinklab.com/discussion/compiling-gene-ontology-annotations-into-an-easy-to-use-format/39#8) annotations
+ *Gene -- function -- Disease* edges from the [DOAF](http://thinklab.com/discussion/functional-disease-annotations-for-genes-using-doaf/94)

And we have several edges from systematic technologies that are not subject to knowledge biases.

+ *Disease -- expression -- Anatomy* edges from [Bgee](http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#8) and [TISSUES](http://thinklab.com/discussion/the-tissues-resource-for-the-tissue-specificity-of-genes/91)
+ *Disease -- up/down-regulation -- Gene* edges from [STARGEO](http://thinklab.com/discussion/stargeo-expression-signatures-for-disease-using-crowdsourced-geo-annotation/96)
+ *Gene -- membership -- Perturbation Gene Set* edges from MSigDB
+ *Gene -- interaction -- Gene* edges from [Y2H experiments](http://thinklab.com/discussion/creating-a-catalog-of-protein-interactions/85#7)
+ *Gene -- evolution -- Gene* edges from [evolutionary rate covariation](http://thinklab.com/discussion/selecting-informative-erc-evolutionary-rate-covariation-values-between-genes/57)
+ *Gene -- knowdown up/down-reglulation -- Gene* edges from [LINCS L1000](http://thinklab.com/discussion/suggestions-for-additional-information-types/22#6)
+ *Compound -- up/down-regulation -- Gene* from [LINCS L1000](http://thinklab.com/discussion/computing-consensus-transcriptional-profiles-for-compounds-using-lincs/43#6)

Thus, for each edge we will create an `unbiased` attribute which takes a `True` or `False` value. **Using our network masking feature, we can easily switch between using the whole network or only the knowledge-unbiased portion.**

Some metaedges will contain a mix of biased and unbiased edges. For example, protein interactions based on their source database. When both a biased and unbiased source contribute an edge, we will give precedence to the unbiased designation.","17",2015-08-08,2015-08-08,2,3378,"base.profile","Daniel","Himmelstein","dhimmel"
"553","comments","rephetio","2015-08-08T22:39:34.502Z",17,"@larsjuhljensen, we will use the integrated dataset as the primary resource. However, the integrated dataset is subject to knowledge biases (stemming from text mining and UniProtKB). Since we [want the option](http://thinklab.com/discussion/text-as-a-resource-for-network-population/48#3) to subset the network to only include knowledge-unbaised edges, we would also like a consolidated score using only the experimental dataset.

In other words, if a gene--tissue edge scores above the cutoff in the consolidated experimental dataset, it's considered unbiased. However, if it only passes the cutoff in the integrated dataset, it's considered biased.

So that leaves one remaining question: **how to create an integrated score using only experimental evidence?**

> some tissues will be entirely lost if you require support from two datasets.

Let's not worry to much about uniform coverage of tissues. Our approach can handle nonuniform network sparsity and uniform coverage is unfeasible in most cases.","17",2015-08-08,2015-08-08,2,1012,"base.profile","Daniel","Himmelstein","dhimmel"
"554","comments","rephetio","2015-08-08T23:36:57.882Z",17,"SIDER is a project to extract side effects from drug labels [@10.1038/msb.2009.98], originally motivated by off-target prediction [@10.1126/science.1158140]. We [evaluated version 2](http://thinklab.com/discussion/assessing-the-quality-and-applicability-of-the-sider-2-resource/30#1) and produced an [online tutorial](http://git.dhimmel.com/SIDER2/). We found that side effect similarity was a [weak predictor](http://thinklab.com/discussion/assessing-the-quality-and-applicability-of-the-sider-2-resource/30#3) of chemical and indication similarity.

Just two days ago, [version 4](http://sideeffects.embl.de/) was released. Here, we will detail our extraction of side effects from SIDER4.","17",2015-08-08,2015-08-08,2,692,"base.profile","Daniel","Himmelstein","dhimmel"
"555","comments","rephetio","2015-08-08T23:49:37.750Z",17,"# Data release formatting

We ran into some issues when parsing the SIDER4 datasets. In defense of the creators, version 4 is still in beta and hasn't become the default version (the url was [provided to us](http://thinklab.com/discussion/assessing-the-quality-and-applicability-of-the-sider-2-resource/30#4) by a project member).

The remainder of the post refers to [this notebook](https://github.com/dhimmel/SIDER4/blob/master/SIDER4.ipynb). I ran into the following issues:

+ `label_mapping.tsv.gz` is strangely encoded and/or is improperly tab-delimited
+ `meddra_all_indications.tsv.gz` is not documented in the README

@larsjuhljensen, are you the right contact for this project?","17",2015-08-08,2015-08-08,2,696,"base.profile","Daniel","Himmelstein","dhimmel"
"556","comments","rephetio","2015-08-09T08:47:44.404Z",125,"The way we currently calculate the integrated score can obviously be applied to any subset of evidence channels and sources (e.g. all sources in the experiments channel, or all sources in the experiments channel except HPA-IHC).

First, we convert all the confidence scores ($$s_{ijk}$$) between 0 and 5 to pseudo-probabilities ($$p_{ijk}$$) between 0 and 1 by simply dividing with 5. Here $$i$$ and $$j$$ are the two entities (proteins, tissues, diseases, etc.) and $$k$$ is the channel or source. Next, assuming independence between the different types of evidence, we define the combined pseudo-probability for two entities as:

$$$p_{ij} = 1-\prod_{k}{(1-p_{ijk})}$$$

Finally, we convert $$p_{ij}$$ back to $$s_{ij}$$ by simply multiplying with 5.

This is admitted *ad hoc* and has not yet been benchmarked or otherwise compared to other alternatives. The major assumption here is that you can convert confidence scores to some sort of probabilities by simply dividing with 5, which is obviously an oversimplification. There is also the assumption of independence, but I believe this is less of a problem. The formula for combining probabilities is very similar to the [STRING](http://string-db.org/) scoring scheme, which has been extensively tested.","125",2015-08-09,2015-08-09,2,1265,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"557","comments","rephetio","2015-08-09T19:42:47.394Z",17,"# Initial release of processed TISSUES data

We have completed an initial processing of the TISSUES data ([repository](https://github.com/dhimmel/tissues/tree/93cd71464ee9673661bc4ddadfc6a8e0e219cd7b), [notebook](https://github.com/dhimmel/tissues/blob/93cd71464ee9673661bc4ddadfc6a8e0e219cd7b/tissues.ipynb)) [@10.5281/zenodo.27244]. The main output of our analysis is [`merged.tsv.gz`](https://github.com/dhimmel/tissues/blob/93cd71464ee9673661bc4ddadfc6a8e0e219cd7b/data/merged.tsv.gz), a table where each row is a tissue (Uberon)--gene (Entrez) pair. For each pair, we provide 5 scores:

+ `score_text`: score from the text mining channel
+ `score_knowledge`: score from the UniProtKB/knowledge channel
+ `score_experiment`: integrated score from the experimental channel
+ `score_experiment_unbiased`: integrated score from the experimental channel without immunohistochemical staining data from the Human Protein Atlas
+ `score_integrated`:  integrated score combining everything

Integrations (`score_experiment` and `score_experiment_unbiased`) were calculated using the [above formula](#7).

## Visualizing channel concordance

We visualized the relationships between scores. The off-diagonal plots show a 2D histogram, using hexagonal bins. The diagonal of the grid contains 1D histograms for the x-variable. Bin counts for all panels are log-transformed.

![](https://raw.githubusercontent.com/dhimmel/tissues/93cd71464ee9673661bc4ddadfc6a8e0e219cd7b/figure/channel-histograms.png)

You may be surprised to see points where `y < x` for the integrated 2D histograms. This occurs because Uberon and Entrez Gene mappings are not always one-to-one.","17",2015-08-09,2015-08-09,2,1673,"base.profile","Daniel","Himmelstein","dhimmel"
"558","comments","rephetio","2015-08-09T21:05:19.849Z",17,"## Updated datasets

We modified the code and formats for our merged indication datasets ([website](https://cdn.rawgit.com/dhimmel/indications/6375b195df61b6e0d44c4690abfa2ac0710bc690//merge.html#indication-table), [downloads](https://github.com/dhimmel/indications/tree/6375b195df61b6e0d44c4690abfa2ac0710bc690/data)). The underlying indications have not changed from [above](#1).

## Pilot on 50 indications

We created a [simpler tsv file](https://github.com/dhimmel/indications/blob/6375b195df61b6e0d44c4690abfa2ac0710bc690/data/curation.tsv) as a curation template. As a start, we are going to have two UCSF physicians each classify a [random subset](https://github.com/dhimmel/indications/blob/6375b195df61b6e0d44c4690abfa2ac0710bc690/data/curation-subset.tsv) of 50 indications. These indications will be a pilot to see if the task is well-defined or needs revision.

The curators will independently do a first pass. Then they will come to a consensus on conflicting classifications. We'll report back with our experience on the pilot. ","17",2015-08-09,2015-08-09,2,1051,"base.profile","Daniel","Himmelstein","dhimmel"
"559","comments","rephetio","2015-08-10T18:14:36.201Z",17,"# SIDER 4

We have begun working with SIDER 4. See [the dedicated discussion](http://thinklab.com/discussion/extracting-side-effects-from-sider4/97) for more information.","17",2015-08-10,2015-08-10,2,172,"base.profile","Daniel","Himmelstein","dhimmel"
"560","comments","rephetio","2015-08-11T06:05:43.190Z",17,"# Initial processing complete

We've completed a first pass off the SIDER 4 data processing ([notebook](https://github.com/dhimmel/SIDER4/blob/2acca0b065e736bc99702906024efd4718e502ee/SIDER4.ipynb), [downloads](https://github.com/dhimmel/SIDER4/tree/2acca0b065e736bc99702906024efd4718e502ee/data)). Our analysis consisted of mapping [STICH](http://stitch.embl.de/) [@10.1093/nar/gkt1207 @10.1093/nar/gkm795] compounds to DrugBank and consolidating duplicate rows. 

We added the side effects extracted from `meddra_all_se.tsv.gz` to our network. Overall, the resource [contributed](https://github.com/dhimmel/integrate/blob/9986ecb2ad62f0e08044334d74d63a9590e4eafd/integrate.ipynb) 139,235 compound-side effect relationships for 5,745 side effects.

## Data quality

Compared to version 2, I subjectively noticed a considerable quality improvement. However, many of the [problems](http://thinklab.com/discussion/assessing-the-quality-and-applicability-of-the-sider-2-resource/30#2) inherent to label based NLP extraction remain. I think there are two potential methods for extracting higher confidence side effects:

1. **Number of labels approach**: Most drugs have multiple labels. Side effects reported by more labels may be of higher quality. [Amphetamine](http://sideeffects.embl.de/drugs/3007/) is a good example.
2. **Frequency approach**: Some side effects have associated frequency information. Placebo comparisons are also sometimes present. Thus enrichment in frequency compared to placebo, other drugs, or a cutoff is feasible. [Ibuprofen](http://sideeffects.embl.de/drugs/3672/) is a good example. 

The current data release may be insufficient to apply these methods. More documentation is needed. Judging from the webapp the underlying database would support both methods. 


","17",2015-08-11,2015-08-11,2,1807,"base.profile","Daniel","Himmelstein","dhimmel"
"561","comments","rephetio","2015-08-12T23:40:14.883Z",17,"A recently published study [@10.1093/nar/gkv810], which calls itself [ADEPTUS](http://acgt.cs.tau.ac.il/adeptus/download.html), calculated differential expression profiles for 14 diseases.

Their disease concepts are broad, so only 3 match a [DO Slim](http://thinklab.com/discussion/unifying-disease-vocabularies/44#6) disease ([notebook](https://github.com/dhimmel/adeptus/blob/4169d25bbc99177d88d0cbd428ae02e886a2d2f9/adeptus.ipynb), [downloads](https://github.com/dhimmel/adeptus/tree/4169d25bbc99177d88d0cbd428ae02e886a2d2f9/data)). Those diseases along with the corresponding number of up and down-regulated genes are:

| disease id | disease name | genes down | genes up |
|-----------|--------------------|------|-----|
| DOID:1324 | lung cancer | 101 | 211 |
| DOID:1612 | breast cancer | 61 | 68 |
| DOID:2531 | hematologic cancer | 512 | 631 |

We're included these edges in our network as a placeholder until [STARGEO is ready](http://thinklab.com/discussion/stargeo-expression-signatures-for-disease-using-crowdsourced-geo-annotation/96). STARGEO currently [contains](http://dev.stargeo.io/) 463,824 sample annotations (tags) whereas ADEPTUS contains only 14,840.","17",2015-08-12,2015-08-12,2,1185,"base.profile","Daniel","Himmelstein","dhimmel"
"562","comments","rephetio","2015-08-12T03:41:52.524Z",17,"# Ontologies for disease-centric GEO annotation

STARGEO allows users to define arbitrary ""tags"" for sample annotation. We have been adding Disease Ontology (DO) IDs to our tag descriptions. This suffices for simple case-control comparisons, but is insufficient for more complex comparisons.

For example, many cancer studies, will compare tumors to healthy tissue but all samples are from cases. Therefore the contrast is not case versus control, but healthy versus diseased tissue. In general, we will want to incorporate these contrasts into our disease-specific expression signatures.

@fbastian and @chrismungall, do you know of any ontologies that could help with our annotation task? I know that Bgee focuses on healthy tissue, but I though you may be able to direct us in the right direction.

**Summary**: we are gathering disease-specific expression signatures. What terminologies should we use to create contrast between samples within a study (GEO Series)?","17",2015-08-12,2015-08-12,2,976,"base.profile","Daniel","Himmelstein","dhimmel"
"563","comments","rephetio","2015-08-12T18:23:34.548Z",17,"# Unbiased PPI datasets

Since we now include a [edge attribute for bias](http://thinklab.com/d/48#3) in our network, we need to identify a subset of our PPIs that are derived from hypothesis free, i.e. unbiased, experiments.

The *Incomplete Interactome* [@10.1126/science.1257601] [describes](http://www.sciencemag.org/content/suppl/2015/02/18/347.6224.1257601.DC1/Menche_SM.pdf#page=5) their creation of an unbiased interactome:

> Since our interactome includes data from literature curation, it is inherently biased towards much studied disease-associated proteins and their interactions. We, therefore, complement our analysis using only interactions from well controlled and completely unbiased high-throughput yeast two-hybrid (y2h) datasets [@10.1016/j.cell.2014.10.050 @10.1038/nmeth.1280 @10.1038/nmeth.1597 @10.1038/nature04209 @55].

Minus the last citation [@55] which is prepublication, we can use the other four resources [@10.1016/j.cell.2014.10.050 @10.1038/nmeth.1280 @10.1038/nmeth.1597 @10.1038/nature04209], two of which were used by @idrdex in his study [@10.1038/ncomms5074].
 
[@55]: ""Center for Cancer Systems Biology, Hi-2012 prepublication""","17",2015-08-12,2015-08-12,2,1178,"base.profile","Daniel","Himmelstein","dhimmel"
"564","comments","rephetio","2015-08-12T21:01:31.686Z",17,"# Completed PPI catalog

We have completed an initial version of our protein interaction catalog for this project [@10.5281/zenodo.48443], named `hetio-ind`. We defined interaction as *two genes whose protein products physically interact*. Physical associations from protein complexes were minimized.

Interactions were taken from the following sources:

+ **Human Interactome Database** ([HID](http://interactome.dfci.harvard.edu/H_sapiens/index.php?page=download)): specifically the `HI-I-05` [@10.1038/nature04209], `Venkatesan-09` [@10.1038/nmeth.1280], `Yu-11` [@10.1038/nmeth.1597], `HI-II-14` [@10.1016/j.cell.2014.10.050], `Lit-BM-13` [@10.1016/j.cell.2014.10.050] datasets.
+ **Incomplete Interactome** [@10.1126/science.1257601]: specifically the `II_binary` and `II_literature` [subsets](#2).
+ **hetio-dag** [@10.1371/journal.pcbi.1004259]: our previous project ([details](#4)). We removed all interactions that were not physical associations ([`MI:0195`](http://www.ebi.ac.uk/ontology-lookup/browse.do?ontName=MI&termId=MI%3A0915&termName=physical%20association)). This step excluded genetic and colocalization interactions.

16,526 interactions reported by `HI-I-05` [@10.1038/nature04209], `Venkatesan-09` [@10.1038/nmeth.1280], `Yu-11` [@10.1038/nmeth.1597], or `HI-II-14` [@10.1016/j.cell.2014.10.050] were considered unbiased. The 135,203 other interactions were considered biased.

In total our dataset contains 151,729 protein interactions ([notebook](https://github.com/dhimmel/ppi/blob/4012fe7af1699222539844256e3639782ae72695/compile-PPIs.ipynb), [downloads](https://github.com/dhimmel/ppi/tree/4012fe7af1699222539844256e3639782ae72695/data)).","17",2015-08-12,2015-08-12,2,1678,"base.profile","Daniel","Himmelstein","dhimmel"
"565","comments","rephetio","2015-08-16T23:53:59.216Z",17,"# Jupyter 1.0.0 released

Last Wednesday [marked a historic day](http://blog.jupyter.org/2015/08/12/first-release-of-jupyter/) for biodata science. The language agnostic parts of IPython, including the notebook, have been [repackaged](https://blog.jupyter.org/2015/04/15/the-big-split/) as Jupyter. The big split was necessary because the project now supports [many languages](https://github.com/ipython/ipython/wiki/IPython-kernels-for-other-languages) not just python.

I am updating the [above](#1) guide, by replacing `ipython` with `jupyter` in code snippets. The revised guidance will apply to new installations. If you have an existing Anaconda installation, you can [install Jupyter](http://jupyter.readthedocs.org/en/latest/install.html) with `conda install jupyter`.

Now who is excited for [September 13th](https://www.python.org/dev/peps/pep-0478/) and the [features](https://github.com/takluyver/talks/blob/master/Python%203.5%20lightning%20talk.ipynb) this day will bring!","17",2015-08-16,2015-08-16,2,992,"base.profile","Daniel","Himmelstein","dhimmel"
"566","comments","rephetio","2015-08-14T11:05:20.654Z",111,"To annotate the condition of a sample, you can use the Experimental Factor Ontology (EFO). But not sure what you mean by ""contrast between samples"" (do you want to annotate each sample, or have terms directly representing, e.g. ""healthy vs. diseased contrast"")

","111",2015-08-14,2015-08-14,2,264,"base.profile","Frederic","Bastian","fbastian"
"567","comments","rephetio","2015-08-14T22:24:08.088Z",17,"# Network version 1.0

We have completed an initial version of our network ([notebook](https://github.com/dhimmel/integrate/blob/2256f1d6d01758c8bab59212a68d890ecb42bb7f/integrate.ipynb), [download](https://github.com/dhimmel/integrate/blob/2256f1d6d01758c8bab59212a68d890ecb42bb7f/data/graph.json.gz)) [@10.5281/zenodo.28040].

The network consists of 10 types of nodes (metanodes) and 27 types of edges (metaedges). It contains 49,427 nodes and 2,997,892 edges (1,488,312 of which are [unbiased](http://thinklab.com/discussion/text-as-a-resource-for-network-population/48#3)). The network is visualized below, laid out by metanode and colored by metaedge (only a subset of edges are drawn for efficiency):

![](https://raw.githubusercontent.com/dhimmel/rephetio/eaad6455815c3886a47aeddf76931fcf1779e090/figure/network-v1.0-labeled.png)

For additional information, see the [summary of nodes](https://github.com/dhimmel/integrate/blob/2256f1d6d01758c8bab59212a68d890ecb42bb7f/data/summary/metanodes.tsv), [summary of edges](https://github.com/dhimmel/integrate/blob/2256f1d6d01758c8bab59212a68d890ecb42bb7f/data/summary/metaedges.tsv), or [visualization of degree distributions](https://github.com/dhimmel/integrate/blob/2256f1d6d01758c8bab59212a68d890ecb42bb7f/viz/degrees.pdf). Network existence (SHA256 checksum for `graph.json.gz`) is [proven](https://blockchain.info/tx/092f81abd7bb5c59e52e2d8e794de6cee4a1cd701f7a87d2bc11cfefe97d4923?show_adv=true) in Bitcoin block 369,898.

## Future changes

There are a few changes we hope to make in the near future. First, replacing [ADEPTUS](http://thinklab.com/discussion/the-adeptus-resource-for-expression-signatures-of-disease/101) with [STARGEO](http://thinklab.com/discussion/stargeo-expression-signatures-for-disease-using-crowdsourced-geo-annotation/96) for expression signatures of disease. Second, updating our indications with a [manually curated](http://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95) subset. As always, suggestions for additional information types are [welcome here](http://thinklab.com/discussion/suggestions-for-additional-information-types/22).","17",2015-08-14,2015-08-14,2,2191,"base.profile","Daniel","Himmelstein","dhimmel"
"568","comments","rephetio","2015-08-16T07:35:00.051Z",125,"Nice of you to share this big network with everyone; however, I think you need to take care not to get yourself into legal trouble here.

I looked into the JSON network file and found the following:
- Gene membership of all KEGG maps. If you look at the [KEGG license](http://www.kegg.jp/kegg/legal.html), it is questionable if you can do that at all, and very clear that you cannot allow commercial use.
- Side effect data from (I assume) SIDER. The SIDER download files are distributed under the [CC-BY-NC-SA license](http://creativecommons.org/licenses/by-nc-sa/3.0/), which means that you are only allowed to redistribute if you give attribution and attach the same license to the derived work.

Given earlier posts, I assume that you also import associations from the [TISSUES database](http://tissues.jensenlab.org/). Even though I distribute this resource under the very permissive [CC-BY license](http://creativecommons.org/licenses/by/4.0/), you are still required to give attribution. This could, for example, be done by including relevant linkouts under ""data"" : { ""url"" : ""..."" }.

I am not trying to cause trouble here - just the contrary. When making a meta-resource, licenses and copyright law are not something you can afford to ignore. I regularly leave out certain data sources from my resources for legal reasons. For example, [OMIM](http://www.omim.org/) is not included in [DISEASES](http://diseases.jensenlab.org/) due to [its restrictive license](http://www.omim.org/help/agreement).","125",2015-08-16,2015-08-16,2,1514,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"569","comments","rephetio","2015-08-16T09:28:46.591Z",125,"Related to the license issues, it is wise that you solicit advice from legal experts. However, as long as you are dealing with databases created by researchers in academia, the risk of actually getting sued is pretty minimal. The most important question that you should be asking yourself is thus not ""what can I technically do without risking to get sued?"", but rather ""what was the intent of the license?"". If you frequently do things that may be technically legal but clearly go against the intent of other researchers, you will quickly make many enemies.

Just friendly words of advise :-)","125",2015-08-16,2015-08-16,2,595,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"570","comments","rephetio","2015-08-17T02:56:46.391Z",17,"We have been developing [tools](https://github.com/dhimmel/hetio) and [applications](http://het.io) [@10.1371/journal.pcbi.1004259 @10.15363/thinklab.4] for *graphs with multiple node and edge types with optional directionality declared by the edge type*. Now, we would like to choose the best term for this definition.

We have adopted a [nomenclature](https://dx.doi.org/10.1371/journal.pcbi.1004259#article1.body1.sec4.sec2.p1) where graph elements (nodes, edges, paths) are prepended with meta when referring to their type (metanodes, metaedges, metapaths). Support for directionality is necessitated by certain metaedges that connect a metanode to itself ([example](http://thinklab.com/discussion/suggestions-for-additional-information-types/22#6)). Whether our conception of directionality should be mandated by the definition is open for discussion.

## Potential names

+ **heterogeneous information network** -- the term used by the foundational works in social network analysis [@10.2200/S00433ED1V01Y201207DMK005 @10.1109/ASONAM.2011.112 @10.1109/ASONAM.2011.107] to describe a graph with typed nodes and edges. The 397 [occurrences](https://scholar.google.com/scholar?hl=en&q=%22heterogeneous+information+network%22) in Google Scholar are of high precision. My major complaints with this term are its verbosity and drabness.
+ **heterogeneous network** -- the term we are currently using but that has a [preexisting meaning](https://en.wikipedia.org/wiki/Heterogeneous_network) in computer networking. The term retrieves 2,930 Google Scholar [occurrences](https://scholar.google.com/scholar?q=%22heterogeneous+network%22&as_ylo=2015) since 2015 with precision below 50%. I dislike this term's ambiguity and use of ""heterogeneous"" which is lengthy and esoteric.
+ **other options**: we would like suggestions for other names. The following criteria are important: brevity, precision (once adopted), intuitiveness, cheer, and accessibility.

## Related terms

Below, I list several graph types (out of many [@10.1002/bult.2010.1720360610]) that are related to but distinct from our definition:

+ [multipartite graphs](https://en.wikipedia.org/wiki/Multipartite_graph) -- graphs with typed nodes but without typed edges. Sometimes [@10.1103/physreve.79.036113] referred to as *multitype networks*.
+ [multigraph](https://en.wikipedia.org/wiki/Multigraph) -- graphs allowing multiple edges between the same source and target nodes but without typed edges. 
+ [multi-relational graphs](http://neo4j.com/docs/stable/cypher-cookbook-multirelational-social-network.html) -- graphs with multiple edge types  
+ [property graphs](https://github.com/tinkerpop/gremlin/wiki/Defining-a-Property-Graph) -- directed multi-relational graphs with edge attributes.

## Seeking input

We would like input and suggestions. Some possibilities are polynets, hetnets, multigraphs, typednets, typedgraphs, and multitype networks.

Collectively, we are pioneering a branch of network analysis that will play a prominent role going forward. We do not want to be hindered by vocabulary.","17",2015-08-17,2015-08-17,2,3095,"base.profile","Daniel","Himmelstein","dhimmel"
"571","comments","rephetio","2015-08-18T03:46:33.049Z",17,"Thanks to a suggestion by @janispi, we have begun processing [DisGeNET](http://www.disgenet.org/web/DisGeNET/menu/home) [@10.1093/database/bav028 @10.1371/journal.pone.0020284 @10.1093/bioinformatics/btq538] to include as a disease--gene edge in our network.

DisGeNET integrates [associations](http://www.disgenet.org/web/DisGeNET/menu/dbinfo#ontology) from many [sources](http://www.disgenet.org/web/DisGeNET/menu/dbinfo#sources) and provides a unified [score](http://www.disgenet.org/web/DisGeNET/menu/dbinfo#score) for each gene--disease pair.

We will likely replace or merge the function edge we [extracted from DOAF](http://thinklab.com/discussion/functional-disease-annotations-for-genes-using-doaf/94) with DisGeNET.

Diseases in DisGeNET are identified with UMLS identifiers. We were [able to map](https://github.com/dhimmel/disgenet/blob/2154cd74307f92d00d2ed192c584cfb33733d7da/disgenet.ipynb) 125 out of 137 of our [DO Slim](http://thinklab.com/discussion/unifying-disease-vocabularies/44#6) diseases.","17",2015-08-18,2015-08-18,2,1020,"base.profile","Daniel","Himmelstein","dhimmel"
"572","comments","rephetio","2015-08-18T03:55:14.132Z",17,"# Data format suggestion

The datasets on the [download page](http://www.disgenet.org/web/DisGeNET/menu/downloads) are gzipped tarballs but only contain a single text file. Using `zless` or `pandas.read_table()` on the `tar.gz` file led to strange behavior. I ended up extracting the file from the tarball and then gzipping it again to reduce filesize ([new file](https://github.com/dhimmel/disgenet/blob/2154cd74307f92d00d2ed192c584cfb33733d7da/download/all_gene_disease_associations.txt.gz)).

@janispi, would it make sense to remove the tarball at your end and go with a plain `.txt.gz` or `.tsv.gz` extension?","17",2015-08-18,2015-08-18,2,617,"base.profile","Daniel","Himmelstein","dhimmel"
"573","comments","rephetio","2015-08-18T08:08:19.392Z",129,"you should not be having problems, but maybe you should just untar the file and then load it? 
Let me know how it goes, so if there is any issue, we will take care of it. ","129",2015-08-18,2015-08-18,2,172,"base.profile","janet","piñero","janispi"
"574","comments","rephetio","2015-08-18T17:15:29.535Z",17,"I ended up doing the following steps to strip out the tarball:

```shell
tar -xzf all_gene_disease_associations.tar.gz
gzip all_gene_disease_associations.txt
rm all_gene_disease_associations.tar.gz
```

The procedure isn't difficult, but you could save users some time by doing away with the tarball, since it only contains a single file.","17",2015-08-18,2015-08-18,2,346,"base.profile","Daniel","Himmelstein","dhimmel"
"575","comments","rephetio","2015-08-18T17:44:36.017Z",17,"# Choosing a score threshold

DisGeNET includes a [score](http://www.disgenet.org/web/DisGeNET/menu/dbinfo#score) for reported gene--disease relationships, described as [@10.1093/database/bav028]:

> The score ranges from 0 to 1 and is computed according to the formula described in ‘Methods’ section. The DisGeNET score allows obtaining a ranking of GDAs and a straightforward classification of curated vs predicted vs literature-based associations since it stratifies the associations based on their level of evidence. For instance, associations only reported by UniProt or CTD, which have been curated by experts, have higher scores (i.e. associations with S ≥ 0.3) than those only supported by animal models or text-mining based sources.

We will need to choose a [minumum threshold](http://thinklab.com/discussion/the-tissues-resource-for-the-tissue-specificity-of-genes/91#4) for edge inclusion in our network. @janispi, can you give us some more information regarding scores? Specifically,

+ how do scores correspond to precision (the probability of the relationship being real)?
+ what is a reasonable cutoff to eliminate junk? Does any relationship with score > 0 already have acceptable confidence?

We would like a permissive threshold, allowing up to a ~30% false discovery rate.","17",2015-08-18,2015-08-18,2,1303,"base.profile","Daniel","Himmelstein","dhimmel"
"576","comments","rephetio","2015-08-18T17:56:25.861Z",17,"# Naming disease--gene metaedges

Up till now, we have been calling our [edges from GWAS](http://thinklab.com/discussion/extracting-disease-gene-associations-from-the-gwas-catalog/80) ""associations"" and our [edges from DOAF](http://thinklab.com/discussion/functional-disease-annotations-for-genes-using-doaf/94) ""functions"".

DisGeNET uses a different [nomenclature](http://www.disgenet.org/web/DisGeNET/menu/dbinfo#ontology). 'Association' refers to all disease--gene relationships while 'genetic variation' is more in line with what we call 'association'.

Should we continue to call our GWAS edge 'association' and put DisGeNET into our 'function' edge? Or we could rename 'function' to 'relationship' to be more general? Or we could switch our GWAS edge to 'variation'.","17",2015-08-18,2015-08-18,2,779,"base.profile","Daniel","Himmelstein","dhimmel"
"577","comments","rephetio","2015-08-18T19:01:30.203Z",22,"I'm a fan of HetNets. It's short and catchy. It does seem to be used for wireless networking but if it's relatively unique in bioinformatics I think the short and catchy part is a big advantage.","22",2015-08-18,2015-08-18,2,194,"base.profile","Casey","Greene","caseygreene"
"578","comments","rephetio","2015-08-19T09:22:09.808Z",129,"I would recommend using the same criteria as in DisGeNET. ""Genetic Variation"" would be equivalent to GWAS.","129",2015-08-19,2015-08-19,2,106,"base.profile","janet","piñero","janispi"
"579","comments","rephetio","2015-08-19T18:11:25.554Z",121,"@fbastian

For now STARGEO annotations really funnel towards performing classical meta-analysis across studies given an standardized set of ""cases"" vs ""controls"".  This kind of fits with micro-array experimental design which usually ""contrast"" some type of case vs control.  So there is a concept of a control for a disease which may or may not be a ""healthy"" control.","121",2015-08-19,2015-08-19,2,370,"base.profile","Dexter","Hadley","idrdex"
"580","comments","rephetio","2015-08-19T18:12:42.999Z",121,"@dhimmel 

We will soon have analyses working on the dev site: http://dev.stargeo.io.  We will probably shut down the old site by the end of the month.","121",2015-08-19,2015-08-19,2,153,"base.profile","Dexter","Hadley","idrdex"
"581","comments","rephetio","2015-08-19T18:53:33.878Z",17,"The Experimental Factor Ontology ([EFO](http://www.ebi.ac.uk/efo/)) [@10.1093/bioinformatics/btq099] has a few terms related to what we need. For example,

+ case control design ([`EFO:0001427`](http://www.ebi.ac.uk/efo/EFO_0001427))
+ control ([`EFO:0001461`](http://www.ebi.ac.uk/efo/EFO_0001461))
+ individual ([`EFO:0000542`](http://www.ebi.ac.uk/efo/EFO_0000542))
+ tissue specimen ([`OBI:0001479`](http://purl.obolibrary.org/obo/OBI_0001479))

Ultimately, for a given disease, we want to be able to differentiate the following:

+ a healthy sample from healthy individual
+ a healthy sample from diseased individual
+ a disease sample from diseased individual

Essentially, we want to support two types of case-control analyses based on a single set of annotations:

1. samples from healthy individuals versus diseased individuals
2. samples from healthy tissue versus diseased tissue, where all samples may come from diseased individuals

It seems that most existing ontologies are good at describing the characteristics of a single sample -- for example, its tissue of origin, the developmental stage of the donor, the phenotypes/diseases of the donor -- but they are not good at allowing tagging for the sole purpose of contrast.

@idrdex suggested that we could use ""qualifiers for the tags: like `PC_individual_case` vs `PC_individual_control` or `PC_tissue_case` vs `PC_tissue_control`"" I like this idea and think it is a good immediate solution.","17",2015-08-19,2015-08-19,2,1478,"base.profile","Daniel","Himmelstein","dhimmel"
"582","comments","rephetio","2015-08-20T06:09:34.741Z",17,"> Do the names on these edges actually matter based on how you are using the network?

@b_good, for predicting the probability of efficacy of a compound--disease pair, the metaedge names do not matter. The [algorithm](http://het.io/hnep) only considers the structure of the network. The names are used to assist with interpretability. For example, the *CtGad* feature (capturing when a compound targets genes that are associated with the disease) may be predictive. In this case, we would conclude that disease-associated genes are informative for repurposing. If what [we call](http://thinklab.com/discussion/processing-disgenet-for-disease-gene-relationships/105#6) an 'association' is actually some other type of relationship, then the interpretation that associations are influential will be unfounded.

When we have multiple metaedges between the same metanodes, we hope there is a difference in the type of information encoded. Otherwise, we would be better off having only a single metaedge. For example, we included [binding](http://thinklab.com/discussion/integrating-drug-target-information-from-bindingdb/53#5) and [target](http://thinklab.com/discussion/protein-target-carrier-transporter-and-enzyme-interactions-in-drugbank/65#1) edges between compounds and genes. It is unclear whether merging these edges would be beneficial, because it's difficult to know how they differ. Therefore, a good understanding what information each metaedge captures will assist with metagraph design. Accurate metaedge names can help with understanding edge content and therefore network design decisions.

> Would also like to see how the result of other text-ming approaches would influence the outcome. e.g. would it change things if you swapped in the relations from semmedDB?

Currently, I am happy with the quality of our [MEDLINE topic cooccurrence](http://thinklab.com/discussion/mining-knowledge-from-medline-articles-and-their-indexed-mesh-terms/67) approach. I assume that you highlight [SemMedDB](http://skr3.nlm.nih.gov/SemMedDB/) [@10.1093/bioinformatics/bts591] because it has the ability to extract the type of relationship. I agree this could be a valuable addition. However, in the interest of time, this will most likely have to wait till a successive project.","17",2015-08-20,2015-08-20,2,2282,"base.profile","Daniel","Himmelstein","dhimmel"
"583","comments","rephetio","2015-08-20T16:26:43.227Z",22,"@idrdex: We've been doing some extensive curation (i.e. back to the literature describing the experiments) on ~1000 samples that matter a lot to a project that we're working on. A couple questions about STARGEO:
1) Is it going to/does it also include samples from organisms other than human?
2) What's the best way to contribute these annotations? Anything programmatic and/or spreadsheet friendly?
3) What's the API like to extract annotations?

Thanks!
Casey","22",2015-08-20,2015-08-20,2,466,"base.profile","Casey","Greene","caseygreene"
"584","comments","rephetio","2015-08-20T17:07:44.875Z",121,"Analysis is working now here: http://dev.stargeo.io/analysis/","121",2015-08-20,2015-08-20,2,61,"base.profile","Dexter","Hadley","idrdex"
"585","comments","rephetio","2015-08-20T20:58:18.326Z",17,"# Preliminary processing complete

We processed DisGeNET by converting to DO Slim diseases ([notebook](https://github.com/dhimmel/disgenet/blob/b21553d7fced15c309f0a7aa15fc68e4d3edaa03/disgenet.ipynb), [download](https://github.com/dhimmel/disgenet/blob/b21553d7fced15c309f0a7aa15fc68e4d3edaa03/data/consolidated.tsv)). We used propagated mappings, so for example relationships with relapsing-remitting multiple sclerosis would be included for multiple sclerosis.

The result was 82,833 gene--disease associations. After filtering for scores ≥ 0.06, 7,779 associations remained with large variability in the number of associations per disease. Additionally, many of the associations appear to be 'genetic variation' edges, which may be captured by our [GWAS edge](http://thinklab.com/discussion/extracting-disease-gene-associations-from-the-gwas-catalog/80). As a reminder, the 0.06 score threshold includes the following (thanks @janispi):

> If you choose score ≥ 0.06, then you will be including associations reporting by curated sources, or having animal models supporting them, or being reported by several papers (20--200).

We mapped DO Slim terms to DisGeNET using UMLS cross-references. The UMLS cross-references in the DO were often non-exact, so one DO term would reference many UMLS terms. Several [UMLS terms](https://github.com/dhimmel/disgenet/blob/master/data/unmapped-umls.tsv) referenced by the DO were not in DisGeNET.","17",2015-08-20,2015-08-20,2,1445,"base.profile","Daniel","Himmelstein","dhimmel"
"586","comments","rephetio","2015-08-20T21:45:22.268Z",17,"We are looking into [DISEASES](http://diseases.jensenlab.org/Search) [@10.1016/j.ymeth.2014.11.020] as a resource for gene--disease relationships. This database is produced by @larsjuhljensen's group and follows similar protocols as [TISSUES](http://tissues.jensenlab.org/Search) [@10.7717/peerj.1054], which we have [already processed](http://thinklab.com/discussion/the-tissues-resource-for-the-tissue-specificity-of-genes/91).

DISEASES includes three types of evidence:

+ **text mining**: using named entity recognition to look for disease--protein cooccurrences in abstracts and sentences. @larsjuhljensen, which literature corpus was used?
+ **knowledge**: curated relationships from [GHR](http://ghr.nlm.nih.gov/) and [UniProtKB](http://www.uniprot.org/uniprot/) [@10.1093/nar/gkt1140]
+ **experiments**: cancer mutation data from [COSMIC](http://cancer.sanger.ac.uk/cosmic) [@10.1093/nar/gku1075 @10.1002/0471142905.hg1011s57] and GWAS data from [DistiLD](http://distild.jensenlab.org/about.html) [@10.1093/nar/gkr899]

We did a preliminary processing of the integrated dataset, which yielded 81,499 gene–disease relationships for [DO Slim](http://thinklab.com/discussion/unifying-disease-vocabularies/44#6) diseases ([notebook](https://github.com/dhimmel/diseases/blob/9ffce4c46d243392a66192ec879df153b2f6830a/diseases.ipynb), [download](https://github.com/dhimmel/diseases/blob/9ffce4c46d243392a66192ec879df153b2f6830a/data/integrated.tsv)). Filtering for scores ≥ 3, resulted in 2,441 relationships.

@larsjuhljensen, are scores in DISEASES comparable between datasets? In other words, are confidence scores standardized to a common gold standard?

We may consider creating an [integrated score](http://thinklab.com/discussion/the-tissues-resource-for-the-tissue-specificity-of-genes/91#7) excluding DistiLD, since we have a [distinct GWAS edge](http://thinklab.com/discussion/extracting-disease-gene-associations-from-the-gwas-catalog/80).","17",2015-08-20,2015-08-20,2,1964,"base.profile","Daniel","Himmelstein","dhimmel"
"587","comments","rephetio","2015-08-28T19:10:38.921Z",17,"# Network overview

We recently released the [first version](http://thinklab.com/discussion/one-network-to-rule-them-all/102) of our network containing 10 node types and 27 edge types. The network contains data (nodes and edges) extracted from [28 resources](https://github.com/dhimmel/integrate/tree/0e343d8745a98757c86e73f645b41353f52b82b5/licenses). Many of these 28 resources have themselves compiled data from disparately-licensed resources. In addition:

+ 12 lack any licensing information
+ 10 use standard licenses
+ 6 use custom licenses
+ 3 resources are publication supplements
+ 6 forbid commercial use
+ 2 forbid any redistribution of the data

# Why an open network

We [are committed](http://thinklab.com/discussion/enabling-reproducibility-and-reuse/23#6) to performing an open project, where all code, data, analyses, and results are maximally reproducible and reusable. The foundation of our research is that datasets are more informative when placed in a broader context. Through integration, we create a resource that is more informative and versatile than the 28 separate sources.

However, data integration is challenging and time intensive. Thus far, our integration effort consists of an 8 month time investment, 41 Thinklab [discussions](http://thinklab.com/p/rephetio/discussion), and 35 GitHub [repositories](https://github.com/dhimmel?tab=repositories). By making our network public and extensible, other researchers can avoid this laborious process while harnessing the benefits of integration.

# The licensing problem

We initially released our network under the [CC0](https://creativecommons.org/publicdomain/zero/1.0/) (public domain) license, but @larsjuhljensen [pointed out](http://thinklab.com/discussion/one-network-to-rule-them-all/102#2) that this may violate many sources' licensing. While we used only publicly available resources -- funded primarily by the public -- many resources are burdened by restrictive licenses. We now must integrate data with incompatible licenses that require legal expertise to understand and operate in jurisdiction dependent manners.

#  Compliance and caveats

We are seeking expert advice on how to proceed. We would like to achieve the following:

+ a network that is publicly available in full and maximally unrestricted
+ public domain findings. Foremost, unencumbered predictions of drug efficacy
+ legal compliance
+ normative compliance that respects the intent of the data creators
+ minimal pruning of the current network to preserve our investment

We plan to add node/edge-specific attribution and license information to our network, but will await expert advice before proceeding.","17",2015-08-28,2015-08-28,2,2698,"base.profile","Daniel","Himmelstein","dhimmel"
"588","comments","rephetio","2015-08-21T05:35:20.574Z",125,"Regarding the scores, they are designed to be as comparable as we could make them; however, it was not possible to do so purely through benchmarking, since a high-quality unbiased benchmark set does not exist.

If you already have GWAS from another source, I would exclude DistiLD too. You already import mutation data from e.g. COSMIC, I would exclude the experiments channel entirely. This also makes comparability of scores much less of an issue, since you're left with only automatically text-mined associations, which are scores the same way as tissue associations, and manually curated associations, which are inherently highly reliable.","125",2015-08-21,2015-08-21,2,645,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"589","comments","rephetio","2015-08-21T20:49:59.898Z",17,"# Completed processing

We have completed an initial processing of DISEASES ([notebook](https://github.com/dhimmel/diseases/blob/e0089ef89a56348d7d4e0684a9c51c5747b16237/diseases.ipynb)). The output is a tsv of gene--disease pairs ([download](https://github.com/dhimmel/diseases/blob/e0089ef89a56348d7d4e0684a9c51c5747b16237/data/merged.tsv.gz)) with scores for following channels:

+ text mining
+ knowledge
+ cosmic -- the COSMIC subset of the experiments channel
+ distild -- the DistiLD subset of the experiments channel
+ integrated_no_distild -- the integration of the four aforementioned scores
+ integrated -- the integrated score calculated by the DISEASES team, without any exclusions

Genes were converted to Entrez identifiers using the STRING 9.1 mapping ([`entrez_gene_id.vs.string.v9.05.28122012.txt`](ftp://string-db.org/STRING/9.1/mapping_files/Entrez_mappings/entrez_gene_id.vs.string.v9.05.28122012.txt)). We also created a dataset with only [DO Slim](http://thinklab.com/discussion/unifying-disease-vocabularies/44#6) diseases ([download](https://github.com/dhimmel/diseases/blob/e0089ef89a56348d7d4e0684a9c51c5747b16237/data/merged-slim.tsv)). For this file, we propagated scores from subsumed diseases and reported the max.

## Visualizing channel concordance

We visualized the relationships between scores on the full dataset. The off-diagonal plots show a 2D histogram, using hexagonal bins. The diagonal of the grid contains 1D histograms for the x-variable. Bin counts for all panels are log-transformed.

![](https://raw.githubusercontent.com/dhimmel/diseases/e0089ef89a56348d7d4e0684a9c51c5747b16237/figure/channel-histograms.png)","17",2015-08-21,2015-08-21,2,1676,"base.profile","Daniel","Himmelstein","dhimmel"
"590","comments","rephetio","2015-08-28T19:37:36.448Z",125,"You may also want to consider splitting the network into multiple files. For example, you may have a base file that includes, for example, only public domain and CC-BY content. The edges with SA and/or NC clauses could be in ""add-on"" files. This partially avoids the problem that your complete network file becomes subject to the lowest common denominator.

Having multiple files will allow people to ""pick their poison"", so to speak. If they need the most permissive license, they will get a less complete network. If they want the most complete network, they will have to live with a less permissive license.","125",2015-08-28,2015-08-28,2,612,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"591","comments","rephetio","2015-08-28T21:19:52.274Z",125,"Regarding the 12 that completely lack any licensing information, I would contact the authors. For academic databases/datasets, this is usually due to people not knowing that when it comes to copyright, the default is ""all rights reserved"". Academics often put things on the internet, thinking that this makes it ""public domain"". If you ask them, they will likely be happy to put a CC0 waiver or CC-BY license on it.","125",2015-08-28,2015-08-28,2,415,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"592","comments","rephetio","2015-08-29T19:43:43.418Z",17,"# Conda for R

Conda is an awesome package manager that [we've been using](http://thinklab.com/discussion/python-for-the-modern-biodata-scientist/84) for Python. In most cases, conda alleviates the horror of installation errors and dependencies.

Now conda is [available for R](http://continuum.io/conda-for-R). In other words, you can install R using the following command:

```shell
conda install --channel r r
```

I found many of my favorite R packages were available in conda's r channel, usually with `r-` prepended to their lowercased name. For example, I installed `r-ggplot2`, `r-tidyr`, `r-dplyr`, `r-caret`, and `r-glmnet`. For notebook support, I installed `rpy2` and `r-irkernel`.

Installing R packages that are not included in conda's channel became more difficult after the switch to conda management. For example, `devtools::install_github()` was failing, and when doing traditional package installation, I had to specify the repos argument because the GUI popup was broken:

```r
install.packages('readr', repos='http://cran.us.r-project.org')
```

Conda can definitely save R users lots of frustration, but I suggest the general user wait for greater maturity before adoption.","17",2015-08-29,2015-08-29,2,1213,"base.profile","Daniel","Himmelstein","dhimmel"
"593","comments","rephetio","2015-09-05T00:49:45.249Z",17,"# Workflow details

Our data workflow consists of three major stages. Each stage invokes various [aspects of copyright](http://www.smashingmagazine.com/2011/06/understanding-copyright-and-licenses/) as described below

## 1) Resource processing

Most resources require processing before they can be added to the network. Common steps include terminology conversion, quality control, subsetting, and record merging.

Our general procedure is to create a public GitHub repository for each resource (examples [1](https://github.com/dhimmel/diseases), [2](https://github.com/dhimmel/SIDER4), [3](https://github.com/dhimmel/lincs), [4](https://github.com/dhimmel/uberon), [5](https://github.com/dhimmel/drugbank)). Separate repositories help keep the project modular and reusable. Each repository contains a `download` directory where we store the unmodified input. Having the local copy is important for reproducibility because the original download location may become unavailable or serve an updated dataset. Therefore, our `download` directory redistributes unmodified data.

Next, we process data from the `download` directory and save the resulting datasets in the `data` directory. The processing steps generally change the database model and field names and include a substantial portion of the original data. However, the original data has usually been transformed in some regard.

**Proposed action**: apply the source's license to the contents of `download`. For the contents of `data`, apply either the source's license or CC0 if the underlying data is not [subject to copyright](http://www.bitlaw.com/copyright/database.html) or the derivative work qualifies as fair use. Resources without a license or that explicitly forbid redistribution are problematic. We propose contacting the creators of these resources for permission or licensing clarification. Components in these repositories that do not derive from protected resources will be released as CC0.

## 2) Integrative network

Our [`integrate`](https://github.com/dhimmel/integrate) repository combines the resource-specific data from stage 1 into a single network. The [`compile`](https://github.com/dhimmel/integrate/tree/master/compile) directory merges resources with the same type of information. The creation of the network is performed by [`integrate.ipynb`](https://github.com/dhimmel/integrate/blob/master/integrate.ipynb). We have [compiled](https://github.com/dhimmel/integrate/tree/master/licenses) the licenses for each resource. The network is saved as text files in the [`data`](https://github.com/dhimmel/integrate/tree/master/data) directory with [`hetnet.json.gz`](https://github.com/dhimmel/integrate/blob/master/data/hetnet.json.gz) as the main release. In this integrated network, the database model and field names from the original resource are not present, just derived data.

**Proposed action**: Adopt a per node/edge licensing framework. Identify which nodes and edges, if any, are eligible for CC0 release. CC0 release may be possible if the creators chose a permissive license or give us permission, the network is fair use, or if the underlying content is not subject to copyright.

## 3) Network analyses

Next, we use the integrated network from stage 2 for data mining. The purpose of the data mining is to evaluate methods, extract insights, and make predictions. As an example, see [this analysis](https://github.com/dhimmel/snplentiful) [@10.5281/zenodo.30105] of the network that @caseygreene and I recently did for a separate project.

Here, it is crucial that findings from analyses on the network are fair use and can be placed in the public domain. Since, the network contains data with [incompatible](https://wiki.creativecommons.org/wiki/Wiki/cc_license_compatibility) licenses such as CC-BY-SA and CC-BY-NC, data mining will be impossible if not considered fair use. In the US, [precedent](http://www.arl.org/storage/documents/TDM-5JUNE2015.pdf) implies our network analyses qualify as fair use. 

**Proposed action**: Identify whether our network analyses qualify as fair use and whether our results can be released as CC0. Evaluate when and if we are subject to European copyright laws, which are less favorable for content users.

# Expert feedback requested

We are seeking expert advice. Specifically, are the proposed actions compliant with copyright law? Regarding the three stages, are we on the right track? Will network analyses count as fair use?","17",2015-09-05,2015-09-05,2,4497,"base.profile","Daniel","Himmelstein","dhimmel"
"594","comments","rephetio","2015-09-05T00:58:52.840Z",17,"# Licensing and copyright

Thanks @larsjuhljensen for your helpful advice. We have created a [separate discussion](http://thinklab.com/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#4) for licensing and copyright to continue the conversation.","17",2015-09-05,2015-09-05,2,280,"base.profile","Daniel","Himmelstein","dhimmel"
"595","comments","rephetio","2015-09-05T01:01:19.214Z",17,"# Network name

We've realized it's a major impediment to not have a name for the network. We are tentatively calling the network `hetio-ind`. However, `rephetio` -- the current Thinklab handle for the project -- is also an option. Will update when the name is finalized.","17",2015-09-05,2015-09-05,2,273,"base.profile","Daniel","Himmelstein","dhimmel"
"596","comments","rephetio","2015-09-07T11:10:57.149Z",111,"To keep you posted: we were recently given access to the GTEx data, so we have started annotating/analyzing the data. We hope to have a new release of Bgee including these data in about 2 months.","111",2015-09-07,2015-09-07,2,195,"base.profile","Frederic","Bastian","fbastian"
"597","comments","rephetio","2015-09-08T02:16:42.932Z",135,"Your analysis of the situation looks great -- you've correctly described the difficulty of combining incompatible licenses and the data they cover, and the potential of fair use (for extracting data subsets and data mining) for what you're trying to do. And for the datasets that lack a license, you know that in many cases they aren't protected by copyright so you're free to do what you want. Federal government agencies are notorious for refusing to assign licenses or rights waivers to the data they release, claiming that everything they have and do is in the public domain and we should all just know that, so sometimes no license means you're fine. Your goal of making it clear to users what rights and licenses apply to which datasets is laudable.

The one thing I didn't see you covering is liability. I can't figure out who actually owns the work that you're doing -- you want to put it in the public domain, which is great, but do you personally have the right to do that? Are you working on a grant project or employed by a university that might claim ""ownership"" of your results? This is usually dealt with by the licenses. Apache open source software licenses include the language ""Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."" Even CC licenses include language like ""No warranties are given. The license may not give you all of the permissions necessary for your intended use. For example, other rights such as publicity, privacy, or moral rights may limit how you use the material."" So if you're using CC0 wherever you can, you might want a separate statement of warranty (or lack thereof) unless you want to be liable, or implicate your institution, if you do accidentally screw up (easy enough to do, in such a complex project, even when you've done everything you can). ","135",2015-09-08,2015-09-08,2,2052,"base.profile","MacKenzie","Smith","mackenziesmith"
"598","comments","rephetio","2015-09-09T05:39:13.885Z",17,"# Who owns the created work

After some background [reading](http://www.d.umn.edu/~pschoff/documents/ElliotR05WhoOwnsScientificDatapdf.pdf) [@10.1087/0953151053584984] and [video watching](https://www.youtube.com/playlist?list=PLYTiwx6hV33tXEfueCk5k7xyLePcqj4XK), who owns the work we're creating is not straightforward.

I am a graduate student at UCSF and my PI, @sergiobaranzini, is a professor at UCSF. I am largely, but not completely, funded by an NSF Graduate Research Fellowship whose conditions [state](http://www.nsf.gov/pubs/2015/nsf15597/nsf15597.htm):

> The National Science Foundation claims no rights to any inventions or writings that might result from its fellowship or traineeship grants.

## Copyright and the UC

The UC's 1992 ['copyright ownership' policy](http://copyright.universityofcalifornia.edu/resources/copyright-ownership.html) stipulates ownership by category of work. Several of these categories may apply:

+ academic appointee originator ownership of ""scholarly/aesthetic work""
> A scholarly/aesthetic work is a work originated by a designated academic appointee resulting from independent academic effort. Ownership of copyrights to scholarly/aesthetic works shall reside with the designated academic appointee originator, unless they are also sponsored works or contracted facilities works, or unless the designated academic appointee agrees to participate in a project which has special provisions on copyright ownership pursuant to Section V.C. of this Policy.

+ originator ownership of ""personal work""
> A personal work is a work that is prepared outside the course and scope of University employment (except for permissible non-University consulting activities) without the use of University Resources. Ownership of copyrights to Personal works shall reside with the originator.

+ originator ownership of ""student work"":
> A student work is a work produced by a registered student without the use of University funds (other than Student Financial Aid), that is produced outside any University employment, and is not a sponsored, contracted facilities, or commissioned work. Ownership of copyrights to student works shall reside with the originator.

+ university ownership of ""institutional work"":
> Except as otherwise provided in this Policy, the University shall own all copyrights to works made by University employees in the course and scope of their employment and shall own all copyrights to works made with the use of University resources.

Therefore, UC's asserted ownership is dependent on which categories our work falls under. Additional guidance [states](http://copyright.universityofcalifornia.edu/ownership/works-created-at-uc.html):

> University staff who create works within the scope of their employment generally do not own the copyright to the work. A work prepared by an employee within the scope of his or her employment is considered a ""work made for hire.""  When a work qualifies as a work made for hire, the employer or commissioning party is considered its author. Under UC policies, some written works created by certain categories of UC faculty, graduate students, and staff are considered works made for hire. 

Thus, the University's assertion of ownership may be contradicted by the [strong argument](http://chronicle.com/article/Employees-or-Not-/145573/) that graduate students, such as myself, are not employees and do not produce ""work made for hire"". Furthermore, the policies and guidelines are outdated and not well tailored towards the collaborative, digital, online, and open approach our project takes. The work I perform goes beyond the sole purposes of studentship, employment, and institutional work. And the academic community has established norms and precedent for allowing creators to transfer copyright and choose licensing -- the foremost examples being academic publishing and open source software contribution.

## Data and the UC

The UC ['copyright ownership' policy](http://copyright.universityofcalifornia.edu/resources/copyright-ownership.html) explicitly states that it only:

> addresses ownership of copyright; it does not address ownership or access to the underlying research results or data, as covered in Academic Personnel Manual Section 020. 

The Academic Personnel Manual [Section 020](http://www.ucop.edu/academic-personnel-programs/_files/apm/apm-020.pdf), dated in 1953, provides little clarification:

> All such research shall be conducted so as to be as generally useful as possible. To this end, the right of publication is reserved by the University. The University may itself publish the material or may authorize, in any specific case, a member or members of the faculty to publish it through some recognized scientific or professional medium of publication. A report detailing the essential data and presenting the final results must be filed with the University. Notebooks and other original records of the research are the property of the University.

Outside of official policy, UC appears to claim ownership of results and data. Quoting from a [talk](https://youtu.be/QQOEG_PyRWY) by @mackenziesmith:

> The University of California posits that it actually has a contractual obligation to maintain the ownership of all research data produced from grant funded projects by any researcher at UC, especially federally funded grants. So they claim that the university owns the data.

Additionally, a [UCSD guide](http://ucsd.libguides.com/c.php?g=90957&p=585144) states:

> + Data produced by UC researchers belong to the Regents of the University of California.
> + To promote sharing and unlimited use of your data, make your data available under a Creative Commons [CC0 Declaration](http://creativecommons.org/choose/zero).

These seemingly contradictory statements imply that UC may own the data but that its creators are free to release it into the public domain.

## Resolutions

We are looking for suggested courses of action to address the ambiguity and potential multiplicity of claims regarding ownership. Two possible actions are:

+ applying a *without warranty* clause to our licensing to limit our liability.
+ identifying all potential parties that may claim ownership and request permission to release the work as freely as possible given the [aforementioned considerations](#4).","17",2015-09-09,2015-09-09,2,6374,"base.profile","Daniel","Himmelstein","dhimmel"
"599","comments","rephetio","2015-09-08T05:32:04.663Z",125,"Regarding the problem of incompatible licenses, it is very important that you are clear on the difference between redistribution and data mining.

You write that ""Since, the network contains data with incompatible licenses such as CC-BY-SA and CC-BY-NC, data mining will be impossible if not considered fair use"". This is to my knowledge simply not true. There is no problem whatsoever in combining material from these incompatible licenses and mining it in any way that you want. The reason is that copyright purely has to do with how you are allow to redistribute things. And if the data mining leads to some results that are substantially different and not effectively a copy of the original material, there is also no problem in redistributing the results.

The problem comes when you want to make what is effectively a meta-resource that combines material from a lot of databases and redistributes it. In this case, you are redistributing something that is effectively a reformatted version of the material. In my opinion, your network falls squarely in that category

However, the solution is very simple. As I have suggested before, you can split the network into subnetworks, that are all redistributed under their respective licenses. You can bundle everything CC-BY-SA in one file and redistribute it under CC-BY-SA. You can bundle everything CC-BY-NC in another file and redistribute it under CC-BY-NC. And as described above, nothing prevents anyone in the world from legally downloading both files, combining them, and mining the data as they please.

To make it simpler, let me make an analogy from the world of text mining, where the situation is somewhat more clearcut, since there is no doubt that articles are subject to copyright law. I can download some articles under CC-BY-SA and some others under CC-BY-NC. I can run text mining on all of them despite the licenses being incompatible, and I can redistribute the results of my efforts under any license I please, because the results are my results, which are not simply a reformatting of the original text. However, I cannot take all the articles, combine them into a text corpus, and release it under CC0.

Caveats: I am not a lawyer, this does constitute legal advice etc.","125",2015-09-08,2015-09-08,2,2256,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"600","comments","rephetio","2015-09-08T05:32:43.986Z",125,"@mackenziesmith makes a very good point about liability, which in my opinion is why you should not attempt to take copyrighted material, claim fair use under US law, and slap a CC0 waiver on it.

Imagine someone in Europe were to download your network, assume that everything was free of copyright (which is what CC0 effectively promises), take all the SIDER data, and redistribute it under CC0. Since SIDER is covered by European *sui generis* database rights, they could get sued and would likely lose. Subsequently, they could choose to sue you for liabilities.

Caveats: I am not a lawyer, this does constitute legal advice etc.","125",2015-09-08,2015-09-08,2,636,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"601","comments","rephetio","2015-09-09T14:49:37.330Z",135,"At a workshop I organized at UC Davis last year -- Data Rights and Data Wrongs -- senior counsel from the UC Office of General Counsel (i.e., the university's lawyers) was very clear that UC retains ownership rights to original data as the official 'grantee' and to insure compliance with federal laws for research conduct, etc. I think the relevant policy is here http://www.ucop.edu/raohome/cgmemos/84-31.html (old but still in effect). So I think your assessment is right that UC asserts ownership but allows you to release the data under reasonable terms, including CC0. However most of the data you're working with isn't original to you, so what UC 'owns' is your own findings and if you did something wrong, the university is liable to some extent. 

Of course, finding all the rights holders and getting their explicit permission to do what you're doing would be ideal, but is that practical? Do you even know who holds the rights to all the data sources? I disagree with the point that you can't rely on Fair Use and release your results under a CC0 waiver -- I believe that's what Fair Use is for, if it's truly transformative -- but you might want to be explicit about the waiver of liability. Especially given how gray the area you're working in is, legally speaking.","135",2015-09-09,2015-09-09,2,1280,"base.profile","MacKenzie","Smith","mackenziesmith"
"602","comments","rephetio","2015-09-16T20:27:18.620Z",20,"Most people I have discussed this with, would understand what heterogeneous networks mean without much ambiguity. I realize that it may not be completely specific to the kind of work we are doing here, but a balance between specificity and name simplicity needs to be reached. In my view, HetNets does it. ","20",2015-09-16,2015-09-16,2,306,"base.profile","Sergio","Baranzini","sergiobaranzini"
"603","comments","rephetio","2015-09-16T21:29:39.630Z",17,"# Preliminary adoption of 'hetnet'

I agree with the previous two comments that ""hetnet"" is a good term. The term transforms ""heterogeneous network"" into a [solid compound noun](https://en.wikipedia.org/wiki/English_compound#Types_of_compound_nouns).

However, I prefer [sentence case](https://en.wikipedia.org/wiki/Letter_case#Sentence_case) (hetnet) to [camel case](https://en.wikipedia.org/wiki/CamelCase) (HetNet). Removing the camel case improves the aesthetics and differentiates the term from its [computer networking usage](https://en.wikipedia.org/w/index.php?title=Heterogeneous_network&oldid=629383185#HetNet).

The term respects its lineage through compatibility with ""heterogeneous network"" and ""heterogeneous information network"".

I have begun publicly using the term hetnet. For example, I [renamed](https://github.com/dhimmel/hetio/commit/869a67858086c9168ae50d693393ade2308f51ce)  the`hetio.graph` module to `hetio.hetnet` to better describe the content. I also [now](https://github.com/dhimmel/hetio/commit/a006a862d1501ec322bd172dc55cb6f3fe83301a) describe the hetio [package](https://github.com/dhimmel/hetio) as ""Hetnets in Python"".","17",2015-09-16,2015-09-16,2,1162,"base.profile","Daniel","Himmelstein","dhimmel"
"604","comments","rephetio","2015-09-19T17:41:55.442Z",17,"# Curation pilot results

@sergiobaranzini recruited two UCSF physicians -- [Ari Green](http://greenlab.ucsf.edu/ari-j-green-md) (AJG) and [Christine Hessler](http://profiles.ucsf.edu/christine.hessler) (CSH) -- for the curation task. We asked the curators to independently classify 50 random indications as disease modifying or symptomatic. See the raw results for [AJG](https://github.com/dhimmel/indications/blob/49efba793216dcaf739fe22a32f60c4549aa3f7a/curation/pilot/ajg.tsv) and [CSH](https://github.com/dhimmel/indications/blob/49efba793216dcaf739fe22a32f60c4549aa3f7a/curation/pilot/csh.tsv).

## Combined results

While we did not specify that ""not an indication"" was an option, both curators identified these instances. While our indication dataset derives from high precision datasets, non-indications will be present. Thus, going forward we will include ""not an indication"" as a classification.

I cleaned the curators free text into 3 classifications: `DM` for disease modifying, `SYM` for symptomatic, and `NOT` for not an indication. This cleaning step required some inference on my part and thus could have introduced a minor bias. The [combined results](https://github.com/dhimmel/indications/blob/49efba793216dcaf739fe22a32f60c4549aa3f7a/curation/pilot/combined.tsv) show 66% agreement, with the following breakdown by curator:

| class | ajg | csh |
|-------|-----|-----|
| DM | 26 | 32 |
| SYM | 20 | 17 |
| NOT | 4 | 1 |

The pilot suggests that the compiled indications are ~58% disease modifying, ~37% symptomatic, and ~5% non-indications.

## Definitions

We did not provide the curators with clear definitions of disease modifying and symptomatic. Our plan is to use the pilot experience to help define the categories. Preferably, these definitions should be crafted by the physicians.

Informally, CSH defined disease modifying as:

> any agent that changes the course of the illness or complications of the illness (not necessarily curing the disease, but preventing ""flares"" or complications). I'd ask myself, ""is it poor form not to prescribe this medication to my patient with disease y and could I be sued for it?""

And symptomatic as:

> agents that are used purely for patient's comfort and don't alter the course of the disease at all. 

## Cocaine and cavities

One bizarre indication was [cocaine](http://www.drugbank.ca/drugs/DB00907) and [dental carries](http://www.disease-ontology.org/term/DOID%3A216), which was contributed [by](https://cdn.rawgit.com/dhimmel/indications/6375b195df61b6e0d44c4690abfa2ac0710bc690//merge.html#indication-table) MEDI-HPS [@10.1136/amiajnl-2012-001431]. Since MEDI doesn't report its sources for individual indications and the authors [did not release](http://thinklab.com/discussion/medi-indications-data-discrepancy-in-resource-specific-counts/31#2) this data upon request, tracking down the provenance of this indication is difficult. However, MEDI does [specify](https://cdn.rawgit.com/dhimmel/indications/6375b195df61b6e0d44c4690abfa2ac0710bc690/medi/) that this indication existed in SIDER 2 [@10.1038/msb.2009.98], which text mined drug labels. Presumably, [this label](http://www.drugs.com/pro/cocaine-hydrochloride-topical-solution.html) for Cocaine Hydrochloride Topical Solution (brand name C-Topical) was the source for the cocaine--cavities indication. The label states the solution ""is indicated for introduction of local (topical) anesthesia of accessible mucous membranes of the oral, laryngeal and nasal cavities."" This suggests a non-indication or at most a symptomatic indication between cocaine and dental caries. However, for a SIDER 2 indication to be included in MEDI-HPS, at least one other source must report the indication. AJG informally suggested that the ""reason for the hit is that cocaine accelerates dental caries and might therefore be considered disease modifying (but in a bad way).""

## Next steps

The pilot experience proved the importance of expert curation of our compiled indication catalog. Before proceeding with the remaining indications, we should formally define the three classifications (DM, SYM, NOT). Clear definitions may increase the agreement between curators, but a final resolution stage for conflicts will be necessary.","17",2015-09-19,2015-09-19,2,4282,"base.profile","Daniel","Himmelstein","dhimmel"
"605","comments","rephetio","2015-10-02T22:20:16.909Z",17,"Recently, I went a two-part meetup series on the graph database [neo4j](http://neo4j.com/). [Nicole White](http://nicolewhite.github.io/) led the meetups and her materials are online:

1.  neo4j: Intro to Graphs ([slides](https://www.dropbox.com/s/zv0s4lwc6gvwxjy/Galvanize.pptx?dl=0), [meetup](http://www.meetup.com/SF-Data-Science/events/224956828))
2. Data Science with Python and Neo4j ([tutorial](http://nicolewhite.github.io/neo4j-jupyter/main.html), [repository](https://github.com/nicolewhite/neo4j-jupyter), [meetup](http://www.meetup.com/SF-Data-Science/events/224406352))

Currently, we store our hetnets in compressed json text files. To perform any computation or graph analyses, we must load the network into memory, a process that takes from 2--5 minutes for version one of our [network](http://thinklab.com/discussion/one-network-to-rule-them-all/102#1). In contrast neo4j provides persistent storage with immediate access.

Additional benefits of neo4j include a mature [ecosystem](https://github.com/GraphGeeks/awesome-neo4j) offering broad functionality. The [Cyper](http://neo4j.com/developer/cypher-query-language/) query language is especially exciting. Cypher uses an ASCII-art based syntax to enable advanced graph lookups and traversals with little boilerplate.

## Comparison to hetio

There are a few differences between neo4j and our python package [hetio](https://github.com/dhimmel/hetio) [@10.5281/zenodo.31763] with regards to hetnets:

+ **nomenclature** -- an edge in hetio is called a relationship in neo4j. hetio calls itself a [hetnet](http://thinklab.com/discussion/renaming-heterogeneous-networks-to-a-more-concise-and-catchy-term/104), while neo4j calls itself a [property graph](http://neo4j.com/developer/graph-database/#property-graph)
+ **node type** -- in hetio each node belongs to one metanode representing its type. in neo4j node are annotated with a label to indicate type, and a node can have ≥ 0 labels
+ **directionality** -- in hetio metaedges are either directed or undirected and edges conform to their metaedge's directionality. neo4j doesn't support undirected edges. The [suggested workaround](http://graphaware.com/neo4j/2013/10/11/neo4j-bidirectional-relationships.html) is to arbitrarily choose a direction upon creation and ignore the direction when querying
+ **type graph** -- hetio requires a predefined graph of types called a metagraph. neo4j does not enforce or explicitly support a graph of type definitions
+ **inverted edges** -- hetio internally stores two copies of each edge (inverses of each other)

We plan to create export functionality from hetio to neo4j, so we can leverage the strengths of neo4j.","17",2015-10-02,2015-10-02,2,2696,"base.profile","Daniel","Himmelstein","dhimmel"
"606","comments","rephetio","2015-09-22T20:42:41.586Z",137,"Hi all,
I am **a** lawyer, but not **your** lawyer (or UC’s lawyer), and this isn’t legal advice. Also, I’m not yet familiar with the data sources or the project at a high level of detail - but here’s what I can say about the general issues.

#I. U.S. law
##   A. Layers of copyright
1. I notice that you’ve generally got a single assessment of copyright/licensing issues associated with each data source. I could see each one having up to three. For instance, you could have facts that both the original distributor and the downstream user agree are in the public domain - layer 1, you can do anything with those if you’ve extracted them and rearranged them. They could be collected and shared in a database that’s licensed under something like CC BY-SA, and the terms of that license would need to be followed when distributing the whole database, or parts of it, in such a way that you were copying & distributing the licensor’s copyrightable arrangement/selection/original authorship. The database is layer 2. Then you might have special software created by the data distributor to access and manipulate the data and/or the database, and that might be licensed separately, either with a CC license or with an open source software license like MIT or BSD. That’s layer 3. Without being an expert on these particular databases, I’m guessing 2 and 3 are often going to be the same thing, but it’s best not to just assume that.
2. If no license terms are posted, the underlying facts are in the public domain, and any copyrightable expression like software, or creative arrangement, is copyright default’s “all rights reserved.”
3. Why am I bothering to spell this out? Depending on the terms of these things and how you want to use/redistribute them, it’s possible that something like the GSEA/MIT terms that look really restrictive may not be a hurdle. I read that one to limit what you can do with layers 2 (“the DATABASE”) and 3 (“the PROGRAM”), but less so layer 1. If you’re committed to redistribution of layer 2 wholesale, then yeah, we’ve got barriers.
##   B. Particular licenses
1.  Software licenses are more commonly used for software than CC licenses are, although either would theoretically work. UC recommends BSD and MIT licenses in particular, because they don’t say anything about patents.
2. There’s some interesting stuff in the fine print of the CC licenses that might be helpful. For instance, the SA requirement has to be retained by the original material, and has to be attached to any “Adapted Material.” But not every use of a work is “Adapted Material.” Compilations generally aren’t an adaptation, so maybe there’s some creative thinking to be done around that. Attribution requirements can be satisfied in “any reasonable manner based on the medium, means, and context,” and maybe we could do some thinking about what’s a reasonable manner in *this* context.
##   C. The CC0 dedication
1. Like the CC licenses, the CC0 dedication only applies to … what it *can* apply to. Just the things the licensor has the ability to waive rights to. Here’s the language:
*Affirmer disclaims responsibility for clearing rights of other persons that may apply to the Work or any use thereof, including without limitation any person's Copyright and Related Rights in the Work. Further, Affirmer disclaims responsibility for obtaining any necessary consents, permissions or other rights required for any use of the Work.*
On the bright side this means that theoretically, you can just release your own layer/contributions/authorship as CC0, without affecting the things you reference or incorporate. Unfortunately, this isn’t so helpful for downstream users who have to try to figure out what the CC0 applies to and what other rights are lurking there. Lots of explanation, labeling, help pages, etc. can be useful if people read them.
##   D. UC and data “ownership”
1. I’m going to keep putting “ownership” in quotes until something official explains to me, to my satisfaction, exactly what UC is claiming to own. The APM policy they seem to rely on from the 50s talks about records, like notebooks. Data can only be owned to the extent there’s intellectual property involved, like patent, copyright, or trade secrets. If none of those are present, there’s nothing to own. There may be contractual restrictions about what you can or must do with something, that you’ve agreed to as part of an employment agreement or a grant agreement, but that’s a different animal, and will be more explicit than the automatic rights involved in copyright.
2. Depending on how this project is funded I think any copyrightable work here - the software, for instance - could be student work, personal work, or institutional work, under the 1992 Copyright Ownership Policy. It’s unlikely to be a scholarly/aesthetic work because of the definition of “designated academic appointee,” but I don’t know who the co-authors are.
3. UC’s lawyers - OGC and general counsel - will generally weigh in to assess legal risk to the university or disposition of university intellectual property. They will not/cannot provide advice about liability to an individual, or assessment of their personal intellectual property.
4. Each campus has a designated authority who is authorized to approve licensing decisions and the like on that campus. I believe UCSF’s is Karin Immergluck. In my experience, if we get to a place where we decide “well, this project includes copyrights owned by UCSF, but we want to license them CC BY or dedicate them to the public domain,” an email to the relevant campus person explaining the rationale (and preferably why this isn’t something the university would make money off of) results in a quick approval.
##   E. Contracts
1. U.S. copyright law includes all kinds of rights for users, including fair use, and the fact that certain things are in the public domain. But you can sign a contract giving away any of these rights. To the extent that you have to agree to restrictive terms to get access to a data set, those terms may effectively limit your rights to reuse even factual data. It’s like when libraries sign a license for a ProQuest database and promise not to make any copies of newspaper articles from the 1800s.
#II. International law
##   A. Database protection generally
Lots of countries protect a database, but not the underlying facts, with copyright law. I see you found the Bitlaw page on this, which is where I would have sent you.
##   B. European database directive
I’ve never had occasion to deal with this before, but there’s a parallel thing in some countries like Italy for, e.g. digitizing old manuscripts. Limited protection as an incentive to create the thing or make it accessible. It sounds like enough of a pain that it’s probably worth figuring out which of the proposed sources are covered. That may be time consuming and difficult - so, something for further discussion/research.
##   C. International liability for potential copyright infringement
This is a tricky issue, and a fun subject for law review articles. Most of them revolve around *selling* things internationally, for a couple reasons. First, that’s when you’re likely to make people mad enough to bother with suing you. Second, there are jurisdictional issues about how much you have to do in a country to subject yourself to a lawsuit there. All I can say is that internet plus free distribution doesn’t automatically equal global legal risk. But that may not matter much because...
#II. There’s law, and then there’s politics.
If we were looking at hundreds of sources, contacting them individually would be a horrible thing to contemplate. With a couple dozen, it might be worth it to put together a form letter to let people know about the project, to avoid burning bridges with current colleagues and potential future collaborators. This could address the things these folks are most likely to be concerned about: what is this project doing with the data sources? How will downstream users be able to tell the source of the data? What things will facilitate or burden commercial use? And there could be a few different versions depending on the legal assessment of the underlying rights and which ones the project implicates - maybe a letter to US sources is more of an FYI, and one to European sources asks them to reply granting permission. Or maybe if the project really wants *everything* to be as open as possible, you just actually get permission from everyone to a release of some version of their data, in this context, under your chosen license. Just because they make it available to the world under, e.g., CC BY-SA doesn’t mean they can’t make it available to you under different terms. There are options. None of them are as easy as “just use it,” but if people have tried to restrict how their stuff is used you have to decide the relative value you place on maximizing your rights under the law vs. maintaining goodwill.

","137",2015-09-22,2015-09-22,2,8988,"base.profile","Katie","Fortney","katiefortney"
"607","comments","rephetio","2015-09-28T18:33:52.869Z",17,"We currently rely on [MSigDB](http://www.broadinstitute.org/gsea/msigdb/index.jsp) [@10.1073/pnas.0506580102 @10.1093/bioinformatics/btr260], the Molecular Signatures Database, for perturbation gene sets and pathways. Since the [license](https://github.com/dhimmel/integrate/blob/afe1c049e4a088bc266533332e6e00499e3d2e20/licenses/custom/MSigDB.asciidoc) is highly restrictive, we have emailed the creators with the below message. We will post any updates regarding MSigDB licensing or permissions on this discussion.

***

Greetings MSigDB Team,

I am a graduate student at UCSF, and I have been using [MSigDB](http://www.broadinstitute.org/gsea/msigdb/index.jsp) for my research. My project aims to predict new uses for existing drugs by integrating many different types of biomedical information. Recently, the issue of database copyright and licensing [came up](http://thinklab.com/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107), and we are now trying to ensure that we have sufficient permissions for each of the 28 databases we're integrating.

I was surprised to learn of MSigDB's restrictive [license](http://www.broadinstitute.org/cancer/software/gsea/wiki/index.php/License_info) that forbids redistribution, especially given the projects [public funding](http://grantome.com/grant/NIH/R01-CA121941-06A1). Currently, several resources I have created may be non-compliant with the license:

My GitHub repository ([`dhimmel/msigdb`](https://github.com/dhimmel/msigdb)) for parsing the MSigDB database contains:

+ unmodified MSigDB downloads
+ a reformatted version of the underlying data

My GitHub repository ([`dhimmel/pathways`](https://github.com/dhimmel/pathways)) for combining pathway databases contains:

+ the reformatted version of C2:CP from `dhimmel/msigdb` and a derived dataset containing pathways from other resources

My GitHub repository ([`dhimmel/integrate`](https://github.com/dhimmel/integrate)) for integrating many resources into a single network contains:

+ the majority of MSigDB 5.0 C2:CP and C2:CGP data stored as network nodes and edges.

My [website](http://het.io/disease-genes/downloads/) for a previous project [@10.1371/journal.pcbi.1004259] contains:

+ a network download formatted as in `dhimmel/integrate`, but containing data from most collections in MSigDB version 3.0.

The public availability of the aforementioned resources is important so others can reproduce and build off of our work. Thus, we request permission for our current redistribution and derivative works of MSigDB. Ideally, we could be granted permission to release MSigDB data under a [Creative Commons license](https://creativecommons.org/licenses/) without a No Derivatives restriction. Applying a CC license would lessen the burden on downstream users.

Thanks for your consideration. Our research is academic in nature, and we suspect it falls under the intended use of MSigDB but perhaps not the license.

Finally, we're performing our project using an open science platform called Thinklab. I've [posted a copy](#1) of this email on Thinklab and will update the discussion with our progress. Alternatively, feel free to respond via Thinklab rather than email. By detailing each step of our research process publicly, we're hoping to create a valuable resource and explore a more holistic and collaborative medium of publication.

Sincerely,
Daniel","17",2015-09-28,2015-09-28,2,3440,"base.profile","Daniel","Himmelstein","dhimmel"
"608","comments","rephetio","2015-09-28T18:06:50.053Z",17,"# Mixed copyright licensing

As explained [above](#4), we have created resources (mostly GitHub repositories) that contain content with varying licenses and restrictions. Therefore, we need to:

+ license different files from the same repository under different licenses
+ license different portions within a single file under different licenses

It appears that there is not a rigid formula for how to specify mixed copyright. I found a few examples including the [neo4j source code](https://github.com/neo4j/neo4j/blob/5f991933fa531f7dd901d4b6570fe78d73f8bb3c/README.asciidoc) and a [license](https://github.com/lucidv01d/samasy/blob/32148fdd01c1993a991787d23f4c851ff26f7c01/LICENSE) the [UCSF Office of Innovation, Technology & Alliances](https://ita.ucsf.edu/) created for my classmate.

In the later case, my classmate asked the ITA to assist him in creating an open source license. As @mackenziesmith predicted, UC asserted ownership of the content and forbid any for-profit usage. As an aside, I am highly confident that UC does not own my work, because it is not *work made for hire*, and I never agreed to any transfer of ownership.

## Proposed license for the SIDER4 repository

SIDER 4 is a resource [we're using](http://thinklab.com/discussion/extracting-side-effects-from-sider-4/97) for drug side effects. I propose the [following license](https://github.com/dhimmel/SIDER4/blob/45d0ba626e406ae3ce6f8f503f09d5af9b4b7b63/LICENSE.md) for the repository:

> SIDER 4 data is [released](http://sideeffects.embl.de/download/) under a [CC-BY-NC-SA](http://creativecommons.org/licenses/by-nc-sa/4.0/) license. Therefore, all redistributed and derived content from SIDER 4 is [CC-BY-NC-SA](http://creativecommons.org/licenses/by-nc-sa/4.0/). All original content is released under [CC0](https://creativecommons.org/publicdomain/zero/1.0/).

> Accordingly, the following files are [CC-BY-NC-SA](http://creativecommons.org/licenses/by-nc-sa/4.0/):

>
+ `download/meddra_all_indications.tsv.gz`
+ `download/meddra_all_se.tsv.gz`
+ `download/meddra_freq.tsv.gz`
+ `data/indication.tsv`
+ `data/side-effects.tsv`

> **Disclaimer**: The repository is provided ""as is"", without warranty of any kind, express or implied, including but not limited to the warranties of merchantability, fitness for a particular purpose and noninfringement. In no event shall the authors or copyright holders be liable for any claim, damages or other liability, whether in an action of contract, tort or otherwise, arising from, out of or in connection with the repository or the use or other dealings in the repository.

We added the disclaimer to limit our liability as [suggested](#4) by @mackenziesmith. Does the proposed license seem adequate? Is it clear? @katiefortney, any suggestions?","17",2015-09-28,2015-09-28,2,2800,"base.profile","Daniel","Himmelstein","dhimmel"
"609","comments","rephetio","2015-09-28T22:59:26.416Z",17,"We're currently using LINCS L1000 data for compound--gene and gene--gene edges in our [network](http://thinklab.com/discussion/one-network-to-rule-them-all/102). Thus far we have developed methods for computing [consensus expression signatures](http://thinklab.com/discussion/computing-consensus-transcriptional-profiles-for-compounds-using-lincs/43) and [mapping LINCS compounds](http://thinklab.com/discussion/unichem-mapping-to-lincs-small-molecules/51) to other identifier systems. However, @larsjuhljensen [pointed out](http://thinklab.com/discussion/one-network-to-rule-them-all/102#2) that the [license](https://github.com/dhimmel/integrate/blob/afe1c049e4a088bc266533332e6e00499e3d2e20/licenses/custom/L1000.md) requires permission for redistribution:

> If you have a derivative work that is significantly different from what we provide and you would like to distribute it, please contact us with the details. Our goal is to encourage significant improvements while maintaining provenance and reproducible research standards.

Therefore, we have emailed the LINCS L1000 team with the following permission request. We will post any updates regarding licensing or permissions on this discussion.

***

Greetings LINCS L1000 Team,

I am a graduate student at UCSF, and I have been using [LINCS L1000](http://www.lincscloud.org/) for my research. My project aims to predict new uses for existing drugs by integrating many different types of biomedical information. Recently, the issue of database copyright and licensing [came up](http://thinklab.com/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107), and we are now trying to ensure that we have sufficient permissions for each of the 28 databases we're integrating.

Currently, several resources I have created may be non-compliant with the license.

My GitHub repository ([`dhimmel/lincs`](https://github.com/dhimmel/lincs)) contains:

+ Python code from [`cmap/l1ktools/python/cmap`](https://github.com/cmap/l1ktools/tree/7f1752e87bbaeeedfce18c68f84c4e1feb331e9e/python/cmap)
+ [Data](https://github.com/dhimmel/lincs/tree/69956dec590ce4caace9df31f5b60c978f321fdc/data) retrieved from the [API](http://api.lincscloud.org/) in an unmodified json format and a condensed tsv format.
+ [Consensus signatures](https://github.com/dhimmel/lincs/tree/69956dec590ce4caace9df31f5b60c978f321fdc/data/consensi) for DrugBank compounds, gene overexpressions, gene knockdowns, and perturbations. Our consensus signatures combine *z*-scores from multiple signatures. We [computed](http://thinklab.com/discussion/computing-consensus-transcriptional-profiles-for-compounds-using-lincs/43#6) our signatures using a method suggested to us during LINCS office hours, with some modifications.
+ Our [`.gitignore`](https://github.com/dhimmel/lincs/blob/69956dec590ce4caace9df31f5b60c978f321fdc/.gitignore) file prevents the following items from being uploaded to the repository: our private API key, `modzs.gctx`, and a local database (`l1000.db`) that is too large for GitHub.
+ An archived version of this repository is [hosted](https://doi.org/10.5281/zenodo.27229) on Zenodo [@10.5281/zenodo.27229].

My GitHub repository ([`dhimmel/integrate`](https://github.com/dhimmel/integrate)) for integrating many resources into a single network contains:

+ Consensus signatures for DrugBank compounds and genetic perturbations (gene overexpressions and knowdowns) encoded as network nodes and edges.

@leobrueggeman assisted with the LINCS analysis. His GitHub repository ([`LABrueggs/L1000`](https://github.com/LABrueggs/L1000/tree/8720f12c25bdc46ef789785c474b8f0af9200fcf)) contains elements similar to `dhimmel/lincs` discussed above. Two files of consensus signatures from his repository are [posted](https://doi.org/10.6084/m9.figshare.1476293) to figshare [@10.6084/m9.figshare.1476293].

The public availability of the aforementioned resources is important so others can reproduce and build off of our work. We have attempted to provide sufficient information for provenance and reproducibility but are happy to make any modifications to assist in these regards.

Thus, we request permission for our current usage of LINCS L1000 data. Ideally, we could be granted permission to release the data under a [Creative Commons license](https://creativecommons.org/licenses/) without a No Derivatives restriction. Applying a CC license would lessen the burden on downstream users.

Thanks for your consideration. Our research is academic in nature, and we suspect it is in line with the intended use of LINCS.

Finally, we're performing our project using an open science platform called Thinklab. I've [posted a copy](#1) of this email on Thinklab and will update the discussion with our progress. Alternatively, feel free to respond via Thinklab rather than email. By detailing each step of our research process publicly, we're hoping to create a valuable resource and explore a more holistic and collaborative medium of publication.

Sincerely,
Daniel","17",2015-09-28,2015-09-28,2,5057,"base.profile","Daniel","Himmelstein","dhimmel"
"610","comments","rephetio","2015-09-29T14:19:20.369Z",17,"# Entrez Gene *Homo sapiens* gotcha

The `Homo_sapiens.gene_info.gz` [download](ftp://ftp.ncbi.nih.gov/gene/DATA/GENE_INFO/Mammalia/) from Entrez Gene contains a potential [gotcha](https://en.wikipedia.org/wiki/Gotcha_%28programming%29). A small number of records at the end of the file are for:

+ Neanderthal ([`tax_id = 63221`](http://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?mode=Info&id=63221))
+ Denisovan ([`tax_id = 741158`](http://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?mode=Info&id=741158))

We only want genes for non-extinct *Homo sapiens* ([`tax_id = 9606`](http://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?mode=Info&id=9606)). We've [updated](https://github.com/dhimmel/entrez-gene/commit/1ff24cce1cbabfb7029704426b5dc4b654e484a4) our Entrez Gene processing to filter for a 9606 tax_id.

The downstream effects of this update should be minimal, since only 73 genes were removed (all mitochondrial). However, we may rebuild some of our resources if necessary. The inclusion of these genes should only present problems when matching by symbol rather than GeneID. We avoid matching by symbol whenever possible.","17",2015-09-29,2015-09-29,2,1155,"base.profile","Daniel","Himmelstein","dhimmel"
"611","comments","rephetio","2015-09-30T17:04:25.075Z",17,"# Chronicling licensing and permission requests

Inspired by the story of Max Haeussler [@10.1038/483134a] who [publicly documented](http://text.soe.ucsc.edu/progress.html) his permission requests to publishers to text mine their corpora, I will be chronicling our licensing efforts that require contact. We will therefore release summaries and statistics pertaining to three types of requests:

+ permission requests to resources with licenses that **forbid redistribution or derivatives**. We have begun by posting our requests to [MSigDB](http://thinklab.com/discussion/msigdb-licensing/108) and [LINCS L1000](http://thinklab.com/discussion/lincs-l1000-licensing/110).
+ requests to post licenses for resources **without licensing information**. Resources for which we could not find license information are [available here](https://github.com/dhimmel/integrate/tree/0e343d8745a98757c86e73f645b41353f52b82b5/licenses). We have already emailed the creators of these resources and will report back with progress.
+ for datasets obtained from **publication supplements**, license clarification or permission requests to the journal.","17",2015-09-30,2015-09-30,2,1138,"base.profile","Daniel","Himmelstein","dhimmel"
"612","comments","rephetio","2015-10-01T23:23:51.066Z",17,"## Definitions

In a meeting yesterday, we (Ari Green, Christine Hessler, @dhimmel, @sergiobaranzini) discussed the pilot experience and definitions. 

AJG pointed out that the term ""disease modifying"" is primarily used for rheumatology and multiple sclerosis. With this caveat in mind, we set out to identify a general definition that could apply broadly to complex disease. 

When considering possible definitions, @sergiobaranzini and I stressed the following quality of a ""disease modifying"" indication:

> If we predicted this indication, would the disease be considered an appropriate and precise application of the drug.

### We agreed on the following definitions:

+ **disease modifying** (`DM`) -- a drug that therapeutically changes the underlying or downstream biology of the disease
+ **symptomatic** (`SYM`) -- a drug that treats a significant symptom of the disease
+ **non-indication** (`NOT`) -- a drug that neither therapeutically changes the underlying or downstream biology nor treats a significant symptom of the disease

We also agreed on the following **guidelines**:

+ **reasonable evidence** of efficacy is required to be classified as disease modifying or symptomatic
+ if no classification accurately describes an indication, the **most appropriate** (although imperfect) classification should be chosen

## Next steps

AJG and CSH found many of their disagreements on the pilot indications resolved once a common definition was reached. With these definitions, we will now move onto the full set of indications, which AJG and CSH have agreed to curate.","17",2015-10-01,2015-10-01,2,1604,"base.profile","Daniel","Himmelstein","dhimmel"
"613","comments","rephetio","2015-10-02T01:58:42.602Z",17,"Our protein interaction catalog includes data from the supplementary material of the Incomplete Interactome publication [@10.1126/science.1257601]. Specifically, [we incorporate](http://thinklab.com/discussion/creating-a-catalog-of-protein-interactions/85#9) a subset of `DataS1_interactome.tsv`.

The [License to Publish](http://www.sciencemag.org/site/feature/contribinfo/prep/4__2014LicensetoPublish_Final_6MAR2014.pdf) agreement for *Science*, which authors must sign, states that:

> In consideration of publication by AAAS in one of its Science journals of the work currently titled [title] and **all associated supplemental materials, data**, audio and/or video files (the ""Work"") and authored by [author] (""Author""), the **sole and exclusive, irrevocable right** is hereby granted to AAAS to **publish, reproduce, distribute, transmit, display, store, translate, create derivative works** from and otherwise use the Work in any form, manner, format, or medium, whether now known or hereafter developed, throughout the world and in any language, for the entire duration of any such right and any renewal or extension thereof and to permit/sublicense others to do any or all of the foregoing as well.

I bolded the relevant phrases that lead me to believe that we require the permission of the AAAS rather than the dataset authors. *Science's* [reprints and permissions page](http://www.sciencemag.org/site/about/permissions.xhtml) suggested using the Copyright Clearance Center's Rightslink service. I made an account, but my request was not supported by Rightslink. Therefore, I emailed the AAAS Permissions Department with my special request. This is our first [request to a publisher](http://thinklab.com/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#12) regarding supplementary data. The email is below.

***

Dear AAAS Permissions Department,

I am a graduate student at UCSF, and I have been using supplementary data from [Menche et. al 2015](https://doi.org/10.1126/science.1257601) for my research. My project aims to predict new uses for existing drugs by integrating many different types of biomedical information. Recently, the issue of database copyright and licensing [came up](http://thinklab.com/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107), and we are now trying to ensure that we have sufficient permissions for each of the 28 databases we're integrating.

Currently, several resources I have created may be non-compliant with your terms.

My GitHub repository ([`dhimmel/ppi`](https://github.com/dhimmel/ppi)) contains:

+ an [unmodified copy](https://github.com/dhimmel/ppi/blob/master/download/ii/Datasets_S1-S4.zip) of `Datasets_S1-S4.zip` download from the Additional Data section [online](https://www.sciencemag.org/content/347/6224/1257601/suppl/DC1)
+ [reformatted versions](https://github.com/dhimmel/ppi/tree/master/data) of the data from `DataS1_interactome.tsv`, a file inside `Datasets_S1-S4.zip`.

My GitHub repository ([`dhimmel/integrate`](https://github.com/dhimmel/integrate)) for integrating many resources into a single network contains:

+ a subset of the protein interactions from the supplement stored as network nodes and edges.

@leobrueggeman assisted with parts of the analysis. His GitHub repository  ([`LABrueggs/incomplete-interactome`](https://github.com/LABrueggs/incomplete-interactome)) contains:

+ datasets of disease names derived from the supplement

The public availability of the aforementioned resources is important so others can reproduce and build off of our work. Thus, we request permission for our aforementioned redistribution and derivative works of the publication's supplemental data. Ideally, we could be granted permission to release the supplemental data under a [Creative Commons license](https://creativecommons.org/licenses/) without a No Derivatives restriction. Applying a CC license would lessen the burden on downstream users.

Thanks for your consideration. Our research is academic in nature, and we suspect it falls under the intended use of supplemental materials but perhaps not your [terms and conditions](http://www.sciencemag.org/site/about/copyright.xhtml).

Finally, we're performing our project using an open science platform called Thinklab. I've [posted a copy](#1) of this email on Thinklab and will update the discussion with our progress. Alternatively, feel free to respond via Thinklab rather than email. By detailing each step of our research process publicly, we're hoping to create a valuable resource and explore a more holistic and collaborative medium of publication.

Sincerely,
Daniel Himmelstein
Graduate Student
University of California, San Francisco","17",2015-10-02,2015-10-02,2,4778,"base.profile","Daniel","Himmelstein","dhimmel"
"614","comments","rephetio","2015-10-04T18:59:32.043Z",17,"# Preliminary feature computation

## Background

Our method for [hetnet edge prediction](http://het.io/hnep) [@10.1371/journal.pcbi.1004259] works by quantifying the connectivity between a source and target node. For this project, source nodes are compounds and target nodes are diseases. To extract a feature from the network, we quantify the prevalence of a specific type of paths (metapath) for each compound--disease pair. We use a metric called the [degree weighted path count](https://doi.org/10.1371/journal.pcbi.1004259#article1.body1.sec2.sec2.p1) (*DWPC*) to quantify the extent that that a path of the specified type connects a compound and disease. The *DWPC* downweights paths through high degree nodes, which are less specific and therefore likely less informative. Thus each metapath yields a feature. We evaluate the predictiveness of a feature by whether it discriminates indicated from non-indicated compound--disease pairs.

## Methods

We computed features for the 261 metapaths with length ≤ 3 for all [1,386 indications](http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#191) and 4,227 non-indications. The 4,227 non-indications were randomly selected from all non-indications. We computed features for 2%, rather than 100%, of non-indications to decrease computation time. This compromise allows us to quickly assess feature-specific performance via [AUROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve), but does not allow us to make comprehensive predictions or provide reliable estimates of measures that depend the balance between positives and negatives, such as [AUPRC](https://en.wikipedia.org/wiki/Precision_and_recall) and properly-scaled predicted probabilities.

We separately assessed the performance of each of the 261 features ([notebook](https://github.com/dhimmel/learn/blob/eabff6bdbe777cb21ad731a7b788720eb1d622f8/learn.ipynb)). We used the *DWPC* with $$w = 0.4$$ -- the dampening exponent to control the downweighting of paths through high degree nodes. We chose $$w = 0.4$$ because that was optimal in our previous study [@10.1371/journal.pcbi.1004259] and performance [was stable](https://doi.org/10.1371/journal.pcbi.1004259.s003) for surrounding parameter choices.

## Results

We created a [table of feature performance](https://github.com/dhimmel/learn/blob/eabff6bdbe777cb21ad731a7b788720eb1d622f8/data/auc.tsv). Scroll to the bottom of [this notebook](https://github.com/dhimmel/learn/blob/eabff6bdbe777cb21ad731a7b788720eb1d622f8/learn.ipynb) for the abbreviation system used in the `metapath` column. `nonzero` indicates the proportion of compound--disease pairs that had at least one path for that metapath. `auroc` represents the chance that a random indication received a higher *DWPC* than a random non-indication. Stay tuned to this discussion for further analysis.

## Limitations

There are still a few steps remaining before we can draw conclusions on the mechanisms of efficacy:

+ Our expert curated indication catalog is not yet ready. Therefore, an [estimated 42%](http://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95#3) the 1,386 indications are symptomatic or non-indications.
+ We haven't yet created permuted networks to compute feature performance on. [Permuted networks](https://doi.org/10.1371/journal.pcbi.1004259.s003#article1.body1.sec2.sec6.p1) preserve degree but destroy edge specificity. Much of the current performance is likely attributable to node degree rather than edge specificity. For example, compounds that are indicated for many other diseases are more likely to be indicated for the target disease. Many of our 261 features will capture this effect.","17",2015-10-04,2015-10-04,2,3795,"base.profile","Daniel","Himmelstein","dhimmel"
"615","comments","rephetio","2015-10-03T20:51:26.605Z",17,"Today is October 3, 2015. [345 days ago](http://www.eventbrite.com/e/bay-area-open-access-week-event-for-generation-open-tickets-13233113599), I first met @jspauld and learned of Thinklab. 330 days ago, @sergiobaranzini and I agreed to try out the platform, and 264 days ago we posted an initial draft of our proposal.

Since then our project [has](http://slides.com/dhimmel/greene-lab-interview#/5/1) recruited 22 reviewers and started 47 discussions containing 266 comments. Currently, our proposal has 641 views and our most highly viewed discussions have [175](http://thinklab.com/discussion/python-for-the-modern-biodata-scientist/84) and [173](http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21) views. These view counts rely on Google Analytics and  are therefore [just estimates](https://peerj.com/blog/post/115284878007/using-big-data-tools-for-small-data-how-peerj-moved-from-google-analytics-to-emr/).

We are pleased with the current progress on Thinklab and expect continued growth as the platform matures. In this thread, we will also post instances of reuse, citation, and publicity received outside of Thinklab.","17",2015-10-03,2015-10-03,2,1168,"base.profile","Daniel","Himmelstein","dhimmel"
"616","comments","rephetio","2015-10-03T21:12:10.146Z",17,"# Initial network release covered by the *Drug Repurposing Portal*

On August 6th 2015, the [initial release](http://thinklab.com/discussion/one-network-to-rule-them-all/102#1) [@10.5281/zenodo.28040] of our network was [covered](http://drugrepurposingportal.com/drug-repurposing-news.php?query=Himmelstein) by the *Drug Repurposing Portal*. This site [describes](http://drugrepurposingportal.com/) itself as a

> first of its kind one-stop-shop platform for intelligent information on Drug Repurposing

The site also includes a [database](http://drugrepurposingportal.com/repurposed-drug-database.php) of over 300 instances of repurposing. While the database is unstructured text (so currently unsuitable for computational analyses), it provides a nice human-readable reference.","17",2015-10-03,2015-10-03,2,785,"base.profile","Daniel","Himmelstein","dhimmel"
"617","comments","rephetio","2015-10-04T00:25:02.158Z",17,"# Protein-coding Entrez Genes with duplicate symbols

After [restricting](#9) to *Homo sapiens*, we found four protein-coding genes with duplicate symbols:

| tax_id | GeneID | Symbol | chromosome | map_location | type_of_gene | description |
|--------|-----------|--------|------------|--------------|----------------|-------------------------------|
| 9606 | [266553](http://www.ncbi.nlm.nih.gov/gene/?term=266553) | OFCC1 | 6 | 6p24.3 | protein-coding | orofacial cleft 1 candidate 1 |
| 9606 | [105369145](http://www.ncbi.nlm.nih.gov/gene/?term=105369145) | OFCC1 | 6 |  | protein-coding | orofacial cleft 1 candidate 1 |
| 9606 | [2867](http://www.ncbi.nlm.nih.gov/gene/?term=2867) | FFAR2 | 19 | 19q13.1 | protein-coding | free fatty acid receptor 2 |
| 9606 | [105372382](http://www.ncbi.nlm.nih.gov/gene/?term=105372382) | FFAR2 | 19 |  | protein-coding | free fatty acid receptor 2 |

We will reach out to Entrez Gene to inquire about this unexpected occurrence.","17",2015-10-04,2015-10-04,2,982,"base.profile","Daniel","Himmelstein","dhimmel"
"618","comments","rephetio","2015-10-04T02:49:12.228Z",17,"# Project Altmetrics

Our project has an [Altmetric page](https://www.altmetric.com/details/4273971), which tracks online attention. Currently, some of the project metadata is wrong, and most mentioning content is missing. @jspauld, perhaps you could investigate improving Altmetric integration?","17",2015-10-04,2015-10-04,2,297,"base.profile","Daniel","Himmelstein","dhimmel"
"619","comments","rephetio","2015-10-04T06:50:05.515Z",17,"# Exporting hetio hetnets to neo4j

We've [added](https://github.com/dhimmel/hetio/commit/1860faadb455c1f20546ce7923b5b78fd74796b3) neo4j export capability to hetio. Our implementation uses the [py2neo](http://py2neo.org/2.0/) toolkit to interact with the neo4j server. 

Adding edges is quite slow and the database size is large. However, the neo4j browser combined with cypher is great for exploratory analyses. In a short amount of time, I discovered 4 issues with our network ([1](https://github.com/dhimmel/integrate/issues/4), [2](https://github.com/dhimmel/integrate/issues/5), [3](https://github.com/dhimmel/integrate/issues/6), [4](https://github.com/dhimmel/integrate/issues/7)) and created a [sneak-preview visualization](https://twitter.com/dhimmel/status/650558967492444160).","17",2015-10-04,2015-10-04,2,792,"base.profile","Daniel","Himmelstein","dhimmel"
"620","comments","rephetio","2015-10-06T18:45:14.620Z",17,"# Version 1.0

Our compilation of pathway gene sets is now [released](https://github.com/dhimmel/pathways/tree/1dc7c744d0d1a8fa17a079f739195e6d3c15117e) (version 1.0) [@10.5281/zenodo.31834]. Gene sets ([download](https://github.com/dhimmel/pathways/blob/1dc7c744d0d1a8fa17a079f739195e6d3c15117e/data/pathways.tsv)) are compiled from WikiPathways and MSigDB. This updated version contains 1,617 pathways.","17",2015-10-06,2015-10-06,2,406,"base.profile","Daniel","Himmelstein","dhimmel"
"621","comments","rephetio","2015-10-05T21:32:26.910Z",17,"# Resolution of Entrez Genes with duplicate symbols

Mike Murphy -- RefSeq Curator at NCBI\NLM\NIH -- responded to our inquiry regarding the [duplicate symbols](#10). With permission, we've copied his response below:

> Thank you for your notification of two cases where the same symbol is used to represent different human GeneIDs. In each case, one of the symbols is ""official"" (as determined by the Human Gene Nomenclature Committee) and the other is ""unofficial"". We consistently use official nomenclature for the gene feature, when available. Unfortunately, situations do arise where the same symbol is used in an official and unofficial capacity on different loci. It is our general policy to retain shared symbols and names on different loci for query and retrieval purposes by various users of our database. However, in both of the cases you pointed out, the two genes with the same symbol really represent the same gene. Therefore, I merged GeneID 105369145 into GeneID 266553, and I merged GeneID 105372382 into GeneID 2867. These updates should be publicly visible within a couple of days.
","17",2015-10-05,2015-10-05,2,1106,"base.profile","Daniel","Himmelstein","dhimmel"
"622","comments","rephetio","2015-10-06T16:18:22.407Z",17,"We [exported](https://github.com/dhimmel/integrate/blob/8d93f5409a5fba85ee1109b470bbf2bb2b1a67e6/neo4j.ipynb) the [current version](https://github.com/dhimmel/integrate/tree/8d93f5409a5fba85ee1109b470bbf2bb2b1a67e6) of our network, which contains 49,399 nodes and 2,997,246 edges, to neo4j. The export took 10 hours and resulted in a 3.04 GB database.

The `data/graph.db/`, which stores the database, contained the following files with sizes over 1 MB:

| file | size |
|-------------------------------------------|----------|
| `messages.log` | 1.3 GB |
| `data/graph.db/neostore.transaction.db.1` | 262 MB |
| `data/graph.db/neostore.transaction.db.2` | 262 MB |
| `data/graph.db/neostore.transaction.db.3` | 262 MB |
| `data/graph.db/neostore.transaction.db.4` | 262 MB |
| `data/graph.db/neostore.transaction.db.5` | 262 MB |
| `data/graph.db/neostore.transaction.db.6` | 262 MB |
| `data/graph.db/neostore.transaction.db.7` | 113 MB |
| `neostore.propertystore.db` | 127.9 MB |
| `neostore.relationshipstore.db` | 102 MB |
| `neostore.propertystore.db.strings` | 25 MB |
| `neostore.relationshipgroupstore.db` | 3.2 MB |
| `rrd` | 2.0 MB |
| `neostore.propertystore.db.arrays` | 1.5 MB |
| `neostore.nodestore.db` | 1.5 MB |

We will look into ways to speed up our write times and reduce storage.","17",2015-10-06,2015-10-06,2,1324,"base.profile","Daniel","Himmelstein","dhimmel"
"623","comments","rephetio","2015-10-08T19:04:14.999Z",79,"Can you add into the [table] (https://github.com/dhimmel/integrate/blob/0e343d8745a98757c86e73f645b41353f52b82b5/licenses/README.md) the corporate or institutional affiliation of the project and the funding agency to each of the data sources?","79",2015-10-08,2015-10-08,2,242,"base.profile","Caty","Chung","cchung"
"624","comments","rephetio","2015-10-10T23:28:06.090Z",17,"# General assessment

We assessed general performance trends on our [preliminary](#1) set of 261 features ([interactive notebook](http://nbviewer.ipython.org/github/dhimmel/learn/blob/ed022ecd93f0599887a359486f3e8849ecda1a03/feature-assess.ipynb)). We discuss the findings below:

All [features](https://github.com/dhimmel/learn/blob/ed022ecd93f0599887a359486f3e8849ecda1a03/data/auc.tsv) yielded AUROCs ≥ 0.5. In other words, no features were negatively associated with indication status: greater path prevalence between a compound and disease never resulted in a lower therapeutic likelihood. The lack of negatively associated features is unsurprising given that our network is primarily composed of general relationships. For example, we have a compound--gene edge for [targeting](https://en.wikipedia.org/wiki/Biological_target#Drug_targets) but not for [agonism](https://en.wikipedia.org/wiki/Agonist) or [antagonism](https://en.wikipedia.org/wiki/Receptor_antagonist).

The majority of features had AUROC ≤ 0.53. In other words, most features performed only slightly better than random. However, a quarter of the features had AUROC ≥ 0.60, and five features had AUROC ≥ 0.80. The strong performance of a subset of features is encouraging.

We [did not observe](http://nbviewer.ipython.org/github/dhimmel/learn/blob/ed022ecd93f0599887a359486f3e8849ecda1a03/feature-assess.ipynb#Performance-by-path-length) major differences in the distributions of AUROCs for features with length 2 versus length 3 metapaths. However, since there are many more metapaths with length 3 than 2, the top performing features were mostly of length 3.

Performance [strongly correlated](http://nbviewer.ipython.org/github/dhimmel/learn/blob/ed022ecd93f0599887a359486f3e8849ecda1a03/feature-assess.ipynb#Feature-AUROC-versus-non-zero-fraction) with the fraction of nonzero values per feature. Metapaths traversing sparsely connected areas of the hetnet performed poorly because they yielded $$DWPC = 0$$ for almost all compound--disease pairs.

AUROC and AUPRC [were](http://nbviewer.ipython.org/github/dhimmel/learn/blob/ed022ecd93f0599887a359486f3e8849ecda1a03/feature-assess.ipynb#Feature-AUPRC-versus-AUROC) positively correlated. However, features with AUROCs near 0.5 (the random expectation) often had AUPRCs considerably above 0.25 (the random expectation). These features were often > 99% zero. Therefore, we suspect the low-AUROC features produced decent top predictions but poor comprehensive predictions due to sparsity, leading to discordance between AUROCs and AUPRCs [@10.1145/1143844.1143874 @10.1371/journal.pone.0009202].

One reason we primarily rely on AUROC rather than AUPRC is to enable comparisons across different prevalences. We may consider using the AUCROC (area under the condensed ROC  [@10.1093/bioinformatics/btq140]) to emphasize top predictions while remaining balance-agnostic.","17",2015-10-10,2015-10-10,2,2907,"base.profile","Daniel","Himmelstein","dhimmel"
"625","comments","rephetio","2015-10-19T23:10:30.482Z",17,"On October 14, Aravind Subramanian, a member of the LINCS team at the Broad, replied to our email. He wrote (posted here with permission):

> You are free to redistribute your re-processing of the Broad LINCS data. We are working on a manuscript describing L1000 and the dataset.

And continued:

> But if you believe your work would be valuable, we don't want our publication needs to hold up access for the field, so kindly proceed as you see fit

Aravind took the position that there is no formal license from the Broad Institute and that the LINCS L1000 licensing is determined by the NIH --- the Broad and L1000 team do not apply any additional restrictions. While the [original](https://github.com/dhimmel/integrate/blob/3633a6db23996f58ea1d75ada5537b53bb99597c/licenses/custom/L1000.md) license from www.lincscloud.org/license/ suggested otherwise, the following update was [added](https://github.com/dhimmel/integrate/blob/7459896115b477301af83310de667ffeeca61f66/licenses/custom/L1000.md): 

> **Update - October 14, 2015**

> All LINCS Production Phase L1000 data generated by the Broad Institute is posted at the NCBIs Gene Expression Omnibus (GEO). Standard NIH data access rules apply - data is freely accessible by anyone (GEO BioProject ID PRJNA290347)

> The website lincscloud.org, a Broad Institute developed resource for analysis of LINCS Phase 1 (2011-2014) data, will be deprecated in 2015 as the NIH has recently funded a separate LINCS Data Coordination and Integration Center (DCIC).

> Our historic license is given below for reference, but the official information on access to all LINCS resources via the DCIC is available at lincsproject.org.

The update specifies that LINCS data will be deposited in [GEO](http://www.ncbi.nlm.nih.gov/geo/). However, GEO availability does not grant usage rights [since](https://github.com/dhimmel/integrate/blob/3b16651051ae12129ddc2250e8d3e6d4050dd349/licenses/custom/GEO.md),

> some submitters may claim patent, copyright, or other intellectual property rights in all or a portion of the data they have submitted.

The update further specifies that the DCIC is the authoritative source for LINCS licensing. Their data release policy [states](https://github.com/dhimmel/integrate/blob/3b16651051ae12129ddc2250e8d3e6d4050dd349/licenses/custom/LINCS.md):

> LINCS data are released with the sole restriction that they must be correctly cited so that others can establish provenance and access the original data

## Conclusion

We have permission to distribute our L1000 datasets. The formal LINCS data policy, which covers the L1000 project, requires attribution. Therefore, we will release our LINCS datasets as [CC-BY](https://creativecommons.org/licenses/by/4.0/).

The LINCS project and the [L1000 team](http://www.lincscloud.org/team/) especially have done a laudable job sharing their data and providing support. Clearly and explicitly specifying the license of all public datasets will help remove any uncertainty and avoid laborious permission requests.","17",2015-10-19,2015-10-19,2,3054,"base.profile","Daniel","Himmelstein","dhimmel"
"626","comments","rephetio","2015-10-16T22:00:04.098Z",17,"# *DWPC* in Cypher

We've [implemented](https://github.com/dhimmel/hetio/blob/3150399c8d2570c2c6c93f1e3866d6b7c6bac2f3/hetio/neo4j.py#L135) the degree-weighted path count (*DWPC* [@10.1371/journal.pcbi.1004259]) in [Cypher](http://neo4j.com/developer/cypher-query-language/). Our implementation produces a different query for each metapath, but specifies the source node (`source`), target node (`target`), and damping exponent (`w`) as [parameters](http://neo4j.com/docs/2.2.6/cypher-parameters.html).

Below is the query for the *CsCuGod>GuD* metapath:

```cypher
MATCH p = (n0:Compound)-[:SIMILARITY]-(n1:Compound)-[:UPREGULATION]-(n2:Gene)-[:OVEREXPRESSION_DOWNREGULATION]->(n3:Gene)-[:UPREGULATION]-(n4:Disease)
WHERE n0.name = { source }
AND n4.name = { target }
WITH [size((n0)-[:SIMILARITY]-(:Compound)),
size((:Compound)-[:SIMILARITY]-(n1)),
size((n1)-[:UPREGULATION]-(:Gene)),
size((:Compound)-[:UPREGULATION]-(n2)),
size((n2)-[:OVEREXPRESSION_DOWNREGULATION]->(:Gene)),
size((:Gene)-[:OVEREXPRESSION_DOWNREGULATION]->(n3)),
size((n3)-[:UPREGULATION]-(:Disease)),
size((:Gene)-[:UPREGULATION]-(n4))] AS degrees
RETURN sum(reduce(pdp = 1.0, d in degrees| pdp * d ^ -{ w }))        
```

The *DWPC* for this metapath measures the extent that compounds similar to the query compound upregulate genes whose overpression downregulates genes upregulated by the query disease. The `MATCH` clause identifies paths corresponding to the metapath. The `WITH` clause computes degrees along each path and the `RETURN` clause computes path degree products (*PDPs*) and sums them to get the *DWPC*.

## Comparison to hetio

We configure our hetio queries to exclude paths with duplicate nodes. However, neo4j [excludes](http://neo4j.com/docs/2.2.6/cypherdoc-uniqueness.html) duplicate relationships. Additionally, when computing features for an indicated compound--disease pair, we configure our hetio queries to ignore that indication. Our current cypher framework does not support this exclusion.

Our preliminary experience is that *DWPC* computations in neo4j run approximately twice as quickly as [in hetio](https://github.com/dhimmel/hetio/blob/3150399c8d2570c2c6c93f1e3866d6b7c6bac2f3/hetio/pathtools.py). However, hetio may have more room for improvement, since we haven't implemented path caching yet.","17",2015-10-16,2015-10-16,2,2332,"base.profile","Daniel","Himmelstein","dhimmel"
"627","comments","rephetio","2015-10-21T22:04:05.279Z",17,"# GraphConnect 2015

Today I attended [GraphConnect](http://graphconnect.com/) -- a conference focused on neo4j. CEO, Emil Eifrem, kicked the event off with several exciting announcements:

+ Neo4j 2.3 has been released bringing speed and scalability [improvements](http://neo4j.com/release-notes/neo4j-2-3-0/). Specifically, the caching infrastructure has been rewritten to [provide](http://neo4j.com/blog/new-on-neo4j-the-neo4j-2-3-0-milestone-2-release-is-here/) ""significant (up to 2-3x) improvements in concurrent read scaling.""
+ Neo4j 3.0 is in the works and will bring unified and official drivers across languages. The initial release will include a Python but not R driver.
+ Cypher [will be](http://neo4j.com/blog/open-cypher-sql-for-graphs/) open sourced as [openCypher](http://www.opencypher.org/). This will hopefully give rise to a standard query language for all graph databases.

## Select learnings

Neo4j is designed for **deep traversals**. Other graph databases preferentially support big data (networks with billions of nodes) over efficient traversal. Since our network is small but our edge prediction method requires deep traversal, neo4j is a good fit for our application.

Neo4j doesn't enforce or specifically support a type graph (also called a schema, **metagraph**, or graph model). However, a metagraph can [easily be created](http://neo4j.com/blog/rvb-2-2-meta-graph/) from an already populated graph. While neo4j won't innately reason based on the created metagraph, it can be convenient from a user standpoint.","17",2015-10-21,2015-10-21,2,1557,"base.profile","Daniel","Himmelstein","dhimmel"
"628","comments","rephetio","2015-11-02T15:53:59.980Z",17,"# LDlink

A recently-published [webapp called LDlink](http://analysistools.nci.nih.gov/LDlink/) calculates SNPs in LD for a given lead SNP using 1000 Genomes Phase 3 data [@10.1093/bioinformatics/btv402]. The LDproxy feature allows specifying a lead SNP and reference population. The resulting table of proxy SNPs is downloadable as a tsv.

Unfortunately, the service doesn't release a public API. Therefore, querying at scale could be difficult.","17",2015-11-02,2015-11-02,2,450,"base.profile","Daniel","Himmelstein","dhimmel"
"629","comments","rephetio","2015-11-04T02:25:25.483Z",17,"[Bgee](http://bgee.org) is an integrative and comparative resource for gene expression [@10.1007/978-3-540-69828-9_12]. We extract the following edges from Bgee for our network:

+ Gene--Anatomy **expression** -- whether a gene is present in an anatomy
+ Gene--Anatomy **upregulation** -- whether a gene is upregulated (overexpressed) in an anatomy
+ Gene--Anatomy **downregulation** -- whether a gene is downregulated (underexpressed) in an anatomy

We have already substantially discussed Bgee on *Thinklab* in a more general gene expression thread [@10.15363/thinklab.d81]. The comments consisted of:

+ an [introduction](http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#3) by @dhimmel 
+ [questions](http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#4) on processing parameters by @dhimmel
+ [answers](http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#5) by @fbastian 
+ preliminary [analysis](http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#6) by @dhimmel
+ additional [guidance](http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#7) by @fbastian 
+ an initial [complete analysis](http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#8) and feedback by @dhimmel 
+ [response](http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#9) to feedback by @fbastian 
+ [tying up](http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#10) loose ends by @dhimmel

We are revisiting our Bgee analysis. Since the original discussion has become cluttered and covers a general topic, we are starting a designated Bgee discussion. Stay tuned.","17",2015-11-04,2015-11-04,2,1748,"base.profile","Daniel","Himmelstein","dhimmel"
"630","comments","rephetio","2015-11-04T02:27:37.960Z",17,"# Bgee discussion migrating

I started a [designated discussion](http://thinklab.com/discussion/processing-bgee-for-tissue-specific-gene-presence-and-overunder-expression/124) for Bgee. Please direct further Bgee attention there.","17",2015-11-04,2015-11-04,2,231,"base.profile","Daniel","Himmelstein","dhimmel"
"631","comments","rephetio","2015-11-04T03:54:30.810Z",17,"# Quality control filters

Initially, we [chose permissive filters](http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#5) for including Bgee edges based largely on the [recommendations](http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#5) of @fbastian. Several developments are making us reevaluate our permissiveness:

1. *Gene--expression--Anatomy* edges are the most prevalent type in the network (see last figure in [this notebook](https://github.com/dhimmel/integrate/blob/1a43ef2718283cbfc9ae869aee1856bf20e2ad6e/integrate.ipynb)). Now that we're traversing the network to extract paths, we're noticing high-degree nodes are computationally problematic. Several anatomies have 20,000 expressed genes and 5000 differentially expressed genes (see [page 2 here](https://github.com/dhimmel/integrate/blob/1a43ef2718283cbfc9ae869aee1856bf20e2ad6e/viz/degrees.pdf)). Therefore downstream constraints favor rigorous thresholds for extremely high-degree edge types.
2. We [also extract](http://doi.org/10.15363/thinklab.d91) *Gene--expression--Anatomy* edges from [TISSUES](http://tissues.jensenlab.org/About) [@10.7717/peerj.1054]. [Currently](https://github.com/dhimmel/tissues/blob/d6b0c99352db27469f2c3399cecb6f9fae2db547/bgee-combine.ipynb), TISSUES contributes 321,516 expression edges, while Bgee contributes 5,406,177. I suspect our TISSUES inclusion threshold (score ≥ 3) is much more stringent than our [Bgee theshold](http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#6).
3. TISSUES provides a score for each tissue--gene relationship. These scores have been calibrated on a gold standard allowing evidence-based weighting of each study. In contrast, Bgee has different categories of evidence based on ambiguity and quality. These measures are codependent and have been difficult to understand. Therefore, it's difficult to conclude whether low quality or high ambiguity relationships have merit.

## Ambiguity and call quality

We [looked into](https://github.com/dhimmel/bgee/blob/add20b29b8f926004ce69b9bacff2edf69cd383c/bgee.ipynb) the relationship between ambiguity and call quality.

Below, we show the contingency table for `Expression` (columns) and `Call quality` (rows) in the `Homo_sapiens_expr-complete` dataset ([documentation](http://bgee.org/?page=doc&action=call_files#single_expr_complete_col7)). Each cell contains the percentage of observations in the corresponding category:

|  | absent | high ambiguity | low ambiguity | present |
|--------|--------|-----------|---------|----------|
| NA | 0 | 0.001 | 0.001 | 0 |
| poor quality | 0 | 0 | 0 | 0.23 |
| high quality | 0.11 | 0 | 0 | 0.67 |

Below, we show the contingency table for `Differential expression` (columns) and `Call quality` (rows) in the `Homo_sapiens_diffexpr-anatomy-simple` dataset ([documentation](http://bgee.org/?page=doc&action=call_files#single_diff_simple_col7)). Each cell contains the percentage of observations in the corresponding category:

|  | high ambiguity | low ambiguity | over-expression | under-expression |
|-------------------------|----------------|---------------|-----------------|------------------|
| NA | 0.025 | 0.16 | 0 | 0 |
| low quality | 0 | 0 | 0.18 | 0.24 |
| high quality | 0 | 0 | 0.21 | 0.20 |

## Conclusions

**Presence:** `Homo_sapiens_expr-complete` uses the value `poor quality` while `Homo_sapiens_diffexpr-anatomy-simple` uses `low quality`. In our previous processing, we used `low quality` as the value for both datasets. Therefore, we accidentally omitted the 23% of observations that were `present` with `poor quality`. Our proposed solution is to take only `high quality` and `present` observations. The observations with ambiguous call qualities are rare, and thus I am not worried about excluding them for simplicity.

**Differential expression:** In `Homo_sapiens_diffexpr-anatomy-simple` differentially expressed observations are split between low and high quality. Low quality is [explained as](http://bgee.org/?page=doc&action=call_files#single_diff_simple_col8):

> differential expression reported as low quality, or there exists a conflict for the same gene, anatomical entity and developmental stage, from different analyses of a same data type (conflicts between different data types are treated differently). For instance, an analysis showed a gene to be over-expressed in a condition, while another analysis showed the same gene to be under-expressed or not differentially expressed in the same condition. Such conflicts are resolved by a voting system based on the number of conditions compared, weighted by p-value. Note that in one case, this quality level is used to reconcile conflicting calls from different data types: when a data type produced an under-expression call, while a different data type has shown that the same gene was never seen as expressed in the same condition. In that case, the overall summary is under-expression low quality.

We are undecided whether to omit low quality differential expression edges.","17",2015-11-04,2015-11-04,2,5102,"base.profile","Daniel","Himmelstein","dhimmel"
"632","comments","rephetio","2015-11-04T10:43:40.342Z",111,"For expression calls, besides being more stringent, it is also possible to discard anatomical entities close to the root of the ontology, that are less informative, and that benefits from the propagation from lots of substructures. See also https://github.com/owlcollab/owltools/issues/145 for a related discussion.

For differential expression, well, as said before, I'm not really surprised with this number of 5,000 differentially expressed genes in some structures. We are still willing to update our FDR computation to take into account all analyses, as mentionned [here](http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#9) (we are currently updating our differential expression pipeline).","111",2015-11-04,2015-11-04,2,723,"base.profile","Frederic","Bastian","fbastian"
"633","comments","rephetio","2015-11-11T22:43:29.686Z",17,"Emilie David -- Assistant Director, Copyright, Licensing and Special Projects at AAAS -- responded to our request. She indicated that AAAS does not generally allow *Science* content to be republished under Creative Commons licenses. However for Supporting Online Materials, authors are able to authorize use.

I looked deeper into the [License to Publish](http://www.sciencemag.org/site/feature/contribinfo/prep/4__2014LicensetoPublish_Final_6MAR2014.pdf) and found the relevant section:

> Author also retains the non-exclusive right to use the Work in the following ways without further permission but only after publication of the Work by AAAS and subject to the requirement that credit be given to its first publication in the appropriate issue of the applicable Science journal:

> 9) Author may use or authorize use of Supporting Online Material associated with the Work for any purpose and in any format.

Thus, we will proceed by requesting permission from the authors.","17",2015-11-11,2015-11-11,2,985,"base.profile","Daniel","Himmelstein","dhimmel"
"634","comments","rephetio","2015-11-19T02:02:39.722Z",17,"# Update to October 2015 release

We updated our analysis [@10.5281/zenodo.33987] to the latest BindingDB release (`BindingDB_All_2015m10.tsv`) and made several implementation [enhancements](https://github.com/dhimmel/bindingdb/commit/36097bc715420827ffd06dd64e05edf95e75f038). Now, our collapsed datasets retain source and pubmed information to help with licensing and attribution.

For more information, see the [notebook](https://github.com/dhimmel/bindingdb/blob/28dc70275103a233a2f02024082adcea45102a96/process.ipynb) for processing the BindingDB export, the rmarkdown [output](https://htmlpreview.github.io/?https://github.com/dhimmel/bindingdb/blob/28dc70275103a233a2f02024082adcea45102a96/collapse.html) for collapsing to compound--gene relationships, and the data download [directory](https://github.com/dhimmel/bindingdb/tree/28dc70275103a233a2f02024082adcea45102a96/data).

## Issue feedback

A few issues arose which were not present for `BindingDB_All_2015m3.tsv`. Paging @mkgilson:

+ Rows 192304--192473 (one indexed) start off with SMILES rather than reactant set IDs.
+ Numeric binding affinities could not be extracted for 19 rows.

I recommend switching from the ragged tsv to a format that can handle nested structure, such as json or xml.","17",2015-11-19,2015-11-19,2,1272,"base.profile","Daniel","Himmelstein","dhimmel"
"635","comments","rephetio","2015-11-23T18:11:33.331Z",17,"# Author permission

Yesterday, I emailed the authors, and first author, Jörg Menche, promptly responded.

He indicated that they published the supporting data with the hope that others would find it useful. As far as they're concerned, we are free to use it anyway we like.

He also mentioned that they compiled their interactions from a variety of resources ([as discussed here](http://thinklab.com/discussion/creating-a-catalog-of-protein-interactions/85#2)). Jörg was unsure whether this placed any restrictions on the downstream use of their dataset.","17",2015-11-23,2015-11-23,2,561,"base.profile","Daniel","Himmelstein","dhimmel"
"636","comments","rephetio","2015-11-26T17:20:29.192Z",17,"# Query Optimization

Above, we [debuted](#4) *DWPC* (degree-weighted path count) computation using Cypher. I noticed that looking up the degrees along each path was a major timesink. This finding was surprising because node degree lookup should be trivial compared to path traversal.

In a stroke of genius, @alizee [hypothesized](https://twitter.com/dhimmel/status/662415810825056256) our inclusion of node labels was to blame. For our diagnostic query, removing node labels [reduced](https://twitter.com/dhimmel/status/662440818398007296) database hits by 1339 fold and runtime by 8 fold.

Michael Hunger, caretaker general of the neo4j community, [explained](https://twitter.com/mesirii/status/662463621335818240):

> `size(pattern)` uses `node.getDegree()` if pattern only contains relationship type & direction

More explanation is [available here](http://neo4j.com/blog/neo4j-2-2-query-tuning/), but the essential insight is that by using only direction and relationship type to lookup node degree, we no longer need to lookup the label on the other end of each edge.

## Database changes

To support this optimization, we need to ensure that no two metaedges that touch a common metanode have the same relationship type. Our current hetnet is noncompliant in this regard: for example, the three Gene Ontology metaedges all have kind 'participation':

1. Gene--participation--Biological Process
2. Gene--participation--Molecular Function
3. Gene--participation--Cellular Component

Therefore, we have implemented unique neo4j relationship types for each metaedge ([primary commit](https://github.com/dhimmel/hetio/commit/8107d783e1b86a33123b9fb3273edf51695b5e82) and bugfixes [1](https://github.com/dhimmel/hetio/commit/d4b5f4ef223a26eb5bce23245a10b403cccf9fe5) and [2](https://github.com/dhimmel/hetio/commit/98121d64feeba829214652960322f00bffcc6b75)) by appending the standardized metaedge abbreviation to its kind. With this change, the relationship types for the Gene Ontology metaedges become:

1. `PARTICIPATION_BPpG`
2. `PARTICIPATION_GpMF`
3. `PARTICIPATION_CCpG`

## Example query

With the updated database, the query for calculating the *DWPC* between goserelin and lung cancer for the `CcSEcCdGuD` metapath is:

```cypher
MATCH paths = (n0:Compound)-[:CAUSATION_CcSE]-(n1)-[:CAUSATION_CcSE]-(n2)-[:DOWNREGULATION_CdG]-(n3)-[:UPREGULATION_DuG]-(n4:Disease)
  WHERE n0.identifier = 'DB00014' // Goserelin
  AND n4.identifier = 'DOID:1324' // lung cancer
WITH [
  size((n0)-[:CAUSATION_CcSE]-()),
  size(()-[:CAUSATION_CcSE]-(n1)),
  size((n1)-[:CAUSATION_CcSE]-()),
  size(()-[:CAUSATION_CcSE]-(n2)),
  size((n2)-[:DOWNREGULATION_CdG]-()),
  size(()-[:DOWNREGULATION_CdG]-(n3)),
  size((n3)-[:UPREGULATION_DuG]-()),
  size(()-[:UPREGULATION_DuG]-(n4))
  ] AS degrees, paths
RETURN
  COUNT(paths) AS PC,
  sum(reduce(pdp = 1.0, d in degrees| pdp * d ^ -0.4)) AS DWPC
```","17",2015-11-26,2015-11-26,2,2933,"base.profile","Daniel","Himmelstein","dhimmel"
"637","comments","rephetio","2015-11-26T22:54:11.765Z",17,"# Concurrent queries using py2neo

As [explained](https://twitter.com/darthvader42/status/670154181064400897) by Stefan Armbruster, a single cypher query is limited to a single core. However, multiple queries can be fulfilled in parallel:

> With current versions of Neo4j, a Cypher query traverses the graph in single threaded mode. Since most graph applications out there are concurrently used by multiple users, this model saturates the available cores. [[source](http://stackoverflow.com/a/27578860/4651668)]

Currently, we perform a separate query for each compound--disease--metapath combination. Depending on the number of compound--disease pairs and metapaths considered, we will need to compute between 1 million and 1 billion *DWPCs*. 

Our software package for hetnets, [hetio](https://github.com/dhimmel/hetio) [@10.5281/zenodo.31763], is built in python. Despite migrating to neo4j, we are still dependent on hetio for:

+ metagraph operations
+ edge directionality
+ metapath abbreviation
+ constructing cypher queries

Therefore, we're using python to construct and execute queries with the [py2neo](http://py2neo.org/2.0/) package.

To enable concurrent queries, we initially used the [multiprocessing](https://docs.python.org/3.5/library/multiprocessing.html) module ([notebook](https://github.com/dhimmel/learn/blob/affb391ac35cd726e1377f08557b060f4098144f/neo4j-compute.ipynb)), which enables parallelism by creating subprocesses. However, subprocesses require substantial overhead. Since the majority of computation is performed outside of python by the neo4j sever, we switched to the [threading](https://docs.python.org/3.5/library/threading.html) module ([notebook](https://github.com/dhimmel/learn/blob/bfc0b4b3adef8ee9bab73676181b84298f6b16fe/neo4j-compute.ipynb)). Threading has less overhead than multiprocessing, but is limited to a single process of pure python. However, since the cypher query releases the [global interpreter lock](https://docs.python.org/3.5/glossary.html#term-global-interpreter-lock), the restriction to a single process is not a time-limiting step.

In the end, we used [concurrent.futures](https://docs.python.org/3.5/library/concurrent.futures.html#threadpoolexecutor) to make threading easier ([notebook](https://github.com/dhimmel/learn/blob/0867341ac64e5875390532e1aa31bd3b6f38c0ad/neo4j-compute.ipynb)). We encountered a [small hiccup](https://github.com/nigelsmall/py2neo/issues/449) where our queue of queries waiting to be executed grew large and consumed substantial memory. We addressed the issue by postponing new query submission until the queue dropped below a given size.

Performing concurrent queries led to ~1000% processor usage by neo4j, equivalent to 10 cores at full load. This benchmark was performed on a 16 core machine running neo4j-community-2.3.1 on Ubuntu 15.10. Increasing the number of concurrent python workers above 16 did not increase the ~1000% usage figure. Let us know of any methods to increase processor saturation.","17",2015-11-26,2015-11-26,2,3027,"base.profile","Daniel","Himmelstein","dhimmel"
"638","comments","rephetio","2015-11-30T20:04:57.718Z",17,"We're building an open project to predict new uses for existing drugs. The core of our project is a network with multiple types of nodes and relationships (hetnet) [@10.15363/thinklab.d102]. We [use neo4j](http://thinklab.com/discussion/using-the-neo4j-graph-database-for-hetnets/112) to store, explore, and quantify this hetnet. 

With regards to licensing, there are several ways we plan to use the software: 

1. **distributing the hetnet** -- we strive to make our hetnet reusable and extensible. Therefore, we need convenient and reliable formats for distributing the network. One format we'd like to use for distribution is an archive file of the database. For example, a tarball of `data/graph.db/`. In addition to an archive of just the database location, we would like to distribute an archive of the binary with the database included. So for example, a user could extract a single archive containing the neo4j server with our database and configuration already loaded.

+ **quantifying the hetnet** -- our method for relationship prediction relies on extracting network features, which quantify the prevalence of specific path types between two nodes. We [implemented](http://thinklab.com/discussion/using-the-neo4j-graph-database-for-hetnets/112#4) the algorithm in cypher. We [read that](http://neo4j.com/neo4j-scales-web-enterprise/) the enterprise version's high-performance cache ""can provide up to 10x the performance under concurrent load."" However, for our application the enterprise edition did not provide a performance improvement over the community edition ([notebook](https://github.com/dhimmel/learn/blob/6b81cd8eccaabf7d90bdedde66c28d8a88483cc6/neo4j-comparison.ipynb)). Therefore, we are inclined to stick to the community version, but may consider enterprise to scale up our query throughput via the high-availability cluster.

+ **exploring the hetnet** -- we have been using the neo4j browser as a GUI to interact with the network. Eventually, we would like to host a publicly-accessible neo4j server which allows anyone to interact with our hetnet from their web browser.

We try to adhere to the following project ground-rules:

+ releasing all of our original data and source code as CC0.
+ avoiding dependencies that forbid distribution, to prevent situations where others cannot reproduce our science due to access issues.

Neo4j comes in two [editions](http://neo4j.com/editions/): *community* which is [GPLv3](http://opensource.org/licenses/GPL-3.0) licensed and *enterprise* which is [AGPLv3](http://opensource.org/licenses/AGPL-3.0) licensed. Exactly what these licenses mean with respect to neo4j server is [subject to debate](http://stackoverflow.com/q/6500925). A [guidance document](https://project.nordu.net/secure/attachment/12828/Fair+Trade+Software+Licensing.pdf) by neo4j states:

> Simply, if you are open source, then Neo4j is open source; if you are closed source, then Neo4j is commercial. 

Our project is open source, although we use CC0 rather than a copyleft license. We do not modify neo4j's source code, although we do want to distribute the compiled version (see 1 above). Finally, it's unclear exactly which aspects of our project are affected by neo4j's license.

Given these complexities, we will reach out to neo4j for guidance. Specifically, we're interested in what restrictions neo4j's license places on our three use cases. And if there are restriction, could we obtain an educational or research license permitting our use?","17",2015-11-30,2015-11-30,2,3511,"base.profile","Daniel","Himmelstein","dhimmel"
"639","comments","rephetio","2015-12-02T23:01:57.635Z",17,"# Concurrency for data science

Processors are now multicore and our code should take advantage of this opportunity. If execution time is not an issue, don't waste time optimizing. But if you find yourself waiting for your program to finish and your computation can be parallelized, look no further than `concurrent.futures`.

`concurrent.futures` gives you easy, no [boilerplate](https://en.wikipedia.org/wiki/Boilerplate_code), access to the two methods of concurrency in python. The methods are:

## [`threading`](https://docs.python.org/3/library/threading.html)

Threads allow multiple paths of execution within a single program. Each thread has access to the global data space, which makes threads convenient for programming. However, proceed with caution: since a single object can be altered by multiple threads simultaneously, there is danger. Avoid the danger by using [locks](https://docs.python.org/3/library/threading.html#lock-objects) (via [`with`](https://docs.python.org/3/library/threading.html#using-locks-conditions-and-semaphores-in-the-with-statement) for convenience) whenever a thread writes to a communal resource.

The main drawback of threading is the global interpreter lock ([GIL](https://docs.python.org/3/glossary.html#term-global-interpreter-lock)) meaning that ""only one thread can execute Python code at once."" Therefore, if you want to reap the benefits of multiple cores, you need to make sure your code isn't limited by the GIL. You can escape the GIL by moving the time intensive computations outside of python by:

1. Using code written in other languages such as C. Many functions implement their core features outside of python. Additionally, many operations rely on external resources such as database or web queries.
2. Using [`numba`](http://numba.pydata.org/) to automatically compile your code with the [`@numba.jit(nogil=True)`](http://numba.pydata.org/numba-doc/0.21.0/user/jit.html#nogil) decorator.

## [`multiprocessing`](https://docs.python.org/3/library/multiprocessing.html)

When your code isn't amenable to releasing the GIL, try multiprocessing. Multiprocessing spawns new python instances for each task. Therefore, any needed data must be serialized via pickling and dispatched to the subprocess. This creates large overhead. Try to send the minimum amount of data required for your application to each process to reduce this overhead.

## [`concurrent.futures`](https://docs.python.org/3/library/concurrent.futures.html)

`concurrent.futures` provides a queue-based system for executing functions in parallel. To use, first initiate an Executor using `concurrent.futures.ThreadPoolExecutor()` for threading or `concurrent.futures.ProcessPoolExecutor()` for multiprocessing. Both constructors accept a `max_workers` argument for the maximum number of threads/processes you would like to devote to the task.

You can interact with the Executor in the following ways:

+ `Executor.submit()` which submits a *single* job to the queue
+ `Executor.map()` which submits *many* jobs to the queue
+ `Executor.shutdown()` which shuts down the executor. The default parameter `wait=True` means this method will wait for all jobs to finish before returning.

Cheers to a concurrent future!","17",2015-12-02,2015-12-02,2,3265,"base.profile","Daniel","Himmelstein","dhimmel"
"640","comments","rephetio","2015-12-09T02:51:40.932Z",17,"Our algorithm relies on extracting paths of a certain type (metapath) between a source and target node. For our previous project where we predicted gene--disease associations, we placed two restrictions on paths [@10.1371/journal.pcbi.1004259]:

> paths with duplicate nodes were excluded, and, if present, the association edge between the source gene and target disease was masked.

However, since [migrating to neo4j](http://thinklab.com/discussion/using-the-neo4j-graph-database-for-hetnets/112), we have not added extra path restrictions beyond the builtin restriction that paths cannot contain duplicate relationships.

So in total, we have relied on three different conditions for excluding a path:

1. duplicated nodes
2. duplicated edges
3. contains the prediction edge

It turns out that 1 implies 2 and 3 (1 ⇒ 2, 1 ⇒ 3). In other words, when we exclude paths with duplicate nodes, we also exclude paths with duplicate edges. And since we omit the length-one metapath that is simply the metaedge being modeled, all paths containing the prediction edge will contain either the source or target node at least twice.

You may have noticed above that for hetio-dag [@10.1371/journal.pcbi.1004259], we masked the prediction edge if present. Masking an edge temporarily removes it from the network. Masking the prediction edge not only eliminates paths containing that edge, but also can affect path degrees, which go into the *DWPC* (degree-weighted path count).

This discussion will focus on identifying the most sensible path restrictions and whether masking is warranted.","17",2015-12-09,2015-12-09,2,1595,"base.profile","Daniel","Himmelstein","dhimmel"
"641","comments","rephetio","2015-12-13T23:30:33.944Z",17,"# Cypher implementations of duplicate node exclusion

With help from Christophe Willemsen, @alizee and I [identified](https://twitter.com/dhimmel/status/674487386949087232) two methods for excluding paths with duplicate nodes in a Cypher query.

We [implemented](https://github.com/dhimmel/hetio/commit/f6deae3294c1d90ba9ba92153c91a40791d4ae8d) both methods. Here, we'll describe them in the context of a length-four path matched using `MATCH paths = (n0)--(n1)--(n2)--(n3)--(n4)`.

The **nested** method adds a `WHERE` clause specifying:

```
ALL (x IN nodes(paths) WHERE size(filter(z IN nodes(paths) WHERE z = x)) = 1)
```

This method uses [list comprehension](http://neo4j.com/docs/2.3.1/syntax-collections.html#_list_comprehension) to iterate over each node in a path and ensure that it only occurs once. This clause can be applied to paths of any length and does not require assigning nodes to identifiers.

The **expanded** method adds a `WHERE` clause specifying:

```
NOT (n0=n1 OR n0=n2 OR n0=n3 OR n0=n4 OR n1=n2 OR n1=n3 OR n1=n4 OR n2=n3 OR n2=n4 OR n3=n4)
```

The method checks that no two nodes are equal by explicitly evaluating all combinations of two nodes. The method requires assigning node identifiers and is path-length dependent. However, it is intuitive and amenable to query plan optimization since filtering can be front-loaded to avoid expanding on illegitimate paths.

## Alternative implementations

Another general solution would be to check whether the number of distinct nodes equals the length of the full path. We currently are unaware of a Cypher implementation for this **distinct** method, but [suspect](https://twitter.com/A_Lizee/status/674655287899348992) it could scale to longer paths better than the nested method.

One final variant of the expanded method, called **labeled**, would avoid comparing nodes with different labels, as these nodes are implicitly different. This method requires the greatest *a priori* knowledge of path characteristics.","17",2015-12-13,2015-12-13,2,2020,"base.profile","Daniel","Himmelstein","dhimmel"
"642","comments","rephetio","2015-12-15T19:46:16.116Z",17,"# Optimization dataset

To help optimize our cypher queries, we computed features for 347 positives and 317 negatives for the 1979 metapaths with length ≤ 4 ([notebook](https://github.com/dhimmel/learn/blob/5d932818e58963b4f5ae5095294853f5bafbe729/unique-nodes/unique-nodes-extract.ipynb), [features](https://github.com/dhimmel/learn/blob/5d932818e58963b4f5ae5095294853f5bafbe729/unique-nodes/dwpc.tsv.gz)). Positives were randomly selected indications, while negatives were randomly selected non-indications. We computed the *PC* (path count) and *DWPC* for each compound--disease--metapath combination using each of three node uniqueness methods described [above](#2). In addition, we computed features without excluding duplicate nodes.

# Runtimes for duplicate node exclusions

We compared the average query runtime for each node uniqueness method ([notebook](https://github.com/dhimmel/learn/blob/5d932818e58963b4f5ae5095294853f5bafbe729/unique-nodes/runtime-comparison.ipynb)):

| `unique_nodes` method | average query runtime | runtime_hit |
|---------------------|--------------------|---------------|
| `False` | 129.41 ms | 0.0% |
| `labeled` | 143.56 ms | 10.9% |
| `expanded` | 173.43 ms | 34.0% |
| `nested` | 179.76 ms | 38.9% |

We found that not performing any duplicate node exclusion was fastest. The most efficient method for exclusion was `labeled`, which explicitly checks that node pairs of the same label are not duplicates. This method only slowed down runtime by 11%, a very acceptable hit.

The `nested` method was on average slightly slower than `expanded`. However, in the overwhelming majority of instances, `nested` was faster than `expected`, yet poor worst case runtime pushed `nested` to last place. This observation underscores the vast asymmetry in runtimes: most queries finish quickly, while a small percentage of queries form a long tail that contributes disproportionately to overall runtime.

Remember that these findings are highly context-dependent. Here they are in the context of a subset of queries chosen to be representative of our specific HNEP (hetnet edge prediction) task.

In conclusion, if excluding paths with duplicate nodes is desired, we will use the `labeled` method.","17",2015-12-15,2015-12-15,2,2247,"base.profile","Daniel","Himmelstein","dhimmel"
"643","comments","rephetio","2015-12-21T19:20:05.708Z",17,"# The effect of duplicate node exclusion on features 

[Above](#3), we described computing features for 664 compound--disease pairs × 1,979 metapaths. In this comment, we'll investigate the effect of excluding paths with duplicate nodes on this dataset.

Paths without the unique node constraint are still subject to neo4j's unique relationship constraint. In essence, the node uniqueness constraint determines whether paths containing a cycle are permitted.

As [previously discussed](#1) the node uniqueness constraint also excludes paths containing the prediction edge. In our case, the prediction edge is an indication between the source compound and target disease.

Therefore, feature performance could decline after applying the unique constraint because:

1. paths with cycles convey meaningful information that the unique node constraint overlooks
2. paths including the prediction edge cause overfitting by incorporating the outcome (indication status) into the predictor (*DWPC*)

For the 1,961 features that contained a duplicate metanode, we calculated the decline in AUROC of the *DWPC* resulting from duplicate node exclusion ([notebook](http://nbviewer.ipython.org/github/dhimmel/learn/blob/2eb24875c5dc5d1017b0eaa6759562fc38c33e7c/unique-nodes/feature-comparison.ipynb), [table](https://github.com/dhimmel/learn/blob/2eb24875c5dc5d1017b0eaa6759562fc38c33e7c/unique-nodes/metapaths.tsv)). We investigated the occurrence of 1 and 2 by segregating metapaths based on whether they include an indication metaedge. If a metapath doesn't include an indication metaedge, then any change in performance must be due to 1. The distributions of AUROC declines identify 2 (overfitting) as a major factor, while showing 1 is at most a very minor factor.

![](https://raw.githubusercontent.com/dhimmel/learn/2eb24875c5dc5d1017b0eaa6759562fc38c33e7c/unique-nodes/AUROC-violins.png)

## Conclusion

Therefore, we will adopt the unique node constraint because it omits paths that include the prediction edge, which leads to overfitting. Absent their potential for overfitting, paths with duplicate nodes did not contribute greatly to *DWPC* performance. Finally, paths that are excluded because they contain a cycle will still be incorporated into *DWPCs* for shorter metapaths that bypass the cyclical segment.","17",2015-12-21,2015-12-21,2,2329,"base.profile","Daniel","Himmelstein","dhimmel"
"644","comments","rephetio","2015-12-22T01:25:50.982Z",17,"Network permutation randomizes edges in a graph to remove signal. Metrics computed on permuted networks provide a baseline to evaluate the extent of signal contained in the network. Different types of permutations destroy different aspects of the information encoded by a network.

The method we've [previously used](https://doi.org/10.1371/journal.pcbi.1004259#article1.body1.sec2.sec6.p1) selects two random edges and swaps the endpoints (labeled `XSwap` in [@10.1137/1.9781611972795.67]). This method preserves node degree while destroying edge specificity.

We [adapted](https://github.com/dhimmel/hetio/blob/1aa1964f92881c54da652cda0c1162ee6e4664b9/hetio/permute.py) the edge swapping technique to hetnets by permuting each metaedge separately---edges are only swapped with other edges of the same type. We found the permutation yielded valuable insights on which aspects of the network were informative and the quality of our predictions [@10.1371/journal.pcbi.1004259].

We've subsequently [migrated](http://thinklab.com/discussion/using-the-neo4j-graph-database-for-hetnets/112) to neo4j, so are now looking to implement hetnet permutation in cypher. We [tweeted](https://twitter.com/dhimmel/status/677260913200644096) this problem, and Michael Hunger [started](http://jexp.github.io/graphgist/?dropbox-14493611%2Fedge_swap_cypher.adoc) us on the right track.

We created a [graphgist](http://portal.graphgist.org/graph_gists/by_url?url=https://gist.github.com/dhimmel/f69730d8bdfb880c15ed/6663d64be53e5b8c438d0a2d55a5778676ccf0b1) with potential implementations and cypher questions.","17",2015-12-22,2015-12-22,2,1600,"base.profile","Daniel","Himmelstein","dhimmel"
"645","comments","rephetio","2016-01-28T01:39:58.688Z",17,"# Official adoption of 'hetnet'

For the past four months, I have been widely using the term 'hetnet'. I now rarely use the term 'heterogeneous network'. If I think an audience will be unfamiliar with my usage, I'll clarify by saying ""a network with multiple types of nodes or edges"". Even when I don't explicitly define the term, unfamiliar recipients seem to instinctively understand the concept. And perhaps most importantly, I haven't encountered any objections. Hence, our adoption of hetnet is now official.

In the spirit of this announcement, we'll be changing our project's title from ""Repurposing drugs on a heterogeneous network"" to ""Repurposing drugs on a hetnet"".

Meanwhile, the community continues to use an assortment of terms to express the concept. For example, a recent study used the ""multiplex network"" [@10.7717/peerj.1525]. The field appears ripe for standardized terminology to emerge.","17",2016-01-28,2016-01-28,2,915,"base.profile","Daniel","Himmelstein","dhimmel"
"646","comments","rephetio","2016-01-06T19:17:34.818Z",17,"# Partial Cypher solutions

We've made some headway implementing `XSwap` in Cypher. But first, here's the general algorithm we're aiming for:

1. Randomly select two relationships of the specified type
2. If valid, XSwap the two relationships
3. Repeat 1 and 2 until a certain number of swaps have succeeded

We [initially attempted](https://gist.github.com/dhimmel/f69730d8bdfb880c15ed#gistcomment-1657527) to implement the above steps in a single cypher query. However, as Michael Hunger [explained](https://gist.github.com/dhimmel/f69730d8bdfb880c15ed#gistcomment-1662589), the eagerness behavior of cypher prevents looping 1 and 2. Instead of `1, 2, 1, 2, 1, 2`, cypher will do `1, 1, 1, 2, 2, 2`, which fails because our technique randomizes iteratively.

Therefore, we switched to python for managing steps 1 and 3, while keeping step 2 in cypher. This external method is now [implemented in hetio](https://github.com/dhimmel/hetio/blob/9facc4bd609d536e733c5297f76a75f8123dc042/hetio/neo4j.py#L257). The function starts by retrieving the ids for all relationships of the specified type. Next, iteration begins:

1. Two relationships ids are randomly selected and sent as parameters to a cypher query.
2. If the swap is invalid, the cypher query returns no rows. Otherwise, the query returns the ids for the two created relationships and the python id list is updated.

There are two outstanding issues with this method:

First, retrieving ids for all relationships of a given type could become problematic for extremely abundant relationship types. Currently this is not a problem as we can retrieve over 1 million ids using py2neo without failure. If problematic, we could create an identity property to each relationship with an existence constraint for efficient lookup. Indexed property values are a practical must for this solution, yet are [currently](https://gist.github.com/dhimmel/f69730d8bdfb880c15ed#gistcomment-1655807) only available with Enterprise.

Second, the rule planner in 2.3.1 does not do an indexed lookup of relationship by id---instead it scans all relationships. The cost planner works as desired with a `DirectedRelationshipByIdSeekPipe`. However the 2.3.1 cost planner doesn't support write operations (3.0 is [slated to add](https://github.com/neo4j/neo4j/wiki/Neo4j-3.0-changelog#300-m01) this functionality).

So in conclusion, we are close to a workable solution for permuting a neo4j hetnet. Depending on developments, we'll choose whether to adopt a solution discussed here or permute outside of neo4j with the legacy [hetio functionality](https://github.com/dhimmel/hetio/blob/1aa1964f92881c54da652cda0c1162ee6e4664b9/hetio/permute.py).","17",2016-01-06,2016-01-06,2,2698,"base.profile","Daniel","Himmelstein","dhimmel"
"647","comments","rephetio","2016-01-11T19:57:18.731Z",17,"# Licensing and usage options

[Trey Knowles](http://neo4j.com/blog/contributor/trey-knowles/), the Startup Community Manager at Neo Technology, assisted us with our licensing questions.

To clarify the situation, we specified four licensing options:

A. Community edition with the default GPLv3 license
B. Community edition with a contractual education license
C. Enterprise edition with the default AGPLv3 license
D. Enterprise edition with a contractual education license

And then we specified four desired uses of Neo4j for our project:
 
1. distribute the neo4j binaries with our network preloaded
2. run internal database queries
3. make a publicly-accessible neo4j server instance
4. release all of our code and data as CC0

Trey provided the following answer, reproduced here with permission, on which of our desired uses are allowed by each license:

> A. Community edition with the default GPLv3 license
>
+ 2 (single server, no clustering / live backups) 
+ 3 (single server, no clustering / live backups) 
+ 4 

> B. Community edition with a contractual education license
>
+ Neo Technology offers no contracts with respect to CE

> C. Enterprise edition with the default AGPLv3 license
>
+ 1 provided you license your work as AGPLv3
+ 2 provided you license your work as AGPLv3
+ 3 provided you license your work as AGPLv3
+ 4 provided you license your work as AGPLv3

> D. Enterprise edition with a contractual education license
>
+ 1
+ 2
+ 3
+ 4* *(pending legal review from Neo team)

Since AGPLv3 would place undesirable restrictions on our work compared to CC0, C is not a good option for us. Therefore, we'll choose between A and D. We will default to A (GPLv3-licensed community edition) unless enterprise features are needed in which case we'll explore D (contractually-licensed enterprise edition). Sticking with the community edition whenever possible will lessen the burden on anyone wanting to replicate or reuse or work.","17",2016-01-11,2016-01-11,2,1991,"base.profile","Daniel","Himmelstein","dhimmel"
"648","comments","rephetio","2016-01-27T22:28:02.019Z",17,"# Results from first two curators

The curations from [AJG](https://github.com/dhimmel/indications/blob/2e4d9be7ef911e48fdd10d99628b22098010d935/curation/ajg/curation-AJG.tsv ""Ari Green's classifications"") and [CSH](https://github.com/dhimmel/indications/blob/2e4d9be7ef911e48fdd10d99628b22098010d935/curation/csh/curation-CSH.csv ""Christine Hessler classifications"") (@chrissyhessler) are in. Both curators went through and classified each of the 1,388 compound--disease pairs. The breakdown of their classifications are as follows:

| class | AJG | CSH | AJG (as %) | CSH (as %) |
|-------|-----|-----|------------|------------|
| DM | 599 | 593 | 43.2% | 42.7% |
| SYM | 514 | 517 | 37.0% | 37.2% |
| NOT | 275 | 278 | 19.8% | 20.0% |

Compared to the [pilot](#3), the curators classified a higher percentage of pairs as non-indications, while classifying a lower percentage as disease-modifying. Similar to the pilot, the curators agreed 68.0% percent of the time. The Cohen's kappa coefficient [@10.1177/001316446002000104 @10.11613/BM.2012.031] between AJG and CSH was 49.9% ([notebook](https://github.com/dhimmel/indications/blob/2e4d9be7ef911e48fdd10d99628b22098010d935/curation/tiebreaker-template.ipynb)), indicating [moderate](http://www.stfm.org/fmhub/fm2005/May/Anthony360.pdf#page=3) agreement.

Looking at only the 944 agreements, there were 447 disease-modifying, 351 symptomatic, and 146 non-indications. For the remaining [444 disagreements](https://github.com/dhimmel/indications/blob/2e4d9be7ef911e48fdd10d99628b22098010d935/curation/pk/template-pk.tsv), we plan to have a third curator break the tie.","17",2016-01-27,2016-01-27,2,1633,"base.profile","Daniel","Himmelstein","dhimmel"
"649","comments","rephetio","2016-01-28T00:06:41.656Z",17,"# Recruitment of a third curator

We have recruited a third curator, Pouya Khankhanian, to break ties. Pouya is a resident physician in neurology at Penn. He received his in MD at UCSF.

When learning of the task and before seeing this discussion and the three classifications, Pouya asked a few questions about what qualifies as an indication. While some of these may be cleared up by the [definitions](#4) we decided on, I thought it would be helpful to post his questions here along my opinions.

> Suppose a drug was indicated for treatment of seizures 10 years ago, but now we have a new drug that is more efficacious and has fewer side effects, so the old drug is no longer ""indicated"" in clinical practice. However, I suppose for the purposes of your study you would still want to call this ""indicated""?

I would not disqualify this indication because it's no longer optimal. It still treats the disease and will therefore be helpful in training and validating our model.

> Or, suppose a drug is clinically used for a disease, but is not actually indicated. Classic example is that almost all of our MS drugs are ""not indicated"" for treatment of progressive MS (meaning no trial has ever shown efficacy), but as you know most of our progressive MS patients get treated.

Off-label usages are acceptable as long as there's _reasonable evidence_ of efficacy from a clinical perspective.

> Or suppose a drug is like fifth line, and is only indicated if someone is medically refractory (i.e. they have failed the first four lines of drugs). Would you consider this ""indicated""?

I don't think being far down the line should be a disqualifying factor for the reasons above.","17",2016-01-28,2016-01-28,2,1693,"base.profile","Daniel","Himmelstein","dhimmel"
"650","comments","rephetio","2016-01-28T19:43:54.578Z",17,"Anaïs Baudot, coauthor of the _PeerJ_ paper [@10.7717/peerj.1525] mentioned in my [previous post](#5), informed me of a fantastically thorough article [@10.1093/comnet/cnu016] on the terminology of complex networks. Quoting from the article's introduction:

> In the last couple of years, it has suddenly become very fashionable to study networks with multiple layers (or multiple types of edges) and networks of networks. Unfortunately, the sudden and immense explosion of papers on multilayer networks has produced an equally immense explosion of disparate terminology, and the lack of a consensus (or even generally accepted) set of terminology and mathematical framework for studying multilayer networks is extremely problematic. Additionally, research on generalizing monoplex-network concepts such as degree, transitivity, centrality and diffusion is only in its infancy. We also expect that it will be necessary to define many concepts that are intrinsic to multilayer networks.

This study adopts the term ""multilayer network"" as a general term for networks with multiple layers. From my understanding a layer is an edge type. However, the definition gets quite technical -- the study is coming from a math/physics angle. So while the term multilayer definitely encompasses our concept of a hetnet, I think it fails in terms of simplicity. We like the term heterogeneous because it expresses the underlying and distinguishing feature of our networks: different types. Multilayer feels less intuitive: not everyone conceptualizes different types as layers.

## A simple definition of hetnet

Whereas the authors of _Multilayer networks_ have nailed the technical details, I think it's important to have easily accessible definitions to unite the field and help it grow. Therefore I propose the following simple and encompassing definition of hetnet:

> **hetnet** -- a network with multiple node or edge types

Depending on your field, 'network' can be replaced with 'graph', 'node' with 'vertex' or 'entity', and 'edge' with 'link', 'arc', or 'relationship'.

## The terminology nightmare

The authors of _Multilayer networks_ [@10.1093/comnet/cnu016] performed an extremely thorough review of existing terminology. I reproduced their Table 1 of network types that multilayer networks encompass below because it does a great job illustrating the terminology nightmare we face. Not only are there many names for the same concept, but the same name often refers to many concepts. Second, I wanted to make their extensive compilation of references extra accessible. One contributing factor to the lack of standards is poor communication between fields. I'm hoping this _Thinklab_ discussion will help bridge the gaps. And what better way to start the ball rolling than by citing the studies that paved the way for the hetnet.

The columns are defined as follows (see the study [@10.1093/comnet/cnu016] for more information):

>
+ **Aligned**: Is the network node-aligned (all nodes are shared between all layers)?
+ **Disj.**: Is the network layer-disjoint (each node is present only in a single layer)?
+ **Eq. Size**: Do all of the layers have the same number of nodes?
+ **Diag.**: Are the couplings diagonal?
+ **Lcoup.**: Do the inter-layer couplings consist of layer couplings?
+ **Cat.**: Are the inter-layer couplings categorical?
+ **|_L_|** denotes the number of possible layers
+ **_d_** denotes the number of ‘aspects’ (i.e. the ‘dimensionality’ of the layers)

| Name | Aligned | Disj. | Eq. Size | Diag. | Lcoup. | Cat. | \|_L_\| | _d_ | Example refs. |
|-----------|---------|-------|----------|-------|--------|------|-----|---|-------|
| Multilayer network |  |  |  | ✓ | ✓ | ✓ | Any | 1 | [@68] |
|  | ✓ |  | ✓ |  |  |  | Any | 1 | [@67] |
| Multiplex network | ✓ |  | ✓ | ✓ |  |  | Any | 1 | [@69 @67] |
|  | ✓ |  | ✓ | ✓ | ✓ | ✓ | Any | 1 | [@70 @71 @72 @73 @74 @75 @76] |
|  | ✓ |  | ✓ | ✓ | ✓ | ✓ | 2 | 1 | [@77 @78 @79] |
|  |  |  |  | ✓ | ✓ | ✓ | Any | 1 | [@80] |
|  | ✓ |  | ✓ | ✓ | ✓ |  | Any | 1 | [@81 @82 @83] |
| Multivariate network | ✓ |  | ✓ | ✓ | ✓ | ✓ | Any | 1 | [@31] |
| Multinetwork | ✓ |  | ✓ | ✓ | ✓ | ✓ | Any | 1 | [@84] |
|  | ✓ |  | ✓ | ✓ | ✓ | ✓ | Any | 2 | [@85] |
| Multirelational network | ✓ |  | ✓ | ✓ | ✓ | ✓ | Any | 1 | [@2 @50 @86 @87] |
| Multirelational data | ✓ |  | ✓ | ✓ | ✓ | ✓ | Any | 1 | [@88 @89] |
| Multilayered network | ✓ |  | ✓ | ✓ | ✓ | ✓ | Any | 1 | [@83 @90 @91 @92] |
| Multidimensional network | ✓ |  | ✓ | ✓ | ✓ | ✓ | Any | 1 | [@93 @94 @95 @96 @97 @98 @99] |
|  | ✓ |  | ✓ | ✓ | ✓ | ✓ | Any | 3 | [@100] |
| Multislice network | ✓ |  | ✓ | ✓ |  |  | Any | 1 | [@66 @101 @102 @103] |
| Multiplex of interdependent networks | ✓ |  | ✓ | ✓ | ✓ | ✓ | Any | 1 | [@104] |
| Hypernetwork | ✓ |  | ✓ | ✓ | ✓ | ✓ | Any | 1 | [@105 @106] |
| Overlay network | ✓ |  | ✓ | ✓ | ✓ | ✓ | 2 | 1 | [@107 @108] |
| Composite network | ✓ |  | ✓ | ✓ | ✓ | ✓ | 2 | 1 | [@109] |
| Multilevel network |  | ✓ |  |  |  |  | Any | 1 | [@110 @111] |
|  |  |  |  | ✓ | ✓ | ✓ | Any | 1 | [@80 @112] |
| Multiweighted graph | ✓ |  | ✓ | ✓ | ✓ | ✓ | Any | 1 | [@113] |
| Heterogeneous network |  | ✓ |  |  |  |  | 2 | 1 | [@49 @50] |
| Multitype network |  | ✓ |  |  |  |  | Any | 1 | [@114 @115 @65] |
| Interconnected networks |  | ✓ | ✓ |  |  |  | 2 | 1 | [@116 @117] |
|  |  | ✓ |  |  |  |  | 2 | 1 | [@118 @119] |
| Interdependent networks |  | ✓ | ✓ |  |  |  | 2 | 1 | [@57] |
|  |  | ✓ |  |  |  |  | 2 | 1 | [@120] |
|  |  |  | ✓ |  |  |  | 2 | 1 | [@121] |
|  |  | ✓ |  |  |  |  | 2 | 1 | [@122 @123] |
|  | ✓ |  | ✓ | ✓ | ✓ | ✓ | Any | 1 | [@124] |
| Partially interdependent networks |  | ✓ |  |  |  |  | 2 | 1 | [@125] |
| Network of networks |  |  | ✓ |  |  |  | Any | 1 | [@126] |
| Coupled networks |  |  |  | ✓ | ✓ | ✓ | Any | 1 | [@127] |
| Interconnecting networks |  |  |  | ✓ | ✓ | ✓ | 2 | 1 | [@128] |
| Interacting networks |  | ✓ |  |  |  |  | Any | 1 | [@56 @129] |
|  |  | ✓ |  |  |  |  | 2 | 1 | [@122] |
| Heterogenous information network |  |  |  |  |  |  | Any | 2 | [@51 @130 @131 @132] |
|  |  | ✓ |  |  |  |  | Any | 1 | [@133] |
| Meta-matrix, meta-network |  |  |  |  |  |  | Any | 2 | [@34 @134 @135] |

[@2]: 10.1017/cbo9780511815478
[@31]: 10.1348/000711099159053
[@34]: 10.1140/epjst/e2013-01712-8
[@49]: 10.1109/icdm.2007.57
[@50]: 10.1007/11564126_44
[@51]: 10.1145/2481244.2481248
[@56]: http://arxiv.org/abs/0907.0894 ""Leicht E. A., D'Souza R. M. Percolation on interacting networks. 2009. arXiv:0907.0894""
[@57]: 10.1038/nature08932
[@65]: 10.1103/PhysRevE.74.066114
[@66]: 10.1126/science.1184819
[@67]: 10.1103/physrevx.3.041022
[@68]: 10.1140/epjst/e2013-01712-8
[@69]: 10.1073/pnas.1318469111
[@70]: 10.1103/PhysRevE.86.036103
[@71]: 10.1103/PhysRevE.85.045102
[@72]: 10.1103/PhysRevLett.111.058701
[@73]: 10.1103/PhysRevE.87.062806
[@74]: 10.1103/PhysRevE.88.052811
[@75]: 10.1103/PhysRevE.89.032804
[@76]: 10.1109/asonam.2012.101
[@77]: http://arxiv.org/abs/1307.2967 ""Min B., Goh K.-I. Layer-crossing overhead and information spreading in multiplex social networks. 2013. arXiv:1307.2967""
[@78]: 10.1088/1367-2630/14/3/033027
[@79]: 10.1103/PhysRevE.89.042811
[@80]: 10.1103/PhysRevE.86.036115
[@81]: 10.1103/PhysRevE.88.032807
[@82]: 10.1103/PhysRevE.88.050801
[@83]: 10.1063/1.4818544
[@84]: 10.1103/PhysRevE.81.046104
[@85]: 10.1016/j.physa.2011.02.004
[@86]: 10.1109/asonam.2012.100
[@87]: 10.1109/cse.2009.69
[@88]: 10.1137/1.9781611972825.13
[@89]: 10.1145/2020408.2020594
[@90]: 10.1007/978-3-642-16318-0_27
[@91]: 10.1109/asonam.2011.67
[@92]: 10.1080/18756891.2012.696922
[@93]: 10.1016/j.jocs.2011.05.009
[@94]: 10.1007/s10618-013-0331-0
[@95]: 10.1007/s11280-012-0190-4
[@96]: 10.1007/s10618-011-0231-0
[@97]: 10.1098/rstb.2012.0113
[@98]: 10.1109/TSMCA.2011.2132707
[@99]: 10.1145/2492517.2492537
[@100]: 10.1007/978-3-642-23935-9_37
[@101]: 10.1063/1.3518696
[@102]: 10.1007/978-3-642-25501-4_19
[@103]: 10.1063/1.4790830
[@104]: 10.1038/srep00620
[@105]: 10.1103/PhysRevE.86.056102
[@106]: 10.1088/1367-2630/14/3/033035
[@107]: 10.1103/PhysRevE.81.036118
[@108]: 10.1103/PhysRevE.84.026105
[@109]: 10.1145/2378956.2378958
[@110]: 10.1016/j.socnet.2013.01.004
[@111]: 10.1016/j.socnet.2008.02.001
[@112]: 10.1080/00207160.2011.577212
[@113]: 10.1080/15427951.2012.678191
[@114]: 10.1103/PhysRevE.88.012809
[@115]: 10.1103/PhysRevE.79.036113
[@116]: 10.1103/PhysRevE.85.066109
[@117]: 10.1038/srep03289
[@118]: 10.1103/PhysRevE.86.026106
[@119]: 10.1109/acc.2013.6580178
[@120]: 10.1103/PhysRevLett.105.048701
[@121]: http://arxiv.org/abs/1304.4731 ""Martin-Hernandez J., Wang H., Van Mieghem P., D'Agostino G. On synchronization of interdependent networks. 2013. arXiv:1304.4731""
[@122]: 10.1073/pnas.1110586109
[@123]: 10.1038/nphys2727
[@124]: 10.1103/PhysRevLett.109.248701
[@125]: 10.1103/PhysRevE.87.052812
[@126]: 10.1103/PhysRevLett.107.195701
[@127]: 10.1109/JSAC.2013.130606
[@128]: 10.1209/0295-5075/93/68002
[@129]: 10.1140/epjb/e2011-10795-8
[@130]: 10.1109/asonam.2011.107
[@131]: http://www-dev.ccs.neu.edu/home/yzsun/papers/vldb11_topKSim.pdf ""Sun Y., Han J., Yan X., Yu P. S., Wu T. PathSim: meta path-based top-k similarity search in heterogeneous information networks. Proceeding of the 2011 International Conference on Very Large Data Based (VLDB 2011) 2011. Seattle, WA.""
[@132]: http://hdl.handle.net/2142/42366 ""Sun Y. Mining heterogeneous information networks. Ph.D. Thesis 2012. University of Illinois at Urbana-Champaign.""
[@133]: 10.1145/1557019.1557107
[@134]: 10.1016/j.dss.2006.04.003
[@135]: http://oai.dtic.mil/oai/oai?verb=getRecord&metadataPrefix=html&identifier=ADA459444 ""Tsvetovat M., Reminga J., Carley K. M. DyNetML: interchange format for rich social network data. CASOS Technical Report 2004. Carnegie Mellon University, School of Computer Science, Institute for Software Research International, CMU-ISRI-04-105.""","17",2016-01-28,2016-01-28,2,10015,"base.profile","Daniel","Himmelstein","dhimmel"
"651","comments","rephetio","2016-01-29T18:38:18.936Z",17,"# 2016 GraphGist Challenge

Neo4j is hosting a GraphGist [challenge](http://portal.graphgist.org/challenge/index.html ""GraphGist Challenge""). GraphGists provide the [following](http://portal.graphgist.org/about ""What is a GraphGist?""):

> With Neo4j GraphGists you can describe and model your domain in a simple text file (AsciiDoc) and render it as a rich, interactive, database-backed page in any browser. It is perfect to document a specific domain, use-case, question or graph problem.

This years competition is Star Wars themed -- a theme we adhered to in [**our submission**](http://portal.graphgist.org/graph_gists/drug-repurposing-by-hetnet-relationship-prediction-a-new-hope ""Drug repurposing by hetnet relationship prediction: a new hope""). To give you a taste, our prologue begins with:

> A long time ago in a galaxy far, far away…​. It is a dark time for drug discovery. The Empire spends over a billion dollars in R&D per new drug approval. The process takes decades, 9 out of 10 attempts fail, and the cost has been doubling every 9 years since 1970. But, a small band of Rebel scientists pursue an alternative. Using public data and open source software, the Rebels are predicting new uses for existing drugs.

Our goal in creating a submission was twofold. First, we're excited to interact with other members of the neo4j community who are doing complimentary work. Second, we designed the GraphGist to be a good introduction to our project and hetnet relationship prediction in general.","17",2016-01-29,2016-01-29,2,1515,"base.profile","Daniel","Himmelstein","dhimmel"
"652","comments","rephetio","2016-02-19T19:49:47.864Z",17,"After an additional round of emails on February 4, 2016, Jill Mesirov got back to me. Dr. Mesirov was the principal investigator for the MSigDB project while at the Broad but has since moved to UCSD. She mentioned that they received permission to distribute certain parts of the database but that they did not receive permission to pass on those rights. She also added Helga Thorvaldsdottir -- the MSigDB project manager at the Broad -- to the conversation.

I responded with the following message:

> Dear Dr. Mesirov et al,

> Thanks for the reply and involving Helga. Hopefully, we can now locate the appropriate parties to handle our request.

> I had guessed that non-transferable distribution rights were part of the issue. I appreciate wanting to build the most comprehensive resource, even when that necessitates stricter licensing.

> Do you know which resources forbid downstream distribution? Perhaps we could be given permission to redistribute the unencumbered portions of the database? And for encumbered portions, we could seek the needed additional permissions from the content owners.

> We feel that distribution fulfills an important scientific need. We're integrating over 30 resources into a single network that we envision becoming a widely used community dataset. Much like MSigDB did with gene sets, our network will enable novel analyses that are only possible once the data has been unified into a single resource. Additionally, forbidding distribution has troubling consequences for reproducibility. See for example [this instance](http://wpo.st/NUj91 ""What happened when a group of researchers tried to repeat a headline-grabbing study"") where data copyright interfered with replication.

> Given these considerations, we would appreciate help in finding a solution that allows us to distribute MSigDB data, even if only a subset of the database.

> Best,
> Daniel

In short, I asked if they could look into granting us permission to distribute the unencumbered portions of the database. Ms. Thorvaldsdottir responded that they will be meeting with the IP/Licensing team to discuss my request.","17",2016-02-19,2016-02-19,2,2140,"base.profile","Daniel","Himmelstein","dhimmel"
"653","comments","rephetio","2016-02-10T01:59:27.854Z",17,"# Gene handling quality control

Currently, we have STARGEO case-control queries for 66 of our diseases. Of these 66 queries, 37 return differential expression results. The rest either have insufficient samples or fail [due to errors](https://github.com/idrdex/star_api/issues/13#issue-123599787 ""idrdex/star_geo#13 Specific failing analyses"").

In the past, I remember coming across a STARGEO output (gene rows × meta-analysis columns) where many rows contained duplicate gene symbols. @idrdex had also mentioned to me that mapping the probe/gene names deposited in GEO can get complicated. Therefore, I wanted to do a few quality controls before proceeding.

I checked into our current STARGEO analysis of differential expression for 37 diseases. I looked for three occurrences which could be due to problems with gene handling ([notebook](https://github.com/dhimmel/stargeo/blob/6c5a348f2ea22edf475dc14a5eed93eb95290d7d/gene-fidelity.ipynb)):

+ GeneID--Symbol mappings that don't exist in Entrez Gene ([results](https://github.com/dhimmel/stargeo/blob/6c5a348f2ea22edf475dc14a5eed93eb95290d7d/diagnose/discord.tsv)). There were 2,274 ID-Symbol pairs that didn't exist in my parsing of Entrez Gene. However, most of these were not protein-coding and appeared to stem from updates to the database over time.
+ Rows with duplicate GeneIDs ([results](https://github.com/dhimmel/stargeo/blob/6c5a348f2ea22edf475dc14a5eed93eb95290d7d/diagnose/duplicate_ids.tsv)). Only two rows were affected by this issue.
+ Rows with duplicate symbols ([results](https://github.com/dhimmel/stargeo/blob/6c5a348f2ea22edf475dc14a5eed93eb95290d7d/diagnose/duplicate_symbols.tsv)). 72 rows were affected by this issue. It did seem however that many gene symbols were not the approved symbols but rather synonyms. Since we [use Entrez Gene](http://thinklab.com/discussion/using-entrez-gene-as-our-gene-vocabulary/34) IDs for mapping, synonyms are not a major concern for us.

So in conclusion, I didn't detect any major issues with the gene handling in STARGEO. These quality controls do not assess the probe--gene mapping, but instead whether the gene information reported for the meta-analyses makes sense.","17",2016-02-10,2016-02-10,2,2198,"base.profile","Daniel","Himmelstein","dhimmel"
"654","comments","rephetio","2016-02-10T11:59:49.322Z",17,"# _Nature News_ mentions our use of _Thinklab_ to avoid publishing delays

A *Nature News* [feature](https://doi.org/10.1038/530148a ""The Waiting Game"") published today [@10.1038/530148a] mentions our Thinklab project:

> Some scientists are going a step further, and using platforms such as GitHub, Zenodo and figshare to publish each hypothesis, data collection or figure as they go along. Each file can be given a DOI, so that it is citable and trackable. Himmelstein, who already publishes his papers as preprints, has been using the Thinklab platform to progressively write up and publish the results of a new project since January 2015. “I push 'publish' and it gets a DOI with no delay,” he says. “Am I really gaining that much by publishing [in a conventional journal]? Or is it better to do what is fastest and most efficient to get your research out there?”

The feature also covers my [blog post](http://blog.dhimmel.com/history-of-delays/ ""The history of publishing delays"") on the history of publishing delays. Using data from PubMed, I found a median time from submission to acceptance of ~100 days and a median time from acceptance to online publication of ~25 days. Since we post most content on *Thinklab* several months before it will ever be submitted, we're getting our work out 200+ days sooner by using realtime open notebook publishing.","17",2016-02-10,2016-02-10,2,1365,"base.profile","Daniel","Himmelstein","dhimmel"
"655","comments","rephetio","2016-02-17T19:43:44.550Z",17,"We've created a [preliminary network](http://thinklab.com/discussion/one-network-to-rule-them-all/102 ""Preliminary hetnet release"") with 10 types of nodes (metanodes) and 27 types of edges (metaedges). Now an important detail is naming node and edge types appropriately.

For each metanode and metaedge, we also need abbreviations. We use the abbreviations to make writing out complete paths less cumbersome. For example, in our previous project, we [abbreviated](https://doi.org/10.1371/journal.pcbi.1004259.s010 ""S1 Table. Features · Hetnet-Based Prioritization of Disease Associations"") the `Gene - interaction - Gene - expression - Tissue - localization - Disease` path to `GiGeTlD` [@10.1371/journal.pcbi.1004259.s010].

We have several conventions for naming and abbreviations, but they haven't been publicly explained or discussed. This discussion is now home to these topics.","17",2016-02-17,2016-02-17,2,887,"base.profile","Daniel","Himmelstein","dhimmel"
"656","comments","rephetio","2016-02-17T22:39:04.375Z",17,"# Naming according to parts of speech

According to [Chen's rules of thumb](https://en.wikipedia.org/w/index.php?title=Entity%E2%80%93relationship_model&oldid=704204795#Mapping_natural_language ""Mapping natural language · Entity–relationship model · Wikipedia""), we should use parts of speech as follows [@10.1016/s0169-023x(97)00017-7]:

+ _common nouns_ for node labels (types)
+ _proper nouns_ for node names
+ _transitive verbs_ for relationship (edge) types
+ _intransitive verbs_ for property (attribute) types
+ _adjectives_ for node properties
+ _adverbs_ for relationship properties

I'm not convinced about the last three, since our properties (data attributes for nodes and relationships) are often highly technical. However, I think we should adhere to the first three rules when possible.

Our node labels are already common nouns. Our node names are already proper nouns. However, we were using common nouns for relationship types. Thus, I switched to transitive verbs for relationship types ([commit](https://github.com/dhimmel/integrate/commit/8ca7c9e971ce5a85c7729b3f1df7db54beb19d18)). The table below shows the noun (old) and verb (new) relationship type.

| Source | Target | Metaedge (noun) | Metaedge (verb) |
|----------|------------|--------|------------|
| compound | gene | binding | binds |
| compound | side effect | causation | causes |
| compound | gene | downregulation | downregulates |
| compound | disease | indication | palliates |
| compound | compound | similarity | resembles |
| compound | disease | indication | treats |
| compound | gene | upregulation | upregulates |
| disease | gene | association | associates |
| disease | gene | downregulation | downregulates |
| disease | anatomy | localization | localizes |
| disease | symptom | presence | presents |
| disease | disease | similarity | resembles |
| disease | gene | upregulation | upregulates |
| gene | anatomy | downregulation | downregulates |
| gene | gene | evolution | evolves |
| gene | anatomy | expression | expresses |
| gene | gene | interaction | interacts |
| gene | biological process | participation | participates |
| gene | cellular component | participation | participates |
| gene | molecular function | participation | participates |
| gene | pathway | participation | participates |
| gene | perturbation | regulation | regulates |
| gene | anatomy | upregulation | upregulates |
| gene | gene | knockdown downregulation | knockdown downregulates |
| gene | gene | knockdown upregulation | knockdown upregulates |
| gene | gene | overexpression downregulation | overexpression downregulates |
| gene | gene | overexpression upregulation | overexpression upregulates |

In several cases, switching from noun to verb cut out several characters -- a welcome occurrence. Switching relationship types to verbs also makes sense as part of our [migration to neo4j](http://thinklab.com/discussion/using-the-neo4j-graph-database-for-hetnets/112). The neo4j convention is to use verbs for relationship types. In fact, a neo4j company [explains relationships](https://www.graphstory.com/elements-of-a-graph-database) by saying:

> Where nodes can be thought of as nouns, relationships can be thought of as verbs.","17",2016-02-17,2016-02-17,2,3270,"base.profile","Daniel","Himmelstein","dhimmel"
"657","comments","rephetio","2016-02-18T06:21:08.503Z",125,"The compound-gene associations are not intuitive to me. I assume that when, for example, a compound downregulates a gene, it is supposed to mean that the compound inhibits the protein product encoded by the gene. However, if read at face value, it would mean that the compound binds to something else that through some signaling results in down-regulation of the gene (i.e. less transcription).

The gene-gene association ""evolves"" is bit of a misnomer, I think. Unless you are looking at ancestral genes, one gene will not have evolved from another gene. Rather two genes will share ancestry. In that case, the term ""homology"" is would be much clearer. Also, you probably want to be able to distinguish between orthologs and paralogs in your network.

Are the gene-anatomy relationships not backwards? I can understand what it means that means that the liver ""upregulates"" a gene (I assume it means that the gene is higher expressed in the liver than elsewhere). But I cannot comprehend what it would mean that a gene upregulates the liver.

Same goes for gene-pertubation relationships. I can understand that a pertubation regulates a gene, but how can a gene regulate a pertubation? And why is this type of association not divided into up- and down-regulation like everything else?

I am not entirely sure how useful the ""knockdown downregulates"" etc. types are. Usually ""knockdown downregulates"" would be interpreted to mean ""upregulates"" etc.","125",2016-02-18,2016-02-18,2,1455,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"658","comments","rephetio","2016-02-18T19:59:49.447Z",17,"> I assume that when, for example, a compound downregulates a gene, it is supposed to mean that the compound inhibits the protein product encoded by the gene. However, if read at face value, it would mean that the compound binds to something else that through some signaling results in down-regulation of the gene (i.e. less transcription).

Your face value interpretation is correct. Compound--downregulates--Gene means the compound decreases the transcriptional expression of the gene. We [extracted these relationships](http://thinklab.com/discussion/computing-consensus-transcriptional-profiles-for-compounds-using-lincs/43#6) from LINCS L1000.

> The gene-gene association ""evolves"" is bit of a misnomer

I agree, ""evolves"" is not good. This edge signifies [evolutionary rate covariation](http://thinklab.com/discussion/selecting-informative-erc-evolutionary-rate-covariation-values-between-genes/57) [@10.1371/journal.pgen.1004967]. It's a mouthful, and I don't know the best way to shorten and verbify it. Perhaps ""covaries"" is an improvement?

> Are the gene-anatomy relationships not backwards? … Same goes for gene-pertubation relationships.

Great point. We should present these edges in subject-verb-object order. I have switched the default orientation of the confusing metaedges ([commit](https://github.com/dhimmel/integrate/commit/3354a4cbb36d184f46e78831fa0f605ff92e7637) ""GitHub · dhimmel/integrate @ 3354a4cbb36d184f46e78831fa0f605ff92e7637"")). In practice the object-verb-subject order may still arise, for example when representing paths.

> I am not entirely sure how useful the ""knockdown downregulates"" etc. types are. Usually ""knockdown downregulates"" would be interpreted to mean ""upregulates"" etc.

I will look into collapsing:

+ _knockdown downregulates_ with _overexpression upregulates_ to create an _upregulates_ edge
+ _knockdown upregulates_ with _overexpression downregulates_ to create a _downregulates_ edge","17",2016-02-18,2016-02-18,2,1961,"base.profile","Daniel","Himmelstein","dhimmel"
"659","comments","rephetio","2016-02-20T03:13:15.931Z",188,"# Initial results from the third curator
I was initially recruited to break the 444 disagreements between the other curators. After an initial pilot review of the first 80 or so disagreements, I noted some ambiguity in definition of the three classes that appeared to be giving rise to some of the disagreements. I discussed these with Daniel and we reached a more precise amended set of definitions.
### Definitions:
- **disease modifying (DM) ** — a drug that therapeutically changes the underlying or downstream biology of the disease
- **symptomatic (SYM) ** — a drug that treats a significant symptom of the disease
-  **non-indication (NOT) ** — a drug that neither therapeutically changes the underlying or downstream biology nor treats a significant symptom of the disease
### Guidelines:
- **reasonable evidence** of efficacy is required to be classified as disease modifying or symptomatic. This includes off-label use.
- if no classification accurately describes an indication, the **most appropriate** (although imperfect) classification should be chosen
### Amendments: (created 1/27/16, not seen by AJG and CSH)
- **Amendment 1: ** if a drug was **previously indicated, but is no longer used** due to side effects, or because there are better drugs, it is still considered **DM**
- **Amendment 2: ** it **doesn't matter whether it is first line or fifth line**, it's still considered **DM**
### Assumptions: (by PK)
- **Assumption 1: DM trumps SYM. ** If a drug is clearly both disease modifying and also treats symptoms, then I will call it disease modifying. This is because most disease modifying drugs also treat symptoms.
- **Assumption 2: SYM trumps NOT.** If a drug is clearly symptomatic treatment, but can actually exacerbate the downstream biology of disease, then I chose SYM. I made this choice because this was the choice I saw most often made by AJG and CSH

With the revised definitions above, I reviewed the 444 disagreements as well as the 944 agreements (and suggested a change on 124 of these). I was not blinded to the other curators' decisions. I was able to see both of their decisions and also any comments they had left regarding their reasoning. In general, my strategy was to look three sources for each drug (unless I clearly already knew that a drug was DM or SYM): uptodate.com, drugbank.ca (link provided by Daniel in the spreadsheet), and a basic google search (which also served as a proxy for a pubmed search). When I noted that one of the two curators was calling an indication which I was not aware of (either DM or SYM), I would do a much more detailed search including a more detailed google search and a direct pubmed search. 

Below is the breakdown of classifications

|class | AJG | CSH | PK |  | class | AJG | CSH | PK
|---|---|---|---|---|---|---|---|---|
|DM | 599 | 593 | 755 |  | DM | 43.2% | 42.7% | 54.4%|
|SYM | 514 | 517 | 390 |  | SYM | 37.0% | 37.2% | 28.1%|
|NOT | 275 | 278 | 243 |  | NOT | 19.8% | 20.0% | 17.5%|
|total | 1388 | 1388 | 1388 |  | total | 100.0% | 100.0% | 100.0%|

The most notable difference was that I called DM more often than the other curators. There are at least two reasons for this. First, I was making use of amendment 1 and amendment 2 to make calls for DM, whereas the other curators were not using these amendments (in fact, when the other curators called NOT, they left comments such as ""no longer recommended due to side effects"", ""not used anymore"", or ""rarely used""). Second, when I found a disagreement between two curators, I was more likely to agree with the curator who called DM. Specifically, of the 444 disagreements, there were 298 where one curator chose DM; of these 298 instances, I chose DM 204 times. I think this is because I did a more detailed search when I knew that one other curator thought that there was a DM indication. Of note, of the 146 times that the other curators were in disagreement between SYM and NOT, I chose SYM 76 times, I chose NOT 52 times, and I chose DM 18 times, likely for the same reasons described above.

The [excel spreadsheet](https://github.com/dhimmel/indications/blob/d3d57b07abcf8d7af55f8e42ef7c4c99acd87ca8/curation/pk/template-pk%20final.xlsx) includes a detailed discussion of every decision that I made. I will not re-iterate here the instances where I used one of the amendments above to change a call or to resolve a disagreement. I will also not detail instances where I changed a call because I thought another curator made a human error (for example, not classifying two proton-pump inhibitors in the same way for the same disease). I will also not re-iterate cases where I felt that one of the two other curators knew about an indication (either DM or SYM) and I was able to confirm evidence of this indication.

I would like to enter into the discussion the cases where there was a tough decision to be made, and would like to welcome an open discussion to come to a consensus. In general, when there was a tough decision, I did look at the other curators' calls to see what the consensus would be. Below is a summary of this discussion (with greater detail given in the spreadsheet), organized by disease and drug class.

- **hypertension, general **— Hypertension (the disease entity) is a heterogenous group of diseases. The most likely subtype of hypertension was likely Essential Hypertension (ET). The disease of Hypertension (including ET) progresses to have complications such as strokes and heart attacks. Hypertension (i.e. high blood pressure) is also a symptom (of many diseases, including diseases that are not called ""hypertension""). Within the disease of ET, hypertension is not just a symptom but also a marker of disease progression, i.e. controlling blood pressure (treating this symptom) will slow the advancement of the disease hypertension and prevent downstream biology (proven by evidence, guideline 1). Therefore, by assumption 1, a total of 29 drugs were called **DM** rather than SYM.

- **hypertension, diuretics **—all called **DM** due to amendment 1 and amendment 2

- **hypertension, drugs used to treat ocular hypertension or pulmonary hypertension **— ""hypertension"" as defined in Daniel's link as ""chronic elevated blood pressure in the arteries"" It is therefore not the same as ""ocular hypertension"" or ""pulmonary hypertension"" (I think the spirit of the definition is systemic arteries, not pulmonary arteries. Also, pulmonary hypertension is quite a different disease with different pharmacology).Therefore, I chose to put **NOT** for all of these.

- **type 2 diabetes, drugs that lower blood sugar **—Diabetes is similar to hypertension. The disease is a tendency to have high blood sugar (hyperglycemia). Hyperglycemia is a symptom (of both diabetes and other diseases). Within the disease of diabetes, hyperglycemia is both a symptom and a marker of disease progression. Therefore anything that lowers hyperglycemia will be **DM**.

- **type 1 and type 2 diabetes, ACE inhibitors and ARBs **— The downstream biology of DM2 includes proteinuria and eventual renal failure. ACE inhibitors and ARBs prevent this downstream biology in DM2 patients. Therefore they are **DM**.

- **epilepsy, anti-epileptic drugs **—I think that for consistency, all anti-epileptics should be either DM or SYM, as there is only very limited evidence that any of these drugs are different from each other. My thoughts would be to label them all as **DM**. Here is why: epilepsy syndrome (disease) is defined as a propensity to have seizures (symptom). However, the natural downstream biology of the disease is that each seizure that you actually have makes you more likely to have worse epilepsy in the future (i.e. seizures beget more seizures). One mechanism is that when you have a lot of seizures, you develop mesial temporal sclerosis, and mesial temporal sclerosis is a risk factor for further seizures. Therefore, I would argue that any drug which treats the symptom of seizure is actually affecting downstream biology, and is therefore disease modifying. And by assumption 1, DM trumps SYM.

- **osteoarthritis, NSAIDs and steroids **— I put everything as **SYM**. From [MedScape](http://emedicine.medscape.com/article/330487-medication): ""To date, no disease-modifying or structure-modifying intervention has been proved effective in osteoarthritis."" CSH agreed with this interpretation, while it was clear that AJG was conflicted. To play devil's advocate, you could potentially say that the biology of osteoarthritis (OA) that it starts with inflammation, and the ""down-stream"" biology is the pain (the primary symptom as well), and therefore NSAIDs prevent ""down-stream"" biology. However, if we want to make that decision, I think we should change all the NSAIDs and steroids to DM.

- **cancers, pain medications **— I think pain is a symptom of cancer and therefore I put all of these as **SYM**. CSH agreed, while AJG was conflicted and sometimes called NOT. 

- **hematologic cancers, steroids **—steroids actually ""treat"" hematologic cancers, even though these days there are much better meds and steroids are not considered ""treatment"", in the past they were the first line. By amendment 1, I put all of these as **DM**.

- **non-hematologic cancers, steroids **— steroids treat the nausea symptoms associated with cancers. While many cancers can potentially cause nausea, most nausea in cancer patients is due to side effect of chemo. However, I still put **SYM** for these because they can treat nausea and nausea is potentially a side effect of any cancer. CSH agreed with me on most of these, AJG was conflicted.

- **cancers, hydroxyurea and other chemotherapies **— AJG called this DM for all cancers. CSH called it DM only for the cancers for which it is indicated. The truth is, any chemotherapy has theoretical benefit against any cancer (any quickly-reproducing cell type). One possibility would be to label all chemotherapies as DM for all cancers. I thought it would be better to be selective and only label DM for chemo that is used (or has been used) in a particular cancer. That way, the results of the drug-repurposing search would yield different results for different cancers (rather than giving the exact same result for all cancers because the input was exactly the same for all cancers).Thus, I labeled some **DM** and some as **NOT**.

- **cancers, bisphosphonates **— I don't think of bone loss as a ""side effect"" of cancers (at least not any of the cancers listed). Some people are malnourished and/or have drug-induced bone loss, or may have bone metastases, but I don't think this captures the essence of cancer. I chose to put **NOT** for all of these (CSH agreed, AJG generally chose SYM).

- **coronary artery disease, drug to treat hypertension or diabetes **— I treated this as pure coronary artery disease (CAD) in the absence of other causes. I did not interpret this as ""CAD as a consequence of hypertension (HTN)"" or ""CAD as a consequence of diabetes (DM2)"". It is true that many of these medications would help prevent CAD if CAD is considered as the ""downstream biology"" of HTN or DM2. However, the medications to not treat any biology downstream of CAD in the absence of HTN or DM2. I therefore labeled these as **NOT**.

- **coronary artery disease, diuretics and other drugs used for congestive heart failure (CHF) **— I consider these to be **DM**. Consider CHF as a common dowstream biology of coronary artery disease (CAD), specifically let's consider HFrEF. The biology of HFrEF is that the heart has poor cardiac output, thus there is fluid retention, thus there is further strain on the heart, creating a vicious cycle. Thus, diuretics should help avoid the vicious cycle and slow the downstream progression of disease. While no trial may have ever showed mortality benefit, I think there is reasonable evidence that this would be true.

- **migraine, general **— While AJG called everything SYM, CSH called one drug (amitryptilene) DM and everything else SYM, citing that this medications ""may decrease frequency of migraines"". I agreed with CSH's interpretation and actually chose to include many other medications as DM based on the same reasoning. Migraine disease is a propensity to get migraine headaches. Therefore, anything that decreased migraine frequency was considered by me to be **DM** (decreases the downstream biology that leads to headache). Anything that treated the pain of the headache I considered **SYM**.

- **autoimmune diseases, steroids and NSAIDs **— I labeled the steroids as **DM** and the NSAIDs as **SYM**. It is true that steroids are rarely if ever actually used for chronic disease (though often used to treat the symptoms of flares), mostly because of their terrible side-effect profile long-term. However, they do actually affect disease biology and do not specifically treat any specific symptom (for example, steroids do not cure ""weakness"", but do change the biology of the multiple sclerosis flare to help the patient recover from ""weakness""). It was a close call for me for NSAIDs (as they do have anti-inflammatory properties, especially useful in the auto-immune arthritidies), but I went with consensus and chose SYM. The other curators tended not to call steroids DM (probably because they were thinking about side-effect profile), and they were inconsistent on their calls on NSAIDs.

- **asthma, steroids and beta-agonists and anticholinergics **— I put **DM** for all of these. I felt steroids are DM (since they are given to prevent attacks), long-acting beta-agonists are also DM in my opinion since they prevent attacks (in conjunction with steroids, despite the small increased risk of asthma-related death in people who don't use steroids). I put short acting beta-agonists as DM because they too can prevent downstream biology (since they are sometimes used, for example before exercise, to prevent downstream biology from happening).

- **allergic rhinitis, steroids and anti-histamines and decongestants **— CSH admittedly had a problem with this, she even noted ""im having a hard time with allergic rhinitis. Maybe all of these meds are SYM."".  AJG was conflicted as well.  I chose to mark all of the steroids and anti-histamines as **DM** because they alter the immune response (the allergy). I chose to mark the decongestants (i.e. pseudoephedrine) as **SYM** because they treat a symptom (congestion) but not the underyling biology (the immune reaction)

- **chronic obstructive pulmonary disease (COPD), general **— I put steroids and beta-agonists as **DM** for similar reasons to asthma, though admittedly there is less evidence for this. I put all the antibiotics as **SYM** (they don't eradicate infection, they don't delay progression, they treat attacks) and did not differentiate between the antibiotics

- **glaucoma, general **— I agreed with CSH that almost every drug is DM, AJG was conflicted. I think it's more **DM**, based on similar discussion as hypertension.

- **alcohol dependence, general **— First, I included symptoms of alcohol withdrawal along with alcohol dependence, presumably because withdrawal symptoms are probably felt at some point in any person with alcohol dependence. Thus, I chose to mark chlordiazepoxide and zofran (used to treat withdrawal) as **SYM** (CSH agreed with both, AJG agreed with one of these). Next, there was the question of drugs designed to curb drinking (Citalopram, Disulfiram, Naltrexone, Acamprosate); I chose to mark these as **DM** because they are different from the drugs above in that they treat the urge to drink (modifying the disease) rather than the symptoms of not drinking (AJG agreed with all 5, CSH agreed with 1)

- **psychiatric diseases other than alcohol/drug dependence, general **— I agreed with both CSH and AJG that in general, the medications used are all **SYM** rather than DM (other than alcohol and nicotine dependence as described).

- **alzheimer's disease, general **— donepezil was marked as **DM** (agreed with AJG) because it is supposed to slow disease, not treat any specific symptom. Other cholinesterase inhibitors were changed to DM to match donepezil. I chose to group all antipsychotics as **SYM** in order to be consistent (AJG and CSH agreed most of the time)

- **anemia **— there is no good way to do this. Anemia is not a single disease, it is a very heterogeneous set of diseases (with very little overlap between sub-types in terms of incidence or pathophysiology). Though the most common cause of anemia is likely iron deficiency anemia, iron deficiency anemia accounts for probably a minority of all anemias. Specific types of anemia will of course respond to specific drugs  (autoimmune anemia to steroids, folate deficiency responds to folate, etc...). I was faced with two choices: (1) choose DM for anything which could treat any type of anemia or (2) choose DM for anything which could treat most types of anemia. Choice (2) means nothing will link to anemia (no DM or SYM) and anemia will essentially be removed from analysis. Choice (1) means we are choosing a variety of drugs to treat a variety of illnesses. I chose choice (2) because I think it's best to ignore anemia, given that it is such a heterogeneous set of diseases. AJG and CSH were rather inconsistent in their answers, it is clear that they too had difficulty with anemia. In summary, everything was marked as **NOT**.","188",2016-02-20,2016-02-20,2,17481,"base.profile","Pouya","Khankhanian","pouyakhankhanian"
"660","comments","rephetio","2016-02-23T00:20:34.010Z",17,"# Overly broad and thus uninformative diseases

@pouyakhankhanian, fantastic curation!

From your comments, it appears that some of our diseases are too general from a pharmacological perspective. For example, you mention anemia and hypertension as particularly troublesome. To recap how we arrived at our 137 diseases, I [selected the subset](http://thinklab.com/discussion/unifying-disease-vocabularies/44#6) of Disease Ontology terms that have been analyzed using GWAS or were a 'body system' cancer. When diseases were redundant, a single disease was chosen (for example, coronary artery disease was chosen over myocardial infarction). In retrospect, input from physicians would have been prudent during this stage.

When we created our [indication catalog](http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#21) (which we're curating here), I propagated indications from specific to more general terms. For example, an indication for non-small cell lung carcinoma (`DOID:3908`) would be considered an indication for lung cancer (`DOID:1324`).

In the cases of hypertension and anemia, @pouyakhankhanian found this practice problematic. Specifically, he considered pulmonary hypertension (`DOID:6432`) to be ""quite a different disease with different pharmacology"" than the definition of hypertension (`DOID:10763`). However the Disease Ontology defines pulmonary hypertension as a subtype of hypertension. Ocular hypertension (`DOID:9282`) is not a subtype -- instead it's part of the glaucoma lineage. He also mentioned anemia as having heterogeneous subtypes.

While my original guidance would have been to chose DM or SYM if the drug is DM or SYM for any subtype, I see the point that some diseases may be too broad and therefore uninformative for our prediction approach.","17",2016-02-23,2016-02-23,2,1826,"base.profile","Daniel","Himmelstein","dhimmel"
"661","comments","rephetio","2016-02-20T23:36:08.170Z",17,"# Redundant terms removed from the slim DO

My [above post](#6) on creating the slim DO didn't specify which diseases were removed to ""resolve overlapping nodes"". The table below shows which diseases we removed and why (rules above). The exclusions counts by rule are: 7 for rule 1, 22 for rule 2, and 5 for rule 3.

| ID | Name | Source | Removed by |
|------------|--------------------------------|--------------|------------|
| DOID:201 | Connective tissue cancer | DOcancerslim | rule 1 |
| DOID:10155 | Intestinal cancer | DOcancerslim | rule 1 |
| DOID:5672 | Large intestine cancer | DOcancerslim | rule 1 |
| DOID:3119 | Gastrointestinal system cancer | DOcancerslim | rule 1 |
| DOID:8618 | Oral cavity cancer | DOcancerslim | rule 1 |
| DOID:170 | Endocrine gland cancer | DOcancerslim | rule 1 |
| DOID:3996 | Urinary system cancer | DOcancerslim | rule 1 |
| DOID:3459 | breast carcinoma | hetio | rule 2 |
| DOID:10286 | prostate carcinoma | hetio | rule 2 |
| DOID:1040 | chronic lymphocytic leukemia | hetio | rule 2 |
| DOID:3905 | lung carcinoma | hetio | rule 2 |
| DOID:1909 | melanoma | hetio | rule 2 |
| DOID:4001 | ovarian carcinoma | hetio | rule 2 |
| DOID:1107 | esophageal carcinoma | hetio | rule 2 |
| DOID:4007 | bladder carcinoma | hetio | rule 2 |
| DOID:289 | endometriosis | hetio | rule 2 |
| DOID:4450 | renal cell carcinoma | hetio | rule 2 |
| DOID:769 | neuroblastoma | hetio | rule 2 |
| DOID:8567 | Hodgkin's lymphoma | hetio | rule 2 |
| DOID:3963 | thyroid carcinoma | hetio | rule 2 |
| DOID:9538 | multiple myeloma | hetio | rule 2 |
| DOID:9952 | acute lymphocytic leukemia | hetio | rule 2 |
| DOID:5517 | stomach carcinoma | hetio | rule 2 |
| DOID:684 | hepatocellular carcinoma | hetio | rule 2 |
| DOID:1380 | endometrial cancer | hetio | rule 2 |
| DOID:4905 | pancreatic carcinoma | hetio | rule 2 |
| DOID:4960 | bone marrow cancer | hetio | rule 2 |
| DOID:706 | mature B-cell neoplasm | hetio | rule 2 |
| DOID:8552 | chronic myeloid leukemia | hetio | rule 2 |
| DOID:5844 | myocardial infarction | hetio | rule 3 |
| DOID:6713 | cerebrovascular disease | hetio | rule 3 |
| DOID:11829 | degenerative myopia | hetio | rule 3 |
| DOID:13641 | exfoliation syndrome | hetio | rule 3 |
| DOID:3324 | mood disorder | hetio | rule 3 |

See the [remaining 137 diseases here](https://github.com/dhimmel/disease-ontology/blob/5cb93c38568536222b0a14fbcb7fb644a348931d/data/slim-terms.tsv).","17",2016-02-20,2016-02-20,2,2477,"base.profile","Daniel","Himmelstein","dhimmel"
"662","comments","rephetio","2016-02-22T23:47:56.149Z",17,"# Indication terminology

We've been referred to when a drug treats a disease as an ""[indication](https://en.wikipedia.org/w/index.php?title=Indication_(medicine)&oldid=703054912 ""Wikipedia · Indication (medicine)"")"". While readers with a medical background understand the term, others find ""indication"" confusing. 

Now [we've split our indications](http://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95) into two categories: disease-modifying and symptomatic. Additionally, we've switched to [using verbs](#2) to describe relationships. 

Given these factors, I chose ""treats"" for disease-modifying indications and ""palliates"" for symptomatic indications. This terminology aligns with a recent repurposing study [@10.1038/ncomms10331], which refers to

> distinguishing non-causative and palliative from causative and effective treatments

While readers may not be familiar with the term palliates, it has an applicable and precise [definition](http://www.oxforddictionaries.com/us/definition/american_english/palliate) (making lookup easier):

> Make (a disease or its symptoms) less severe or unpleasant without removing the cause

@pouyakhankhanian, do you think the treats/palliates terminology makes sense?","17",2016-02-22,2016-02-22,2,1282,"base.profile","Daniel","Himmelstein","dhimmel"
"663","comments","rephetio","2016-02-26T17:17:30.858Z",17,"@alessandrodidonna suggested adding RNA interference data, so we [incorporated genetic perturbation relationships](http://thinklab.com/discussion/suggestions-for-additional-information-types/22#6) from LINCS L1000. The L1000 project measures how the expression of 978 genes (called landmark genes) changes in response to perturbation. Here we are focusing on gene knockdown (shRNA) and gene overexpression perturbations.

We [computed consensus transcriptional profiles](http://thinklab.com/discussion/computing-consensus-transcriptional-profiles-for-compounds-using-lincs/43#6) for knockdown ([`pert_type = trt_sh`](http://support.lincscloud.org/hc/en-us/articles/202216073-Perturbation-Types ""lincscloud Perturbation Types"")) and overexpression (`pert_type = trt_oe`) perturbations. For each gene perturbation, we end up with a vector of 978 z-scores representing the change in expression of each landmark gene. Using a Bonferroni cutoff to correct for the 978 comparisons, we identify the significantly upregulated and downregulated genes for each perturbation. Using this approach, we generate four relationship types for our network:

1. Gene → knockdown downregulates → Gene
2. Gene → knockdown upregulates → Gene
3. Gene → overexpression downregulates → Gene
4. Gene → overexpression upregulates → Gene

In a [separate discussion](http://thinklab.com/discussion/data-nomenclature-naming-and-abbreviating-our-network-types/162#3), @larsjuhljensen commented:

> I am not entirely sure how useful the ""knockdown downregulates"" etc. types are. Usually ""knockdown downregulates"" would be interpreted to mean ""upregulates"" etc.

In other words, shouldn't we combine relationship types 1 & 4 above into ""Gene → upregulates → Gene"" and 2 & 3 into ""Gene → downregulates → Gene""? To investigate whether this makes sense, I looked into whether knockdown and overexpression profiles for the same gene were anticorrelated. Does knocking down a gene have the opposite trascriptional effect as overexpressing it?

The results were surprising ([notebook](https://github.com/dhimmel/lincs/blob/00c55f95ead78bec72b9c7255f38b512c4a3da30/binarize-consensi.ipynb)). Knockdown and overexpression of the same gene resulted in positively correlated transcriptional profiles 65.0% of the time. And if we correlate the knockdown of a random gene with the overexpression of a different random gene, we see a positive correlation 65.3% of the time. In summary, the transcriptional profiles of knocking down and overexpressing genes are more often than not positively correlated. And profiles for the same gene show no more correlation or anticorrelation than profiles for two different genes. Hmm.

![Violinplots of correlation distributions](https://github.com/dhimmel/lincs/raw/00c55f95ead78bec72b9c7255f38b512c4a3da30/viz/knockdown-overexpression-corr.png)

What could cause this counterintuitive finding?

+ We could have a mistake in our code. Does anyone know of a gold standard for genetic perturbations that we could compare to?
+ By looking only at the 978 landmark genes, we are overlooking the crucial genes and instead picking up on a general perturbation response.
+ Gene regulation is a non-linear process.
+ Our method of analysis or the LINCS L1000 data may be limitated.

Does anyone, specifically those with gene expression experience (@caseygreene, @larsjuhljensen, @fbastian), have any insight on what might be happening? I'll also reach out to the L1000 team.","17",2016-02-26,2016-02-26,2,3485,"base.profile","Daniel","Himmelstein","dhimmel"
"664","comments","rephetio","2016-02-23T12:59:08.531Z",188,"Re: ""While my original guidance would have been to chose DM or SYM if the drug is DM or SYM for any subtype, I see the point that some diseases may be too broad and therefore uninformative for our prediction approach.""

I actually think either approach is reasonable. The key would be to maintain consistency throughout the curation process. After making a final decision on how to proceed, we can go back and ensure that we are being consistent.

I also think we may want to consider the relative frequency of subtypes of disease. For example, ""lung cancer"" has probably three very common subtypes which each account for 25-30% of the total entity of ""lung cancer"". Similarly, 90-95% of ""Hypertension"" is accounted for by ""essential hypertension"", even if you include ""pulmonary hypertension"". in contrast, most of the subtypes of ""anemia"" included in this curation each account for probably less than 1-2% of all ""anemia"".","188",2016-02-23,2016-02-23,2,928,"base.profile","Pouya","Khankhanian","pouyakhankhanian"
"665","comments","rephetio","2016-02-23T14:43:26.748Z",188,"I certainly agree with maintaining the terminology consistent with prior studies. I think the terms ""indication and ""palliates"" are well defined as you describe. My only concern is the use of the word ""treat"" to mean ""disease-modifying"" as opposed to symptom management, especially since it is very common to use the phrase ""treat symptoms"". 

If there are other prior studies that use alternate terminology, it might be best to align with those. Otherwise, I would think the two goals are (1) maintain previous terminology and (2) make sure to define our terminology very clearly.","188",2016-02-23,2016-02-23,2,583,"base.profile","Pouya","Khankhanian","pouyakhankhanian"
"666","comments","rephetio","2016-02-24T00:15:33.603Z",17,"# Results from all three curators

To recap our curation effort thus far, we first had AJG and CSH (@chrissyhessler) independently classify the 1388 indications. Then a third curator, PK (@pouyakhankhanian), classified each indication with access to the picks and notes from the first two curators.

PK provided [detailed documentation](#7) of his methodology, with a focus on instances of disagreement. I now report of the results from all three curators ([notebook](https://github.com/dhimmel/indications/blob/49cf8e3858f124e552051fc1e8c1c229a43dadf6/curation/results-three-curators.ipynb), [dataset](https://github.com/dhimmel/indications/blob/49cf8e3858f124e552051fc1e8c1c229a43dadf6/curation/results-three-curators.tsv)).

PK's kappa coefficient was 51.5% with AJG and 65.1% with CSH. PK classified many indications as disease-modifying that the other curators considered symptomatic. Overall, there were [34 threeway disagreements](https://github.com/dhimmel/indications/blob/49cf8e3858f124e552051fc1e8c1c229a43dadf6/curation/results-threeway-disagreements.tsv) and [124 instances](https://github.com/dhimmel/indications/blob/49cf8e3858f124e552051fc1e8c1c229a43dadf6/curation/results-PK-changes.tsv) where PK disagreed with the consensus of the first two curators.

# Reaching a consensus

The next step is to agree upon a consensus classification for each indication. These indications will go into our network and will be used to train our model for predicting drug repurposing.

We would like the first two curators to review [PK's methodology](#7) and voice their opinions. In particular, do AJG and CSH agree with PK's reasoning that led him to reverse [124 instances where they agreed](https://github.com/dhimmel/indications/blob/49cf8e3858f124e552051fc1e8c1c229a43dadf6/curation/results-PK-changes.tsv)? Given this feedback, we will determine how to proceed.","17",2016-02-24,2016-02-24,2,1883,"base.profile","Daniel","Himmelstein","dhimmel"
"667","comments","rephetio","2016-02-24T01:31:28.304Z",17,"I'm not sure the phrase ""drug X treats symptom Y"" is that problematic, since symptom Y is the sentence's subject rather than a disease. I agree that we should maintain existing terminology, but I'm not finding much guidance in the literature.

Potential alternatives to ""treats"" for representing disease-modifying indications are: modifies, medicates, indicates, remedies, ameliorates, betters, improves, corrects, affects, alleviates, repairs, and cures. @pouyakhankhanian, do you prefer any of these verbs to ""treats""?

And regardless of which term we pick, we'll make sure to define each relationship type.","17",2016-02-24,2016-02-24,2,613,"base.profile","Daniel","Himmelstein","dhimmel"
"668","comments","rephetio","2016-02-25T22:56:18.333Z",17,"We've previously discussed [what hetnet permutation is and why we do it](http://thinklab.com/discussion/permuting-hetnets-and-implementing-randomized-edge-swaps-in-cypher/136#1). To permute a hetnet, we go through each relationship type (metaedge) and repeatedly swap the target nodes of two random relationships (edges). This strategy is called `XSwap` [@10.1137/1.9781611972795.67].

We looked into performing the [permutation in neo4j using cypher](http://thinklab.com/discussion/permuting-hetnets-and-implementing-randomized-edge-swaps-in-cypher/136#2), but decided to stick with our [python implementation](https://github.com/dhimmel/hetio/blob/a6c8a286ec0c7367673970c6ddda06cd47733034/hetio/permute.py#L7 ""hetio.permute.permute_graph · dhimmel/hetio on GitHub"") since cypher's cost planner currently lacks the needed abilities.

## Implementation specifics

We closely followed the parameters from our previous study [@10.1371/journal.pcbi.1004259] and did the following:

+ We created 5 permuted hetnets. The first permutated hetnet was created from the unpermuted hetnet; the second permutated hetnet was created from the first permutated hetnet; and so on until the fifth permutated hetnet was created from the fourth permutated hetnet. This iterative strategy is referred to as a Markov chain.
+ To create each permuted hetnet, we separately permuted each metaedge. For a given metaedge, we attempted _n_ XSwaps where _n_ equals four times the number of edges (`multipler = 4`).
+ Xswaps can be unsuccessful for several reasons. The same edge could have been randomly selected twice (referred to as `same_edge`). One or both of the potential new edges may already exist (`duplicate` or `undirected_duplicate` for select cases where a biderectional edge connects two nodes of the same type). One or both of the potential new edges may connect a node to itself (`self_loop`). In these instances, no swap is performed. In the future, we may switch to stopping a completing permutation after a certain number of successes rather than attempts.

## Assessing permutation effectiveness

For each permutation and each metaedge, we measure the progress of the randomization at 10 points ([dataset](https://github.com/dhimmel/integrate/blob/ebd71cd2157d26e52646b5b483f5c70293a84f71/data/permuted/stats.tsv)). The measure we're primarily interested in is the percent of edges that are unchanged after a permutation (`unchanged`).

We find that the percent of unchanged edges varies by metaedge ([notebook cell 4](http://nbviewer.jupyter.org/github/dhimmel/integrate/blob/ebd71cd2157d26e52646b5b483f5c70293a84f71/data/permuted/evaluate-permutations.ipynb#How-many-permutations-are-needed-to-randomize-an-edge)). It appears that we could safely reduce our multiplier from 4 to 2.5 and still generate permuted networks that are maximally diversified from their predecessor.

Of concern are metaedges where a high percentage of the edges do not change. This occurred when a high percentage of swaps resulted in already existing edges ([notebook cell 6](https://github.com/dhimmel/integrate/blob/ebd71cd2157d26e52646b5b483f5c70293a84f71/data/permuted/evaluate-permutations.ipynb)). Particularly troublesome was the _Anatomy--expresses--Gene_ edge where almost all attempts yielded duplicated edges and only ~10% of edges changed from a permutation. I'm now inclined to revisit our [previous observation](http://thinklab.com/discussion/processing-bgee-for-tissue-specific-gene-presence-and-overunder-expression/124#2) that we're being too permissive regarding expression edge inclusion.

Metaedges whose edges do not change from permutation are limited in informativeness. Such edges hold little information besides their degree contribution to the nodes they connect. In the context of our expression edge, the problem is visible in the node degree distribution: most anatomies express 0 genes while a minority of anatomies express an extremely high number of genes ([see the `anatomy - expresses - gene` panel on page 10](http://nbviewer.jupyter.org/github/dhimmel/integrate/blob/ebd71cd2157d26e52646b5b483f5c70293a84f71/viz/degrees.pdf#page=10)).","17",2016-02-25,2016-02-25,2,4163,"base.profile","Daniel","Himmelstein","dhimmel"
"669","comments","rephetio","2016-02-26T17:26:44.322Z",22,"Quick thoughts: Is there a specific set of genes driving the positive correlation? Maybe perturbations in general lead to some change in, for example, growth rate? What, specifically, is your high correlation measuring? Is it possible that highly expressed genes tend to remain highly expressed, or did you transform the data in some way to normalize gene expression across conditions per gene.","22",2016-02-26,2016-02-26,2,394,"base.profile","Casey","Greene","caseygreene"
"670","comments","rephetio","2016-02-26T17:28:07.784Z",125,"Messing about with cells always tends to induce some degree of stress-induced global expression changes. This is the case pretty much no matter which perturbation you do to the cells, including overexpression of some gene, knockdown of some gene, cell-cycle synchronization, centrifugation, increasing temperature, decreasing temperature, etc.

My guess is that the small positive correlation you see is caused by small changes in expression of a large number of genes, which you could summarize as ""not a happy cell"".","125",2016-02-26,2016-02-26,2,520,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"671","comments","rephetio","2016-02-26T19:53:18.806Z",17,"> Did you transform the data in some way to normalize gene expression across conditions per gene.

@caseygreene, our profiles contain _z_-scores measuring the differential expression for 978 genes. The profiles (called consensus signatures in [L1000 terminology](http://support.lincscloud.org/hc/en-us/articles/202099616-Signature-Generation-and-Analysis-L1000-)) are at the CONSENSUS stage in the following pipeline:

![Processing of Broad LINCS data](http://support.lincscloud.org/hc/en-us/article_attachments/200733106/data_flow.png)

The _z_-scores compare a gene's expression level in cells given the perturbation to cells without the perturbation (controls). I believe the controls account for the non-specific disturbances caused by delivering the molecular payload, but will confirm.

Now I will look into the following questions:

+ @larsjuhljensen: My guess is that the small positive correlation you see is caused by small changes in expression of a large number of genes.
+ @caseygreene: Is there a specific set of genes driving the positive correlation?","17",2016-02-26,2016-02-26,2,1077,"base.profile","Daniel","Himmelstein","dhimmel"
"672","comments","rephetio","2016-03-01T19:30:53.637Z",17,"# Methods for reducing the number of Bgee expression relationships

@fbastian, we're looking to reduce the number of expression relationships extracted from Bgee. Our motivation is twofold:

1. Our hetnet [currently contains](https://github.com/dhimmel/integrate/blob/dff453c020bbea953adc6cc3225235e445ba94f9/data/summary/metaedges.tsv#L3 ""hetio-ind metaedge summaries"") over 1 million _Anatomy--expresses--Gene_ relationships. This high number of relationships is causing computational bottlenecks.
2. Our network permutations [do little to randomize the expression relationships](http://thinklab.com/discussion/assessing-the-effectiveness-of-our-hetnet-permutations/178#1). In other words, too many expression relationships connect super anatomies -- anatomies which express most genes -- limiting the information content of the edge.

From our previous conversations, it appears that there are three ways to proceed:

1. Exclude relationships for general anatomies, as [suggested above](#3).
2. Use only RNA-Seq experiments. @fbastian [mentions](http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#5) that using only RNA-Seq data avoids the ambiguity states. So what happens when a gene is present in one experiment but not the other for the same data type and conditions? With RNA-seq we should be able to adjust the RPKM inclusion threshold.
3. Use unpropagated relationships, so for example genes expressed in for brain gray matter would not automatically be transmitted to brain.

These options are not mutually exclusive. We can choose any combination of the three.

I am leaning towards option 3, because I think studies will often be performed on clinically relevant anatomies. In other words, we may accomplish the goal of 1 (removing overly broad anatomies) by including only relationships to their directly annotated anatomies. Additionally, since our hetnet contains [many nested levels Uberon terms](http://thinklab.com/discussion/tissue-node/41#16),  we would not be throwing out too many experiments entirely. In the future, we can even write queries that perform the propagation in realtime.

**Data complications:** In `Homo_sapiens_expr-complete.tsv` version 13.1, all the values for `In situ call quality` and `In situ call quality` equal `no data`. Additionally, all values for `Including in situ observed data` are `no`. @fbastian, I assume this is a bug? Is there a workaround? Advice on the specific filters to apply on which files to achieve options 2 or 3 would be appreciated.","17",2016-03-01,2016-03-01,2,2545,"base.profile","Daniel","Himmelstein","dhimmel"
"673","comments","rephetio","2016-03-02T16:49:17.802Z",172,"Very thorough analysis by Pouya. I agree with the slight change in the definitions of categories. One clarification: is a drug still considered disease modifying if there are significant and dangerous side effects? amendment 1 seems to indicate that the answer is yes.
 
For the most part, I agree with how you classified the following. I have made some comments for the particularly challenging disease categories:

+ **hypertension, general**
+ **hypertension, diuretics**
+ **hypertension, ocular and pulmonary htn**
+ **diabetes, drugs that lower blood sugar**
+ **diabetes, ACEi and ARBs**
+ **epilepsy**: I think I agree with categorizing all AEDs as DM instead of SYM. I thought the pathophysiology behind MTS was not clearcut and treating someone with AEDs does not necessarily prevent MTS, although I think it may prevent morbidity and mortality.
+ **OA, NSAIDs and steroids**
+ **cancers, pain meds**
+ **hematologic cancers, steroids**
+ **non-heme cancers, steroids**
+ **cancers, hydroxyura and other chemotx**
+ **cancers, bisphos**
+ **CAD, drugs for htn or dm**
+ **CAD, diuretics**
+ **migraine**: I think prophylactic medications should be DM; abortives may be better classified as SYM
+ **asthma, steroids, beta gonists, antichol**
+ **allergic rhinitis**: this categorization makes sense to me.
+ **COPD, general**
+ **etoh dependence**
+ **psych disease**
+ **AD**
+ **anemia**: I agree. It is like trying to categorize ""leukocytosis"" or some other lab abnormality, without getting at the etiology.

I am still stuck on one disease entity:

+ **Autoimmune diseases, steroids**: do steroids actually change the long-term disease of autoimmune diseases? Do they reduce morbidity and mortality?","172",2016-03-02,2016-03-02,2,1741,"base.profile","Chrissy","Hessler","chrissyhessler"
"674","comments","rephetio","2016-03-03T00:50:58.434Z",17,"# Initial release of STARGEO analyses

We've released the first complete version of our STARGEO analysis ([repository](https://github.com/dhimmel/stargeo) [@10.5281/zenodo.46866]). Thanks @idrdex for helping us get all of the queries [running smoothly](https://github.com/idrdex/star_api/issues/13#issuecomment-191414422).

In summary, we defined case-control queries for [66 diseases](https://github.com/dhimmel/stargeo/blob/1a11633b5e0095454453335be82012a9f0f482e4/data/queries.tsv). Of these diseases, 49 contained sufficient data (multiple studies with at least 3 samples per class). We used STARGEO's random effects meta-analysis and applied an FDR _p_-value threshold of 0.05 to identify deferentially expressed genes for each disease. 

48,688 _Disease--downregulates--Gene_ and 50,287 _Disease--upregulates--Gene_ relationships were identified ([dataset](https://github.com/dhimmel/stargeo/blob/1a11633b5e0095454453335be82012a9f0f482e4/data/diffex.tsv)). The number of dysregulated genes [varied widely](https://github.com/dhimmel/stargeo/blob/1a11633b5e0095454453335be82012a9f0f482e4/data/summary.tsv) by disease. No deferentially expressed genes were identified for endogenous depression, which had a combined sample size of [533 cases and controls](https://github.com/dhimmel/stargeo/blob/1a11633b5e0095454453335be82012a9f0f482e4/data/doslim/DOID_1595/samples.tsv).

Now we will integrate these relationships into our hetnet. We may choose to limit each disease to the 500 most significantly up and 500 most significantly down-regulated genes.","17",2016-03-03,2016-03-03,2,1562,"base.profile","Daniel","Himmelstein","dhimmel"
"675","comments","rephetio","2016-03-03T01:18:31.088Z",188,"- **Re: Autoimmune diseases and steroids**. I do believe that steroids are DM in a variety of auto-immune diseases. The easiest examples are Lupus and RA where the occasional difficult-to-control patient is given low-dose maintenance steroids to prevent disease flares (i.e. reduce morbidity). Tougher examples include MS but there is some evidence that it may help decrease disease activity and relapse rate [@10.1212/wnl.57.7.1239], which puts it is a similar category to say Copaxone which we would probably mark as DM (even though copaxone also does not delay progression of disease). Given that, I felt it was reasonable to assume the same for other auto-immune diseases, although I must admit I'm probably under-qualified to comment on the subtleties of this (perhaps we can curb-side a rheumatologist). I fully agree that there is a high side-effect burden and chronic steroids are probably not clinically indicated for treatment, but perhaps they should still DM for the purposes of this study. I think of it like this, if Daniel's analysis could suggest a drug because it acted on some of the same molecular targets as do steroids, but that drug had zero side effects, then would that drug be of interest in treating auto-immune diseases? If yes, then I think we should classify steroids as DM.

- **Re: epilepsy**. Good point that AEDs prevent morbidity and mortality, it's clearly better than my hand-waving and highly disputed MTS argument. Additionally, I think we should consider the same argument as above, if Daniel's network were to find a drug that acts on the same molecular targets as our AEDs, then would we consider that drug when treating epilepsy? I would think yes.

- **Re: migraine**. I wholly agree with what you wrote. I think I just didn't state it as clearly as you did.","188",2016-03-03,2016-03-03,2,1805,"base.profile","Pouya","Khankhanian","pouyakhankhanian"
"676","comments","rephetio","2016-03-03T17:50:32.818Z",111,"For me, the two working solutions would either be:  

* ""3. Use unpropagated relationships"": actually, you would still use the propagated data, but you would consider only the anatomical structures described in the experiments. This is what our ""simple"" expression file contains.
* or manually select a list of 50-100 anatomical structures you are interested in, and use the propagated data in them. Maybe you can also include all cell types. This is very similar to the previous solution, except that you'd have more freedom about the choice of the organs. Although you should already have lots of organs experimentally described once we include the GTEx data (see bottom of this message), so the previous solution might be good enough.

""2. Use only RNA-Seq experiments"" is incorrect: you'll still get the ambiguity states if two libraries provide contradicting information. And, it would be sad not to use other data types – lots of good information come from Affymetrix data.
And adjusting the RPKM threshold will not solve your problem: your problem comes from the propagation of data to upper level terms.

To implement solution ""3"", you can either use our ""simple"" expression file, or use the ""complete"" file, but filter thanks to the column ""Observed data"": http://bgee.org/?page=doc&action=call_files#single_expr_complete_col9

Otherwise, we can think of alternative solutions: 

* Using only over-/under-expression data. We should have a lot of them thanks to the GTEx data in the near future
* Using only the best-ranked anatomical structures for each gene, rather than all data, and do the propagation based on that (e.g., in TISSUES the anatomical structures are ranked – we are going to release a gene page next week also providing ranked anatomical structures). 
* Using a completely different approach, based on gene lists rather than individual genes: see our new GO-like expression enrichment test: http://bgee.org/?page=top_anat. I don't know if it can be applied to your network, though, but maybe you can link groups of genes to anatomical structures, rather than individual genes.


**About in situ data:** we don't have in situ data for human. I don't know of any resource providing systematic gene expression analyses in human using in situ hybridization. This data type is not well suited for human (e.g., I think you're not supposed to use frozen tissues). 

**Additional information:** we have started the pipeline for Bgee 14, that will include the GTEx data. The full pipeline run should take a few months, but you'll get the data ultimately. Also, I'll let you know about the status of our work of re-annotation in the other thread, as we have completed it.","111",2016-03-03,2016-03-03,2,2706,"base.profile","Frederic","Bastian","fbastian"
"677","comments","rephetio","2016-03-04T01:41:27.690Z",17,"## Clarification

Let's see if I understand: It is not possible to tell whether gene presence for a specific condition (anatomy--developmental stage) was from an experiment on that exact condition or was propagated. However, the simple file (or complete file filtered for `Observed data`) contains only conditions with directly annotated experiments, but any given gene presence call may be from propagation.

## Proposed gene presence method

I think the ideal setup for our network would be *propagation by developmental stage but not by anatomical structure*. Using just the simple or complete datasets, this doesn't currently seem to be possible. However, I've what about the following workaround: using all adult stages on the simple dataset.

Using the simple dataset, I found all gene--anatomy pairs where `Expression` is `present` and `Call quality` is `high quality` for any adult developmental stage. To identify adult developmental stages, I filtered for `HsapDv:0000087` and its descendants ([notebook](https://github.com/dhimmel/bgee/blob/5cfed945305d7ec118fe79a1486c28d6a97ee8ee/developmental-stages.ipynb), [dataset](https://github.com/dhimmel/bgee/blob/5cfed945305d7ec118fe79a1486c28d6a97ee8ee/data/stages.tsv#L76)).

The resulting presence/absence matrix of gene expression is 16,257 genes × 188 anatomies  ([notebook](https://github.com/dhimmel/bgee/blob/5cfed945305d7ec118fe79a1486c28d6a97ee8ee/bgee.ipynb), [dataset](https://github.com/dhimmel/bgee/blob/5cfed945305d7ec118fe79a1486c28d6a97ee8ee/data/present-in-adult.tsv.gz)) compared to the [previous dimensions](http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#8) of 16,278 genes × 666 anatomies. We hope that this pruning of anatomies will help address the network problems we [were facing](#4).

## Miscellaneous

Thanks @fbastian for suggesting other possible approaches. For future networks, we will revisit these options. For now we're looking for the most straightforward and immediately actionable option.

> We don't have in situ data for human. I don't know of any resource providing systematic gene expression analyses in human using in situ hybridization.

I had misinterpreted `Including in situ observed data` to mean `Observed data`","17",2016-03-04,2016-03-04,2,2263,"base.profile","Daniel","Himmelstein","dhimmel"
"678","comments","rephetio","2016-03-04T13:08:49.847Z",111,">  the simple file (or complete file filtered for Observed data) contains only conditions with directly annotated experiments, but any given gene presence call may be from propagation.

No, you have the guarantee that there exists an unpropagated call for that very gene. What you can't know for sure from these files, is where the quality level comes from. For instance: 

    gene A expressed in brain with low quality from experiment A
    gene A expressed in brain substructure with high quality from experiment B
    => gene A expressed in brain with high quality in Bgee files

Or 

    gene A NOT expressed in brain from RNA-Seq experiment A
    gene A expressed in brain substructure from Affymetrix experiment B
    => gene A with lowly conflicting status in brain substructure, in Bgee files 


Data in adult for human must represent 90% of the data, so you shouldn't add much by considering all developmental stages. 

If you want, I can provide you with a completely unpropagated dataset. But I think it's good to benefit from propagation (e.g., to determine that 2 genes are both expressed in brain, which you might miss if they were expressed in different brain substructures). 

> I had misinterpreted `Including in situ observed data` to mean `Observed data`

I see, we should rename these fields with `in situ hybridization` then.","111",2016-03-04,2016-03-04,2,1368,"base.profile","Frederic","Bastian","fbastian"
"679","comments","rephetio","2016-03-07T23:55:51.378Z",17,"# Concensus signatures version 2.0

We've released `v2.0` of our analysis of LINCS L1000. This release brings major updates including:

+ **Inferred genes**. [Previously](#6), dysregulation scores were only reported for the 978 landmark (directly measured) genes. Now we've expanded our analysis to include 6,489 imputed genes from the best inferred gene set (`is_bing`), which covers genes imputed with high accuracy. However, we've maintained backwards compatibility by only using landmark probes for signature weighting.
+ **Significantly dysregulated genes**. We now report significantly down or upregulated perturbagen--gene pairs.
+ **Improved knockdown and overexpression pipeline**. We now convert gene symbols to entrez genes at the earliest stage. Now two genetic perturbations with different symbols that map to the same entrez gene will benefit from [_z_-score meta-analysis](#5).

## Consensus signature datasets

Our consensus signatures are available on [GitHub](https://github.com/dhimmel/lincs/tree/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi) [@10.5281/zenodo.47223] and [figshare](https://doi.org/10.6084/m9.figshare.3085426 ""Consensus signatures for LINCS L1000 perturbations · figshare data deposition"") [@10.6084/m9.figshare.3085426]. Each consensus signature measures the transcriptional response to a perturbation at [7,467 genes](https://github.com/dhimmel/lincs/blob/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/genes.tsv). Genes are identified by their Entrez GeneID. Consensi are produced for:

+ **DrugBank compounds** -- 1,170 small molecule compounds identified by their DrugBank ID. L1000 compounds were mapped to DrugBank [using atomic connectivity](http://thinklab.com/discussion/unichem-mapping-to-lincs-small-molecules/51#8).
+ **Gene knockdowns** -- 4,326 knocked-down genes identified by their Entrez GeneID.
+ **Gene overexpressions** -- 2,413 overexpressed genes identified by their Entrez GeneID
+ **All L1000 pertubations** -- 38,327 perturbagens identified by their L1000 `pert_id`.

## Methodology

To recap our methodology, our objective is to compute a consensus signature from multiple input signatures. Each input signature measures the dysregulation caused by a specific perturbation and condition. The purpose of computing consensi is to combine signatures for the same perturbation under different conditions (for examples different dosages, cell types, or time points). 

Our method, developed in consultation with the L1000 team, arrives at a consensus signature from a set of input signatures by:

A) Starting with a probe × signature matrix of dysregulation _z_-scores with the following filters:

+ **Initial probe filter**: include all landmark or `is_bing` probes with the following exclusions: a) inferred probes for genes with a landmark probe. b) probes with non-existent Entrez GeneIDs.
+ **Initial signature filter**: use only [gold signatures](#3) to remove non-replicating or indistinct signatures

B) Then a gene-level consensus signature is computed by:

1. Calculating an input signature weight. Each input signature gets a weight equal to its average Spearman's correlation with other input signatures. We set a minimum correlation value of 0.05 to ensure all signatures make at least a small contribution and to prevent negative weights. Weights are computed using only landmark probes.
2. [Meta-analyzing _z_-scores](#5) with Stouffer's method to compute a probe-level consensus signature.
3. Condensing to a gene-level consensus by averaging probe _z_-scores for the same entrez gene.

C) Finally, significant _Perturbagen--regulates--Gene_ relationships are extracted for a given perturbation by:

1. Converting gene _z_-scores to _p_-values by via a normal distribution
2. Correcting p-values for multiple testing using a Bonferroni adjustment. The correction is applied separately to measured genes and inferred genes. Hence, inferred genes are more heavily penalized for multiple testing.
3. Filter genes for corrected _p_-value ≤ 0.05.
4. Allowing at most 1000 significant inferred genes. In cases with more than 1000 significant inferred genes, filter to the 1000 smallest _p_-values.

The methods described above are executed in the [`consensi.ipynb`](https://github.com/dhimmel/lincs/blob/abcb12f942f93e3ee839e5e3593f930df2c56845/consensi.ipynb) and [`significance.ipynb`](https://github.com/dhimmel/lincs/blob/abcb12f942f93e3ee839e5e3593f930df2c56845/significance.ipynb) notebooks.","17",2016-03-07,2016-03-07,2,4524,"base.profile","Daniel","Himmelstein","dhimmel"
"680","comments","rephetio","2016-03-07T23:26:38.528Z",17,"# Method for mapping L1000 compounds to external vocabularies

We chose to map LINCS L1000 compounds to external vocabularies by querying UniChem with the InChIKey of each L1000 compound (strategy 2 [above](#2)). This approach enabled us to map L1000 compounds not only to DrugBank, but also to the other vocabularies covered by UniChem.

The InChIKey for each L1000 compound was retrieved from the [L1000 API](http://api.lincscloud.org/a2/docs/pertinfo ""L1000 pertinfo API"") ([notebook](https://github.com/dhimmel/lincs/blob/093dc3a0497028ad2b9549a3f9fa12f8ce38461f/api.ipynb ""api.ipynb in the dhimmel/lincs GitHub repository"")). Only perturbations with `pert_type == 'trt_cp'` and a non-null `inchi_key` were mapped. We queried the [UniChem API](https://www.ebi.ac.uk/unichem/info/widesearchInfo ""Connectivity Search Documentation"") for each L1000 InChIKey to retrieve matches ([notebook](https://github.com/dhimmel/lincs/blob/093dc3a0497028ad2b9549a3f9fa12f8ce38461f/unichem.ipynb ""unichem.ipynb in the dhimmel/lincs GitHub repository"")).

We used the same UniChem Connectivity Search parameters that we [used for mapping DrugBank](http://thinklab.com/discussion/unifying-drug-vocabularies/40#5). Our search permissively matches compounds by atomic structure, ignoring small molecular details [@10.1186/s13321-014-0043-5]. We store all the UniChem output in our SQLite database (`l1000.db` [@10.6084/m9.figshare.3085837.v1], `unichem` table), so users could later choose more restrictive parameters without having to requery UniChem.","17",2016-03-07,2016-03-07,2,1542,"base.profile","Daniel","Himmelstein","dhimmel"
"681","comments","rephetio","2016-03-08T02:21:02.188Z",17,"# Releasing `dhimmel/bgee v1.0`

We've released [version 1.0](https://github.com/dhimmel/bgee/tree/08ba54e83ee8e28dec22b4351d29e23f1d034d30 ""GitHub repository"") of our Bgee processing [@10.5281/zenodo.47157].

## Datasets

Genes are identified with Entrez GeneIDs and anatomical structures (anatomies) are identified by Cell Ontology or Uberon terms.

+ [`present-in-adult.tsv.gz`](https://github.com/dhimmel/bgee/blob/08ba54e83ee8e28dec22b4351d29e23f1d034d30/data/present-in-adult.tsv.gz) indicates whether a gene is present (`1`) or absent (`0`) for a given anatomy in human adults. The dataset is a matrix of 16,257 genes × 188 anatomies.
+ [`diffex.tsv.gz`](https://github.com/dhimmel/bgee/blob/08ba54e83ee8e28dec22b4351d29e23f1d034d30/data/diffex.tsv.gz) indicates whether a gene is over-expressed (`1`), under-expressed (`-1`), or non-deferentially expressed (`0`) for a given anatomy. The dataset is a matrix of 18,620 genes × 98 anatomies.

## Changelog

Compared to [version 0](http://thinklab.com/discussion/tissue-specific-gene-expression-resources/81#8) -- the Bgee data in the [initial version](http://thinklab.com/discussion/one-network-to-rule-them-all/102) of our hetnet -- the following change was made:

+ We adopted the modification [proposed above](#6): gene presence was extracted from the simple Bgee dataset, which [guarantees](#6) that each _Anatomy--expresses--Gene_ relationship contains direct (unpropagated) experimental data.","17",2016-03-08,2016-03-08,2,1469,"base.profile","Daniel","Himmelstein","dhimmel"
"682","comments","rephetio","2016-03-08T20:48:53.558Z",17,"Today, I'm teaching a workshop for the [Systems Pharmacology](http://coursecatalog.ucsf.edu/course/1266 ""Pharmacogenomics 245B · UCSF Registrar"") course at UCSF. The course primarily consists of first year students in the [Pharmaceutical Sciences and Pharmacogenomics](http://pspg.ucsf.edu/ ""PSPG PhD Program at UCSF"") graduate program.

The topic of my workshop is ""Big data"". Therefore, I thought a perfect activity would be to analyze the transcriptional perturbation data from [LINCS L1000](http://www.lincscloud.org/l1000/ ""Gene Expression Data · L1000 · Broad Institute""). And stars have aligned: first, we've [just released](http://thinklab.com/discussion/computing-consensus-transcriptional-profiles-for-lincs-l1000-perturbations/43#7) version 2 of our consensus signatures; second, we recently noticed some [counterintuitive occurrences](http://thinklab.com/discussion/positive-correlations-between-knockdown-and-overexpression-profiles-from-lincs-l1000/171) in the genetic perturbation data. 

Hence, I've designed a set of questions. Each pupil will be assigned a question. The pupils will then use R to attempt to answer the question. At the end of the three hour workshop, we will encourage pupils to post their findings as a comment on this discussion.

I'm hoping to teach my [R best practices](http://thinklab.com/discussion/r-best-practices/83) as well as introduce several packages for modern data science. We will strive for the following workflow in R (not every step is needed for each question):

1. Read the appropriate file into a dataframe using [`readr`](https://github.com/hadley/readr). The `readr::read_tsv()` function should come in handy. Datasets are [available on GitHub](https://github.com/dhimmel/lincs/tree/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi) (`readr` should be able to read from the raw dataset URL).
2. Tidy the dataframe using [`tidyr`](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html). The `tidyr::spread()` function will help convert the wide (matrix) format to a long format.
3. Manipulate the dataframe using [`dplyr`](https://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html). Common operations here will be `dplyr::filter` and `dplyr::mutate`.
4. Join dataframes using `dplyr::inner_join()` or `dplyr::left_join()`. 
5. Answer the question, either by using `dplyr::group_by()` followed by `dplyr::summarize()` or by using [`ggplot2`](http://docs.ggplot2.org/) to visualize the results.

Questions will follow!","17",2016-03-08,2016-03-08,2,2526,"base.profile","Daniel","Himmelstein","dhimmel"
"683","comments","rephetio","2016-03-08T21:50:14.240Z",17,"# Datasets

The [above questions](#2) can all be answered using the following three datasets.

### Gene information [`genes.tsv`](https://github.com/dhimmel/lincs/blob/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/genes.tsv)

This dataset contains which genes have regulation scores. It also contains whether the gene's expression was directly measured or imputed. The raw dataset is available at:

```
https://github.com/dhimmel/lincs/raw/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/genes.tsv
```

Below is a preview:

| entrez_gene_id | status | symbol | type_of_gene | description |
|----------------|---------|--------|----------------|----------------------|
| 100 | imputed | ADA | protein-coding | adenosine deaminase |
| 1000 | imputed | CDH2 | protein-coding | cadherin 2, type 1, N-cadherin (neuronal) |
| 10000 | imputed | AKT3 | protein-coding | v-akt murine thymoma viral oncogene homolog 3 |

### Genes dysregulated by knockdowns [`dysreg-knockdown.tsv`](https://github.com/dhimmel/lincs/blob/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/signif/dysreg-knockdown.tsv)

This dataset contains significantly dysregulated genes due to knockdown perturbations. The raw dataset is available at:

```
https://github.com/dhimmel/lincs/raw/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/signif/dysreg-knockdown.tsv
```

Below is a preview:

| perturbagen | entrez_gene_id | z_score | symbol | status | direction | nlog10_bonferroni_pval |
|-------------|----------------|---------|---------|----------|-----------|------------------------|
| 2 | 133 | -5.495 | ADM | imputed | down | 3.596 |
| 2 | 501 | -4.317 | ALDH7A1 | measured | down | 1.811 |
| 2 | 9915 | -5.579 | ARNT2 | measured | down | 4.626 |

### Genes dysregulated by overexpressions [`dysreg-overexpression.tsv`](https://github.com/dhimmel/lincs/blob/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/signif/dysreg-overexpression.tsv)

This dataset contains significantly dysregulated genes due to overexpression perturbations. The raw dataset is available at:

```
https://github.com/dhimmel/lincs/raw/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/signif/dysreg-overexpression.tsv
```

Below is a preview:

| perturbagen | entrez_gene_id | z_score | symbol | status | direction | nlog10_bonferroni_pval |
|-------------|----------------|---------|--------|----------|-----------|------------------------|
| 2 | 991 | -4.687 | CDC20 | measured | down | 2.567 |
| 2 | 54438 | 4.551 | GFOD1 | measured | up | 2.282 |
| 2 | 5950 | 4.590 | RBP4 | imputed | up | 1.541 |","17",2016-03-08,2016-03-08,2,2636,"base.profile","Daniel","Himmelstein","dhimmel"
"684","comments","rephetio","2016-03-08T21:30:42.249Z",17,"# Questions

Here are the 13 questions for the workshop. They all focus on understanding the transcriptional response to genetic perturbation.

1. How many knockdowns significantly downregulated their target gene (expected)? How many knockdowns significantly upregulated their target gene (unexpected)?

2. How many overexpressions significantly upregulated their target gene (expected)? How many overexpressions significantly downregulated their target gene (unexpected)?

3. How many genes were never significantly dysregulated by any knockdown perturbation? Report this number for both the measured and inferred gene sets.

4. How many genes were never significantly dysregulated by any knockdown perturbation? Report this number for both the measured and inferred gene sets. (**same as 3 by accident**)

5. Which ten genes were most frequently significantly downregulated by gene knockdowns? How many knockdowns significantly downregulated these genes? How many knockdowns significantly upregulated these genes?

6. Which ten genes were most frequently significantly upregulated by gene knockdowns? How many knockdowns significantly upregulated these genes? How many knockdowns significantly downregulated these genes?

7. Which ten genes were most frequently significantly downregulated by gene overexpression? How many overexpressions significantly downregulated these genes? How many overexpressions significantly upregulated these genes?

8. Which ten genes were most frequently significantly upregulated by gene overexpression? How many overexpressions significantly upregulated these genes? How many overexpressions significantly downregulated these genes?

9. For knockdown perturbations, what is the correlation between number of significantly down and upregulated measured genes.

Dataset documentation will follow.","17",2016-03-08,2016-03-08,2,1850,"base.profile","Daniel","Himmelstein","dhimmel"
"685","comments","rephetio","2016-03-08T22:59:21.544Z",203,"# Question 2

I answered:

> How many overexpressions significantly upregulated their target gene (expected)? How many overexpressions significantly downregulated their target gene (unexpected)?

R code: 
```R
# workshop with dan himmelstein

# which genes have regulation scores. It also contains whether the gene's expression was directly measured or imputed

path <- 'https://github.com/dhimmel/lincs/raw/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/genes.tsv'
gene_df <- readr::read_tsv(path)

# significantly dysregulated genes due to knockdown perturbations

path2 <- 'https://github.com/dhimmel/lincs/raw/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/signif/dysreg-knockdown.tsv'
kd_df <- readr::read_tsv(path2)

# significantly dysregulated genes due to overexpression perturbations

path3 <- 'https://github.com/dhimmel/lincs/raw/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/signif/dysreg-overexpression.tsv'
oe_df <- readr::read_tsv(path3)

dat <- filter(oe_df, perturbagen == entrez_gene_id)

dat %>%
  dplyr::group_by(direction) %>%
  dplyr::summarize(
    count = n()
  )
```

R output: 
```R
Source: local data frame [2 x 2]

  direction count
      (chr) (int)
1      down     4
2        up   124
/
```

So, 4 genes were significantly downregulated after being overexpressed (unexpected) and 124 genes were significantly upregulated after being overexpressed (expected). 

Thanks Dan!","203",2016-03-08,2016-03-08,2,1475,"base.profile","Kathleen","Keough","kathleenk"
"686","comments","rephetio","2016-03-08T23:45:28.542Z",205,"For question 3,

> How many genes were never significantly dysregulated by any knockdown perturbation? Report this number for both the measured and inferred gene sets.

The elegant dplyr solution (thanks Daniel) looks like:

```r
#how many times are genes disregulated in all?
count_df = knockdown_df %>%
  dplyr::group_by(entrez_gene_id) %>%
  dplyr::summarise(count=n())

#join the table of counts with the full table of genes. the genes that were not present
#are automatically converted to missing data
full=gene_df %>% 
  dplyr::left_join(count_df)

#divide the missing data by imputed vs. measured
result = full %>% dplyr::filter(is.na(count)) %>% 
  dplyr::group_by(status) %>% 
  dplyr::summarise(count=n())
```

The solution: of all the genes, very few avoid disregulation!

```
    status count
     (chr) (int)
1  imputed    55
2 measured     1
```","205",2016-03-08,2016-03-08,2,889,"base.profile","Misha","Vysotskiy","mishavysotskiy"
"687","comments","rephetio","2016-03-08T23:56:35.270Z",206,"# Question 1

>How many knockdowns significantly downregulated their target gene (expected)? How many knockdowns significantly upregulated their target gene (unexpected)?

Here is the Code :)

```r
path = 'https://github.com/dhimmel/lincs/raw/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/signif/dysreg-knockdown.tsv'
gene_kd = readr::read_tsv(path)

gene_kd %>%
  dplyr::filter(perturbagen == entrez_gene_id) %>%
  dplyr::group_by(direction) %>%
  dplyr::summarize(
    count = n()
  )

```

Output:

```
  direction count
      (chr) (int)
1      down   806
2        up     9
```

**Conclusion:** Of the knockdown genes, 806 significantly downregulated their gene (expected) while 9 upregulated their gene (unexpected)","206",2016-03-08,2016-03-08,2,757,"base.profile","Jeffrey","Kim","jeffreykim"
"688","comments","rephetio","2016-03-09T00:01:36.493Z",204,"## Question 6
    knock_down_path =    ""https://github.com/dhimmel/lincs/raw/abcb12f942f93e3ee839e5e3593f930df2c56845/data/con    sensi/signif/dysreg-knockdown.tsv""
    kd_genes = readr::read_tsv(knock_down_path)
    kd_genes$direction = as.factor(kd_genes$direction)

    kd_genes %>%
      group_by(symbol, direction) %>%
      dplyr::summarise(count=n()) %>%
      tidyr::spread(key = direction, value = count, fill = 0) %>%
      arrange(desc(up)) %>% top_n(n = 10, wt = desc(up))

## Resulting Table
| symbol   | down | up   |
|----------|------|------|
| MCOLN1   | 2    | 1128 |
| MAL      | 0    | 985  |
| WIF1     | 0    | 884  |
| SERPINA3 | 0    | 873  |
| SATB1    | 0    | 862  |
| CES1     | 0    | 849  |
| XIST     | 30   | 764  |
| CRIP1    | 0    | 713  |
| KLHL21   | 2    | 602  |
| COL11A1  | 0    | 562  |
| TF       | 0    | 527  |
| ERAP2    | 0    | 512  |
| ABCC5    | 3    | 501  |
| AGR2     | 2    | 478  |
| CPVL     | 1    | 476  |

## Notes
These are the top 10 most unregulated genes. These up-regulated genes do not appear to be down-regulated with any significant frequency","204",2016-03-09,2016-03-09,2,1140,"base.profile","Beau","Norgeot","beaunorgeot"
"689","comments","rephetio","2016-03-09T00:09:28.230Z",208,"# Question 5

> Which ten genes were most frequently significantly downregulated by gene knockdowns? How many knockdowns significantly downregulated these genes? How many knockdowns significantly upregulated these genes?

Here's my code:

```r
path=""https://raw.githubusercontent.com/dhimmel/lincs/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/genes.tsv""
path2=""https://raw.githubusercontent.com/dhimmel/lincs/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/signif/dysreg-knockdown.tsv""
path3=""https://raw.githubusercontent.com/dhimmel/lincs/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/signif/dysreg-overexpression.tsv""
gene_df = readr::read_tsv(path)
kd_gene = readr::read_tsv(path2)
oexp_gene= readr::read_tsv(path3)
head(gene_df)
head(kd_gene)
View(kd_gene)
library(dplyr)
library(tidyr)

gene_df %>%
  dplyr::group_by(status) %>%
  dplyr::summarize(
    count=n()
  )

gene_df %>% 
  dplyr::mutate(kind='gene')

#which 10 genes were most frequently dowregulated by KDs

#first, find number of distinct genes downregulated by KDs (7411)
kd_gene$entrez_gene_id %>% 
  n_distinct()
#next, find number of pertubagens (4312)
kd_gene$perturbagen %>% 
  n_distinct()

#from the top 10 genes, how many times were they downregulated? 
#genes most frequently DOWNREGULATED by the KNOCKDOWNS


#filter to only downregulated KDs
downregulated_kds <- kd_gene %>% 
  filter(direction==""down"")
#sort by count to downregulated KDs
downreg_kd_sorted <- downregulated_kds %>%
  dplyr::group_by(symbol) %>%
  dplyr::summarise(
    count=n()
  ) %>%
  dplyr::arrange(desc(count))
head(downreg_kd_sorted, 10)
View(downreg_kd_sorted)

#from the top 10 genes, how many times were they UPREGULATED? 
#genes most frequently UPREGULATED by the KNOCKDOWNS

#filter to only upregulated KDs
upregulated_kds <- kd_gene %>% 
  filter(direction==""up"")
#sort by count to upregulated KDs
upreg_kd_sorted <- upregulated_kds %>%
  dplyr::group_by(symbol) %>%
  dplyr::summarise(
    count=n()
  ) %>%
  dplyr::arrange(desc(count))
head(upreg_kd_sorted, 10)
View(upreg_kd_sorted)


#How many knockdowns downregulated these genes? 195,786
#How many knockdowns upregulated these genes? 132,282
nrow(kd_gene)
kd_gene %>%
  dplyr::group_by(direction) %>%
  dplyr::summarize(
    count=n()
  )

upreg_kd_sorted<- upreg_kd_sorted %>% 
  dplyr::rename(up_count=count)
dim(upreg_kd_sorted)
View(upreg_kd_sorted)

downreg_kd_sorted <-downreg_kd_sorted %>%
  dplyr::rename(down_count=count)
dim(downreg_kd_sorted)

MYANSWER<- dplyr::full_join(downreg_kd_sorted, upreg_kd_sorted)

MYANSWER[is.na(MYANSWER)] = 0
MYANSWER
```

Here's my answer:

| symbol | down_count | up_count |
|--------|------------|----------|
| RPS4Y1 | 1637       | 0        |
| CDC20  | 1456       | 1        |
| PCNA   | 1360       | 0        |
| NME1   | 1182       | 0        |
| MIF    | 1052       | 0        |
| CSRP1  | 1031       | 1        |
| STUB1  | 996        | 10       |
| TIMM9  | 989        | 4        |
| TYMS   | 881        | 0        |
| GDF15  | 866        | 0        |","208",2016-03-09,2016-03-09,2,3154,"base.profile","Julia","Cluceru","juliacluceru"
"690","comments","rephetio","2016-03-09T00:35:44.397Z",209,"# Question 7, 8, and 9

```r
#read in data 
path_genes = 'https://github.com/dhimmel/lincs/raw/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/genes.tsv'
gene_df = readr::read_tsv(path_genes)

path_down = 'https://github.com/dhimmel/lincs/raw/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/signif/dysreg-knockdown.tsv'
down_df = readr::read_tsv(path_down)

path_over = 'https://github.com/dhimmel/lincs/raw/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/signif/dysreg-overexpression.tsv'
over_df = readr::read_tsv(path_over)
```

## Question 7- Emmalyn Chen 

```r
q.7 = over_df %>% subset(z_score < 0) %>% group_by(entrez_gene_id) %>% summarize(count=n()) %>% arrange(-count)
q.7 = q.7[1:10,]
```
a. Which ten genes were most frequently significantly downregulated by gene overexpression? 
```
entrez_gene_id count
            (int) (int)
1            6192   166
2             991   165
3            5111   165
4            5018   122
5             994   105
6           26520   102
7            1738    91
8            9133    86
9            7298    84
10          22827    83

```
b. How many overexpressions significantly downregulated these genes?

```r
q.7.2 = over_df %>% subset(z_score < 0) %>% filter(entrez_gene_id %in% q.7$entrez_gene_id) %>% 
  group_by(perturbagen) %>% summarize(count = n())
```
612 overexpressed genes 

c. How many overexpressions significantly upregulated these genes?

```r
q.7.3 = over_df %>% subset(z_score > 0) %>% filter(entrez_gene_id %in% q.7$entrez_gene_id) %>% 
  group_by(perturbagen) %>% summarize(count = n())
```
4 overexpressed genes

## Question 8 - Liz Levy 

```r
q.8 = over_df %>% subset(z_score > 0) %>% group_by(entrez_gene_id) %>% summarize(count=n()) %>% arrange(-count)
q.8 = q.8[1:10,]
``` 
a. Which ten genes were most frequently significantly upregulated by gene overexpression? 
``` 
entrez_gene_id count
            (int) (int)
1           57192   180
2            5331   152
3           25966   140
4           23378   113
5            4118   104
6            9903    99
7           55008    98
8            1066    96
9            5971    94
10           7503    94
```
b. How many overexpressions significantly upregulated these genes?
```r
q.8.2 = over_df %>% subset(z_score > 0) %>% filter(entrez_gene_id %in% q.8$entrez_gene_id) %>% 
  group_by(perturbagen) %>% summarize(count = n())
```
792 overexpressed genes  

c. How many overexpressions significantly downregulated these genes?
```r
q.8.3 = over_df %>% subset(z_score < 0) %>% filter(entrez_gene_id %in% q.8$entrez_gene_id) %>% 
  group_by(perturbagen) %>% summarize(count = n())
```
14 overexpressed genes 

## Question 9 - Marjorie Imperial 

For knockdown perturbations, what is the correlation between number of significantly down and upregulated measured genes.
```r
q.9.down.reg = down_df %>% subset(z_score < 0) %>% group_by(perturbagen) %>% summarize(count.down.reg = n())
q.9.up.reg = down_df %>% subset(z_score > 0) %>% group_by(perturbagen) %>% summarize(count.up.reg = n())

joined_df = dplyr::full_join(q.9.down.reg, q.9.up.reg)
joined_df[is.na(joined_df)] = 0
```
Pearson correlation, R =0.9371317
```r
cor(joined_df$count.down.reg, joined_df$count.up.reg)
```
Kendall correlation R = 0.732456 
``` r
cor(joined_df$count.down.reg, joined_df$count.up.reg, method = 'kendall')
```","209",2016-03-09,2016-03-09,2,3445,"base.profile","Marjorie","Imperial","marjorieimperial"
"691","comments","rephetio","2016-03-09T00:36:44.588Z",210,"See Question 7 above.","210",2016-03-09,2016-03-09,2,21,"base.profile","Emmalyn","Chen","emmalynchen"
"692","comments","rephetio","2016-03-09T00:38:17.837Z",211,"# Question 4

> How many genes were never significantly dysregulated by any knockdown perturbation? 

```r
library(dplyr)
install.packages(""tidyr"")
library(readr)
library(ggplot2)

path = 'https://github.com/dhimmel/lincs/raw/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/genes.tsv'
path_ko = 'https://github.com/dhimmel/lincs/raw/abcb12f942f93e3ee839e5e3593f930df2c56845/data/consensi/signif/dysreg-knockdown.tsv'
gene_df = readr::read_tsv(path)
gene_ko_df = readr::read_tsv(path_ko)

ghost_df = gene_df[! (gene_df$entrez_gene_id %in% gene_ko_df$entrez_gene_id), ]
nrow(ghost_df)

#for a list of these genes
ghost_df$symbol
```

The number of genes that were not sig dysregulated by knockdown perturbation (on main list of genes, but not on knockdown list of genes) = 56!","211",2016-03-09,2016-03-09,2,803,"base.profile","Jasleen","Sodhi","jasleensodhi"
"693","comments","rephetio","2016-03-09T01:40:45.660Z",213,"See question 8 above.","213",2016-03-09,2016-03-09,2,21,"base.profile","Elizabeth","Levy","elizabethlevy1"
"694","comments","rephetio","2016-03-09T03:23:31.969Z",17,"# Closing remarks

Impressive work!

Each of the nine pupils in attendance answered their question. Most finished within two hours -- despite several having little R experience -- after an initial 30 minute tutorial. The workshop succeeded at introducing a broad range of topics: R, the hadleyverse, transcriptomics, LINCS L1000, markdown, _Thinklab_, and open science.

I enjoyed helping the pupils learn while they performed original and noteworthy analyses. And meanwhile, through the power of realtime open science on _Thinklab_, we're now coauthors on a citeable work [@10.15363/thinklab.d181].

The workshop built off of many developments in scientific education: specifically, solving problems [@10.1038/523272a] in contemporary research [@10.1126/science.1216570] while contributing to the scientific record [@10.1038/521263f].

Next, I'll review the answers to see what we have learned.","17",2016-03-09,2016-03-09,2,905,"base.profile","Daniel","Himmelstein","dhimmel"
"695","comments","rephetio","2016-03-09T04:48:50.298Z",17,"# Workshop conclusions

Here's my analysis of the answers from today's workshop. Thanks again to the pupils for their hard work.

### Do target genes of genetic perturbation respond in the expected direction?

Yes, we established this important control. Knockdown overwhelming downregulated (806 instances) rather than upregulated (9 instances) its target gene ([Q1](#6) by @jeffreykim). Overexpression overwhelming upregulated (124 instances) rather than downregulated (4 instances) its target gene ([Q2](#4) by @kathleenk).

### Are the many genes that never respond to genetic perturbation?

No, we saw that almost all genes were dysregulated by at least one genetic perturbation. Only 0.7% of genes (56 out of 7,467) were never dysregulated by a knockdown ([Q4](#11) by @jasleensodhi). Only 1 of these genes was measured, while the remaining 55 were imputed ([Q3](#5) by @mishavysotskiy). This imbalance makes sense since imputed genes were [subject to](http://thinklab.com/discussion/computing-consensus-transcriptional-profiles-for-lincs-l1000-perturbations/43#70) a more stringent significance threshold. The low number of never-dysregulated genes is a welcome result from a network perspective, where pervasive connectivity is important.

### Which genes are most frequently dysregulated?

Next, we identified which genes were most frequently dysregulated due to a knockdown. _RPS4Y1_ was downregulated by 37.8% (1,637 out of 4,326) of knockdowns ([Q5](#8) by @juliacluceru). _MCOLN1_ was upregulated by 26.1% (1,128 out of 4,326) of knockdowns ([Q6](#7) by @beaunorgeot). The top-ten-most-frequently-downregulated-by-knockdown genes were rarely upregulated by knockdown. The same consistency in direction of dysregulation applied to the top-ten-most-frequently-upregulated genes as well.

Next, we identified which genes were most frequently dysregulated due to overexpression. _RPS4Y1_ was downregulated by 6.9% (166 out of 2,413) of overepressions ([Q7](#12) by @emmalynchen). _MCOLN1_ was upregulated by 7.5% (180 out of 2,413) of overepressions ([Q8](#12) by @elizabethlevy1). Interestingly, _RPS4Y1_ was the most downregulated gene by both knockdown and overexpression. Conversely, _MCOLN1_ was the most upregulated gene for both perturbation types.

The findings from Q5--8 fit with @larsjuhljensen's [hypothesis](http://thinklab.com/discussion/positive-correlations-between-knockdown-and-overexpression-profiles-from-lincs-l1000/171#3) that a general stress response may cause many genes to respond to any genetic perturbation in a consistent direction. Q5--8 also help address @caseygreene's question on [which genes](http://thinklab.com/discussion/positive-correlations-between-knockdown-and-overexpression-profiles-from-lincs-l1000/171#2) are driving the signals.

### Does broad downregulation occur in tandem with broad upregulation?

Finally, there was a strong correlation between the number of downregulated and upregulated genes per knockdown ([Q9](#12) by @marjorieimperial). In other words, a perturbation which downregulates many genes will also likely upregulate many genes.","17",2016-03-09,2016-03-09,2,3125,"base.profile","Daniel","Himmelstein","dhimmel"
"696","comments","rephetio","2016-03-09T18:23:08.023Z",17,"# Update with workshop findings

I recently led a Systems Pharmacology workshop for first-year graduate students. [We analyzed](http://thinklab.com/discussion/workshop-to-analyze-lincs-data-for-the-systems-pharmacology-course-at-ucsf/181) the L1000 genetic perturbation data with the goal of shedding light on the issues in this discussion. The workshop was based on significant dysregulation due to knockdown or overexpression from [`dhimmel/lincs v2.0`](http://thinklab.com/discussion/computing-consensus-transcriptional-profiles-for-lincs-l1000-perturbations/43#7) [@10.5281/zenodo.47223 @10.6084/m9.figshare.3085426]. Compared to `v1.0` (what the [leadoff post](#1) was based on), `v2.0` adds dysregulation scores for imputed genes.

See the [summary of our findings](http://thinklab.com/discussion/workshop-to-analyze-lincs-data-for-the-systems-pharmacology-course-at-ucsf/181#14). In short, certain genes responded in the same direction to a large number of perturbations. For example, _RPS4Y1_ was frequently downregulated and _MCOLN1_ was frequently upregulated, regardless of which gene was perturbed in which direction.

@larsjuhljensen noted:

> Reassuring to see that things behave the way I would expect. This should make it fairly easy to derive a scoring scheme that extracts only associations that are specifically associated with a small number of perturbations, as opposed to associated with any perturbation.

I think Lars makes a great suggestion, worthy of investigation. However, due to time constraints, we will have to postpone this analysis for a future undertaking.

# Proposed quick fix 

Currently, I'm leaning towards collapsing all four types of regulation into a single relationship type (_Gene → regulates → Gene_), which means perturbation of the source gene significantly dysregulated the target gene. In other words, we'll take the union of the four [aforementioned](#1) regulation relationships.

Our _DWPC_ method for quantifying the connectivity between two nodes downweights paths through high degree nodes [@10.1371/journal.pcbi.1004259]. Thus the pervasively dysregulated genes should not be too problematic.","17",2016-03-09,2016-03-09,2,2165,"base.profile","Daniel","Himmelstein","dhimmel"
"697","comments","rephetio","2016-03-09T20:45:38.038Z",17,"Time is short to finalize our indication catalog by consensus.

@pouyakhankhanian, are any changes needed to your original classifications to reach a consensus with @chrissyhessler regarding epilepsy and migraine indications?

@pouyakhankhanian, how many indications are subject to what we decide for autoimmune diseases and steroids? I agree this is a tough call. In practice, steroids are [not referred to](http://www.nationalmssociety.org/For-Professionals/Clinical-Care/Managing-MS/Disease-Modification ""Disease Modification · National MS Society"") as disease modifying for multiple sclerosis. However, I'm not convinced there is a logic to this omission that could be consistently applied to other diseases. Thoughts?

We do want our catalog to be broadly applicable to projects beyond our specific study. In other words, we want the catalog to be generally useful to train and test computational approaches without too many disputable calls. 

> One clarification: is a drug still considered disease modifying if there are significant and dangerous side effects?

My take here is yes as long as the drug has been indicated in a disease-modifying capacity in some context. The context may be the time before the dangerous side effects were fully appreciated or the time before better tolerated therapies came to market.","17",2016-03-09,2016-03-09,2,1334,"base.profile","Daniel","Himmelstein","dhimmel"
"698","comments","rephetio","2016-03-10T08:15:17.165Z",188,"- **Re: migraines and epilepsy.**  No changes need to be made to the spreadsheet, the proposed classification presented by CSH matches what I chose.

- **Re: steroids and auto-immune diseases.** There are about 70 steroid-autoimmune connections that would need to be subject to this decision. I think there are about 20 which are Rheumatoid Arthritis and Lupus, which I think are safely DM. That leaves another 50 which would have to be re-evaluated based on the decision. For the case of multiple sclerosis, I still tend to favor calling steroids DM for a few reasons. First, let's consider an easy (but  rare) example. Suppose a patient comes in with painful trigeminal neuralgia due to an active demyelinating lesion. One would give this patient steroids. The steroids would decrease active inflammation and demyelination, thereby decreasing the duration of time of the symptom of pain. The steroid does not actually treat the pain directly (like a ""pain-killer""), but it treats the biology behind the pain. While it is true that the steroid does not slow the progression from RRMS to SPMS, nor does it prevent future attacks (hence it is not called ""DM"" in the clinic), it does affect the biology of the current attack. Next, let's consdier a more complex (but more common) example. Suppose a patient comes in with leg weakness making her unable to walk, due to an active demyelinating lesion. One would give this patient steroids. The steroids would decrease active inflammation and demyelination, thereby decreasing the duration of time of the symptom of weakness. The steroid does not directly treat weakness (like a drug like Ampyra might do). Again, while it is true that the steroid does not slow the progression from RRMS to SPMS, nor does it prevent future attacks (hence it is not called ""DM"" in the clinic), it does affect the biology of the current attack. Finally, let's consider [this article] (http://journals.lww.com/neurotodayonline/Fulltext/2009/07020/Monthly_Steroid_Pulses_Cut_MS_Relapses_38_Percent.12.aspx ""Neurology Green journal""). In that article, they give monthly steroids and in order to prevent future attacks. They find that the number of future attacks is decreased (though it is likely not a large enough effect to justify the use of chronic steroids long-term given all the side effects that go along with chronic steroid use). Decreasing the number of attacks is exactly what defines nearly all of the drugs typically which are [""in practice... referred to as disease modifying""] (http://www.nationalmssociety.org/For-Professionals/Clinical-Care/Managing-MS/Disease-Modification  ""National MS Society definition of DM"") (most of these drugs to not prevent progression from RRMS to SPMS). For the three reasons above, I would still tend to favor calling steroids DM in MS. If we choose otherwise, then I think we should use MS as an example to set up a precise definition of what qualifies as disease modifying in auto-immune diseases, and then re-evaluate the other 50 steroid-autoimmune indications based on that definition.","188",2016-03-10,2016-03-10,2,3064,"base.profile","Pouya","Khankhanian","pouyakhankhanian"
"699","comments","rephetio","2016-03-15T05:24:35.132Z",17,"## Introducing PharmacotherapyDB

I'm excited to announce the initial release of our catalog of drug therapies for disease. The catalog  contains physician curated medical indications. It's available on [figshare](https://doi.org/10.6084/m9.figshare.3103054) [@10.6084/m9.figshare.3103054] and [GitHub](https://github.com/dhimmel/indications/tree/11d535ba0884ee56c3cd5756fdfb4985f313bd80 ""dhimmel/indications at v1.0"") [@10.5281/zenodo.47664] and licensed to be maximally reusable.

This initial release contains 97 diseases and 601 drugs. Between these drug–disease pairs, there are 755 disease-modifying therapies, 390 symptomatic therapies, and 243 non-indications. To enable integrative analyses, drugs and diseases are coded using [DrugBank](http://www.drugbank.ca/) and [Disease Ontology](http://disease-ontology.org/) identifiers.

The catalog adheres to pathophysiological principals first. Therefore, the catalog includes indications with a poor risk–benefit ratio that are rarely used in the modern clinic. Contributions are welcome as we hope to expand and refine the catalog over time.

## History & Methods

One of our priorities from the beginning of this project was to construct a catalog of efficacious pharmacotherapies. Since our approach learns how to repurpose drugs based on the indications we feed it, a high quality indication catalog was a crucial. 

### Compilation and data integration

We began by looking for existing indication resources. In a [discussion](http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21) which generated 23 comments -- the most of any Thinklab discussion to date -- we received helpful suggestions from the community. Based on these suggestions and our research, we proceeded by integrating four resources:

+ **MEDI-HPS** [@10.1136/amiajnl-2012-001431] -- indications from RxNorm, SIDER 2, MedlinePlus, and Wikipedia ([discussed](http://thinklab.com/discussion/medi-indications-data-discrepancy-in-resource-specific-counts/31)).
+ **LabeledIn** -- indications extracted from drug labels by experts [@10.1016/j.jbi.2014.08.004] and crowdsourced non-experts [@10.1093/database/bav016] ([discussed](http://thinklab.com/discussion/processing-labeledin-to-extract-indications/46)).
+ **ehrlink** [@10.1136/amiajnl-2012-000852] -- indications from electronic health records where physicians linked medications to problems ([discussed](http://thinklab.com/discussion/extracting-indications-from-the-ehrlink-resource/62)).
+ **PREDICT** [@10.1038/msb.2011.26] -- indications from UMLS relationships, drugs.com, and drug labels ([discussed](http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#17)).

We mapped these resources onto our slim sets of [137 diseases](http://thinklab.com/discussion/unifying-disease-vocabularies/44#6) and [1,552 small molecule compounds](http://thinklab.com/discussion/unifying-drug-vocabularies/40#5). Taking the union of the four resources, [we extracted](http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#21) 1,388 high-confidence indications.

### Curation and categorization

Next, [we decided](http://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95) physician curation was needed to separate disease-modifying from symptomatic indications. We recruited two physician curators (@chrissyhessler & Ari J. Green) to perform a pilot on 50 random indications. Then together, we defined disease modifying as ""a drug that therapeutically changes the underlying or downstream biology of the disease"" and symptomatic as ""a drug that treats a significant symptom of the disease.""

The two curators then each reviewed all 1,388 indications and classified them as disease modifying (`DM`), symptomatic (`SYM`), or a non-indication (`NOT`). The initial two curators [disagreed](http://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95#5) 444 times. We recruited a third curator (@pouyakhankhanian) who had access to the prior curations. The third curator developed a [detailed methodology](http://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95#7) that helped us [reach consensus](http://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95#15) for the time being.

### Future plans

We're receptive to feedback on how to improve PharmacotherapyDB. For future releases, we hope to curate the unpropagated indications, include additional sources, and expand our disease and drug vocabularies.","17",2016-03-15,2016-03-15,2,4706,"base.profile","Daniel","Himmelstein","dhimmel"
"700","comments","rephetio","2016-03-12T20:24:37.834Z",17,"# Announcing the consensus curation

In the interest of time, we are finalizing the consensus curation now. We have chosen the [PK curation](#7) as the consensus. Discussion is still welcome and will be helpful for future incarnations of our catalog.

## Resolving steroids for autoimmune disease

Both original curators were given a change to respond to the PK curation and methodology. In CSH's [response](#11) and offline discussion with AJG, questions were raised regarding calling steroids DM for autoimmune diseases. Further discussion with PK, both above and offline, helped clarify the issue and convinced @sergiobaranzini and I that the DM classification was appropriate.

According to PK, steroids are not considered DM in the clinic because their poor risk–benefit ratios generally preclude longterm use. Clinicians interpret ""disease modifying"" to mean a therapy for changing the longterm disease course and therefore do not consider steroids, which are usually given for only a short period of time, disease modifying. However, our definition of DM does not require longterm modification. Nevertheless, PK points to some evidence [@10.1097/01.NT.0000357562.58878.0a @10.1212/wnl.57.7.1239] that steroids do modify the longterm disease course when administered over a prolonged period.

While a clinician's decision to prescribe a steroid for an autoimmune disease is motivated by reducing symptoms, PK believes the steroid reduces symptoms by modifying the underlying disease biology. In his opinion, steroids lead to a short-term suppression of the underlying biology -- in the case of autoimmune disease, the overactive immune response -- leading to a short-term improvement in symptoms. One litmus test is that while a steroid may be prescribed to treat a specific symptom of a multiple sclerosis relapse, the steroid would not treat the symptom in the absence of MS.

In conclusion, we are conformable with the decision that steroids modify autoimmune disease rather than treat their symptoms according to our [definition](#7). However, it's important to clarify that our indication catalog is designed primarily from a perspective of pathophysiology rather than clinical best practice.","17",2016-03-12,2016-03-12,2,2215,"base.profile","Daniel","Himmelstein","dhimmel"
"701","comments","rephetio","2016-03-11T17:13:45.157Z",17,"# Improved randomization of expression edges

We [updated our method](http://thinklab.com/discussion/processing-bgee-for-tissue-specific-gene-presence-and-overunder-expression/124#6) for extracting _Anatomy–expresses–Gene_ relationships from Bgee. This update [reduced the number](https://github.com/dhimmel/integrate/commit/d68b823bf2167e7ab7f0e784d1280200c33fb3bf#diff-c849eed0ccfe917ca2fceb4f57045444R3) of expression edges in our hetnet from 1,006,278 to 526,407. The number of genes with an expression edge went from 18,147 to 18,094. The number of anatomies with an expression edge went from 256 to 241.

The permutation of expression edges increased in effectiveness. Now ~25% of expression edges (as opposed to ~10% [previously](#1)) [change in](http://nbviewer.jupyter.org/github/dhimmel/integrate/blob/d68b823bf2167e7ab7f0e784d1280200c33fb3bf/data/permuted/evaluate-permutations.ipynb#How-many-permutations-are-needed-to-randomize-an-edge) a permuted hetnet. And this is in spite of fewer attempted swaps per permutation: I decreased the multiplier from 4 to 3 to reduce runtime.","17",2016-03-11,2016-03-11,2,1093,"base.profile","Daniel","Himmelstein","dhimmel"
"702","comments","rephetio","2016-03-11T22:41:36.326Z",17,"We [recently released](http://thinklab.com/discussion/computing-consensus-transcriptional-profiles-for-lincs-l1000-perturbations/43#7) version 2.0 of our LINCS L1000 analysis [@10.6084/m9.figshare.3085426 @10.5281/zenodo.47223]. This release added dysregulation _z_-scores for 6,489 imputed genes, in addition to the 978 directly measured genes on the L1000 [epsilon](http://support.lincscloud.org/hc/en-us/articles/202264116-What-are-L1000-probe-pools- ""What Are L1000 Probe Pools? · LINCS Cloud Support"") platform. We only added imputed genes that were part of the best inferred gene set (BING, genes [supposedly](http://thinklab.com/discussion/computing-consensus-transcriptional-profiles-for-lincs-l1000-perturbations/43#3) imputed with high quality).

We've also been [looking into](http://thinklab.com/discussion/positive-correlations-between-knockdown-and-overexpression-profiles-from-lincs-l1000/171) the genetic perturbation data in L1000. Here, we will assess the quality of the Broad's gene imputation using genetic perturbation consensus signatures. Specifically, we'll use whether a genetic perturbation dysregulates its target gene in the correct direction as a quality metric.

Below we show the distribution of dysregulation _z_-scores by imputation status and perturbation type ([notebook](https://github.com/dhimmel/lincs/blob/7f0f937cc3f3346f88a5d18eae8b07c6822ce653/imputation-assess.ipynb ""imputation-assess.ipynb · dhimmel/lincs · GitHub"")):

![Violin plots of perturbagen-self z-scores](https://github.com/dhimmel/lincs/raw/7f0f937cc3f3346f88a5d18eae8b07c6822ce653/viz/self-targeting-perts.png ""Violin plots of perturbagen-self z-scores"")

In general, the measured genes responded in the expected direction. For genetic perturbations whose targets were measured, 97% of knockdowns downregulated their targets (negative _z_-score), and 64% of overexpressions upregulated their targets (positive _z_-score). Instances where a measured gene responded in the reverse direction could be due to problems with perturbation delivery or [expression quantification](http://arxiv.org/abs/1602.06316 ""Model-based clustering with data correction for removing artifacts in gene expression data · Young et al. · arXiv"").

For genetic perturbations whose targets were imputed, 54% of knockdowns downregulated their targets, and 51% of overexpressions upregulated their targets. Using the success rates of measured genes as a baseline, we're led to conclude that the imputation quality of BING genes is poor.

If we instead judge the imputation based only significantly dysregulated genes, the results improve. For significant, imputed perturbagen--target pairs, 67% of knockdowns (18 of 24) downregulated their target, while 80% of overexpressions (4 of 5) upregulated their target. Since these sample sizes are small, I'm hesitant to declare that filtering for significant genes is sufficient to overcome the imputation problems.

For reader reference, recent research [@10.1093/bioinformatics/btw074] looked at improved imputation techniques that presumably could be applied to reimpute LINCS L1000 gene expression.","17",2016-03-11,2016-03-11,2,3138,"base.profile","Daniel","Himmelstein","dhimmel"
"703","comments","rephetio","2016-03-14T18:17:15.121Z",17,"# Mention in _Storybench_ piece on BLAZE

Margaux Phares wrote an article [published today on _Storybench_](http://www.storybench.org/science-search-engine-visualizing-discovery-process/ ""How a Science Search Engine Is Visualizing the Discovery Process"") exploring BLAZE. [BLAZE](http://openknowledgemaps.org/search/) is a new type of scholarly search engine that returns search results as bubble maps rather than lists. The article quotes me:

> “I’ll often work on problems for years before encountering seminal works that would have been helpful from day one,” Himmelstein said. “The [scientific literature search problem] is worst at the cross-section of fields as each field has its own specialized terminology.” He thinks Blaze may help solve this problem.

This quote was motivated by this project: specifically, the difficultly we faced when finding literature on hetnets. As I wrote to Margaux:

> I work on networks with multiple types of relationships. I call these networks ""hetnets"". It wasn't until the fifth year of my PhD, that I [learned of a plethora](http://thinklab.com/discussion/renaming-heterogeneous-networks-to-a-more-concise-and-catchy-term/104#6) of other terms referring to the same concept. And had I not been highly proactive at reaching out to diverse players, my ignorance would persist to this day.","17",2016-03-14,2016-03-14,2,1339,"base.profile","Daniel","Himmelstein","dhimmel"
"704","comments","rephetio","2016-03-14T18:26:05.738Z",188,"- **I think this is a valuable data source to maintain.** I understand the need to freeze it at the moment for your analysis. Going forward, I'd love to see a couple additional data sources. One would be uptodate, which would add to the total number of indications (including those where side effects outweight potential benefit) and would give you precise disease-indications for drugs (no need for curation by experts). When thinking about a second data source which may help add to your total number of indications, I might suggest a more clinically relevant source (like medscape). I think your current data-sources are heavy on government approval and, per our discussion earlier, for often politico-economic reasons, drugs may be very commonly used but not had any pharma funding for official approval, and these drugs may not all be caught when surveying pharmacy or doctor's ""indication notes"" as those may lack sensitivity (due to under-reporting of key ""disease"" designations).
- **I would keep an eye out for the steroids in auto-immune diseases** Steroid represent a relatively large fraction of the drugs, and auto-immune diseases a reasonable fraction of the total diseases (approximately 5%). I would interpret any results that your algorithm suggests in light of this. For example, I expect this will drive your algorithm into picking things that ""look"" like steroids (in terms of molecular structure, and known targets of possible action). As you know, steroids are molecularly quite similar to each other, and are often associated with the same limited number of key molecular targets. The other immunosuppressive agents (i.e. all the other drugs on your typical clinical list of choices) represent a variety of shapes (molecular structure) and known targets, and may provider richer (but more subtle, and probably lower powered to get a trustworthy result) information, and hopefully provide a more nuanced drug suggestion rather than picking things that ""look"" like steroids (e.g. suggesting a drug that nobody would ever have considered) .
- **Consider assigning mechanisms to drugs**. If you note that something richer is to be gained by ""decreasing the gain"" in large drug classes (i.e. the class ""steroids"" includes about 10 drugs in the list), consider using drug classes as an attribute. This will also aid any person who will have to curate the disease-drug connections.
- **The few remaining discrepancies, if using my calls as final calls**. After the discussion of the major discrepancies (where multiple discrepant drug-disease connections hinged on a single discussion), there are still minor discrepancies. There appear to be 55 other discrepancies to eventually be evaluated, totaling less than 5 percent of the total number of connections. Given the small number of total calls (less than 5% of total calls) and the large amount of discussion that would be required to solve each one, it makes sense to go forward with a data freeze for your downstream analysis. But I think it would be great to have you at least aware of these, and we can decide what to do on future versions. 
Of the 55 cases of discrepant calls, there are include 31 cases where my curation changed a previous agreement between the prior 2 curators, and those 24 cases where my curation resulted in a three way tie. 
--- 7 are explained directly by ammendment 1
--- 14 where I made a call which was explained by a prior call regarding the same disease being connected to another drug within the same drug class
--- 11 can be encapsulated in a discussion regarding hormone therapy in breast cancer. This is a more complex discussion than that of steroids, because the hormone therapies include ""partial agonists"". 
--- 3 which treated symptom of chemo rather than symptom of disease (therefore changed to NOT)
--- 3 regarding SSRIs in parkinson's
--- 17 discrepancies would each require a long discussion (similar to our discussions of diseases earlier). These are briefly denoted below.

|drug|disease|CSH|AJG|PK|PK_notes|
|----|-------|---|---|--|--------|
|Memantine|Alzheimer's disease|SYM|SYM|DM|""neuroprotective"", doesn't treat any symptom|
|Colchicine|primary biliary cirrhosis|NOT|NOT|DM|admittedly less evidence, but see [""uptodate 'Overview of the treatment of primary biliary cholangitis (primary biliary cirrhosis)' ""](http://www.uptodate.com/contents/overview-of-the-treatment-of-primary-biliary-cholangitis-primary-biliary-cirrhosis)|
|Pentoxifylline|systemic scleroderma|SYM|SYM|DM|affects the biology of the disease, thereby easing symptoms|
|Tretinoin|peripheral nervous system neoplasm|NOT|NOT|DM|can treat sarcomas [@10.1002/14651858.CD003256.pub2] and per amendment 1|
|Ursodeoxycholic acid|primary biliary cirrhosis|SYM|SYM|DM|doesn't treat any symptom, only modifies disease, see [""uptodate 'Overview of the treatment of primary biliary cholangitis (primary biliary cirrhosis)' ""](http://www.uptodate.com/contents/overview-of-the-treatment-of-primary-biliary-cholangitis-primary-biliary-cirrhosis)|
|Colchicine|systemic scleroderma|NOT|DM|SYM|for arthralgia, not aware of disease modification|
|Chenodeoxycholic acid|primary biliary cirrhosis|SYM|NOT|DM|in trials, see [""uptodate 'Overview of the treatment of primary biliary cholangitis (primary biliary cirrhosis)' ""](http://www.uptodate.com/contents/overview-of-the-treatment-of-primary-biliary-cholangitis-primary-biliary-cirrhosis)|
|Dimenhydrinate|allergic rhinitis|SYM|NOT|DM|it blocks histamine-H1 just like benadryl. Granted, one would never actually use this in clinic (you would just use benadryl given better efficacy and less side effects), but given the mechanism of action there is reasonable evidence of efficacy|
|Dimenhydrinate|atopic dermatitis|SYM|NOT|DM|it blocks histamine-H1 just like benadryl. Granted, one would never actually use this in clinic (you would just use benadryl given better efficacy and less side effects), but given the mechanism of action there is reasonable evidence of efficacy|
|Sildenafil|type 1 diabetes mellitus|NOT|DM|SYM|may be DM for DM2 but not for DM1 [@10.2337/diacare.26.2.279]|
|Temozolomide|skin cancer|NOT|NOT|DM|melanoma|
|Acetylcysteine|chronic obstructive pulmonary disease|DM|DM|SYM|mucolytic, does not affect disease biology|
|Epoprostenol|systemic scleroderma|NOT|DM|SYM|not aware of disease modification, agree with CSH comment re: symptom|
|Timolol|coronary artery disease|NOT|SYM|DM|per [""uptodate - Timolol Drug info""](http://www.uptodate.com/contents/timolol-systemic-drug-information?source=search_result&search=timolol&selectedTitle=1~36)
|
|Finasteride|prostate cancer|SYM|DM|NOT|prevents but doesn't treat it. Not sure what the symptomatic thing CSH refers to, does she mean symptoms of BPH? (and if so isn't that a different disease?)|
|Digoxin|dilated cardiomyopathy|DM|NOT|SYM|see [""uptodate: Overview of the therapy of heart failure with reduced ejection fraction""](http://www.uptodate.com/contents/overview-of-the-therapy-of-heart-failure-with-reduced-ejection-fraction)|
|Ergocalciferol|metabolic syndrome X|SYM|DM|NOT|would you give this med to anyone who has metabolic syndrome X but does not also have vitamin D deficiency?|","188",2016-03-14,2016-03-14,2,7213,"base.profile","Pouya","Khankhanian","pouyakhankhanian"
"705","comments","rephetio","2016-03-15T03:01:43.148Z",17,"# Data licensing and compliance report

As a refresher, we released an initial version of our network built from publicly-availabe resources. I had assumed that as long as a resource was public, we could use it for our research. In addition, we're committed to open science — releasing our network and intermediate data, both for reproducibility and to allow others to build off of our research. However, as @larsjuhljensen [pointed out](http://thinklab.com/discussion/one-network-to-rule-them-all/102#2), legal issues arise when using public data that isn't specifically licensed to permit reuse.

It has now been 212 days since Lar's alert and 199 days since I started this discussion seeking expert advice. Here I'll report on the strategy we chose. Our goals were: to bring us into compliance with copyright law and license agreements; to respect the intent of resource creators; to preserve our sunk time investment; and to retain the scientific value of our network. Unfortunately, no one solution satisfied every objective. We were left to choose between several imperfect ways forward.

## Compliance efforts

First, I compiled the [licenses for all of the resources](https://github.com/dhimmel/integrate/blob/145810796f0729d1ed5255bcb83c658490a198f9/licenses/README.md) we included in our network. Of the 28 resources we integrated, only 12 had licenses that [met](http://opendefinition.org/licenses/0) the [criteria for open knowledge](http://opendefinition.org/od/2.1/en/ ""Open Definition 2.1""). As a result, our project would not be a possibility under a paradigm of absolute compliance.

Resources fell into four categories regarding their licensing:

1. Resources that are in the **public domain**.
2. Resources with a license that **allows** use, redistribution, and modification.
3. Resources with a license that **forbids** use, redistribution, or modification.
4. Resources that **do not have** a license.

While I retrospectively assigned these categories while writing this post, the approach we pursued for a given resource aligned with its category. We approached category 1 & 2 resources by specifying their license wherever we use, redistribute, or modify them. We approached category 3 & 4 resources by requesting permission from their creators or owners. I attempted attribution for all resources, regardless of category, to maintain data provenance.

### Category 1 & 2 resources

There were 4 **category 1** resources — Entrez Gene, MEDLINE, LabeledIn, and MeSH — all due to US federal Government creations [not being entitled](https://en.wikipedia.org/w/index.php?title=Copyright_status_of_work_by_the_U.S._government&oldid=708981516) to copyright protection. These resources were easy to integrate: I could proceed without restriction and released derivative works under CC0.

There were 14 **category 2** resources. If the resource uses a standard license, such as a license by [Creative Commons](https://creativecommons.org/licenses/) or [Open Data Commons](http://opendatacommons.org/licenses/), I used the same license including version for redistribution and derivative works. Examples include Disease Ontology, DISEASES, Gene Ontology, TISSUES, Uberon, WikiPathways, BindingDB, DisGeNET. If the resource used a custom license, then I applied a Creative Commons license that abided by the custom stipulations. For example, [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/) for custom licenses that require attribution — GWAS Catalog & LINCS L1000 — and [CC BY-NC 4.0](https://creativecommons.org/licenses/by-nc/4.0/) for custom licenses that forbid commercial use or specify academic use only — DrugBank.

I embedded licensing into the network as node/relationship properties. Therefore, users can filter to retain only specific licenses when querying or parsing our network. Prior to the network stage when data for each resource still resides in separate repositories, I specified licensing via a `LICENSE.md` file or a section in the `README.md` file.

### Category 3 & 4 resources

Originally I identified 3 **category 3** resources — MSigDB, Incomplete Interactome, LINCS L1000. I chronicled these permission requests on _Thinklab_. Through our permission requests, we learned that the [Incomplete Interactome was](https://doi.org/10.15363/thinklab.d111) actually category 4 and [LINCS L1000 was](https://doi.org/10.15363/thinklab.d110) actually category 2. Our permission request to MSigDB [is ongoing](http://doi.org/10.15363/thinklab.d108).

There were 9 **category 4** resources — ADEPTUS, Bgee, DOAF, ehrlink, ERC, hetio-dag, Incomplete Interactome, Human Interactome Database, STARGEO. Since I am the creator of hetio-dag and our STARGEO analysis, these resources did not require any action. For the remaining resources, I sent permission requests.

For category 3 & 4 resources, I opted to continue including the resource in our network regardless of whether we affirmatively received permission. I deemed these resources too critical from a scientific perspective to justify their removal. Several factors shaped my decision: many scientists who post their data assume it will automatically be reusable; the resources were publicly funded with the intent to be used for science; copyright may not apply if our network is fair use or the underlying data is factual; and reuse of scientific data despite all rights reserved is prevalent throughout academia.

There are several unpleasant consequences to my decision to include category 3 & 4 works. First, I risk the legal consequences of infringement. Second, we could have to purge content from our network if a data creator/owner requests that we discontinue use of their resource. Third, anyone who wants to use or build off of our network will have to revisit the same issues we're facing here.

#### Permission requests by outcome

For category 3 & 4 resources, I requested permission to use the resource for our project. I've organized my requests into four outcomes:

+ EXST — We received a response referring us to an existing license. In the four instances, we had overlooked the license because it was difficult to find or unclear whether it applied.
+ PERM — We received a response granting us permission to use the resource. In both cases, the authors granted their permission but acknowledged that they may not be the rights holder.
+ INC — We received an inconclusive response. In all three cases, the authors indicated they would take licensing actions which have yet to happen.
+ NORESP — No response.

Each resource for which we requested permissions is below. Days indicates the time till first response. When present, public documentation of our request is linked to in Contact Method. The table is sorted by outcome and then by days.

| Resource | Outcome | Days | Contact Method |
|----------|----------|------|----------------|
| [Uberon](http://uberon.org) | EXST | 0 | [GitHub Issue](https://github.com/obophenotype/uberon/issues/1139) |
| [Entrez Gene](http://www.ncbi.nlm.nih.gov/gene) | EXST | 2 | helpdesk |
| [LINCS L1000](http://www.lincscloud.org/l1000/) | EXST | 16 | [email](https://doi.org/10.15363/thinklab.d110) |
| [GWAS Catalog](https://www.ebi.ac.uk/gwas/) | EXST | 19 | email |
| [Incomplete Interactome](http://science.sciencemag.org/content/suppl/2015/02/18/347.6224.1257601.DC1) | PERM | 0 | [email](https://doi.org/10.15363/thinklab.d111) |
| [Evolutionary Rate Covariation](http://csb.pitt.edu/erc_analysis/Methods.php) | PERM | 16 | email |
| [DOAF](http://doa.nubic.northwestern.edu/pages/search.php) | INC | 2 | email |
| [Bgee](http://bgee.org) | INC | 9 | email/[note](https://doi.org/10.15363/thinklab.d82#15) |
| [MSigDB](http://software.broadinstitute.org/gsea/msigdb) | INC | 129 | [email](https://doi.org/10.15363/thinklab.d108) |
| [Human Interactome Database](http://interactome.dfci.harvard.edu/H_sapiens/index.php?page=download) | NORESP | 189+ | email |
| [ADEPTUS](http://acgt.cs.tau.ac.il/adeptus/) | NORESP | 198+ | email |

## Conclusion

We've gone to great lengths and invested substantial time in complying with data copyright and licensing. However, under a strict interpretation, our project may infringe upon the rights of publicly-funded scholarly resources.","17",2016-03-15,2016-03-15,2,8298,"base.profile","Daniel","Himmelstein","dhimmel"
"706","comments","rephetio","2016-03-15T05:25:20.118Z",17,"## Category breakdown by resource

Using the consensus curation, we have gone back and calculated the composition of indication category by resource ([notebook](https://github.com/dhimmel/indications/blob/11d535ba0884ee56c3cd5756fdfb4985f313bd80/curation/catalog.ipynb)).

| Resource | DM | SYM | NOT | Total |
|-----------|-------------|-------------|------------|------------|
| MEDI-HPS | 532 (67.1%) | 168 (21.2%) | 93 (11.7%) | 793 (100%) |
| PREDICT | 346 (59.7%) | 158 (27.2%) | 76 (13.1%) | 580 (100%) |
| EHRLink | 205 (44.3%) | 163 (35.2%) | 95 (20.5%) | 463 (100%) |
| LabeledIn | 183 (66.1%) | 72 (26.0%) | 22 (7.9%) | 277 (100%) |

The table indicates that of the 793 indications we extracted from MEDI-HPS, 532 (67.1%) were disease modifying. In short, we found that MEDI-HPS and LabeledIn contained the highest percentage of disease-modifying indications. EHRLink, which is based on electronic health records, contained the highest percentage of symptomatic (35.2%) and non (20.5%) indications.

## Category breakdown by number of resources

Next, we looked at the category composition based on the number of resources reporting each indication.

| # of Resources | DM | SYM | NOT | Total |
|----------------|-------------|-------------|-------------|------------|
| 1 | 433 (47.4%) | 271 (29.6%) | 210 (23.0%) | 914 (100%) |
| 2 | 190 (66.2%) | 74 (25.8%) | 23 (8.0%) | 287 (100%) |
| 3 | 75 (61.0%) | 38 (30.9%) | 10 (8.1%) | 123 (100%) |
| 4 | 57 (89.1%) | 7 (10.9%) | 0 (0.0%) | 64 (100%) |

The more resources that reported an indication the more likely it was to be disease modifying: indications in only a single resource were disease modifying 47.4% of the time whereas indications in all four resources were disease modifying 89.1% of the time.","17",2016-03-15,2016-03-15,2,1792,"base.profile","Daniel","Himmelstein","dhimmel"
"707","comments","rephetio","2016-03-15T23:58:06.449Z",17,"# 2016 Neo4j GraphGist Challenge

We [created](http://thinklab.com/discussion/using-the-neo4j-graph-database-for-hetnets/112#8) a Star Wars themed entry to the 2016 Neo4j GraphGist challenge. The competition aimed to showcase exciting uses of Neo4j -- a graph database designed for hetnets. The winners were [announced today](http://neo4j.com/blog/graphgist-challenge-winners/ ""The Graph Is Strong with This One: GraphGist Challenge Winners!"") and [our GraphGist](http://neo4j.com/graphgist/c4eab62c-7f5e-4e17-8f75-811d65d83127 ""Drug repurposing by hetnet relationship prediction: a hew hope"") won the ""Open/Government Data and Politics"" category.","17",2016-03-15,2016-03-15,2,649,"base.profile","Daniel","Himmelstein","dhimmel"
"708","comments","rephetio","2016-03-16T21:56:38.375Z",17,"# PharmacotherapyDB Version 1.0

We [completed physician curation](http://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95#15) for the time being and [released the first version](http://thinklab.com/discussion/announcing-pharmacotherapydb-the-open-catalog-of-drug-therapies-for-disease/182) of our indications catalog called PharmacotherapyDB.

Thanks @b_good, @TIOprea, @allisonmccoy, @ritukhare, and @alizee -- your suggestions and feedback were immensely helpful!

We'll keep this discussion alive for any suggestions of new resources or methods to improve future versions of PharmacotherapyDB.","17",2016-03-16,2016-03-16,2,656,"base.profile","Daniel","Himmelstein","dhimmel"
"709","comments","rephetio","2016-03-16T22:14:15.042Z",17,"# Therapeutic Target Database

The Therapeutic Target Database ([TTD](http://bidd.nus.edu.sg/group/cjttd/ ""Therapeutic Target Database Homepage"")) is a target focused resource with pharmacological relationships. @janispi [suggested](https://twitter.com/Janis3_14159/status/709844572600475648 ""Twitter"") we check out TTD as a source of drug--disease therapies.

Specifically, TTD has a dataset of indications, which range from approved to investigational, available online ([`drug-disease_TTD2016.txt`](http://database.idrb.cqu.edu.cn/TTD/download/drug-disease_TTD2016.txt)). I couldn't find how these indications were constructed from their publications [@10.1093/nar/30.1.412 @10.1093/nar/gkp1014 @10.1093/nar/gkr797 @10.1093/nar/gkt1129 @10.1093/nar/gkv1230], although I may have missed it. I emailed Professor Yu Zong (`csccyz@nus.edu.sg`), who indicated their drug-disease relationships were human curated.

Just wanted to note this information, so we remember to keep TTD in mind.","17",2016-03-16,2016-03-16,2,991,"base.profile","Daniel","Himmelstein","dhimmel"
"710","comments","rephetio","2016-03-20T16:41:10.716Z",17,"I spoke with @TIOprea and Oleg Ursu from the University of New Mexico. They are constructing a highly curated yet highly integrative database of pharmacology named [DrugCentral](http://datascience.unm.edu/drugdb/). They have not yet published a journal article detailing their database. However, they have posted an alpha [webapp](http://pasilla.health.unm.edu/tomcat/drugcentral/drugcentral ""DrugCentral Browser"") and [data repository](https://github.com/olegursu/drugtarget ""olegursu/drugtarget on GitHub""), which provide access to select components of the database.

My impression was that the database is similar in concept to [DrugBank](http://www.drugbank.ca/) but has key advantages in certain areas. First, it has integrated types of data which are not currently part of DrugBank. Second, it takes a more clinical approach to curation compared to DrugBank. For example, drug--target relationships in DrugCentral adhere more to the ""three pillars [@10.1016/j.drudis.2011.12.020]"" of pharmacological activity.

I created a repository ([`dhimmel/drugcentral`](https://github.com/dhimmel/drugcentral ""dhimmel/drugcentral on GitHub"")) to process parts of DrugCentral for inclusion in our network. Details of the integration will follow.","17",2016-03-20,2016-03-20,2,1243,"base.profile","Daniel","Himmelstein","dhimmel"
"711","comments","rephetio","2016-03-20T17:21:28.930Z",17,"# Contributions to our hetnet

I processed DrugCentral data and converted it into the identifier systems used by our network ([notebook](https://github.com/dhimmel/drugcentral/blob/e80a0c966a53ce48650d98069b126801c2793517/drugcentral-to-rephetio.ipynb)). I have initially added two relationship types from DrugCentral into the hetnet ([commit](https://github.com/dhimmel/integrate/commit/0f2ef740197dd2767cb0de80f57d9f47e2e91c7a)). 


## Drug targets

I extracted drug--target relationships from DrugCentral and converted them into the DrugBank and Entrez Gene identifiers in our network ([dataset](https://github.com/dhimmel/drugcentral/blob/e80a0c966a53ce48650d98069b126801c2793517/rephetio/targets.tsv)). The table below shows the sources from which DrugCentral compiled drug targets and how many relationships each source contributed. 

| Resource | Count |
| ------------- | -------- |
| DrugCentral (ChEMBL) | 2,922 |
| DrugCentral (literature) | 182 |
| DrugCentral (label) | 89|
| DrugCentral (IUPHAR) | 56 |
| DrugCentral (KEGG DRUG) | 25 |

Prior to including DrugCentral, our network contained 10,747 _Compound--binds--Gene_ relationships from [DrugBank](http://thinklab.com/discussion/protein-target-carrier-transporter-and-enzyme-interactions-in-drugbank/65#1) and [BindingDB](http://thinklab.com/discussion/integrating-drug-target-information-from-bindingdb/53#6). Drug targets from DrugCentral added 824 additional binding relationships.

## Pharmacologic classes

DrugCentral has compiled the membership of compounds in pharmacologic classes from several [sources](https://github.com/olegursu/drugtarget/blob/9a6d84bed8650c6c507a2d3d786814c774568610/README.md#pharmacologic-class-table), which contain the following types of classes:

+ FDA -- Mechanism of Action
+ FDA -- Physiologic Effect
+ FDA -- Chemical/Ingredient
+ FDA -- Established Pharmacologic Class
+ MeSH -- Pharmacological Action
+ CHEBI -- Application

I decided to assign all of these classes to a single node type (_Pharmacologic Class_). I added a new relationship type for _Pharmacologic Class--includes--Compound_. DrugCentral contributed 10,959 relationships for 1,262 [pharmacologic classes](https://github.com/dhimmel/drugcentral/blob/e80a0c966a53ce48650d98069b126801c2793517/rephetio/classes.tsv ""Table of Pharmacologic Classes extracted from DrugCentral"").","17",2016-03-20,2016-03-20,2,2378,"base.profile","Daniel","Himmelstein","dhimmel"
"712","comments","rephetio","2016-03-20T19:18:45.927Z",17,"# Medical indications

In my conversation with DrugCentral team members, we first discussed PharmacotherapyDB, our [recently-released](http://thinklab.com/discussion/announcing-pharmacotherapydb-the-open-catalog-of-drug-therapies-for-disease/182) physician-curated catalog of indications. One major takeaway was that we needed to more clearly explain that our definition of disease modifying differs from the clinical definition. Also, we need to more clearly state that `NOT` refers to non-indications.

As part of DrugCentral, they've constructed their own indications catalog. Their seeded their catalog from [OMOP](http://omop.org/ ""Observational Medical Outcomes Partnership"") in 2012 and have since then manually added additional indications. OMOP has now become [OHDSI](http://www.ohdsi.org/ ""Observational Health Data Sciences and Informatics"") and hosts their vocabular on GitHub at [`OHDSI/Vocabulary-v5.0`](https://github.com/OHDSI/Vocabulary-v5.0). As a side note, we were not aware of OMOP [@10.7326/0003-4819-153-9-201011020-00010] or OHDSI [@10.3233/978-1-61499-564-7-574] when we [assembled](http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#21) our indications for version 1.0 of PharmacotherapyDB.

## Aligning indications with PharmacotherapyDB

I converted the DrugCentral indications to the slim sets of DrugBank drugs and Disease Ontology diseases in PharmacotherapyDB 1.0 ([notebook](https://github.com/dhimmel/drugcentral/blob/e80a0c966a53ce48650d98069b126801c2793517/drugcentral-to-rephetio.ipynb), [dataset](https://github.com/dhimmel/drugcentral/blob/e80a0c966a53ce48650d98069b126801c2793517/rephetio/indications.tsv)). For each disease, I aggregated direct indications as well as indications for subtypes (referred to as propagation). 

In the [converted dataset](https://github.com/dhimmel/drugcentral/blob/e80a0c966a53ce48650d98069b126801c2793517/rephetio/indications.tsv), I included a `category` column giving the indication's PharmacotherapyDB 1.0 status. Of a total of 671 indications extracted from DrugCentral, 210 were not in PharmacotherapyDB 1.0. Of the 461 indications in PharmacotherapyDB, 359 were classified as disease modifying (78%), 77 were classified as symptomatic (17%), and 25 were classified as non-indications (5%). 

6 of the non-indications were [for anemia](https://github.com/dhimmel/drugcentral/blob/e80a0c966a53ce48650d98069b126801c2793517/rephetio/indications.tsv#L38) and 8 were [for hypertension](https://github.com/dhimmel/drugcentral/blob/e80a0c966a53ce48650d98069b126801c2793517/rephetio/indications.tsv#L296), two diseases for which we have a [known problem](http://thinklab.com/discussion/expert-curation-of-our-indication-catalog-for-disease-modifying-treatments/95#8) with their generality. [Compared to the four sources](http://thinklab.com/discussion/announcing-pharmacotherapydb-the-open-catalog-of-drug-therapies-for-disease/182#2) of PharmacotherapyDB indications, DrugCentral appears to have a higher percentage of disease modifying indications. However, we're basing this assessment on indications that appeared in DrugCentral and at least one other resource, so it's potentially biased.

@pouyakhankhanian, if you are up for curating the 210 new indications as `DM`, `SYM`, or `NOT`, we could potentially:

1. add these indications to a future release of PharmacotherapyDB
2. use these indications to test our predictions","17",2016-03-20,2016-03-20,2,3452,"base.profile","Daniel","Himmelstein","dhimmel"
"713","comments","rephetio","2016-03-24T00:57:39.774Z",17,"# Pharmacologic Classes that are indications

We've noticed that many of the [pharmacologic classes](https://github.com/dhimmel/drugcentral/blob/e80a0c966a53ce48650d98069b126801c2793517/rephetio/classes.tsv) are essentially indications. This could be problematic since it could confound our classification approach. Specifically, it could lead to the appearance that our method predicts indications when in reality it just regurgitates indications which were encoded by a pharmacologic class.

Some examples of classes that resemble indications are:

| class_id | class_name | class_source | class_type |
|------------------|------------|--------------|---------------------|
| [CHEBI:35469](http://identifiers.org/chebi/CHEBI%3A35469) | antidepressant | CHEBI | Application |
| [N0000175482](http://purl.bioontology.org/ontology/NDFRT/N0000175482) | Antimalarial | FDA | FDA Established Pharmacologic Class |
| [D018501](http://identifiers.org/mesh/D018501) | Antirheumatic Agents | MeSH | Pharmacological Action |

@sergiobaranzini and I looked through the 6 sources and found that 3 were **less problematic**:

+ FDA — Chemical/Ingredient
+ FDA — Mechanism of Action
+ FDA — Physiologic Effect

The other 3 were **more problematic**:

+ FDA — Established Pharmacologic Class
+ MeSH — Pharmacological Action
+ CHEBI — Application

Therefore, I excluded classes from the 3 more problematic sources. This reduced the number of classes from 1,262 to 345, the number of edges from 10,959 to 1,029, and the number of compounds in a class from 1,423 to 724 ([commit](https://github.com/dhimmel/integrate/commit/1229536c6d2146c4cae97f045cf8cbdd272420f6)).

One step would be to salvage many of the filtered classes by manual curation. The majority of the removed classes did not overlap with [DO Slim](http://thinklab.com/discussion/unifying-disease-vocabularies/44#6) diseases and thus shouldn't confound our analysis. If we decide to curate, we'll have to decide whether to exclude all indications or just indications in DO Slim.","17",2016-03-24,2016-03-24,2,2052,"base.profile","Daniel","Himmelstein","dhimmel"
"714","comments","rephetio","2016-03-22T17:03:53.425Z",17,"Our approach quantifies the hetnet topology between compound--disease pairs by calculating the prevalence of different path types (metapaths) [@10.1371/journal.pcbi.1004259]. We would like to be able to estimate the complexity of a metapath, given the graph. We'll define complexity as the number of Neo4j database hits (`dbhits`) needed to execute a query. Specifically, we're interested in  assessing the runtime of queries for a given metapath, without having to run the queries. 

If we can accurately predict runtime using estimated complexity, we can selectively avoid computing features for overly complex metapaths. Since the number of potential metapaths (as well as paths per metapath) scales combinatorially with increasing path length, our method will be always run into computational limits. We're hoping to use complexity estimates to help choose a tractable set of metpaths.

## Metapath runtime on a trial feature extraction

In the past, we've used a length cutoff for metapaths. In a trial run of our feature extraction, I computed features for all metapaths with lengths 2--4. However, I terminated the process midway because progress was too slow. What we saw was that a few metapaths took a disproportionate amount of time to query.

See [cells 11--12 in this notebook](http://nbviewer.jupyter.org/github/dhimmel/learn/blob/5c94a0b53d71f2ac0a2f48133a8e1d4e4e0ee26c/all-features-pyviz.ipynb#Time-per-query), noting that ~half of metapaths with lengths 2--4 are missing and that paths with duplicate nodes were not excluded as they [should have been](http://thinklab.com/discussion/path-exclusion-conditions/134#4). Nonetheless, the results are clear: the metapaths with long runtimes were only mildly predictive (`auroc`), did not decline in predictiveness due to [network permutation](http://thinklab.com/discussion/assessing-the-effectiveness-of-our-hetnet-permutations/178) (`delta_auroc`).

The worst metapath was _CdGeAeGuD_, taking on average 37 seconds per query (compound--disease pair).  This metapath combines four gene-expression-based edges, which can be terribly high degree on their non-gene terminus.

Hence, we will look into estimating metapath complexity to exclude such runtime outliers.","17",2016-03-22,2016-03-22,2,2238,"base.profile","Daniel","Himmelstein","dhimmel"
"715","comments","rephetio","2016-03-22T17:31:44.934Z",17,"# Estimating the complexity of a sequential traversal

In sequential traversal, the query begins on a single node and expands to create a tree of paths conforming to the specified metapath. Once the tree has been fully expanded, only paths whose leaves match the desired ending node are retained.

To estimate the sequential complexity of a metapath on a given graph, I first calculated the average degree of each metaedge based on our specific hetnet. Then, I took the log10 of the product of the average degrees along the path. Each metaedge contributes one degree: the average degree of whichever metanode is traversed first by the path. Since you can start a sequential traversal from either end of a path, we'll refer to forward versus backward sequential traversal.

@alizee proved to me in whiteboard discussion, that there is always a constant difference between the complexity of a forward and reverse sequential traversal, which is based only on the number of nodes of the source and target metanodes. The estimated complexity of a sequential traversal is less when starting on the node whose type is more abundant. I'll let @alizee explain the details.

On the trial feature extraction, forward sequential complexity was a good estimator of runtime ([notebook cell 13](http://nbviewer.jupyter.org/github/dhimmel/learn/blob/5c94a0b53d71f2ac0a2f48133a8e1d4e4e0ee26c/time.ipynb#sequential_complexity ""Disregard cells 14--15, which use a flawed method for computing join complexity"")). However, it's important to note that our Neo4j queries were not performed sequentially. Instead, traversal began from both termini and met in the middle where the results were joined. Even so, estimated sequential complexity may be a good metric to use for metapath selection.","17",2016-03-22,2016-03-22,2,1777,"base.profile","Daniel","Himmelstein","dhimmel"
"716","comments","rephetio","2016-03-23T17:19:48.764Z",23,"# A note on traversal complexity

## Intro

The question here is to estimate the complexity of graph traversal when following a 'metapath': a specification for which kind of nodes we need to traverse, in which order. This complexity will be useful to get a proxy for computation time when create the features we currently use in _rephetio_ for prediction problems, the DWPC. We mainly look at sequential complexity, which is estimating complexity of traversal from one point to another, in only one direction, without joining two partial traversals in the middle. (even though the latter is almost always a better option)

We can reasonably make the hypothesis that sequential complexity is equal to the number of possible paths that must be traversed. You propose above, and I would agree, that we use something along the [mean-field approximation](https://en.wikipedia.org/wiki/Mean_field_theory) and consider that the average number of paths to be traversed when following a Metapath is equal to the multiplication of the average degrees (outward connections) of all node types along the metapath. Doing so, we intrinsically base our analysis on the number of edges in the networks, which gives us some simple, neat properties.

## Formal definition

We consider as an example 4 types of Nodes in our Network, $$A, B, C, D$$, linked with symmetrical edges, and the Metapath joining them $$A-B-C-D$$. We consider these nodes in order, since the difference between 'forward' (starting from $$A$$) and 'backward' (starting from $$D$$) traversal matters - as defined by @dhimmel above. Each node type has respectively $$N_A, N_B, N_C, N_D$$ nodes, noted  $$A_i, B_j,$$... Each of these single nodes has a forward degree, noted $$a_i$$ for instance, and a backward degree, noted with a prime, eg $$b_i'$$. These degrees represent the number of edges that connect the node at stake ($$A_i$$ and $$B_i$$ in our examples) to the nodes of the next ($$B$$) or previous ($$A$$) types respectively.

[remark: we use the actual types instead of a notation ""$$K$$"" for simplicity. The results that are written below for nodes of type $$A$$ or $$B$$ stand general]

## Proof of the equivalence between forward and backward complexities

The average of node degree is written $$E[a_i]$$ such as:

$$$
\begin{align}
E_{i\in1,...,N_A}[a_i]=\frac{1}{N_A}\sum_{i\in1,...,N_A}{a_i}
\end{align}
$$$

Then, we have

$$$
\begin{align}
E_{i\in1,...,N_A}[a_i] \cdot N_A = N_{A-B} = E_{i\in1,...,N_B}[b_i'] \cdot N_B 
\end{align}
$$$

where $$N_{A-B}$$ is the number of edges from the nodes $$A$$ to $$B$$. Follows, in short notation: 

$$$
\begin{align}
E[a_i] = E[b_i'] \cdot \frac{N_B} {N_A} 
\quad or \quad
E[b_i'] = E[a_i] \cdot \frac{N_A} {N_B} 
\end{align}
$$$

The estimation of 'forward complexity' outlined above, for discovering the paths that correspond to the metapath $$A-B-C-D$$ is written as:

$$$
\begin{equation}
FC_{A-B-C-D} = E[a_i] \cdot E[b_i] \cdot E[c_i]
\end{equation}
$$$

The estimated backward complexity can be written as:

$$$
\begin{align}
BC_{A-B-C-D} = FC_{D-C-B-A} = E[b_i'] \cdot E[c_i'] \cdot E[d_i']
\end{align}
$$$

Follows:

$$$
\begin{align}
BC_{A-B-C-D} &= E[b_i'] \cdot E[c_i'] \cdot E[d_i']\\
 &= E[a_i]\frac{N_A}{N_B} \cdot E[b_i]\frac{N_B}{N_C} \cdot E[c_i]\frac{N_C}{N_D}\\
 &= E[a_i] \cdot E[b_i]\ \cdot E[c_i] \cdot \frac{N_A}{N_D}\\
BC_{A-B-C-D} &= FC_{A-B-C-D} \cdot \frac{N_A}{N_D}
\end{align}
$$$

More generally:

$$$
\begin{equation}
\boxed{BC = FC \cdot \frac{N_{START}}{N_{END}}}
\end{equation}
$$$

## All sequential complexities are made equal

Thus, forward and backward complexities are trivially related by the formula above. 

*Nevertheless*, we need to keep in mind that the forward and backward complexity estimates above stand only for a single traversal, starting either from one Node $$A_i$$ or $$D_i$$ respectively. Thus, if you plan to do these traversals for all the $$N_A \cdot N_D $$ possible pairs (or a randomly selected subset of those) you need to multiply these complexities by the number of starting nodes, $$N_A$$ or $$N_D$$ in order to get a relevant time estimate. As a result of this computation and under these hypotheses, there is no difference between forward and backward traversal - which is reassuring.

## Conclusion

+ Forward and Backward Complexity estimates are trivially related through the formula above.
+ Time estimates should take into account the number of starting nodes, resulting in no difference between both directions of traversal.
+ About join complexity: I believe that the sequential complexity estimates discussed here are good proxies for the process of ""joint"" traversal, when two semi-traversals are joined in the middle in order to reduce computation time.","23",2016-03-23,2016-03-23,2,4832,"base.profile","Antoine","Lizee","alizee"
"717","comments","rephetio","2016-03-31T00:13:13.028Z",17,"# The @alizee theorem of sequential complexity

@alizee, fantastic proof! The takeaway for me is that if you're doing a sequential traversal from one source to one target, start from the end where there are a greater number of nodes. In situations where we are using sequential complexity to estimate runtime, we only have be consistent on reporting either forward or backward complexity.","17",2016-03-31,2016-03-31,2,390,"base.profile","Daniel","Himmelstein","dhimmel"
"718","comments","rephetio","2016-03-31T00:37:47.170Z",17,"# A formula for estimating joint traversal complexity

Rather than perform traversals sequentially, both [Neo4j](http://neo4j.com/docs/2.3.3/execution-plans-combining.html#query-plan-node-hash-join ""Node Hash Join in Neo4j"") and [hetio](https://github.com/dhimmel/hetio/blob/2c135fcd32616d6979972105ba60b003d65c98bd/hetio/pathtools.py#L96 ""hetio.pathtools.paths_between()"") support joint traversal. In joint traversal, paths are expanded upon from both endpoints until meeting at an interior node, where they are joined.

Using @alizee's notation [above](#3), we'll consider metapath $$A-B-C-D$$. If we adopt a join index of 2 (joining on _C_), we compute joint complexity (_JC_) as:

$$$
JC_{A-B-C_{join}-D} = \log _{10} (E[a_i] \cdot E[b_i] + E[d_i'])
$$$

Note that @alizee didn't include the log, but for consistency with our reported complexity values, I'm including it. This proposed formula for complexity assumes that joining the traversals is a free operation. In Neo4j a [`NodeHashJoin`]((http://neo4j.com/docs/2.3.3/execution-plans-combining.html#query-plan-node-hash-join ""Node Hash Join in Neo4j"") doesn't require any dbhits, but could still add to runtime.

When the join index is 0, the joint traversal becomes equivalent to backward traversal. When the join index is the target node, the joint traversal becomes equivalent to forward traversal.","17",2016-03-31,2016-03-31,2,1372,"base.profile","Daniel","Himmelstein","dhimmel"
"719","comments","rephetio","2016-03-31T02:09:04.916Z",17,"# Choosing the best join index for Neo4j queries

If you don't give Neo4j 2.3.2 any hints where to join, the planner decides for itself. The planner is capable of sequential or join traversal. However, which query plan to use is determined prior to query execution (see [my issue](https://github.com/neo4j/neo4j/issues/6030 ""GitHub Issue on whether the join index could be adaptively determined during Neo4j query execution"")). You can tell Neo4j which node to join on using a join hint (`USING JOIN ON` in Cypher). If you specify a terminal node to join on in 2.3.2, a sequential query will be executed, but Neo4j will decide for itself whether to do a forward or backward sequential join.

Therefore, we wanted to see whether we could use our [estimated join complexities](#5) to optimize our Neo4j queries. Therefore we did a parameter sweep where we evaluated all possible join indexes when computing features (_DWPCs_) for 75 metapaths × 150 compound–disease pairs ([notebook](https://github.com/dhimmel/learn/blob/92d89c9eaf54704968f7397fac38d3e7a2074ca5/optimize/join-index/sweep.ipynb)). In total, we performed 66,600 queries.

We consider three options for specifying the join index:

+ **midpoint index** -- the floor of the metapath length divided by two. Note if there were more diseases than compounds, then [we expect](#3) the ceiling would outperform the floor.
+ **optimal index** -- the least complex join index based on [our formula](#5) for estimating join complexity.
+ **no hint** -- where we let Neo4j choose the join index. The query planner will choose a join index, although we do not know which index was used.

For each metapath, we identified the average runtime of the three options ([table](https://github.com/dhimmel/learn/blob/92d89c9eaf54704968f7397fac38d3e7a2074ca5/optimize/join-index/data/index-choice-by-metapath.tsv)). While no option was universally fastest for all metapaths, on average the midpoint index was best (0.229 seconds), followed by the optimal index (0.339), and last no hint (0.656). In other words, specifying the midpoint as the join index cut runtime in third compared to not providing any join hint. Interestingly, our optimal complexity estimate performed ~50% worse than the midpoint overall.

On an individual query level, the midpoint index was the fastest index for 40% of queries, while the optimal index was the fastest index for 29% of the queries. The average rank of the fastest join index according to our complexity estimate was 2.5.

In conclusion, the optimal join index for a specific query is highly variable. For a given metapath, different compound–disease pairs will prefer different join indexes. However, since we plan to select a join index at the metapath level, the midpoint is the best option thus far.","17",2016-03-31,2016-03-31,2,2800,"base.profile","Daniel","Himmelstein","dhimmel"
"720","comments","rephetio","2016-03-31T02:42:11.987Z",17,"# Complexity poorly estimates runtime

We recently performed 22,933,125 _DWPC_ queries (136 compounds × 1,538 diseases × 1,215 metapaths × 5 hetnets). For these queries, I specified the optimal join index according to our [formula for join complexity](#5). In the future, we will switch to the midpoint join index.

Both sequential complexity and optimal index join complexity poorly predicted runtime ([notebook](http://nbviewer.jupyter.org/github/dhimmel/learn/blob/edb3cb68cb62e37ac426e39dc9196cfb279db2e7/optimize/time.ipynb)). Many of the outlier metapaths appear to contain a _Gene→regulates→Gene_ edge. Since, the target genes for these edges will largely [be restricted](http://thinklab.com/discussion/computing-consensus-transcriptional-profiles-for-lincs-l1000-perturbations/43#7) to the 978 landmark L1000 genes, I suspect mean degree is a underestimating complexity. One idea I've had is to weight the average degree calculation by degree to address this issue. In other words, should we account for the fact that queries are more likely to traverse high degree nodes when estimating complexity?","17",2016-03-31,2016-03-31,2,1111,"base.profile","Daniel","Himmelstein","dhimmel"
"721","comments","rephetio","2016-03-31T04:55:38.403Z",17,"# Permission to reuse ADEPTUS

Now that our STARGEO [analysis is ready](http://thinklab.com/discussion/stargeo-expression-signatures-for-disease-using-crowdsourced-geo-annotation/96#10), we're no longer including ADEPTUS in our hetnet. From STARGEO, we extracted differential expression signatures for 49 diseases, so integrating the signatures for the 3 diseases from ADEPTUS no longer made sense.

However, on August 29, 2015 I emailed the authors requesting permission to reuse the ADEPTUS data as I did not see a license on their [website](http://acgt.cs.tau.ac.il/adeptus/download.html). This was part of a [broader effort](http://thinklab.com/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#14) to try to comply with the copyrights and licenses of our sources.

Today, David Amar responded stating that we have permission to use the datasets in question. Specifically, he noted that the publication itself [@10.1093/nar/gkv810] grants permission to use any of their results.","17",2016-03-31,2016-03-31,2,1021,"base.profile","Daniel","Himmelstein","dhimmel"
"722","comments","rephetio","2016-04-01T21:13:21.147Z",17,"Our approach for hetnet edge prediction models the relationship between two nodes by extracting degree-weighted path counts (_DWPCs_) [@10.1371/journal.pcbi.1004259]. We use _DWPCs_, each corresponding to a different metapath, as the main features for a logistic regression classifier. Here we will investigate whether _DWPCs_ should be transformed prior to being used as predictors.

Below, we show the distribution of _DWPCs_ for randomly selected metapaths, stratified by percent of non-zero values ([notebook](https://github.com/dhimmel/learn/blob/becacbb47bed3346478a4c05beade44c165a22bd/all-features/transform.ipynb)). We look at three metapaths for each non-zero quintile. These distributions are calculated from all positives (_Compound--treats--Disease_ pairs) but only a small subset of negatives (4 times the # of positives). Since positives tend to be more connected than negatives, we expect the distribution for all compound--disease pairs to be even sparser. 

![Raw DWPC distributions](https://github.com/dhimmel/learn/raw/becacbb47bed3346478a4c05beade44c165a22bd/all-features/media/DWPC-distribution.png ""Facet strips note the non-zero quintile, metapath abbreviation, and non-zero percentage"")

Note that the y-axis (histograms counts) is heavily transformed. The _DWPC_ distribution is zero-inflated. The non-zero portion of the distribution has a long right tail, looking potentially lognormal.

My concern is that these long-tailed distributions are suboptimal for linear modeling. For example, they lead to very few extremely high predictions at the expense of all other predictions. We [observed this trend](http://het.io/disease-genes/browse/disease/?disease=DOID_12236 ""Predictions for primary biliary cirrhosis"") when we used a _DWPC_ approach for predictng gene--disease associations.

This discussion will look into whether transforming _DWPCs_ makes sense.","17",2016-04-01,2016-04-01,2,1895,"base.profile","Daniel","Himmelstein","dhimmel"
"723","comments","rephetio","2016-04-01T21:35:20.632Z",17,"# Inverse hyperbolic sine transformation

One option is to use the inverse hyperbolic sine (IHS) transformation [@10.2307/2288929 @10.2307/2332539]. The IHS transformation has [nice properties](http://worthwhile.typepad.com/worthwhile_canadian_initi/2011/07/a-rant-on-inverse-hyperbolic-sine-transformations.html ""A rant on inverse hyperbolic sine transformations""). Foremost, it's zero preserving and easy to implement. It has a single parameter, _θ_ that controls to what extent values are pulled towards 0. Here's an R implementation:

```r
ihs_transform <- function(x, theta = 1) {
  # Inverse Hyperbolic Sine transformation
  return(asinh(theta * x) / theta)
}
```

This implementation can be easily ported to Python by replacing [`asinh`](https://stat.ethz.ch/R-manual/R-devel/library/base/html/Hyperbolic.html) with [`numpy.arcsinh`](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.arcsinh.html).

Now many applications, where the values extend into the natural number range, will do fine with the default _θ_ = 1. However, since _DWPCs_ tend to be very small numbers, the IHS transformation will have a negligible effect unless we increase _θ_.

Others have discussed choosing _θ_ to [achieve normality](http://stats.stackexchange.com/a/79109/74908) using [maximum likelihood](http://stats.stackexchange.com/a/26373/74908). There is also a recent R package [`ihs`](https://cran.r-project.org/web/packages/ihs/index.html) that could be useful.

So the question becomes, what exactly do we want our transformation to do? Should we base the fitting of _θ_ only on the non-zero _DWPCs_ or on all _DWPCs_. Should we use an efficient and simple heuristic to fit _θ_ or should we go with a more intense likelihood method?","17",2016-04-01,2016-04-01,2,1756,"base.profile","Daniel","Himmelstein","dhimmel"
"724","comments","rephetio","2016-04-02T15:31:03.700Z",188,"Overall I'd say arcsin is a fine function. But to achieve your stated goals, I wonder why you didn't just use a log transformation? 

To achieve goal
1.zero preserving
2. easy to implement

x -> log(x+1)

To acheive a third goal
3. has a ""theta"" value that could be use to ""pull"" values toward zero

x-> log(ax+1) / a

The arsinh, as you know, is a linear derivative of the exponential function. And thus the inverse of this is a derivative of the log. So I guess it's unclear why you chose a derivative rather than the actual.","188",2016-04-02,2016-04-02,2,540,"base.profile","Pouya","Khankhanian","pouyakhankhanian"
"725","comments","rephetio","2016-04-02T19:05:58.165Z",17,"# Log versus IHS transformation

@pouyakhankhanian, originally I stayed away from `log1p` because because it's [practically linear](https://www.wolframalpha.com/input/?i=log(x+%2B+1)+between+0+and+1 ""log(x + 1) between 0 and 1 · WolframAlpha"") across the range of our _DWPCs_. You bring up a good point regarding scaling _DWPCs_ prior to transformation.

Yesterday, @alizee and I looked into scaling _DWPCs_ before transformation. This would eliminate the need to fit _θ_: we could use _θ_ = 1 for both the log and IHS transforms. For example, if `x` is the vector of _DWPCs_ for a single feature, we could transform using:

```r
# Standard deviation scaling
x_scale = sd(x)

# Mean absolute deviation scaling
x_scale = mad(x, center = mean(x))

# Mean scaling
x_scale = mean(x)

# Scale
x_scaled = x / x_scale

# Inverse hyperbolic sine transform
asinh(x_scaled)

# Log transform
log1p(x_scaled)
```

I think we should choose between the log and IHS methods based on which gives better performance. Regarding choosing a derivative rather than the actual, I don't view one as inherently superior, especially since the IHS has better transformation properties than the log, such as handling negatives (although this isn't an issue here).

I think we should also use performance to choose the scaling method, but with a preference for standard deviation scaling since @alizee thinks it the most versatile method.","17",2016-04-02,2016-04-02,2,1438,"base.profile","Daniel","Himmelstein","dhimmel"
"726","comments","rephetio","2016-04-02T22:16:02.980Z",17,"# Replacing MSigDB with Pathway Commons

Due to [licensing issues with MSigDB](http://thinklab.com/discussion/msigdb-licensing/108), we've removed MSigDB pathways and switched to Pathway Commons as @alexanderpico [initially suggested](#1). [Pathway Commons](http://www.pathwaycommons.org/pc2/ ""Pathway Commons 2"") aggregates pathway and binary interaction data from [many providers](http://www.pathwaycommons.org/pc2/datasources) [@10.1093/nar/gkq1039].

Pathway Commons data is [freely available](https://github.com/dhimmel/integrate/blob/e0d90e389c017dddacd98189d80ec1ffe3223c9b/licenses/custom/PathwayCommons.md), but the data is licensed under the terms of each contributing database. For example, Pathway Commons includes KEGG pathways, which have a [problematic license](https://github.com/dhimmel/integrate/blob/e0d90e389c017dddacd98189d80ec1ffe3223c9b/licenses/custom/KEGG.md). Accordingly, we only include pathways from Pathway Commons resources that are openly licensed.

Specifically, I identified only two appropriate resources from the 8 Pathway Commons resources that contribute pathways (see [notebook](https://github.com/dhimmel/pathways/blob/1bd2c68853e38297d20f8f885419ff81fc0608a8/merge-resources.ipynb) cell 7). These resources were [Reactome](http://www.reactome.org/) [@10.1093/nar/gkv1351] and the [Pathway Interaction Database](http://pid.nci.nih.gov/) (PID) [@10.1093/nar/gkn653]. Reactome is licensed as CC BY, while I believe PID data is in the public domain since it was created by US Government employees. At least the PID publication states, ""All data in PID is freely available, without restriction on use. [@10.1093/nar/gkn653]"" Since Reactome and PID contributed the [majority of MSigDB pathways](#6), I suspect that we didn't lose much information by abandoning MSigDB.

Ultimately, our updated compilation of human gene sets (`dhimmel/pathways v2.0` [@10.5281/zenodo.48810]) contains 1,862 human pathways of which 1,341 are from Reactome, 298 are from WikiPathways, and 223 are from the PID.","17",2016-04-02,2016-04-02,2,2034,"base.profile","Daniel","Himmelstein","dhimmel"
"727","comments","rephetio","2016-04-03T04:08:21.092Z",17,"# Removing MSigDB from the Rephetio project

I removed MSigDB from our project, since we haven't been able to resolve the licensing issues. It's been 186 days since we initially contacted the MSigDB team and 53 days since we were told that the IP/Licensing team had been notified and a meeting scheduled. Unfortunately, we can't wait any longer.

There are a few distinctions that make MSigDB distinct from [other resources](http://thinklab.com/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#14) where permission is pending but we continue to include. MSigDB is the [only resource](https://github.com/dhimmel/integrate/blob/daefe6e3e9a44b9fdc85cb79cee597927f119559/licenses/README.md ""Table of licenses for all sources"") with a license that explicitly forbids distribution. Additionally, the MSigDB website requires [registration](http://software.broadinstitute.org/gsea/register.jsp), although accessing the database by URL bypasses registration.

Registration makes the license into a legally binding agreement. Essentially, the registration acts as a contract, which can place additional restrictions beyond copyright. As an aside, I therefore find it misleading that the [website](http://software.broadinstitute.org/gsea/msigdb) states:

> Registration is free. Its only purpose is to help us track usage for reports to our funding agencies.

Specifically, [the license](https://github.com/dhimmel/integrate/blob/daefe6e3e9a44b9fdc85cb79cee597927f119559/licenses/custom/MSigDB.asciidoc ""MSigDB License"") contains several troubling components. First is a reporting requirement for modifications and bug fixes:

> modifications and BUG FIXES shall be provided to MIT promptly upon their creation.

While this reporting requirement only applies to the program, which we don't use, a different reporting requirement applies to database:

> As consideration for the licenses granted in this Agreement, LICENSEE agrees to provide … a written evaluation of the PROGRAM and the DATABASE, including a description of its functionality or problems and areas for further improvement in the PROGRAM or the DATABASE.

The license is very clear that distribution is prohibited. In fact, uploading the database to a private cloud service appears to violate the license:

> 2.2 No Sublicensing or Additional Rights. In no event shall LICENSEE sublicense or distribute, in whole or in part, the PROGRAM, modifications, BUG FIXES, or the DATABASE, without prior permission from MIT. LICENSEE agrees not to allow any non-employee of LICENSEE to access, view, or use the PROGRAM or the DATABASE, unless such person is an independent contractor performing services on behalf of LICENSEE. LICENSEE agrees not to put the PROGRAM or the DATABASE on a network, server, or other similar technology that may be accessed by any individual other than the LICENSEE.

As a result, using MSigDB as part of extensible open science project is not possible.

## Remedial action

I removed MSigDB from our hetnet ([commit](https://github.com/dhimmel/integrate/commit/daefe6e3e9a44b9fdc85cb79cee597927f119559)). Our hetnet no longer contains perturbation gene sets, which were from the `C2:CGP` collection. I [replaced](http://thinklab.com/discussion/adding-pathway-resources-to-your-network/72#11) the MSigDB pathways (`C2:CP` collection) using [Pathway Commons](http://www.pathwaycommons.org/). Both Pathway Commons and MSigDB include data from Reactome and the PID, but by going through Pathway Commons we were able to release those resources as CC BY and CC0.

I deleted my GitHub repository, formerly [`dhimmel/msigdb`](https://github.com/dhimmel/msigdb), for converting the database into a single user-friendly TSV. Our [website](http://het.io/disease-genes/downloads/) for a previous project contains a hetnet including MSigDB 3.0, which I posted before being aware of the licensing issue. Since this hetnet is the foundation of our prior study [@10.1371/journal.pcbi.1004259], taking it offline would be problematic for reproducibility and destructive to science. Therefore, I am not taking down this dataset unless specifically requested.

Finally, I removed the following two paragraphs from our project report draft. I'll let them serve as a eulogy:

> Pathways were extracted by combining human pathways from [WikiPathways](http://www.wikipathways.org/) [@10.1093/nar/gkv1024 @10.1371/journal.pbio.0060184] and MSigDB version 5.1 [@10.1073/pnas.0506580102 @10.1093/bioinformatics/btr260]. Perturbations were extracted from MSigDB. Each perturbation corresponds to a differential expression experiment of a chemical or genetic perturbation.

> _Perturbation–regulates–Gene_ edges are from MSigDB [@10.1073/pnas.0506580102 @10.1093/bioinformatics/btr260]. These edges represent groups of genes that responded in the same direction to a chemical or genetic perturbation. Our previous project found this indiscriminate, automated, and high-throughput method produced gene sets that together were highly informative for predicting disease–gene associations [@10.1371/journal.pcbi.1004743].

## Reflections

One issue at play is the restrictive licensing of resources that MSigDB integrates. For example, KEGG [requires](https://github.com/dhimmel/integrate/blob/daefe6e3e9a44b9fdc85cb79cee597927f119559/licenses/custom/KEGG.md) academic services to obtain a [subscription](http://www.bioinformatics.jp/docs/subscription_organizational.pdf), which stipulates that:

> Your Product or Service must not allow Your users to obtain KEGG FTP Data, except in small quantities.

Hence, portions of the MSigDB dataset do have to be licensed to forbid redistribution. Nevertheless, MIT went beyond these upstream restrictions when writing the MSigDB license. First, much of the database could likely be released openly. Second, I find the reporting requirements extreme. It's possible that MIT had a financial motivation when writing the license, as it states:

> LICENSEE agrees that neither the PROGRAM nor the DATABASE shall be used as the basis of a commercial software or hardware product

I think the MSigDB team deserves credit for making their comprehensive compilation of gene sets public. However, given the [extent of public funding](http://grantome.com/grant/NIH/R01-CA121941-10 ""See Related projects on Grantome"") this project has received, I question whether it's ethical for MIT to apply such a problematic license.

Finally I'm not deflecting responsibility: I'm the one who included a resource whose license forbids redistribution. While scientists are often poorly informed on the legality of data reuse, I think it's important to take responsibility for educating yourself. Going forward I will address licensing issues before using a new dataset to avoid similar problems.","17",2016-04-03,2016-04-03,2,6839,"base.profile","Daniel","Himmelstein","dhimmel"
"728","comments","rephetio","2016-04-04T17:41:01.777Z",23,"## A remark on asinh, log1p and derivatives

[The aim of this post is mainly to respond to @pouyakhankhanian regarding his post above] 

@pouyakhankhanian: I find your last remark interesting, but unfortunately not quite accurate as currently stated. 

(i) $$\sinh$$ is not a linear derivative of the exponential function, but a simple linear combination of it: $$ \sinh = \frac{1}{2}(e^x - e^{-x}) $$.

(ii) Further, your second sentence has no grounding: the inverse of a derivative of a function $$f$$ is definitely not the derivative of the inverse of the same $$f$$... So even if (i) was right, the result wouldn't hold. 

To see more clearly that $$log1p$$ and $$asinh$$ are not derivatives of each other, we can look at their analytical formulae:

$$$
\begin{align}
\text{log1p}(x) &= \log(1 + x)\\
\sinh^{-1}(x) &= \log(x + \sqrt{1 + x^2})
\end{align}
$$$

On a related note, we see here that both functions are very similar. This similarity is even clearer when looking at their derivatives:

$$$
\begin{align}
\text{log1p}'(x) &= \frac{1}{1 + x}\\
(\sinh^{-1})'(x) &= \frac{1}{\sqrt{1 + x^2}}
\end{align}
$$$

When [plotted](https://www.wolframalpha.com/input/?i=Plot%5B%7B1%2FSqrt%5B1+%2B+x%5E2%5D,+(1+%2B+x)%5E(-1)%7D,+%7Bx,+0,+10%7D%5D), the trend is clear. The derivative of $$\text{asinh}$$ takes some time to get into the form of $$ \frac{1}{x} $$, thus expanding the beginning of the range (for $$x \in 0..2$$) more than its counterpart.","23",2016-04-04,2016-04-04,2,1482,"base.profile","Antoine","Lizee","alizee"
"729","comments","rephetio","2016-04-05T22:49:42.917Z",23,"# The Prior Problem

The last step of our project _rephetio_ is to use our heterogeneous Network _biohetnet_ \* to create features that can predict missing edges in the Network. As the goal is to repurpose existing drugs to existing diseases, the outcome metaedge we are predicting is *treatments* (read 'treats' as a verb in our nomenclature). We tackle here a major issue that we call 'self-testing', which makes our Machine Learning approach non-conventional.

## Self-testing

For computational and semantical reasons, we currently fit our machine-learned models and report evaluated performance based on the **training** error. Indeed, our Network architecture, implementation and data currently prevents us from creating separate training and testing sets, e.g. by selectively hiding predictor and predicted edges based on time of apparition. As a result (i) predictive models are trained with features that have intrinsic knowledge of the outcome, exposing us to overfitting of these features (ii) classical performance evaluation measures (like AUROC) lose relevance and applicability.

## Source-Target Degrees as Features

We included source-target degrees as features of our edge prediction problem. The goal of this addition, as explained elsewhere, is to avoid misleading selection of DWPC features that are proxies for this basic topological information. 

In this discussion, we want to focus on treatment degrees. They can be noted $$n_{DtC}(Ci)$$ and $$n_{CtD}(D_j)$$, and represent, respectively, the number of diseases treated by a Compound $$C_i$$ (source Node) and the number of compounds that treat a Disease $$D_j$$ (target Node). We believe that these degrees, as features, crystallizes the problem of self-testing in our edge-prediction problem.

## Direct contamination

These degrees characterize with precision the (bipartite) subnetwork $$\mathcal{N}_O$$ that have only edges from the 'treatment' metaedge and source and target nodes (from the Compound and Disease metanodes). $$\mathcal{N}_O$$ contains no information apart from the actual outcomes we want to predict, and yet it is sufficient to compute all the treatment degrees $$n_{DtC}$$ and $$n_{CtD}$$. As a result, outcome observations directly 'contaminates' our features on which the models are trained and evaluated. Because these degrees are so unequally distributed (they follow a [power law](https://en.wikipedia.org/wiki/Power_law)), and since these degree features are directly linked to the probability of existence of a treatment, fitting a model with only these two degree features gives misleeading high performance numbers.

A first pass gave a AUROC above 0.97.

## Prior knowledge

The information encapsulated in these two degree features are solely characterizing the treatment edges, _as we use them for fitting and evaluation_. We are not tackling here the more general problem of knowledge bias, but the specific issue arising as a result of self-testing: actual outcome observations directly contaminates our features, inducing prior knowledge about their value (positive or negative) before any additional information being integrated in our network.

---
\* This is the first public use of the name '_biohetnet_' for our heterogeneous network that powers - in particular -the project _rephetio_. We call it a 'soft disclosure' ;-)","23",2016-04-05,2016-04-05,2,3366,"base.profile","Antoine","Lizee","alizee"
"730","comments","rephetio","2016-04-07T22:14:58.448Z",23,"# Characterizing the Prior

Removal of degree features would only obfuscate the problem at hand, since this trivial information about outcomes could be picked up in subtler ways by DWPC features. On the contrary, we found that embracing the concept of prior knowledge presented above could solve both problems of fitting and evaluating our models. We will strive here for more accurate characterization of this prior knowledge.

## Computing prior probabilities

Solely from the two treatment degree features, we can directly compute a probability of a given Compound-Disease couple to be linked by a treatment edge. 

Considering a couple $$C_i\text{-}D_j$$ where the treatment degree from the compound $$C_i$$ is known, the probability of this couple to be a treatment is equal to the number of disease $$C_i$$ is connected to divided by the total number of diseases it connects to. This can be written as:
$$$
\begin{align}
p_t(C_i\text{-}D) & = \frac{n_{CtD}(C_i)}{N_{C_i\text{-}D}} \\
p_t(C_i\text{-}D)  & = \frac{n_{CtD}(C_i)}{N_D}
\end{align}
$$$
... where $$N_{C_i\text{-}D}$$ is the total number of possible edges starting from $$C_i$$, equal to $$N_D$$ the number of Diseases in the network.

A similar formula can be derived for the Disease degrees:
$$$
\begin{align}
p_t(D_j\text{-}C)  & = \frac{n_{DtC}(D_j)}{N_C}
\end{align}
$$$

And both of these prior probabilities can be combined to get the prior probability of a given treatment edge knowing both degrees:
$$$
\begin{equation}
\boxed{p_{ij} = p_t(C_i\text{-}D_j) = \frac{n_{DtC}(C_i) \cdot n_{DtC}(D_j)}{N_D \cdot N_C}}
\end{equation}
$$$

This probability fully describes the prior knowledge about the outcome that the treatment degrees hold.


## A Null model

A null model can be specified, where the outcome for any source-target couple when predicting presence of a treatment edge is equal to the prior probability $$p_{ij}$$ above. This model is denoted $$\mathcal{M}_{prior}$$.

$$\mathcal{M}_{prior}$$, when tested on all observations, is expected to have a very high AUROC, because it successfully stratifies the population of potential edges into tiers that have increasing and radically different probabilities of being a true link. For instance, it successfully discriminates the huge majority (85%) of couples that have no chances of being a treatment edge because either the Compound and/or the Disease has a treatment degree equal to zero. 

## AUROC of the null model

Just considering this point in the ROC curve, with $$P_0 = P\left(p_{ij} = 0\right)$$ the proportion of edges that have a priori probability of zero, we can compute (for the fun) a lower bound for the AUROC that will illustrate why the expected performance is high. Every couple with prior probability of zero is ranked lower than any other couple, and each of these couples is actually a True Negative (TN) by design. Since we know that the model will be better than random for the remaining of the range of specificity, the lower bound for the AUROC of this null model is given by a simple linear interpolation based on one point we know in ROC space. 

This point corresponds to classifying only these ""absolute negatives"" that have $$p_{ij} = 0$$, as negatives. We get a sensitivity $$sens = 1$$, since all the real positives are predicted to be positives; and a specificity of 
$$$
\begin{align}
spe &= \frac{P_0}{P_0 + (1 - P_0) \cdot (1 - pre)}\\
&= \frac{P_0}{1 - pre \cdot (1 - P_0)}\\
spe &\simeq  P_0
\end{align}
$$$
with the prevalence $$pre$$ being negligible (of the order of $$10^{-4}$$).

The linear interpolation gives us:
$$$ 
\begin{align}
auroc_{min}\left(\mathcal{M}_{prior}\right) &= 1 - \frac{1 - P_0}{2}
\end{align}
$$$
With $$P_0 = 0.85 $$, we get $$ \boxed{auroc_{min}\left(\mathcal{M}_{prior}\right) = 0.925} $$ as a lower bound for the null model performance.

---

The measured AUROC of the this null model, on all observations is equal to:
$$$ auroc\left(\mathcal{M}_{prior}\right)  = 0.xxx $$$ [@dhimmel is finishing the computations]","23",2016-04-07,2016-04-07,2,4084,"base.profile","Antoine","Lizee","alizee"
"731","comments","rephetio","2016-04-07T23:43:24.684Z",23,"# Incorporating the prior in fitting and testing

## Using $$\mathcal{M}_{prior}$$ as baseline

The performance achieved by the null model $$\mathcal{M}_{prior}$$ should serve as a baseline, thus mitigating the lack of meaning of the AUROC: we'll use $$auroc(\mathcal{M}_{prior})$$ as a minimum value to improve on (instead of the usual $$auroc(\mathcal{M}_{random})= 0.5$$).

## Using $$p_{ij}$$ as covariate

Nevertheless, we also want to include as a covariate in our models this prior probability, in order to isolate the prior knowledge about the outcome it describes, and avoid selection of DWPC features that 'tag' it. 

In the framework of generalized linear regressions I propose to directly take the linear predictor that corresponds to the computed prior probability. In the case of logistic regression, the feature to use as covariate in the model would be equal to:
$$$
\begin{align}
\boxed{f_{prior}\left(C_i\text{-}D_j\right) = \text{logit}\left(p_{ij}\right)\strut}
\end{align}
$$$

## Proposed procedure

We propose an incremental approach to the fitting and evaluation of the models, going through different iteration:

$$$
\begin{align}
\text{1.} && \mathcal{M}_{prior}: \; &\text{the null model described above} \\
\text{2.} && \mathcal{M}_{deg}: \; &\delta_{CtD}  \sim f_{prior} + degrees \\
\text{3.} && \mathcal{M}_{perm}: \; &\delta_{CtD}  \sim f_{prior} + degrees + DWPC_{permuted} \\
\text{4.} && \mathcal{M}_{real}: \; &\delta_{CtD}  \sim f_{prior} + degrees + DWPC_{real} \\
\end{align}
$$$

where we use the R formula notation to specify outcomes and features of the model;
where $$\delta_{CtD} = \delta_{DtC}$$ is the outcome variable that denotes the presence of a treatment edge between a given couple of Compound and Disease; 
where '$$degrees$$' are all the source/target degree features; and
where the $$DWPC_{permuted}$$ and $$DWPC_{real}$$ are the all DWPC features computed respectively from the degree-preserving permuted network $$ \mathcal{N}_{permuted} $$ (see ***) and the full network $$\mathcal{N}$$.

We expect $$ \mathcal{M}_{deg} $$ to bring no additional predictive value than the null model $$ \mathcal{M}_{prior} $$, since the latter withholds already the best information possible at the atomicity of the source/target degrees level. For $$\mathcal{M}_{perm}$$ and $$\mathcal{M}_{real}$$, the degrees might be useful in conjunction with the DWPC features.

Testing of new or fitted data will be carried out using an arbitrary value for the prior in the models, e.g. an estimation of the prevalence.

## Redefining the training & testing sets

Finally, we propose to fit the models above only on couples that have a non-null prior probability of being a treatment edge, i.e. couples that verify both:
$$$
\left\{ 
\begin{array}{c}
n_{CtD}(C_i) > 0 \\
n_{DtC}(D_j) > 0
\end{array}
\right. 
$$$

Indeed, when the prior probability $$p_{ij}$$ is equal to zero, the points do not theoretically contribute to the fitting, whereas they practically induce complications (lack of convergence, problem with the numerical encoding of $$-\infty$$ ... ). Moreover, it gives us the opportunity to report results for the couples from the complementary set (of the couples that have a null prior), which seems quite independent from the set used for training.","23",2016-04-07,2016-04-07,2,3346,"base.profile","Antoine","Lizee","alizee"
"732","comments","rephetio","2016-04-08T13:55:13.834Z",224,"Extracting LD from 1000 genomes data is not straightforward. Here is a rough outline of the solution I came up with. I used Plink1.9 <https://www.cog-genomics.org/plink2/> and VCFTools. It will require some tweaking for specific applications.
#
Step 0: Download 1000 genomes data and remove duplicate SNP IDs
#
#
Step 1: use vcftools to generate a population specific tped file

```
vcftools --gzvcf <vcf_file> --plink-tped --keep <samples.txt> --out <tped_fh>
```
where <samples.txt> is the location of a text file with a single column of sample IDs
#
Step 2: transpose the tped file (more efficient than creating a ped file originally)

```
plink --tfile <tped_fh> --recode --threads <num_threads> --no-sex --no-pheno --out <ped_fh>
```
#
Step 3: use Plink1.9 to pull out an LD matrix

```
plink --file <vcf_file> --allow-no-sex --r2 --threads <num_threads> --ld-window-r2 <window> --chr <chromosome> --ld-snps <snp_string> --out <out_name>
```
where <snp_string> is a comma separated list of RS IDs","224",2016-04-08,2016-04-08,2,1024,"base.profile","Greg","Way","gregway"
"733","comments","thinklabOSP","2016-02-19T06:41:11.813Z",17,"Thinklab captures the benefits of making research immediately available without abandoning peer review. I think publishing delays should be play a more prominent role in the proposal.

First, publishing delays are a real pain point for scientists and solutions will be appreciated. My blog posts on the topic ([first](http://blog.dhimmel.com/plos-and-publishing-delays) and [second](http://blog.dhimmel.com/history-of-delays/)) are two of my most popular works.

With [ASAPbio](http://asapbio.org/) having just taken place [@10.1038/530265a], speeding up communication will be on peoples' minds. Harness the attention!

Delays can be split into two categories:

1. delays prior to journal submission. See [@10.1073/pnas.1511912112].
2. delays post journal submission. See [@10.1096/fj.12-0901ufm @10.1038/530148a @10.1038/523131f @10.1038/nature.2016.19375 @10.1016/j.joi.2013.09.001].

Preprints only address the second category. However, Thinklab addresses both. And the first category usually takes the majority of time. Posting projects online from their conception would bring content into the public domain years before the current publication system permits.

Any hard numbers, even if just estimates, will help readers grasp the Thinklab's potential in shortening delays.","17",2016-02-19,2016-02-19,2,1292,"base.profile","Daniel","Himmelstein","dhimmel"
"734","comments","thinklabOSP","2016-02-16T12:50:44.682Z",125,"After a first quick read through the proposal, I think the main weakness is the issue of stealing ideas. Currently, I do not feel this is addressed in a good way.

The proposal acknowledges that this will be a concern of many researchers, and that this indeed is inherent to the way the system currently works. I fully agree with that. The problem is the proposed solution: ""In our view, the solution to this predicament is clear: we need to change the rules of the game!"" In effect, what you write is that the ThinkLab approach won't work within the current system.

As a reviewer, I would tend to say that this implies that you're putting the cart before the horse. You are trying to develop a very specific tool that won't work until the whole system has been changed, which is likely to take a long time. On other words, why develop the system now? Why not focus on changing the system and worry about developing the tool, once the system makes it feasible?

(I am obviously playing devil's advocate here.)","125",2016-02-16,2016-02-16,2,1016,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"735","comments","thinklabOSP","2016-02-16T18:06:25.264Z",2,"Thanks for playing devil's advocate. I think there's a few things we need to clarify.

By ""changing the rules of the game"", we don't mean to imply that the *entire* system must change at once. Funders can change the rules of the game just for those researchers that they fund. They can require that proposals be submitted openly in the same way that they require that results must be published openly.

Basically, the idea here is that funders have a lot of power because demand for funding is so much higher than supply. Now it's possible requiring an openly submitted proposal could result in lower quality researchers applying initially -- but you could also look at it another way: the result may be that the only teams that apply are those that are confident that they are the best team for the job. An open process could save funders a huge amount of time filtering through poor proposals.

We should also clarify that we see ""changing the rules of the game"" as the *ideal* solution. Basically, we need to use language that leaves room for the possibility that we can start to persuade some grant writers to share their proposals without funders changing anything at all.","2",2016-02-16,2016-02-16,2,1183,"base.profile","Jesse","Spaulding","jspauld"
"736","comments","thinklabOSP","2016-02-17T20:03:12.524Z",125,"I agree that researchers will largely tend to follow the money, so if funders start demanding that proposals are shared in a public manner, people would do so. There are some pretty big caveats to that statement, though.

Firstly, the chance of getting promoted and getting grants also depends a lot on having good publications. There would thus till be a very strong force pulling in the opposite direction, unless both universities and funders stop looking so much at people's publication records.

Secondly, it will enforce the already a very common practice that grant proposals in fact ""plan"" to do what has already been done (but not published quite yet), and that the money are subsequently channelled into other projects, for which the PI will apply for funding later. PHD Comics explains this well: http://www.phdcomics.com/comics/archive.php?comicid=1431

It will be very hard to convince scientists to share ideas they have not even started to work on yet, in a scientific world where being the first to do something is key.","125",2016-02-17,2016-02-17,2,1041,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"737","comments","thinklabOSP","2016-02-17T23:53:02.456Z",2,"> Firstly, the chance of getting promoted and getting grants also depends a lot on having good publications. There would thus till be a very strong force pulling in the opposite direction

Yes, that's true but not sure it's a problem. Surely one good incentive and one bad one is better than 2 bad ones. Also consider that scientists are already pulled in two directions. For example they know that sharing data is good for science (pulling them to share data), but at the same time they think it may be risky for their career to do so (pulling them to hoard data).

> Secondly, it will enforce the already a very common practice that grant proposals in fact ""plan"" to do what has already been done (but not published quite yet), and that the money are subsequently channelled into other projects, for which the PI will apply for funding later. PHD Comics explains this well: http://www.phdcomics.com/comics/archive.php?comicid=1431

This is really interesting. I have heard this before but I don't think I properly appreciated the implications. If researchers have already conducted most of the research they propose to do, it takes away a significant portion of the benefit we've highlighted in having grant proposals openly reviewed. What do you think @daniel_mietchen?

> It will be very hard to convince scientists to share ideas they have not even started to work on yet, in a scientific world where being the first to do something is key.

There is one model that should overcome this problem. The only problem is it may be *even harder* to get funders to go for this one. Basically, funders would put up a pool of money to reward research idea generation in a particular area of interest. Scientists would contribute ideas (that they were not working on themselves), and there would be some kind of collaborative process to find the best ideas and then develop them into full research plans. There would then be some kind of bidding process where research groups could bid to actually conduct the research. This was actually one of my original ideas but it seemed to radical as a starting point!","2",2016-02-17,2016-02-17,2,2113,"base.profile","Jesse","Spaulding","jspauld"
"738","comments","thinklabOSP","2016-02-18T04:41:03.053Z",17,"# Incentives for open proposals

In most cases posting an open proposal will _prevent_ others from scooping you:

1. Posting the proposal establishes precedent. You will likely get cited by highly similar works.
2. Other researches are dissuaded from pursuing your idea because you could beat them to the finish line.
3. Other researchers who were considering the idea will contribute to your project rather than taking the risk of performing the project in parallel.
4. Similar concerns regarding preprints haven't played out. Preprints often bring considerable attention to a project with [few disadvantages](http://blog.dhimmel.com/preprints-2015/ ""The preprint in 2015 and what comes next"").

And if others are really better suited to perform your proposal and are willing to invest the time, then you should consider a different project because you're at high risk for being scooped regardless of whether you proposal is public.

### The internet and the visibility of your research

However, one incentive trumps all prior considerations. It's an incentive based on a mechanism few scientists understand: the nature of information propagation on the internet. 

First, page visits, attention, and incoming hyperlinks are cumulative over time: the older a piece of content, the more it will have been consumed. Once your proposal is posted, you start becoming recognized by the internet as an expert on the topic. It's a highly time dependent process -- people stumble upon content in unpredictable ways over a prolonged period of exposure.

Second, activity brings webpages to the top of feeds, increases search engine rankings, and gives consumers a dose of fresh content. When you post a proposal and continue the project openly, you harness increased online activity for your research.

Open science allows you to passively build a brand by letting your content propagate throughout the internet. And from my experience, your personal brand is far more important than journal publications for career advancement.","17",2016-02-18,2016-02-18,2,2040,"base.profile","Daniel","Himmelstein","dhimmel"
"739","comments","thinklabOSP","2016-02-18T05:10:52.574Z",17,"# Already-been-done proposals

Great point @larsjuhljensen that many grant proposals are already partially completed upon submission. In these instances, _Thinklab_'s proposal review features lose much of their appeal.

However, the _Thinklab_ model is the long term solution to already-been-done proposals. By creating a home for open proposals, _Thinklab_ creates the infrastructure to begin rewarding the posting of proposals. The [incentives for open proposals](#5) will lead to a race to propose first. The proposal curve will shift to more nascent ideas, as proposal creators rush to establish precedence.","17",2016-02-18,2016-02-18,2,615,"base.profile","Daniel","Himmelstein","dhimmel"
"740","comments","thinklabOSP","2016-02-18T05:49:59.995Z",125,"Regarding the already-been-done proposals, it is important to appreciate why researchers behave like that. In my experience, there are two major reasons:

1) The grant system is too slow. If you get an idea and apply to get funding for it, someone else will have gotten the same idea, done the job, and published the result by the time you get the money start. You thus need to have some ""money in the bank"" that allows you to start immediately when you have a great idea.

2) Rigid funding rules. The European Commission in particular has been very bad at making grants that are essentially contracts. If you don't deliver the promised deliverables, you will be in all kinds of trouble and even may have to pay back part of the money that you've already spent! Of course, if what you do is actual research, you cannot know with certainty that things will work. Unless, of course, you have already done them before you make promises.

I am not convinced that Thinklab would make people would rush to establish precedence but putting their idea out in public. It again all depends on how researchers are evaluated by e.g. universities: as long as the evaluators care about who publish first, that is what researchers will optimize for doing. This is also why researchers in most fields are still hesitant to use prepring repositories; what counts is who publishes first, not who deposits first.","125",2016-02-18,2016-02-18,2,1399,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"741","comments","thinklabOSP","2016-02-18T20:36:47.814Z",2,"@larsjuhljensen consider this: 

If funders start requiring openly posted proposals, at first this may enforce the practice of researchers ""planning"" to do what has already been done. Because if they're going to have their research ideas published on the internet they want to make sure they have a head start in getting to publish the results. I agree with this logic.

However there are a few things that would work against this I think:

1. We're asking researchers to publish their proposals openly *and* participate in a collaborative process where the community helps them improve the plan. Because this is in public it will significantly increase the awkwardness of pretending they haven't already done what they propose to do.

2. The open collaborative process I just described actually has significant benefit to the researcher. It helps them improve their research plan! And it may even identify fundamental flaws in their proposal. If the researcher has to publish their research plan *anyway*, they might as well do it before they start the research so they can benefit from the feedback.

3. If researcher A has published a research plan proposing to do X, this will *prevent* researcher B from submitting the same idea for funding. This creates an *extremely* strong incentive for researchers to publish their research ideas as soon as possible. If they don't, it means another researcher might publish the idea first and thereby prevent them from obtaining funding based on the merits of that idea.","2",2016-02-18,2016-02-18,2,1524,"base.profile","Jesse","Spaulding","jspauld"
"742","comments","thinklabOSP","2016-02-19T06:04:20.536Z",17,"The best thing about Thinklab is that it not that it solves a major problem in science but that it solves most major problems in science. Having used Thinklab for over a year now, I have experienced the plethora of benefits. However, I think the OSP proposal is lacking specificity and details. My worry is that the reviewers may not fully appreciate the platform's potential.

I have a few specific recommendations.

**Mention Thinklab's current successes:** How many projects and proposals are there currently? How many users? How many discussions? How many comments? Are there notable achievements? Are there any lessons you've learned in the past two years that are shaping your future plans?

**Infuse more examples:** There are many assertions with little evidence presented to back them up. While you may consider the statements intuitive, it will help solidify the concepts in readers' mind if there are examples. Are there past events that reinforce your vision of open science? Stories that the readers will be familiar with that Thinklab addresses? The proposal needs to be more _data driven_ and _evidence based_.

**Add citations:** I think some reviewers may desire more citations. The lack of citations and examples makes the project seem detached from the rest of the open science movement. Citations also lend credibility to your statements.

There are several repetitive statements throughout the proposal, which can be refactored out to accommodate the details.","17",2016-02-19,2016-02-19,2,1490,"base.profile","Daniel","Himmelstein","dhimmel"
"743","comments","thinklabOSP","2016-02-19T06:27:25.767Z",17,"Is there data on how long project's usually take? Ron Vale found, for example, that it now takes UCSF graduate students on average 6 years to publish their first paper [@10.1073/pnas.1511912112]. ","17",2016-02-19,2016-02-19,2,196,"base.profile","Daniel","Himmelstein","dhimmel"
"744","comments","thinklabOSP","2016-02-19T06:28:03.008Z",17,"Any examples where early feedback was beneficial or where a lack of feedback was harmful?","17",2016-02-19,2016-02-19,2,89,"base.profile","Daniel","Himmelstein","dhimmel"
"745","comments","thinklabOSP","2016-02-19T06:28:29.856Z",17,"Any examples? Open source software could be a relevant example for 2 and 3.","17",2016-02-19,2016-02-19,2,75,"base.profile","Daniel","Himmelstein","dhimmel"
"746","comments","thinklabOSP","2016-02-19T06:28:42.658Z",17,"""Needs citation"" would be nice.","17",2016-02-19,2016-02-19,2,31,"base.profile","Daniel","Himmelstein","dhimmel"
"747","comments","thinklabOSP","2016-02-19T06:28:51.589Z",17,"Missing period after citation. Also the book can be cited by DOI: [@10.1515/9781400839452] ","17",2016-02-19,2016-02-19,2,91,"base.profile","Daniel","Himmelstein","dhimmel"
"748","comments","thinklabOSP","2016-02-19T06:29:18.109Z",17,"Rather than calling it a ""big problem"", perhaps rephrase that incentives will catalyze participation. I agree here with Lars's [cart before the horse](http://thinklab.com/discussion/how-to-address-the-risk-of-stealing-ideas/161#1) comment. I believe open science is incentive compatible currently, just few realize it. I think it's important you stress that Thinklab gives people the tools to take advantage of incentives, many of which already exist and that Thinklab doesn't have to pay for. ","17",2016-02-19,2016-02-19,2,494,"base.profile","Daniel","Himmelstein","dhimmel"
"749","comments","thinklabOSP","2016-02-19T06:29:26.490Z",17,"can replace with ""became"" ","17",2016-02-19,2016-02-19,2,26,"base.profile","Daniel","Himmelstein","dhimmel"
"750","comments","thinklabOSP","2016-02-19T06:30:01.391Z",17,"Link to the [leaderboard](http://thinklab.com/leaderboard)? ","17",2016-02-19,2016-02-19,2,60,"base.profile","Daniel","Himmelstein","dhimmel"
"751","comments","thinklabOSP","2016-02-19T06:30:12.140Z",17,"This paragraph would benefit from a citation or two.","17",2016-02-19,2016-02-19,2,52,"base.profile","Daniel","Himmelstein","dhimmel"
"752","comments","thinklabOSP","2016-02-19T06:30:33.271Z",17,"Consider changing to ""the analog of a GitHub issue"" ","17",2016-02-19,2016-02-19,2,52,"base.profile","Daniel","Himmelstein","dhimmel"
"753","comments","thinklabOSP","2016-02-19T06:30:39.165Z",17,", ","17",2016-02-19,2016-02-19,2,2,"base.profile","Daniel","Himmelstein","dhimmel"
"754","comments","thinklabOSP","2016-02-19T06:30:46.002Z",17,"Not sure what you mean exactly here. This whole paragraph repeats already established concepts. ","17",2016-02-19,2016-02-19,2,96,"base.profile","Daniel","Himmelstein","dhimmel"
"755","comments","thinklabOSP","2016-02-19T06:31:02.689Z",17,"Needs citation","17",2016-02-19,2016-02-19,2,14,"base.profile","Daniel","Himmelstein","dhimmel"
"756","comments","thinklabOSP","2016-02-19T06:31:41.355Z",17,"Add citations to sources with a ""formal academic background"" as well to lend credibility to the claim.","17",2016-02-19,2016-02-19,2,102,"base.profile","Daniel","Himmelstein","dhimmel"
"757","comments","thinklabOSP","2016-02-19T06:34:39.031Z",17,"Consider citing RIO [@10.3897/rio.1.e7547]
and the five deadly sins [@10.12688/f1000research.6488.1] either here or elsewhere.
","17",2016-02-19,2016-02-19,2,127,"base.profile","Daniel","Himmelstein","dhimmel"
"758","comments","thinklabOSP","2016-02-19T06:44:20.811Z",17,"> Creation of APIs so our CC-BY content can be more easily accessed

I think this point could be expanded to creating infrastructure for internet-based scientific communication. This includes integration with other elements of the internet age scholarly stack such as:

+ indexing -- see [PeerJ's list](https://peerj.com/blog/post/115284878226/where-is-peerj-indexed/ ""Where is PeerJ indexed and archived?"")
+ RSS feeds -- see this [discussion](http://thinklab.com/discussion/rss-feed-per-project-option/55)
+ PubMed Integration
+ LOCKSS/CLOCKSS/Portico -- see [PeerJ's experience](https://peerj.com/blog/post/40018981867/long-term-archiving-and-peerj/ ""Long Term Archiving and PeerJ"")
+ Enabling bulk download of an entire project
+ Adding paper discussions to Post Publication Peer Review aggregation services.
+ Altmetrics to help track project and discussion attention -- see [this comment](http://thinklab.com/discussion/tracking-project-reuse-citation-and-publicity/113#3)
+ Search engine optimization
+ Document export to MS Word, including an export option for showing the difference between two versions.","17",2016-02-19,2016-02-19,2,1125,"base.profile","Daniel","Himmelstein","dhimmel"
"759","comments","thinklabOSP","2016-02-19T14:07:37.466Z",125,"Ad 1: I think people usually apply for funding for work that they have already done, but not published yet. Pretending to not have done it already is thus not quite so awkward as if it was published already.

Ad 2: I completely see the advantages of getting input to improve a research plan. Question is if it is sufficient to outweigh the disadvantage of risking that someone steals your idea at the stage when it is still only an idea. I would expect people to mostly share proposals that represent incremental work on their current line of research, not proposals that are based on truly novel ideas.

Ad 3: I sure hope you are wrong! If someone proposing an idea and failing to get funding were to prevent anyone else from trying to get funding for the idea, that would be a major roadblock for science. It would effectively grant monopoly on ideas.","125",2016-02-19,2016-02-19,2,857,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"760","comments","thinklabOSP","2016-02-19T15:23:58.946Z",125,"I think the key improvement that is needed is to not automatically equate ""open"" with ""better"". I know that the goal here is open science, and I am very much for open. But arguing that X is better than Y because X is open or public, is not a very convincing argument on its own. For example, it is stated as an advantage for reviewers that their reviews will be public; I'm pretty sure that if you ask reviewers, many would prefer to provide their input in a private manner.

The current proposal is a bit heavy on justifying why doing what ThinkLab does/wants to do is good. In my opinion it falls short on concretely stating what you want to do next if you get funded. The fundamental idea of the proposal is to be open and share ideas before you carry them out. Leaving out your own novel ideas that you have not been implemented yet, could thus be seen by some as a bit hypocritical.","125",2016-02-19,2016-02-19,2,889,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"761","comments","thinklabOSP","2016-02-19T18:08:22.337Z",2,"> Ad 1: I think people usually apply for funding for work that they have already done, but not published yet. Pretending to not have done it already is thus not quite so awkward as if it was published already.

Fair point, but we could simply add a checkbox that says ""I certify I have not already completed anything I am proposing to do"". The parts that they *have* already done can be stated as such. I would imagine such a checkbox would work for 90% of people -- especially when they have to carry on conversations as if it is true.

> Ad 2: I completely see the advantages of getting input to improve a research plan. Question is if it is sufficient to outweigh the disadvantage of risking that someone steals your idea at the stage when it is still only an idea. I would expect people to mostly share proposals that represent incremental work on their current line of research, not proposals that are based on truly novel ideas.

Just to be clear: getting feedback was only *one* of the incentives. The primary one being that sharing ideas at an early stage would be a requirement of getting funded. Several other meaningful incentives were described by @dhimmel [above](http://thinklab.com/discussion/how-to-address-the-risk-of-stealing-ideas/161#5). 

If a research idea is truly novel or brilliant, I could quite easily imagine a future where a large portion of respect and credit is bestowed on whoever shared it first. With that said, I do see that at the present moment a novel idea will give researchers more incentive to keep it secret. But that's okay. I believe Thinklab can be successful even with a small percentage of proposals starting to come online initially. 

Also just real quick: it's kind of become common knowledge in the startup community that people have overblown fears of their ideas being stolen, while simultaneously undervaluing the importance of sharing their ideas to get feedback. I suspect the same is true in research.

> Ad 3: I sure hope you are wrong! If someone proposing an idea and failing to get funding were to prevent anyone else from trying to get funding for the idea, that would be a major roadblock for science. It would effectively grant monopoly on ideas.

Keep in mind there is not really going to be a hard and fast rule. I'm just speculating about what will happen. If qualified research group A submits a proposal before qualified research group B, I imagine a culture norm will develop where group A gets some kind of priority. (It seems only natural.) However, if group A is *not* adequately qualified, it also seems natural that funders could choose another research group to do it. As you said, if they couldn't this would be a major problem. This would ultimately be up to funders to decide -- but they are, of course, sensitive to researcher opinion.

I think we've covered a lot of ground. One of my big takeaways is that funders really ought to take a moment and think about what they're doing. If researchers have already conducted the work they propose to do, it reveals the entire logic of their funding mechanism as a sham. If Thinklab can start working with science funders as clients, we'll be in a position to push them towards more sensible models. It's clear to me that researchers need to be in a position to share ideas when they have them, get feedback from the community immediately, and start working immediately thereafter.

Sorry for making people read so much!! Good conversation though.","2",2016-02-19,2016-02-19,2,3489,"base.profile","Jesse","Spaulding","jspauld"
"762","comments","thinklabOSP","2016-02-19T18:46:39.369Z",2,"Thanks for reviewing our proposal Lars! I really appreciate it.

I would definitely like to correct all cases where the proposal argues X is better than Y because of ""open"". I see we did a poor job of this in the section you noted.

I wrote the part about reviewer benefit with a fundamental assumption that if a scientist thinks they have something valuable to say, they'd like to be recognized by their peers for it. This would lead me to believe that if a reviewer prefers to provide input in a private manner, it's likely because they don't have much confidence their contribution improve their reputation or be seen as adding value. Do you think that is wrong? Can you shed more light on why many might prefer to provide their input in a private manner? 

> In my opinion it falls short on concretely stating what you want to do next if you get funded. 

Yes, we will try to fill this out. It's not something we really know that concretely. Basically, we've already got a working prototype -- but it needs a lot of refinement that will largely depend on user feedback and user testing. We're not hiding some additional novel idea. I think we've already got a huge amount on our plate.","2",2016-02-19,2016-02-19,2,1197,"base.profile","Jesse","Spaulding","jspauld"
"763","comments","thinklabOSP","2016-02-19T20:28:49.674Z",125,"One could easily argue that such specific input could as well be given only after funding has been obtained. ","125",2016-02-19,2016-02-19,2,109,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"764","comments","thinklabOSP","2016-02-19T20:29:01.016Z",125,"This is a strong point, but more for the general concept of open notebook science than specifically for what this proposal is about. ","125",2016-02-19,2016-02-19,2,133,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"765","comments","thinklabOSP","2016-02-19T20:29:07.804Z",125,"I understand that you want to give credit, but this is not the place to do so. You want to end on a punchline. Now you have a punchline, followed by ""oh this is actually not really our idea"". ","125",2016-02-19,2016-02-19,2,192,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"766","comments","thinklabOSP","2016-02-19T20:29:15.078Z",125,"His name is spelled Daniel Mietchen ","125",2016-02-19,2016-02-19,2,36,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"767","comments","thinklabOSP","2016-02-19T20:33:17.594Z",125,"Strange backwards phrasing that initially makes it sound as if you doubt your own goal. ""We believe science funders are in the best position to ..."" would be a much stronger opening. ","125",2016-02-19,2016-02-19,2,183,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"768","comments","thinklabOSP","2016-02-19T20:36:20.338Z",125,"Too vague. Link directly to next sentence to get to what you concrete want to attain. ","125",2016-02-19,2016-02-19,2,86,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"769","comments","thinklabOSP","2016-02-19T20:36:52.369Z",125,"Just get to the point: ""We recognize ..."" ","125",2016-02-19,2016-02-19,2,42,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"770","comments","thinklabOSP","2016-02-19T20:37:13.772Z",125,"Too long and vague. Don't tell me what you could hypothetically do. Tell me what you will do. ""In the meantime, we will do everything to drive adoption by ..."" ","125",2016-02-19,2016-02-19,2,160,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"771","comments","thinklabOSP","2016-02-19T20:37:50.277Z",125,"Too much text saying too little. Again, nice of you to give credit to who got which ideas, but it waters down your proposal. In this case, where Ben came with the fundamental idea for the proposal, you could consider making him a partner. ","125",2016-02-19,2016-02-19,2,239,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"772","comments","thinklabOSP","2016-02-19T20:38:02.600Z",125,"This section seems largely redundant with the bullet list at the very beginning of the proposal. ","125",2016-02-19,2016-02-19,2,97,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"773","comments","thinklabOSP","2016-02-19T20:39:40.576Z",125,"That depends somewhat on what I say as a reviewer. Not everything is nice to say in public.","125",2016-02-19,2016-02-19,2,91,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"774","comments","thinklabOSP","2016-02-19T20:40:10.841Z",125,"Without reading up on the overjustification effect, I do not understand this part. ","125",2016-02-19,2016-02-19,2,83,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"775","comments","thinklabOSP","2016-02-19T20:40:14.978Z",125,"This comes across as awfully patronizing! ","125",2016-02-19,2016-02-19,2,42,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"776","comments","thinklabOSP","2016-02-19T20:40:22.795Z",125,"Considering that content will be copyright of the contributors, describing it as yours may rub some people the wrong way. ","125",2016-02-19,2016-02-19,2,122,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"777","comments","thinklabOSP","2016-02-19T20:40:29.812Z",125,"Comes across as vague. How is Gleb related to ThinkLab? ","125",2016-02-19,2016-02-19,2,56,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"778","comments","thinklabOSP","2016-02-19T20:40:34.002Z",125,"there are ","125",2016-02-19,2016-02-19,2,10,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"779","comments","thinklabOSP","2016-02-19T20:40:38.720Z",125,"Having both ""enormous"" and ""massive"" so close to each other comes across as overselling. ","125",2016-02-19,2016-02-19,2,89,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"780","comments","thinklabOSP","2016-02-19T20:40:43.608Z",125,"I would leave this out. ","125",2016-02-19,2016-02-19,2,24,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"781","comments","thinklabOSP","2016-02-19T20:46:33.365Z",125,"Why would scientists not like to post reviews/comments on proposals in public?

The fundamental problem is that we typically can only allocate very short time to go through a proposal and provide input on it. Consequently, some comments will be poorly thought through, be silly mistakes due to reading too fast, be poorly phrased, and possibly full of typos. This is all fine when you send the input in an email to the person writing the proposal; they take the input that makes sense and ignores the silly mistakes and typos. But we would not feel comfortable about putting such hasty, half-baked comments online for everyone to read forever after.

Doing public open review will thus likely take more time than providing private input, due to self-imposed quality requirements.","125",2016-02-19,2016-02-19,2,783,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"782","comments","thinklabOSP","2016-02-19T21:03:01.431Z",2,"Okay great points. I will update the language to take all this into account.","2",2016-02-19,2016-02-19,2,76,"base.profile","Jesse","Spaulding","jspauld"
"783","comments","thinklabOSP","2016-02-19T22:39:08.800Z",2,"Hm, I was thinking the ideal time to form collaborations would be when ideas are still forming. I'll rephrase this a bit to be clear what it's referring to.","2",2016-02-19,2016-02-19,2,156,"base.profile","Jesse","Spaulding","jspauld"
"784","comments","thinklabOSP","2016-02-19T22:46:22.291Z",2,"I take your point. Any suggestion on where I could move this? Maybe to the beginning of this section? It shouldn't come off like we are just taking his ideas. These are all ideas derived from first principles analysis. But it seems only right to link to Daniel's work because he has been out there promoting open proposals the most.","2",2016-02-19,2016-02-19,2,332,"base.profile","Jesse","Spaulding","jspauld"
"785","comments","thinklabOSP","2016-02-19T22:46:55.360Z",2,"Crap. Embarrassing. I thought that was fixed. Sorry Daniel!","2",2016-02-19,2016-02-19,2,59,"base.profile","Jesse","Spaulding","jspauld"
"786","comments","thinklabOSP","2016-02-19T22:49:48.633Z",2,"Why do you say this waters down the proposal? I would imagine listening to the community would be seen as a good thing!","2",2016-02-19,2016-02-19,2,119,"base.profile","Jesse","Spaulding","jspauld"
"787","comments","thinklabOSP","2016-02-19T23:35:15.166Z",2,"Thanks Daniel. It's been great having you on the platform!

We will try to implement changes in all the ways you mention here.","2",2016-02-19,2016-02-19,2,128,"base.profile","Jesse","Spaulding","jspauld"
"788","comments","thinklabOSP","2016-02-20T14:43:13.983Z",125,"It is just unnecessarily wordy. From the perspective of a reviewer, I don't care who got which idea. ""There are a number of benefits to this"" says nothing that the heading ""Benefits for grant writers"" doesn't say. Last sentence says nothing that couldn't be said by just referring to the URL after the second-to-last sentence :-)","125",2016-02-20,2016-02-20,2,329,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"789","comments","thinklabOSP","2016-02-20T14:44:36.186Z",125,"In my opinion you could drop the sentence entirely and just cite reference 1 somewhere (I lack the overview to tell where).","125",2016-02-20,2016-02-20,2,123,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"790","comments","thinklabOSP","2016-02-20T14:46:46.817Z",125,"Q&A sites like SEQanswers and Biostars could be other suitable examples.","125",2016-02-20,2016-02-20,2,72,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"791","comments","thinklabOSP","2016-02-20T14:48:10.147Z",125,"That would be an excellent time indeed. It is just a problem of too generic phrasing.","125",2016-02-20,2016-02-20,2,85,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"792","comments","thinklabOSP","2016-02-21T19:03:27.353Z",17,"Consider some references on how current closed grant peer review is not very effective [@10.7554/eLife.13323]. You want to stress that funders could desperately use help in selecting which proposals to fund.","17",2016-02-21,2016-02-21,2,207,"base.profile","Daniel","Himmelstein","dhimmel"
"793","comments","thinklabOSP","2016-02-22T18:39:51.002Z",22,"Interpretation and experience: I'd suggest that the authors should interpret my review as someone who is interested in the open science movement. I'd be happy to experiment with such a proposal myself, and the UI was quite excellent. That said, I'm also skeptical about a pitch to change the overall system radically without careful experimentation and evaluation of unintended consequences.

Fund/not fund: I wouldn't fund the proposal as it stands now. I think it needs revision on the pitch side, because I'm having trouble envisioning how this works - particularly if I'm not currently reading/working on the proposal on this platform. I also think it needs revision on the measurement of impact side.

Most important advice: Imagine the audience is far more skeptical of what you're pitching than you are.","22",2016-02-22,2016-02-22,2,814,"base.profile","Casey","Greene","caseygreene"
"794","comments","thinklabOSP","2016-02-22T18:41:07.583Z",22,"I agree. Rubbed me the wrong way too.","22",2016-02-22,2016-02-22,2,37,"base.profile","Casey","Greene","caseygreene"
"795","comments","thinklabOSP","2016-02-22T18:43:40.751Z",22,"Just a heads up - the discussion phase UI is not nearly as slick as the single-person UI. I'm seeing a really crowded document where it's hard to connect the notes on the right to the content on the left.","22",2016-02-22,2016-02-22,2,204,"base.profile","Casey","Greene","caseygreene"
"796","comments","thinklabOSP","2016-02-22T18:51:01.495Z",22,"Can you start with: What would the funding process be like with thinklab? Paint a picture of the world for me. What's better in it? ","22",2016-02-22,2016-02-22,2,132,"base.profile","Casey","Greene","caseygreene"
"797","comments","thinklabOSP","2016-02-22T18:51:08.246Z",22,"Would it be helpful to specify these as things that thinklab lets you create: a Thinklab Notebook and a Thinklab Proposal. The notebook provides the tools to perform open and collaborative science, while the proposal provides you with the tools to get broad feedback on a grant.
I always find ""facilitates"" less concrete than the outputs. ","22",2016-02-22,2016-02-22,2,339,"base.profile","Casey","Greene","caseygreene"
"798","comments","thinklabOSP","2016-02-22T18:51:12.001Z",22,"This is not discussed in the proposal below. If you're not going to talk about it, I'd suggest removing it. ","22",2016-02-22,2016-02-22,2,108,"base.profile","Casey","Greene","caseygreene"
"799","comments","thinklabOSP","2016-02-22T18:51:25.566Z",22,"Why? ","22",2016-02-22,2016-02-22,2,5,"base.profile","Casey","Greene","caseygreene"
"800","comments","thinklabOSP","2016-02-22T18:51:29.097Z",22,"who is convinced? thinklab or the open science community as a whole? ","22",2016-02-22,2016-02-22,2,69,"base.profile","Casey","Greene","caseygreene"
"801","comments","thinklabOSP","2016-02-22T18:51:32.496Z",22,"How valid is this concern? How valid is it if they are already doing rigorous and reproducible research? ","22",2016-02-22,2016-02-22,2,105,"base.profile","Casey","Greene","caseygreene"
"802","comments","thinklabOSP","2016-02-22T18:51:35.664Z",22,"Enable? Do tools that do everything required already exist + you're making better, or do they not exist outside of your platform? ","22",2016-02-22,2016-02-22,2,130,"base.profile","Casey","Greene","caseygreene"
"803","comments","thinklabOSP","2016-02-22T18:51:38.546Z",22,"I think you should lead with this section. Why first. ","22",2016-02-22,2016-02-22,2,54,"base.profile","Casey","Greene","caseygreene"
"804","comments","thinklabOSP","2016-02-22T18:51:44.044Z",22,"Each of these points is somewhat long. Instead, can you flip this to describing what the workflow of open grant applications is like. You could then work in the benefits there. You don't even need to mention thinklab specifically. That could come up later. This same point applies to 1-4 here. ","22",2016-02-22,2016-02-22,2,294,"base.profile","Casey","Greene","caseygreene"
"805","comments","thinklabOSP","2016-02-22T18:51:50.761Z",22,"Could you slightly rephrase this to: Why should/will scientists participate? With the current phrase you need to make an iron clad case that people actually will do it. I don't think you have the evidence for this yet. With the re-framing, it just needs to be clear that it will be advantageous for scientists to participate. ","22",2016-02-22,2016-02-22,2,326,"base.profile","Casey","Greene","caseygreene"
"806","comments","thinklabOSP","2016-02-22T18:51:53.438Z",22,"I'd re-write this bit also as above. What does the world look like when researchers are using thinklab? Highlight the points where it's better for the scientist. ","22",2016-02-22,2016-02-22,2,162,"base.profile","Casey","Greene","caseygreene"
"807","comments","thinklabOSP","2016-02-22T18:51:57.670Z",22,"See above: why is the world better for funders - paint me a vivid picture. ","22",2016-02-22,2016-02-22,2,75,"base.profile","Casey","Greene","caseygreene"
"808","comments","thinklabOSP","2016-02-22T18:52:02.797Z",22,"A critical reviewer could easily see this as adding busywork. Funders can require a lot. If you hold the purse strings you have the power to decide what happens. This can be good or bad. Why is this good? Imagine that I'm a skeptical reader who thinks: imagine the paperwork now - even before I get the grant! ","22",2016-02-22,2016-02-22,2,310,"base.profile","Casey","Greene","caseygreene"
"809","comments","thinklabOSP","2016-02-22T18:52:07.394Z",22,"I think this belongs first, and that it should get worked into the proposed ""Why will scientists participate?"" section. ","22",2016-02-22,2016-02-22,2,120,"base.profile","Casey","Greene","caseygreene"
"810","comments","thinklabOSP","2016-02-22T18:52:11.130Z",22,"Casey Greene, a first time reviewer on this proposal, said: ""The UI is very slick!""
 ","22",2016-02-22,2016-02-22,2,85,"base.profile","Casey","Greene","caseygreene"
"811","comments","thinklabOSP","2016-02-22T18:52:15.429Z",22,"any evidence? ","22",2016-02-22,2016-02-22,2,14,"base.profile","Casey","Greene","caseygreene"
"812","comments","thinklabOSP","2016-02-22T18:52:19.019Z",22,"How do you get a proposal in front of the right reviewers to make sure that it's well reviewed. There's a lot of feeling that the twitterverse is essentially a mutual admiration society. How do you keep this from becoming that? ","22",2016-02-22,2016-02-22,2,228,"base.profile","Casey","Greene","caseygreene"
"813","comments","thinklabOSP","2016-02-22T18:52:21.536Z",22,"Who is the community here? Other scientists, etc? ","22",2016-02-22,2016-02-22,2,50,"base.profile","Casey","Greene","caseygreene"
"814","comments","thinklabOSP","2016-02-22T18:52:24.980Z",22,"Let's say I'm a grad student or postdoc with a valid critique of a grant, but everyone who posted thus far loves this thing. What's the benefit to adding my (potentially negative) comment? Conversely - what's the benefit to reacting positively to a grant that is widely viewed as negative by earlier reviewers? How do you keep feedback independent of the first people to comment. ","22",2016-02-22,2016-02-22,2,380,"base.profile","Casey","Greene","caseygreene"
"815","comments","thinklabOSP","2016-02-22T18:52:28.198Z",22,"Will there be an option for this? ","22",2016-02-22,2016-02-22,2,34,"base.profile","Casey","Greene","caseygreene"
"816","comments","thinklabOSP","2016-02-22T18:53:02.549Z",22,"Why not? What if we switch to this and thinklab fails. Would we lose the ability to apply for funding? Yikes!","22",2016-02-22,2016-02-22,2,109,"base.profile","Casey","Greene","caseygreene"
"817","comments","thinklabOSP","2016-02-22T18:53:09.006Z",22,"I think you might want to play with the ordering of this. As I read, I encountered these questions (see above) before they were addressed. Easier to read if you supply answers as the questions are raised. ","22",2016-02-22,2016-02-22,2,205,"base.profile","Casey","Greene","caseygreene"
"818","comments","thinklabOSP","2016-02-22T18:53:14.416Z",22,"Do the reviewers see a revised proposal? Is there a way for the author to mark the places where a grant changed in response to specific comments? I might be willing to come back to see my notes overlaid on changes, but I probably wouldn't if I had to manually put them side by side. ","22",2016-02-22,2016-02-22,2,283,"base.profile","Casey","Greene","caseygreene"
"819","comments","thinklabOSP","2016-02-22T18:53:20.136Z",22,"I don't have: ""Add inline comment"" Looks like it might always happen when you click ""Note"" ","22",2016-02-22,2016-02-22,2,91,"base.profile","Casey","Greene","caseygreene"
"820","comments","thinklabOSP","2016-02-22T18:53:23.725Z",22,"If you're going to put this in here - how does it work? Does the open notebook platform integrate with the open proposal platform? ","22",2016-02-22,2016-02-22,2,131,"base.profile","Casey","Greene","caseygreene"
"821","comments","thinklabOSP","2016-02-22T18:53:28.095Z",22,"for whom? ","22",2016-02-22,2016-02-22,2,10,"base.profile","Casey","Greene","caseygreene"
"822","comments","thinklabOSP","2016-02-22T18:53:31.481Z",22,"This is either an expansion or reduce. What's the purpose of including this here? If you don't have time to talk about it, I might remove it for now. You could mention it in a future directions, but is this within the scope of this grant? Feels a bit like scope creep. ","22",2016-02-22,2016-02-22,2,269,"base.profile","Casey","Greene","caseygreene"
"823","comments","thinklabOSP","2016-02-22T18:53:34.829Z",22,"I might move this above just under Scientists and Funders and call it: Why will reviewers participate? ","22",2016-02-22,2016-02-22,2,103,"base.profile","Casey","Greene","caseygreene"
"824","comments","thinklabOSP","2016-02-22T18:53:38.350Z",22,"The answer to this from reviewers could definitely be: ""no."" What if I'm busy and reviewing this proposal from an airplane where I can't focus enough to make deep comments? What if I'm without internet access? For the first: I realize we shouldn't review grants when we don't have sufficient time to think deeply, but we should acknowledge that this does happen. Would thinklab lead to fewer (but more successful) proposals reaching review panels? This could be a big selling point. ","22",2016-02-22,2016-02-22,2,483,"base.profile","Casey","Greene","caseygreene"
"825","comments","thinklabOSP","2016-02-22T18:53:41.336Z",22,"What if I'm an early career scientist, and I'm assigned Big Shot 5's grant to review? This seems like a situation with a lot of potential downside for an early career scientist. Is there a way to protect reviewers? ","22",2016-02-22,2016-02-22,2,215,"base.profile","Casey","Greene","caseygreene"
"826","comments","thinklabOSP","2016-02-22T18:53:45.793Z",22,"How does this not degenerate into a mutual admiration/criticism society? It feels like some twitter discussions certainly do. ","22",2016-02-22,2016-02-22,2,126,"base.profile","Casey","Greene","caseygreene"
"827","comments","thinklabOSP","2016-02-22T18:53:49.128Z",22,"Who gets the money? Does it go to me personally or to my science? ","22",2016-02-22,2016-02-22,2,66,"base.profile","Casey","Greene","caseygreene"
"828","comments","thinklabOSP","2016-02-22T18:53:52.583Z",22,"Though I'd say ""comments that are valuable"" - because it might be possible to write comments that peers find valuable that aren't actually. ","22",2016-02-22,2016-02-22,2,140,"base.profile","Casey","Greene","caseygreene"
"829","comments","thinklabOSP","2016-02-22T18:53:55.977Z",22,"I'm not sure that this is true. I'd say that a very small minority are already doing this. ","22",2016-02-22,2016-02-22,2,91,"base.profile","Casey","Greene","caseygreene"
"830","comments","thinklabOSP","2016-02-22T18:54:00.911Z",22,"What makes thinklab different than all of these others? Speaking of which - what is the related work to thinklab? Haven't seen it yet. ","22",2016-02-22,2016-02-22,2,135,"base.profile","Casey","Greene","caseygreene"
"831","comments","thinklabOSP","2016-02-22T18:54:05.809Z",22,"I'm still not entirely sure that the case has been made that the proposed system is better. Is it valuable because it's different, or is there some evidence that it's inherently better? ","22",2016-02-22,2016-02-22,2,186,"base.profile","Casey","Greene","caseygreene"
"832","comments","thinklabOSP","2016-02-22T18:54:09.513Z",22,"I'm honestly not entirely sure that discussing the role of money in this is helpful. Sure, it may be a way to get people to participate, but it seems like refining the specific incentive structure is an experiment that needs to be performed. With some preliminary data, you could make an argument for why this incentive structure is good. Right now, it feels like this is one of many, w/o evidence, but it feels a bit concrete. ","22",2016-02-22,2016-02-22,2,428,"base.profile","Casey","Greene","caseygreene"
"833","comments","thinklabOSP","2016-02-22T18:54:13.271Z",22,"As you can see from my comments, I was wondering about alternatives earlier. What if you worked these parts into the envisioned future bits that I discussed earlier. You could envision what the future would be like with open grant review. Then you could discuss how much of this can be done now (and how difficult it is) with existing tools if a scientist was motivated to do this. ","22",2016-02-22,2016-02-22,2,382,"base.profile","Casey","Greene","caseygreene"
"834","comments","thinklabOSP","2016-02-22T18:54:15.860Z",22,"evidence? ","22",2016-02-22,2016-02-22,2,10,"base.profile","Casey","Greene","caseygreene"
"835","comments","thinklabOSP","2016-02-22T18:54:18.313Z",22,"evidence? ","22",2016-02-22,2016-02-22,2,10,"base.profile","Casey","Greene","caseygreene"
"836","comments","thinklabOSP","2016-02-22T18:54:21.252Z",22,"This seems outside of the domain of proposal submission, which this focuses on. Can you integrate w/ github/continuous integration providers to provide a verifiable record behind figures? ","22",2016-02-22,2016-02-22,2,188,"base.profile","Casey","Greene","caseygreene"
"837","comments","thinklabOSP","2016-02-22T18:54:25.612Z",22,"There's not a lot here to judge Jesse on. The specificity level is low. ","22",2016-02-22,2016-02-22,2,72,"base.profile","Casey","Greene","caseygreene"
"838","comments","thinklabOSP","2016-02-22T18:54:29.148Z",22,"Really? Which ones. ","22",2016-02-22,2016-02-22,2,20,"base.profile","Casey","Greene","caseygreene"
"839","comments","thinklabOSP","2016-02-22T18:54:31.968Z",22,"I'm not sure that this is the case now - science definitely feels at least within-team collaborative. Can you make this a concrete example that is a bit more connected to the way things work right now? ","22",2016-02-22,2016-02-22,2,202,"base.profile","Casey","Greene","caseygreene"
"840","comments","thinklabOSP","2016-02-22T18:54:35.845Z",22,"Think of evolution: sure, existing living systems are bizarre and often seem sub-optimal but if you just start making changes to the genetic code willy-nilly, it's probably not going to make the system more efficient. How are you going to measure your impact? How will you know if this is improving or harming the process of scientific research? How you will you adjust if it turns out that items need to be changed? ","22",2016-02-22,2016-02-22,2,417,"base.profile","Casey","Greene","caseygreene"
"841","comments","thinklabOSP","2016-02-22T19:23:02.783Z",2,"Yes, I agree -- it looks a little cluttered and crazy. With regard to connecting notes and content -- you did click them right? Did you mean it's hard to see which text a comment refers to? We could try removing all other highlights when a comment is selected. That should look nice.","2",2016-02-22,2016-02-22,2,283,"base.profile","Jesse","Spaulding","jspauld"
"842","comments","thinklabOSP","2016-02-22T19:26:47.775Z",2,"Thinklab is convinced :) I take it this wasn't clear?","2",2016-02-22,2016-02-22,2,53,"base.profile","Jesse","Spaulding","jspauld"
"843","comments","thinklabOSP","2016-02-22T19:30:37.218Z",2,"Hm, I'm not really sure what you're getting at here?","2",2016-02-22,2016-02-22,2,52,"base.profile","Jesse","Spaulding","jspauld"
"844","comments","thinklabOSP","2016-02-22T19:45:23.681Z",2,"They exist, but they need to be coupled with a) a points and/or monetary system that rewards participation and b) a system that directs researcher attention to discussion that is relevant to them. I assume you're raising a concern and creating tools that already exist.","2",2016-02-22,2016-02-22,2,269,"base.profile","Jesse","Spaulding","jspauld"
"845","comments","thinklabOSP","2016-02-22T19:52:16.546Z",2,"Hm, I don't know. Let me know if you have a suggestions.","2",2016-02-22,2016-02-22,2,56,"base.profile","Jesse","Spaulding","jspauld"
"846","comments","thinklabOSP","2016-02-22T19:59:48.552Z",2,"I'm not sure what you mean here. How would you lose the ability to apply for funding? It's not open source because we are trying to create a sustainable business so that we can achieve our goal of making science much more open and collaborative.","2",2016-02-22,2016-02-22,2,245,"base.profile","Jesse","Spaulding","jspauld"
"847","comments","thinklabOSP","2016-02-22T20:02:41.472Z",2,"It's a good feature idea. When editing the proposal we can set things up so authors will save a ""commit"", and have that commit reference a particular comment. In the meantime authors can just paste in a link to the diff. I'll try to do that with this proposal.","2",2016-02-22,2016-02-22,2,260,"base.profile","Jesse","Spaulding","jspauld"
"848","comments","thinklabOSP","2016-02-22T20:05:13.887Z",2,"It's the same platform. The discussion on the proposal just becomes part of a larger discussion of the whole project as it moves forward. Is that more clear?","2",2016-02-22,2016-02-22,2,157,"base.profile","Jesse","Spaulding","jspauld"
"849","comments","thinklabOSP","2016-02-22T20:05:38.444Z",2,"For science/society.. will clarify.","2",2016-02-22,2016-02-22,2,35,"base.profile","Jesse","Spaulding","jspauld"
"850","comments","thinklabOSP","2016-02-22T20:26:30.961Z",2,"I don't think anyone would ever be *assigned* as a reviewer. People should only be reviewing if they actually have some expertise and expect their review to be of some value. We could consider adding anonymous commenting at some point in the future but in the near term it's not something we are looking at.","2",2016-02-22,2016-02-22,2,307,"base.profile","Jesse","Spaulding","jspauld"
"851","comments","thinklabOSP","2016-02-22T20:28:55.734Z",2,"Good question. The ratings are private. If it was public, I would agree: users would rate each other highly as thanks, or rate each other low as revenge.","2",2016-02-22,2016-02-22,2,153,"base.profile","Jesse","Spaulding","jspauld"
"852","comments","thinklabOSP","2016-02-22T20:30:13.173Z",2,"Personally. In theory it could go towards supporting your lab, but not everyone is in a lab. This is intended to reward participation from people outside academia as well.","2",2016-02-22,2016-02-22,2,171,"base.profile","Jesse","Spaulding","jspauld"
"853","comments","thinklabOSP","2016-02-22T20:32:22.999Z",2,"Well, unfortunately we will not be able to detect comments that peers find valuable but that are not, in fact, valuable. So yes, you can game the system by writing comments that peers think are valuable but that actually are not. LOL","2",2016-02-22,2016-02-22,2,233,"base.profile","Jesse","Spaulding","jspauld"
"854","comments","thinklabOSP","2016-02-22T20:58:20.542Z",22,"I did not realize that I could right click them. This is helpful to know. Removing other highlights would help to clarify more, but knowing about the right click bit is a huge help already.","22",2016-02-22,2016-02-22,2,189,"base.profile","Casey","Greene","caseygreene"
"855","comments","thinklabOSP","2016-02-22T20:59:45.080Z",22,"Is it valid for scientists to feel that openness is not in their interest, or do they feel this as a reaction to the state right now? Is there some downside to openness that even the right incentive structure can't fix? Is that concerned lessened if they are currently using best practices for reproducibility and rigor?","22",2016-02-22,2016-02-22,2,320,"base.profile","Casey","Greene","caseygreene"
"856","comments","thinklabOSP","2016-02-22T21:01:51.357Z",22,"Well, I'm trying to get towards whether or not you're doing a bit more than facilitating. The overall structure of this grant doesn't entirely work for me. It feels like lots of detail about thinklab up front. I want to see up front how the world will be different with thinklab in regular use.","22",2016-02-22,2016-02-22,2,294,"base.profile","Casey","Greene","caseygreene"
"857","comments","thinklabOSP","2016-02-22T21:03:17.239Z",22,"I could imagine someone wanting their grant text itself to be -ND. Would you like someone to copy a substantial amount of your grant to their own when applying for funding, even with credit?","22",2016-02-22,2016-02-22,2,190,"base.profile","Casey","Greene","caseygreene"
"858","comments","thinklabOSP","2016-02-22T21:07:46.899Z",22,"Let's say that funders adopt thinklab to manage grant review. At some point, thinklab ceases to function. Now the entire platform has to be rebuilt to maintain the same approach to review. Is there a way that you could make it open source *but* offer a hosted/turnkey solution? This would give people the peace of mind that they *could* deal with a shutdown if they had to, but I bet the barrier to entry of issuing dois/etc would let you still price reasonably aggressively.","22",2016-02-22,2016-02-22,2,475,"base.profile","Casey","Greene","caseygreene"
"859","comments","thinklabOSP","2016-02-22T21:08:45.137Z",22,"It is to me because I've interacted with @dhimmel's project. I'm not sure it'd be clear for your reviewers at this point, because they may have no idea how the notebook solution works.","22",2016-02-22,2016-02-22,2,184,"base.profile","Casey","Greene","caseygreene"
"860","comments","thinklabOSP","2016-02-22T21:09:40.943Z",22,"Might be helpful to note this very briefly.","22",2016-02-22,2016-02-22,2,43,"base.profile","Casey","Greene","caseygreene"
"861","comments","thinklabOSP","2016-02-22T21:10:05.080Z",22,":)","22",2016-02-22,2016-02-22,2,2,"base.profile","Casey","Greene","caseygreene"
"862","comments","thinklabOSP","2016-02-22T21:10:19.557Z",2,"What kind of evidence are you looking for? This is more a statement of logic: if we direct people's attention to discussion that matches their interests then we will draw more people into the conversation. Google Docs does not do that. If you want attention on your Google Doc you have to share it with people. I guess the proposal needs to better explain that a ""Thinklab Inbox"" will surface content *automatically* based on a users's interests. Relates to [this part](#section-28) of the proposal.","2",2016-02-22,2016-02-22,2,499,"base.profile","Jesse","Spaulding","jspauld"
"863","comments","thinklabOSP","2016-02-22T21:10:58.197Z",22,"Might be useful detail to add. I didn't realize the outside academia component, so this might be a good place to let readers see that vision.","22",2016-02-22,2016-02-22,2,141,"base.profile","Casey","Greene","caseygreene"
"864","comments","thinklabOSP","2016-02-22T21:12:09.242Z",2,"I will rephrase this. Simply making the point that not all conversations have to be crammed into the sidebar.","2",2016-02-22,2016-02-22,2,109,"base.profile","Jesse","Spaulding","jspauld"
"865","comments","thinklabOSP","2016-02-22T21:14:33.924Z",2,"I was referring to the incentive to keep everything secret until publishing a paper. Will clarify.","2",2016-02-22,2016-02-22,2,98,"base.profile","Jesse","Spaulding","jspauld"
"866","comments","thinklabOSP","2016-02-22T21:19:29.388Z",22,"Gotcha! I actually didn't even realize that there was a ""discussion"" beyond the sidebar until I got to the later categorization part.","22",2016-02-22,2016-02-22,2,133,"base.profile","Casey","Greene","caseygreene"
"867","comments","thinklabOSP","2016-02-22T21:20:00.546Z",22,"What the the incentives though? Is it inertia or are there actual incentives?","22",2016-02-22,2016-02-22,2,77,"base.profile","Casey","Greene","caseygreene"
"868","comments","thinklabOSP","2016-02-22T22:19:23.749Z",2,"@caseygreene made an [inline comment](http://thinklab.com/doc/12/review#89) on this proposal text:

> Given a [wide variety of problems](http://thinklab.com/blog/10-consequences-of-a-broken-scientific-reward-system/36) in our current scientific system, isn't it worth experimenting with ways we might improve it?

He says:

> Think of evolution: sure, existing living systems are bizarre and often seem sub-optimal but if you just start making changes to the genetic code willy-nilly, it's probably not going to make the system more efficient. How are you going to measure your impact? How will you know if this is improving or harming the process of scientific research? How you will you adjust if it turns out that items need to be changed?

There's two points I want to make:

1. I see no evidence or reason to think that our scientific system has been optimized by an evolutionary process. Living systems don't have [this many](http://thinklab.com/blog/10-consequences-of-a-broken-scientific-reward-system/36) flaws. What is the mechanism by which evolutionary forces are working? I will grant you that things are *slowly* moving in the right direction. But damn. Why has it taken science funders like *20 years* to figure out that requiring scientists to publish the results of their research open access would be a good thing?

2. We are not making changes willy-nilly. We explained why having grant proposals reviewed in the open would be a good thing. Then we proposed funders create grants program that require openly posted proposals, and we proposed funders create an incentive for scientists everywhere to share feedback and insights on those proposals. It's all very logical. Science funders should create incentivizes for behavior that is good for science and society as a whole.

Let me know if you have further thoughts.","2",2016-02-22,2016-02-22,2,1850,"base.profile","Jesse","Spaulding","jspauld"
"869","comments","thinklabOSP","2016-02-22T22:20:26.031Z",2,"I see this proposal has completely failed to persuade you. I posted a response here: [Has our scientific system been optimized by an evolutionary process?](http://thinklab.com/discussion/has-our-scientific-system-been-optimized-by-an-evolutionary-process/170)","2",2016-02-22,2016-02-22,2,259,"base.profile","Jesse","Spaulding","jspauld"
"870","comments","thinklabOSP","2016-02-22T22:23:47.549Z",22,"My main point was less around the process that generated our current system, and more towards an interest in metrics that you will use to assess your changes. How are you going to measure the impact of thinklab? How will you determine whether its influence is positive or negative for the practice of science? I think these are key elements to address in the proposal.","22",2016-02-22,2016-02-22,2,368,"base.profile","Casey","Greene","caseygreene"
"871","comments","thinklabOSP","2016-02-22T22:25:48.867Z",22,"I tried to read this as a skeptical grant reviewer. I actually like what you're doing, and I view your contributions positively. I wanted to give feedback that I thought would help you slightly reframe your proposal to make it more compelling to the interested but skeptical.","22",2016-02-22,2016-02-22,2,275,"base.profile","Casey","Greene","caseygreene"
"872","comments","thinklabOSP","2016-02-22T22:31:24.686Z",2,"It's a good question. Unfortunately, I'm not sure there is an obvious answer. I think it will just be a general sense amongst participants and observers of how much impact the research is having.","2",2016-02-22,2016-02-22,2,195,"base.profile","Jesse","Spaulding","jspauld"
"873","comments","thinklabOSP","2016-02-22T22:35:58.265Z",2,"Thank you. I really appreciate you taking the time!","2",2016-02-22,2016-02-22,2,51,"base.profile","Jesse","Spaulding","jspauld"
"874","comments","thinklabOSP","2016-02-22T22:45:01.581Z",2,"Well they are concerned about people taking their ideas and publishing something first. This gets even more concerning if we're asking people to share *proposals*. I do think these concerns are overblown but nonetheless they are there. And I do believe there are many benefits to the researcher for being open that aren't fully appreciated. And yes, inertia, that's big.","2",2016-02-22,2016-02-22,2,370,"base.profile","Jesse","Spaulding","jspauld"
"875","comments","thinklabOSP","2016-02-22T22:48:28.528Z",2,"Actually I never thought about having money go towards supporting the person's lab. It's something that could definitely be done that way if that's what funders want. (At least for those affiliated with a lab.)","2",2016-02-22,2016-02-22,2,210,"base.profile","Jesse","Spaulding","jspauld"
"876","comments","thinklabOSP","2016-02-22T23:01:02.035Z",2,"argh.. I still don't get what you're saying :( Are you suggesting that many scientists *feel* it is not in their personal interests, but in reality it is? (Because they don't fully appreciate the benefits?) Anyway, the point here is to lead into a statement that Thinklab's goal is to create incentives for scientists so they *do* feel it is in their interests.","2",2016-02-22,2016-02-22,2,361,"base.profile","Jesse","Spaulding","jspauld"
"877","comments","thinklabOSP","2016-02-22T23:09:41.556Z",22,"Sorry - I'm not doing a good job of this. Inherently in science is there some value at some time to a system that doesn't require everything to be open. Does it help people take risks/etc that they wouldn't take in an open system?

An alternative is that most people are closed right now because things are hyper-competitive or that this is the way things have always been.

If the second case is true, then I'm going to look for solutions that maximize openness because they're good for science in the long run. If the former is true, I'm going to look for things that promote openness but don't necessarily require it in all cases.

I don't have an answer. This question just came to mind when reading this part.","22",2016-02-22,2016-02-22,2,714,"base.profile","Casey","Greene","caseygreene"
"878","comments","thinklabOSP","2016-02-22T23:10:45.154Z",22,"Well - in this case my inclination would be to say that the incentive could go towards an individual or their research program, which allows academics with labs and members of the public without labs to participate.","22",2016-02-22,2016-02-22,2,215,"base.profile","Casey","Greene","caseygreene"
"879","comments","thinklabOSP","2016-02-22T23:11:12.379Z",2,"No. I'll change the language to be less matter of fact.","2",2016-02-22,2016-02-22,2,55,"base.profile","Jesse","Spaulding","jspauld"
"880","comments","thinklabOSP","2016-02-22T23:13:08.610Z",22,"What about using the term ""challenges"" and highlighting ""inertia"" and ""fear""? Incentives (particularly aligning with how the term is used in this grant) feels like someone is paying scientists to be closed.","22",2016-02-22,2016-02-22,2,206,"base.profile","Casey","Greene","caseygreene"
"881","comments","thinklabOSP","2016-02-22T23:15:40.839Z",2,"Yes, well there has to be a lot of reward! I imagine you're reviewing this as a favor, because you've used Thinklab before, and because you'll be working with @dhimmel soon. But generally it is really hard to get people to take time away from their own work to give feedback. That's why I think funders should *pay* people for it. On top of that we add an impact points system so people feel they are being recognized appropriately.","2",2016-02-22,2016-02-22,2,432,"base.profile","Jesse","Spaulding","jspauld"
"882","comments","thinklabOSP","2016-02-22T23:17:33.129Z",22,"Do I invite people, do the funders invite people, or do people self select? That was the bit that I was a bit unclear on.","22",2016-02-22,2016-02-22,2,121,"base.profile","Casey","Greene","caseygreene"
"883","comments","thinklabOSP","2016-02-22T23:32:09.008Z",2,"Hm, I don't know. The main concern of open sourcing now would be that a group of academics would decide this shouldn't be run as a for-profit company. They would be able to *quickly* launch an identical service and because of it's existence few people would signup on Thinklab. I believe it would also make it *very hard* for us to get funding from traditional investors. I will just say that we much prefer to have ""impact investors"" involved but the reality is we need to keep our options open at this point.","2",2016-02-22,2016-02-22,2,510,"base.profile","Jesse","Spaulding","jspauld"
"884","comments","thinklabOSP","2016-02-22T23:36:36.285Z",22,"I see - makes sense! It probably wouldn't hurt to keep thinking about this in case there's a way to make it work. I could see some trepidation around the current setup. Perhaps there's a way to ameliorate that without removing your ability to find traditional investors. I'll try to keep thinking too.","22",2016-02-22,2016-02-22,2,301,"base.profile","Casey","Greene","caseygreene"
"885","comments","thinklabOSP","2016-02-22T23:37:03.944Z",2,"Will remove","2",2016-02-22,2016-02-22,2,11,"base.profile","Jesse","Spaulding","jspauld"
"886","comments","thinklabOSP","2016-02-23T01:22:04.051Z",17,"I do think scientific publishing, like all systems, evolves. However, I don't think this discussion will add to the proposal or @caseygreene's comment.

I read @caseygreene's comment as _the proposal doesn't provide convincing evidence that the changes will be beneficial and doesn't offer a framework for assessing the benefits_. This comment falls in line with [my general feedback](http://thinklab.com/discussion/review-summary/164) that the proposal needs  to be more evidence based and quantitative.

@jspauld, regarding ""we are not making changes willy-nilly"" -- you need to establish this point in the proposal not via discussion, since the proposal alone will determine the winner of the open science prize. Reviewer feedback and counterpoints only matter if they affect the proposal. In other words, @caseygreene's comment has no relevance beyond how it instructs you to improve the proposal.","17",2016-02-23,2016-02-23,2,905,"base.profile","Daniel","Himmelstein","dhimmel"
"887","comments","thinklabOSP","2016-02-23T04:13:00.025Z",2,"**Regarding measuring impact:**

I don't believe there is any good evidence based or quantitative metric for determining the impact that Thinklab may have. Measuring scientific impact is just really difficult. The idea that we measure a scientists impact by the number of papers they publish is at the very core of the problem we are trying to solve. So we're certainly not going to use that metric! 

On Thinklab we measure impact via direct peer assessment of the value added by each contribution. The best way I can imagine that we could measure the impact of Thinklab as a whole would be to simply ask the people that have used and observed the platform. But we are not going to be able to ask them until we actually try it! That's why I highlighted the importance of doing experiments at the end of the proposal.","2",2016-02-23,2016-02-23,2,821,"base.profile","Jesse","Spaulding","jspauld"
"888","comments","thinklabOSP","2016-02-23T05:31:41.218Z",125,"I very much share @caseygreene concern on this. It can be outright deadly to the career of a young scientist to publicly criticize a big shot. At the same time, the vast majority of scientists are early career scientists. If one cannot find a mechanism to protect them, one will very quickly run out of reviewers.","125",2016-02-23,2016-02-23,2,313,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"889","comments","thinklabOSP","2016-02-23T05:36:05.166Z",125,"Giving the money personally is certainly the strongest incentive. This does bring a few ethical and practical challenges, though. Is it fair that I spent work hours on reviewing for ThinkLab instead of working for my employer? Or does this turn reviewing into a side job? Do all universities allow their researchers to have side jobs?","125",2016-02-23,2016-02-23,2,334,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"890","comments","thinklabOSP","2016-02-23T05:38:12.481Z",2,"Yeah, maybe cross those bridges when we get there :)","2",2016-02-23,2016-02-23,2,52,"base.profile","Jesse","Spaulding","jspauld"
"891","comments","thinklabOSP","2016-02-23T05:56:30.401Z",2,"Okay I get it! You mean scientists have reasons for not be open that are valid in the sense that forcing them to be open would be bad for science as a whole. There may be. Although I suspect those benefits are far outweighed by the benefits of being open in most cases. It's something to keep in mind","2",2016-02-23,2016-02-23,2,300,"base.profile","Jesse","Spaulding","jspauld"
"892","comments","thinklabOSP","2016-02-23T06:03:48.232Z",2,"Right now it's up to the authors to invite people. However, with funders involved that could change. I imagine it will always be open for self selected commenters as well.","2",2016-02-23,2016-02-23,2,171,"base.profile","Jesse","Spaulding","jspauld"
"893","comments","thinklabOSP","2016-02-24T02:03:23.213Z",25,"I cannot comment on whether this proposal should be funded or not in the context of this Prize.

A topic I found lacking is version history.","25",2016-02-24,2016-02-24,2,142,"base.profile","Daniel","Mietchen","daniel_mietchen"
"894","comments","thinklabOSP","2016-02-24T02:12:20.491Z",25,"This could be resolved by using ""by default"" as a qualifier for the entire process being open. There are numerous conditions under which openness isn't an option even if the scientists would want it (think patient privacy, locations of near-extinct species or archeological sites in danger of being looted).","25",2016-02-24,2016-02-24,2,307,"base.profile","Daniel","Mietchen","daniel_mietchen"
"895","comments","thinklabOSP","2016-02-24T02:16:45.288Z",25,"Collaboration can form at any point in principle. Laying out the research process in detail renders more of those points discoverable by potential collaborators.","25",2016-02-24,2016-02-24,2,161,"base.profile","Daniel","Mietchen","daniel_mietchen"
"896","comments","thinklabOSP","2016-02-24T02:19:23.968Z",25,"No need to mention my name. A good place to reference such related efforts might be right after ""Thinklab is intended for broad use across all of science, including biomedical research."" above.","25",2016-02-24,2016-02-24,2,193,"base.profile","Daniel","Mietchen","daniel_mietchen"
"897","comments","thinklabOSP","2016-02-24T02:23:15.712Z",25,"Versioning would be useful for such cases, and a mechanism for removing comments that do not apply to later versions any more.","25",2016-02-24,2016-02-24,2,126,"base.profile","Daniel","Mietchen","daniel_mietchen"
"898","comments","thinklabOSP","2016-02-24T02:24:07.872Z",25,"Agreed.","25",2016-02-24,2016-02-24,2,7,"base.profile","Daniel","Mietchen","daniel_mietchen"
"899","comments","thinklabOSP","2016-02-24T02:27:56.561Z",25,"Key point here could be that many of the bureaucratic layers have been built to address issues that do not manifest themselves the same way in open science, so if tackled properly, open science (a stick for many, a carrot for some) could actually be combined with a reduction in red tape, which should be a carrot for every researcher.","25",2016-02-24,2016-02-24,2,335,"base.profile","Daniel","Mietchen","daniel_mietchen"
"900","comments","thinklabOSP","2016-02-24T02:29:42.403Z",25,"Agree.","25",2016-02-24,2016-02-24,2,6,"base.profile","Daniel","Mietchen","daniel_mietchen"
"901","comments","thinklabOSP","2016-02-24T02:37:30.630Z",25,"There may sometimes be benefits in both of these scenarios, but they might require a specific bit of knowledge (or occasionally even ignorance of mainstream views). I'd expect it to be more common, though, that if reviewers 1-3 agree, others would pile on comments that essentially amount to ""+1"".","25",2016-02-24,2016-02-24,2,297,"base.profile","Daniel","Mietchen","daniel_mietchen"
"902","comments","thinklabOSP","2016-02-24T02:39:39.612Z",25,"I don't think anything more restrictive should be allowed, but CC0 would be nice.","25",2016-02-24,2016-02-24,2,81,"base.profile","Daniel","Mietchen","daniel_mietchen"
"903","comments","thinklabOSP","2016-02-24T02:42:36.106Z",2,"I think it is risk/reward too. If 3 reviewers agree and a young grad student offers a dissenting opinion with a convincing argument that persuades the first 3 reviewers, this young grad student would gain a lot of respect (I would imagine).","2",2016-02-24,2016-02-24,2,240,"base.profile","Jesse","Spaulding","jspauld"
"904","comments","thinklabOSP","2016-02-24T02:43:42.980Z",25,"Yeah, same here - is the figure showing an earlier UI?","25",2016-02-24,2016-02-24,2,54,"base.profile","Daniel","Mietchen","daniel_mietchen"
"905","comments","thinklabOSP","2016-02-24T02:54:50.742Z",2,"There actually can be versions -- and in the new version your name will be corrected :) All of these inline review comments are tied to this particular version.","2",2016-02-24,2016-02-24,2,160,"base.profile","Jesse","Spaulding","jspauld"
"906","comments","thinklabOSP","2016-02-24T03:01:20.205Z",25,"The road to openness is not all about fear. Intelligent comments on some big shot's stuff might actually get a newbie attention in a space where they currently get basically none, and if that attention becomes unpleasant, they might possibly have a better handle on it than in the current closed system. Plus, an open system would do the sorting into big shots and others in a more meritocratic way than the current system. The challenge is to find good ways to navigate these spaces. Are there examples from open-source that might be instructive in this context?","25",2016-02-24,2016-02-24,2,563,"base.profile","Daniel","Mietchen","daniel_mietchen"
"907","comments","thinklabOSP","2016-02-24T03:08:02.806Z",25,"I can see numerous scenarios in which either the lab or the individual might not be in a position to accept the money (perhaps even both), but in some cases, it might work well. It's important to be flexible here, e.g. to allow active reviewers to have a say in how funds are spent in their broader area, or to donate their monetary rewards to some good cause (think a fund for minority scientists or so).","25",2016-02-24,2016-02-24,2,405,"base.profile","Daniel","Mietchen","daniel_mietchen"
"908","comments","thinklabOSP","2016-03-01T11:30:45.119Z",68,"I love everything about thinklab, except for this. Not being F/OSS is a dealbreaker for me. No way am I going to contribute to a platform that locks me in. F/OSS is completely separate from your ability to make a decent profit.","68",2016-03-01,2016-03-01,2,227,"base.profile","Michael","Crusoe","michael_r_crusoe"
"909","comments","thinklabOSP","2016-03-01T16:54:32.659Z",2,"@michael_r_crusoe the content on Thinklab is CC-BY. In what sense are you locked in? And in what sense would you not be locked in if the Thinklab code was F/OSS?","2",2016-03-01,2016-03-01,2,161,"base.profile","Jesse","Spaulding","jspauld"
"910","notes","meta","2015-01-16T20:40:50.876Z",17,"Meta link is broken. Also, perhaps a feature so I can delete this note once the issue is fixed.","17",2015-01-16,2015-01-16,1,95,"base.profile","Daniel","Himmelstein","dhimmel"
"911","notes","meta","2015-01-19T01:00:04.382Z",2,"Fixed. For now the plan is to wait and see how often it's requested to be able to delete a note. I don't think it's something we want happening a lot. Although, if people are free to edit their comments it makes sense that they could delete it as well.","2",2015-01-19,2015-01-19,1,252,"base.profile","Jesse","Spaulding","jspauld"
"912","notes","meta","2015-01-19T01:47:22.814Z",17,"I still get a 'ERR_EMPTY_RESPONSE' error when clicking [Meta](http://thinklab.com/p/meta). I was thinking, once these bugs are fixed, we could delete these messages, but I'm fine with the messages staying online.","17",2015-01-19,2015-01-19,1,212,"base.profile","Daniel","Himmelstein","dhimmel"
"913","notes","meta","2015-01-23T18:11:30.784Z",2,"Yes, you can. If you click your profile image in the top right of the screen you will see a menu. Click 'Account'. This UI is being used by others, such as Twitter. But, I don't actually think it's that intuitive -- so, may change it.","2",2015-01-23,2015-01-23,1,234,"base.profile","Jesse","Spaulding","jspauld"
"914","notes","meta","2015-01-23T18:13:34.531Z",2,"This should be fixed. Can you try again with one of the images that didn't work?","2",2015-01-23,2015-01-23,1,80,"base.profile","Jesse","Spaulding","jspauld"
"915","notes","meta","2015-01-23T18:23:27.088Z",2,"Thanks for the feedback. The preview of the resource may not be possible. However, we should be able to come up with a better UX for those who want to go directly to the link (most people). Will work on it..","2",2015-01-23,2015-01-23,1,207,"base.profile","Jesse","Spaulding","jspauld"
"916","notes","meta","2015-01-23T18:26:25.163Z",2,"I actually fixed a different Meta link. Now both are fixed. As trivial as this conversation is I think it's best to leave it :)","2",2015-01-23,2015-01-23,1,127,"base.profile","Jesse","Spaulding","jspauld"
"917","notes","meta","2015-01-23T19:23:37.809Z",23,"Okay I should've dig a bit further to understand ""account"" and ""profile"" settings are different. It's not that counter-intuitive, but adding a link to the account settings in the profile editing pane and vice-versa would be nice. Or just two tabs? Thanks for the quick answer.","23",2015-01-23,2015-01-23,1,276,"base.profile","Antoine","Lizee","alizee"
"918","notes","meta","2015-01-23T19:37:23.827Z",23,"It works now, thanks. But I need to refresh the profile page to see the modifications.","23",2015-01-23,2015-01-23,1,86,"base.profile","Antoine","Lizee","alizee"
"919","notes","meta","2015-01-26T14:19:02.943Z",17,"> @dhimmel do you feel like this feature would be valuable right away? Right now I'm thinking to wait until there is more activity on the site.

I think holding off on the feature could be the right move -- we'll come up with better solutions once discussion visibility actually becomes a *problem*.","17",2015-01-26,2015-01-26,1,299,"base.profile","Daniel","Himmelstein","dhimmel"
"920","notes","meta","2015-01-26T17:57:30.714Z",2,"Good point. I think we'll try with that then.","2",2015-01-26,2015-01-26,1,45,"base.profile","Jesse","Spaulding","jspauld"
"921","notes","meta","2015-01-26T17:58:32.581Z",2,"Solid argument!","2",2015-01-26,2015-01-26,1,15,"base.profile","Jesse","Spaulding","jspauld"
"922","notes","meta","2015-02-17T03:04:44.103Z",17,"@jspauld, the new display format and linking system for references is a big improvement. Some suggestions:

+ the tooltip that appears when hovering over a references disappears when I move my mouse over it (so I cannot click links or copy text).
+ the author list is overly punctuated. I prefer the sparsely punctuated format of ""Wei WQ, Cronin RM, ..."".
+ consider journal names in italic
+ consider article names in bold or underlined
+ consider implementing in [citation style language](http://citationstyles.org/) and [sharing](https://github.com/citation-style-language/styles), so I can use the style for my RMarkdown documents.","17",2015-02-17,2015-02-17,1,635,"base.profile","Daniel","Himmelstein","dhimmel"
"923","notes","meta","2015-02-17T06:04:54.324Z",17,"The counterargument that ""git checkout --"" should be `git checkout --` is convincing to me. GitHub markdown has additional limitations, such as no formulas, that are not present in TLFM. ","17",2015-02-17,2015-02-17,1,187,"base.profile","Daniel","Himmelstein","dhimmel"
"924","notes","meta","2015-02-17T06:09:50.271Z",17,"I start from the premise that TLFM should be capable of publication quality output. This is likely not the case for Discourse, Stackoverflow, or GitHub.","17",2015-02-17,2015-02-17,1,152,"base.profile","Daniel","Himmelstein","dhimmel"
"925","notes","meta","2015-02-17T07:30:28.156Z",2,"Good points. I think we'll start with doing something with the titles and then go from there.","2",2015-02-17,2015-02-17,1,93,"base.profile","Jesse","Spaulding","jspauld"
"926","notes","meta","2015-02-17T18:43:03.681Z",2,"Changed","2",2015-02-17,2015-02-17,1,7,"base.profile","Jesse","Spaulding","jspauld"
"927","notes","meta","2015-02-25T19:33:32.008Z",2,"Good catch! Yes, they were evaluated case sensitive. This should be fixed now.","2",2015-02-25,2015-02-25,1,78,"base.profile","Jesse","Spaulding","jspauld"
"928","notes","meta","2015-02-25T20:08:30.122Z",2,"Lol. It says you're looking out for your own interests -- like the rest of us. We can forgive you.","2",2015-02-25,2015-02-25,1,98,"base.profile","Jesse","Spaulding","jspauld"
"929","notes","meta","2015-02-27T20:43:33.768Z",17,"@jspauld, perhaps we should be able to associate multiple publications with a single discussion. For example, many resources have an initial publication and periodical update publications. Or a discussion could compare two resources and therefore be applicable to both.

It would also be helpful for publication pages to link out to all citing pages.","17",2015-02-27,2015-02-27,1,350,"base.profile","Daniel","Himmelstein","dhimmel"
"930","notes","meta","2015-03-01T00:18:13.417Z",2,"@dhimmel Agree with your points and will work on it.","2",2015-03-01,2015-03-01,1,52,"base.profile","Jesse","Spaulding","jspauld"
"931","notes","meta","2015-03-17T19:34:51.341Z",2,"Will fix. We forgot to update that when we added author ordering to ThinkLab.","2",2015-03-17,2015-03-17,1,77,"base.profile","Jesse","Spaulding","jspauld"
"932","notes","meta","2015-03-31T23:27:50.330Z",2,"@dhimmel Most of your suggestions have been implemented. Publication pages now link out to all citing pages, and I've created a [separate post](http://thinklab.com/discussion/new-citation-features/45) about that.","2",2015-03-31,2015-03-31,1,212,"base.profile","Jesse","Spaulding","jspauld"
"933","notes","meta","2015-04-02T17:23:54.526Z",17,"@jspauld, I am getting a database error when I try to change the publication associated with a [discussion](http://thinklab.com/discussion/processing-labeledin-to-extract-indications/46).","17",2015-04-02,2015-04-02,1,187,"base.profile","Daniel","Himmelstein","dhimmel"
"934","notes","meta","2015-04-02T20:33:06.259Z",2,"@dhimmel should be fixed now. Please ignore the last message -- I was mistakenly still logged in as you.","2",2015-04-02,2015-04-02,1,104,"base.profile","Jesse","Spaulding","jspauld"
"935","notes","meta","2015-04-05T00:56:25.045Z",2,"Author ordering with Crossref has now been corrected.","2",2015-04-05,2015-04-05,1,53,"base.profile","Jesse","Spaulding","jspauld"
"936","notes","meta","2015-04-13T23:34:50.357Z",2,"Great, I've added it to our to do list.","2",2015-04-13,2015-04-13,1,39,"base.profile","Jesse","Spaulding","jspauld"
"937","notes","meta","2015-04-29T09:12:30.394Z",23,"To be noted: there is a utility to visualize html files from github repositories: http://htmlpreview.github.io/ I found it very useful to share reports that are compiled directly in the projects (using R Markdown for instance).","23",2015-04-29,2015-04-29,1,227,"base.profile","Antoine","Lizee","alizee"
"938","notes","meta","2015-04-29T17:27:03.035Z",23,"I agree with Jesse on the link behavior. It's easy enough to hold cmd/ctrl if you want a new tab!","23",2015-04-29,2015-04-29,1,97,"base.profile","Antoine","Lizee","alizee"
"939","notes","meta","2015-04-30T19:59:16.797Z",17,"Regarding comment/note deletion, [see the subsequent discussion](http://thinklab.com/discussion/comments-notes-interface-and-behaviour-suggestions/60) by @alizee.","17",2015-04-30,2015-04-30,1,162,"base.profile","Daniel","Himmelstein","dhimmel"
"940","notes","meta","2015-05-01T18:21:07.596Z",23,"I agree on the limited usage of notes so far. Adding the upvotable feature might be premature.","23",2015-05-01,2015-05-01,1,94,"base.profile","Antoine","Lizee","alizee"
"941","notes","meta","2015-05-01T18:21:28.292Z",23,"What do you mean by ""structure""?","23",2015-05-01,2015-05-01,1,32,"base.profile","Antoine","Lizee","alizee"
"942","notes","meta","2015-05-01T18:22:29.041Z",23,"On a related note, I agree that ""comment"" might not be the right term for the posts on ThinkLab.","23",2015-05-01,2015-05-01,1,96,"base.profile","Antoine","Lizee","alizee"
"943","notes","meta","2015-05-01T18:29:37.729Z",55,"What do I mean by ""structure""?
That's a very good question since I carry a lot of tacit thoughts that really need to come out.
My thinking is this: this ""thread"" is essentially a linear list. It's a conversation sequenced temporally. With careful use of @thingies, one can add just a bit of structure. The fact that I am replying to an indented set of comments on my comment, there already is structure, though I was not allowed to indent my comment against those comments, so structure, as implemented here, has its limits. I'll start a new, um, comment, about structure.","55",2015-05-01,2015-05-01,1,572,"base.profile","Jack","Park","jackpark"
"944","notes","meta","2015-05-03T21:02:08.323Z",23,"I'm in favor of the mandatory field for deletion.","23",2015-05-03,2015-05-03,1,49,"base.profile","Antoine","Lizee","alizee"
"945","notes","meta","2015-05-03T21:02:25.624Z",23,"Of course, deletion of thread-making posts should not be possible.","23",2015-05-03,2015-05-03,1,66,"base.profile","Antoine","Lizee","alizee"
"946","notes","meta","2015-05-05T00:33:57.780Z",17,"The `htmlpreview` bug I experienced was due to mixed content. This issue was [recently reported](https://github.com/htmlpreview/htmlpreview.github.com/issues/32) on GitHub, so a fix may be in the works.","17",2015-05-05,2015-05-05,1,202,"base.profile","Daniel","Himmelstein","dhimmel"
"947","notes","meta","2015-05-05T22:24:30.228Z",5,"I thnk it is a bit risky to say ""Improve your odds of NIH/NSF funding"" ... seems possible but not proven","5",2015-05-05,2015-05-05,1,104,"base.profile","Jonathan","Eisen","jonathaneisen"
"948","notes","meta","2015-05-06T06:05:28.379Z",2,"Thanks for your comments and links Daniel! We will certainly publish any suggestions we have for the NIH as far as removing any red tape or supporting open science. The community is lucky to have you there at NIH! Please keep us posted on any new initiatives!","2",2015-05-06,2015-05-06,1,259,"base.profile","Jesse","Spaulding","jspauld"
"949","notes","meta","2015-05-06T06:18:20.075Z",2,"I'm thinking this is a big selling point though. Someone who doesn't believe it probably wouldn't post their proposal anyway. So unless this is really a turn off I would think it's worth taking the risk and leaving it in.","2",2015-05-06,2015-05-06,1,221,"base.profile","Jesse","Spaulding","jspauld"
"950","notes","meta","2015-05-06T06:24:00.848Z",2,"Thanks for the link!","2",2015-05-06,2015-05-06,1,20,"base.profile","Jesse","Spaulding","jspauld"
"951","notes","meta","2015-05-06T16:52:38.438Z",23,"As of today, both works very well for me.","23",2015-05-06,2015-05-06,1,41,"base.profile","Antoine","Lizee","alizee"
"952","notes","meta","2015-05-07T05:30:00.948Z",2,"Thanks we'll look into an appropriate limit","2",2015-05-07,2015-05-07,1,43,"base.profile","Jesse","Spaulding","jspauld"
"953","notes","meta","2015-05-07T05:33:13.030Z",2,"Thanks will add a link in our markdown guide","2",2015-05-07,2015-05-07,1,44,"base.profile","Jesse","Spaulding","jspauld"
"954","notes","meta","2015-05-08T00:14:16.423Z",2,"Agree. Something like that looks good.","2",2015-05-08,2015-05-08,1,38,"base.profile","Jesse","Spaulding","jspauld"
"955","notes","meta","2015-05-16T23:17:13.178Z",2,"@dhimmel Two dashes `--` and three dashes `---` now both automatically convert to em-dashes (--) in markdown and discussion titles. Additionally, quotes in discussion titles convert to curly quotes.","2",2015-05-16,2015-05-16,1,198,"base.profile","Jesse","Spaulding","jspauld"
"956","notes","meta","2015-05-16T23:20:00.844Z",17,"Why doesn't `--` convert to an en-dash (–)?","17",2015-05-16,2015-05-16,1,43,"base.profile","Daniel","Himmelstein","dhimmel"
"957","notes","meta","2015-05-17T00:05:26.216Z",2,"Because people commonly use `--` in place of an em-dash. If we do what you suggest they will be getting en-dashes when they mean to get em-dashes! It seems strange to expect people to type 3 dashes to get an em-dash. I've never seen that.","2",2015-05-17,2015-05-17,1,238,"base.profile","Jesse","Spaulding","jspauld"
"958","notes","meta","2015-05-17T00:14:53.658Z",17,"I think that most users will expect `--` to return an en-dash. Latex and [other markdown extensions](https://pythonhosted.org/Markdown/extensions/smarty.html) use `--` for en and `---` for em. Personally, I frequently use en-dashes for numerical ranges.","17",2015-05-17,2015-05-17,1,253,"base.profile","Daniel","Himmelstein","dhimmel"
"959","notes","meta","2015-05-17T04:16:19.934Z",2,"Okay, what I've done is the following:

1. `---` and  `(space)--(space)` convert to em-dash
2. `--` converts to en-dash

This should then work as expected in most scenarios. Let me know if you see a problem.","2",2015-05-17,2015-05-17,1,207,"base.profile","Jesse","Spaulding","jspauld"
"960","notes","meta","2015-06-16T00:11:53.936Z",2,"Yes, sorry, I forgot I partially added the figures for your proposal. I've fixed this for you — just required re-saving the edit figures form. Also, I just noticed you still have Table 3 in its original format.","2",2015-06-16,2015-06-16,1,210,"base.profile","Jesse","Spaulding","jspauld"
"961","notes","meta","2015-06-16T00:36:04.060Z",17,"Good catch, I converted Table 3.","17",2015-06-16,2015-06-16,1,32,"base.profile","Daniel","Himmelstein","dhimmel"
"962","notes","meta","2015-07-08T05:55:59.269Z",2,"Thanks. Will fix.","2",2015-07-08,2015-07-08,1,17,"base.profile","Jesse","Spaulding","jspauld"
"963","notes","meta","2015-07-08T05:58:15.776Z",2,"Thanks. We will address this issue.","2",2015-07-08,2015-07-08,1,35,"base.profile","Jesse","Spaulding","jspauld"
"964","notes","meta","2015-07-28T22:06:25.331Z",17,"I observed another new user accidentally navigate away from a draft when testing a link in preview mode.","17",2015-07-28,2015-07-28,1,104,"base.profile","Daniel","Himmelstein","dhimmel"
"965","notes","meta","2015-08-11T05:25:19.312Z",125,"I think that seeing your score decrease over time is demotivating to most people, and I think that this is human nature. Describing it as an education issue comes across as condescending, especially to new users. (Just to be clear: I am not offended in any way - I just fear this will drive users away in busloads.)","125",2015-08-11,2015-08-11,1,315,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"966","notes","meta","2015-08-11T05:25:51.989Z",17,"There is a custom amount option under the downward arrow. For further discussion of the rating bar [see this thread](http://thinklab.com/discussion/contribution-valuation-options/49).","17",2015-08-11,2015-08-11,1,183,"base.profile","Daniel","Himmelstein","dhimmel"
"967","notes","meta","2015-08-11T05:37:27.887Z",125,"I do not see how having the custom amount option addresses the problem. Sure it means that I could vote $1. But whether I vote $1 or $0, it will pull down the average, whereas not voting will not. To me not bothering to vote and voting low is the same, which is why I find averaging fundamentally flawed.","125",2015-08-11,2015-08-11,1,304,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"968","notes","meta","2015-08-11T06:20:44.154Z",17,"Was just making sure you were aware of options between 0 and 5. The [participation score](http://thinklab.com/how-it-works/earnings) should incentivize all ratings regardless of amount, but it is helpful to know that intuitively no rating seems equivalent to a low rating.","17",2015-08-11,2015-08-11,1,272,"base.profile","Daniel","Himmelstein","dhimmel"
"969","notes","meta","2015-08-11T16:32:43.238Z",2,"Yes, I basically agree with Lars. I think the expectation for these kinds of things is that points are earned and they only go up. I think it will surely help if people understand the mechanics -- but even so I agree seeing points go down should be avoided as best as possible.","2",2015-08-11,2015-08-11,1,277,"base.profile","Jesse","Spaulding","jspauld"
"970","notes","meta","2015-08-17T00:33:55.033Z",17,"Good points. Let's revisit this idea when more data is available.","17",2015-08-17,2015-08-17,1,65,"base.profile","Daniel","Himmelstein","dhimmel"
"971","notes","meta","2015-12-16T05:57:08.350Z",2,"Fixed","2",2015-12-16,2015-12-16,1,5,"base.profile","Jesse","Spaulding","jspauld"
"972","notes","meta","2015-12-16T07:02:22.525Z",2,"Just a quick update -- we chose to enable manual entry of a dollar amount as a solution for now.","2",2015-12-16,2015-12-16,1,96,"base.profile","Jesse","Spaulding","jspauld"
"973","notes","meta","2016-04-05T17:36:07.620Z",23,"Thanks! That's the most simple way to go forward.","23",2016-04-05,2016-04-05,1,49,"base.profile","Antoine","Lizee","alizee"
"974","notes","meta","2016-04-08T00:25:17.270Z",23,"Allright - thanks for considering.","23",2016-04-08,2016-04-08,1,34,"base.profile","Antoine","Lizee","alizee"
"975","notes","meta","2016-04-08T17:29:46.313Z",23,"Great workaround.","23",2016-04-08,2016-04-08,1,17,"base.profile","Antoine","Lizee","alizee"
"976","notes","meta","2016-04-08T20:14:28.607Z",17,"I agree the visitor counts would be great. I'm already learning from our project's [discussion view counts](http://thinklab.com/p/rephetio/discussion). And if we set up an automatic export every week, we will be able to do fascinating analytics of interest in subjects over time.","17",2016-04-08,2016-04-08,1,279,"base.profile","Daniel","Himmelstein","dhimmel"
"977","notes","MicrobeResist","2014-06-02T18:51:07.909Z",2,"As of this moment it's actually not designed to work there. I think the reason is that I was planning to have that text shortened to X characters with a ""more"" link for people who wanted to read more. Just get's a little tricky if it's in markdown. However, links would be nice so I'll see what can be done.","2",2014-06-02,2014-06-02,1,307,"base.profile","Jesse","Spaulding","jspauld"
"978","notes","MicrobeResist","2014-06-11T00:01:24.353Z",2,"I just want to note that none of the collaborators on the project received an email notification when you posted this. The post *will* still appear in their ThinkLab inbox however. I'm still trying to figure out the best system of notifications.","2",2014-06-11,2014-06-11,1,245,"base.profile","Jesse","Spaulding","jspauld"
"979","notes","MicrobeResist","2014-06-12T22:16:59.949Z",2,"Just a quick note. We have actually updated the markdown parser so it recognizes under_scores_between_words as not meant to be italic. The next time the proposal is saved this should be corrected automatically. And by the way, if you disagree with any of my [concerns](http://thinklab.com/MicrobeResist/discussion/7) please say so. I don't actually understand the science so keep that in mind!","2",2014-06-12,2014-06-12,1,393,"base.profile","Jesse","Spaulding","jspauld"
"980","notes","MicrobeResist","2014-06-12T22:44:40.565Z",14,"Actually, I think your concerns were useful, since it is so important to make sure that non-specialists understand the methods and impact. Holly's answers were well stated, and will add nicely to the proposal! ","14",2014-06-12,2014-06-12,1,210,"base.profile","James","Meadow","JamesMeadow"
"981","notes","MicrobeResist","2014-06-28T04:42:29.357Z",2,"Just FYI - the profile 'about' section will not be markdown for now. I've taken the liberty of removing the markdown you added for you.","2",2014-06-28,2014-06-28,1,135,"base.profile","Jesse","Spaulding","jspauld"
"982","notes","MicrobeResist","2014-09-16T20:54:44.139Z",2,"Just FYI - You no longer need to use @username to invite people to a discussion. If they are following the project they will be notified of any new comments via a daily or biweekly 'new activity' email. The @username feature can be used if you'd like to insure that the user is notified of your comment *immediately*. Note that users following a discussion thread will typically be notified of new comments in that thread straight away anyway.","2",2014-09-16,2014-09-16,1,443,"base.profile","Jesse","Spaulding","jspauld"
"983","notes","MicrobeResist","2014-09-16T21:06:10.883Z",2,"ThinkLab now tracks a version history for proposals. If you have a new version of the proposal I suggest you update ThinkLab with it. There will be a page you can link us to that will highlight the differences between the new version and the old version.","2",2014-09-16,2014-09-16,1,254,"base.profile","Jesse","Spaulding","jspauld"
"984","notes","pathways4life","2015-06-15T16:20:21.984Z",17,"@jspauld, most of the non-DOI references have DOIs. These should be converted, right?","17",2015-06-15,2015-06-15,1,85,"base.profile","Daniel","Himmelstein","dhimmel"
"985","notes","pathways4life","2015-12-16T02:19:11.348Z",2,"Yes, you're probably right ;)","2",2015-12-16,2015-12-16,1,29,"base.profile","Jesse","Spaulding","jspauld"
"986","notes","pathways4life","2015-12-16T02:29:11.162Z",2,"Better get them on [WikiPathways](http://www.wikipathways.org/) to start with then!","2",2015-12-16,2015-12-16,1,83,"base.profile","Jesse","Spaulding","jspauld"
"987","notes","rephetio","2015-01-23T05:05:37.375Z",17,"I don't see the ""attached reference"". Can you link to it or add a citation? Check out the [markdown syntax](http://thinklab.com/help/writing-in-markdown) offered by ThinkLab.","17",2015-01-23,2015-01-23,1,174,"base.profile","Daniel","Himmelstein","dhimmel"
"988","notes","rephetio","2015-01-23T19:27:36.905Z",23,"I'm talking about the reference you provided, whose [link](https://pdf.yt/d/Sx3jMbr8vANgxAej/download) is in the code.","23",2015-01-23,2015-01-23,1,118,"base.profile","Antoine","Lizee","alizee"
"989","notes","rephetio","2015-01-25T17:28:47.470Z",17,"Okay, I made some code organization and documentation changes. My first github fork and [pull request](https://github.com/antoine-lizee/R-GSC/pull/1) (:","17",2015-01-25,2015-01-25,1,152,"base.profile","Daniel","Himmelstein","dhimmel"
"990","notes","rephetio","2015-01-26T23:18:48.088Z",23,"Sorry, I saw your request too late to make a merge efficient, but I implemented your small formal changes that improve readability. Thanks!","23",2015-01-26,2015-01-26,1,139,"base.profile","Antoine","Lizee","alizee"
"991","notes","rephetio","2015-02-11T03:49:38.622Z",2,"It seems appropriate that some of these things be put in the research plan. For example, that you plan to follow the 10 rules of reproducible computational research.","2",2015-02-11,2015-02-11,1,165,"base.profile","Jesse","Spaulding","jspauld"
"992","notes","rephetio","2015-02-17T00:28:30.913Z",17,"**markdown error**: @jspauld, give me my bold! See SPL-X bullet.","17",2015-02-17,2015-02-17,1,64,"base.profile","Daniel","Himmelstein","dhimmel"
"993","notes","rephetio","2015-02-17T00:57:39.879Z",2,"Yep, will fix.","2",2015-02-17,2015-02-17,1,14,"base.profile","Jesse","Spaulding","jspauld"
"994","notes","rephetio","2015-02-17T13:52:36.308Z",22,"Thanks! For things that require significant cluster usage I haven't yet found a cost effective way to do this either outside of a grant from one of the cloud providers. I wonder if you could apply to amazon or google for access to compute instances for this purpose.","22",2015-02-17,2015-02-17,1,266,"base.profile","Casey","Greene","caseygreene"
"995","notes","rephetio","2015-02-27T22:53:29.690Z",17,"The authors do not plan on releasing the resource-specific indication data for the current MEDI database. However, they will consider doing so for future releases.","17",2015-02-27,2015-02-27,1,163,"base.profile","Daniel","Himmelstein","dhimmel"
"996","notes","rephetio","2015-03-18T22:52:13.592Z",17,"@b_good, thanks for the suggestion. I am excited about any venues where we can publish the data to increase its reuse. Once we complete the data integration stage, I will touch base with you -- it's still not entirely clear to me what exactly we would upload.","17",2015-03-18,2015-03-18,1,259,"base.profile","Daniel","Himmelstein","dhimmel"
"997","notes","rephetio","2015-03-19T23:42:23.213Z",2,"Here's a [link to the new discussion](http://thinklab.com/discussion/tissue-node/41) (Venkat, it might be a good idea to edit your post to add this link)","2",2015-03-19,2015-03-19,1,153,"base.profile","Jesse","Spaulding","jspauld"
"998","notes","rephetio","2015-03-20T02:37:46.580Z",17,"@vsmalladi, you may consider switching the associated publication to the Uberon paper [@10.1186/gb-2012-13-1-r5] and move the ENCODE use-case paper [@10.1093/database/bav010] as an [inline citation](http://thinklab.com/help/writing-in-markdown).","17",2015-03-20,2015-03-20,1,245,"base.profile","Daniel","Himmelstein","dhimmel"
"999","notes","rephetio","2015-03-20T02:38:37.568Z",17,"@jspauld, see the citation display failure in the previous note.","17",2015-03-20,2015-03-20,1,64,"base.profile","Daniel","Himmelstein","dhimmel"
"1000","notes","rephetio","2015-03-20T04:07:52.432Z",2,"@dhimmel Yeah, the inline citations don't work in the notes right now. I suspect it will be rare that people will try to use them in notes given that most of the substantive conversation is intended to take place in comments. So, for the time being I think I'll wait and see how much demand there will be. [**Edit:** After speaking with @dhimmel offline he has convinced me this was a bug. Inline note citations now work!]","2",2015-03-20,2015-03-20,1,422,"base.profile","Jesse","Spaulding","jspauld"
"1001","notes","rephetio","2015-03-20T04:09:55.058Z",17,"In support of the semantic web, you should check out ThinkLab's awesome [markdown syntax](http://thinklab.com/help/writing-in-markdown), which includes easy citation and hyperlink capabilities.","17",2015-03-20,2015-03-20,1,193,"base.profile","Daniel","Himmelstein","dhimmel"
"1002","notes","rephetio","2015-03-20T04:11:01.433Z",2,"With regard to the associated publication -- at the present moment this cannot be changed by the user. @vsmalladi, if you agree it makes sense to change it please just let me know and I'll take care of it.","2",2015-03-20,2015-03-20,1,205,"base.profile","Jesse","Spaulding","jspauld"
"1003","notes","rephetio","2015-03-20T04:48:01.252Z",35,"@jspauld yes please update the citation","35",2015-03-20,2015-03-20,1,39,"base.profile","Venkat","Malladi","vsmalladi"
"1004","notes","rephetio","2015-03-20T05:47:50.995Z",2,"Updated. If you'd like to do an inline citation to the original DOI you were referencing just insert the following in your markdown: `[@10.1093/database/bav010]`","2",2015-03-20,2015-03-20,1,161,"base.profile","Jesse","Spaulding","jspauld"
"1005","notes","rephetio","2015-03-20T06:31:04.885Z",2,"FYI, it looks like you mentioned the wrong person here. I'm assuming you meant @dhimmel .. Any idea how that happened?","2",2015-03-20,2015-03-20,1,118,"base.profile","Jesse","Spaulding","jspauld"
"1006","notes","rephetio","2015-03-20T15:39:36.836Z",35,"@jspauld I believe this was just user error. ","35",2015-03-20,2015-03-20,1,45,"base.profile","Venkat","Malladi","vsmalladi"
"1007","notes","rephetio","2015-03-29T19:04:10.713Z",17,"Saw this paper [@10.1371/journal.pcbi.1004068] which explores when disease/compound expression profiles are reliable therapeutic indicators, specifically with regards to lung cancer.","17",2015-03-29,2015-03-29,1,182,"base.profile","Daniel","Himmelstein","dhimmel"
"1008","notes","rephetio","2015-04-02T01:20:01.294Z",2,"The markdown error has been fixed.","2",2015-04-02,2015-04-02,1,34,"base.profile","Jesse","Spaulding","jspauld"
"1009","notes","rephetio","2015-04-02T21:47:12.107Z",2,"For future reference it's probably better to wait until you have more to say here before you post this. The project's followers probably don't need to know what you are planning to post here (until you actually post it!) What do you think? And yes, 'draft mode' is coming soon!","2",2015-04-02,2015-04-02,1,277,"base.profile","Jesse","Spaulding","jspauld"
"1010","notes","rephetio","2015-04-02T21:59:36.572Z",17,"Hey Jesse, I was making a stub because one project member may be interested in posting and I thought this would simplify the process.","17",2015-04-02,2015-04-02,1,133,"base.profile","Daniel","Himmelstein","dhimmel"
"1011","notes","rephetio","2015-04-02T22:05:48.541Z",2,"Oh alright, carry on then :)","2",2015-04-02,2015-04-02,1,28,"base.profile","Jesse","Spaulding","jspauld"
"1012","notes","rephetio","2015-04-03T05:28:22.756Z",48,"Ah.. guessing this is the reason behind http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21 ","48",2015-04-03,2015-04-03,1,128,"base.profile","Benjamin","Good","b_good"
"1013","notes","rephetio","2015-04-03T18:01:46.261Z",17,"@ritukhare, if you have a readily-available and exhaustive mapping of ingredient and disease identifiers to names, I could update my analysis with those names.","17",2015-04-03,2015-04-03,1,159,"base.profile","Daniel","Himmelstein","dhimmel"
"1014","notes","rephetio","2015-04-08T02:11:06.726Z",17,"Added the reference to my initial post. Given the quality issues, I do not plan to include this resource in our gold standard set of indications. It could be helpful later as a literature-derived set of *potential* indications.","17",2015-04-08,2015-04-08,1,227,"base.profile","Daniel","Himmelstein","dhimmel"
"1015","notes","rephetio","2015-04-09T01:30:54.293Z",17,"+1 for grant agencies to fund this type of activity","17",2015-04-09,2015-04-09,1,51,"base.profile","Daniel","Himmelstein","dhimmel"
"1016","notes","rephetio","2015-04-09T02:27:27.578Z",17,"Thanks for the clarification. We also plan to perform some indication propagation on the Disease Ontology hierarchy.","17",2015-04-09,2015-04-09,1,116,"base.profile","Daniel","Himmelstein","dhimmel"
"1017","notes","rephetio","2015-04-21T20:03:30.075Z",2,"The 'notebook' link is broken here","2",2015-04-21,2015-04-21,1,34,"base.profile","Jesse","Spaulding","jspauld"
"1018","notes","rephetio","2015-04-21T20:50:45.888Z",17,"Fixed, thanks","17",2015-04-21,2015-04-21,1,13,"base.profile","Daniel","Himmelstein","dhimmel"
"1019","notes","rephetio","2015-05-01T22:06:14.259Z",17,"Looks like this is all term type definitions across the entire UMLS.","17",2015-05-01,2015-05-01,1,68,"base.profile","Daniel","Himmelstein","dhimmel"
"1020","notes","rephetio","2015-05-01T22:27:00.760Z",17,"Awesome, you have set the train in motion for us to include ehrlink indications. Let's move discussion to [this new thread specifically for ehrlink analysis](http://thinklab.com/discussion/extracting-indications-from-the-ehrlink-resource/62).","17",2015-05-01,2015-05-01,1,242,"base.profile","Daniel","Himmelstein","dhimmel"
"1021","notes","rephetio","2015-05-02T20:23:23.972Z",23,"Correct - that is why I thought it could be a useful ressource to share.","23",2015-05-02,2015-05-02,1,72,"base.profile","Antoine","Lizee","alizee"
"1022","notes","rephetio","2015-05-03T20:54:14.123Z",23,"As a side-note, I removed all the row name columns in the csvs, because it was annoying for display in github. You might have to change slightly your code to understand the new format.","23",2015-05-03,2015-05-03,1,184,"base.profile","Antoine","Lizee","alizee"
"1023","notes","rephetio","2015-05-03T20:57:42.872Z",23,"You might want to update #7 with my latest results from [#6](http://thinklab.com/discussion/how-should-we-construct-a-catalog-of-drug-indications/21#185)","23",2015-05-03,2015-05-03,1,153,"base.profile","Antoine","Lizee","alizee"
"1024","notes","rephetio","2015-05-04T19:19:49.666Z",17,"For reference, @alizee [used](https://github.com/antoine-lizee/RRxNorm/blob/master/RxNorm2.R#L67) the following term type priority list (high to low):

`SCD`, `SBD`, `SCDF`, `SBDF`, `BN`, `SCDC`, `SBDC`, `IN`, `MIN`, `PIN`, `GPCK`, `BPCK`, `SCDG`, `SBDG`, `DF`, `DFG`","17",2015-05-04,2015-05-04,1,267,"base.profile","Daniel","Himmelstein","dhimmel"
"1025","notes","rephetio","2015-05-08T19:45:18.976Z",22,"I should add that the full text search is basically a last ditch effort to find genes w/o any matching identifiers in the structured databases. We use this on the description and alias field, as well as all of the cross reference IDs. We use elasticsearch via django-haystack to power this. It's pretty easy to set this up on AWS or locally. We previously used solr, but the configuration headache didn't outweigh the benefits.","22",2015-05-08,2015-05-08,1,427,"base.profile","Casey","Greene","caseygreene"
"1026","notes","rephetio","2015-05-10T18:49:08.949Z",17,"A common source of detailed variation between compounds is stereochemistry. See [this video](https://youtu.be/457xnJv80O0) for an introduction and [this paper](//www.ncbi.nlm.nih.gov/pmc/articles/PMC353039/) [@10.4088/pcc.v05n0202] for the relevance of stereochemistry in pharmacology.","17",2015-05-10,2015-05-10,1,285,"base.profile","Daniel","Himmelstein","dhimmel"
"1027","notes","rephetio","2015-05-13T20:19:22.125Z",17,"Elvira Mitraka [added these cross-references](http://sourceforge.net/p/diseaseontology/feature-requests/75/#5304) to revision 2815.","17",2015-05-13,2015-05-13,1,131,"base.profile","Daniel","Himmelstein","dhimmel"
"1028","notes","rephetio","2015-05-13T20:20:56.580Z",17,"Elvira Mitraka [fixed these typos and inconsistencies](http://sourceforge.net/p/diseaseontology/feature-requests/77/#a1e0) in revision 2815.","17",2015-05-13,2015-05-13,1,140,"base.profile","Daniel","Himmelstein","dhimmel"
"1029","notes","rephetio","2015-05-13T20:21:42.950Z",17,"Elvira Mitraka [added these cross-references](//sourceforge.net/p/diseaseontology/feature-requests/76/#04c8) to revision 2815.","17",2015-05-13,2015-05-13,1,126,"base.profile","Daniel","Himmelstein","dhimmel"
"1030","notes","rephetio","2015-05-19T02:40:56.552Z",17,"See this [newer symptom–disease pair tsv file](https://raw.githubusercontent.com/dhimmel/medline/2a427d37c4174e492873e2387c9b1d51236a4f7b/data/disease-symptom-cooccurrence.tsv) which has [additional](https://github.com/dhimmel/medline/commit/2a427d37c4174e492873e2387c9b1d51236a4f7b?diff=unified#diff-3417fe5acc9338308981e0e58eca0f11) DO slim diseases with MeSH mappings. ","17",2015-05-19,2015-05-19,1,372,"base.profile","Daniel","Himmelstein","dhimmel"
"1031","notes","rephetio","2015-05-28T00:07:51.486Z",17,"@allisonmccoy, thanks for following up and congratulations on your paper [@10.4338/ACI-2015-01-RA-0010]. I read the abstract, but could you [email me](mailto:daniel.himmelstein@gmail.com) the pdf?

Enjoy the travels, we would definitely appreciate the data!","17",2015-05-28,2015-05-28,1,257,"base.profile","Daniel","Himmelstein","dhimmel"
"1032","notes","rephetio","2015-06-12T17:22:48.072Z",17,"2015-06-12: I reassessed the implications of the centimorgan versus kilobase window span correlation. My current conclusion is that a single centimorgan threshold cannot be chosen that produces similar windows to the *r*-squared method.","17",2015-06-12,2015-06-12,1,236,"base.profile","Daniel","Himmelstein","dhimmel"
"1033","notes","rephetio","2015-06-19T15:13:07.277Z",17,"What does SRA stand for?","17",2015-06-19,2015-06-19,1,24,"base.profile","Daniel","Himmelstein","dhimmel"
"1034","notes","rephetio","2015-06-19T15:24:56.910Z",111,"Sequence Read Archive (http://www.ncbi.nlm.nih.gov/sra). This is where we usually download the raw data from. But I think GTEx keep them private, for their ""on demand"" data sharing policy...","111",2015-06-19,2015-06-19,1,190,"base.profile","Frederic","Bastian","fbastian"
"1035","notes","rephetio","2015-06-19T23:32:57.683Z",17,"My mistake regarding ""transcript abundance"" -- we actually only care about gene abundance.","17",2015-06-19,2015-06-19,1,90,"base.profile","Daniel","Himmelstein","dhimmel"
"1036","notes","rephetio","2015-06-20T01:06:56.926Z",111,"@dhimmel: OK, it should fit your needs then. Let me know if you have any other question.","111",2015-06-20,2015-06-20,1,88,"base.profile","Frederic","Bastian","fbastian"
"1037","notes","rephetio","2015-06-20T22:30:37.369Z",17,"Links are broken","17",2015-06-20,2015-06-20,1,16,"base.profile","Daniel","Himmelstein","dhimmel"
"1038","notes","rephetio","2015-06-26T23:25:24.504Z",17,"Thanks @akolow! Let us know if you experience any problems or have suggestions.","17",2015-06-26,2015-06-26,1,79,"base.profile","Daniel","Himmelstein","dhimmel"
"1039","notes","rephetio","2015-06-29T04:07:20.652Z",17,"Much appreciated. Thanks!","17",2015-06-29,2015-06-29,1,25,"base.profile","Daniel","Himmelstein","dhimmel"
"1040","notes","rephetio","2015-08-09T04:06:47.324Z",125,"No, the right person to contact is Michael Kuhn.","125",2015-08-09,2015-08-09,1,48,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"1041","notes","rephetio","2015-08-09T04:12:25.999Z",125,"Please note that using only the experiments channel will not eliminate knowledge biases. In particular, the immunohistochemical staining data from the Human Protein Atlas are heavily biased, since it depends strongly on the number and quality of antibodies available for each protein. ","125",2015-08-09,2015-08-09,1,285,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"1042","notes","rephetio","2015-08-09T20:18:38.535Z",17,"In `human_tissue_integrated_full.tsv` I treated `HPA` as referring to HPA-IHC. Is this correct?","17",2015-08-09,2015-08-09,1,95,"base.profile","Daniel","Himmelstein","dhimmel"
"1043","notes","rephetio","2015-08-10T04:11:26.832Z",125,"If you meant experiments instead of integrated in that filename, then yes.","125",2015-08-10,2015-08-10,1,74,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"1044","notes","rephetio","2015-08-11T05:55:36.726Z",17,"I contacted Michael Kuhn. `label_mapping.tsv.gz` was not essential and was removed. Documentation was added to the README for `meddra_all_indications.tsv.gz`.","17",2015-08-11,2015-08-11,1,158,"base.profile","Daniel","Himmelstein","dhimmel"
"1045","notes","rephetio","2015-08-12T16:48:08.890Z",17,"Yes, I meant `human_tissue_experiments_full.tsv.gz`.","17",2015-08-12,2015-08-12,1,52,"base.profile","Daniel","Himmelstein","dhimmel"
"1046","notes","rephetio","2015-08-12T18:12:56.111Z",17,"Your study alludes that it includes [citation 51](https://dx.doi.org/10.1038/ncomms5074#ref51) [@10.1038/nature01156] as a human interactome dataset. I don't think we'll include this study as it's old and doesn't seem to be a PPI database.","17",2015-08-12,2015-08-12,1,239,"base.profile","Daniel","Himmelstein","dhimmel"
"1047","notes","rephetio","2015-08-16T07:39:18.514Z",125,"I forgot to mention explicitly that this obviously means that you cannot distribute your network file on GitHub under the CC0 waiver as you currently do.","125",2015-08-16,2015-08-16,1,153,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"1048","notes","rephetio","2015-08-16T07:48:48.752Z",125,"Redistribution of LINCS data is also problematic, unless you contacted them and got permission to do so (http://www.lincscloud.org/license/).","125",2015-08-16,2015-08-16,1,141,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"1049","notes","rephetio","2015-08-16T08:21:11.712Z",17,"Okay, I will look into the copyright issues and make any necessary modifications. I like the idea of including source and license fields for each node and edge. My understanding is that CC licenses prior to 4.0 [do not restrict](https://wiki.creativecommons.org/wiki/Data) the underlying data when used in the United States. However, I will need to do more reading and solicit the advice of copyright experts.","17",2015-08-16,2015-08-16,1,409,"base.profile","Daniel","Himmelstein","dhimmel"
"1050","notes","rephetio","2015-08-16T08:27:17.366Z",17,"I updated the [repository license](https://github.com/dhimmel/integrate/blob/950f26ddff83e17fa6e398e7ae66179d8b2638e3/LICENSE.md) until we clarify these issues.","17",2015-08-16,2015-08-16,1,160,"base.profile","Daniel","Himmelstein","dhimmel"
"1051","notes","rephetio","2015-08-16T08:27:28.794Z",125,"CC licenses prior to 4.0 were not very well suited for data. I only just noticed that the new SIDER still uses the old license, which I think should be changed. Not to make it more restrictive, but simply because the 4.0 license addresses a problem in the earlier license (i.e. the attribution stacking problem).","125",2015-08-16,2015-08-16,1,312,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"1052","notes","rephetio","2015-08-16T08:39:27.607Z",125,"Unfortunately, as far as I know, it is not sufficient to consider US law when you distribute data to the whole world. Although the US does not have sui generis database right, other parts of the world do, including the EU. This means that databases created in the EU are protected by such laws. (Caveat: I am not a lawyer, this does not constitute legal advice, yada yada yada.)","125",2015-08-16,2015-08-16,1,378,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"1053","notes","rephetio","2015-08-17T07:33:53.127Z",129,"I think that for gene-disease associations you should check DisGeNET (www.disgenet.org). I would start by checking the disease list that you already have and query DisGeNET with it. Currently, DisGeNET may be searched using MeSH, OMIMs, and UMLS CUIs. You can download the data in tab files.","129",2015-08-17,2015-08-17,1,291,"base.profile","janet","piñero","janispi"
"1054","notes","rephetio","2015-08-18T03:56:41.965Z",17,"@janispi, thanks for the suggestion. We've [begun](http://thinklab.com/discussion/processing-disgenet-for-disease-gene-relationships/105) adding DisGeNET.","17",2015-08-18,2015-08-18,1,154,"base.profile","Daniel","Himmelstein","dhimmel"
"1055","notes","rephetio","2015-08-19T09:03:54.261Z",129,"you are absolutely right, I have removed the tar the files, and now I just gzip them. ","129",2015-08-19,2015-08-19,1,86,"base.profile","janet","piñero","janispi"
"1056","notes","rephetio","2015-08-19T09:19:03.563Z",129,"I was waiting for this question. All GDAs have score > 0. 
If you choose score >= 0.06, then you will be including associations reporting by curated sources, or having animal models supporting them, or being reported by several papers (20 -200). It will not be permissive, though (less than 10% of GDAs satisfies this criteria). MAybe you could start with this score, and see how it goes. ","129",2015-08-19,2015-08-19,1,389,"base.profile","janet","piñero","janispi"
"1057","notes","rephetio","2015-08-19T18:26:50.742Z",17,"I am not able to resolve http://dev.stargeo.org/","17",2015-08-19,2015-08-19,1,48,"base.profile","Daniel","Himmelstein","dhimmel"
"1058","notes","rephetio","2015-08-19T18:33:23.335Z",121,"Make that: http://dev.stargeo.io. But not live quite yet.  I'll get an update tonight on the UI.  Current only working from command line, but at least its working :)","121",2015-08-19,2015-08-19,1,165,"base.profile","Dexter","Hadley","idrdex"
"1059","notes","rephetio","2015-08-19T18:55:47.985Z",17,"Okay, I'll switch the hyperlinks on Thinklab over to http://dev.stargeo.io/","17",2015-08-19,2015-08-19,1,75,"base.profile","Daniel","Himmelstein","dhimmel"
"1060","notes","rephetio","2015-08-20T00:30:41.694Z",48,"I'm wondering about your relation ontology here.  Can you really distinguish a causal relation from co-occurrence information?  Do the names on these edges actually matter based on how you are using the network ?  If the meaning of the relations is really important, I think there are other text-mining approaches that you should look into.  If not, the co-occurrence stuff should be fine.  Really curious about this experiment..  Would also like to see how the result of other text-ming approaches would influence the outcome.  e.g. would it change things if you swapped in the relations from semmedDB ?","48",2015-08-20,2015-08-20,1,604,"base.profile","Benjamin","Good","b_good"
"1061","notes","rephetio","2015-08-20T17:05:36.232Z",121,"I think whatever we do is ultimately arbitrary and will become our 'protocol'.  We can assume that tags reference the sample itself which probably is some type of tissue and applies to the individual.  Like diabetic pancreas tissue is from a diabetic individual.  But cancer is a ""mosaic"" disease which puts tissue vs individual out of sync.  I think eventually for every set of annotations made on a GSE, we can allow for qualifiers from EFO to be set.","121",2015-08-20,2015-08-20,1,453,"base.profile","Dexter","Hadley","idrdex"
"1062","notes","rephetio","2015-08-20T17:07:20.448Z",121,"I guess.  This is mainly for testing.  By the end of the month or soon thereafter it should revert back to .org (public marketed site) and .io will remain for testing among a chosen few (and relatively private)","121",2015-08-20,2015-08-20,1,210,"base.profile","Dexter","Hadley","idrdex"
"1063","notes","rephetio","2015-08-20T17:12:12.642Z",22,"I took a look at that but it doesn't look like it provides hooks to the underlying annotations. Are those going to be available? For the types of analyses that we work on, those are much more valuable than the profiles.","22",2015-08-20,2015-08-20,1,219,"base.profile","Casey","Greene","caseygreene"
"1064","notes","rephetio","2015-08-20T17:12:47.779Z",121,"1) Yes multi species are on the books.  But for now we are focusing on humans to get the site launched.
2) Lets get you an account which for now is through me.  I'm idrdex at both google hangouts and Skype. 


3) Everything for now is accessed through the site.  We are working on an API to serve the data for the computational folks.  Basically allow retrival of annotations and served matrices with matching gene ids.","121",2015-08-20,2015-08-20,1,419,"base.profile","Dexter","Hadley","idrdex"
"1065","notes","rephetio","2015-08-20T17:16:09.000Z",121,"The ""annotations"" interface is not ready yet.  But imagine a searchable list where you could put GSEs in for instance and get all our annotations across GSMs.  For now I could probably generate a .csv for you.   We currently have 400K+ annotations  over 100+ tags.  Some GSEs have been done up to quadruplicate and ones with multiple annotations we have kappa inter-related sats calculated.","121",2015-08-20,2015-08-20,1,390,"base.profile","Dexter","Hadley","idrdex"
"1066","notes","rephetio","2015-08-20T17:21:53.596Z",22,"The annotations interface sounds very helpful! I'm looking forward to it! The analysis that we're doing right now isn't for human datasets, so if your curations are generally there we can't check the overlap with our own curations. We do a lot of human work though, so it'll be very helpful to us to have these annotations available.","22",2015-08-20,2015-08-20,1,333,"base.profile","Casey","Greene","caseygreene"
"1067","notes","rephetio","2015-08-20T17:23:01.622Z",121,"I've got a postgres table that you can query if you like.  Let's hangout and discuss :)","121",2015-08-20,2015-08-20,1,87,"base.profile","Dexter","Hadley","idrdex"
"1068","notes","rephetio","2015-08-20T17:27:50.566Z",121,"It would be useful to compare and contrast STARGEO with this ADEPTUS list.  To be clear the 400+ annotations cover about 200+ distinct tags made on samples --  i.e samples can be redundantly annotated to check for validity of the original annotations.  This validation on demand allows us to weed out problematic studies that poorly describe their samples and individual sample annotations whose semantics are imprecise.","121",2015-08-20,2015-08-20,1,420,"base.profile","Dexter","Hadley","idrdex"
"1069","notes","rephetio","2015-08-20T22:32:29.292Z",17,"Okay, we can change links to http://stargeo.org now or once the public site goes live. Your call.","17",2015-08-20,2015-08-20,1,97,"base.profile","Daniel","Himmelstein","dhimmel"
"1070","notes","rephetio","2015-08-21T20:54:30.263Z",17,"We don't include COSMIC anywhere else, so I would like to include it. @larsjuhljensen, which literature corpus was used for text mining?","17",2015-08-21,2015-08-21,1,136,"base.profile","Daniel","Himmelstein","dhimmel"
"1071","notes","rephetio","2015-08-21T20:59:14.336Z",125,"Just Medline so far.","125",2015-08-21,2015-08-21,1,20,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"1072","notes","rephetio","2015-08-28T20:38:08.534Z",17,"Great suggestion. This way users can avoid having to subset the network and reconcile various licenses.","17",2015-08-28,2015-08-28,1,103,"base.profile","Daniel","Himmelstein","dhimmel"
"1073","notes","rephetio","2015-09-07T16:07:27.482Z",17,"Exciting, thanks for the update. On another note, I wasn't able to find any licensing information on the Bgee website, which technically means [all rights reserved](http://choosealicense.com/no-license/). We're [tying to compile](http://thinklab.com/discussion/integrating-resources-with-disparate-licensing-into-an-open-network/107#3) licenses for each resource we use. It would be great if you could add a license.","17",2015-09-07,2015-09-07,1,416,"base.profile","Daniel","Himmelstein","dhimmel"
"1074","notes","rephetio","2015-09-07T16:38:45.337Z",111,"Yep, I wanted to reply to you after checking all our datasources. I think we are going to use a cc-by, but I'll contact you when I can confirm that for sure.","111",2015-09-07,2015-09-07,1,157,"base.profile","Frederic","Bastian","fbastian"
"1075","notes","rephetio","2015-09-10T10:52:06.035Z",125,"The big problem I see here is the term ""results"". If the results are actually new results, then I agree that they can be released whichever way you like. But if your ""results"" are in fact other people's databases mapped to different identifiers, bundled, and reformatted in JSON format, then claiming fair use is in my opinion a very risky proposition.","125",2015-09-10,2015-09-10,1,352,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"1076","notes","rephetio","2015-09-10T19:26:59.238Z",17,"@larsjuhljensen and @mackenziesmith, I think we may all be on the same page. Results from *network analyses* are truly transformative and thus eligible for CC0 licensing due to fair use. However, the *resource processing* and *integrative network* [steps](#4), which distribute unmodified downloads as well as network-coerced versions of databases, should generally transmit the source licensing.","17",2015-09-10,2015-09-10,1,396,"base.profile","Daniel","Himmelstein","dhimmel"
"1077","notes","rephetio","2015-09-10T19:47:47.420Z",125,"@dhimmel, we almost agree. The one point where I disagree is that, in my opinion, fair use has nothing to do with it. If you do a network analysis that truly produces new results (e.g. predicting new edges based on the imported ones), then those edges are yours. You are free to do with them whatever you want, not because of fair use, but simply because you are the original creator :-)","125",2015-09-10,2015-09-10,1,387,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"1078","notes","rephetio","2015-09-10T20:17:01.002Z",17,"I am interested in subnetworks for user convenience -- if a user wants only CC-BY-SA content, then the subnetwork saves them time. However, I disagree that subnetworks are a substitute for a complete network with mixed licensing. Merging networks will be burdensome to my hypothetical user who is interested only in analyzing rather than redistributing the network. Additionally, I am not sure the entire network can be represented by copyright uniform subnetworks. For example, DrugBank [forbids](https://github.com/dhimmel/integrate/blob/0e343d8745a98757c86e73f645b41353f52b82b5/licenses/custom/DrugBank.md) commercial reuse. However, our drug--gene binding edges derive from the CC-BY-SA ChEMBL resource. Thus the CC-BY-SA subnetwork would contain edges whose nodes cannot be included.","17",2015-09-10,2015-09-10,1,788,"base.profile","Daniel","Himmelstein","dhimmel"
"1079","notes","rephetio","2015-09-14T22:38:05.507Z",17,"Continuum [has created](http://continuum.io/blog/conda-jupyter-irkernel) an `r-essentials` bundle containing many of the most common R packages. Installing, `r-essentials` should also add the R kernel to your jupyter notebook.","17",2015-09-14,2015-09-14,1,226,"base.profile","Daniel","Himmelstein","dhimmel"
"1080","notes","rephetio","2015-09-23T05:43:28.403Z",125,"Thanks a lot for also pointing out the politics aspect. In my opinion, the risk of actually getting sued in academia is probably fairly low. However, if you were to systematically take resources with restrictive licenses, integrate them, and redistribute the complete data under CC0, you would almost for sure be burning bridges.","125",2015-09-23,2015-09-23,1,329,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"1081","notes","rephetio","2015-10-02T19:29:30.472Z",17,"Yesterday, we [sent out](http://thinklab.com/discussion/incomplete-interactome-licensing/111) our first permission request for a publication [@10.1126/science.1257601] supplement.","17",2015-10-02,2015-10-02,1,179,"base.profile","Daniel","Himmelstein","dhimmel"
"1082","notes","rephetio","2015-10-05T02:33:53.056Z",2,"Just a small correction -- Thinklab is tracking views independently of Google Analytics. Our figure attempts to track the total number of *humans* that have viewed the page. Our figure will be less than what Google Analytics has because for them a unique page view is really the number of *sessions* with at least one page view.","2",2015-10-05,2015-10-05,1,328,"base.profile","Jesse","Spaulding","jspauld"
"1083","notes","rephetio","2015-10-05T02:44:07.397Z",2,"I've emailed them and will report back","2",2015-10-05,2015-10-05,1,38,"base.profile","Jesse","Spaulding","jspauld"
"1084","notes","rephetio","2015-10-06T15:55:53.335Z",17,"2015-09-06: I updated this post to correct edge counts. Previously, I wrote the network contains ""5,998,711 edges (2,977,167 of which are unbiased)"". The issue was caused by counting single edges multiple times.","17",2015-10-06,2015-10-06,1,211,"base.profile","Daniel","Himmelstein","dhimmel"
"1085","notes","rephetio","2015-10-09T16:11:40.411Z",17,"I've [added institutional affiliations](https://github.com/dhimmel/integrate/blob/7ef64533f0822fb5728ab4c1d88dc39f3345dcc8/licenses/README.md). I did not specify affiliations for community driven projects or multi-affiliated projects. In general, is funding information available? Where can I find it?","17",2015-10-09,2015-10-09,1,301,"base.profile","Daniel","Himmelstein","dhimmel"
"1086","notes","rephetio","2015-10-13T18:05:23.266Z",79,"Funding is available on the project site or the citation.  For example [DO] (http://disease-ontology.org/about/), their last [publication]
(http://nar.oxfordjournals.org/content/early/2014/10/27/nar.gku1011.full.pdf?keytype=ref&ijkey=Ul8AlMyerFSf0rP), the funding are from several grants from NIH, EMBL and the department of energy. 

When sources are looking into licensing or terms of use, do they bind to the affiliation, funding or make the best educated guess?","79",2015-10-13,2015-10-13,1,465,"base.profile","Caty","Chung","cchung"
"1087","notes","rephetio","2015-10-14T23:09:31.462Z",137,"Generally with a CC license you should say how the author wants to be credited - if not specific as to manner, than at least with a name of person or organization. That's all so far. I'll keep an eye out now that I'm back in the office...","137",2015-10-14,2015-10-14,1,238,"base.profile","Katie","Fortney","katiefortney"
"1088","notes","rephetio","2015-10-22T03:37:18.366Z",125,"Neo4j 3.0 should be interesting. So far, what has mainly held me back was that I do not want to develop my bioinformatics software in Java and doing everything through Cypher was not sufficiently efficient to warrant migration from a PostgreSQL database.","125",2015-10-22,2015-10-22,1,254,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"1089","notes","rephetio","2015-12-04T21:52:50.278Z",17,"Milestone 1 of version 3.0 was [released today](http://neo4j.com/blog/neo4j-3-0-milestone-1-release/) with a [python driver](https://github.com/neo4j/neo4j-python-driver). The update promises fast access from outside of java. However, you will still need to use Cypher (which I find easier and more powerful than SQL). @larsjuhljensen, I would wait till the final 3.0 release for production use but wanted to give you a heads up of what lies ahead.","17",2015-12-04,2015-12-04,1,448,"base.profile","Daniel","Himmelstein","dhimmel"
"1090","notes","rephetio","2015-12-04T22:16:40.803Z",125,"Thanks - my problem was, though, that my network queries could not be expressed efficiently in Cypher. Whereas shortest path could be done very efficiently, something as simple as shortest path in a weighted graph could not. Maybe Cypher has become more powerful since?","125",2015-12-04,2015-12-04,1,269,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"1091","notes","rephetio","2015-12-04T23:34:50.299Z",17,"Cypher doesn't have great algorithm coverage. Shortest weighted path [isn't too hard](http://www.khalidabuhakmeh.com/finding-the-shortest-path-using-neo4j-graph-database) to implement, albeit inefficiently. However, if you're encoding anything that resembles a hetnet, cypher will beat SQL for data interactions.","17",2015-12-04,2015-12-04,1,312,"base.profile","Daniel","Himmelstein","dhimmel"
"1092","notes","rephetio","2015-12-14T00:55:48.202Z",17,"We've [implemented](https://github.com/dhimmel/hetio/commit/0683f5fd43ff0ca51c0bd1de1217f589a8891274) the **labeled** method, which can be used for our path traversal, since the metapath is known *a priori*.","17",2015-12-14,2015-12-14,1,207,"base.profile","Daniel","Himmelstein","dhimmel"
"1093","notes","rephetio","2016-02-05T22:03:55.034Z",17,"Noting another disease--phenotype approach [@10.1038/srep10888] titled ""Analysis of the human diseasome using phenotype similarity between common, genetic, and infectious diseases.""","17",2016-02-05,2016-02-05,1,181,"base.profile","Daniel","Himmelstein","dhimmel"
"1094","notes","rephetio","2016-02-20T06:23:56.287Z",17,"Pouya's curations are available as a [spreadsheet](https://github.com/dhimmel/indications/blob/d3d57b07abcf8d7af55f8e42ef7c4c99acd87ca8/curation/pk/template-pk%20final.xlsx ""GitHub · `template-pk final.xlsx`"") or [TSV file](https://github.com/dhimmel/indications/blob/49cf8e3858f124e552051fc1e8c1c229a43dadf6/curation/pk/curation-PK.tsv ""GitHub · `curation-PK.tsv`"").","17",2016-02-20,2016-02-20,1,367,"base.profile","Daniel","Himmelstein","dhimmel"
"1095","notes","rephetio","2016-02-26T17:37:11.558Z",125,"Exactly - we think alike. What I refer to as ""not a happy cell"" is usually some mix of stress response and reduced growth rate, which also results in a change in the distribution of cells across cell-cycle phases.","125",2016-02-26,2016-02-26,1,213,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"1096","notes","rephetio","2016-02-26T17:42:00.179Z",22,"@larsjuhljensen Indeed! My guess right now is that or no gene-wise normalization (e.g. the most highly expressed genes are still the most highly expressed).","22",2016-02-26,2016-02-26,1,156,"base.profile","Casey","Greene","caseygreene"
"1097","notes","rephetio","2016-02-26T17:46:19.124Z",125,"I assume that the expression values here are already ratios between perturbed and non-perturbed. Otherwise, I would put my money on it being a normalization artifact, but in that case I would expect a much stronger correlation than what is observed.","125",2016-02-26,2016-02-26,1,249,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"1098","notes","rephetio","2016-03-08T06:25:39.678Z",17,"I removed the following sentence, since it is not true:

> Unfortunately, none of the perturbed genes were in the landmark set, so I can't detect whether the perturbations are actually affecting their target genes in the desired direction.","17",2016-03-08,2016-03-08,1,239,"base.profile","Daniel","Himmelstein","dhimmel"
"1099","notes","rephetio","2016-03-09T06:46:22.029Z",125,"Reassuring to see that things behave the way I would expect. This should make it fairly easy to derive a scoring scheme that extracts only associations that are specifically associated with a small number of perturbations, as opposed to associated with any perturbation.","125",2016-03-09,2016-03-09,1,270,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"1100","notes","rephetio","2016-03-09T06:47:25.413Z",125,"The part about broad downregulation occurring in tandem with broad upregulation is almost a given. Even if it is not the case biologically, this will be the case after most normalization methods.","125",2016-03-09,2016-03-09,1,195,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"1101","notes","rephetio","2016-03-15T03:00:45.439Z",17,"I [updated the table](https://github.com/dhimmel/integrate/blob/145810796f0729d1ed5255bcb83c658490a198f9/licenses/README.md) to include funding information. Without seeing the specific contractual arrangements between funders and Universities and between Universities and their researchers, it's difficult to know whether there are any binding obligations regarding data licensing.","17",2016-03-15,2016-03-15,1,381,"base.profile","Daniel","Himmelstein","dhimmel"
"1102","notes","rephetio","2016-03-15T06:31:19.499Z",125,"I get an error when trying to follow the figshare link. Looks like the DOI is either wrong or not registered correctly (yet).","125",2016-03-15,2016-03-15,1,125,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"1103","notes","rephetio","2016-03-15T08:09:10.808Z",125,"If I were you, I would just delete Human Interactome Database and ADEPTUS from the network, unless they are crucial. Considering that over half a year has gone by without them responding, it seems likely that you will get permission, so I would remove them to not have legally questionable data in my resource.","125",2016-03-15,2016-03-15,1,310,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"1104","notes","rephetio","2016-03-15T15:02:14.154Z",17,"The figshare DOI link is [now active](https://doi.org/10.6084/m9.figshare.3103054). The citation metadata [@10.6084/m9.figshare.3103054] should resolve with time.","17",2016-03-15,2016-03-15,1,162,"base.profile","Daniel","Himmelstein","dhimmel"
"1105","notes","rephetio","2016-03-15T16:36:03.799Z",17,"ADEPTUS is no longer included (indicated by ‡ [here](https://github.com/dhimmel/integrate/blob/145810796f0729d1ed5255bcb83c658490a198f9/licenses/README.md)). The Human Interactome Database ([HID](http://interactome.dfci.harvard.edu/H_sapiens/index.php?page=download)) is important because it's the only [resource we include](http://thinklab.com/discussion/creating-a-catalog-of-protein-interactions/85#9) of systematic (unbiased by knowledge) interactions. The HID -- having received many millions in NIH funding (see [a](http://grantome.com/grant/NIH/U01-HG001715-16), [b](http://grantome.com/grant/NIH/U41-HG001715-17), & [c](http://grantome.com/grant/NIH/R01-HG001715-13)) to create its dataset -- provides a unique resource that is commonly reused despite it's lack of a license. I will follow up on my initial emails to the HID.","17",2016-03-15,2016-03-15,1,833,"base.profile","Daniel","Himmelstein","dhimmel"
"1106","notes","rephetio","2016-03-17T04:22:20.379Z",17,"Lars, you should have mentioned your article on whether graph databases are ready for bioinformatics [@10.1093/bioinformatics/btt549]! This is a citation that belongs in this discussion.","17",2016-03-17,2016-03-17,1,186,"base.profile","Daniel","Himmelstein","dhimmel"
"1107","notes","rephetio","2016-03-21T13:29:59.475Z",188,"I'm up for it. I should have some time either late this week or early next week. ","188",2016-03-21,2016-03-21,1,81,"base.profile","Pouya","Khankhanian","pouyakhankhanian"
"1108","notes","rephetio","2016-03-31T05:00:22.399Z",17,"We [received permission](http://thinklab.com/discussion/the-adeptus-resource-for-expression-signatures-of-disease/101#2) to use ADEPTUS. The ADEPTUS row in the permission request table now becomes PERM after 213 days.","17",2016-03-31,2016-03-31,1,217,"base.profile","Daniel","Himmelstein","dhimmel"
"1109","notes","rephetio","2016-03-31T05:10:48.632Z",125,"I know it's dangerous to make pre-morning coffee comments on a mathematical proof, but didn't you get N_START and N_END swapped in the last formula? In the formula just above, I thought N_A was the number of start nodes and N_D the number of end nodes.

It would also make more sense intuitively, since it implies that N_START⋅FC = N_END⋅BC. In other words, it doesn't matter whether you start from every start node and do forward traversal or start from every end node and do backward traversal. Both involve that you traverse all possible paths between all start nodes and all end nodes and have the same complexity.","125",2016-03-31,2016-03-31,1,618,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"1110","notes","rephetio","2016-04-01T01:47:55.441Z",17,"Just came across this publication [@10.1002/psp4.12009], which analyzed how chemical similarity correlated with transcriptional similarity in LINCS L1000.","17",2016-04-01,2016-04-01,1,154,"base.profile","Daniel","Himmelstein","dhimmel"
"1111","notes","rephetio","2016-04-02T20:22:56.180Z",17,"Noting an updated WikiPathways citation [@10.1093/nar/gkv1024] in 2016 _NAR_ Database Issue.","17",2016-04-02,2016-04-02,1,92,"base.profile","Daniel","Himmelstein","dhimmel"
"1112","notes","rephetio","2016-04-03T04:21:04.803Z",17,"MSigDB -- the only remaining category 3 resource -- has now [been removed](http://thinklab.com/discussion/msigdb-licensing/108#3).","17",2016-04-03,2016-04-03,1,130,"base.profile","Daniel","Himmelstein","dhimmel"
"1113","notes","rephetio","2016-04-03T20:18:20.176Z",23,"@larsjuhljensen: I wish I could say I let this one slip to test readership's attention, but it just seems that your pre-morning coffee brain is more awake than my post-lunch one. Well spotted - thank you.","23",2016-04-03,2016-04-03,1,204,"base.profile","Antoine","Lizee","alizee"
"1114","notes","rephetio","2016-04-03T20:19:09.802Z",23,"Correct","23",2016-04-03,2016-04-03,1,7,"base.profile","Antoine","Lizee","alizee"
"1115","notes","rephetio","2016-04-04T17:33:36.794Z",23,"@pouyakhankhanian I find your last remark interesting, but unfortunately not quite accurate. I'll try to show it below (notes are not good for math...)","23",2016-04-04,2016-04-04,1,151,"base.profile","Antoine","Lizee","alizee"
"1116","notes","rephetio","2016-04-04T18:19:03.130Z",188,"To be clear, I didn't mean ""derivative"" in the strict mathematical definition (i.e. d/dx f(x)) .  I supposed a better word would be a ""relative"" or ""derivation"", so please excuse the language. And I do agree that both functions are very similar, that was the point I was trying to make. I think Daniel understood the spirit of my comment and has addressed it appropriately.","188",2016-04-04,2016-04-04,1,373,"base.profile","Pouya","Khankhanian","pouyakhankhanian"
"1117","notes","rephetio","2016-04-04T18:29:09.339Z",23,"I thought it was maybe the case, but also that clarification might be useful in general.","23",2016-04-04,2016-04-04,1,88,"base.profile","Antoine","Lizee","alizee"
"1118","notes","rephetio","2016-04-04T18:37:42.089Z",23,"RStudio is getting better with every iteration and has improved significantly since this post. Many features (smart completion, tight git integration, ...) make it a better IDE today than the Jupyter notebooks in my opinion.","23",2016-04-04,2016-04-04,1,224,"base.profile","Antoine","Lizee","alizee"
"1119","notes","rephetio","2016-04-05T17:39:22.111Z",23,"I would love to see how sequential complexity predicts midpoint runtime when these results will be ready.","23",2016-04-05,2016-04-05,1,105,"base.profile","Antoine","Lizee","alizee"
"1120","notes","thinklabOSP","2016-02-23T03:50:33.441Z",2,"If this proposal is going to be funded it is very likely that the reviewers will come here to see the commentary. @caseygreene's comment compared the existing scientific system to a living organism (which is actually incredibly well optimized by evolution) and it also suggested that we were proposing to experiment with this system willy-nilly. Either suggestion would kill this proposal so I could not let them go unchallenged.","2",2016-02-23,2016-02-23,1,429,"base.profile","Jesse","Spaulding","jspauld"
"1121","threads","dFoxPoperant","2015-11-25T14:23:50.090Z",157,NA,"157",2015-11-25,2015-11-25,3,2,"base.profile","Björn","Brembs","brembs"
"1122","threads","dFoxPoperant","2015-12-01T17:13:33.160Z",NA,NA,NA,2015-12-01,2015-12-01,3,2,NA,NA,NA,NA
"1123","threads","dFoxPoperant","2015-12-01T20:33:03.623Z",2,NA,"2",2015-12-01,2015-12-01,3,2,"base.profile","Jesse","Spaulding","jspauld"
"1124","threads","EdgeProject","2016-02-23T23:33:01.236Z",48,NA,"48",2016-02-23,2016-02-23,3,2,"base.profile","Benjamin","Good","b_good"
"1125","threads","EdgeProject","2016-02-23T23:33:01.467Z",NA,NA,NA,2016-02-23,2016-02-23,3,2,NA,NA,NA,NA
"1126","threads","EdgeProject","2016-02-24T02:08:25.801Z",2,NA,"2",2016-02-24,2016-02-24,3,2,"base.profile","Jesse","Spaulding","jspauld"
"1127","threads","EdgeProject","2016-02-25T21:20:10.261Z",48,NA,"48",2016-02-25,2016-02-25,3,2,"base.profile","Benjamin","Good","b_good"
"1128","threads","HHMI_Bcr_Abl","2016-01-18T19:48:55.431Z",NA,NA,NA,2016-01-18,2016-01-18,3,2,NA,NA,NA,NA
"1129","threads","HHMI_Bcr_Abl","2016-01-18T23:51:24.055Z",48,NA,"48",2016-01-18,2016-01-18,3,2,"base.profile","Benjamin","Good","b_good"
"1130","threads","HHMI_Bcr_Abl","2016-01-19T16:59:17.873Z",48,NA,"48",2016-01-19,2016-01-19,3,2,"base.profile","Benjamin","Good","b_good"
"1131","threads","HHMI_Bcr_Abl","2016-01-31T05:30:14.232Z",187,NA,"187",2016-01-31,2016-01-31,3,2,"base.profile","Obi","Griffith","obigriffith"
"1132","threads","HHMI_Bcr_Abl","2016-02-05T05:19:40.782Z",17,NA,"17",2016-02-05,2016-02-05,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1133","threads","issnindiadatabase","2016-03-11T07:45:54.180Z",NA,NA,NA,2016-03-11,2016-03-11,3,2,NA,NA,NA,NA
"1134","threads","LWT_FOR_OPEN_SCIENCE","2016-03-01T04:00:24.065Z",NA,NA,NA,2016-03-01,2016-03-01,3,2,NA,NA,NA,NA
"1135","threads","meta","2015-01-15T23:27:18.322Z",2,NA,"2",2015-01-15,2015-01-15,3,2,"base.profile","Jesse","Spaulding","jspauld"
"1136","threads","meta","2015-01-23T22:35:21.795Z",17,NA,"17",2015-01-23,2015-01-23,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1137","threads","meta","2015-01-23T22:36:28.002Z",17,NA,"17",2015-01-23,2015-01-23,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1138","threads","meta","2015-01-26T15:08:52.580Z",17,NA,"17",2015-01-26,2015-01-26,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1139","threads","meta","2015-02-17T03:13:40.434Z",17,NA,"17",2015-02-17,2015-02-17,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1140","threads","meta","2015-02-22T05:42:25.323Z",17,NA,"17",2015-02-22,2015-02-22,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1141","threads","meta","2015-03-12T02:27:34.784Z",17,NA,"17",2015-03-12,2015-03-12,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1142","threads","meta","2015-03-31T23:05:03.024Z",2,NA,"2",2015-03-31,2015-03-31,3,2,"base.profile","Jesse","Spaulding","jspauld"
"1143","threads","meta","2015-04-03T21:04:07.199Z",17,NA,"17",2015-04-03,2015-04-03,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1144","threads","meta","2015-04-13T23:18:18.927Z",17,NA,"17",2015-04-13,2015-04-13,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1145","threads","meta","2015-04-20T19:50:11.876Z",84,NA,"84",2015-04-20,2015-04-20,3,2,"base.profile","Alex","Pankov","apankov"
"1146","threads","meta","2015-04-21T01:16:04.625Z",2,NA,"2",2015-04-21,2015-04-21,3,2,"base.profile","Jesse","Spaulding","jspauld"
"1147","threads","meta","2015-04-23T03:45:34.596Z",48,NA,"48",2015-04-23,2015-04-23,3,2,"base.profile","Benjamin","Good","b_good"
"1148","threads","meta","2015-04-23T18:53:53.860Z",17,NA,"17",2015-04-23,2015-04-23,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1149","threads","meta","2015-04-29T17:52:20.313Z",23,NA,"23",2015-04-29,2015-04-29,3,2,"base.profile","Antoine","Lizee","alizee"
"1150","threads","meta","2015-05-04T19:25:04.030Z",2,NA,"2",2015-05-04,2015-05-04,3,2,"base.profile","Jesse","Spaulding","jspauld"
"1151","threads","meta","2015-05-05T18:13:49.072Z",2,NA,"2",2015-05-05,2015-05-05,3,2,"base.profile","Jesse","Spaulding","jspauld"
"1152","threads","meta","2015-05-19T00:36:30.990Z",2,NA,"2",2015-05-19,2015-05-19,3,2,"base.profile","Jesse","Spaulding","jspauld"
"1153","threads","meta","2015-06-15T06:31:09.360Z",2,NA,"2",2015-06-15,2015-06-15,3,2,"base.profile","Jesse","Spaulding","jspauld"
"1154","threads","meta","2015-06-15T06:53:37.952Z",2,NA,"2",2015-06-15,2015-06-15,3,2,"base.profile","Jesse","Spaulding","jspauld"
"1155","threads","meta","2015-07-07T18:55:08.060Z",17,NA,"17",2015-07-07,2015-07-07,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1156","threads","meta","2015-08-09T05:54:31.203Z",125,NA,"125",2015-08-09,2015-08-09,3,2,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"1157","threads","meta","2015-08-11T05:02:30.184Z",17,NA,"17",2015-08-11,2015-08-11,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1158","threads","meta","2015-09-28T22:44:54.712Z",17,NA,"17",2015-09-28,2015-09-28,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1159","threads","meta","2015-10-04T17:23:13.962Z",17,NA,"17",2015-10-04,2015-10-04,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1160","threads","meta","2015-12-01T15:24:27.118Z",159,NA,"159",2015-12-01,2015-12-01,3,2,"base.profile","Joseph","McArthur","josephmcarthur"
"1161","threads","meta","2016-01-13T18:36:02.569Z",176,NA,"176",2016-01-13,2016-01-13,3,2,"base.profile","Tong Shu","Li","tongli"
"1162","threads","meta","2016-01-13T18:59:33.843Z",176,NA,"176",2016-01-13,2016-01-13,3,2,"base.profile","Tong Shu","Li","tongli"
"1163","threads","meta","2016-01-20T16:32:42.861Z",48,NA,"48",2016-01-20,2016-01-20,3,2,"base.profile","Benjamin","Good","b_good"
"1164","threads","meta","2016-02-17T22:56:27.690Z",17,NA,"17",2016-02-17,2016-02-17,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1165","threads","meta","2016-02-22T02:03:39.120Z",17,NA,"17",2016-02-22,2016-02-22,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1166","threads","meta","2016-03-22T21:26:45.161Z",17,NA,"17",2016-03-22,2016-03-22,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1167","threads","meta","2016-03-23T17:29:50.577Z",23,NA,"23",2016-03-23,2016-03-23,3,2,"base.profile","Antoine","Lizee","alizee"
"1168","threads","meta","2016-03-25T22:16:02.784Z",17,NA,"17",2016-03-25,2016-03-25,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1169","threads","meta","2016-03-26T06:01:08.698Z",17,NA,"17",2016-03-26,2016-03-26,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1170","threads","meta","2016-03-26T21:12:55.100Z",17,NA,"17",2016-03-26,2016-03-26,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1171","threads","meta","2016-04-05T06:40:59.646Z",23,NA,"23",2016-04-05,2016-04-05,3,2,"base.profile","Antoine","Lizee","alizee"
"1172","threads","meta","2016-04-07T23:03:45.759Z",23,NA,"23",2016-04-07,2016-04-07,3,2,"base.profile","Antoine","Lizee","alizee"
"1173","threads","MicrobeResist","2014-06-02T18:11:29.266Z",2,NA,"2",2014-06-02,2014-06-02,3,2,"base.profile","Jesse","Spaulding","jspauld"
"1174","threads","MicrobeResist","2014-06-03T19:42:05.765Z",4,NA,"4",2014-06-03,2014-06-03,3,2,"base.profile","Holly","Ganz","hollyganz"
"1175","threads","MicrobeResist","2014-06-03T23:01:17.321Z",2,NA,"2",2014-06-03,2014-06-03,3,2,"base.profile","Jesse","Spaulding","jspauld"
"1176","threads","MicrobeResist","2014-06-09T21:29:24.734Z",2,NA,"2",2014-06-09,2014-06-09,3,2,"base.profile","Jesse","Spaulding","jspauld"
"1177","threads","MicrobeResist","2014-06-10T23:08:38.726Z",4,NA,"4",2014-06-10,2014-06-10,3,2,"base.profile","Holly","Ganz","hollyganz"
"1178","threads","MicrobeResist","2014-06-11T23:59:22.634Z",2,NA,"2",2014-06-11,2014-06-11,3,2,"base.profile","Jesse","Spaulding","jspauld"
"1179","threads","MicrobeResist","2014-06-12T20:57:58.551Z",14,NA,"14",2014-06-12,2014-06-12,3,2,"base.profile","James","Meadow","JamesMeadow"
"1180","threads","MicrobeResist","2014-09-10T20:33:29.473Z",2,NA,"2",2014-09-10,2014-09-10,3,2,"base.profile","Jesse","Spaulding","jspauld"
"1181","threads","pathways4life","2015-06-09T02:28:14.495Z",104,NA,"104",2015-06-09,2015-06-09,3,2,"base.profile","Alexander","Pico","alexanderpico"
"1182","threads","pathways4life","2015-06-10T23:17:15.323Z",17,NA,"17",2015-06-10,2015-06-10,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1183","threads","pathways4life","2015-06-10T23:23:57.865Z",17,NA,"17",2015-06-10,2015-06-10,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1184","threads","pathways4life","2015-06-10T23:34:36.664Z",17,NA,"17",2015-06-10,2015-06-10,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1185","threads","pathways4life","2015-10-09T21:05:26.485Z",NA,NA,NA,2015-10-09,2015-10-09,3,2,NA,NA,NA,NA
"1186","threads","pathways4life","2015-10-30T23:15:04.302Z",2,NA,"2",2015-10-30,2015-10-30,3,2,"base.profile","Jesse","Spaulding","jspauld"
"1187","threads","pathways4life","2015-10-30T23:49:10.382Z",2,NA,"2",2015-10-30,2015-10-30,3,2,"base.profile","Jesse","Spaulding","jspauld"
"1188","threads","pathways4life","2015-10-31T00:11:28.596Z",2,NA,"2",2015-10-31,2015-10-31,3,2,"base.profile","Jesse","Spaulding","jspauld"
"1189","threads","pathways4life","2015-10-31T00:29:30.890Z",2,NA,"2",2015-10-31,2015-10-31,3,2,"base.profile","Jesse","Spaulding","jspauld"
"1190","threads","pathways4life","2015-10-31T00:48:03.240Z",2,NA,"2",2015-10-31,2015-10-31,3,2,"base.profile","Jesse","Spaulding","jspauld"
"1191","threads","rephetio","2015-01-14T05:55:24.808Z",17,NA,"17",2015-01-14,2015-01-14,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1192","threads","rephetio","2015-01-16T00:46:28.770Z",17,NA,"17",2015-01-16,2015-01-16,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1193","threads","rephetio","2015-01-16T10:18:57.231Z",2,NA,"2",2015-01-16,2015-01-16,3,2,"base.profile","Jesse","Spaulding","jspauld"
"1194","threads","rephetio","2015-01-22T18:14:09.267Z",17,NA,"17",2015-01-22,2015-01-22,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1195","threads","rephetio","2015-02-13T02:25:05.517Z",17,NA,"17",2015-02-13,2015-02-13,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1196","threads","rephetio","2015-02-17T02:21:47.729Z",17,NA,"17",2015-02-17,2015-02-17,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1197","threads","rephetio","2015-02-27T19:35:36.720Z",17,NA,"17",2015-02-27,2015-02-27,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1198","threads","rephetio","2015-03-12T16:26:39.575Z",17,NA,"17",2015-03-12,2015-03-12,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1199","threads","rephetio","2015-03-16T23:22:11.497Z",17,NA,"17",2015-03-16,2015-03-16,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1200","threads","rephetio","2015-03-19T19:15:53.241Z",35,NA,"35",2015-03-19,2015-03-19,3,2,"base.profile","Venkat","Malladi","vsmalladi"
"1201","threads","rephetio","2015-03-25T21:20:49.503Z",21,NA,"21",2015-03-25,2015-03-25,3,2,"base.profile","Leo","Brueggeman","leobrueggeman"
"1202","threads","rephetio","2015-03-27T02:43:44.010Z",17,NA,"17",2015-03-27,2015-03-27,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1203","threads","rephetio","2015-03-31T00:16:47.505Z",17,NA,"17",2015-03-31,2015-03-31,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1204","threads","rephetio","2015-04-02T17:16:17.459Z",17,NA,"17",2015-04-02,2015-04-02,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1205","threads","rephetio","2015-04-03T04:43:56.722Z",48,NA,"48",2015-04-03,2015-04-03,3,2,"base.profile","Benjamin","Good","b_good"
"1206","threads","rephetio","2015-04-03T04:53:35.463Z",48,NA,"48",2015-04-03,2015-04-03,3,2,"base.profile","Benjamin","Good","b_good"
"1207","threads","rephetio","2015-04-09T00:53:23.860Z",21,NA,"21",2015-04-09,2015-04-09,3,2,"base.profile","Leo","Brueggeman","leobrueggeman"
"1208","threads","rephetio","2015-04-09T17:39:42.860Z",21,NA,"21",2015-04-09,2015-04-09,3,2,"base.profile","Leo","Brueggeman","leobrueggeman"
"1209","threads","rephetio","2015-04-13T20:32:22.752Z",17,NA,"17",2015-04-13,2015-04-13,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1210","threads","rephetio","2015-04-23T03:38:31.895Z",17,NA,"17",2015-04-23,2015-04-23,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1211","threads","rephetio","2015-04-30T22:03:36.172Z",17,NA,"17",2015-04-30,2015-04-30,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1212","threads","rephetio","2015-05-01T14:51:24.521Z",17,NA,"17",2015-05-01,2015-05-01,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1213","threads","rephetio","2015-05-09T06:26:06.835Z",17,NA,"17",2015-05-09,2015-05-09,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1214","threads","rephetio","2015-05-09T13:55:34.587Z",22,NA,"22",2015-05-09,2015-05-09,3,2,"base.profile","Casey","Greene","caseygreene"
"1215","threads","rephetio","2015-05-10T21:10:43.786Z",17,NA,"17",2015-05-10,2015-05-10,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1216","threads","rephetio","2015-05-12T02:41:44.048Z",17,NA,"17",2015-05-12,2015-05-12,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1217","threads","rephetio","2015-05-19T02:56:31.048Z",17,NA,"17",2015-05-19,2015-05-19,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1218","threads","rephetio","2015-06-08T18:54:53.831Z",17,NA,"17",2015-06-08,2015-06-08,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1219","threads","rephetio","2015-06-09T01:15:52.882Z",104,NA,"104",2015-06-09,2015-06-09,3,2,"base.profile","Alexander","Pico","alexanderpico"
"1220","threads","rephetio","2015-06-16T20:43:50.470Z",17,NA,"17",2015-06-16,2015-06-16,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1221","threads","rephetio","2015-06-17T18:56:26.645Z",17,NA,"17",2015-06-17,2015-06-17,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1222","threads","rephetio","2015-06-17T20:51:35.121Z",17,NA,"17",2015-06-17,2015-06-17,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1223","threads","rephetio","2015-06-18T04:18:56.839Z",17,NA,"17",2015-06-18,2015-06-18,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1224","threads","rephetio","2015-06-24T05:08:18.194Z",17,NA,"17",2015-06-24,2015-06-24,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1225","threads","rephetio","2015-07-02T00:44:39.833Z",17,NA,"17",2015-07-02,2015-07-02,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1226","threads","rephetio","2015-07-10T18:15:03.705Z",17,NA,"17",2015-07-10,2015-07-10,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1227","threads","rephetio","2015-07-14T19:30:52.136Z",17,NA,"17",2015-07-14,2015-07-14,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1228","threads","rephetio","2015-07-14T19:55:24.432Z",17,NA,"17",2015-07-14,2015-07-14,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1229","threads","rephetio","2015-07-14T21:45:53.200Z",17,NA,"17",2015-07-14,2015-07-14,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1230","threads","rephetio","2015-07-28T21:14:07.053Z",17,NA,"17",2015-07-28,2015-07-28,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1231","threads","rephetio","2015-08-08T23:36:57.800Z",17,NA,"17",2015-08-08,2015-08-08,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1232","threads","rephetio","2015-08-12T23:40:14.796Z",17,NA,"17",2015-08-12,2015-08-12,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1233","threads","rephetio","2015-08-14T22:24:08.006Z",17,NA,"17",2015-08-14,2015-08-14,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1234","threads","rephetio","2015-08-17T02:56:46.304Z",17,NA,"17",2015-08-17,2015-08-17,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1235","threads","rephetio","2015-08-18T03:46:32.961Z",17,NA,"17",2015-08-18,2015-08-18,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1236","threads","rephetio","2015-08-20T21:45:22.187Z",17,NA,"17",2015-08-20,2015-08-20,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1237","threads","rephetio","2015-08-28T19:10:38.805Z",17,NA,"17",2015-08-28,2015-08-28,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1238","threads","rephetio","2015-09-28T18:33:52.774Z",17,NA,"17",2015-09-28,2015-09-28,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1239","threads","rephetio","2015-09-28T22:59:26.327Z",17,NA,"17",2015-09-28,2015-09-28,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1240","threads","rephetio","2015-10-02T01:58:42.504Z",17,NA,"17",2015-10-02,2015-10-02,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1241","threads","rephetio","2015-10-02T22:20:16.807Z",17,NA,"17",2015-10-02,2015-10-02,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1242","threads","rephetio","2015-10-03T20:51:26.506Z",17,NA,"17",2015-10-03,2015-10-03,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1243","threads","rephetio","2015-10-04T18:59:31.943Z",17,NA,"17",2015-10-04,2015-10-04,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1244","threads","rephetio","2015-11-04T02:25:25.390Z",17,NA,"17",2015-11-04,2015-11-04,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1245","threads","rephetio","2015-11-30T20:04:57.637Z",17,NA,"17",2015-11-30,2015-11-30,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1246","threads","rephetio","2015-12-09T02:51:40.846Z",17,NA,"17",2015-12-09,2015-12-09,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1247","threads","rephetio","2015-12-22T01:25:50.912Z",17,NA,"17",2015-12-22,2015-12-22,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1248","threads","rephetio","2016-02-17T19:43:44.509Z",17,NA,"17",2016-02-17,2016-02-17,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1249","threads","rephetio","2016-02-26T17:17:30.782Z",17,NA,"17",2016-02-26,2016-02-26,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1250","threads","rephetio","2016-02-25T22:56:18.276Z",17,NA,"17",2016-02-25,2016-02-25,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1251","threads","rephetio","2016-03-08T20:48:53.483Z",17,NA,"17",2016-03-08,2016-03-08,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1252","threads","rephetio","2016-03-15T05:24:35.059Z",17,NA,"17",2016-03-15,2016-03-15,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1253","threads","rephetio","2016-03-11T22:41:36.229Z",17,NA,"17",2016-03-11,2016-03-11,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1254","threads","rephetio","2016-03-20T16:41:10.657Z",17,NA,"17",2016-03-20,2016-03-20,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1255","threads","rephetio","2016-03-22T17:03:53.346Z",17,NA,"17",2016-03-22,2016-03-22,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1256","threads","rephetio","2016-04-01T21:13:21.069Z",17,NA,"17",2016-04-01,2016-04-01,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1257","threads","rephetio","2016-04-05T22:49:42.877Z",23,NA,"23",2016-04-05,2016-04-05,3,2,"base.profile","Antoine","Lizee","alizee"
"1258","threads","thinklabOSP","2016-02-15T16:34:22.887Z",NA,NA,NA,2016-02-15,2016-02-15,3,2,NA,NA,NA,NA
"1259","threads","thinklabOSP","2016-02-19T06:41:11.751Z",17,NA,"17",2016-02-19,2016-02-19,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1260","threads","thinklabOSP","2016-02-16T12:50:44.652Z",125,NA,"125",2016-02-16,2016-02-16,3,2,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"1261","threads","thinklabOSP","2016-02-19T06:04:20.499Z",17,NA,"17",2016-02-19,2016-02-19,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1262","threads","thinklabOSP","2016-02-19T06:44:20.761Z",17,NA,"17",2016-02-19,2016-02-19,3,2,"base.profile","Daniel","Himmelstein","dhimmel"
"1263","threads","thinklabOSP","2016-02-19T15:23:58.915Z",125,NA,"125",2016-02-19,2016-02-19,3,2,"base.profile","Lars Juhl","Jensen","larsjuhljensen"
"1264","threads","thinklabOSP","2016-02-22T18:39:50.971Z",22,NA,"22",2016-02-22,2016-02-22,3,2,"base.profile","Casey","Greene","caseygreene"
"1265","threads","thinklabOSP","2016-02-22T22:19:23.706Z",2,NA,"2",2016-02-22,2016-02-22,3,2,"base.profile","Jesse","Spaulding","jspauld"
"1266","threads","thinklabOSP","2016-02-24T02:03:23.183Z",25,NA,"25",2016-02-24,2016-02-24,3,2,"base.profile","Daniel","Mietchen","daniel_mietchen"
