{
  "comments": [
    {
      "fields": {
        "body_html": "<p>Not sure if this discussion fits here or should wait for the larger, technical part of the proposal, but we will need to explain why we think we should do this in a dynamic manner (query the web on demand) rather than building an all-encompassing data warehouse as the first step and how we are realistically going to make this happen.</p>\r\n\r\n<p>Why: The Web evolves constantly, keeping a warehouse in sync is very difficult and maintaining a very large knowledge graph (e.g. a SPARQL server) is expensive.  If answers could be gathered automatically via a distributed services that could go up and and come down, it would be more sustainable and more extensible.  </p>\r\n\r\n<p>How: The workflows would be constrained according to a set of important semantic types (genes, drugs, diseases).  Based on these constraints, we would map out paths (stories) to compose the workflows.  A plugin/registry system such as BioCatalogue would be used to identify functional services that would meet the requests.  The outputs would be modeled in nanopublication RDF, integrated, and delivered to the client for rendering.  Note this would probably not be instantaneous..</p>",
        "body_md": "Not sure if this discussion fits here or should wait for the larger, technical part of the proposal, but we will need to explain why we think we should do this in a dynamic manner (query the web on demand) rather than building an all-encompassing data warehouse as the first step and how we are realistically going to make this happen.\r\n\r\nWhy: The Web evolves constantly, keeping a warehouse in sync is very difficult and maintaining a very large knowledge graph (e.g. a SPARQL server) is expensive.  If answers could be gathered automatically via a distributed services that could go up and and come down, it would be more sustainable and more extensible.  \r\n\r\nHow: The workflows would be constrained according to a set of important semantic types (genes, drugs, diseases).  Based on these constraints, we would map out paths (stories) to compose the workflows.  A plugin/registry system such as BioCatalogue would be used to identify functional services that would meet the requests.  The outputs would be modeled in nanopublication RDF, integrated, and delivered to the client for rendering.  Note this would probably not be instantaneous..",
        "profile": 48,
        "published": "2016-02-23T23:33:01.306Z",
        "thread": 172
      },
      "model": "base.comment",
      "pk": 1062
    },
    {
      "fields": {
        "body_html": "<p>I think if this is intended to be beneficial to the general public, there needs to be sections of the proposal that explain the value in terms the general public will understand. I would give clear examples that describe the users need, what they do in the app/website, what information is returned to them, and how it works on the backend technically.</p>\r\n\r\n<p>Unfortunately I don't have the expertise to comment on the viability of the approach itself.</p>",
        "body_md": "I think if this is intended to be beneficial to the general public, there needs to be sections of the proposal that explain the value in terms the general public will understand. I would give clear examples that describe the users need, what they do in the app/website, what information is returned to them, and how it works on the backend technically.\r\n\r\nUnfortunately I don't have the expertise to comment on the viability of the approach itself.",
        "profile": 2,
        "published": "2016-02-24T02:08:25.831Z",
        "thread": 176
      },
      "model": "base.comment",
      "pk": 1110
    },
    {
      "fields": {
        "body_html": "<p>Seems very vague </p>",
        "body_md": "Seems very vague ",
        "profile": 2,
        "published": "2016-02-24T02:08:37.415Z",
        "thread": 174
      },
      "model": "base.comment",
      "pk": 1111
    },
    {
      "fields": {
        "body_html": "<p>Maybe you should/could use some language that would be compelling to the user you are targeting?  I really couldn't make much sense of this sentence upon first reading. And maybe give an example of what a user might enter and what information they might bet back. </p>",
        "body_md": "Maybe you should/could use some language that would be compelling to the user you are targeting?  I really couldn't make much sense of this sentence upon first reading. And maybe give an example of what a user might enter and what information they might bet back. ",
        "profile": 2,
        "published": "2016-02-24T02:08:41.227Z",
        "thread": 174
      },
      "model": "base.comment",
      "pk": 1112
    },
    {
      "fields": {
        "body_html": "<p>It's actually not that clear to me what \"why\" means here. The question for me might be \"what is the relationship between them?\" </p>",
        "body_md": "It's actually not that clear to me what \"why\" means here. The question for me might be \"what is the relationship between them?\" ",
        "profile": 2,
        "published": "2016-02-24T02:08:45.833Z",
        "thread": 174
      },
      "model": "base.comment",
      "pk": 1113
    },
    {
      "fields": {
        "body_html": "<p>Do you mean by looking at nano-publications? If so, do enough of them exist for this to be useful? </p>",
        "body_md": "Do you mean by looking at nano-publications? If so, do enough of them exist for this to be useful? ",
        "profile": 2,
        "published": "2016-02-24T02:08:51.591Z",
        "thread": 174
      },
      "model": "base.comment",
      "pk": 1114
    },
    {
      "fields": {
        "body_html": "<p>Building a mobile application seems like a totally separate challenge that you don't necessarily need to embark upon. Why not just create a simple web interface that proves the technology and let others build a mobile app or website? Isn't creating the core technology challenging enough? </p>",
        "body_md": "Building a mobile application seems like a totally separate challenge that you don't necessarily need to embark upon. Why not just create a simple web interface that proves the technology and let others build a mobile app or website? Isn't creating the core technology challenging enough? ",
        "profile": 2,
        "published": "2016-02-24T02:08:55.835Z",
        "thread": 174
      },
      "model": "base.comment",
      "pk": 1115
    },
    {
      "fields": {
        "body_html": "<p>Agreed and in the works.  Maybe, as usual, a better more specific example would help explain things better in the short space of a 1 page idea.</p>",
        "body_md": "Agreed and in the works.  Maybe, as usual, a better more specific example would help explain things better in the short space of a 1 page idea.",
        "profile": 48,
        "published": "2016-02-24T07:33:46.523Z",
        "thread": 176
      },
      "model": "base.comment",
      "pk": 1131
    },
    {
      "fields": {
        "body_html": "<p>Another point that we need to address is the data cleaning. One reason for the warehouse approach is that testing procedures can be built in efficiently in order to clean the data. This is much more challenging in a dynamic approach. We can argue that we make use of sources with at least some level of data cleaning in place already and that we leave the rest to the user. By suppling the user with tools to annotate and even change links themselves we give them power.</p>",
        "body_md": "Another point that we need to address is the data cleaning. One reason for the warehouse approach is that testing procedures can be built in efficiently in order to clean the data. This is much more challenging in a dynamic approach. We can argue that we make use of sources with at least some level of data cleaning in place already and that we leave the rest to the user. By suppling the user with tools to annotate and even change links themselves we give them power.",
        "profile": 196,
        "published": "2016-02-24T09:47:44.538Z",
        "thread": 172
      },
      "model": "base.comment",
      "pk": 1132
    },
    {
      "fields": {
        "body_html": "<p>Based on the quick, early feedback received here and on twitter we are re-writing this proposal from the ground up.  This is taking place in a google document: <br><a href=\"https://docs.google.com/document/d/1VoObxwVDtjHDenGpQLFNK4UCuZxuT3-RY7mDnYjLd00/edit\">https://docs.google.com/document/d/1VoObxwVDtjHDenGpQLFNK4UCuZxuT3-RY7mDnYjLd00/edit</a><br>Not sure how best to integrate that process (rewriting) with the ThinkLab process?  Especially in an extremely small window of time.. </p>",
        "body_md": "Based on the quick, early feedback received here and on twitter we are re-writing this proposal from the ground up.  This is taking place in a google document: \r\nhttps://docs.google.com/document/d/1VoObxwVDtjHDenGpQLFNK4UCuZxuT3-RY7mDnYjLd00/edit\r\nNot sure how best to integrate that process (rewriting) with the ThinkLab process?  Especially in an extremely small window of time..",
        "profile": 48,
        "published": "2016-02-25T21:20:10.304Z",
        "thread": 177
      },
      "model": "base.comment",
      "pk": 1134
    },
    {
      "fields": {
        "body_html": "<p>We've just updated the site so you can now \"End Review of Version\" from the \"Manage\" page of the proposal. I went ahead and did this for you. Thinklab is not the really intended as a tool for collaborative writing, so it makes sense that you're doing that in Google Docs. Thinklab would come back into play if you had a more complete version that you wanted to have reviewed. (There's an \"Open for Review\") button. I guess there's not a lot of time left now :)</p>",
        "body_md": "We've just updated the site so you can now \"End Review of Version\" from the \"Manage\" page of the proposal. I went ahead and did this for you. Thinklab is not the really intended as a tool for collaborative writing, so it makes sense that you're doing that in Google Docs. Thinklab would come back into play if you had a more complete version that you wanted to have reviewed. (There's an \"Open for Review\") button. I guess there's not a lot of time left now :)",
        "profile": 2,
        "published": "2016-02-26T07:00:14.080Z",
        "thread": 177
      },
      "model": "base.comment",
      "pk": 1136
    },
    {
      "fields": {
        "body_html": "<p>As you can see, this is a bit of a challenge.  Typically we end up writing in Google docs until the last possible moment.  To use ThinkLab effectively would require a lot of discipline in terms of self-imposed deadlines that were sufficiently in advance of actual hard deadlines to allow for the process to unfold.  No one would argue that such discipline would improve the end-product, ThinkLab or not.  I can tell you from my personal situation over the past 2 months leading up to this particular proposal that the delay was not for lack of trying..  Just too many things to do that are all top priority.  </p>\r\n\r\n<p>I think its worth thinking hard about the relationship between ThinkLab and real collaborative editing.  If you could embed a live Google doc as an entity in this framework, you might make more progress in opening up the entire process.  I'm not sure if the citable, frozen versions are the best things during the creative process.  In cases like this proposal and Toby's earlier one, I think it would be better if things could be adapted quickly in response to feedback.</p>\r\n\r\n<p>Now if you could make it such that the agencies that hand out the money made ThinkLab a necessary stop on the way to submission, you would get the missing 'real' deadline that would be needed to make this really work.</p>",
        "body_md": "As you can see, this is a bit of a challenge.  Typically we end up writing in Google docs until the last possible moment.  To use ThinkLab effectively would require a lot of discipline in terms of self-imposed deadlines that were sufficiently in advance of actual hard deadlines to allow for the process to unfold.  No one would argue that such discipline would improve the end-product, ThinkLab or not.  I can tell you from my personal situation over the past 2 months leading up to this particular proposal that the delay was not for lack of trying..  Just too many things to do that are all top priority.  \r\n\r\nI think its worth thinking hard about the relationship between ThinkLab and real collaborative editing.  If you could embed a live Google doc as an entity in this framework, you might make more progress in opening up the entire process.  I'm not sure if the citable, frozen versions are the best things during the creative process.  In cases like this proposal and Toby's earlier one, I think it would be better if things could be adapted quickly in response to feedback.\r\n\r\nNow if you could make it such that the agencies that hand out the money made ThinkLab a necessary stop on the way to submission, you would get the missing 'real' deadline that would be needed to make this really work.",
        "profile": 48,
        "published": "2016-02-26T17:27:13.491Z",
        "thread": 177
      },
      "model": "base.comment",
      "pk": 1138
    }
  ],
  "documents": [
    {
      "fields": {
        "body_html": "<p>We propose to create a mobile application for the Life Sciences, targeting non-technical users, that will provide candidate explanations for relationships between pairs of concepts based on information harvested dynamically from the Web.  </p>\r\n\r\n<p>Active researchers, curious citizens, and desperate patients have access to a vast collection of associations, both meaningful and imaginary.  Zika and microcephaly, NGLY1 deficiency and alacrima, mianserin and life extension, eggs and cholesterol, etc..  For scientists, new candidate associations now routinely emerge from high-throughput screens.  For the general public, media-friendly, often vague and sometimes completely unfounded associations are a daily experience.  For patients and their family members, the associations are personal and directly observed: taking a drug and having a reaction, having a rare genetic mutation and whole constellation of associated symptoms, eating bread and having an upset stomach, etc. etc..  The question that unites all of these associations is “why?”.  </p>\r\n\r\n<p>Currently, people primarily turn to Google searches for answers to this question, yet lists of documents where terms co-occur are a far cry from a direct, well-supported explanation of the relationships that hold or do not hold between two concepts.  This is one reason that all of the major search engines are building “knowledge graphs” in their attempts to improve their services <a href=\"https://www.google.com/intl/bn/insidesearch/features/search/knowledge.html\">https://www.google.com/intl/bn/insidesearch/features/search/knowledge.html</a> .  Knowledge graphs are structured networks of concepts linked together with semantic relationships.  These networks, whose roots lie in decades of research in artificial intelligence research, are the building blocks of true question answering services.</p>\r\n\r\n<p>Knowledge graphs, generated by human knowledge engineers, machine reading of the literature, and all manner of increasingly accessible databases can help provide evidence supporting, refuting or explaining potential relationships.  Yet, to date, there is a substantial divide between this potential and its realization - especially for non-data scientists.  This divide is the result of both the technical challenges of gathering, integrating and querying distributed information and of delivering effective user interfaces.  </p>\r\n\r\n<p>Today, the maturing work of the Linked Data community is making it possible to dynamically gather the contents of knowledge graphs through SPARQL endpoints such as those provided by the EBI <a href=\"https://www.ebi.ac.uk/rdf/\">https://www.ebi.ac.uk/rdf/</a> and an increasing number of Web APIs such as OpenPHACTS <a href=\"https://dev.openphacts.org/docs/2.0\">https://dev.openphacts.org/docs/2.0</a>, <a href=\"http://mygene.info\">http://mygene.info</a>, and <a href=\"http://query.wikidata.org\">http://query.wikidata.org</a> that implement the key Linked Data principles of unique concept identifiers and standard data formats such as JSON-LD.  With access to these services the task of assembling knowledge graphs on demand is approachable, yet this is still not enough.  In the context of explanation generation, the formalization of knowledge as a graph of concept nodes generates two important requirements:</p>\r\n\r\n<ul><li>Given an edge connecting two nodes, provide evidence for or against it.</li><li>When nodes are not directly connected (or if more evidence is desired for a particular edge), use intervening nodes to provide candidate explanations for associations observed or hypothesized to exist between those nodes.</li></ul>\r\n\r\n<p>We propose to address the first challenge using the nanopublication model [http://nanopub.org/]. Data providing evidence for or against an edge will be gathered from nanopublication stores or dynamically structured according to this data model facilitating dynamic integration and display.  For the second challenge we propose to enhance current graph algorithms (e.g. shortest path) using the paradigm of semantic storytelling.  Experts will help design 'stories' that form the structure of meaningful explanations for associations between concepts.   These stories will be captured as automated workflows, each with 2 concepts as inputs (e.g. a disease and drug) and candidate, human readable explanations as output.  We will apply these technical innovations in the context of an application designed to bring the biomedical knowledge of the Web into the hands of any person with access to a mobile phone.</p>",
        "body_md": "We propose to create a mobile application for the Life Sciences, targeting non-technical users, that will provide candidate explanations for relationships between pairs of concepts based on information harvested dynamically from the Web.  \r\n\r\nActive researchers, curious citizens, and desperate patients have access to a vast collection of associations, both meaningful and imaginary.  Zika and microcephaly, NGLY1 deficiency and alacrima, mianserin and life extension, eggs and cholesterol, etc..  For scientists, new candidate associations now routinely emerge from high-throughput screens.  For the general public, media-friendly, often vague and sometimes completely unfounded associations are a daily experience.  For patients and their family members, the associations are personal and directly observed: taking a drug and having a reaction, having a rare genetic mutation and whole constellation of associated symptoms, eating bread and having an upset stomach, etc. etc..  The question that unites all of these associations is “why?”.  \r\n\r\nCurrently, people primarily turn to Google searches for answers to this question, yet lists of documents where terms co-occur are a far cry from a direct, well-supported explanation of the relationships that hold or do not hold between two concepts.  This is one reason that all of the major search engines are building “knowledge graphs” in their attempts to improve their services https://www.google.com/intl/bn/insidesearch/features/search/knowledge.html .  Knowledge graphs are structured networks of concepts linked together with semantic relationships.  These networks, whose roots lie in decades of research in artificial intelligence research, are the building blocks of true question answering services.\r\n\r\nKnowledge graphs, generated by human knowledge engineers, machine reading of the literature, and all manner of increasingly accessible databases can help provide evidence supporting, refuting or explaining potential relationships.  Yet, to date, there is a substantial divide between this potential and its realization - especially for non-data scientists.  This divide is the result of both the technical challenges of gathering, integrating and querying distributed information and of delivering effective user interfaces.  \r\n\r\nToday, the maturing work of the Linked Data community is making it possible to dynamically gather the contents of knowledge graphs through SPARQL endpoints such as those provided by the EBI https://www.ebi.ac.uk/rdf/ and an increasing number of Web APIs such as OpenPHACTS https://dev.openphacts.org/docs/2.0, http://mygene.info, and http://query.wikidata.org that implement the key Linked Data principles of unique concept identifiers and standard data formats such as JSON-LD.  With access to these services the task of assembling knowledge graphs on demand is approachable, yet this is still not enough.  In the context of explanation generation, the formalization of knowledge as a graph of concept nodes generates two important requirements:\r\n\r\n * Given an edge connecting two nodes, provide evidence for or against it.\r\n * When nodes are not directly connected (or if more evidence is desired for a particular edge), use intervening nodes to provide candidate explanations for associations observed or hypothesized to exist between those nodes.\r\n\r\nWe propose to address the first challenge using the nanopublication model [http://nanopub.org/]. Data providing evidence for or against an edge will be gathered from nanopublication stores or dynamically structured according to this data model facilitating dynamic integration and display.  For the second challenge we propose to enhance current graph algorithms (e.g. shortest path) using the paradigm of semantic storytelling.  Experts will help design 'stories' that form the structure of meaningful explanations for associations between concepts.   These stories will be captured as automated workflows, each with 2 concepts as inputs (e.g. a disease and drug) and candidate, human readable explanations as output.  We will apply these technical innovations in the context of an application designed to bring the biomedical knowledge of the Web into the hands of any person with access to a mobile phone.",
        "doc_published": "2016-02-23T23:33:01.153Z",
        "intro_html": "",
        "intro_md": "",
        "title": "",
        "topic_field": ""
      },
      "model": "base.document",
      "pk": 14
    }
  ],
  "notes": [],
  "profiles": [
    {
      "fields": {
        "first_name": "Jesse",
        "last_name": "Spaulding",
        "username": "jspauld"
      },
      "model": "base.profile",
      "pk": 2
    },
    {
      "fields": {
        "first_name": "Benjamin",
        "last_name": "Good",
        "username": "b_good"
      },
      "model": "base.profile",
      "pk": 48
    },
    {
      "fields": {
        "first_name": "Kristina",
        "last_name": "Hettne",
        "username": "kristinahettne"
      },
      "model": "base.profile",
      "pk": 196
    }
  ],
  "retrieved": "2016-04-09T03:28:51.202599Z",
  "threads": [
    {
      "fields": {
        "document": null,
        "doi_field": "",
        "profile": 48,
        "published": "2016-02-23T23:33:01.236Z",
        "subject": "dynamic sub-graph assembly versus data warehousing",
        "topic_field": "semantic web,linked data,question answering,workflows"
      },
      "model": "base.thread",
      "pk": 172
    },
    {
      "fields": {
        "document": 14,
        "doi_field": null,
        "profile": null,
        "published": "2016-02-23T23:33:01.467Z",
        "subject": "",
        "topic_field": ""
      },
      "model": "base.thread",
      "pk": 174
    },
    {
      "fields": {
        "document": 14,
        "doi_field": null,
        "profile": 2,
        "published": "2016-02-24T02:08:25.801Z",
        "subject": "",
        "topic_field": ""
      },
      "model": "base.thread",
      "pk": 176
    },
    {
      "fields": {
        "document": null,
        "doi_field": "",
        "profile": 48,
        "published": "2016-02-25T21:20:10.261Z",
        "subject": "what to do when you start over",
        "topic_field": "ThinkLab,google docs"
      },
      "model": "base.thread",
      "pk": 177
    }
  ]
}